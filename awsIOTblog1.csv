,Title,Author,Published_date,Image,Link,Description
0,Optimize image classification on AWS IoT Greengrass using ONNX Runtime,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/04/17/Optimize-image-classification-on-AWS-IoT-Greengrass-using-ONNX-Runtime.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/optimize-image-classification-on-aws-iot-greengrass-using-onnx-runtime/,"b'Introduction\nPerforming machine learning inference on edge devices using models trained in the cloud has become a popular use case in Internet of Things (IoT) as it brings the benefits of low latency, scalability, and cost savings. When deploying models to edge devices with limited compute and memory, developers have the challenge to manually tune the model to achieve the desired performance. In this blog post, I will discuss an example on how to use the ONNX Runtime on AWS IoT Greengrass to optimize image classification at the edge.\nONNX is an open format built to represent any type of machine learning or deep learning model while making it easier to access hardware optimizations. It provides a standard format for interoperability between different machine learning frameworks. You can train an image classification model using one of your preferred frameworks (TensorFlow, PyTorch, MxNet, and more) and then export it to ONNX format. To maximize performance, you can use your ONNX models with an optimized inference framework, like ONNX Runtime. ONNX Runtime is an open source project designed to accelerate machine learning inference across a variety of frameworks, operating systems, and hardware platforms with a single set of APIs. While this blog post focuses on an example for image classification, you can use ONNX for a wide range of use cases, like object detection, image segmentation, speech and audio processing, machine comprehension and translation, and more.\nAWS IoT Greengrass is an open source Internet of Things (IoT) edge runtime and cloud service that helps you build, deploy, and manage IoT applications on your devices. You can use AWS IoT Greengrass to build edge applications using software modules, called components, that can connect your edge devices to AWS or third-party services. There are several AWS-provided machine learning components that can be used to perform inference on remote devices, with locally generated data, using models trained in the cloud. You can also build your custom machine learning components which can be divided in two categories: components for deploying and updating your machine learning models and runtimes at the edge as well as components that contain the necessary application logic for performing machine learning inference.\nSolution Overview\nIn this example, you will learn how to build and deploy a custom component for image classification on AWS IoT Greengrass. The below architecture and steps represent a possible implementation for this solution.\n1. Train a model using your preferred framework and export it to ONNX format, or use a pre-trained ONNX model. You can use Amazon SageMaker Studio and Amazon SageMaker Pipelines to automate this process.\nIn this blog post, you will be using a pre-trained ResNet-50 model in ONNX format for image classification available from the ONNX Model Zoo. ResNet-50 is a convolutional neural network with 50 layers and the pre-trained version of the model can classify images into a thousand object categories, such as keyboard, mouse, pencil, and many animals.\n2. Build and publish the necessary AWS IoT Greengrass components:\nAn ONNX Runtime component that contains the necessary libraries to run the ONNX model.\nA component for inference that contains the necessary code, the ResNet-50 model in ONNX format as well as some labels and sample images that will be used for classification. This component will have a dependency on the ONNX Runtime component.\n3. Deploy the component on the target device. Once the component is running, it will classify the sample images and publish the results back to AWS IoT Core to the topic demo/onnx. AWS IoT Core is a managed AWS service that let\xe2\x80\x99s you connect billions of IoT devices and route trillions of messages to AWS services without managing infrastructure.\nPrerequisites\nTo be able to run through the steps in this blog post, you will need:\nBasic knowledge of AWS IoT Core and AWS IoT Greengrass.\nBasic understanding of machine learning concepts.\nAn AWS Account.  If you don\xe2\x80\x99t have an AWS Account, follow the instructions to create one.\nAWS Command Line Interface (AWS CLI) and Git installed.\nAn AWS Identity and Access Management (IAM) user with the necessary permissions for creating and managing AWS resources.\nImplementation walkthrough\nInitial setup\nAs part of the initial setup for the environment, there are several resources that you need to provision. All the resources need to be provisioned in the same region. This guide is using the eu-central-1 region. Follow the steps below to get started:\n1. The component\xe2\x80\x99s artifacts are going to be stored in an Amazon Simple Storage Service (Amazon S3) bucket. To create an Amazon S3 bucket, follow the instructions from the user guide.\n2. To emulate a device where we will deploy the component, you will use an AWS Cloud9 environment and then install AWS IoT Greengrass client software. To perform these steps, follow the instructions from the AWS IoT Greengrass v2 workshop, sections 2 and 3.1.\n3. On the AWS Cloud9 environment, make sure you have python 3.6.9 as well as pip 23.0 or higher installed.\nBuild and publish the ONNX Runtime and inference components\nIn the next section, you will build and publish the custom components by using AWS CLI, either from a terminal on the local machine or in an AWS Cloud9 environment.\nTo upload the artifacts to the Amazon S3 bucket created as part of the initial setup, follow the next steps:\n1. Clone the git repository that contains the component\xe2\x80\x99s artifacts and recipe:\ngit clone https://github.com/aws-samples/aws-iot-gg-onnx-runtime.git\nBash\n2. Navigate to the artifacts folder and zip the files:\ncd aws-iot-gg-onnx-runtime/artifacts/com.demo.onnx-imageclassification/1.0.0 \nzip -r greengrass-onnx.zip .\nBash\n3. Upload the zip file to the Amazon S3 bucket that you created in the initial setup:\naws s3 cp greengrass-onnx.zip s3://{YOUR-S3-BUCKET}/greengrass-onnx.zip\nBash\nTo publish the components, perform the following steps:\n1. Open the recipe file aws-iot-gg-onnx-runtime/recipes/com.demo.onnx-imageclassification-1.0.0.json in a text editor. Below you have the command to navigate to the recipes directory:\ncd aws-iot-gg-onnx-runtime/recipes/\nBash\n2. Replace the Amazon S3 bucket name in artifacts URI with your own bucket name defined above:\n""Artifacts"": [\n    {\n      ""URI"": ""s3://{YOUR-S3-BUCKET}/greengrass-onnx.zip"",\n      ""Unarchive"": ""ZIP""\n    }\n  ]\nJSON\n3. Before publishing the component, make sure that you are using the same region where you created the resources in the initial setup. You can set your default region by using the following command:\naws configure set default.region eu-central-1\nBash\n4. Publish the ONNX Runtime component:\naws greengrassv2 create-component-version --inline-recipe fileb://com.demo.onnxruntime-1.0.0.json\nBash\n5. Publish the component that will perform the image classification and that has a dependency on the ONNX Runtime:\naws greengrassv2 create-component-version --inline-recipe fileb://com.demo.onnx-imageclassification-1.0.0.json\nBash\n6. To verify that the components were published successfully, navigate to the AWS IoT Console, go to Greengrass Devices >> Components. In the My Components tab, you should see the two components that you just published:\nDeploy the component to a target device\n1. To deploy the component to a target device, make sure that you have provisioned an AWS Cloud9 environment with AWS IoT Greengrass client software installed.\n2. To setup the necessary permissions for the Greengrass device, make sure that the service role associated with the Greengrass device has permissions to retrieve objects from the Amazon S3 bucket you previously created as well as permissions to publish to the AWS IoT topic demo/onnx.\n3. To deploy the component to the target device, go to the AWS IoT Console, navigate to Greengrass Devices >> Deployments and choose Create.\n4. Fill in the deployment name as well as the name of the core device you want to deploy to.\n\n5. In the Select Components section, select the component com.demo.onnx-imageclassification.\n6. Leave all other options as default and choose Next until you reach the Review section of your deployment and then choose Deploy.\n7. To monitor the logs and progress of the components\xe2\x80\x99 deployment, you can open the log file of Greengrass core device on the AWS Cloud9 environment with the following command:\nsudo tail -f /greengrass/v2/logs/greengrass.log\nBash\n8. Please note that the ONNX Runtime component, com.demo.onnxruntime, is automatically installed since the image classification component that we selected for deployment has a dependency on it.\nTest the ONNX image classification component deployment\nWhen the image classification component is in the running state, it will loop through the files in the images folder and it will classify them. The results are published to AWS IoT Core to the topic demo/onnx.\nTo understand this process, let\xe2\x80\x99s have a look at some code snippets from the image classification component:\n1. To check the sample images so that you can later compare them with the predicted labels, please open the images located in aws-iot-gg-onnx-runtime/artifacts/com.demo.onnx-imageclassification/1.0.0/images folder.\n2. The predict function shown below starts an inference session using the ONNX Runtime and the pre-trained ResNet-50 neural network in ONNX format.\ndef predict(modelPath, labelsPath, image):\n    labels = load_labels(labelsPath)\n    # Run the model on the backend\n    session = onnxruntime.InferenceSession(modelPath, None)\nPython\n3. The image is initially preprocessed and then passed as an input parameter to the inference session. Please note that ResNet-50 model uses images of 224 x 224 pixels.\nimage_data = np.array(image).transpose(2, 0, 1)\ninput_data = preprocess(image_data)\nstart = time.time()\nraw_result = session.run([], {input_name: input_data})\nend = time.time()\nPython\n4.  From the inference result, you extract the label of the image, and you also calculate the inference time in milliseconds.\ninference_time = np.round((end - start) * 1000, 2)\nidx = np.argmax(postprocess(raw_result))\ninferenceResult = {\n ""label"": labels[idx],\n ""inference_time"": inference_time\n}\nPython\n5. The image classification component loops through the files present in the images folder and invokes the predict function. The results are published to AWS IoT Core to the demo/onnx topic every 5 seconds.\nfor img in os.listdir(imagesPath):\n        request = PublishToIoTCoreRequest()\n        request.topic_name = topic\n        image = Image.open(imagesPath + ""/"" + img)\n        pred = predict(modelPath, labelsPath, image)\n        request.payload = pred.encode()\n        request.qos = qos\n        operation = ipc_client.new_publish_to_iot_core()\n        operation.activate(request)\n        future_response = operation.get_response().result(timeout=5)\n        print(""successfully published message: "", future_response)\n        time.sleep(5)\nPython\nTo test that the results have been published successfully to the topic, go to AWS IoT Console, navigate to MQTT Client section and subscribe to the topic demo/onnx. You should see the inference results like in the screenshot below:\nCleaning up\nIt is a best practice to delete resources you no longer want to use. To avoid incurring additional costs on your AWS account, perform the following steps:\n1. Delete the AWS Cloud9 environment where the AWS IoT Greengrass software was installed:\naws cloud9 delete-environment --environment-id <your environment id>\nBash\n2. Delete the Greengrass core device:\naws greengrassv2 delete-core-device --core-device-thing-name <thing-name>\nBash\n3. Delete the Amazon S3 bucket where the artifacts are stored:\naws s3 rb s3://{YOUR-S3-BUCKET} --force\nBash\n'"
1,Protecting Linux-based IoT devices against unintended USB access,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/04/14/Protecting-Linux-based-IoT-devices-against-unintended-USB-access.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/protecting-linux-based-iot-devices-against-unintended-usb-access/,"b'Introduction\nThe Internet of Things (IoT) industry continues to grow at an aggressive pace. As the number of connected devices ramps up, managing security of these devices at scale can be challenging. One of the potential risks that IoT devices face is unintended USB access, which can occur when an unauthorized connection is made through its USB port. For example, if a user gains physical access to a security camera system, there\xe2\x80\x99s a risk they could plugin an unauthorized USB device that provides access to the camera system and its data. This could result in unauthorized access to sensitive data or a disruption in system availability.\nProtecting IoT devices from unintended USB access requires a multi-layered security approach that includes both hardware and software solutions. Hardware solutions include implementing an additional layer of security to the USB ports and limiting physical access to devices. Software solutions include implementing firmware and software updates, as well as implementing security protocols that can detect and prevent unintended USB access.\nThe access level for a device can also be different depending on whether it is in service or in debug mode. When a device is in service, you may want its USB ports to be fully protected. When it is in debug mode, you sometimes need to open up its USB ports to allow a technician to plug in diagnosis software. The control over the device\xe2\x80\x99s mode needs to be securely performed by a security or DevOps team, as shown in Figure 1.\nIn this blog, you will learn how to protect Linux-based IoT devices and computers against unintended USB access with USBGuard and how to securely change a device from In-Service mode to Debug mode with AWS IoT Device Management.\nFigure 1: Use case explanation\nPrerequisites\nAn AWS account. If you do not have an AWS account, you will need to create and activate an AWS account first and set up both AWS IoT Core and AWS IoT Device Management. For getting started instructions, please view the AWS IoT Core getting started guide and the guide for how to manage devices with AWS IoT.\nTurn on AWS IoT Core fleet indexing, which is required for use with Fleet Hub for AWS IoT Device Management.\nIntegrated with AWS IoT Core, AWS IoT Device Management helps you register, organize, monitor, and remotely manage IoT devices at scale. With Fleet Hub you can build standalone web applications for monitoring the health of your device fleets.\nA Linux based physical machine with USB ports. Nvidia Jetson Nano is used in this blog.\nBasic understanding of Linux (e.g. create directories, set file permissions) and programming (compiling code)\nWalkthrough\nThe following diagram, Figure 2, shows an architecture of a Linux-based device connecting through AWS IoT Core using MQTT. On the device, the USBGuard service has been installed and enabled. USBGuard is a software framework that offers an allow/deny -listing mechanism for USB-devices. Inspiration for this is drawn from issues like BadUSB. It makes use of a device blocking infrastructure included in the Linux kernel.\nThe device has a device mode attribute defined. You can set the device mode to either in-service or debug mode through Jobs for AWS IoT. IoT Jobs define a set of remote operations that can be sent to and run on one or more devices connected to AWS IoT. For this use case, there are two jobs defined: set-debug-mode-job and set-in-service-mode-job. You can monitor device mode attributes and perform jobs through AWS IoT Device Management Fleet Hub.\nWhen running the set-in-service-mode-job, the IoT communication client will pick up the job, set a USBGuard policy to restrict USB ports access only to designated USB device, block other devices with a hidden keyboard interface in a USB flash disk, and set the device shadow attribute with in-service mode . On the contrary, when running the set-debug-mode-job, it loosens the rules on the USB ports (e.g. a USBGuard policy to allow all USB ports access), and sets the device shadow attribute with debug mode. This way, a technician can plug in a mouse and a keyboard and run debugging software through USB ports.\nFigure 2: Solution architecture\nThis can be accomplished through the following procedures:\nConfigure AWS IoT Core policy and device attributes\nProvision the device\nInstall USBGuard on the device\nImplement the IoT communication client code\nConfigure job docs in IoT Jobs\nCreate AWS IoT Device Management Fleet Hub application\nSteps 1 and 2 can be performed either in AWS IoT Core console or through AWS CLI. We use AWS CLI commands in the walkthrough. Step 3 and 4 are configured on the IoT device. And step 5 and 6 are performed in AWS IoT console.\nStep 1: Configure AWS IoT Core policy and device attributes\nPOLICY_NAME=IoTJobDemo_Policy\nTHING_TYPE_NAME=DemoDevice\n\n# Create an IoT policy\n# NOTE: This policy is for demonstration purpose only! Please do not use in production environment.\n# Replace us-east-1:123456789012 with your AWS_REGION:AWS_ACCOUNT_ID\n# Replace uniqueThingName with your IoT device thing name\naws iot create-policy --policy-name $POLICY_NAME --policy-document \'{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:us-east-1:123456789012:client/uniqueThingName""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": [\n        ""arn:aws:iot:us-east-1:123456789012:*""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:us-east-1:123456789012:*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Receive"",\n      ""Resource"": [\n        ""arn:aws:iot:us-east-1:123456789012:topic/test/dc/subtopic"",\n        ""arn:aws:iot:us-east-1:123456789012:topic/$aws/things/uniqueThingName/jobs/*""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:DescribeJobExecution"",\n        ""iot:GetPendingJobExecutions"",\n        ""iot:StartNextPendingJobExecution"",\n        ""iot:UpdateJobExecution""\n      ],\n      ""Resource"": ""arn:aws:iot:us-east-1:123456789012:topic/$aws/things/uniqueThingName""\n    }\n  ]\n}\n\'\n\n\n# Create thing type\naws iot create-thing-type --thing-type-name $THING_TYPE_NAME\n\n# Create dynamic thing groups\naws iot create-dynamic-thing-group --thing-group-name ""Debug"" --query-string ""shadow.name.device-mode.reported.mode:Debug"" > /dev/null\naws iot create-dynamic-thing-group --thing-group-name ""InService"" --query-string ""shadow.name.device-mode.reported.mode:InService"" > /dev/null\nBash\nStep 2: Provision the device\nTHING_NAME=""<your device unique identifier>""\nTHING_PATH=""<your work directory>/$THING_NAME""\n\naws iot create-thing --thing-name $THING_NAME --thing-type-name $THING_TYPE_NAME \n\n# Create keys and certificate\naws iot create-keys-and-certificate --set-as-active \\\n    --private-key-outfile $THING_PATH/private.key \\\n--certificate-pem-outfile $THING_PATH/certificate.pem > $THING_PATH/keys_response\n\n# Get Root CA\nwget https://www.amazontrust.com/repository/AmazonRootCA1.pem -O $THING_PATH/rootCA.pem\n\n# Parse output for certificate ARN and ID\nCERTIFICATE_ARN=$(jq -r "".certificateArn"" $THING_PATH/keys_response)\nCERTIFICATE_ID=$(jq -r "".certificateId"" $THING_PATH/keys_response)\n# Attach policy to certificate\naws iot attach-policy --policy-name $POLICY_NAME --target $CERTIFICATE_ARN\n# Attach certificate to thing\naws iot attach-thing-principal --thing-name $THING_NAME --principal $CERTIFICATE_ARN\nBash\nStep 3: Install USBGuard on the device\nFollow the public documentation to install USBGuard.\nGenerate two USBGuard policies, debug-rules.conf and in-service-rules.conf. in-service-rules.conf contains strict rules and will be used in device\xe2\x80\x99s in-service mode. debug-rules.conf loosens the rules on the USB ports and will be used in device\xe2\x80\x99s debug mode.\nFor example, a debug-rules.conf can be a policy allowing all access to all USB ports:\necho ""allow id *:*"" > debug-rules.conf\nBash\nin-service-rules.conf can contain rules to reject any USB flash disk which implements a keyboard or a network interface.\nallow with-interface equals { 08:*:* }\nreject with-interface all-of { 08:*:* 03:00:* }\nreject with-interface all-of { 08:*:* 03:01:* }\nreject with-interface all-of { 08:*:* e0:*:* }\nreject with-interface all-of { 08:*:* 02:*:* }\nBash\nStep 4: Implement the IoT communication client code\nOn the IoT device itself, create a work directory:\nWORKDIR=""<your work directory>""\nTHING_PATH=""$WORKDIR/$THING_NAME""\nmkdir -p $THING_PATH\nBash\nPut the certificate.pem, private.key, rootCA.pem from Step 2 under the $THING_PATH.\nWe use the AWS IoT Device Client on the device. The AWS IoT Device Client is free, open-source, modular software written in C++ that you can compile and install on your Embedded Linux based IoT devices to access AWS IoT Core, AWS IoT Device Management, and AWS IoT Device Defender features by default. To install and configure the client:\n# Building\ncd $WORKDIR\ngit clone https://github.com/awslabs/aws-iot-device-client\ncd aws-iot-device-client\nmkdir build\ncd build\ncmake ../\ncmake --build . --target aws-iot-device-client\n\n# Setup\ncd ../\n./setup.sh \nBash\nAt this point you\xe2\x80\x99ll need to respond to prompts for information, including paths to your thing certs:\nDo you want to interactively generate a configuration file for the AWS IoT Device Client? y/n\ny\nSpecify AWS IoT endpoint to use:\n<This is the iot:Data-ATS endpoint. Check out https://docs.aws.amazon.com/iot/latest/developerguide/iot-connect-devices.html>\nSpecify path to public PEM certificate:\n$THING_PATH/certificate.pem\nSpecify path to private key:\n$THING_PATH/private.key\nSpecify path to ROOT CA certificate:\n$THING_PATH/rootCA.pem \nSpecify thing name (Also used as Client ID):\n$THING_NAME\nWould you like to configure the logger? y/n\nn\nEnable Jobs feature? y/n\ny\nSpecify absolute path to Job handler directory:\n$WORKDIR/.aws-iot-device-client/jobs\n\xe2\x80\xa6\nEnable Sample Shadow feature? y/n\ny\nSpecify a shadow name for the feature to create or update:\ndevice-mode\nSpecify the path of a file for the feature to read from:\n$WORKDIR/.aws-iot-device-client/device-mode-input.json      \nSpecify a the path of a file for the feature to write shadow document to:\n$WORKDIR/.aws-iot-device-client/device-mode-output.json           \n\xe2\x80\xa6\nDo you want to install AWS IoT Device Client as a service? y/n\nN\nBash\nIn the $WORKDIR/.aws-iot-device-client/jobs, create a usbguard-policy directory and put the debug-rules.conf and in-service-rules.conf generated from step 3 in there.\nCreate two corresponding job handler scripts in the $WORKDIR/.aws-iot-device-client/jobs to handle set device mode. They will be triggered by IoT Job docs.\nThe script to set device to debug mode: set-debug-mode.sh\n#!/usr/bin/env sh\nset -e\n\nBASEDIR=$(dirname $0)\necho \'{""mode"": ""Debug""}\' > $BASEDIR/../device-mode-input.json\ncat $BASEDIR/usbguard-policy/debug-rules.conf > /etc/usbguard/rules.conf\nsystemctl restart usbguard.service\nBash\nThe script to set device to in-service mode: set-in-service-mode.sh\n#!/usr/bin/env sh\nset -e\n\nBASEDIR=$(dirname $0)\necho \'{""mode"": ""InService""}\' > $BASEDIR/../device-mode-input.json\ncat $BASEDIR/usbguard-policy/in-service-rules.conf > /etc/usbguard/rules.conf\nsystemctl restart usbguard.service\nBash\nNow, everything has been configured on the device, we can run the device client by:\ncd $WORKDIR/aws-iot-device-client\nsudo ./build/aws-iot-device-client\nBash\nStep 5: Configure job docs in IoT Jobs\nTwo job docs need to be created in IoT Jobs. set_debug_mode.json and set_in_sevice_mode.json. They will trigger the set-debug-mode.sh and set_in_sevice_mode.sh handlers that we wrote in Step 4 respectfully.\nExample of set_debug_mode.json:\n{\n  ""_comment"": ""This sample JSON file can be used for set debug mode."",\n  ""version"": ""1.0"",\n  ""steps"": [\n    {\n      ""action"": {\n        ""name"": ""Set Device Mode to Debug"",\n        ""type"": ""runHandler"",\n        ""input"": {\n          ""handler"": ""set-debug-mode.sh""\n        },\n        ""runAsUser"": ""root""\n      }\n    }\n  ]\n}\nJSON\nCreate an Amazon S3 bucket and upload the job docs. In AWS IoT Jobs console, configure the Job templates with the two job docs:\nStep 6: Create AWS IoT Device Management Fleet Hub application\nFollow the blog post Get Started with Fleet Hub for AWS IoT Device Management to set up Fleet Hub. On your Fleet Hub application, you should be able to see your device and its mode.\nYou can also control to change the mode by run jobs from the dashboard.\nOn the device, you should be able to observe that access to any USB port is corresponding to the rules you have set for the device mode.\nCleaning up\nTo avoid incurring future charges, delete all resources that you have created.\nThe Fleet Hub application can be deleted by first navigating to Fleet Hub in the AWS IoT console and then selecting applications. Select your application and choose delete.\nAWS IoT Core Fleet indexing can be turned off by navigating to the AWS IoT Core console, selecting Settings, then navigating to Manage fleet Indexing and then Thing indexing and group indexing.\nIn the AWS IoT Core console, delete Things, Thing groups and Thing types under All devices. Detach \xe2\x80\x98thing\xe2\x80\x99 and IoT policy from registered certificate. Delete device certificate, \xe2\x80\x98thing,\xe2\x80\x99 and IoT policy.\n'"
2,Deploying and managing an IoT workload on AWS,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/04/14/Deploying-and-managing-an-IoT-workload-on-AWS.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/deploying-and-managing-an-iot-workload-on-aws/,"b'Introduction\nWhen implementing an Internet of Things (IoT) workload, companies are faced with multiple options when it comes to choosing a platform. From building it entirely from scratch, including your own device hardware, all the way to purchasing preconfigured hardware and just connecting to a completely Software as a service (SaaS) IoT platform.\nThe goal of this blog is to help you understand what skills and knowledge are required for designing an IoT solution and help you decide what components you would want to build versus buy. If you\xe2\x80\x99re thinking of migrating your IoT workload to AWS, then please review the Planning a Seamless Migration to AWS IoT Core blog as a first step to understand key reasonings, incentives, and support offered by AWS that can help simplify your migration process.\nCommon AWS IoT architecture components\nDevice manufacturing\nWhen developing and manufacturing device hardware, there are several factors to consider. Based upon your requirements, hardware must be selected to meet the current and future needs of your solution. Decisions must be made in regards to common IoT constraints such as managing power (supply and consumption), connectivity, security, and operating system.\nIf you are not building hardware in-house, then an Original Device Manufacturer (ODM) will need to be chosen. ODMs have the production line, tooling, and processes in place to produce large volumes of devices. They are able to build to the specification provided by you, which typically includes the printed circuit board (PCB) schematics, a bill of materials, firmware, and provisioning requirements.\nConsiderations for device hardware constraints include:\nPower consumption: How and where devices are to be used has a large impact on how they will be powered. A wearable device will require a small battery whereas a television will be able to leverage an AC power supply. For devices requiring batteries, you need to determine if they will be rechargeable, replaceable, or expected to last the life-time of the hardware.\nOperating system and firmware: The selection of an operating system or firmware will depend on the type of device and the tasks it is expected to perform. Small, low-power devices could require a real-time operating system, such as FreeRTOS, whereas larger, dedicated-power devices may utilize a full-stack operating system such as Linux.\nConnectivity: There are a multitude of connectivity and protocol options for IoT solutions, such as Ethernet, Wi-Fi, Cellular, LoRaWAN, and Bluetooth Low Energy (BLE). Device geography, availability, power consumption, security, and use case will determine which connectivity option is best for your solution.\nTo help with this component, AWS offers the AWS Partner Device Catalog, which offers a list of AWS partner manufactured devices that have completed the AWS Device Qualification Program. Devices from this list can help you go to market faster and ensure your device is compatible with AWS IoT and AWS best practices. In addition, if you\xe2\x80\x99ve manufactured your own devices, you can use the AWS IoT Core Device Advisor to validate their ability to reliably and securely connect with AWS IoT Core.\nDevice provisioning\nHow you provision devices in your IoT solution will vary based on the capabilities of your device and its manufacturing process. The main focus here is on how your device and its credentials are created.\nSecurity should be a high priority for you, your customers, and device manufacturers. When using X.509 certificates, the manufacturing process must specify when devices will receive their unique certificate and private key pairing as well as how they will be registered in your IoT solution.\nConsiderations for device provisioning and certificate management include:\nManufacturer selection: A complete certificate chain of trust starts when you develop hardware in-house or select an OEM partner. If going with the latter, their processes will need to be inspected to ensure that certificate integrity is maintained throughout their supply chain.\nCertificate Authority (CA): To provide flexibility in the manufacturing of device, AWS has several options available including using your own CA, a third-party CA, or the Amazon Root certificate authority (CA).\nHardware security module: Secure elements built into IoT devices form the basis for device security. This enables encryption and tamper-proof storage of certificates and secrets and firmware and applications to be validated. To help with this, AWS has a range of connectivity modules powered by AWS IoT ExpressLink which include software implementing AWS mandated security requirements.\nExternal resources: Resources may need to be created in your IoT solution to enable a custom provisioning process. These resources have to be designed to scale as your device fleet grows. With AWS, this could be an AWS Lambda function that acts as a Pre-provisioning hook.\nDevice-level logic: A device may require on-device logic to successfully, reliably, and securely be provisioned. With AWS, the AWS IoT SDKs have been built to enable this on-device logic.\nFor more information on provisioning and registering devices securely with AWS IoT Core, please review the Device Manufacturing and Provisioning with X.509 Certificates in AWS IoT Core AWS whitepaper and the AWS IoT Core Device Provisioning documentation.\nDevice management\nWith a mature provisioning process, a device can be secure and up-to-date from the first time it connects but it may require updates, such as firmware or certificate rotation, to remain fully compliant and provide the best user experience. Solutions for these updates will need to be designed to react to interruptions in delivery, connectivity, rollback routines, and to scale automatically.\nConsiderations for your device management strategy include:\nOrganize devices: The ability to quickly identify and interact with devices gives you the ability to troubleshoot and potentially isolate them if they become out of compliance. When operating fleets of devices, you need to have solutions in-place to organize, index, and categorize your devices at scale. With AWS, you could use Fleet Hub for AWS IoT Device Management.\nMonitor devices: Monitoring the status of your device fleet is important in helping identify any malfunctioning or out-of-compliance devices. Ensure you have a monitoring solution in place to collect observational and security data, such as device metrics, logs, or configuration. AWS IoT Device Defender provides auditing and ongoing intelligent monitoring for security of your fleet.\nRespond to events: By defining a minimum set of logs, metrics, and alarms, your operations team can defend against significant business interruptions. A scalable alerting solution that integrates with your monitoring solution will be required for this. With AWS, you could use Amazon CloudWatch.\nEnable Over-The-Air (OTA) Updates: Devices should be designed to receive and apply updates. Your IoT solution should be designed to send updates and monitor a device\xe2\x80\x99s update progress. With AWS, you could use AWS IoT Device Management Jobs.\nTo help with this component, AWS IoT Device Management, AWS IoT Device Defender, and AWS IoT Core offer a full set of capabilities to address device organization, monitoring, alerting, and OTA updates across your fleet of IoT devices.\nDevice data ingestion\nNot all IoT solutions will focus just on data ingestion, but for the ones that do, this will be a primary component that affects the solution\xe2\x80\x99s entire architecture. The requirements for this component will affect your solution\xe2\x80\x99s scale, cost, security, and performance which means you should design your IoT solution\xe2\x80\x99s architecture to meet your current and potential future data ingestion.\nConsiderations for your data ingestion strategy include:\nData size: Assuming your devices are not hardware constrained, for optimal efficiency, try to keep the size of your messages consistent and consider batching of smaller messages to accomplish this. Keep in mind, batching can occur on and after message transmission such as batching messages using IoT Rules after they\xe2\x80\x99ve been ingested by IoT Core.\nData frequency & structure: Consider how often your devices transmit messages and if your solution is designed to scale for this. In addition to frequency, the structure of your data will determine if your IoT workload is messaging or streaming based.\nMQTT topic design: If you\xe2\x80\x99re using this protocol, you should strive to find a balance between a schema that enforces least privilege communication and also allows for supporting future device deployments. A good topic schema will implement a common naming structure to provide for flexible message filtering and message routing.\nData storage: Analyze the flow and usage of your messages to identify the right storage solutions. These storage solutions will have multiple considerations such as your specific use case, overall message structure, scale (for current and future growth), and cost.\nRouting: Once ingested, you\xe2\x80\x99ll need an easy, rules-based solution to route messages to either storage or other services. These rules can then be used for further message batching, processing, or even alerting.\nEdge Gateway: A common architecture pattern is to have a gateway, or broker, for ingesting, processing, and/or batching data before transmitting to your IoT solution. This can be implemented as either a local endpoint, closer to your devices, or cloud, closer to your IoT solution, based gateway.\nTo help with this component, AWS IoT Core enables you to connect billions of IoT devices and route trillions of messages to other AWS services, such as Amazon SQS, Amazon Kinesis, and Amazon SNS, without managing any infrastructure. AWS also offers AWS IoT Greengrass which is an open-source edge runtime that provides the capabilities of an edge gateway. For more information on patterns for data ingestion with AWS IoT Core, please refer to the AWS IoT blog 7 patterns for IoT data ingestion and visualization- How to decide what works best for your use case.\nReal-time video and data streams\nIn addition to the items discussed in the previous section, you will need to consider a few more if your IoT workload consists of video or other high volume data streams. An IoT workload that handles streams of data typically deals with high frequencies and raw, unstructured data for applications such as video processing and analysis.\nConsiderations streaming based workloads include:\nProducing: How your data streams are produced can directly affect how they are ingested, processed and stored in your IoT solution downstream. Aspects such as your device\xe2\x80\x99s streaming protocol, network availability, accessibility and cost constraints will affect how your streams are produced.\nConsuming: The consumption and processing of your data streams can affect the required scale and overall cost of your IoT solution. High frequencies of data, such as video streams, will lead to the need for a robust architecture that is highly available, easy to manage, and can handle your throughput requirements. Consider the direct business value of these streams in your overall IoT solution to determine the most cost-effective and scalable way to consume and process them.\nTo help with this type of architecture, AWS offers AWS IoT Greengrass, Amazon Kinesis, and Amazon Kinesis Video Streams. AWS IoT Greengrass is an open-source edge runtime that provides the capabilities to easily consume and process data streams at the edge and transfer them to AWS via AWS-provided components. Amazon Kinesis is a cost-effective, managed service that can process and analyze streaming data produced either directly from a device, the AWS IoT Greengrass Stream manager component or an AWS IoT Rule. Amazon Kinesis Video Streams is a managed AWS service that can be used to securely view, process and analyze video streams produced either directly by a device or the AWS IoT Greengrass Edge connector for Kinesis Video Streams, regardless of the source protocol.\nDevice command-and-control\nCommand-and-control is the operation of sending a message to a device requesting it to perform an action with an optional acknowledgement of success or failure. This can be accomplished with either a command message to your device or by changing and relaying your device\xe2\x80\x99s state from your IoT solution. Evaluating and optimizing your IoT solution\xe2\x80\x99s messaging needs for data ingestion versus command-and-control ensures that you get the best outcomes in balancing performance and cost.\nConsider the following patterns for your device command-and-control strategy:\nCommand messaging: Use direct device message(s) with your messaging protocol of choice to transmit command(s) directly to a device. You will need device-level logic in place to accept and execute the command as well as report the device\xe2\x80\x99s execution status. Please be aware that this pattern will require your IoT solution to ensure the command message is delivered or results in an actionable failure should your device be offline or disconnected.\nDevice state: A device\xe2\x80\x99s persisted state will need to be handled by your IoT solution and can be used to set device commands and update their execution status. This persisted state could be a simple document that is sent to the device when changes are made from the IoT solution and sent back if the device makes changes as well. This pattern will allow your IoT solution to interact with your device, whether it\xe2\x80\x99s connected or not.\nTo help with this component, AWS IoT Core offers the AWS IoT Device Shadow service, the MQTT5 request/response pattern, and AWS IoT Device Management offers the AWS IoT Jobs feature. For more information on patterns for implementing device command-and-control, please see the Device Commands section of the AWS IoT Lens for the AWS Well-Architected Framework whitepaper.\nCloud architecture\nWhen an IoT solution exists in the cloud, you may start with one regional service or with a small fleet of devices to test with your requirements. This will be fine for proof-of-concepts or demonstrations, but when you move the solution into production you need to ensure it\xe2\x80\x99s built with cloud-based best practices in mind.\nThe AWS Well-Architected framework can help you in the design, build or even review of your solution to ensure it is using AWS in a secure, high-performing, resilient, and efficient manner. For more information on cloud based best practices with AWS IoT, please see the IoT Lens \xe2\x80\x93 AWS Well-Architected Framework.\n'"
3,Secure IIoT secondary sensing using AWS Snowcone and CloudRail,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/04/11/Secure-IIoT-secondary-sensing-using-AWS-Snowcone-and-CloudRail.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/secure-iiot-secondary-sensing-using-aws-snowcone-and-cloudrail/,"b""Introduction\nOne of the major barriers to Industrial IoT (IIoT) adoption is integrating modern IIoT solutions in brownfield environments with legacy components and systems. These legacy industrial components and systems could be 20, 30, 40 years old and are less capable of supporting modern security standards. Physically connecting legacy industrial systems to the cloud can be complex, costly, and time-consuming. Secondary sensing refers to equipping older machines (brownfield) with additional sensors to gather data for IIoT applications. We discussed secondary sensing and actuation for factories using AWS IoT and CloudRail Gateways. In this blog post, we provide guidance on an alternate approach and discuss the benefits of a secondary sensing solution using AWS Snowcone (Snowcone) running CloudRail.OS Docker application. This solution is a non-invasive, secure, and cost-effective way to collect and send OT data from brownfield environments to AWS IoT SiteWise without impacting safety and plant operations.\nBackground\nTo enable IIoT applications for improving operational efficiencies, reducing unplanned downtime, and improving product quality, data from machines and industrial equipment needs to be acquired and transferred to the edge and cloud for processing. A mixture of legacy and modern equipment, as well as a variety of different protocols can make this connectivity difficult to establish. Furthermore, industrial organizations are facing a new challenge as they try to merge the traditional physical world (Operational Technology or OT) and the digital world (Information Technology or IT). This is discussed in Managing Organizational Transformation for Successful OT/IT Convergence.\nIntroducing IIoT in brownfield environments can open new avenues for cyber-events and needs additional security consideration since it can result in connecting \xe2\x80\x9cinsecure by design legacy industrial control (ICS/OT) systems\xe2\x80\x9d to external and untrusted networks like the internet. In brownfield IIoT deployments, new IIoT technologies co-exists with legacy brownfield systems. This integration of IT and OT introduces risk since systems built for usage in hostile networks are integrated with those that were not.  IIoT has significantly widened the array of technologies available for use in industrial environments like secondary sensors. OT/IT convergence and the growth of IIoT increases the attack surface, which inherently increases the risk of compromise in these environments. For brownfield environments, AWS recommends following the Ten Security Golden Rules for IIoT solutions.\nSolution architecture and components\n The architecture enclosed shows a secondary sensing solution using CloudRail.OS running on an AWS Snowcone acting as an edge gateway. An IO-Link Master is used to connect temperature and vibration IO-Link sensors to CloudRail.OS on Snowcone. Sensor data is securely sent to AWS IoT SiteWise in the AWS Cloud.\nFigure 1: Secondary sensing architecture using CloudRail.OS on AWS Snowcone\nA brief description of the solution components is as follows:\nAWS Snowcone\nAWS Snowcone is a small, rugged, and secure device offering edge computing and local data storage, in environments with little or no connectivity to the AWS Region. Snowcone is used to run IIoT applications in austere (non-data center) industrial edge environments. With 2 vCPUs, 4 GB of memory, and 8 TB of usable storage (14 TB for Snowcone SSD), Snowcone devices can come provisioned with several AWS services, including Amazon EC2, AWS NFS, and Amazon EBS, for secure, ruggedized data storage and compute ideal for IIoT and factory floor uses. Snowcone\xe2\x80\x99s small size (8.94 inches long x 5.85 inches wide x 3.25 inches tall / 227 mm x 148.6 mm x 82.65 mm) enables you to set it next to machinery in a factory to collect, format, and transport data back to AWS for storage and analysis. All data on the Snowcone is always automatically encrypted and the Trusted Platform Module (TPM) provides hardware root of trust. Snowcone simplifies OT/IT integration by securely bridging OT and IT networks.\nCloudRail\nCloudRail is a fully managed plug-and-play solution to acquire data from industrial environments, pre-process it locally, and send it to AWS IoT Core, AWS IoT SiteWise, or AWS IoT Greengrass. CloudRail works for greenfield as well as brownfield applications. It uses industry standards like OPC-UA to connect modern equipment, while old machines are retrofitted with secondary sensors. A database of over 12,000 sensor definitions in combination with automated data transformation and device provisioning reduces the setup time for connecting a machine to the cloud from weeks to just hours. The optional support of AWS IoT Greengrass runs powerful logic locally on the edge device like data pre-processing or machine learning applications.\nCloudRail.OS provides a container-based Docker application which runs on the Snowcone.\nBy combining CloudRail\xe2\x80\x99s plug-and-play approach for connecting industrial assets to the cloud with the AWS Snowcone\xe2\x80\x99s secure and rugged compute and storage offering, customers get an industrial-grade ruggedized solution. Due to the deep integration of CloudRail with AWS IoT services, data acquisition is simple, cost effective and scalable. The solution enables customers to quickly, easily, and securely collect OT data from brownfield environments to implement IIoT use cases.\nIO-Link\nIO-Link is a serial digital communication protocol used in industrial automation systems. It connects sensors and actuators to a programmable logic controller (PLC) and is a PLC standard for a serial communication protocol that allows three types of data to be exchanged \xe2\x80\x93 process data, service data, and events.\nIO-Link uses point-to-point connectivity between an IO-Link Master device and sensors rather than a message bus topology. Multiple IO-Link Masters can be connected to the Snowcone gateway box via an Ethernet connection. This allows a single gateway to support sensors and actuators across longer runs within a factory floor. Hundreds of IO-Link based sensors and actuators are supported by vendors such as IFM, Turck, Sick, Pepperl+Fuchs, or Balluff. IO-Link Design Guide can be used in designing IIoT solutions using IO-Link sensors and actuators.\nSome of the benefits of the CloudRail.OS on AWS Snowcone IIoT secondary sensing solution are:\nIoT plug-and-play support for industrial secondary sensors and support for thousands of IO-Link sensors\nReduce the time to connect an industrial machine to AWS\nStart small and quickly scale based on your learnings\nRuggedized and industrial-grade AWS managed gateway appliance with AWS Snowcone\nImprove security with AWS Snowcone security features including TPM, for hardware root of trust and data encryption at rest by default using 256-bit keys\nSimplify OT/IT convergence by securely bridging OT and IT networks\nImprove safety and reduce downtime when adding secondary sensing to production sites without impacting production\nOptionally add security audit and monitoring using AWS IoT Device Defender to audit for security best practices and monitor for device anomalies\nSolution Configuration\nWe will provide steps to build the architecture diagram mentioned above (Figure 1). The steps will guide you from ordering Snowcone to setting up Cloudrail.OS on an EC2 instance running on Snowcone.\nI. Prerequisite steps:\nProcured sensors from your manufacturer of choice and request a Cloudrail.OS container license here.\nOrder a Snowcone device as per the steps listed here (Job type: Local compute and storage only).\nDownload Snowcone device credentials \xe2\x80\x98unlock code\xe2\x80\x99 and \xe2\x80\x98manifest file\xe2\x80\x99 as described here.\nDownload AWS Opshub on the local machine used to interact with AWS Snowcone device via GUI.\nDownload SnowballEdge Client on the local machine used to interact with AWS Snowcone device via CLI.\nConfigure SnowballEdge Client by navigating here.\nII. Snowcone configration\nPower on the Snowcone device and connect it to local network device via Ethernet connection or Wifi (Router/Switch).\nConfigure RJ451 or RJ452 as DHCP/Static to get local LAN IP address on the Snowcone\xe2\x80\x99s display screen.\nUnlock Snowcone using AWS Opshub or SnowballEdge Client.\nLaunch the EC2 instance on the Snow device following the steps provided here. In this blog we will be using default Amazon Linux AMI validated to be used on Snow devices.\nFigure 2: Launch the EC2 instance using AWS Opshub for Snow\nCreate a direct network interface (DNI) and attach it to the Amazon EC2 instance as per the steps explained here.\nNote: DNI is only supported on RJ45 interface. DNI is required for the communication between IO-Link master and CloudRail.OS running on the EC2 instance.\nFigure 3: SnowconeEdge CLI used to set up a Direct Network Interface (DNI)\n III. CloudRail.OS set up \nSSH into EC2 instance\nssh -i <key-pair.pem> ec2-user@x.x.x.x\nsudo yum update -y\nInstall Docker\n$ sudo amazon-linux-extras install docker\n$ sudo service docker start\n$ sudo systemctl enable docker\n$ sudo usermod -a -G docker ec2-user\nPull the latest container image from docker public repository. Steps to set up container is found here. Latest CloudRail-image is found here.\nFor example.\n$ sudo docker pull cloudrailos/cr-container-os:beta-2.0.6\nThe \xe2\x80\x98cr-container-for-snow.zip\xe2\x80\x99 will contain module-credentials to be used by the container to connect to CloudRail DMC. Configure interface (to be used as field port for IO-Link master connectivity) in the container-config.json.\nFor example.\n$ sudo docker run -d \xe2\x80\x94name cr-firmware \\\n\xe2\x80\x94net=host -v '/home/ec2-user/cr-container-for-snow/cr-agent/cr-container':/home/cr-container \\\ncloudrailos/cr-container-os:beta-2.0.6\nIV. CloudRail management console registration\nLogin to CloudRail management console and register the serial number provided by CloudRail.\nOnce the box is added the status of the box should be \xe2\x80\x9conline\xe2\x80\x9d. Follow the steps here to set up CloudRail environment.\nBelow is the example of CloudRail console\nFigure 4: CloudRail console with Snowcone gateway appliance\nV. Processing the telemetry data\nIn order to set up CloudRail.OS to forward telemetry data to AWS IoT SiteWise follow these steps.\n"""
4,Ingest industrial data at scale with AWS IoT SiteWise Edge on Microsoft Windows Server,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/04/04/Ingest-industrial-data-at-scale-with-AWS-IoT-SiteWise-Edge-on-Microsoft-Windows-Server.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/ingest-industrial-data-at-scale-with-aws-iot-sitewise-edge-on-microsoft-windows-server/,"b'Introduction\nIndustrial customers in manufacturing, oil and gas, energy, and utilities industries commonly use Windows-based industrial devices and infrastructure. The recent release of AWS IoT SiteWise Edge for Windows, enables these customers to rapidly deploy and connect AWS IoT industrial facilities to AWS.\nCustomers will be able to install AWS IoT SiteWise Edge natively on Microsoft Windows without the need for any virtualization. This capability not only reduces the time to deploy AWS IoT SiteWise Edge, but also reduces costs and maintenance overhead by not having to acquire new infrastructure to run Linux.\nIn this blog post, we will walk through the installation and configuration of AWS IoT SiteWise Edge software on Windows to ingest equipment data to AWS IoT SiteWise. Subsequently, we discuss organizing and processing of ingested data in asset models. Finally, we will discuss configuring AWS IoT SiteWise Monitor to monitor equipment performance.\nSolution walk through\nThere are three key steps to consider when building this solution:\nAWS IoT SiteWise provides a number of components which deliver the capabilities shown in each step of the image above.\nSolution components\nStep 1: Collect data\nAWS IoT SiteWise gateway: This ingests data from IoT devices in the facility and transmits it securely to AWS IoT SiteWise. It supports connectivity to the devices using the standard OPC-UA, Modbus TCP, MQTT and Ethernet IP protocol.\nAWS IoT SiteWise Edge: For facilities with intermittent or unstable internet connection, AWS IoT SiteWise Edge brings the functionality of AWS IoT SiteWise and AWS IoT SiteWise Monitor to a local facility. It pulls in the configurations made in the cloud to a local device, allowing users to monitor asset performance locally even when there is a loss of internet connection.\nAWS IoT SiteWise Edge is a software package available on AWS IoT Greengrass that we will run on an existing Windows industrial gateway device at the manufacturing facility.\nStep 2: Organize and process data\nAWS IoT SiteWise: Once ingested, we need to organize and process the data collected. AWS IoT SiteWise allows us to add context and structure to the data to make it useful information. For example, what machine is the data coming from, how does this relate to the rest of the machines/processes in the facility, and how to define alarm limits on a metric.\nStep 3: Monitor equipment performance\nAWS IoT SiteWise Monitor: A no code web UI real-time monitoring portal, which allows users to monitor the performance of their equipment using information processed through AWS IoT SiteWise. It provides customizable dashboards and integrates with AWS Identity Access Management (IAM) to support authentication and authorization of users. It provides the capability to control which users can edit the dashboards and how much data a reader is allowed to access.\nIn this blog, we will focus on Step 1, particularly around ingesting data using AWS IoT SiteWise gateway. In this scenario, AWS IoT SiteWise gateway will be installed on a local industrial gateway device, running a Windows operating system. (Version 2016 or later).\nMetadata\n Time to read   20 minutes\n Learning level   300\n Services used   AWS IoT Greengrass V2, AWS IoT SiteWise, AWS IoT SiteWise Edge and AWS IoT SiteWise Monitor\nPrerequisites\nAt a minimum, AWS IoT SiteWise Edge requires an industrial computer running Linux or Windows with a x86 64 bit quad-core processor, 32GB RAM, and 256GB in disk space. The gateway device must allow inbound traffic on port 443 and it must allow outbound traffic on ports 443 and 8883.\nWe recommend you use dedicated hardware for AWS IoT SiteWise Edge. AWS IoT SiteWise Edge software runs on AWS IoT Greengrass V2 installed on Windows 2016 or later.\nSteps\nThese sections summarize how to create a SiteWise Edge gateway and includes detailed instructions for steps that are specific to creating a Windows gateway.\n1. Collect data\nCreate the gateway\nIn the AWS Management Console, create the SiteWise gateway, following Steps 1-4. During this process, choose Default setup and include a Data processing pack to enable edge capabilities. You can optionally choose to enable LDAP access, configure how data is published from the gateway to the cloud, and set up data sources.\nDuring Step 5 of the creation process, scroll down to the bottom of the page and select Windows as the industrial gateway OS. Click Generate.\nWhen the SiteWise Edge installer dialog box appears, click Acknowledge. Save the installer to a secure location, as you will not have access to it again.\nThe installer package (.ps1 extension) will be created and begin downloading to your local machine. In the AWS console, the gateway summary page will load. The Gateway configuration section of the Overview tab will show connectivity is \xe2\x80\x9cPending device pairing.\xe2\x80\x9d\nInstall edge software onto your industrial gateway\nOn the Windows server where you\xe2\x80\x99ll create the industrial gateway, log in as an administrator. If the edge installer was not downloaded directly to this machine, copy it to this machine.\nOnce the .ps1 file is on the Windows server, type PowerShell in the Windows search bar. In the search results, right-click on Windows PowerShell to bring up the context menu, and choose Run as administrator.\nAt the PowerShell prompt, change to the directory where you downloaded the installer file.\nRun the command below to unblock the installer file (replace Gateway-wAgJBvXS9.deploy.ps1 with the name of your file):\nunblock-file Gateway-wAgJBvXS9.deploy.ps1\nPowerShell\nThen, run the installer:\n./Gateway-wAgJBvXS9.deploy.ps1\nPowerShell\nWhen the installer finishes successfully, the message will say Done!\nThe SiteWise Edge gateway is now installed and running on the Windows server. To confirm, return to the gateway summary page in the AWS console (Services->AWS IoT SiteWise->Edge->Gateways-> select your gateway).\nThe Gateway configuration section of the Overview tab should now say \xe2\x80\x9cConnected.\xe2\x80\x9d\nSiteWise Edge gateways use packs to determine how to collect and store data. We recommend updating all packs installed on your gateway to their latest versions.\nThe rest of the process to create a SiteWise Edge gateway is the same for all gateway OS.\nConfigure your edge gateway from the Cloud\nOnce the gateway is created and connected, you can add an OPC-UA data source. As part of this process, provide the data source local endpoint (the hostname and port of the OPC-UA server), and select AWS IoT SiteWise as the data destination. If needed, the Advanced configuration options also allow you to specify authentication and other security settings.\nAfter adding a data source, the Data sources section in the Overview tab of the gateway summary page should show the source as \xe2\x80\x9cIn Sync\xe2\x80\x9d within 3-5 minutes. This confirms that data is being published from the Windows gateway to AWS IoT SiteWise.\n2. Organize and process data\nOnce data is being ingested into AWS IoT SiteWise, structure and enrich it with additional context. AWS IoT SiteWise Models and Assets enable you to create a virtual representation of your industrial operations. You can map industrial data streams to asset properties, create asset hierarchies, apply mathematical transformations to measurements, and create metrics for assets or groups of assets. In the AWS console, first create an asset model and then create assets.\n3. Monitor equipment performance\nOnce an AWS IoT SiteWise asset model is established, you can use AWS IoT SiteWise to monitor your equipment using alarms and web portals. To use alarms, first define IoT Events alarms on your asset models, and then configure alarm thresholds and notifications on specific assets.\nYou can also create web portals to monitor the data from your processes, devices, and equipment. In the console, create a AWS IoT SiteWise Monitor web portal to view and securely share operational dashboards. To use the web portal with limited network connectivity, enable your portal at the edge.\nCleaning Up\nBe sure to clean up the work in this blog to avoid charges. Delete the following resources when finished in this order.\nAWS IoT SiteWise Monitor\nDashboard\nProject\nPortal\nAWS IoT SiteWise Gateway, Asset, and Asset Model\nAWS IoT Greengrass Core device under menu Greengrass \xe2\x86\x92 Core devices\nCore Device Thing in AWS IoT Core under the menu Manage \xe2\x86\x92 Things\n'"
5,Introducing the latest AWS Well- Architected IoT Lens,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/31/Introducing-the-latest-AWS-Well-Architected-IoT-Lens.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/introducing-the-latest-aws-well-architected-iot-lens/,"b'Introduction \nWe are pleased to introduce the latest version of AWS Well-Architected IoT Lens. IoT projects can be complex due to a combination of many factors, including devices, software, use case scenarios, environments, processing patterns, network connectivity technologies, communication protocols, security issues, technical risks, compliance requirements and standards. The AWS Well-Architected IoT Lens provides simple and detailed guidance when building IoT workloads on AWS.\nSince 2015, the AWS Well-Architected Framework (WAF) has been helping AWS customers and partners improve their cloud architectures and reduce their technical risk. The framework consists of questions, design principles, and best practices across the six pillars: Operational Excellence, Security, Reliability, Performance Efficiency, Cost Optimization, and Sustainability.\nThe AWS Well-Architected Framework helps you understand the pros and cons of the design decisions you make when building systems on AWS. Using WAF, you can learn architectural best practices for designing and operating reliable, secure, efficient, and cost-effective systems in the cloud. The framework provides a way for you to consistently measure your architecture against industry best practices, and help you identify potential areas for improvement. We believe that having well-architected systems greatly increases the likelihood of business success.\nIn 2019, we introduced AWS Well-Architected Lens for IoT workloads.  The IoT Lens provides you with a consistent approach to evaluate your IoT architectures, implement scalable designs, and identify and mitigate technical risks. The IoT Lens covers common IoT implementation scenarios and identifies key workload elements to allow you to architect your IoT device, edge and cloud-based applications and workloads according to the best practices that we have gathered from supporting thousands of customer implementations.\nToday, we are delighted to introduce the latest version of the AWS Well-Architected Internet of Things (IoT) Lens white paper. Here\xe2\x80\x99s an overview of what\xe2\x80\x99s new in the IoT Lens.\nWhat\xe2\x80\x99s new in the IoT Lens?\nImproved best practices and implementation guidance \xe2\x80\x94 Notably, it provides you with actionable guidance that you can use to improve your workloads in the areas that matter most to your business.\nUpdated guidance on new features and services \xe2\x80\x94 AWS IoT continues to evolve with new services, features, and emerging best practices. A set of updated IoT features and services announced to-date have been incorporated into the IoT Lens whitepaper to help you create more well-architected workloads. Some of the new services and features include: AWS IoT ExpressLink, AWS IoT FleetWise, AWS IoT TwinMaker, AWS IoT SiteWise Edge, AWS IoT RoboRunner, and Fleet Hub for AWS IoT Device Management. These and other improvements will make it easier for your development team to create innovative IoT workloads in your enterprise.\nUpdated architectures and links \xe2\x80\x94 Many new documents, blogs, instructional and video links have been provided to reflect a host of new products, features, and current industry best practices to assist with your IoT projects.\nIndustrial Internet of Things (IIoT) \xe2\x80\x93 New Lens guidance has been provided for industrial IoT, manufacturing, and critical infrastructure. Although general best practices still apply, there are some additional considerations that you should consider to be put into place to support the greater criticality and larger impact of Operational Technology (OT) and IIoT systems. These issues are outlined in detail in the new Lens.\nUpdated Well-Architected questions \xe2\x80\x93 combining the IoT Lens Checklist and the questions in the original IoT Lens.\nWho should use the IoT Lens?\nThe IoT Lens will be useful for many roles, including:\nBusiness Leaders \xe2\x80\x94 to widen your appreciation of the end-to-end implementation and benefits of IoT\nChief Technology Officers \xe2\x80\x94 to understand how to use the new AWS services and implementation guidance\nIoT solution architects \xe2\x80\x94 to learn to build solutions according to the tenets of the Well-Architected Framework\nIoT embedded engineers \xe2\x80\x94 to design IoT devices according to the tenets of the Well-Architected Framework\nOperations team \xe2\x80\x94 to monitor and manage innovative infrastructures that drive the operation of a broader range of IoT workloads\nSecurity team members \xe2\x80\x93 to incorporate security requirements in their IoT projects\n'"
6,Guidance on using ISA/IEC 62443 for IIoT projects,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/24/Guidance-on-using-ISA-IEC-62443-for-IIoT-projects.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/guidance-on-using-isa-iec-62443-for-iiot-projects/,"b'Introduction\nWith the increasing proliferation of Industrial Internet of Things (IIoT) systems and cloud services for innovation and digital transformation, government agencies and industrial customers are faced with protecting an expanding attack surface. The ISA/IEC 62443 series of standards were written before IIoT technologies were common but provide a strong basis for securing these environments. In this blog, we discuss the ISA/IEC 62443 standards, what is changing in the standards, and certifications to support the use of IIoT in Industrial Automation and Control Systems (IACS).\nBackground    \nThe ISA/IEC 62443 series of standards are developed jointly by ISA99 and IEC to address the need to design cybersecurity robustness and resilience into IACS. The goal in applying the 62443 series is to improve the safety, availability, integrity and confidentiality of components or systems used for industrial automation and control. In addition, they provide criteria for procuring and implementing secure industrial automation and control systems. Conformance with the requirements of the 62443 series is intended to improve cyber security and help identify and address vulnerabilities, reducing the risk of compromising confidential information or causing degradation or failure of the equipment (hardware and software) of processes under control. The 62443 series builds on established standards for the security of general-purpose information technology (IT) systems (e.g., the ISO/IEC 27000 series), identifying and addressing the important differences present in IACS. Many of these differences are based on the reality that cyber security risks with IACS may have Health, Safety, or Environment (HSE) implications and the response should be integrated with other existing risk management practices.\nISA/IEC 62443 is \xe2\x80\x9cconsensus-based,\xe2\x80\x9d comprehensive, and widely used across industries. Today, the growing availability of IIoT has widened the array of technologies and methodologies available for use in industrial automation environments. This growth increases the attack surface, which inherently increases the risk of compromise in these environments. To secure environments that use IIoT in IACS, a thorough understanding of IACS cybersecurity lifecycle is beneficial. The ISA/IEC 62443 series can provide a risk-based, defense-in-depth, and performance-based approach that can assist asset owners and their service providers in navigating the use of IIoT in industrial automation and control systems.\nUnderstanding the ISA/IEC 62443 Standards\nISA/IEC 62443, officially ANSI/ISA/IEC 62443, is a set of standards and technical reports that deal with industrial cybersecurity. Holistically, ISA/IEC 62443 is designed to help asset owners (end users), system integrators, and manufacturers reduce the risk of deploying and operating an IACS. Figure 1 gives an idea of the different parts of the standard. You can see that it is a multi-part standard.\nFigure 1: ISA/IEC 62443 documents (Courtesy of ISA)\nThese documents are arranged in four groups, corresponding to the primary focus and intended audience/role. It\xe2\x80\x99s helpful to consider the structure of these standards and how the hierarchy defines the roles and responsibilities for providing a robust IACS security posture.\nGeneral \xe2\x80\x93 This group includes documents that address topics that are common to the entire series.\nPolicies and Procedures \xe2\x80\x93 Documents in this group focus on the policies and procedures associated with IACS security.\nSystem Requirements \xe2\x80\x93 The documents in the third group address requirements at the system level.\nComponent Requirements \xe2\x80\x93 The fourth and final group includes documents that provide information about the more specific and detailed requirements associated with the development of IACS products.\nThe benefit of these standards is that asset owners can more easily (than on their own) define a required security level that references to a specific threat level, a measure that provides tighter security controls for higher risk functions. The benefit for service providers is that the standards provide clear explicit language of the requirements specified from the end user. And the benefit for product or component manufacturers is that they can more clearly describe the functionality of their products (from a security perspective) and differentiate themselves competitively, all of which is better than simply providing a long list of security features.\nPERA model and ISA TR 62443-4-3 (draft)\nToday, with the growing use of IIoT in Operational Technology (OT) environments, there is a need for the standards to be updated to support IIoT. Even though the standards were written before IIoT technologies were common, most concepts remain applicable or can be adapted for that environment. ISA 99 Working Group 9 published a Technical Report ISA TR 62443-4-3 (draft) which IEC calls IEC PAS 62443-4-3 (draft) which address the use of IIoT technology in IACS.\nPreviously, the Purdue Enterprise Reference Architecture (PERA) popularly referred to as the Purdue Model was used as a reference model for IACS. That model was rooted in several assumptions about technology and connections that IIoT technology can upset. With the advent of IIoT technology, the norms of the PERA model have been blurred as conventional thinking of physical network segregation and levels of functionality are changed by the internet-connected nature of IIoT technology.  IIoT technology has not rendered the model\xe2\x80\x99s illustration of functionality obsolescent but has blurred the network architecture analogy made during the 1990s on where these functionalities can reside. For example, in that model, the devices at Level 0 (the field level) were not as smart and had no connectivity directly to external systems. Today, however, a small temperature or vibration sensor can also be an IIoT device, that can connect to the cloud directly, bypassing all higher levels of the PERA model. The PERA model was used to describe functionality of existing IACS, but it began to be used as a model to implement a secured architecture, which was not originally envisaged.\nFigure 2: IIoT upsets the traditional Purdue (PERA) model (Adapted from ISA/IEC 62443-4-3 (draft))\nAssessing OT and IIoT cybersecurity risk, provides an example of zones and conduits in IACS with IIoT systems and discusses how asset owners can use ISA/IEC 62443-3-2, Security Risk Assessment for System Design. This is a key step in the risk assessment process by partitioning the System Under Consideration (SUC) into separate Zones and Conduits. The intent is to identify those assets which share common security characteristics in order to establish a set of common security requirements that reduce cybersecurity risk. Partitioning the SUC into Zones and Conduits can also reduce overall risk by limiting the impact of a cyber incident. Zone and conduit diagrams can assist in detailed IIoT cyber security risk assessments and help in identifying threats, and vulnerabilities, determining consequences and risks and providing remediations or control measures to safeguard assets from cyber events.\nThe draft Technical Report 62443-4-3 provides several examples of security capabilities which can be offered by Cloud Providers which asset owners can take advantage of for securing their IIoT solutions to achieve their security level targets. Refer to the table enclosed for a description of these security capabilities and AWS resources available to asset owners:\nIIoT cloud-based functionality (CBF) Security Controls Explanation\nIdentity management\nCloud providers can provide identity management capabilities for IIoT. These capabilities can include both the management of identity for devices as well as authentication and authorization for user access.\nEXAMPLE: The cloud service provider can support the use of hardware security modules (HSM), rotation of credentials.\nAWS resources\nAWS provides the following assets and services to help with identity management:\nSecurity and Identity for AWS IoT\nAmazon Cognito is a service that provides authentication, authorization, and user management for your web and mobile apps.\nAWS Identity and Access Management (IAM) is a service that enables you to manage access to AWS services and resources securely.\nDevice authentication and authorization for AWS IoT Greengrass.\nAWS Secrets Manager is a service that can be used to securely store and manage secrets in the cloud and encrypts the secrets using AWS KMS.\nIdentifying IoT device certificates with a revoked intermediate CA blog\nHow to manage IoT device certificate rotation with AWS IoT blog\nEnhancing IoT device security using HSM and AWS IoT Device SDK blog\nAuthorization management for components\nCloud providers can provide rights management capabilities to control access and authorization within the cloud and, in some cases, to IIoT CBF equipment.\nAWS resources\nAWS provides the following assets and services to help with authorization management for components:\nSecurity and Identity for AWS IoT\nAmazon Cognito is a service that provides authentication, authorization, and user management for your web and mobile apps.\nAWS Identity and Access Management (IAM) is a service that enables you to manage access to AWS services and resources securely.\nDevice authentication and authorization for AWS IoT Greengrass.\nAWS IoT Core Authorization\nData protection policies Cloud providers can provide capabilities to assist asset owners in protecting data availability, integrity, privacy and confidentiality in IIoT CBF including use of encryption for data in transit and at rest.\nEXAMPLE: Supporting asset owner\xe2\x80\x99s data classification and safeguardingAWS resourcesAWS provides the following assets and services to help with data protection:\nAWS Shared Responsibility Model for security and compliance.\nAWS Data Privacy\nAWS Compliance Programs and Offerings\nAWS Compliance Solutions Guide\nAWS KMS enables you to easily create and control the keys used for cryptographic operations in the cloud.\nData protection in AWS IoT SiteWise\nAmazon Macie to discover and protect sensitive IIoT data at scale.\nPrivacy Features of AWS Services\nData residency policies\nCloud providers can provide the capability for asset owners to establish residency controls for data in the cloud.\nAWS resources\nAWS provides the following assets and services to help with data residency requirements:\nAWS Global Infrastructure\nAWS Data Residency whitepaper\nAddressing Data Residency with AWS blog\nAWS Outposts allows you to extend and run native AWS services on premises\nAWS Hybrid Cloud services extends AWS infrastructure and services to on premises and at the edge\nSecure communications management\nCloud providers can offer services such as VPNs or other secure communication capabilities for IIoT CBF communications. These capabilities can include a service to convert insecure automation protocols into secure communication protocols before transmission.\nAWS resources\nAWS provides the following assets and services to help with secure communications management:\nAWS IoT SDKs to help you securely and quickly connect devices to AWS IoT.\nFreeRTOS Libraries for networking and security in embedded applications.\nSecurity best practices for AWS IoT SiteWise\n AWS Virtual Private Network (VPN) solutions establish secure connections between industrial plants and AWS global network.\nAWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated network connection from your premises to AWS.\nAWS IoT SiteWise gateway allow you to ingest data using industrial protocols such as OPC-UA, Modbus TCP and Ethernet/IP, etc.\n Machine to Cloud Connectivity Framework\nAudit and monitoring services\nCloud providers can offer audit and monitoring capabilities for IIoT CBF, including the ability to centrally log events and provide analysis. This can also include threat detection and behavior anomalies.\nAWS resources\nAWS provides the following assets and services to help with audit and monitoring:\nAWS IoT Device Defender to monitor and audit your fleet of IoT devices.\nMonitoring AWS IoT with CloudWatch Logs to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.\nLogging AWS IoT API Calls with AWS CloudTrail to provide a record of actions taken by a user, a role, or an AWS service in AWS IoT.\nMonitoring with AWS IoT Greengrass logs\nAWS Config to assess, audit, and evaluate the configurations of your AWS resources.\nAmazon GuardDuty to continuously monitor for malicious activity and unauthorized behavior to protect your AWS accounts and workloads.\nAWS Security Hub to automate AWS security checks and centralize security alerts.\nImplement security monitoring across OT, IIoT and cloud blog\nIncident response\nCloud providers can provide capabilities to supplement asset owner\xe2\x80\x99s incident response activities\nAWS resources\nAWS provides the following assets and services to help with incident response:\nAWS Security Incident Response Guide\n AWS Systems Manager provides a centralized and consistent way to gather operational insights and carry out routine management tasks.\n Enable compliance and mitigate IoT risks with automated incident response blog\nAWS Incident response blogs\nAWS Customer Incident Response Team blog\nPatch management\nCloud providers can provide patching capabilities for IIoT CBF equipment.\nAWS resources\nAWS provides the following assets and services to help with patch management:\nFreeRTOS Over-the-Air Updates\nAWS IoT Greengrass Core Software OTA Updates\nAWS IoT jobs to define a set of remote operations that you send to and execute on one or more devices connected to AWS IoT.\nAWS Systems Manager Patch Manager automates the process of patching managed instances with both security related and other types of updates such as operating systems and applications.\nSchedule remote operations using AWS IoT Device Management Jobs blog\nSecurity analytics\nCloud providers can provide the capability to identify anomalies to gain insights on complex events which can be used to improve the security posture of your IIoT Cloud Based Functionality (CBF). This can enable the asset owner to detect and respond to incidents in a timely manner.\nAWS resources\nAWS provides the following assets and services to help with security analytics:\nAWS IoT Device Defender helps you identify and respond to IoT security issues\n AWS IoT Events helps you detect and respond to events from IoT sensors and applications\nAmazon GuardDuty protects your AWS accounts with intelligent threat detection\n Amazon Security Lake helps you centralize security data for analytics\n AWS services for security analytics\nBackup and Recovery of OT and IIoT data\nCloud providers can provide backup and recovery options for IIoT CBF data.\nAWS resources\nAWS provides the following assets and services to help with backup and recovery of OT and IIoT data:\n Resilience in AWS IoT Greengrass to help support data resiliency and backup needs.\n Backup and Restore Use Cases with AWS\nCloudEndure Disaster Recovery for fast and reliable recovery into AWS.\nAWS Backup to centrally manage and automate backups across AWS services.\nDisaster Recovery for AWS IoT solution guidance\nFigure 3: Examples of security capabilities offered by cloud providers (from TR-62443-4-3) along with AWS services and guidance.\nOther useful AWS resources for asset owners include the AWS Well Architected Framework, IoT Lens to design, deploy, and architect IIoT workloads aligned with architectural best practices and AWS Security Best Practices for Manufacturing OT whitepaper.\nISASecure IIoT Component Security Assurance (ICSA)\nThe ISASecure program announced a new ISASecure certification for Industrial Internet of Things (IIoT) components based on the ISA/IEC 62443 series of standards. The certification addresses the need for industry-vetted IIoT certification program. The ISASecure IIoT Component Security Assurance (ICSA) is a security certification program for IIoT devices and IIoT gateways. ICSA is based upon the 62443 standard and a component that meets the requirements of the ISASecure ICSA specification will earn the ISASecure ICSA certification; a trademarked designation that provides recognition of product security characteristics and capabilities, and provides an independent industry stamp of approval similar to a \xe2\x80\x98Safety Integrity Level\xe2\x80\x99 Certification (ISO/IEC 61508). The ICSA is based on 62443-4-1 and 62443-4-2 with some exceptions and extensions. The extensions clarify the application of 62443 principles to IIoT environments. Examples are creating \xe2\x80\x9cinternal\xe2\x80\x9d zones using compartmentalization technologies, controlling application of software updates, securing remote management, device authentication strength, and component resilience to cloud services or the cloud interface. In addition, an ongoing security maintenance audit is required to maintain certification. Cloud services are not in scope for this certification.\n'"
7,How to build smart applications using Protocol Buffers with AWS IoT Core,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/21/How-to-build-smart-applications-using-Protocol-Buffers-with-AWS-IoT-Core-1024x576.png,https://aws.amazon.com/blogs/iot/how-to-build-smart-applications-using-protocol-buffers-with-aws-iot-core/,"b'Introduction to Protocol Buffers\nProtocol Buffers, or Protobuf, provide a platform-neutral approach for serializing structured data. Protobuf is similar to JSON, except it is smaller, faster, and is capable of automatically generating bindings in your preferred programming language.\nAWS IoT Core is a managed service that lets you connect billions of IoT devices and route trillions of messages to AWS services, enabling you to scale your application to millions of devices seamlessly. With AWS IoT Core and Protobuf integration, you can also benefit from Protobuf\xe2\x80\x99s lean data serialization protocol and automated code binding generation.\nAgility and security in IoT with Protobuf code generation\nA key advantage comes from the ease and security of software development using Protobuf\xe2\x80\x99s code generator. You can write a schema to describe messages exchanged between the components of your application. A code generator (protoc or others) interprets the schema and implements the encoding and decoding function in your programming language of choice. Protobuf\xe2\x80\x99s code generators are well maintained and widely used, resulting in robust, battle-tested code.\nAutomated code generation frees developers from writing the encoding and decoding functions, and ensures its compatibility between programming languages. Allied with the new launch of AWS IoT Core\xe2\x80\x99s Rule Engine support for Protocol Buffer messaging format, you can have a producer application written in C running on your device, and an AWS Lambda function consumer written in Python, all using generated bindings.\nOther advantages of using Protocol Buffers over JSON with AWS IoT Core are:\nSchema and validation: The schema is enforced both by the sender and receiver, ensuring that proper integration is achieved. Since messages are encoded and decoded by the auto-generated code, bugs are eliminated.\nAdaptability: The schema is mutable and it is possible to change message content maintaining backward and forward compatibility.\nBandwidth optimization: For the same content, message length is smaller using Protobuf, since you are not sending headers, only data. Over time this provides better device autonomy and less bandwidth usage. A recent research on Messaging Protocols and Serialization Formats revealed that a Protobuf formatted message can be up to 10 times smaller than its equivalent JSON formatted message. This means fewer bytes effectively go through the wire to transmit the same content.\nEfficient decoding: Decoding Protobuf messages is more efficient than decoding JSON, which means recipient functions run in less time. A benchmark run by Auth0 revealed that Protobuf can be up to 6 times more performant than JSON for equivalent message payloads.\nThis blog post will walk you through deploying a sample application that publishes messages to AWS IoT Core using Protobuf format. The messages are then selectively filtered by the AWS IoT Core Rules Engine rule.\nLet\xe2\x80\x99s review some of the basics of Protobuf.\nProtocol Buffers in a nutshell\nThe message schema is a key element of Protobuf. A schema may look like this:\nsyntax = ""proto3"";\n\nimport ""google/protobuf/timestamp.proto"";\n\nmessage Telemetry\n{\n  enum MsgType\n  {\n    MSGTYPE_NORMAL = 0;\n    MSGTYPE_ALERT = 1;\n  }\n  MsgType msgType = 1;\n  string instrumentTag = 2;\n  google.protobuf.Timestamp timestamp = 3;\n  double value = 4;\n}\nThe first line of the schema defines the version of Protocol Buffers you are using. This post will use proto3 version syntax, but proto2 is also supported.\nThe following line indicates that a new message definition called Telemetry will be described.\nThis message in particular has four distinct fields:\nA msgType field, which is of type MsgType and can only take on enumerated values ""MSGTYPE_NORMAL"" or ""MSGTYPE_ALERT""\nAn instrumentTag field, which is of type string and identifies the measuring instrument sending telemetry data\nA timestamp field of type google.protobuf.Timestamp which indicates the time of the measurement\nA value field of type double which contains the value measured\nPlease consult the complete documentation for all possible data types and additional information on the syntax.\nA Telemetry message written in JSON looks like this:\n{\n  ""msgType"": ""MSGTYPE_ALERT"",\n  ""instrumentTag"": ""Temperature-001"",\n  ""timestamp"": 1676059669,\n  ""value"": 72.5\n}\nJSON\nThe same message using protocol Buffers (encoded as base64 for display purposes) looks like this:\n0801120F54656D70657261747572652D3030311A060895C89A9F06210000000000205240\nNote that the JSON representation of the message is 115 bytes, versus the Protobuf one at only 36 bytes.\nOnce the schema is defined protoc can be used to:\nCreate bindings in your programming language of choice\nCreate a FileDescriptorSet, that is used by AWS IoT Core to decode received messages.\nUsing Protocol Buffers with AWS IoT Core\nProtobuf can be used in multiple ways with AWS IoT Core. The simplest way is to publish the message as binary payload and have recipient applications decode it. This is already supported by AWS IoT Core Rules Engine and works for any binary payload, not just Protobuf.\nHowever, you get the most value when you want to decode Protobuf messages for filtering and forwarding. Filtered messages can be forwarded as Protobuf, or even decoded to JSON for compatibility with applications that only understand this format.\nThe recently launched AWS IoT Rules Engine support for Protocol Buffer messaging format allows you to do just that with minimal effort, in a managed way. In the following sections we will guide you through deploying and running a sample application.\nPrerequisites\nTo run this sample application you must have the following:\nA computer with protoc installed. Refer to the official installation instructions for your Operating System.\nAWS CLI (installation instructions)\nAWS account and valid credentials with full permissions on Amazon S3, AWS IAM, AWS IoT Core and AWS CloudFormation\nPython 3.7 or newer\nSample application: Filtering and forwarding Protobuf messages as JSON\nTo deploy and run the sample application, we will perform 7 simple steps:\nDownload the sample code and install Python requirements\nConfigure your IOT_ENDPOINT and AWS_REGION environment variables\nUse protoc to generate Python bindings and message descriptors\nRun a simulated device using Python and the Protobuf generated code bindings\nCreate AWS Resources using AWS CloudFormation and upload the Protobuf file descriptor\nInspect the AWS IoT Rule that matches, filters and republishes Protobuf messages as JSON\nVerify transformed messages are being republished\nStep 1: Download the sample code and install Python requirements\nTo run the sample application, you need to download the code and install its dependencies:\nFirst, download and extract the sample application from our AWS github repository: https://github.com/aws-samples/aws-iotcore-protobuf-sample\nIf you downloaded it as a ZIP file, extract it\nTo install the necessary python requirements, run the following command within the folder of the extracted sample application\npip install -r requirements.txt\nThe command above will install two required Python dependencies: boto3 (the AWS SDK for Python) and protobuf.\nStep 2: Configure your IOT_ENDPOINT and AWS_REGION environment variables\nOur simulated IoT device will connect to the AWS IoT Core endpoint to send Protobuf formatted messages.\nIf you are running Linux or Mac, run the following command. Make sure to replace <AWS_REGION> with the AWS Region of your choice.\nexport AWS_REGION=<AWS_REGION>\nexport IOT_ENDPOINT=$(aws iot describe-endpoint --endpoint-type iot:Data-ATS --query endpointAddress --region $AWS_REGION --output text)\nStep 3: Use protoc to generate Python bindings and message descriptor\nThe extracted sample application contains a file named msg.proto similar to the schema example we presented earlier.\nRun the commands below to generate the code bindings your simulated device will use to generate the file descriptor.\nprotoc --python_out=. msg.proto\nprotoc -o filedescriptor.desc msg.proto\nAfter running these commands, you should see in your current folder two new files:\nfiledescriptor.desc msg_pb2.py\nStep 4: Run the simulated device using Python and the Protobuf generated code bindings\nThe extracted sample application contains a file named simulate_device.py.\nTo start a simulated device, run the following command:\npython3 simulate_device.py\nVerify that messages are being sent to AWS IoT Core using the MQTT Test Client on the AWS console.\nAccess the AWS IoT Core service console: https://console.aws.amazon.com/iot; make sure you are in the correct AWS Region.\nUnder Test, select MQTT test client.\nUnder the Topic filter, fill in test/telemetry_all\nExpand the Additional configuration section and under MQTT payload display select Display raw payloads.\nClick Subscribe and watch as Protobuf formatted messages arrive into the AWS IoT Core MQTT broker.\nStep 5: Create AWS Resources using AWS CloudFormation and upload the Protobuf file descriptor\nThe extracted sample application contains an AWS CloudFormation template named support-infrastructure-template.yaml.\nThis template defines an Amazon S3 Bucket, an AWS IAM Role and an AWS IoT Rule.\nRun the following command to deploy the CloudFormation template to your AWS account. Make sure to replace <YOUR_BUCKET_NAME> and <AWS_REGION> with a unique name for your S3 Bucket and the AWS Region of your choice.\naws cloudformation create-stack --stack-name IotBlogPostSample \\\n--template-body file://support-infrastructure-template.yaml \\\n--capabilities CAPABILITY_IAM \\\n--parameters ParameterKey=FileDescriptorBucketName,ParameterValue=<YOUR_BUCKET_NAME> \\\n--region=<AWS_REGION>\nAWS IoT Core\xe2\x80\x99s support for Protobuf formatted messages requires the file descriptor we generated with protoc. To make it available we will upload it to the created S3 bucket. Run the following command to upload the file descriptor. Make sure to replace <YOUR_BUCKET_NAME> with the same name you chose when deploying the CloudFormation template. aws s3 cp filedescriptor.desc s3://<YOUR_BUCKET_NAME>/msg/filedescriptor.desc\nStep 6: Inspect the AWS IoT Rule that matches, filters, and republishes Protobuf messages as JSON\nLet\xe2\x80\x99s assume you want to filter messages that have a msgType of MSGTYPE_ALERT, because these indicate there might be dangerous operating conditions. The CloudFormation template creates an AWS IoT Rule that decodes the Protobuf formatted message our simulated device is sending to AWS IoT Core, it then selects those that are alerts and republishes, in JSON format, so that another MQTT topic responder can subscribe to. To inspect the AWS IoT Rule, perform the following steps:\nAccess the AWS IoT Core service console: https://console.aws.amazon.com/iot\nOn the left-side menu, under Message Routing, click Rules\nThe list will contain an AWS IoT Rule named ProtobufAlertRule, click to view the details\nUnder the SQL statement, note the SQL statement, we will go over the meaning of each element shortly\nUnder Actions, note the single action to Republish to AWS IoT topic\nSELECT\n  VALUE decode(encode(*, \'base64\'), ""proto"", ""<YOUR_BUCKET_NAME>"", ""msg/filedescriptor.desc"", ""msg"", ""Telemetry"")\nFROM\n  \'test/telemetry_all\'\nWHERE\n  decode(encode(*, \'base64\'), ""proto"", ""<YOUR_BUCKET_NAME>"", ""msg/filedescriptor.desc"", ""msg"", ""Telemetry"").msgType = \'MSGTYPE_ALERT\'\nSQL\nThis SQL statement does the following:\nThe SELECT VALUE decode(...) indicates that the entire decoded Protobuf payload will be republished to the destination AWS IoT topic as a JSON payload. If you wish to forward the message still in Protobuf format, you can replace this with a simple SELECT *\nThe WHERE decode(...).msgType = \'MSGTYPE_ALERT\' will decode the incoming Protobuf formatted message and only messages containing field msgType with value MSGTYPE_ALERT will be forwarded\nStep 7: Verify transformed messages are being republished\nIf you click on the single action present in this AWS IoT Rule, you will note that it republishes messages to the topic/telemetry_alerts topic.\nThe destination topic test/telemetry_alerts is part of the definition of the AWS IoT Rule action, available in the AWS CloudFormation template of the sample application.\nTo subscribe to the topic and see if JSON formatted messages are republished, follow these steps:\nAccess the AWS IoT Core service console: https://console.aws.amazon.com/iot\nUnder Test, select MQTT test client\nUnder the Topic filter, fill in test/telemetry_alerts\nExpand the Additional configuration section and under MQTT payload display make sure Auto-format JSON payloads option is selected\nClick Subscribe and watch as JSON-converted messages with msgType MSGTYPE_ALERT arrive\nIf you inspect the code of the simulated device, you will notice approximately 20% of the simulated messages are of MSGTYPE_ALERT type and messages are sent every 5 seconds. You may have to wait to see an alert message arrive.\nClean Up\nTo clean up after running this sample, run the commands below:\n# delete the file descriptor object from the Amazon S3 Bucket\naws s3 rm s3://<YOUR_BUCKET_NAME>/msg/filedescriptor.desc\n\n# detach all policies from the IoT service role\naws iam detach-role-policy --role-name IoTCoreServiceSampleRole \\\n  --policy-arn $(aws iam list-attached-role-policies --role-name IoTCoreServiceSampleRole --query \'AttachedPolicies[0].PolicyArn\' --output text)\n\n# delete the AWS CloudFormation Stack\naws cloudformation delete-stack --stack-name IotBlogPostSample\n'"
8,Building an OCPP-compliant electric vehicle charge point operator solution using AWS IoT Core,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/21/Building-an-OCPP-compliant-electric-vehicle-charge-point-operator-solution-using-AWS-IoT-Core.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/building-an-ocpp-compliant-electric-vehicle-charge-point-operator-solution-using-aws-iot-core/,"b'The shift from fossil fuels to electric powered vehicles is a key component of government and commercial commitments to achieve net-zero emissions by 2050. It is projected that the United States alone will require a national network of at least 500,000 electric vehicle (EV) chargers by 2030 to support the projected number of EVs on the road [1][2]. Globally, governments and industries are partnering to build millions of public charging and private fleet charging networks [3].\nInstalling and powering the physical charging infrastructure is just the first step \xe2\x80\x94 chargers (Charge Points or \xe2\x80\x9cCP\xe2\x80\x9d) need to be continuously monitored and managed by their operators (Charge Point Operators or \xe2\x80\x9cCPO\xe2\x80\x9d). CPOs are responsible for regular remote and on-site maintenance, collecting health metrics, and managing operational configurations. CPOs are also responsible for ensuring that the CPs are compatible with the latest industry standards and protocols, like Open Charge Point Protocol (OCPP) and ISO 15118. And all this must be implemented with security measures that can support CPs at scale.\nThis post demonstrates how AWS services like AWS IoT Core, Amazon Elastic Container Service (Amazon ECS), and AWS Lambda can be used to build a highly-scalable, low-latency electric vehicle charge point operator system based on the EV industry standard, OCPP.\nAbout AWS IoT Core\nAWS IoT Core lets you connect billions of devices and route trillions of messages to and from AWS services without managing infrastructure. AWS IoT Core handles the heavy-lifting of scaling and message routing\xe2\x80\x94making it easier for customers needing to support large fleets of remote devices, like CPs, communicating through publish-and-subscribe patterns. AWS IoT Core natively implements MQTT, HTTPS, and MQTT over WebSockets, and can be adapted to support other protocols, like OCPP.\nOverview\nMost commercially available CPs implement OCPP as a means of bi-directional publish-and-subscribe communication with a CPO. Operating a CPO on AWS requires the introduction of an OCPP WebSocket endpoint, with which CPs communicate. That endpoint, described here as the OCPP Gateway, acts as a proxy between OCPP and MQTT, enabling integration with AWS IoT Core and downstream CPO services built on AWS.\nThe following architecture diagram illustrates the high-level end-to-end solution you will build in this blog post.\nFigure 1: Charge Point OCPP message proxied to CPO Service via one-to-one relationship between WebSocket connection and MQTT topic\nArchitecture\nThe architecture diagram below depicts the resources that this solution will deploy into your account.\nFigure 2: OCPP Gateway solution stack architecture\nThe OCPP Gateway is deployed as an Amazon ECS application which can run on either AWS Fargate or Amazon Elastic Compute Cloud (EC2). AWS Fargate eliminates the need for infrastructure management and is the preferred option for this solution. Containerized applications can be scaled horizontally, allowing the OCPP Gateway to automatically scale up or down as the number of connected CPs changes. The long running nature of ECS tasks allows for WebSockets connections to be maintained for extended periods, reducing network traffic and connection overheads.\nA Network Load Balancer (NLB) fronts multiple OCPP Gateway containers. The NLB provides a single, fully qualified domain name (FQDN) that serves as the OCPP endpoint to which CPs initiate connection. Upon connection initiation, the NLB will route the charge point connection to one of the OCPP Gateway instances, which will establish the WebSocket connection between itself and the CP.\nWhen a CP establishes a socket connection with an instance of the OCPP Gateway, that Handler sets up an MQTT connection to AWS IoT Core using the CP\xe2\x80\x99s unique identifier as the Thing ID. That client subscribes to MQTT message topics associated with that CP.\nThe MQTT client implemented by the OCPP Gateway is socket aware, thereby providing a one-to-one association between the MQTT subscription and the CP. Any messages initiated by the CPO will be delivered to the MQTT client associated with the destination CP and forwarded over the socket to that CP. AWS IoT Core is highly elastic and will readily scale as more CPs are on-boarded.\nSolution walk-through\nThis solution demonstrates how you can use AWS to build a scalable CPO by deploying the OCPP Gateway to integrate with AWS IoT Core. The steps below will walk you through the deployment of an OCPP Gateway into your AWS account, will demonstrate how you can simulate CP message, and will provide examples of you how can act on those message using AWS resources.\nPrerequisites\nVerify that your environment satisfies the following prerequisites:\nYou have:\nAn AWS account\nAdministratorAccess policy granted to your AWS account (for production, we recommend restricting access as needed)\nBoth console and programmatic access\nAWS CLI installed and configured to use with your AWS account\nNodeJS 12+ installed\nTypescript 3.8+ installed\nAWS CDK CLI installed\nDocker installed\nPython 3+ installed\nPrepare the CDK\nThe solution will be deployed into your AWS account using infrastructure-as-code wih the AWS Cloud Development Kit (CDK).\nClone the repository:\ngit clone https://github.com/aws-samples/aws-ocpp-gateway.git\nBash\nNavigate to this project on your computer using your terminal:\ncd aws-ocpp-gateway\nBash\nInstall the project dependencies by running this command:\nnpm install\nBash\nSet environment variables for CDK to the target AWS account ID and region where you wish to deploy this stack\nNote: AWS IoT Core is available in these AWS regions.\nexport CDK_DEPLOY_ACCOUNT=targetAccountId (e.g. 12345678910)\nexport CDK_DEPLOY_REGION=targetRegion (e.g. eu-west-1)\nBash\n(Optional) Bootstrap AWS CDK on the target account and regioon\nNote: This is required if you have never used AWS CDK before on this account and region combination. (More information on CDK bootstrapping).\nnpx cdk bootstrap aws://{targetAccountId}/{targetRegion}\nBash\n(Optional) Enable WebSockets using TLS with your own domain name\nIf you have an Amazon Route 53 hosted zone in your account, this solution can automatically:\nCreate subdomain (A Record) gateway.yourdomain.com\nCreate an AWS Certificate Manager (ACM) SSL certificate for it\nEnable TLS for your gateway wss://gateway.yourdomain.com\nUncomment this line in /bin/aws-ocpp-gateway.ts and replace yourdomain.com with your own domain name (i.e. example.com)\n  // domainName: \'yourdomain.com\',\nBash\nDeploy the solution to your AWS Account\nVerify that Docker is running with the following command:\ndocker version\nBash\nNote: If you get an error like the one below, then Docker is not running and need to be restarted:\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\nBash\nDeploy the OCPP Gateway using the following CDK command:\nnpx cdk deploy\nBash\nNote: This step can take about 10 minutes, depending on your computer and network speed.\nYou can view the progress of your CDK deployment in the CloudFormation console in the selected region.\nScreenshot: AWS CloudFormation stack resources\nOnce deployed, take note of the AwsOcppGatewayStack.websocketURL value\nNote: This WebSocket URL is the entry point that will be set in your CP configurations or in the\nEV Charge Point simulator described below.\nIf you used your own domain, your output will look like:\n..\nOutputs:\nAwsOcppGatewayStack.loadBalancerDnsName = gateway.example.com\n\xf0\x9f\x91\x89 AwsOcppGatewayStack.websocketURL = wss://gateway.example.com\n...\nBash\nOtherwise, like this:\n...\nOutputs:\nAwsOcppGatewayStack.loadBalancerDnsName = ocpp-gateway-xxxxxxx.elb.xx-xxxx-x.amazonaws.com\n\xf0\x9f\x91\x89 AwsOcppGatewayStack.websocketURL = ws://ocpp-gateway-xxxxxxx.elb.xx-xxxx-x.amazonaws.com\n...\nBash\nSimulating CP connectivity\nWe have provided the simulate.py Python script to help you test and explore the capability of the OCPP Gateway and AWS IoT Core without the need for a physical CP. Other OCPP simulators, like OCPP-2.0-CP-Simulator, can also be used.\nSimulation setup\nIn AWS Explorer, select your region and open AWS IoT Core, All devices, Things. On the Things tab choose Create a things.\nSelect Create single thing and choose Next\nEnter a Thing name\nNote: Each EV Charge Point must map to a single IoT Thing. For our test, we\xe2\x80\x99ll set the Thing name as CP1\nScreenshot: Creating an IoT Thing\nChoose Next\nFor Device certificate, select Skip creating a certificate at this time, and choose Create thing\nScreenshot: Skip the certification creation\nNavigate to this folder with your terminal:\ncd ev-charge-point-simulator\nBash\nCreate a Python virtual environment and activate it by running this command:\npython3 -m venv venv && source venv/bin/activate\nBash\nInstall the Python dependencies by running:\npip3 install -r requirements.txt\nBash\nSimulate an EV charge point boot and heartbeat notification\nThe Python script simulates some basic functionality of an EV charge point:\nSending a BootNotification, including attributes about the CP hardware\nSending Heartbeat messages based on a frequency instructed by the CPO (this is defined by the interval parameter returned in the response to the BootNotification)\nRun the Python script using the following command, making sure to replace the --url value with the AwsOcppGatewayStack.websocketURL returned from the cdk deployment:\npython3 simulate.py --url {websocket URL generated from the AWS OCPP Stack} --cp-id CP1 \nBash\nNote: we are using --cp-id CP1 which must match the value of the IoT Thing created above. If the --cp-id doesn\xe2\x80\x99t match the IoT Thing name, the connection will be rejected by the OCPP Gateway.\nA successful output should look like this:\n(venv) ev-charge-point-simulator % python3 simulate.py --url {websocket URL generated from the AWS OCPP Stack} --cp-id CP1 \nINFO:ocpp:CP1: send [2,""0678cb2a-a7a2-42bc-8037-d01164e77ac6"",""BootNotification"",{""chargingStation"":{""model"":""ABC 123 XYZ"",""vendorName"":""Acme Electrical Systems"",""firmwareVersion"":""10.9.8.ABC"",""serialNumber"":""CP1234567890A01"",""modem"":{""iccid"":""891004234814455936F"",""imsi"":""310410123456789""}},""reason"":""PowerUp""}]\nINFO:ocpp:CP1: receive message [3,""0678cb2a-a7a2-42bc-8037-d01164e77ac6"",{""currentTime"":""2023-02-16T19:00:18.630818"",""interval"":10,""status"":""Accepted""}]\nINFO:root:CP1: connected to central system\nINFO:root:CP1: heartbeat interval set to 10\nINFO:ocpp:CP1: send [2,""9b7933a7-5216-496d-9bb0-dae45014bb98"",""Heartbeat"",{}]\nINFO:ocpp:CP1: receive message [3,""9b7933a7-5216-496d-9bb0-dae45014bb98"",{""currentTime"":""2023-02-16T19:00:19.073675""}]\nBash\nThis exchange represents a successful simulation of a CP, first sending a BootNotification, followed by subsequent Heartbeat at the specified interval. The output includes both the simulated OCPP message sent from the CP to AWS IoT (prefixed send) and the response received from AWS (prefixed received message).\nTo simulate with a different CP, set a different value for the --cp-id argument.\nNote: if the --cp-id value doesn\xe2\x80\x99t have a correspondent IoT Thing the OCPP Gateway will reject the connection. Here is an unsuccessful example passing --cp-id CP2, which is not registered as a Thing in IoT:\n(venv) ev-charge-point-simulator % python3 simulate.py --url {websocket URL generated from the AWS OCPP Stack} --cp-id CP2 \nINFO:ocpp:CP2: send [2,""32dc5b6e-77b0-4105-b217-28e20b579ecc"",""BootNotification"",{""chargingStation"":{""model"":""ABC 123 XYZ"",""vendorName"":""Acme Electrical Systems"",""firmwareVersion"":""10.9.8.ABC"",""serialNumber"":""CP1234567890A01"",""modem"":{""iccid"":""891004234814455936F"",""imsi"":""310410123456789""}},""reason"":""PowerUp""}]\nERROR:root:CP2: received 1008 (policy violation) Charge Point CP2 not registered as an IoT Thing; then sent 1008 (policy violation) Charge Point CP2 not registered as an IoT Thing\nBash\nMonitor OCPP activity in the AWS Console\nMessages from and to the CP are brokered through AWS IoT Core. These messages utilize the MQTT publish-and-subscribe protocol. You can see these messages in the console.\nIn AWS Explorer, select your region and open AWS IoT Core, MQTT test client\nIn the test client, select the Subscribe to a topic tab, and subscribe to these two topics by entering these values in the Topic filter:\na. To view all messages from CP to AWS\n+/in\nBash\nb. To view all messages from AWS to CP\n+/out\nBash\nScreenshot: Subscribe to Topics\nRun the Python script to simulate a CP and watch the messages in the MQTT test client\nTrack EV Charge Point hardware attributes in device shadows\nWhen a CP sends a BootNotification, its hardware attributes are stored in a Device Shadow associated with the IoT Thing. You can see these attributes in the console.\nIn AWS Explorer, select your region and open AWS IoT Core, All devices, Things\nToggle the check box against the Thing created previously\nSelect the Device Shadows tab.\nSelect the Classic Shadow device shadow name hyperlink to see the Device Shadow document and the hardware attributes reported by the EV Charge Point:\n{\n  ""state"": {\n    ""reported"": {\n      ""chargingStation"": {\n        ""model"": ""ABC 123 XYZ"",\n        ""vendorName"": ""Acme Electrical Systems"",\n        ""firmwareVersion"": ""10.9.8.ABC"",\n        ""serialNumber"": ""CP1234567890A01"",\n        ""modem"": {\n          ""iccid"": ""891004234814455936F"",\n          ""imsi"": ""310410123456789""\n        }\n      },\n      ""reason"": ""PowerUp""\n    }\n  }\n}\nJSON\nScreenshot: IoT Thing shadow document\nSimulate different CP hardware attributes by passing these arguments into the simulate.py script and verify their affect on the Device Shadow:\n--cp-serial \xe2\x80\x93 to set the serial number\n--cp-model \xe2\x80\x93 to set the model identification\n--cp-version \xe2\x80\x93 to set the firmware version\n--cp-vendor \xe2\x80\x93 to set the vendor name\n'"
9,Ingesting industrial media to Amazon Kinesis Video Streams using AWS IoT Greengrass V2 components,b'Costin B\xc4\x83dici',2023-04-17T17:33:20+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/21/Ingesting-industrial-media-to-Amazon-Kinesis-Video-Streams-using-AWS-IoT-Greengrass-V2-components.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/ingesting-media-to-kinesis-video-streams/,"b'Introduction\nOrganizations install hundreds of Internet Protocol (IP) cameras to increase security by surveilling indoor and outdoor spaces. This is a common need for manufacturing plant floors across industries such as automotive, commercial, Oil & Gas, public safety, and agri-tech. Companies connect cameras to the cloud to create a centralized view of their siloed data and also to add digital twin capabilities to their facilities. In this post, we will discuss how to use AWS IoT Greengrass V2 components to package and deploy an Amazon Kinesis Video Streams stream uploader that can do live-streaming, on-demand video upload, and local caching, thus facilitating use cases that require ingestion of live audio and video streams from pre-installed IP cameras.\nKinesis Video Streams is a fully managed AWS service that you can use to stream live video from devices to AWS, build applications for real-time video processing, perform batch video analytics, and more. You can use the Kinesis Video Streams service to ingest video and non-video data from many different sources like smartphones, security cameras, web cameras, drones, thermal imagery, and audio. Recently, we released an AWS IoT Greengrass component for Kinesis Video Streams that lets you stream media from your existing devices. The edge connector for the Kinesis Video Streams component (aws.iot.EdgeConnectorForKVS) reads video feeds from local IP cameras using Real Time Streaming Protocol (RTSP) and publishes the streams to the Kinesis Video Streams endpoint.\nSolution overview\nA company that develops smart building solutions is interested in building an application that ingests hundreds of video streams from the building entry, access control areas, and security gates. The company might be looking to incorporate video feeds in to a digital twin application using AWS IoT TwinMaker, along with using the AWS IoT TwinMaker application plugin for Grafana dashboard to request uploading of videos and checking historical video timelines.\nIt can be challenging to refactor the existing cameras to stream to an endpoint. Instead, you can deploy an AWS IoT Greengrass edge gateway and an AWS IoT Greengrass edge connector for Kinesis Video Streams component to ingest data from these cameras. The component connects to IP cameras within the same network and streams the video feed to Kinesis Video Streams. On the consumption side, you can use an application to read from the Kinesis Video Streams endpoint to act as a client. This component supports features like edge video caching, scheduled video recording, scheduled video uploading, live streaming, and historical video uploading to Kinesis Video Streams. The edge connector component provides a fully working AWS IoT Greengrass V2 component for video ingestion that can be customized based on needs.\nThe number of cameras that can be connected to this component per AWS IoT Greengrass hub is dependent on the compute power of the underlying hardware, network bandwidth, and AWS IoT SiteWise child assets used to store the configuration of the connector (currently this limit is 2000, refer to the documentation for details on child asset quotas). This architecture assumes that there is a stable network connection between the AWS IoT Greengrass device and AWS, with sufficient bandwidth for streaming the media.\nFigure: Ingesting video feed from IP cameras using AWS IoT Greengrass v2 components\nDeployment of AWS IoT Greengrass Core at the edge device. This device will be responsible for running the edge connector and interfacing with the cameras. The Greengrass Core software can be deployed on a Linux device, such as a Raspberry Pi or a Windows device. This device will eventually run the edge connector  Kinesis Video Streams component. Refer documentation for more details on how to setup AWS IoT Greengrass.\nInstall GStreamer version 1.18.4 or later on the edge device.\nOnce the edge device is setup, use the AWS IoT Greengrass service to deploy the edge connector for Kinesis Video Streams component. Edit the configuration page with the details specific to your deployment. Refer documentation to learn more about how to deploy components to AWS IoT Greengrass.\nOnce the edge connector for Kinesis Video Streams component is deployed, the configuration for the component is stored in AWS IoT SiteWise and AWS Secrets Manager. AWS IoT SiteWise stores two types of assets: theEdgeConnectorForKVSHub asset contains the asset name that identifies the unique hub where the connector is running and the EdgeConnectorForKVSCamera contains the properties specific to the cameras, like cron expression to start streaming and recording. For details, refer the GitHub page about the configuration parameters needed for this service .\nThe edge connector for Kinesis Video Streams ingests data from the camera feeds. There is an option here to add local storage as well as stream them to the Kinesis Video Streams endpoint.\nOn the client side, you can build your own custom applications to consume data from the Kinesis Video Streams endpoint. As an example, you can trigger live streaming video when you detect a motion.\nFor detailed steps on implementing this architecture and above steps, refer to github documentation.\nDetailed edge architecture\nFigure: Architecture for ingesting IP video cameras feed in Amazon Kinesis Video Stream\nThe edge architecture has three modules: controller, video recorder, and video uploader (see the previous diagram). While the default setting of the Kinesis Video Streams connector component is to stream the video, it has an optional functionality of recording video on the file system for local storage. The controller acts as a broker between the recorder and the uploader. It also facilitates communication between the two. The controller first initiates a pair of piped input and output stream objects. The video recorder retrieves stream data from the camera and puts the data into the piped output stream. Finally, the video uploader takes stream data from the piped input stream, then uploads the data to Kinesis Video Streams.\nScaling the solution\nNext, we\xe2\x80\x99ll look at sizing and limits to see how the solution scales. In the architecture, the edge connector for Kinesis Video Streams component and Greengrass Core do not have any scaling limitations. As the solution uses AWS IoT SiteWise to manage the RTSP camera configuration, the only hard limit is from the AWS IoT SiteWise child assets quota, which is fewer than 2000 child assets per parent asset. The number of cameras that can be supported by the edge device/Hub only depends on its hardware configurations. If there is enough network bandwidth and hardware capacity, the AWS IoT Greengrass device can support more cameras. From our internal testing, we tested 10+ cameras connected to the same edge device to ingest the feeds without any issues. Refer to the documentation Kinesis Video Streams API limits and quotas.\nBelow are some sample edge device configurations and the number of video streams they can support for optimal performance:\nA small instance (like Raspberry Pi 4 Model B) with 2GB RAM and 16GB SSD can support up to 2 1080p HD RTSP cameras uploading to the cloud at the same time with a network speed of 100 MBPS.\nA medium instance (like NVIDIA Jetson Nano Developer Kit) with 4GB RAM and 16GB SSD can support up to 4 1080p HD RTSP cameras uploading to the cloud at the same time over a network speed of 100 MBPS.\nA large instance (like Intel NUC) with 25GB RAM and 1T SSD can support up to 24 1080p HD RTSP cameras uploading to the cloud at the same time with a network speed of 600 MBPS.\nThis solution is primarily memory dependent, hence compute resources like CPU and GPU type and capacity are less relevant.\nClean up\nIf you used the GitHub link to implement this architecture, make sure to use the below steps to clean-up the resources to avoid incurring cost.\nUninstall Greengrass core software from the edge device\nDelete Kinesis Video Stream:\nOpen the Kinesis Video Streams console\nChoose Video streams in the left-hand menu and select the video stream\nChoose Delete video stream in the upper right corner of the screen\nA confirmation screen will appear. Enter Delete in the field and select Delete.\n'"
10,How to replicate AWS IoT SiteWise resources across environments,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/16/How-to-replicate-AWS-IoT-SiteWise-resources-across-environments.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/how-to-replicate-aws-iot-sitewise-resources-across-environments/,"b'Introduction\nAs you scale your AWS IoT SiteWise applications and move them into production, you may consider adopting common CI/CD methodologies that separate development and QA environments from production environments. This separation allows you to automate the deployment of these applications through deployment pipelines. You also may have multiple business units and/or industrial sites with common asset models and hierarchies that you would like to share and reuse across your organization. In these cases, customers typically have different AWS accounts to separate environments, whether between dev and prod or between different business units. The following diagram depicts such an example where development is separated from QA and production environments:\n\nTo help customers replicate AWS IoT SiteWise resources between environments, we created AWS IoT SiteWise Tools, a set of utilities that allow you export AWS IoT SiteWise Asset Models, Assets, and AWS IoT SiteWise Monitor Dashboards into AWS CloudFormation templates. The exported templates can then be used to recreate the exported resources into another AWS environment. In this blog, you will see a sample walkthrough of how to use AWS IoT SiteWise Tools to export models followed by an example architecture of how to automate the export and replication process in a CI/CD pipeline.\nAsset Model Export Walkthrough\nThe utilities in the AWS IoT SiteWise Tools repository give you the flexibility to replicate only the resources you need for your specific use case. You can choose to only export AWS IoT SiteWise asset models, or also export the corresponding assets and AWS IoT SiteWise Monitor dashboards. The export tool can be used manually from the command line (e.g. for a one-time export of an asset model into another environment) or can be integrated into your automation pipelines for CI/CD deployment scenarios. The utility can also be used to copy AWS IoT SiteWise resources for multi-region deployments within the same account. The AWS IoT SiteWise Tools repository has detailed documentation on how to use each of the utilities but for a basic demonstration of the tools, we created two asset models of a CNC Machine and Production Line as seen below. Each model contains a property and a hierarchical relationship between the two models.\nTo keep it simple, we will only export the models. Using the AWS IoT SiteWise export tools, we optionally specify the region we want to export models from and run the command with no other flags (if you also want to export assets along with the models, you would simply add the -a, --assets flag). The command output will look something like the following:\nIf the command succeeds, a CloudFormation template will be saved to a folder in the local directory named cfnexport. In our example case the CloudFormation will look like the following:\n{\n    ""AWSTemplateFormatVersion"": ""2010-09-09"",\n    ""Description"": ""SiteWise Export"",\n    ""Resources"": {\n        ""CNCMachineResource"": {\n            ""Type"": ""AWS::IoTSiteWise::AssetModel"",\n            ""Properties"": {\n                ""AssetModelName"": ""CNC Machine"",\n                ""AssetModelProperties"": [\n                    {\n                        ""Name"": ""SpindleSpeed"",\n                        ""DataType"": ""DOUBLE"",\n                        ""Unit"": ""RPM"",\n                        ""Type"": {\n                            ""TypeName"": ""Measurement""\n                        },\n                        ""LogicalId"": ""SpindleSpeed9f2e03dd""\n                    }\n                ],\n                ""AssetModelHierarchies"": []\n            }\n        },\n        ""ProductionLineResource"": {\n            ""Type"": ""AWS::IoTSiteWise::AssetModel"",\n            ""Properties"": {\n                ""AssetModelName"": ""Production Line"",\n                ""AssetModelProperties"": [\n                    {\n                        ""Name"": ""Location"",\n                        ""DataType"": ""STRING"",\n                        ""Type"": {\n                            ""TypeName"": ""Attribute"",\n                            ""Attribute"": {}\n                        },\n                        ""LogicalId"": ""Locationafc85231""\n                    }\n                ],\n                ""AssetModelHierarchies"": [\n                    {\n                        ""Name"": ""CNC Machines"",\n                        ""ChildAssetModelId"": {\n                            ""Ref"": ""CNCMachineResource""\n                        },\n                        ""LogicalId"": ""CNCMachines""\n                    }\n                ]\n            }\n        }\n    }\n}\nJSON\nThis CloudFormation template can now be launched in another region or another AWS Account to create the same asset models we defined above.\nThat\xe2\x80\x99s it, now you have an understanding how the export utility works. In the next section we will provide an example architecture that shows how you can integrate the utilities into your CI/CD automation pipelines.\nExample CI/CD Architecture\nIn this example architecture we assume you have an existing CI/CD pipeline that can deploy AWS services using CloudFormation and the AWS SDKs.\nBuild\nFor the build stage of the architecture, the CI/CD pipeline initiates a Step Function workflow in the source environment which executes three Lambda functions, one for each resource type \xe2\x80\x93 asset models, assets, and dashboards. The Lambda functions can be run in parallel and use the export utilities to query the AWS IoT SiteWise service API to generate the corresponding CloudFormation templates for the resources you wish to replicate. The Lambda function will then store the generated files in an Amazon S3 bucket for use during the deploy stage of the pipeline. For the S3 bucket, you can either use a common shared bucket across all of your AWS environments or use S3 replication to automatically copy the files between separate buckets in each environment.\nDeploy\nIn the deploy stage, the AWS IoT SiteWise resources need to be created or modified in a specific order in the target environment, namely, asset models, assets, and dashboards. To do this, AWS StepFunction workflow states are defined for each resource type and the workflow is configured to execute them in the proper order. Each workflow state will use Lambda function tasks that reference the corresponding CloudFormation template in S3. The resources first need to be created by the CI/CD pipeline, therefore the initial workflow deployment tasks will create the CloudFormation stacks.\nOnce the stacks are created, subsequent updates from the CI/CD pipeline will use the workflow and step functions to update those stacks which will modify and update the AWS IoT SiteWise resources. The asset and dashboard states will wait for the previous state to finish deploying in CloudFormation before they start because they require those resources to exist before they can be created. Please see the architecture below for a visual representation.\nFor production workloads, customers can use CloudFormation change sets in their deployment pipeline and have a manual approval gate to verify the CloudFormation updates before they are made. Finally, if dashboards are part of your deployment pipeline, an AWS IoT SiteWise Monitor Portal must be created beforehand in the target environment.\n'"
11,Enabling device maintenance across multiple time zones using AWS IoT Jobs,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/03/06/Enabling-device-maintenance-across-multiple-time-zones-using-AWS-IoT-Jobs.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/enabling-device-maintenance-across-multiple-time-zones-using-aws-iot-jobs/,"b'Introduction\nA benefit of Internet of things (IoT) technology is the ability to connect your devices to the cloud and easily access them from around the world. While this benefit has unlocked many opportunities, it has also has created a major challenge of keeping devices updated. Managing and maintaining a fleet of IoT devices spread across multiple geographies and time zones is logistically difficult. To help solve this challenge, AWS IoT Jobs offers the ability to programmatically schedule over-the-air (OTA) updates for a global fleet of devices, across time zones, and schedule a time-window for these updates.\nWith the new recurring maintenance window schedule configuration feature, you can now schedule AWS IoT Jobs to only run in the exact time zone a device is deployed in, within a specific timeframe. For example, let\xe2\x80\x99s say you have devices in factories across the world that need to receive a weekly OTA update, but only when the factories are closed on Saturdays, from 9PM to 6AM. Using a combination of AWS IoT Jobs, dynamic thing groups, and AWS IoT Device Shadow, you can group devices together by the time zone they report they\xe2\x80\x99re in and implement a weekly OTA update to only be applied between 9PM and 6AM device local time on Saturdays.\nIn this blog post, we\xe2\x80\x99ll detail what steps to take to fully create and enable an OTA update scheduling solution using AWS IoT Jobs, dynamic thing groups, and Device Shadows.\nPrerequisites\nTo follow through this blog post, you will need:\nAn AWS account\nAccess to an AWS IoT Core supported region\nAccess to an AWS IoT Device Management supported region\nAccess to AWS CloudShell\nWalkthrough\nFor the demonstration in this post, you will schedule a weekly OTA update that can only run between 9PM and 6AM device local time. To do this, you will create two AWS IoT dynamic thing groups, one for Central Standard Time (CST) and one for Pacific Standard Time (PST), that will each be automatically populated with devices according to their time zone. A device\xe2\x80\x99s time zone will be reported by their corresponding AWS IoT Device Shadow. You will then create and configure two AWS IoT Jobs, one for each dynamic thing group. Each job will have a schedule configuration with the maintenance window set to reoccur weekly from 9PM to 6AM. The illustration below details what this solution will look like once fully implemented.\nStep 1: Create AWS IoT dynamic thing groups\nTo create your AWS IoT dynamic thing groups (AWS CloudShell, AWS CLI):\nEnable AWS IoT Device Management fleet indexing by issuing the update-indexing-configuration command\nFor this blog post, you will only need to enable thing indexing for the AWS IoT thing registry and classic shadows. You will use this thing index to create your AWS IoT dynamic thing groups with.\naws iot update-indexing-configuration --thing-indexing-configuration thingIndexingMode=REGISTRY_AND_SHADOW\nBash\nCreate the AWS IoT dynamic thing group for devices in the PST time zone by issuing the create-dynamic-thing-group command\naws iot create-dynamic-thing-group --thing-group-name ""pstdevices"" --query-string ""shadow.reported.timezone:PST""\nBash\nCreate the AWS IoT dynamic thing group for devices in the CST time zone by issuing the create-dynamic-thing-group command\naws iot create-dynamic-thing-group --thing-group-name ""cstdevices"" --query-string ""shadow.reported.timezone:CST""\nBash\nStep 2: Configure device time zones\nTo configure your device\xe2\x80\x99s time zones (AWS CloudShell, AWS CLI):\nCreate an AWS IoT thing for the device deployed in the PST time zone by issuing the create-thing command\naws iot create-thing --thing-name ""vibrationdevicepsttimezone""\nBash\nCreate an AWS IoT thing for the device deployed in the CST time zone by issuing the create-thing command\naws iot create-thing --thing-name ""vibrationdevicecsttimezone""\nBash\nCreate an AWS IoT Device Shadow for the device deployed in the PST time zone by issuing the update-thing-shadow command\naws iot-data update-thing-shadow --cli-binary-format raw-in-base64-out --thing-name vibrationdevicepsttimezone --payload \'{""state"":{""reported"":{""timezone"":""PST""}}}\' ""vibrationdevicepsttimezone.txt""\nBash\nCreate an AWS IoT Device Shadow for the device deployed in the CST time zone by issuing the update-thing-shadow command\naws iot-data update-thing-shadow --cli-binary-format raw-in-base64-out --thing-name vibrationdevicecsttimezone --payload \'{""state"":{""reported"":{""timezone"":""CST""}}}\' ""vibrationdevicecsttimezone.txt""\nBash\nVerify that the AWS IoT thing for the device deployed in the PST time zone was added to the pstdevices AWS IoT dynamic group by issuing the list-thing-groups-for-thing command\naws iot list-thing-groups-for-thing --thing-name vibrationdevicepsttimezone\nBash\nThe output from the command should look similar to the following:\n{\n    ""thingGroups"": [\n        {\n            ""groupName"": ""pstdevices"",\n            ""groupArn"": ""arn:aws:iot:us-east-1:<AWSACCOUNTID>:thinggroup/pstdevices""\n        }\n    ]\n}\nJSON\nVerify that the AWS IoT thing for the device deployed in the CST time zone was added to the cstdevices AWS IoT dynamic group by issuing the list-thing-groups-for-thing command\naws iot list-thing-groups-for-thing --thing-name vibrationdevicecsttimezone\nBash\nThe output from the command should look similar to the following:\n{\n    ""thingGroups"": [\n        {\n            ""groupName"": ""cstdevices"",\n            ""groupArn"": ""arn:aws:iot:us-east-1:<AWSACCOUNTID>:thinggroup/cstdevices""\n        }\n    ]\n}\nJSON\nStep 3: Create AWS IoT Jobs\nTo create your AWS IoT Jobs (console):\nOpen the AWS IoT console\nOn the left-hand navigation bar, under Manage, Remote Actions, choose Jobs\nChoose Create Job\nSelect Create custom job\nEnter a job name of pstdevicesiotjob\nFor Thing groups to run this job, choose pstdevices\nChoose the Job template you wish to use for this demonstration\nChoose Next\nFor Job run Type, select Continuous\nUnder Additional configurations, choose Scheduling configuration\nFor Job start, enter today\xe2\x80\x99s date and a time one hour ahead of your current time\nFor Recurring maintenance window, select Weekly\nFor On these weekdays, select Saturday\nFor Maintenance window starts from, enter a time of 21:00 (9:00PM in 24-hour format)\nFor Maintenance window duration, enter 9 hours and 0 minutes (ending job executions at 6:00AM)\nYour console should be similar to the following screenshot:\nChoose Submit\nRepeat steps 2 through 15 using the following:\nSet job name to cstdevicesiotjob\nSet Thing groups to run this job to cstdevices\nChoose the same Job template you used in step 7\nChoose Submit\nUnder Status, ensure both jobs are showing as Scheduled\nYour console should be similar to the following screenshot:\nThe status of each job will change to In progress after your configured Maintenance window starts from date and time passes. Each job will then start a job execution on every device within the targeted AWS IoT dynamic thing group at 9PM device local time on Saturday and end job executions at 6AM on Sunday. These job executions will occur on every current and newly added device until the Maintenance window duration time has passed. Once the Maintenance window duration time has passed, the status of each job will change back to Scheduled. This process will occur weekly until you cancel each job.\nCleaning Up\nBe sure to remove the resources created in this blog to avoid charges.\nFrom your AWS CloudShell environment issue the following commands:\naws iot delete-thing \xe2\x80\x94thing-name ""vibrationdevicepsttimezone""\nBash\naws iot delete-thing \xe2\x80\x94thing-name ""vibrationdevicecsttimezone""\nBash\naws iot delete-job --job-id ""pstdevicesiotjob""\nBash\naws iot delete-job --job-id ""cstdevicesiotjob""\nBash\naws iot delete-dynamic-thing-group --thing-group-name ""pstdevices""\nBash\naws iot delete-dynamic-thing-group --thing-group-name ""cstdevices""\nBash\naws iot update-indexing-configuration --thing-indexing-configuration thingIndexingMode=OFF\nBash\n'"
12,Convert Messages from IoT Devices to Voice Commands Using AWS IoT Core and Amazon Polly,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/02/23/Convert-Messages-from-IoT-Devices-to-Voice-Commands-Using-AWS-IoT-Core-and-Amazon-Polly.jpg-1024x576.png,https://aws.amazon.com/blogs/iot/convert-messages-from-iot-devices-to-voice-commands-using-aws-iot-core-and-amazon-polly/,"b'AWS IoT Core is a fully managed service that lets you connect billions of IoT devices and route trillions of messages to AWS services without managing infrastructure. One of the key features of AWS IoT Core is Rules Engine.\nWith Rules Engine, you can send data from your IoT devices to other services in AWS. This gives you the ability to take immediate actions on your IoT data, such as triggering alarms and notifications, collecting logs, or running analytics and machine learning models. In this post, we will show how you can take JSON messages coming in from your device and convert them to audio using the Amazon Polly text to speech machine learning model. Amazon Polly uses deep learning technologies to synthesize natural-sounding human speech, so you can convert articles to speech. With dozens of lifelike voices across a broad set of languages, you can use Amazon Polly to build speech-activated applications.\nScenario\nFor this example, we will be working with cleaning robots that are navigating through a supermarket to clean the floors. The robots send messages on an MQTT topic, robot/<clientID>/data, whenever the robots change states [running, waiting, stuck, charging]. The messages include the robot\xe2\x80\x99s current state as well as its location in the supermarket.\nHere is sample MQTT message coming in from a robot:\nTopic: robot/cleaning_robot_1/data\n{\n""state"": ""stuck"",\n""location"": ""aisle 6""\n}\nJSON\nIn our example, the supermarket intends to notify its employees through wireless headsets whenever a robot is stuck. They want the announcement to play an audio clip identifying which robot is stuck and where it is located at, so the staff can easily navigate to the robot and resolve the issue.\nHere is an example of the audio the employees will hear:\nsample-audio-message.mp3 (Clip playing: \xe2\x80\x9cCleaning robot 1 is stuck on aisle 6.\xe2\x80\x9d)\nDownload the file and play in your computer\nFigure 1 \xe2\x80\x93 Download Sample Audio\nSolution overview\nIn order to provide the supermarket with this solution, you will need to build the following:\nIoT device to represent the robot that publishes messages when the robot changes state.\nIoT device to represent the speaker that plays audio messages.\nIoT Rule that:\nListens to messages on the topic robot/+/data.\nConverts the JSON message to the desired String sentence when the robot is in a \xe2\x80\x9cstuck\xe2\x80\x9d state.\nPublishes a new message to topic speaker/message.\nFigure 2 \xe2\x80\x93 Solution Diagram\nPrerequisites\nFor this walk through, you should have the following prerequisites:\nAn AWS account. If you don\xe2\x80\x99t have an AWS Account, follow the instructions to create one.\nA user role with administrator access (service access associated with this role can be constrained further when the workflow goes to production).\nRecent modern browser (latest version of Firefox or Chrome)\nPython and Pip installed\nNo specialized knowledge is required to build this solution, but basic Linux and Python knowledge will help.\nWalkthrough\nStep 1: Clone the GitHub repository and download the AWS IoT Device SDK\nClone the GitHub repository for the sample applications that simulate the robot and speaker.\nIf you want to try this workflow on a real robot and speaker, copy the robot1 and speaker1 folders to their respective devices. Otherwise, you can leave both to simulate locally on your computer.\ngit clone https://github.com/aws-samples/iot-polly\nInstall the AWS IoT Device SDK for python.\nIf you are running the robot and speaker separately, you will need to run this command for all devices.\npython3 -m pip install AWSIoTPythonSDK\nBash\nStep 2: Set up permissions for the devices\nRobot\nFirst, set up the proper permissions for any robots. The robots need to be able to connect to AWS IoT and publish to the topic robot/<robotID>/data. This can be done with an IoT policy.\nNavigate to the AWS IoT Core console. In the navigation menu, under Security, choose Policies.\nChoose Create policy.\nFor Policy name enter policy_robot.\nFor Policy statements choose JSON and then paste in the following policy document:\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Connect"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:client/${iot:Connection.Thing.ThingName}""\n},\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Publish"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:topic/robot/${iot:Connection.Thing.ThingName}/data""\n}\n]\n}\nJSON\nInsert your <region> and <accountID> into the policy and then choose Create.\nFigure 3 \xe2\x80\x93 IoT Policy Robot\nSpeaker\nNext, set up the proper permissions for the speaker device. The speaker needs to be able to connect to AWS IoT and subscribe to the topic speaker/message. The speaker also needs permissions to access Amazon Polly for converting text to audio. To give an IoT device access to other AWS services, you will need to give the device permission to assume a role alias.\nChoose Create policy.\nFor Policy name enter policy_speaker.\nFor Policy statements choose JSON and then paste in the following policy:\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:AssumeRoleWithCertificate"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:rolealias/speaker-role-alias""\n},\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Connect"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:client/${iot:Connection.Thing.ThingName}""\n},\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Subscribe"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:topicfilter/speaker/message""\n},\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Receive"",\n""Resource"": ""arn:aws:iot:<region>:<accountID>:topic/speaker/message""\n}\n]\n}\nJSON\nInsert your <region> and <accountID> into the policy and then choose Create.\nFigure 4 \xe2\x80\x93 IoT Policy Speaker\nStep 3: Set up permissions for Amazon Polly actions\nTo give the speaker permissions to access Amazon Polly you will need to create an AWS Identity and Access Management(IAM) role and then create an IoT role alias to attach the IAM role to an IoT thing.\nNavigate to AWS IAM console. In the navigation menu choose Roles.\nChoose Create Role.\nSelect Custom trust policy.\nPaste the following JSON policy:\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Principal"": {\n""Service"": ""credentials.iot.amazonaws.com""\n},\n""Action"": ""sts:AssumeRole""\n}\n]\n}\nJSON\nChoose Next.\nUnder Permissions policies, search for polly and select the checkbox for AmazonPollyReadOnlyAccess.\nChoose Next.\nFor role name, enter speaker_role.\nChoose Create role.\nNavigate to the AWS IoT Core console. In the navigation menu, under Security, choose Role Aliases.\nSelect Create role alias.\nFor role alias name, enter speaker-role-alias.\nFor role, select speaker_role from the dropdown.\nLeave the credentials duration as 3600 seconds (1 hour) and choose Create.\nStep 4: Connect the devices to AWS IoT Core\nCreate IoT things in AWS IoT Core for your robot and speaker devices.\nNavigate to the AWS IoT Core console. In the navigation menu, under Manage, choose All devices, Things.\nChoose Create things.\nChoose Create single thing. Choose Next.\nFirst, create the robot. Give the robot a Thing name of cleaning_robot_1.\nLeave the rest as is, and choose Next.\nFigure 5 \xe2\x80\x93 Creating IoT Thing on AWS IoT Core\nChoose Auto-generate a new certificate (recommended). Choose Next.\nSelect the checkbox next to the policy_robot. Choose Create thing.\nFigure 6 \xe2\x80\x93 Attach Policy\nDownload all four files: Device certificate, Public Key file, Private key file, RSA 2048 bit key: Amazon Root CA 1.\nChoose Done.\nFigure 7 \xe2\x80\x93 Download Certificates\nMove the four files to the folder in the iot-polly repository titled robot1.\nRename the private key and certificate files as follows:\nxxxx-private.pem.key to robot1-private.pem.key\nxxxx-certificate.pem.crt to robot1.certificate.pem.crt\nRepeat the steps above for the speaker device with the following changes:\nName the IoT thing: speaker_1.\nSelect the IoT policy: policy_speaker.\nRename the private key and certificate files as follows:\nxxxx-private.pem.key to speaker1-private.pem.key\nxxxx-certificate.pem.crt to speaker1.certificate.pem.crt\nStep 5: Test the robot and speaker\nIn the AWS IoT Core console navigation menu, choose MQTT test client.\nFor Subscribe to a topic, enter robot/+/data.\nIn the navigation menu, choose Settings. Copy the Device data endpoint.\nEnter the following commands in your terminal. Navigate to the iot-polly repository.\ncd robot1\nBash\n# on a PC:\npy -m venv env\ncd env\\Scripts\\\nactivate\ncd ../..\nPowerShell\n# on a Mac/Ubuntu:\npython3 -m venv env\nsource env/bin/activate\nBash\nReplace <iot endpoint> with the device data endpoint you just copied.\npip install -r requirements.txt\naws iot describe-endpoint --endpoint-type iot:Data-ATS\npython3 robot.py --clientId cleaning_robot_1 --endpoint <iot endpoint> --key robot1-private.pem.key --cert robot1-certificate.pem.crt --rootCA AmazonRootCA1.pem\nBash\nNavigate back to the MQTT test client to see a message come through from robot/cleaning_robot_1/data:\n{\n""state"": ""stuck"",\n""location"": ""aisle 17"",\n""robotID"": ""cleaning robot 1""\n}\nJSON\nKeep robot1 running in the background as you will come back to it later.\nIn a new tab in your terminal, navigate to the iot-polly repository.\ncd speaker1\nBash\n# on a PC:\npy -m venv env\ncd env\\Scripts\\\nactivate\ncd ../..\nPowerShell\n# on a Mac/Ubuntu:\npython3 -m venv env\nsource env/bin/activate\nBash\n# on both:\npip install -r requirements.txt\nBash\nGet your IoT endpoint and credential provider url:\naws iot describe-endpoint --endpoint-type iot:Data-ATS\naws iot describe-endpoint --endpoint-type iot:CredentialProvider --region <region>\nBash\nEnsure the audio on your computer is on. Run the speaker device: (Make sure to replace your endpoint and credential provider with the outputs of the commands above).\npython3 speaker-device.py --thingname speaker_1 --region <region> --endpoint <iot endpoint> --key speaker1-private.pem.key --cert speaker1-certificate.pem.crt --rootCA AmazonRootCA1.pem --credentials_url https://<credential-provider-endpoint>/role-aliases/speaker-role/alias/credentials\nBash\nNavigate back to the MQTT test client.\nChoose the tab Publish to a Topic.\nTopic name: speaker/message\nMessage payload:\n{ ""message"": ""Hello from AWS IoT console"" }\nJSON\nChoose Publish\nspeaker1 uses the boto3 library in the speaker-device.py file to call the Amazon Polly API to convert the text received in the message to an MP3 audio file. It then automatically plays the audio using the playsound library.\nYou should hear the message \xe2\x80\x9cHello from AWS IoT console\xe2\x80\x9d and see the following message come through in your terminal window:\nReceived a new message:\nb\'{\\n ""message"": ""Hello from AWS IoT console""\\n}\'\nfrom topic:\nspeaker/message\nKeep speaker1 running as you will come back to it later.\nStep 6: Create the IoT rule\nIn the AWS IoT Core console, choose Message routing, Rules.\nChoose Create rule.\nFor rule properties, give your rule a name: robot_stuck and description. Choose Next.\nFigure 8 \xe2\x80\x93 Specify Rule Properties\nLeave the SQL_version as is, and then enter the follow as the SQL_statement:\nSELECT concat(robotID, \' is stuck on \', location) as message FROM \'robot/+/data\' WHERE state = ""stuck""\nFigure 9 \xe2\x80\x93 SQL Statement\nThis SQL statement receives any messages on the wildcard topic \xe2\x80\x98robot/+/data\xe2\x80\x98 where the state is \xe2\x80\x9cstuck\xe2\x80\x9d and then concatenates the data into a sentence format of \xe2\x80\x9c<robotID> is stuck on <location>\xe2\x80\x9d.\nChoose Next.\nFor Rule actions, choose Republish to AWS IoT topic, and then type the topic speaker/message.\nFigure 10 \xe2\x80\x93 Rule Actions\nChoose Create new role.\nName the role, Role_IoTVoice_rule.\nChoose Create.\nChoose Next.\nChose Create.\nYou should see a new rule successfully created.\nFigure 11 \xe2\x80\x93 New IoT Rule Created\nStep 7: Test the IoT rule\nEnsure robot1 and speaker1 are still running in your terminal and your audio is on.\nOpen the JSON file robot_payload.json (found in the robot1 folder) in your desired text editor.\nEdit the location in the JSON and save.\n{\n""state"": ""stuck"",\n""location"": ""aisle 12""\n}\nJSON\nYou will see that robot1 published a message:\nPublished topic robot/cleaning_robot_1/data: {""state"": ""stuck"", ""location"": ""aisle 12"", ""robotID"": ""cleaning robot 1""}\nThe topic is then automatically routed through your IoT rule and published back to speaker1.\nReceived a new message:\nb\'{""message"":""cleaning robot 1 is stuck on aisle 12""}\'\nfrom topic:\nspeaker/message\nspeaker1 converts the text received from your IoT Rule to an MP3 audio file and automatically plays the message. \xe2\x80\x9cCleaning robot 1 is stuck on aisle 12\xe2\x80\x9d.\nTry editing the robot_payload.json file again, but this time change the state to \xe2\x80\x9crunning\xe2\x80\x9d. Save the file.\n{\n""state"": ""running"",\n""location"": ""aisle 2""\n}\nJSON\nYou will see that robot1 receives the message, but the message is never forwarded to speaker1 because it is not stuck so the rule filters it out.\nCongratulations! You have successfully created an IoT rule that converts and routes messages to another device for conversion to audio with Amazon Polly.\nSummary\nIn this blog, you learned how you can use AWS IoT Core\xe2\x80\x99s Rule Engine and Amazon Polly to listen to IoT messages, but what you learned can be applied in a variety of solutions, for example:\nSmart Vehicle can notify drivers with voice message \xe2\x80\x9cCurrent range is 30 miles; next gas station is 5 miles way\xe2\x80\x9d.\nSmart Freezer: \xe2\x80\x9cTemperature inside the freezer is high. It went from 0oF to 5oF in 10 minutes\xe2\x80\x9d\nBlood Sugar Monitor: \xe2\x80\x9cYour blood sugar is too high, 210mg/DL\xe2\x80\x9d\nTo learn more about how to utilize the IoT Rules Engine, check out our course, Deep Dive into AWS IoT Rules Engine. Let us know how you are acting on your IoT data to improve your business operations.\nAdilson Perinei\nAdilson Perinei is an AWS Consultant, member of AWS IoT Technical Field Community. Adilson holds 7 AWS certifications, including Solution Architect Professional, DevOps Engineer Professional and Security Specialty.\nErica Goldberger\nErica Goldberger is a Solutions Architect specializing in Robotics at Amazon Web Services (AWS). Prior to being a Solutions Architect, Erica was a Technical Curriculum Developer building training courses for AWS on topics such as containers and IoT. Erica has a Master\xe2\x80\x99s in Robotics from the University of Pennsylvania.'"
13,Route messages across multiple accounts with AWS IoT Core and Amazon SQS,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/route-messages-across-multiple-accounts-with-aws-iot-core-and-amazon-sqs/,"b'Introduction\nIn this blog, we explain how to route AWS IoT Core messages from one or more ingestion accounts to Amazon Simple Queue Service (Amazon SQS) in a data account. It is a common pattern to have IoT telemetry ingested into one account and then require it to be shipped to another account for further processing. For example, when an organization hosts devices in multiple accounts and the data being ingested is classified as both sensitive and operational. Sensitive data needs to be kept in the original collection account but operational data needs to be relayed to another account monitored by an operations team.\nYou will learn how to configure AWS IoT rules for cross-account access to route MQTT topic data sets into Amazon SQS. Rules for AWS IoT give your devices the ability to interact with AWS services. You can use rules to support tasks such as augmenting or filtering data from a device, writing data to database, publishing messages to Amazon SQS and more.  For a complete list of tasks you can perform, please refer to the Rules for AWS IoT section of the AWS IoT Core Developer Guide.\nSolution Overview\nIn this solution, you will first create an Amazon SQS queue in the data account and grant permissions to the ingestion account to publish to it . Next, you will create AWS IoT rules and send messages to them to test.\nCreate an Amazon SQS queue called iot-data in the data account and allow publishing to this queue from the ingestion account.\nIn the ingestion account:\na. Create an Identity and Access Management (IAM) role with a policy that allows publishing to Amazon SQS in the data account.\nb. Create an IAM role with a policy that allows a republish action for errors encountered when publishing to the SQS queue.\nCreate an IoT rule in the ingestion account to evaluate messages from a topic called data/private and send them to the data account SQS queue. The rule will have an error action that republishes messages to the error/rules topic for troubleshooting.\nPublish messages to the MQTT topic data/private and verify the messages are visible in the data account SQS queue.\nSolution Diagram\nSolution Instructions\nPrerequisites\nTwo AWS accounts\nAdministrator privileges in both accounts\nAWS Command Line Interface (AWS CLI)\nCreate an SQS queue in the data account\nCreate a file named queue_attributes.json with the following content.\n{ ""MessageRetentionPeriod"": ""259200"" }\nJSON\nWith the AWS CLI configured for the data account and using the create-queue.json file, create an SQS queue called iot-data.\naws sqs create-queue \\\n     --queue-name iot-data \\   \n     --attributes file://queue_attributes.json\nBash\nRecord the QueueURL from the output as that will be needed in the next section.\nTo grant permissions for the Amazon SQS queue resource to be accessed by the ingestion account, run the add-permission command. Be sure to update the account numbers accordingly.\naws sqs add-permission \\\n     --queue-url https://sqs.<data account region>.amazonaws.com/<data account ID>/iot-data \\\n     --label IoTSendMessage \\\n     --aws-account-ids <ingestion account ID> \\\n     --actions SendMessage\nBash\nCreate the AWS Identity and Access Management (IAM) role and policy for cross-account publishing to SQS\nIn order to publish to the SQS queue from the data account, you first need to allow that action.\nCreate a file named iot_policy.json with the following content:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Principal"": {\n                ""Service"": ""iot.amazonaws.com""\n            },\n            ""Action"": ""sts:AssumeRole""\n        }\n    ]\n}\nJSON\nWith the AWS CLI configured for the ingestion account, run the following command to create a role called iot-cross-sqs-allow and attach the trust policy to allow it to interact with IoT.\naws iam create-role \\ \n     --role-name iot-cross-sqs-allow \\ \n     --assume-role-policy-document file://iot_policy.json\nBash\nReview the output and ensure it is correct:\n{\n    ""Role"": {\n        ""Path"": ""/"",\n        ""RoleName"": ""iot-cross-sqs-allow"",\n        ""RoleId"": ""XXXXXXXXXXXXXXXXXXXXX"",\n        ""Arn"": ""arn:aws:iam::XXXXXXXXXXXX:role/iot-cross-sqs-allow"",\n        ""CreateDate"": ""2022-09-07T05:05:58+00:00"",\n        ""AssumeRolePolicyDocument"": {\n            ""Version"": ""2012-10-17"",\n            ""Statement"": [\n                {\n                    ""Effect"": ""Allow"",\n                    ""Principal"": {\n                        ""Service"": ""iot.amazonaws.com""\n                    },\n                    ""Action"": ""sts:AssumeRole""\n                }\n            ]\n        }\n    }\n}\nJSON\nCreate a file called allow_send_cross_sqs.json with the following content. For the resource ARN, be sure to update with the region and account ID of the data account.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": ""sqs:SendMessage"",\n            ""Resource"": ""arn:aws:sqs:<data account region>:<data account ID>:iot-data""\n        }\n    ]\n}\nJSON\nAdd this custom inline policy to the role you created in the previous step by using the following command:\naws iam put-role-policy \\\n     --role-name iot-cross-sqs-allow \\\n     --policy-name new-iot-cross-sqs-policy \\\n     --policy-document file://allow_send_cross_sqs.json\nBash\nCreate the AWS IAM role and policy to allow republishing of errors\nWhen republishing messages with an AWS IoT rule, permissions need to be properly set to allow this action.\nWith the AWS CLI configured for the ingestion account and using the same file created earlier, create a new role called iot-republish:\naws iam create-role \\\n     --role-name iot-republish \\\n     --assume-role-policy-document file://iot_policy.json\nBash\nReview the output and ensure it is correct:\n{\n    ""Role"": {\n        ""Path"": ""/"",\n        ""RoleName"": ""iot-republish"",\n        ""RoleId"": ""XXXXXXXXXXXXXXXXXXXXX"",\n        ""Arn"": ""arn:aws:iam::XXXXXXXXXXXX:role/iot-republish"",\n        ""CreateDate"": ""2022-09-07T05:24:36+00:00"",\n        ""AssumeRolePolicyDocument"": {\n            ""Version"": ""2012-10-17"",\n            ""Statement"": [\n                {\n                    ""Effect"": ""Allow"",\n                    ""Principal"": {\n                        ""Service"": ""iot.amazonaws.com""\n                    },\n                    ""Action"": ""sts:AssumeRole""\n                }\n            ]\n        }\n    }\n}\nJSON\nNext create a file called allow_republish.json with the following content. Please note that this policy restricts publishing to topic names starting with errors. Be sure to update with the region and account ID of the ingestion account.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Action"": ""iot:Publish"",\n        ""Resource"": ""arn:aws:iot:<ingestion account region>:<ingestion account ID>:errors/*""\n    }\n}\nJSON\nAdd the policy just created as an inline policy to the iot-republish role:\naws iam put-role-policy \\\n     --role-name iot-republish \\\n     --policy-name iot-republish \\\n     --policy-document file://allow_republish.json\nBash\nCreate an IoT rule in the ingestion account to evaluate messages and republish errors\nNext, we will create the IoT rule that will route messages to the SQS queue in the and also republish any messages that encounter an error to a topic named error/rules.\nCreate a file named ingestion_rule.json with the following content. Be sure to update the queueURL and roleArn values with those received in previous steps.\n{\n""sql"": ""SELECT * FROM \'data/private\'"" ,\n""description"": ""Cross-account publishing of messages to SQS."",\n""ruleDisabled"": false,\n""awsIotSqlVersion"": ""2016-03-23"",\n""actions"": [{\n    ""sqs"": {\n        ""roleArn"": ""<iot-cross-sqs-allow role ARN>"",\n        ""queueUrl"": ""https://sqs.<data account region>.amazonaws.com/<data account ID>/iot-data"",\n        ""useBase64"": true\n    }\n}], \n""errorAction"": {\n    ""republish"": {\n      ""roleArn"": ""<iot-republish role ARN>"",\n      ""topic"": ""error/rules"",\n      ""qos"": 0\n    }\n  }\n}\nJSON\nWith the AWS CLI configured for the ingestion account, create an IoT rule for the publishing of message to SQS in the data account:\naws iot create-topic-rule \\\n     --rule-name ""cross_account_sqs_publish"" \\\n     --topic-rule-payload file://ingestion_rule.json\nBash\nPublish messages and verify they are visible in the data account SQS queue\nTo test the solution, you can publish a message to AWS IoT Core and see if it arrives successfully in the data account SQS queue.\nFrom the ingestion account, use the AWS IoT MQTT client to subscribe to the data/private and error/rules topics.\nContinuing with the AWS MQTT IoT client, publish a message to the data/private topic with a sample payload:\n{\n    ""message"": ""Hello, world"",\n    ""clientType"": ""MQTT client""\n}\nJSON\nRetrieve messages from the SQS queue and review the output by configuring the AWS CLI for the data account and running the following command.\naws sqs receive-message \\\n    --queue-url https://sqs.<data account region>.amazonaws.com/<data account ID>/iot-data\nBash\nThe Body parameter of the output may be Base64 encoded. If so, you will need to decode it to see the contents of the published message\nIf messages are not being received in the SQS queue, check the error/rules topic subscription for error messages related to delivery from the AWS MQTT IoT client in the ingestion account.\nCleaning Up\nIt is good practice to clean up any resources you no longer want to use. Cleaning up AWS resources prevents your account from incurring any further charges.\nDelete the SQS queue:\naws sqs delete queue \\\n   --queue-url https://sqs.<data account region>.amazonaws.com/<data account ID>/iot-data\nBash\nDelete the iot-cross-sqs-all IAM role:\naws iam delete-role-policy \\\n     --role-name iot-cross-sqs-all \\\n     --policy-name iot-cross-sqs-all\n\naws iam delete-role --role-name iot-cross-sqs-all\nBash\nDelete the iot-republish role:\naws iam delete-role-policy \\\n     --role-name iot-republish \\\n     --policy-name iot-republish\n\naws iam delete-role --role-name iot-republish\nBash\nDelete the cross_account_sqs_publish topic rule:\naws iot delete-topic-rule \\\n     --rule-name cross_account_sqs_publish\nBash\n'"
14,Identify misconfigured IoT policies using AWS IoT Device Defender,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/02/10/BLOGTEMPLATE1.jpg,https://aws.amazon.com/blogs/iot/identify-misconfigured-iot-policies-using-aws-iot-device-defender/,"b'Introduction\nWe are excited to announce a new AWS IoT Device Defender audit feature to identify potential misconfigurations when using wild cards in Internet of Things (IoT) policies. AWS IoT Device Defender is a fully managed IoT security service that enables you to audit and monitor your IoT device fleet and secure your IoT configurations on an ongoing basis. Security misconfigurations, such as overly permissive policies that permit a device access to unintended resources, can be a major cause of security incidents and compromise the security posture of your solution. With the new AWS IoT Device Defender IoT policy potentially misconfigured audit feature, you can more easily identify flaws, troubleshoot issues, and take necessary corrective actions. This can help you improve the security posture of your IoT solutions.\nBackground\nAWS IoT Core policies are JSON documents. They follow the same conventions as AWS Identity and Access Management (IAM) policies. With AWS IoT Core policies, you can control access to the AWS IoT Core data plane. The AWS IoT Core data plane consists of operations that enable you to connect to the AWS IoT Core message broker and send and receive MQTT messages. Similarly, data plane operations can also help you get or update the state of your device through AWS IoT Device Shadow, a feature of AWS IoT Core that makes a device\xe2\x80\x99s state available to apps and other services, whether the device is connected to AWS IoT or not.\nIn some cases, customers might misconfigure IoT policies because of confusion between IoT policy wildcards and MQTT wildcards. If a customer configures IoT policies in a certain way, it is possible to over-subscribe devices to receive data on topics when the devices should have been explicitly denied subscription.\nIn this blog, we discuss two types misconfigurations and how you can use AWS IoT Device Defender audit to identify and fix these potential misconfigurations in IoT policies.\nUsing wildcard characters in MQTT and AWS IoT Core policies\nMQTT and AWS IoT Core policies have different wildcard characters and you should choose them after careful consideration. In MQTT, the wildcard characters \xe2\x80\x98+\xe2\x80\x99 and \xe2\x80\x98#\xe2\x80\x99 are used in MQTT topic filters to subscribe to multiple topic names. Character \xe2\x80\x98+\xe2\x80\x99 for single MQTT topic level, and \xe2\x80\x98#\xe2\x80\x99 for multiple MQTT topic levels. AWS IoT Core policies use \xe2\x80\x98*\xe2\x80\x99 and \xe2\x80\x98?\xe2\x80\x99 as wildcard characters and follow the conventions of IAM policies. In a policy document, the \xe2\x80\x98*\xe2\x80\x99 represents any combination of characters and a question mark \xe2\x80\x98?\xe2\x80\x99 represents any single character. In policy documents, the MQTT wildcard characters, \xe2\x80\x98+\xe2\x80\x99 and \xe2\x80\x98#\xe2\x80\x99 are treated as those characters having no special meaning. To describe multiple topic names and topic filters in the resource attribute of a policy, use the \xe2\x80\x98*\xe2\x80\x99 and \xe2\x80\x98?\xe2\x80\x99 wildcard characters in place of the MQTT wildcard characters.\nWhen choosing wildcard characters to use in a policy document, consider that the \xe2\x80\x98*\xe2\x80\x99 character is not confined to a single topic level as the \xe2\x80\x98+\xe2\x80\x99 character is in an MQTT topic filter. To help constrain a wildcard specification to a single MQTT topic filter level, consider using multiple \xe2\x80\x98?\xe2\x80\x99 characters. Refer to the documentation for examples of wildcard characters used in MQTT and AWS IoT Core policies for MQTT clients.\nThere are 2 types of misconfigurations:\nType 1: When customers want a device to receive messages for a whole topic space \xe2\x80\x98building/*\xe2\x80\x99 but not for specific sub-topics related to \xe2\x80\x98building/control_room/*\xe2\x80\x99.\nIn this example, topic filters are intended to deny access, but the use of wildcard results in allowing access. In a policy that contains topic filter with wildcards in allow statements, and a deny statement that has a subset of allow resources, the deny topic messages can potentially be accessed by subscribing to wildcards.\n{\nEffect:  Allow\nAction: Subscribe\nResource: /topicfilter/building/*\nEffect: Deny\nAction: Subscribe\nResource: /topicfilter/building/control_room/#\nEffect: Allow\nAction: Receive\nResource: /topics/building/ *\n}\nHowever, when a device subscribes to \xe2\x80\x98building/#\xe2\x80\x99, it gets messages from \xe2\x80\x98building/control_room/3\xe2\x80\x99.\nThis is because topic \xe2\x80\x98building/#\xe2\x80\x99matches allow \xe2\x80\x98building/*\xe2\x80\x99, authorizing the subscription operation for the device. Note that lower in the application code, \xe2\x80\x98building/#\xe2\x80\x99 matches all data, and since a device is already subscribed it will receive all the matching topic data.\nWhen you specify topic filters in AWS IoT Core policies for MQTT clients, MQTT wildcard characters \xe2\x80\x98+\xe2\x80\x99 and \xe2\x80\x98#\xe2\x80\x99 are treated as literal strings. Their use might result in unintended behavior.\nHow to fix it:\n{\nEffect:  Allow\nAction: Subscribe\nResource: /topicfilter/building/*\nEffect: Deny\nAction: Subscribe\nResource: /topicfilter/building/control_room/*\nEffect: Deny\nAction: Receive\nNot-resource: /topic/building/control_room/*\n}\nOnce you do that, the device will receive messages published on any topic under topic/ (for example \xe2\x80\x98building/common_area\xe2\x80\x99) however, the device will not receive any messages published on any topic under \xe2\x80\x98building/control_room/\xe2\x80\x99 (for example \xe2\x80\x98building/control_room/3\xe2\x80\x99)\nThere could be legitimate use cases where the author may have done it this way, for example, to permit maintenance crew to access a particular space (for example \xe2\x80\x98/building/control_room/3\xe2\x80\x99). Thus, in our AWS IoT Device Defender audit check, we named this a potential misconfiguration and we leave it up to the user to decide, whether this was intentional or an unintended misconfiguration.\nType 2: When customers want a device to receive messages for a whole topic space \xe2\x80\x98building/camera/*\xe2\x80\x99 but not for specific sub-topics that involve control_room as in \xe2\x80\x98building/+/control_room\xe2\x80\x99. MQTT wildcards in Deny statements could potentially be circumvented by devices when replacing wildcards with specific strings.\n{\nEffect: Deny\nAction: Subscribe\nResource: /topicfilter/building/+/control_room\nEffect: Allow\nAction: Subscribe\nResource: /topicfilter/building/camera/*\n}\nThe desired behavior is to deny device access to \xe2\x80\x98building/camera/control_room\xe2\x80\x99, but allow access to \xe2\x80\x98building/camera/resident1\xe2\x80\x99.\nHowever, devices can send request to topic \xe2\x80\x98/building/+/control_room\xe2\x80\x99 and end up receiving messages from topic \xe2\x80\x98/building/camera/control_room\xe2\x80\x99.\nHow to fix it:\n{\nEffect: Deny\nAction: Subscribe\nResource: /topicfilter/building/*/control_room\nEffect: Allow\nAction: Subscribe\nResource:  /topicfilter/building/camera/*\nEffect: Allow\nAction: Receive\nResource: /topic/building/camera/*\nEffect: Deny\nAction: Receive\nResource: /topic/building/*/control_room\n}\nWith this fix, IoT policy will allow the device to receive messages from:\n/building/camera/resident1\n/building/camera/resident2\n/building/camera/resident3\nBut not from\n/building/camera1/control_room\n/building/camera2/control_room\n/building/any_camera/control_room\nIdentify potential misconfigurations using AWS IoT Device Defender audit check\nIn this section, we\xe2\x80\x99ll show how to configure, run, and take corrective actions in the AWS IoT Console for the two types of misconfigurations described earlier.\nIn this example we\xe2\x80\x99ve entered Type 1 and Type 2 in AWS IoT as follows:\nFigure 1: Type 1 policy named as \xe2\x80\x98MisconfiguredPolicy\xe2\x80\x99 configured in AWS IoT\nFigure 2: Type 2 policy named as \xe2\x80\x98MisconfiguredPolicyInfo_2\xe2\x80\x99 configured in AWS IoT\nThen, once we run the new \xe2\x80\x98IoT policy potentially misconfigured\xe2\x80\x99 audit check, the following reason code is returned when this check finds a potentially misconfigured AWS IoT policy:\na) POLICY_CONTAINS_MQTT_WILDCARDS_IN_DENY_STATEMENT\nb) TOPIC_FILTERS_INTENDED_TO_DENY_ALLOWED_USING_WILDCARDS\nFigure 3: Results from AWS IoT Device Defender \xe2\x80\x98IoT policy potentially misconfigured\xe2\x80\x99 audit check\nThe AWS IoT Device Defender \xe2\x80\x98IoT policy potentially misconfigured\xe2\x80\x99 check inspects for MQTT wildcard characters (\xe2\x80\x98+\xe2\x80\x99 or \xe2\x80\x98#\xe2\x80\x99) in deny statements. Wildcards are treated as literal strings in a policy document and can make it overly permissive.\nHow to fix it\nThis audit check flags potentially misconfigured policies as there might be false positives. Mark any false positives using Audit finding suppressions so they don\xe2\x80\x99t get flagged in the future.\nYou can also follow these steps to fix any noncompliant policies attached to things, thing groups, or other entities:\nUse CreatePolicyVersion to create a new, compliant version of the policy. Set the setAsDefault flag to true. (This makes this new version operative for all entities that use the policy.)\nVerify that all associated devices are able to connect to AWS IoT Core. If a device is unable to connect, use SetPolicyVersion to roll back the default policy to the previous version, revise the policy, and try again.\n'"
15,Schedule remote operations using AWS IoT Device Management Jobs,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/schedule-remote-operations-using-aws-iot-device-management-jobs/,"b'Introduction\nOnce Internet of Things (IoT) devices are deployed in the field, on-site intervention can be challenging, expensive, and may not be feasible due to technical and logistical constraints. The ability to perform remote updates on your IoT device software is an important factor that improves your IoT application\xe2\x80\x99s lifespan and operational resilience, provisions the latest functionality, addresses bug fixes, and reduces security risks. AWS IoT Device Management is a fully managed service that helps you register, organize, monitor, and remotely manage IoT devices at scale. Developers are using AWS IoT Device Management Jobs to perform remote actions (e.g., firmware updates, device reboots, factory resets, etc.) on devices that are connected to AWS IoT Core.\nA \xe2\x80\x9cjob\xe2\x80\x9d is a set of operations defined in the cloud and sent to and ran on one or more devices, while a job execution is an instance of such a remote action on a targeted device. For example, developers can define a single job that performs an \xe2\x80\x9cOver-The-Air\xe2\x80\x9d (OTA) update on 1000 devices, which then executes 1000 job executions to update each individual device. In many situations, developers need a mechanism to control the time window during which jobs are active and running, such as a start and end time configurable parameter, as well as the ability to cancel job executions upon reaching an end time, to stop rolling out remaining executions which were not started. Examples of use cases where this is needed are:\nIoT devices are performing sensitive operations in a factory, such as controlling industrial equipment, and must be updated on schedules,\nIoT devices provide consumer services, such as internet connectivity in homes, and should only be upgraded during periods of idleness,\nIoT devices operate under strict availability Service Level Agreements (SLAs), where remote operations must be performed only during defined time windows to reduce operational disruptions.\nThis blog post provides guidance for developers looking to schedule rollouts of jobs, using AWS IoT Device Management Jobs scheduling feature.\nMetadata\nLearning level: 300\nServices used: AWS IoT Device Management, AWS IoT Core, AWS IoT Device Client.\nPrerequisites\nTo be able to run through the steps in this blog, you will need:\nAn AWS account and permissions to provision IoT things, and use AWS IoT Device Management features.\nTo run the steps in this blog, access to AWS IoT Device Client with its Jobs feature, as the open source software running on a simulated IoT device, is needed. In production, you can continue using your existing on device set-up.\nAn application to interact with your operating system command line interface (e.g.: Terminal on Mac OS, or Powershell on Windows).\nAWS Command Line Interface (CLI) installed. Refer to AWS CLI Documentation for instructions on how to install and configure AWS CLI.\nAn AWS Identity and Access Management (IAM) user with the credentials for creating AWS resources through CLI.\nSchedule AWS IoT Job rollouts \xe2\x80\x93 walkthrough\nStep 1: Create an IoT thing and configure the AWS IoT Device Client\nTo get started with creating the IoT thing and setting up AWS IoT Device Client, you can follow part 1, 2 and 3 from the Getting started workshop. Name your IoT thing demoDevice . After performing these steps, you should have AWS IoT Device Client with the Jobs feature enabled and running, and your IoT thing created with the correct policy in place.\nStep 2: Create the AWS IoT Job from an AWS managed template\nWe will be creating a job to reboot the device at a provided start time, using the AWS managed template AWS-Reboot.\nIn the scheduling configuration of the job, you can specify the start time, end time, as well as the end behavior for all job executions after a job reaches the selected end time. As an end behavior, you can specify what should happen to the remaining job executions, including retry attempts and queued jobs, when the end time is reached. The requirements for the start time, end time, and end behavior can be found here.\nNote that the start time and end time must be passed into the CLI command as Coordinated Universal Time (UTC) strings. Additionally, you need to make sure that the start time is scheduled a minimum of thirty minutes from the current time.\nTo create the job, you can use the AWS CLI, and run the following commands:\n1. Create the required environment variables:\nexport ACCOUNT_ID=<Replace with your account ID>\nexport THING_NAME=<Replace with your thing name>\nexport REGION =<Replace with your region>\nexport JOB_ID =<Replace with your job ID>\nexport START_TIME =<Replace with your desired start time>\nBash\n2. Run the command below to create an IoT job:\n aws iot create-job \\\n --targets arn:aws:iot:${REGION}:${ACCOUNT_ID}:thing/${THING_NAME} \\\n --job-id ${JOB_ID} \\\n --job-template-arn arn:aws:iot:${REGION}::jobtemplate/AWS-Reboot:1.0 \\\n --document-parameters pathToHandler=/etc/.aws-iot-device-client/jobs \\\n --scheduling-config startTime=${START_TIME}\nBash\n3. Verify the AWS CLI output. It should look like below:\n{ ""jobArn"": ""arn:aws:iot:${REGION}:${ACCOUNT_ID}:job/reboot-scheduled-job"", ""jobId"": ""${JOB_ID}"", ""description"": ""A managed job template for rebooting the device."" }\nJSON\nStep 3: Verify scheduled job creation in AWS IoT Console\nTo verify the scheduled job creation, do the following:\n1. In the AWS IoT Console, in the left menu, choose Manage-> Remote actions-> Jobs, and ensure that your job that has been created.\n2. You should check that the \xe2\x80\x9cJob status\xe2\x80\x9d is Scheduled, and that the estimated start time is correct. The time zone displayed in the AWS Management Console is your current system time zone.\n3. Once the start time is reached, you should see that the job changes to IN PROGRESS.\nStep 4: Check the AWS IoT Device Client logs for job execution feedback\nOnce the start time is reached, the next step is to tail the logs of the AWS IoT Device Client, for successful job execution. The standard location of the log is in /var/log/aws-iot-device-client/aws-iot-device-client.log. If you modified the log location configuration, please use your location.\nFor a successful job execution, the log should look similar to the one below.\nStep 5: Cleaning Up\nTo avoid further costs, you should clean up the used resources:\n1. Follow the clean up steps from the Getting started workshop, to remove only the resources you created in Step 1.\n2. You should delete the created IoT job. You can use the following AWS CLI command to delete the job:\naws iot delete-job \xe2\x80\x94job-id ${JOB_ID}\nBash\n'"
16,Identifying IoT device certificates with a revoked intermediate CA using AWS IoT Device Defender,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/01/26/figure2.png,https://aws.amazon.com/blogs/iot/identifying-iot-device-certificates-with-a-revoked-intermediate-ca-using-aws-iot-device-defender/,"b'Introduction\nDynamically verifiable device identity is a foundational component of a Zero Trust Architecture (ZTA). Ongoing dynamic evaluation of identity and trust requires complete and timely visibility into relevant components of that identity. Active device certificates issued by a revoked intermediate Certificate Authority (CA) can pose a security threat due to the intermediate CA being potentially compromised. Previously, there had been no ready-made solution to identify active device certificates that were issued by a revoked intermediate CA.\nBackground\nFigure 1. Hierarchical public key infrastructure (PKI) chain including root CA, intermediate CA, and IoT device certificates issued by an intermediate CA.\nAWS IoT Core customers can use X.509 certificates to authenticate client and device connections. These certificates can be generated by AWS IoT, or signed by a CA, irrespective of whether the CA is registered with AWS IoT.\nIn most practical applications, intermediate CAs issue device certificates as this approach provides an additional layer of security and helps manage security incidents gracefully. For example, in case of a suspected security incident with a device or group of devices, only the intermediate CA can be revoked instead of revoking the root certificate. When the intermediate CA is revoked, all device certificates that are in the same chain as the revoked intermediate CA are revoked automatically. This approach limits the cost and impact of the security incident.\nPreviously, AWS IoT Core customers who brought their own device certificates backed by an external multi-level Public Key Infrastructure (PKI) hierarchy had no ready-made solution to identify active AWS IoT Core certificates issued by a revoked intermediate CA. These customers needed to build custom solutions to gain required visibility, or they risked being exposed to potential threats stemming from unmonitored usage of possibly compromised device credentials.\nSolution\nCustomers using their own device certificates needed an automated mechanism to identify certificates with a revoked intermediary CA. With the new CA chain audit check, AWS IoT Device Defender addresses this gap. AWS IoT Device Defender, a fully managed service for auditing and monitoring devices connected to AWS IoT, supports checking for active certificates issued by a revoked intermediate CA. When a potentially compromised intermediate CA is revoked, all active certificates issued by that intermediate CA are identified as non-compliant, failing the associated audit check.\nThe new check makes it easier for customers to identify affected certificates using relevant X.509 certificate extension declarations and standard certificate revocation methods, such as Certificate Revocation Lists (CRLs) and Online Certificate Status Protocol (OCSP). You can use the new audit check as part of a broader integrated AWS IoT Device Defender and AWS Security Hub architecture to continuously audit, monitor, and remediate your Internet of Things (IoT) devices in accordance with the core principles of ZTA.\nHow to identify active device certificates with a revoked intermediate CA\nThe new audit check leverages standard revocation check methods whilst being able to traverse public key infrastructure (PKI) hierarchies. It relies on the information provided via relevant X.509 certificate extensions to discover the PKI CA hierarchy and perform the associated certificate revocation checks.\nIn our sample scenario shown in Figure 2, this audit check occurs as the following sequence:\nRoot CA or intermediate CA revokes the target intermediate CA certificate, where the intermediate CA is the issuer of a certificate actively used by an IoT device interacting with AWS IoT Core.\nCustomer initiates an AWS IoT Device Defender audit, which includes the revoked intermediate CA audit check.\nAWS IoT Device Defender performs the revocation check using the available revocation check method, in accordance with the hierarchy of the associated PKI.\nIf a revoked intermediate CA is identified, the audit generates a non-compliant \xe2\x80\x9cIntermediate CA revoked for active device certificates\xe2\x80\x9d finding.\nFigure 2. AWS IoT Device Defender revoked intermediate CA audit check flow.\nTo use this feature, you can access the Device Defender audit section within your AWS Console and enable the new audit check. If you have not enabled Device Defender audit, you can do it with one-click using Automate IoT security audit on Device Defender to help secure your IoT devices.\nFigure 3. AWS IoT Device Defender audit section.\nThe check handles device certificates that have an issuer endpoint declared in the relevant X.509 extension, and reports active certificates issued by a revoked intermediate CA. You can disable the compromised device certificate using a pre-built mitigation action or initiate a custom mitigation through an AWS Lambda function. More documentation on AWS IoT Device Defender intermediate CA audit check can be found here.\nCustomer device certificates used with AWS IoT Core need to include the necessary Authority Information Access (AIA) details required to perform the underlying CA revocation checks:\nFigure 4. X.509 certificate extension declarations showing certificate Authority Information Access (AIA) and CRL endpoint details.\nSubsequently, the Intermediate CA revoked for active device certificates audit check can be used to identify any active device certificates issued by the revoked intermediate CA.\nFigure 5. Selecting the Intermediate CA revoked for active device certificates audit check as part of new audit creation process.\nThe check can leverage the AIA details and published certificate revocation information, whilst traversing the associated PKI hierarchy to determine the intermediate CA revocation status. In this test example, we can see that an intermediate CA used to issue device certificates was revoked by the root CA:\n.\nFigure 6. Example Certificate Revocation List (CRL) entry showing a revoked certificate corresponding to the intermediate CA.\nUpon revocation, a previously compliant audit check would fail, because AWS IoT Device Defender identifies a revoked intermediate CA.\nFigure 7. AWS IoT Device Defender Audit Result showing non-compliant audit finding.\nThe associated finding provides additional information about the impacted device certificates, as well as the affected issuer identifier registered with AWS IoT Core.\nFigure 8. Additional information provided as part of the associated Intermediate CA revoked for active device certificates audit finding.\nYou can now identify client or device certificates that have their issuing CA revoked in a CA chain via a scheduled audit automatically, or initiate an ad-hoc AWS IoT Device Defender audit report manually as needed.\nIf non-compliant certificates are identified, you can initiate a pre-built mitigation action, such as disabling the affected device certificate or initiate a custom mitigation action through a Lambda function.\n'"
17,Tracking Assets using AWS IoT Core and Amazon Location Service,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/tracking-assets-using-aws-iot-core-and-amazon-location-service/,"b'In this post, we explore the recently launched \xe2\x80\x9clocation action\xe2\x80\x9d feature that connects AWS IoT Core with Amazon Location Service trackers, creating a scalable, simple, and cost effective way to track and store IoT device location updates.\nTracking resources and real-world assets is a critical part of any logistics and operations workflow. Companies need a simple and economical way to view their assets on a single pane of glass, allowing operators to track and monitor their assets in real time, then take the necessary action when they observe issues or anomalies. The ability to track assets with location data can help organizations improve operational uptime, reduce bottlenecks, and improve productivity, reducing operational expenses typically incurred during the maintenance and management of Internet of Things (IoT) devices.\nIoT sensors and devices provide a viable option to deliver deeper visibility and predictability required for tracking assets. With IoT sensors and devices, you can continuously record and monitor the movement of assets through a centralized management system. An IoT-enabled device such as a smart bicycle, a delivery truck, a shipping container, or a connected vehicle can publish and subscribe to AWS IoT Core, a fully managed service that lets you connect billions of IoT devices and route trillions of message topics to Amazon Web Services (AWS). These message topics can then interface with a host of AWS services, ranging from storage to messaging to location services, using the Rules Engine.\nRules Engine enables you to send data from IoT devices to 20+ downstream services using Actions including Amazon Simple Storage Service (Amazon S3), Amazon Simple Notification Services (Amazon SNS), Amazon Kinesis, and AWS Lambda.\nFig.1 Tracking Assets using AWS IoT Core and Amazon Location Service \xe2\x80\x93 Sample Architecture\nA typical workflow involving the IoT rules \xe2\x80\x9clocation action\xe2\x80\x9d capability looks like this.\nStep 1: IoT enabled devices can use the MQTT protocol to send messages to AWS IoT Core. These messages can typically consist of geospatial data like latitude and longitude, providing insight into the physical location of the assets with accuracy within a few meters.  Alternatively, the AWS IoT Core Device Location feature enables IoT devices without built-in GPS to relay their location information to AWS IoT Core using cellular, GNSS (Global navigation satellite system), or network location.\nStep 2: AWS IoT Core then listens to these messages and the Rules Engine processes them.\nStep 3:  Rules Engine invokes the \xe2\x80\x9cLocation action\xe2\x80\x9d functionality, triggering a connection to an Amazon Location Service tracker resource.\nStep 4: These tracker resources can then interface with Amazon Location geofences, with the ability to trigger events when a tracker resource enters or exits a geofence.\nStep 5 : A geofence event can be sent to an event bus like Amazon EventBridge, which can subsequently connect to other services or workflows like notifications, storage, or analytics.\nThis entire solution can be setup without deploying any infrastructure, in a serverless manner with just a few lines of code.\nHow to use the IoT Device Simulator to trigger a \xe2\x80\x9clocation Action\xe2\x80\x9d\nSetting up the IoT Device Simulator\nThe IoT Device Simulator solution helps customers test device integration and improve the performance of their IoT backend services, via an intuitive web-based graphical user interface (GUI). The solution allows customers to create and simulate hundreds of connected devices, without having to configure and manage physical devices, or develop time-consuming scripts. Using the instructions on the solution page, deploy the IoT Device Simulator to your AWS Account.\nCreating a device\nOnce the IoT Device Simulator is deployed, you can log in and create your device.\nTo create a device\nNavigate to Device Types, choose Add device type\nChoose Automotive Demo\nIn the Device Type Definition, do the following:\nFor Device type name, enter Tracking Demo\nFor Topic enter iot/trackingdemo\nChoose Save\nFig.2 Creating a Device Type\nCreating a simulation\nNavigate to Simulations, and choose Add Simulation\nIn the Simulation Details, do the following:\nFor Simulation name, enter TrackingDemo\nFor Simulation Type, choose Automotive Demo\nFor Select a device type, choose TrackingDemo\nFor Data transmission interval, enter 5\nFor Data transmission duration, enter 600\nChoose Save\nFig. 3 Creating a Simulation\nNow that you have created a simulated device, it\xe2\x80\x99s time to create your AWS IoT Core rule.\nCreate an AWS IoT Core rule\nNavigate to the AWS IoT Core console\nSelect Message Routing, then select Rules\nFig 4. IoT Core Console\nChoose Create Rule\nFig 5. Creating the Rule\nIn the Specify rules properties page, enter the following:\nFor Rule name, enter TrackingDemo\nFor Description, enter An IoT Rule for Amazon Location Service Tracking\nChoose Next\nFig. 6 Specifying rule properties\nOn the Configure SQL statement page, enter the following:\nFor  SQL statement, enter\nSELECT * FROM \'iot/trackingdemo\'\nSQL\nChoose Next\nFig. 7 Configuring SQL Statement\nIn the Rules actions dialog box, do the following:\nFor Action 1, select the Choose an action dropdown, and select Location\nIn the Tracker name section, choose Create a tracker\nFig. 8 Creating a Tracker\nTo create a tracker\nOn the Create tracker page, do the following:\nFor Name enter TrackerDemo\nFor Position filtering, choose Accuracy-based filtering\nChoose Create tracker\nFig. 9 Tracker Properties\nTo configure the tracker rule\nNavigate to your AWS Iot Core tab, and choose Refresh next to the Choose an Amazon Location Service tracker dropdown\nSelect TrackerDemo\nSince AWS IoT Core supports substitution, you can derive these fields directly from the payload. Enter the following:\nFor Device ID enter ${VIN}\nFor Longitude enter ${location.longitude}\nFor Latitude enter ${location.latitude}\nFor Timestamp value enter ${timestamp()}\nChoose Create new role and enter TrackingDemo for the Role name.\nFig. 10 Creating the IAM Role\nYour configuration should look like this\nFig. 11 Rule Configuration\nChoose Next then choose Create on the Review and create page.\nStarting the simulation\nNavigate to your IoT Device Simulator, choose View next to TrackingDemo\nFig. 12 Viewing the Simulation\nChoose Start and within a few seconds, you should see the map update with the position of your simulated device. If it doesn\xe2\x80\x99t show up within a few seconds, refresh the page.\nFig. 13 Starting the Simulation\nViewing the Amazon Location Service tracker\nYou can now confirm that the tracker is being updated. From the simulation, copy the VIN number from the Messages portion of the page. The Messages portion shows all the raw data being sent to AWS IoT Core.\nViewing Tracker History\nNavigate to the AWS IoT Core Console and open CloudShell which is located in the top right menu bar near the Region. This will open an interactive command line interface that you can use to issue commands against the Location Service API.\nFig. 14 CloudShell Service\nEnter the following command, substituting <VIN>  for the VIN number from the simulator\naws location get-device-position --device-id <VIN> --tracker-name TrackerDemo\nBash\nThis will return the latest device position. For example:\n[cloudshell-user@ip-10-0-136-227 ~]$ aws location get-device-position --device-id <VIN> --tracker-name TrackerDemo\n{""DeviceId"": ""<VIN>;"",\n""Position"": [\n-77.227279,\n38.918713\n],\n""ReceivedTime"": ""2022-11-11T16:30:47.807000+00:00"",\n""SampleTime"": ""2022-11-11T16:30:47.665000+00:00""}\nBash\n4.     You can use the same CloudShell session to view the device position history as well. Enter the following command:\naws location get-device-position-history --device-id <VIN> --tracker-name TrackerDemo\nBash\n5.     This will provide a list of past device updates, up to 30 days. This data can be used to plot the device history on a map, or perform analytics regarding distances traveled, time spent at locations, and more.\nCleanup\nTo remove the IoT Device Simulator, follow the steps in the implementation guide.\nTo delete the AWS IoT Core rule\nNavigate to AWS IoT Core choose Message Routing\nChoose Rules, select TrackingDemo and select Delete.\nSummary\nIn this post, you have learned how to use the new Location Action feature in AWS IoT Core rules to update an Amazon Location Service tracking resource using messages from AWS IoT Core. Using the IoT Device Simulator, you can set up a simple demo of a device moving down a road, and using the Amazon Location Service API, you can track and visualize that device\xe2\x80\x99s current position, as well as its position history. These granular insights on location data can help you better manage your devices, reduce operational expenses, and empower your maintenance crew with actionable information. To learn more about the Amazon Location action for AWS IoT Core, visit the documentation here.\nAbout the Authors\nZachariah Elliott works as a Solutions Architect focusing on Amazon Location Service at AWS. He is passionate about helping customers build geospatial solutions on AWS. He is also part of the IoT Subject Matter Expert community at AWS and loves helping customers develop unique IoT-based solutions.\n  Anand Vijayan works as a Senior Product Manager focusing on Amazon Location Service at AWS. He is excited about geospatial technologies and enjoys helping customers solve complex problems at scale leveraging the power of the cloud. He is an avid astronomer and has a keen interest in all things space.'"
18,Which AWS IoT device provisioning method should I use?,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/which-aws-iot-device-provisioning-method-should-i-use/,"b'One of the first steps you come across when starting an Internet of Things (IoT) project is provisioning your IoT devices. This blog highlights the different provisioning methods you can use to connect your devices to AWS IoT Core.\nDevice provisioning in AWS establishes the first trust relationship between device and AWS. During the provisioning process, AWS registers the device, which defines the link between AWS and the device. Resources created vary depending on which provisioning method your use case utilizes. There are resource that are created on the device and resources that are created on AWS IoT Core.\nResources that are created on the device include X.509 Certificate, Private Key, and Amazon Trusted Service Root Certificate Authority (Root CA) or Signer Certificate Authority. All are used to authenticate and securely connect the device to AWS IoT Core.\nX.509 certificates: Can be created by AWS IoT, or a certificate authority (ca) registered with AWS IoT that signed the X.509 certificate. X.509 certificates also support use of public and private keys on the device.\nAmazon Root CA: Is an Amazon Trusted Service Root CA that your device will use along with the X.509 certificate to authenticate the connection with AWS IoT Core server. For more information check out server authentication.\nResources that are created in AWS IoT Core include IoT Thing, IoT Policy, and IoT Certificate. When the IoT Thing is created, an IoT Certificate (X.509) is also created (AWS best practices recommends that each IoT Thing to be configured with a unique certificate), also an IoT Policy (policies don\xe2\x80\x99t have to be unique to each device). When the resources are created, the IoT Policy is attached to the IoT Certificate and the IoT Certificate is attached to the IoT Thing. This allows your device to access AWS resources.\nIoT Thing is a representation of you IoT device in the AWS IoT Core.\nIoT policy is a JSON document used to allow or restrict device access to the AWS IoT resources.\nSingle thing provisioning\nThe single thing provisioning method is usually adopted during development/testing phase. For example, you are testing the cloud connection between your device and AWS IoT Core. In this example setup, you will create a IoT thing in the AWS console or AWS IoT API and download the certificates to your local machine. You will also need to establish secure access to the device certificates that will be used to connect to AWS IoT Core. Then, you can create an IoT Policy and attach it to your certificate. After creating the IoT Policy you will then attach the policy to your certificate which is connected to your IoT thing. This method is commonly used for development, although it can be integrated to other provisioning method or external APIs in order to accomplish scalability.\nJust in time provisioning\nJust in time provisioning (JITP) is secure, easy and scalable way to provision devices at scale. For example, using this provisioning method is if you are able to get the unique client certificates securely loaded onto your device at the time of manufacturing. This method also requires your own Root Certificate Authority (root CA). When using JITP, device certificate auto registration must be enabled. With JITP you will use your own CA and register it with AWS IoT, then attach your JSON provisioning template which is used as a blueprint for the registration flow. When your device is connecting for the first time, the IoT device will present its unique device certificate signed by the Certificate Authority that was registered to AWS IoT Core. After the certificate is activated, an IoT thing will be created and registered, subsequently an IoT policy will be attached to the activated certificate. Using this provisioning method meets the use case of auto provisioning devices when they connect to AWS IoT for the very first time. For more information, check out this previous AWS blog post \xe2\x80\x9cSetting up just in time provisioning with AWS IoT core.\xe2\x80\x9d\nJust in time registration\nJust in time registration (JITR) can also securely provision devices at scale. JITR like JITP can be used when your trusted manufacturer can install the unique device certificate securely on every device. Like in JITP, in JITR a root CA needs to be registered with AWS IoT Core, but no provisioning template is necessary. In the JITR registration flow, when your IoT device connects for the first time and presents the signed unique device certificate, a registration event is published to an AWS IoT reserved topic. Also an AWS IoT Rule will be created and subscribed to the MQTT lifecycle event topic, when the MQTT message is sent to the IoT rule it will trigger an AWS Lambda function. The Lambda function can then perform additional verification checks. For example, the Lambda function can check the device certificate or device serial number against an allowed list in a database. After the Lambda function verified the device certificate, then the same lambda function can activate the certificate, create an IoT thing, and an IoT policy for the certificate. Your device will be able to successfully connect to the AWS IoT core after that. For more information, check out this previous AWS blog post \xe2\x80\x9cJust in time registration of Device certificates on AWS IoT.\xe2\x80\x9d\nMulti-Account Registration (MAR) is a feature that can use the same device certificate across different AWS accounts and endpoints. MAR can now be used with JITP and JITR, thanks the latest feature that allows the registration of the same certificate authority using Server Name Indication (SNI) mode. With SNI mode you can register the Certificate authority throughout many accounts and regions, and now devices are able to initiate the JITP or JITR flow by simply pointing to the correct account endpoint. For more information, check out this blog \xe2\x80\x9cSimplify multi-account device provisioning and certificate authority registration when using AWS IoT Core.\xe2\x80\x9d\nFleet Provisioning\nUnlike JITR and JITP, fleet provisioning does not require that you bring your own certificate authority nor requires unique device certificate before provisioning. It utilizes an AWS IoT generate device certificate which is signed by the managed Amazon trust root CA. Fleet provisioning uses the AWS IoT CA and creates a AWS unique device certificate with two distinct provisioning methods, which are provision by claim and provisioning by trusted user. Both provisioning methods use a provisioning template.\nFleet provisioning by claim is usually applied when a trusted manufacturer can load all devices with a common bootstrap certificate. When the IoT device connects to AWS IoT Core for the very first time, it will connect using the bootstrap certificate which has a very restrictive policy. After connecting, the device must deliver the correct payload and parameters to a restricted and reserved topic. AWS IoT Core then generates a unique device certificate and delivers back to the device. This certificate is only activated after the parameters are evaluated by a Lambda function. For more information check \xe2\x80\x9cHow to automate onboarding of IoT devices to AWS IoT Core at scale with Fleet Provisioning.\xe2\x80\x9d\nFleet provisioning by trusted user is a method usually applied when a device maker designs a companion application(app). The companion app, mobile or web app will call the Fleet provisioning API using credentials and permission that have been given to that trusted user. The API then respond with a temporary claim certificate, which is only active for five minutes. Once a temporary claim certificate is obtained from AWS, the app will then pass the temporary claim certificate to the device, the relationship in between companion app and device should be developed by the device maker, for example a secure Bluetooth connection. The device then uses the temporary certificate to connect to AWS IoT core and claim a unique device certificate. When connecting to AWS IoT core a provision template is used to create and attach a IoT policy to the new device certificate, a IoT thing will be created and registered, the device will then disconnect and reconnect with new device certificate.\nBulk Registration\nFinally, we must cover Bulk provisioning, which can be used to provision your fleet of devices in bulk. For example, if you have a fleet of air conditioner units and they are being retrofitted with devices to connected to AWS IoT Core, in this case Bulk provisioning can help register and connect the devices during system delivery. Bulk provisioning is used when you have a list of attributes about your devices, such as model, serial numbers, firmware version and other attributes, organized as a JSON provision file. The file can be stored in an Amazon Simple Storage Service (Amazon S3) bucket. After that, you can run the bulk provisioning task to onboard your devices. Bulk registration is also commonly applied to device certificate rotation.\n'"
19,Enhancing IoT device security using Hardware Security Modules and AWS IoT Device SDK,b'Tim Wilson',2023-03-16T13:39:40+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/enhancing-iot-device-security-using-hardware-security-modules-and-aws-iot-device-sdk/,"b'Introduction\nSecurity of operations and security of data are among the top priorities of customers dealing with sensitive information or operating in highly regulated markets. Internet of Things (IoT) customers have the additional challenge of enabling high security standards for IoT communications to their cloud platforms. Data encryption with asymmetric algorithms and cryptographic keys are widely adopted mechanisms to secure communication traffic.\nThe most important requirement related to cryptographic keys for IoT devices is that they must be securely stored to deny direct access from malicious users. The leakage of a private key would allow a malicious user to impersonate an IoT device and access sensitive resources from corporate IT, or send counterfeit data, with threatening results.\nHardware Security Modules (HSMs) provide an effective hardware-based mechanism to avoid exposure of private keys and are a trending technology among customers that want to protect their digital keys and certificates. However, their integration in the software stack of IoT Devices is not a trivial process.\nThis post will walk you through some notable examples of security challenges across IoT Industry verticals, and provide a sample implementation of a secure communication IoT client with few lines of code on AWS using a simulated Hardware Security Module, AWS IoT Device SDK v2, and AWS IoT.\nCybersecurity in IoT: protecting your device secrets\nA common standard in IoT communications security is to leverage a Transport Level Security layer (TLS) to protect data as it moves between the device and the cloud. For example AWS IoT Core adopts TLS v1.2 and X.509 certificates for its IoT transport level security.\nIn a secure communication scenario, IoT devices are provided with a key-pair, containing the private key and the public certificate, and a trust-store containing the server Certificate Authority (CA) chain. This information is needed to allow both server authentication on the client side (using the trust-store) and the client authentication on the server side (using the key pair). This approach is called Mutual TLS authentication and is depicted in the following diagram.\nFigure 1: High level functional view of mutual authentication between IoT devices and AWS IoT Core\nCustomers managing the IoT device software and operations are ultimately responsible for provisioning, storing, and utilizing such secrets, and limiting the exposure of the keys. For additional information on how AWS and customers manage workload security, refer to the Shared Responsibility Model.\nRisks of IoT device secrets leakage\nExamples of risks related to IoT device secrets leaking include the following:\nAutomotive telematics IoT customers are exposed to the risk that a malicious attacker can impersonate a vehicle and send counterfeit data to the cloud, or download sensitive data from the corporate datacenter.\nIn March 2021, The United Nations Economic Commission for Europe (UNECE) approved and published UN Regulations on CyberSecurity (UN R155) and SW updates (UN R156) for connected vehicles. In the regulations, security controls for the storage of cryptographic keys is among the proposed mitigation actions for cyberthreats.\nIoT smart cities customers are exposed to the risk that operations of their connected smart lighting poles, traffic lights, etc. could be tampered with, resulting in service outages or public safety issues.\nIoT smart grids customers are concerned about fraudulent users tampering with a connected smart meter and providing counterfeit data to the central grid system.\nBut how can device secrets be compromised?\nIn a typical lifecycle, security keys for an IoT device must be provisioned, stored, regularly rotated, and used for cryptographic operations.\nLifecycle state Security threat Mitigation\nProvisioning Injecting the keys from outside of the device results in risk of exposure to a malicious attacker. Generate private keys in the device, and never expose outside.\nStorage A malicious attacker can tamper the device and/or take control of the device software to access its non-volatile memory. Use a device with anti-tampering mechanisms (such as HSM). If not available, encrypting your storage can reduce risk.\nUsage If a software cryptographic library is used, the software will need to access the secrets through volatile memory (without encryption). An attacker could retrieve it through JTAG (Joint Test Action Group) debuggers or similar mechanisms. Perform cryptographic operations off-chip so the keys are not exposed in the software flow.\nIn general, storing device keys inside the device memory or in cloud storage is not advisable. In a security incident known as the SolarWinds hack in 2020, malicious attackers were able to gain access to the protected data in the Active Directory Federation Services (ADFS) of the customer, collect encryption keys that were stored in the system, and use them to impersonate legitimate users, stealing sensitive data.\nHow Hardware Security Modules improve the security of IoT communications\nA Hardware Security Module (HSM) is a physical module in the form of a cryptographic chip. It can be soldered on board of the device, or connected to a high speed bus. It provides the following:\nA secure key vault store and entropy-based random key generation.\nImplements cryptographic operations on-chip, without exposing them to the software stack.\nAdvanced anti-tampering mechanisms for physical protection of the chip\xe2\x80\x99s non volatile memory (NVM).\nFigure 2: High level functional view of Hardware Security Module integration with business applications using PKCS#11 APIs\nUsing such a device, customers can reduce the exposure of security keys, since the private key generation and cryptographic operations happen in the chip itself.\nApplications interact with the device through specific purpose-built APIs, of which one of the industry standards is PCKS#11 or \xe2\x80\x9cCryptoki\xe2\x80\x9d. A full description of the PKCS#11 APIs can be consulted at OASIS PKCS#11 specifications.\nUsing an HSM mitigates the risks of exposure of private keys as follows:\nLifecycle state Security threat\nProvisioning Injecting the keys from outside of the device results in risk of exposure to a malicious attacker.\nStorage A malicious attacker can tamper the device and/or take control of the device software to access its non-volatile memory.\nUsage If a software cryptographic library is used, the software will need to access the secrets through volatile memory (without encryption). An attacker could retrieve it through JTAG (Joint Test Action Group) debuggers or similar mechanisms.\nDue to the complexity of the implementation, interfacing an HSM through PCKS#11 can be a time consuming and difficult task for an IoT engineer.\nAWS IoT Device SDKs v2 helps customers that want to implement HSM-based device security, providing dedicated libraries to help developers implement a secure MQTT client connection using an HSM with PKCS#11 with few lines of code.\nImplementing a secure MQTT client from your IoT device with IoT Device SDK for Python v2 and software HSM\nIn this blog, you will replicate the steps required to set up an MQTT IoT Client to AWS IoT Core using a Hardware Security Module and AWS IoT Device SDK for Python v2 in few lines of code.\nThe following diagram depicts the architecture of the proposed solution:\nFigure 3: High level architecture diagram of the proposed solution for secure IoT communications between an IoT device and AWS IoT Core\nThe proposed example simulates a Hardware Security Module with a software-HSM using softHSM2 from the OpenDNSSEC project.\nThe device certificate will be signed by the Amazon Root CA built-in to AWS IoT Core. In case a Private CA is used, the request must be sent to the proper Public Key Infrastructure of the customer (PKI).\nPrerequisites\nAn AWS account.\nA Linux debian-based machine.\nOpenSSL 3.0+ installed on your machine (refer to this link for instructions).\nPython 3.6+ installed on your machine (refer to this this link for instructions).\nsoftHSM version2 installed on your machine (refer to this this link for instructions).\nAmazon RSA 2048 bit rootCA 1 key (download here).\nStep 1: Provisioning a device certificate through HSM in AWS IoT Core\nA device certificate for your device must be provisioned and activated in AWS IoT Core. You can use the softHSM2 software to simulate a HSM, and openssl to generate a Certificate Signing Request (CSR).\nIt is not scope of this blog to provide examples of how to use softHSM2, and openssl; please refer to the software documentation.\nThe steps required are the following:\nInstall softHSM2 and pcks11 tools (refer to this link for instructions):\nsudo apt install softhsm\nsudo apt install opensc opensc-pkcs11 openssl libengine-pkcs11-openssl\nBash\nConfigure a token and a generate a private key:\nsudo softhsm2-util --init-token --free --label <token-label>\nBash\nThis command should prompt you to enter a PIN, just follow instructions and remember that PIN.\nGet the Slot ID:\nOnce you have your token configured, you need to retrieve the Slot number to be used in the next command. To do that, run the following:\nsudo softhsm2-util --show-slots\nBash\nYou should get a response like the following:\nAvailable slots:\nSlot <slot-id>\n    Slot info:\n        Description:      SoftHSM slot ID 0x35927c85\n        Manufacturer ID:  SoftHSM project\n        Hardware version: 2.6\n        Firmware version: 2.6\n        Token present:    yes\n    Token info:\n        Manufacturer ID:  SoftHSM project\n        Model:            SoftHSM v2\n        Hardware version: 2.6\n        Firmware version: 2.6\n        Serial number:    aede8dd735927c85\n        Initialized:      yes\n        User PIN init.:   yes\n        Label:            <token-label>\nSlot 1\n    Slot info:\n        Description:      SoftHSM slot ID 0x1\n        Manufacturer ID:  SoftHSM project\n        Hardware version: 2.6\n        Firmware version: 2.6\n        Token present:    yes\n    Token info:\n        Manufacturer ID:  SoftHSM project\n        Model:            SoftHSM v2\n        Hardware version: 2.6\n        Firmware version: 2.6\n        Serial number:\n        Initialized:      no\n        User PIN init.:   no\n        Label:\nCheck which slot contains the label related to the previous command and get its ID (the one on the left of the Slot <slot-id> line).\nGenerate the certificate:\nOnce you have generated the token on softHSM2 and you have the <slot-id>, you can use pkcs11-tool to generate a key-pair in it. To do that, use the following command replacing the <PIN> and <token-lable> placeholders.\nNote: the module path /usr/lib/softhsm/libsofthsm2.so is based on the ubuntu-like instance of the machine. It may vary according to the environment you are testing into.\nsudo pkcs11-tool -l --pin <PIN> --keypairgen --hash-algorithm ""SHA256"" --key-type RSA:2048 --label <token-label> --slot <slot-id> --module /usr/lib/softhsm/libsofthsm2.so\nBash\nYou should get a response like this:\nKey pair generated:\nPrivate Key Object; RSA\n  label:      <token-label>\n  Usage:      decrypt, sign, unwrap\n  Access:     sensitive, always sensitive, never extractable, local\nPublic Key Object; RSA 2048 bits\n  label:      <token-label>\n  Usage:      encrypt, verify, wrap\n  Access:     local\nCreate a Certificate Signing Request using openssl and softHSM2. (see following link for a sample walkthrough).\nYou can generate an RSA key with a length of 2048 bits and SHA256 algorithm. Refer to AWS IoT Core documentation for a full list of certificate signing algorithms supported:\nsudo openssl req -new -engine pkcs11 -keyform engine -key \xe2\x80\x9cpkcs11:object=<token-label>;pin-value=<PIN>\xe2\x80\x9d -out certificate.csr\nBash\nThis command will prompt you to enter certificate information to be embedded into the sign request.\nUse the following command to check if the Certificate Signing Request has been filled with the correct information:\nopenssl req -in certificate.csr -noout -text\nBash\nIssue the following AWS CLI command to generate a device certificate using your CSR:\naws iot create-certificate-from-csr \\\n    --set-as-active \\\n    --certificate-signing-request=file://certificate.csr\nBash\nThe command will provide you the Amazon Resource Name (ARN) of the certificate and the content:\n{\n   ""certificateArn"": ""arn:aws:iot:{region}:{accountId}:cert/{certificateId}"",\n   ""certificateId"": ""{certificateId}"",\n   ""certificatePem"": ""<certificate-text>""\n}\nStore your public certificate in your device in a file called deviceCertificate.pem using the following AWS CLI command:\naws iot describe-certificate \\\n    --certificate-id ""{certificateId}""| jq -r "".certificateDescription.certificatePem"" > deviceCertificate.pem\nBash\nCreate a file called policy.json representing an IoT Policy with \xe2\x80\x98Connect\xe2\x80\x99 only action permissions:\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": [\n        { \n           ""Effect"": ""Allow"",\n           ""Action"": ""iot:Connect"",\n           ""Resource"": ""arn:aws:iot:{region}:{accountId}:client/${iot:Connection.Thing.ThingName}""\n        }\n   ]\n}\nRemember to replace {region} and {accountId} with your data.\nCreate the IoT policy resource in AWS IoT Core with the following AWS CLI command:\naws iot create-policy \\\n    --policy-name HSMDevicePolicy \\\n    --policy-document file://policy.json\nBash\nCreate a \xe2\x80\x98thing\xe2\x80\x99 in AWS IoT Core, attach the IoT policy to the certificate and the certificate to the \xe2\x80\x98thing\xe2\x80\x99 (remember to replace {certificateArn} with the value obtained from earlier):\naws iot create-thing \\\n    --thing-name HSMDevice\nBash\naws iot attach-policy \\\n    --target ""{certificateArn}"" \\\n    --policy-name ""HSMDevicePolicy""\nBash\naws iot attach-thing-principal \\\n    --thing-name HSMDevice \\\n    --principal ""{certificateArn}""\nBash\nStep 2: Setting up the client with AWS IoT Device SDK2\nWith AWS IoT Device SDK2, you can create an IoT client and establish an MQTT connection using an HSM with a single line of code.\nThe following example uses Python as language of preference, but the feature is available for all the target languages of AWS IoT Device SDK 2 (see complete list at following link).\nPrerequisites\nPKCS#11 libso file is available for your HSM (in case of softHSM this is typically found in /usr/lib/softhsm/libsofthsm2.so). The file is required from the AWS IoT Device SDK 2 to properly set up the connection.\nThe following Python module (and its dependencies) must be installed before running the client: sudo pip3 install awsiotsdk.\nCreate a file called client.py with the following content:\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0.\n\nfrom awscrt import io\nfrom awsiot import mqtt_connection_builder\nfrom uuid import uuid4\nimport argparse\nimport sys\n\n# Callback when connection is accidentally lost.\ndef on_connection_interrupted(connection, error, **kwargs):\n    print(""Connection interrupted. error: {}"".format(error))\n\n# Callback when an interrupted connection is re-established.\ndef on_connection_resumed(connection, return_code, session_present, **kwargs):\n    print(""Connection resumed. return_code: {} session_present: {}"".format(return_code, session_present))\n\nif __name__ == \'__main__\':\n    # Create a connection using websockets.\n    # Note: The data for the connection is gotten from cmdUtils.\n    # (see build_pkcs11_mqtt_connection for implementation)\n\n    parser = argparse.ArgumentParser(description=\'Input arguments for PKCS#11 MQTT Client.\')\n    parser.add_argument(""--pcks11lib"", type=str , help=""path to pkcs11 library"")\n    parser.add_argument(""--slot"", type=int , help=""HSM slot"")\n    parser.add_argument(""--pin"", type=str , help=""HSM slot pin"")\n    parser.add_argument(""--tokenlabel"", type=str , help=""HSM token label"")\n    parser.add_argument(""--keylabel"", type=str , help=""HSM ptivate key label"")\n    parser.add_argument(""--certpath"", type=str , help=""device certificate file path"")\n    parser.add_argument(""--endpoint"", type=str , help=""AWS IoT Core endpoint"")\n    parser.add_argument(""--cafile"", type=str , help=""CA certificate file path"")\n    parser.add_argument(""--clientid"", type=str , help=""clientId to use for MQTT connection"")\n\n    if len(sys.argv)==1:\n        parser.print_help(sys.stderr)\n        sys.exit(1)\n    args = parser.parse_args()\n    \n    # We load the HSM library\n    pkcs11_lib_path = args.pcks11lib\n    print(f""Loading PKCS#11 library \'{pkcs11_lib_path}\' ..."")\n    pkcs11_lib = io.Pkcs11Lib(\n        file=pkcs11_lib_path,\n        behavior=io.Pkcs11Lib.InitializeFinalizeBehavior.STRICT)\n    print(""Loaded!"")\n\n    pkcs11_slot_id = args.slot\n    pkcs11_pin = args.pin\n    pkcs11_tokenlabel = args.tokenlabel\n    pkcs11_keylabel = args.keylabel\n    certpath = args.certpath\n    endpoint = args.endpoint     \n    cafile = args.cafile \n    clientid = args.clientid\n\n    # This is the core section of the example client. \n    # This single instruction instantiates an MQTT connection \n    # and performs encyrption operations using your HSM\n    # through the mqtt_connection_builder.mtls_with_pkcs11 method\n    mqtt_connection = mqtt_connection_builder.mtls_with_pkcs11(\n        pkcs11_lib          =   pkcs11_lib,\n        user_pin            =   pkcs11_pin,\n        slot_id             =   pkcs11_slot_id,\n        token_label         =   pkcs11_tokenlabel,\n        private_key_label   =   pkcs11_keylabel,\n        cert_filepath       =   certpath,\n        endpoint            =   endpoint,\n        port                =   8883,\n        ca_filepath         =   cafile,\n        on_connection_interrupted   =   on_connection_interrupted,\n        on_connection_resumed       =   on_connection_resumed,\n        client_id           =   clientid,\n        clean_session       =   False,\n        keep_alive_secs     =   30)\n\n    connect_future = mqtt_connection.connect()\n\n    # Future.result() waits until a result is available\n    connect_future.result()\n    print(""Connected!"")\n\n    # Disconnect\n    print(""Disconnecting..."")\n    disconnect_future = mqtt_connection.disconnect()\n    disconnect_future.result()\n    print(""Disconnected!"")\nPython\nThe core of the above client implementation is the awsiot.mqtt_connection_builder.mtls_with_pkcs11() method from the AWS IoT Device SDK v2. The method is responsible for establishing a secure MQTT connection using the HSM to perform cryptographic operations.\nInput parameters of the method are:\nParameter Description\npkcs11_lib Link to pkcs11 library (in case of softHSM this is typically found in /usr/lib/x86_64-linux-gnu/softhsm/libsofthsm2.so)\nuser_pin User PIN of your HSM\nslot_id The slot id of your private key\ntoken_label The token label of your private key\nprivate_key_label The label of your private key\ncert_filepath The path to your deviceCertificate.pem file\nca_filepath The path to your AmazonRootCA1.pem file\nclient_id The clientID you want to use to connect AWS IoT Core\nport The port to use for MQTT connection\nIn our example, such parameters are provided through command line from the script arguments.\nStep 3: Test your secure connection\nYou can retrieve your MQTT connection endpoint with the following CLI Command:\naws iot describe-endpoint \\\n    --endpoint-type iot:Data-ATS\nBash\nPlace the content of the endpointAddress field into the environmental variable to be used later:\nexport IOT_CORE_ENDPOINT=<endpointAddress>\nBash\nExecute the above script using Python 3 executable (python3) with sudo privileges, in order to allow access to the HSM library:\nsudo python3 client.py --pcks11lib /usr/lib/x86_64-linux-gnu/softhsm/libsofthsm2.so \\\n --pin <PIN> \\\n --tokenlabel <token-label> \\\n --certpath deviceCertificate.pem \\\n --endpoint ${IOT_CORE_ENDPOINT} \\\n --cafile AmazonRootCA1.pem \\\n --clientid HSMDevice\nBash\nA successful execution should return the following:\nLoading PKCS#11 library \'/usr/lib/x86_64-linux-gnu/softhsm/libsofthsm2.so\' ...\nLoaded!\nConnected!\nDisconnecting...\nDisconnected!\nCleaning up resources\nDetach \xe2\x80\x98thing\xe2\x80\x99 and IoT policy from registered certificate:\naws iot detach-policy \\    \n    --target ""{certificateArn}"" \\\n    --policy-name ""HSMDevicePolicy""\nBash\naws iot detach-thing-principal \\    \n    --thing-name HSMDevice \\\n    --principal ""{certificateArn}""\nBash\nDelete device certificate, \xe2\x80\x98thing,\xe2\x80\x99 and IoT policy:\naws iot delete-thing \\\n    --thing-name HSMDevice\nBash\naws iot delete-certificate \\\n    --certificate-id ""{certificateId}""\nBash\naws iot delete-policy --policy-name ""HSMDevicePolicy""\nBash\n'"
20,How to get started with the new AWS IoT Core Device Location service,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-get-started-with-the-new-aws-iot-core-device-location-service/,"b'Introduction\nThe new AWS IoT Core Device Location feature allows Internet of Things (IoT) devices to retrieve and report their current location without relying on Global Positioning System (GPS) hardware. Devices and clients connected to AWS IoT Core can now use cloud-assisted Global Navigation Satellite System(GNSS), WiFi scan, cellular triangulation, and reverse IP lookup techniques with the AWS IoT Core Device Location feature to determine their GPS coordinates and overall location.\nGeo-location information and location tracking are requirements in many Internet of Thing (IoT) applications. Segments such as logistics and automotive cannot deliver significant results without this data. Historically, Geolocation monitoring relies on specific hardware, like Global Positioning System (GPS) modules. If devices don\xe2\x80\x99t have a GPS hardware, adding one or upgrading existing devices can be costly at scale or might not be feasible to implement. However, even with a built-in GPS hardware, there isn\xe2\x80\x99t a guarantee that these devices will have constant connectivity to GPS satellites to retrieve and report their coordinates.\nIn this blog post, we\xe2\x80\x99ll show how to get started with the AWS IoT Core Device Location. We\xe2\x80\x99ll detail what steps you can take before using the feature and demonstrate how to use it to resolve your device\xe2\x80\x99s location based on only its IP address.\nPrerequisites\nTo follow through this blog post, you will need an AWS account, an AWS IoT Core supported region,  permissions to create AWS IoT Rules, AWS Lambda Functions,  AWS Identity and Access Management (IAM) roles and policies, and access to AWS CloudShell. We also assume you have familiar with the basics of Linux bash commands.\nWalkthrough\nFor the demonstration in this post, you will resolve a device\xe2\x80\x99s location by first publishing its IP address via an MQTT message to AWS IoT Core. Second, an AWS IoT Rule will forward the message to a Lambda function. Third, this Lambda function will call the AWS IoT Core Device Location feature, via the GetPositionEstimate API. Finally, the Lambda function will publish the device\xe2\x80\x99s location data as an MQTT message back to the device or any MQTT client subscribed to the location response topic. The illustration below details what this solution will look like once fully implemented.\nStep 1: Create AWS Lambda execution role and policy\nFrom your AWS CloudShell environment implement the following commands:\nCreate the environmental variables for the upcoming command\nexport ACCOUNT_ID=<Replace with your account ID>\nexport REGION=<Replace with your region>\nBash\nCreate the IAM execution role for the Lambda function using the create-role command\naws iam create-role --role-name ""lambda-ex-ipAddressToDeviceLocationService"" \\\n--assume-role-policy-document \'{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Principal"": {\n                ""Service"": ""lambda.amazonaws.com""\n            },\n            ""Action"": ""sts:AssumeRole""\n        }\n    ]\n}\'\nBash\nNow we will create the policy document for the role\xe2\x80\x99s permissions, run the command below to create the policy document\n( jq -n \\\n            --arg region ""$REGION"" \\\n            --arg account_id ""$ACCOUNT_ID"" \\\n            \'{\n            ""Version"": ""2012-10-17"",\n            ""Statement"": [\n                {\n                    ""Effect"": ""Allow"",\n                    ""Action"": ""iotwireless:GetPositionEstimate"",\n                    ""Resource"": ""*""\n                },\n                {\n                    ""Effect"": ""Allow"",\n                    ""Action"": [\n                        ""logs:CreateLogGroup"",\n                        ""iot:Publish""\n                    ],\n                    ""Resource"": [\n                        ""arn:aws:logs:\\($region):\\($account_id):*"",\n                        ""arn:aws:iot:\\($region):\\($account_id):topic/device/test-1/location/ipbased/response""\n                    ]\n                },\n                {\n                    ""Effect"": ""Allow"",\n                    ""Action"": [\n                        ""logs:CreateLogStream"",\n                        ""logs:PutLogEvents""\n                    ],\n                    ""Resource"": ""arn:aws:logs:\\($region):\\($account_id):log-group:/aws/lambda/ipAddressToDeviceLocationService:*""\n                }\n            ]\n        }\' ) > lambda_policy.json\nBash\nUse the put-role-policy command to attach the policy to the role\naws iam put-role-policy \\\n--role-name ""lambda-ex-ipAddressToDeviceLocationService"" \\\n--policy-name lambda-ex-ipAddressToDeviceLocationService-policy \\\n--policy-document file://lambda_policy.json\nBash\nUse the get-role-policy command to check if the policy has been successfully attached\naws iam get-role-policy \\\n--role-name ""lambda-ex-ipAddressToDeviceLocationService"" \\\n--policy-name lambda-ex-ipAddressToDeviceLocationService-policy\nBash\nStep 2: Create a  Lambda Function\nFrom your AWS CloudShell environment implement the following commands:\nOur Lambda function has a dependency on the AWS SDK for Python (Boto3) SDK, and the new GetPositionEstimate API is supported on version 1.26.45 or later.  In order to create a Lambda function with the latest version of Boto3, we will create and publish a Lambda layer.\nTo Implement the lambda layer use the following commands\nLIB_DIR=boto3-mylayer/python\n \nmkdir -p $LIB_DIR\n\n#(You may need to run this command 2 or 3 times so it can be resolved automatically)\npip3 install boto3 -t $LIB_DIR\n\ncd boto3-mylayer \n\nzip -r /tmp/boto3-mylayer.zip .\n\nLAYER=$(aws lambda publish-layer-version --layer-name boto3-mylayer --zip-file fileb:///tmp/boto3-mylayer.zip)\n \nLAYER_ARN=$(jq -r \'.LayerVersionArn\' <<< ""$LAYER"")\nBash\nImplement the following commands to create your Lambda function deployment package\ncd /home/cloudshell-user\ntouch lambda_function.py\n\ncat > lambda_function.py <<EOF\nimport json, boto3\nfrom datetime import datetime\niot_wireless_client = boto3.client(\'iotwireless\')\niot_data_client = boto3.client(\'iot-data\')\n\ndef lambda_handler(event, context):\n\n    iot_wireless_response = iot_wireless_client.get_position_estimate(Ip={ \'IpAddress\': event[\'ipAddress\']}, Timestamp=datetime.now())\n\n    print(f""IoT Wireless Response: {iot_wireless_response}"")\n    \n    iot_data_response = iot_data_client.publish(\n        topic=\'device/test-1/location/ipbased/response\',\n        qos=0,\n        payload=json.dumps({\'location\':json.loads(iot_wireless_response[\'GeoJsonPayload\'].read())})\n        )\n   \n    print(f""IoT Data Response: {iot_data_response}"")\nEOF\n\nzip -r lambda_function.zip lambda_function.py\nBash\nImplement the commands below to create your Lambda function and add the Boto3 Lambda layer to it\nLAMBDA_FUNCTION=$(aws lambda create-function --function-name ipAddressToDeviceLocationServiceFunction \\\n--zip-file fileb://lambda_function.zip --handler lambda_function.lambda_handler --runtime python3.9 \\\n--role arn:aws:iam::$ACCOUNT_ID:role/lambda-ex-ipAddressToDeviceLocationService)\n\nLAMBDA_ARN=$(jq -r \'.FunctionArn\' <<< ""$LAMBDA_FUNCTION"")\n\n\naws lambda update-function-configuration \\\n--function-name ipAddressToDeviceLocationServiceFunction \\\n--layers $LAYER_ARN\nBash\nUse the add-permission command to allow AWS IoT Core to invoke the Lambda function\naws lambda add-permission --function-name ipAddressToDeviceLocationServiceFunction \\\n--statement-id iot-events --action ""lambda:InvokeFunction"" --principal iot.amazonaws.com\nBash\nStep 3: Create an AWS IoT Rule\nYou will create an AWS IoT Rule use the commands below from the AWS CloudShell session:\nCreate the rule using the create-topic-rule command\n( jq -n \\\n    --arg lambda_arn ""$LAMBDA_ARN"" \\\n    \'{\n        ""sql"": ""SELECT * FROM \\""device/+/location/ipbased\\"""",\n        ""ruleDisabled"": false,\n        ""awsIotSqlVersion"": ""2016-03-23"",\n        ""actions"": [{\n            ""lambda"": {\n                ""functionArn"": ""\\($lambda_arn)""\n            }\n        }]\n    }\' ) > iot_rule_document.json\n    \naws iot create-topic-rule \\\n--rule-name ""ip_address_to_device_location_service"" \\\n--topic-rule-payload file://iot_rule_document.json\nBash\nStep 4: Viewing device location using the AWS IoT MQTT client\nTo view MQTT messages in the MQTT client do the following:\nIn the AWS IoT console, in the left menu, under Test, choose MQTT test client.\nIn the Subscribe to a topic tab, enter the topic device/test-1/location/ipbased/response and then choose Subscribe\nTo publish a message to an MQTT topic do the following:\nIn the Publish to a topic tab, enter the topic device/test-1/location/ipbased and then enter the below JSON as the Message Payload\n{ ""ipAddress"": ""<replace-with-public-ip-address>"" }\nHit Publish to publish your message\nFigure 2 \xe2\x80\x93 Publish to a topic screen in MQTT test client\nThe output from the publish request should look similar to the following:\n{\n  ""location"": {\n    ""coordinates"": [\n      **Longitude**,\n      **Latitude**\n    ],\n    ""type"": ""Point"",\n    ""properties"": {\n      ""country"": ""United States"",\n      ""city"": ""New York"",\n      ""postalCode"": ""*****"",\n      ""horizontalAccuracy"": 20,\n      ""horizontalConfidenceLevel"": 0.67,\n      ""state"": ""New York"",\n      ""timestamp"": ""2023-01-04T20:59:13.024Z""\n    }\n  }\n}\nJSON\n\nCleaning Up\nBe sure to remove the resources created in this blog to avoid charges. Run the following commands to delete these resources:\naws iot delete-topic-rule --rule-name ""ip_address_to_device_location_service""\nBash\naws lambda delete-function --function-name ""ipAddressToDeviceLocationServiceFunction""\nBash\naws iam delete-role-policy --role-name ""lambda-ex-ipAddressToDeviceLocationService""  --policy-name ""lambda-ex-ipAddressToDeviceLocationService-policy""\nBash\naws iam delete-role --role-name ""lambda-ex-ipAddressToDeviceLocationService""\nBash\n'"
21,Generating insights from vehicle data with AWS IoT FleetWise: Introduction,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/12/Screenshot-2022-07-12-at-21.09.06-1024x526.png,https://aws.amazon.com/blogs/iot/generating-insights-from-vehicle-data-with-aws-iot-fleetwise-part1/,"b'This blog post is written by Senior IoT Specialist Solutions Architect Andrei Svirida.\nAutomakers, fleet operators, and automotive suppliers are digitalizing their products and services, and vehicle data is fueling this digitalization in several ways. First, access to vehicle data allows evolutionary improvement of existing business processes. One example of this is faster detection of quality-related issues and analysis of their root causes. Second, access to vehicle data is foundational for mega trends like Advanced Driver Assistance Systems (ADAS), power-train electrification, and the mobility sharing economy.\nHowever, managing vast amounts of vehicle data can be challenging from the technical (e.g., proprietary Electronic Control Units (ECU) data formats), economical (e.g., connectivity costs), and organizational (e.g., data silos) perspectives.\nAWS IoT FleetWise is a fully managed AWS service which makes it easier and more cost efficient to collect, transform, and transfer vehicle data to the cloud. Once transferred, automakers can use the data to build applications by capabilities of AWS such as analytics and machine learning.\nIn this blog, you will first get an overview of the use cases enabled by vehicle data access, as well as the typical implementation challenges. Then, you will learn how to use AWS IoT FleetWise to manage vehicle data in a cost-efficient, secure, and scalable way. Finally, we will introduce an example solution for battery health monitoring using AWS IoT FleetWise. This blog is the first part of a blog series. In the second part, you will get an implementation guide on how to set up and run the battery health monitoring solution in your own AWS account.\nUse cases for near-real time vehicle data processing\nLet\xe2\x80\x99s take a look at some example use cases enabled by near-real time access to the vehicle data.\nVehicle issue prevention\nAccess to vehicle data in near-real time enables automakers and fleet operators to provide a better driving experience and improve vehicle quality. For example, consider the scenario of an electric vehicle (EV) battery overheating.\nEV battery temperature is a critical metric that should be continuously analyzed for the entire vehicle fleet. In order to avoid costly continuous data ingestion, you may want to optimize the data collection by setting a threshold on EV battery temperature. If the threshold is breached, the alarm will be triggered. Based on this alarm, an automatic process for detailed collection and analysis of the vehicle data from the Battery Management System (BMS) will begin.\nThe results of this analysis will be provided to the automaker\xe2\x80\x99s quality engineering department, enabling fast assessment of the criticality and possible root causes of the issue. Based on the root cause analysis, the automaker can then take short-term actions to support the driver affected by the issue, as well as mid-term actions to improve vehicle quality.\nOptimization loop for Advanced Driver Assistance Systems (ADAS)\nADAS requires vehicles to have both awareness and perception. Awareness is the ability to sense the environment using the vehicle sensors (e.g., camera or Lidar). Perception is the ability to collect data from the vehicle sensors and process that data to understand the world around the vehicle.\nIn order to understand the vehicle sensor data, machine learning models must be constantly retrained and optimized. The purpose of such optimization is to minimize the amount of \xe2\x80\x9cunknowns\xe2\x80\x9d, (i.e., objects or situations that vehicle perception cannot process). The best data set for retraining is the data extracted from a production vehicle.\nUntil now, extracting data for ADAS optimization from production vehicles at scale was cost-prohibitive due to high connectivity costs or high manual effort.\nImplementation challenges\nTo implement data-driven use cases, automakers and fleet operators must be able to access and process vehicle data fleet-wide and in near-real time. To ensure efficient implementation, vehicle data must be available in standardized formats to facilitate analysis across various types and models of the vehicles. Automotive customers face the following challenges when implementing data-driven use cases:\nImplementation complexity due to proprietary data formats\nAn ECU is an embedded system in a vehicle which controls one or more vehicle components. ECUs are capable of both emitting the data (e.g., vehicle\xe2\x80\x99s BMS sending current battery temperature via CAN bus) and receiving data (e.g., air conditioning system receiving a stop command via CAN bus). ECUs communicate with other vehicle components via vehicle networks. Examples of vehicle networks include CAN, LIN, FlexRay and Ethernet. For Ethernet networks examples of protocols are DDS and SOME/IP. The data formats used in a vehicle vary depending on ECU type and the vehicle network.\nThe variety of data formats leads to high complexity of systems needed to analyze vehicle-wide and fleet-wide vehicle data. This complexity results in a high implementation and maintenance effort, often preventing or slowing down implementation of data-driven use cases.\nAccessing vehicle data at scale is cost-prohibitive\nEven when the access to vehicle data is technically possible, scaling access to the whole vehicle fleet is often not economically feasible due to high connectivity costs. For this reason, automakers are often prevented from implementing use cases that require fleet-wide access to the vehicle data.\nLimited availability of knowledge about ECU data formats\nKnowledge of vehicle data formats is often locked in organizational silos. This makes it difficult for teams within the organization to collaborate effectively to innovate based on vehicle data.\nFor example, the application development team might run into difficulties implementing a battery monitoring mobile app for customers. The reason could be that the application development team does not know how to decode BMS data, as this knowledge is only available on the BMS engineering team.\nHow AWS IoT FleetWise helps to overcome challenges in implementing data-driven use cases\nBy using AWS IoT FleetWise, customers can overcome the challenges outlined in the previous section with lower development and operational effort.\nUnlock standardized access to vehicle data\nAWS IoT FleetWise enables automakers and fleet operators to collect vehicle data from multiple vehicle data sources in a standardized way. After storing the collected vehicle data in a purpose-built database such as Amazon Timestream or object storage like Amazon Simple Storage Service (S3) (available after General Availability (GA)), vehicle data can be efficiently queried.\nFor example, using AWS IoT FleetWise, a fleet operator can collect the \xe2\x80\x9cCharging Current\xe2\x80\x9d metric for a set of heterogeneous vehicles from different manufacturers and store the collected data in Amazon Timestream. Now fleet-wide queries for \xe2\x80\x9cCharging Current\xe2\x80\x9d metric are possible.\nReduce data volume for cloud ingestion\nAWS IoT FleetWise helps to reduce data volume by providing intelligent data filtering capabilities. With AWS IoT FleetWise, you can reduce data volume in two ways.\nFirst, you can configure the vehicle to collect only the signals, that are required for the purpose of your use cases. Second, you can configure AWS IoT FleetWise to collect the signals only under certain conditions. Examples for such conditions are scheduled collection (e.g., only between 1PM and 2PM on a specific date) or condition-based collection (e.g., only when battery temperature is above the threshold).\nMake vehicle data actionable in near-real time\nWith AWS IoT FleetWise customers can build solutions acting on the vehicle data in near-real time. For that purpose, AWS IoT FleetWise provides capabilities for ingesting and storing the vehicle data to AWS. The data ingestion allows secure, scalable, and cost-efficient connectivity for any size fleet.\nAfter the data is ingested, AWS IoT FleetWise will orchestrate storing the data in a purpose-built database or object storage.\nAccelerate innovation\nWith AWS IoT FleetWise you can accelerate innovation by giving all entitled teams in your company access to the vehicle data. Examples of teams who can benefit from access to the vehicle data include vehicle engineering, quality engineering, application development, sales, and marketing.\nLogical architecture of solutions based on AWS IoT FleetWise\nNow that we have learned about the capabilities of AWS IoT FleetWise, let us dive deeper into the logical architecture and involved personas. The following image represents a logical architecture of a solution based on AWS IoT FleetWise.\nLogical architecture for AWS IoT FleetWise solutions\nPersonas\nTwo personas who directly interact with AWS IoT FleetWise service are Data Engineer and Vehicle Engineer:\nData Engineer has a task to make the raw data from the vehicles usable by the stakeholders inside the organization. Specific stakeholders may vary depending on the use case.One example is a Quality Assurance department, who is interested in using vehicle data (e.g., temperature sensors) for the root cause analysis of vehicle quality issues. Another example is a team developing an EV battery health monitoring solution, who needs access to BMS system data each time EV battery temperature is above specific threshold.\nVehicle Engineer has a detailed knowledge of the vehicle ECUs and vehicle networks. In particular, the Vehicle Engineer is aware of both the signals provided by an individual ECU as well as encoding of these signals in a specific vehicle network (e.g., CAN bus).\nArchitectural layers\nIn order to understand the functionality of AWS IoT FleetWise we will discuss the individual layers of the architecture above.\nCollect, transform, and transfer of vehicle data (vehicle-side)\nAWS IoT FleetWise Edge Agent is a C++ software to collect, decode, normalize, cache, and ingest vehicle data to AWS. It supports multiple deployment options, such as vehicle gateways (e.g. NXP S32G2), infotainment systems, telecommunication control units or aftermarket devices. At the time of publishing, it supports decoding for CAN Bus and OBD2 messages. AWS IoT FleetWise Edge Agent is available on GitHub under Amazon Software License 1.0.\nTransport vehicle data to the cloud\nTo transfer the data over to the cloud, Edge Agent uses AWS IoT Core. It provides a secure, scalable, and cost-efficient MQTT/TLS connectivity.\nOrchestrate vehicle data collection\nFleet Operators can use AWS IoT FleetWise service to build and run vehicle data collection pipelines, both for the purpose of manual ad-hoc analysis as well as automated continuous vehicle data processing. They can use the following features of AWS IoT FleetWise:\nManage data collection campaigns. A data collection campaign defines which vehicle data and under which conditions shall be collected.\nRoute the vehicle data to the purpose-built database or storage services. At the time of publishing of this blog, AWS IoT FleetWise supports Amazon Timestream service. Amazon S3 will be supported after GA.\nModel signals and vehicles\nBefore a Data Engineer can create a data collection pipeline, the Vehicle Engineer builds a virtual representation of the vehicles in the cloud. Three key concepts for vehicle modelling with AWS IoT FleetWise are Signal catalog, Vehicle model and Decoder Manifest.\nSignal catalog is a central, company-wide repository of vehicle signals organized in a hierarchical way. It allows you to abstract underlying vehicle implementation details and establish a \xe2\x80\x9ccommon language\xe2\x80\x9d across the vehicle fleet.For example, the current charging rate of an EV could be modeled as sensor with data type \xe2\x80\x9cfloat\xe2\x80\x9d and addressable by the full qualified name \xe2\x80\x9cPowertrain.Battery.Charging.ChargeRate\xe2\x80\x9d. The signal catalog is based on COVESA`s Vehicle Signal Specification (VSS).\nThe Vehicle model refers to a subset of the signals from the signal catalog with a purpose to model a vehicle type sharing the same signals.\nDecoder manifest contains decoding instructions to transform binary data from the vehicle networks (e.g., CAN) into human-readable.\nIn an example of CAN bus-based communication, decoder manifest could contain instructions on how to transform a binary CAN bus message with Message id 123 and value 0x0011000 to value 17 of BMS.Battery.BatteryTemperature.\nStore vehicle data\nAWS IoT FleetWise stores the collected vehicle data in purpose-built storage services:\nAmazon Timestream is a fast, scalable, and server-less time series database. We recommend using it to store vehicle data that requires near real-time processing.\nAmazon S3 is a cloud object storage with industry-leading scalability, data availability, security, and performance. We recommend using it to store vehicle data which requires batch processing.\nAnalyze and act on vehicle data\nOnce the vehicle data is stored, it can be analyzed using AWS services for Analytics, Machine Learning and Application Integration, or visualized using Amazon Managed Grafana (visualization and dashboarding) or Amazon QuickSight (business intelligence).\nIntroducing an example solution for battery health monitoring\nNow, let\xe2\x80\x99s review an example solution that implements the logical architecture outlined before. You can use this solution to monitor health of the battery in an EV and to notify the driver once the health issue is detected. Below you see an architecture of the solution:\nSample solution for for battery health monitoring\nThe solution includes the following components:\n1. Vehicle engineer models vehicles and configures decoding rules\nFirst, the Vehicle Engineer uses their deep knowledge of the vehicle design to configure the necessary cloud resources for the AWS IoT FleetWise service (via AWS Management console, AWS CLI or AWS APIs). These resources include Signal catalog , Vehicle model , Decoder manifest , and Vehicle instances .\n2. Data engineer starts vehicle data collection campaign\nNow, the Data Engineer can initiate a data collection campaign in AWS IoT FleetWise (via AWS Management console , AWS CLI or AWS APIs). The campaign configuration contains data like:\nUnique names of the vehicle signals to be collected and transferred to the cloud\nFor time-based campaigns, a sampling rate for the signal collection\nFor condition-based campaigns, a logical expression used to recognize what data to collect (e.g., $variable.BatteryTemperature > 40.0)\n3. AWS IoT FleetWise sends campaign configuration to the Edge Agent running on the vehicle.\nAWS IoT Core service provides secure and scalable transport of data between AWS cloud and the Edge Agent.\n4. The Edge Agent runs the data collection campaign\nFirst, the Edge Agent collects the signals specified in the campaign configuration from the vehicle network. In case of intermittent connectivity, the Edge Agent will temporarily store the vehicle data and continue the ingestion once connectivity is available.\n5.The Edge Agent ingests the collected vehicle data to the AWS.\nAWS IoT Core service provides secure and scalable transport of data between the Edge Agent and AWS cloud.\n6. AWS IoT FleetWise stores vehicle data\nFor data persistence we will use Amazon Timestream, a fast, scalable, and server-less time series database.\n7. Battery health detection service analyses vehicle data\nThe battery health detection component is implemented using an AWS Lambda function. The Amazon EventBridge service will be configured to run the AWS Lambda function at a regular rate.\nOn each run the AWS Lambda function queries the vehicle data and analyzes the results to identify the battery health issues. For each identified battery health issue, the AWS Lambda function will ingest a message into Amazon Kinesis Data Streams .\n8. Battery management service acts on battery health data\nThe battery management component will be implemented using an AWS Lambda function. It will process the battery health insights from the data stream. For each insight that requires a user notification, it will retrieve the driver\xe2\x80\x99s contact data from Amazon DynamoDB and send a notification request to an Amazon Simple Queue Service (SQS)\n9. Notification handler service sends an SMS notification to the driver\nThe notification handler service reads the notification request from Amazon SQS, enriches the Vehicle Identification Number (VIN) data of the vehicle with the contact data of the current vehicle driver, and sends a message to the driver via Amazon Simple Notification Service (SNS)\nSummary and next steps\nIn this first part of the blog post, you have learned about the use cases, technical capabilities, and a logical architecture of a solution based on AWS IoT FleetWise. Then, we reviewed an architecture of an example solution for battery health monitoring. In the second part of this blog post, we will walk you through the implementation steps for the example solution in your AWS account.\nAbout the author\nAndrei Svirida is Senior Specialist Solutions Architect at Amazon Web Services. He is passionate about enabling companies of all sizes and industries to become data-driven businesses. To that end, he helps AWS customers to architect and build secure and scalable solutions on AWS, focusing on IoT, Analytics and Data Engineering. Prior to joining AWS, Andrei worked at KUKA AG as Head for IoT Delivery and as VP in in-house consulting at Deutsche Telekom AG. Andrei has a computer science background and more then 18 years of industry experience.'"
22,Building a Digital Twin with Photogrammetry and AWS IoT TwinMaker,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/building-a-digital-twin-with-photogrammetry-and-aws-iot-twinmaker/,"b'Introduction\nIn this blog post, you will learn how you can use photographs taken by a drone to create a 3D model of real world environments within a digital twin. Digital twins are virtual representations of physical systems that are regularly updated with data to mimic the structure, state, and behavior of the assets they represent. A digital twin can enable quicker and better decision-making, by connecting multiple data sources within a single pane of glass and providing actionable insights. However, building and managing digital twins from scratch is time-consuming, complicated, and costly. It requires a team of developers with varying and specialized skills working together to build integrated solutions that combine data from different sources. The developers must generate live insights from streaming data and create contextualized visualizations to better connect end users to the data. With AWS IoT TwinMaker, you can easily create digital twins of physical environments and build applications that provide an interactive 3D digital representation of large and complex physical structures through the browser.\nOverview\nOne of the key features of AWS IoT TwinMaker is the ability to import existing 3D models (e.g., CAD and BIM models or point cloud scans) into an AWS IoT TwinMaker scene and then overlay data sourced from other systems over this visualization. The AWS IoT TwinMaker scene uses a real-time WebGL viewport and supports the glTF format. While CAD and BIM models represent the structure of an asset as designed, in some cases, such models may not exist, or the asset as built may differ from the design. It is valuable to provide a 3D model within the digital twin that reflects the current reality as closely as possible. There are a number of mechanisms available to create a 3D model of the real world, with two popular approaches being laser scanning and photogrammetry.\nLaser scanning uses specialized and often costly equipment to create highly accurate 3D models of physical environments. In contrast, photogrammetry is the process of extracting 3D information from overlapping 2D photographs using computer vision techniques, including Structure from Motion (SfM).\nThis post focuses on using a low-cost aerial photography platform (a consumer-level quadcopter \xe2\x80\x93 the DJI Phantom 4 Pro) combined with photogrammetry to create a photorealistic model of a large area representing an asset modeled in AWS IoT TwinMaker. Following this approach, you can quickly build a 3D model of an asset that may be prohibitively expensive or impossible to create using laser scanning. This model can be updated quickly and frequently by subsequent drone flights to ensure your digital twin closely reflects reality. It is important to note at the outset that this model will favor photorealism over the absolute accuracy of the generated model.\nIn this blog, we will also describe how you can capture a dataset of georeferenced photographs via automatic flight planning and execution. You can then feed those photographs through a photogrammetry processing pipeline that automatically creates a scene of the resultant 3D visualization within AWS IoT TwinMaker. We use popular free and open-source photogrammetry software to process the data into glTF format for import into AWS IoT TwinMaker. The processing pipeline also supports OBJ files that can be exported from DroneDeploy or other photogrammetry engines.\nSolution Walkthrough\nData acquisition\nPhotogrammetry relies on certain characteristics of source aerial photographs to create an effective 3D model, including:\nA high degree of overlap between images\nThe horizon not being visible in any of the photographs\nThe capture of both nadir and non-nadir photographs\nThe altitude of capture being based on the desired resolution of the model\nWhile it is possible for a skilled drone pilot to manually capture photographs to be used in photogrammetry, you can achieve more consistent results by automating the flight and capture. A flight planning tool can create an autonomous flight plan that captures images at relevant locations, elevations, and degree of overlap for effective photogrammetry processing. Shown below is the flight planning interface of DroneDeploy, a popular reality capture platform for interior and exterior aerial and ground visual data that we used to capture the images for our example.\nFigure 1 \xe2\x80\x93 DroneDeploy flight planning interface\nWe used the flight planning and autonomous operation capabilities of the DroneDeploy platform to capture data that represents an asset to be modeled in AWS IoT TwinMaker. The asset of interest is an abandoned power station in Fremantle, Western Australia. As shown in the previous screenshot, the flight was flown at the height of 160 feet, covering an area of 6 acres over the course of less than 9 minutes, and capturing 149 images. Following, we show two examples of the aerial photographs captured from the drone flight that were subsequently used to generate the 3D model, illustrating the high degree of overlap between images.\nFigure 2 \xe2\x80\x93 A high degree of image overlap for effective photogrammetry\nPhotogrammetry processing pipeline architecture\nOnce the aerial imagery has been captured, it must be fed through a photogrammetry engine to create a 3D model. DroneDeploy provides a powerful photogrammetry engine with the ability to export 3D models created by the engine in OBJ format, as shown in the following screenshot.\nFigure 3 \xe2\x80\x93 Export model\nWe have created a photogrammetry processing pipeline that leverages the NodeODM component of the popular free and open-source OpenDroneMap platform to process georeferenced images in a completely serverless manner. The pipeline leverages AWS Fargate and AWS Lambda for compute, creating as output a scene in AWS IoT TwinMaker that contains the 3D model created by OpenDroneMap.\nThe pipeline also supports processing of 3D models created by the DroneDeploy photogrammetry engine, creating a scene in AWS IoT TwinMaker from an OBJ file exported from DroneDeploy.\nThe photogrammetry processing pipeline architecture is illustrated in the following diagram.\nFigure 4 \xe2\x80\x93 Pipeline architecture\nThe execution of the pipeline using the OpenDroneMap photogrammetry processing engine follows these steps:\nA Fargate task is started using the NodeODM image of OpenDroneMap from the public docker.io registry\nA set of georeferenced images obtained by a drone flight are uploaded as a .zip file to the landing Amazon S3 bucket\nThe upload of the zip file results in the publication of an Amazon S3 Event Notification that triggers the execution of the Data Processor Lambda\nThe Data Processor Lambda unzips the file, starts a new processing job in NodeODM running in Fargate, and uploads all the images to the NodeODM task\nThe Status Check Lambda periodically polls the NodeODM task to check for completion of the processing job\nWhen the NodeODM processing job is complete, the output of the job is saved in the processed S3 bucket\nSaving of the output zip file results in the publication of an Amazon S3 Event Notification that triggers the glTF Converter Lambda\nThe glTF Lamba converts the OBJ output of the NodeODM processing job to a binary glTF file and uploads it to the workspace S3 bucket, which is associated with the AWS IoT TwinMaker workspace and is produced when the workspace is created by the CloudFormation stack\nThe glTF Lambda creates a new scene in the AWS IoT TwinMaker workspace with the glTF file\nIf you are utilizing the DroneDeploy photogrammetry engine to create the 3D model, you can upload the exported OBJ zip file directly to the Processed bucket, and steps 6-8 will complete as normal.\nWhen the photogrammetry processing pipeline completes execution, a new scene will be created in an AWS IoT TwinMaker workspace containing the generated 3D model, as shown below for the asset of interest.\nFigure 5 \xe2\x80\x93 Generated 3D scene in AWS IoT TwinMaker\nPrerequisites\nAn AWS account will be required to set up and execute the steps in this blog. An AWS CloudFormation template will configure and install the necessary VPC and networking configuration, AWS Lambda Functions, AWS Identity and Access Management (IAM) roles, Amazon S3 buckets, AWS Fargate Task, Application Load Balancer, Amazon DynamoDB table, and AWS IoT TwinMaker Workspace. The template is designed to run in the Northern Virginia region (us-east-1). You may incur costs on some of the following services:\nAmazon Simple Storage Service (Amazon S3)\nAmazon DynamoDB\nAmazon VPC\nAmazon CloudWatch\nAWS Lambda processing and conversion functions\nAWS Fargate\nAWS IoT TwinMaker\nSteps\nDeploy the photogrammetry processing pipeline\nDownload the sample Lambda deployment package. This package contains the code for the Data Processor Lambda, Status Check Lambda, and glTF Converter Lambda described above\nNavigate to the Amazon S3 console\nCreate an S3 bucket\nUpload the Lambda deployment package you downloaded to the S3 bucket created in the previous step. Leave the file zipped as is\nOnce the Lambda deployment package has been placed in S3, launch this CloudFormation Template\nIn the Specify Stack Details screen, under the Parameters section, do the following:\nUpdate the Prefix parameter value to a unique prefix for your bucket names. This prefix will ensure the stack\xe2\x80\x99s bucket names are globally unique\nUpdate the DeploymentBucket parameter value to the name of the bucket you uploaded the Lambda deployment package\nIf you are processing a large dataset, increase the Memory and CPU values for the Fargate task based on allowable values as described here\nChoose Create stack to create the resources for the photogrammetry processing pipeline\nOnce complete, navigate to the new S3 landing bucket. A link can be found in the Resources tab as shown below\nFigure 6 \xe2\x80\x93 Upload bucket resource\nUpload a zip file containing your images to the S3 bucket\nRunning the photogrammetry processing pipeline\nThe photogrammetry processing pipeline will automatically be initiated upon upload of a zip file containing georeferenced images. The processing job can take over an hour (depending on the number of images provided, and the CPU and memory provided within the Fargate processing task), and you can track the job\xe2\x80\x99s progress by looking at the status within the Amazon CloudWatch logs of the Status Check Lambda. When a processing job is active, the Status Check Lambda will output the status of the job when it runs (on a 5-minute schedule). The output includes the progress of the processing job as a percentage value, as shown below.\nFigure 7 \xe2\x80\x93 Photogrammetry job progress\nBuilding a digital twin based on the 3D model\nWhen the photogrammetry processing pipeline has completed and a new scene has been created in the AWS IoT TwinMaker workspace, you can start associating components bound to data sources using the 3D model to provide visual context for the data and provide visual cues based on data-driven conditions.\nYou can configure a dashboard using the AWS IoT TwinMaker Application Plugin for Grafana to share your digital twin with other users.\nClean up\nBe sure to clean up the work in this blog to avoid charges. Delete the following resources when finished in this order\nDelete any created scenes from your AWS IoT TwinMaker workspace\nDelete all files in the Landing, Processed, and Workspace S3 Buckets\nDelete the CloudFormation Stack\n'"
23,Use AWS IoT Core MQTT broker with standard MQTT libraries,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/use-aws-iot-core-mqtt-broker-with-standard-mqtt-libraries/,"b'Introduction\nAWS IoT Core connects Internet of Things (IoT) devices to AWS IoT and other AWS services. Devices and clients can use the MQTT protocol to publish and subscribe to messages. MQTT libraries, such as the AWS IoT Device SDKs, include open-source libraries, developer guides with samples, and porting guides so that you can build innovative IoT products or solutions on your choice of hardware platforms.\nCustomers ask us how they can use the AWS IoT Core message broker with standard MQTT libraries. The reasons for this request can be wanting to migrate from another MQTT broker to AWS IoT Core while currently using standard MQTT libraries, or they might already be using standard MQTT libraries.\nIn this post you will learn how you can use standard MQTT libraries for different languages like Python, Node.js, or Java to interact with the AWS IoT Core message broker. The MQTT libraries covered in this post support the MQTT protocol version 5. AWS IoT Core recently launched support for MQTT version 5. To get started and to learn more about MQTT5 for AWS IoT Core, refer to the technical documentation.\nMetadata\nTime to read: 8 minutes\nLearning level: 300\nServices used: AWS IoT Core\nPrerequisites\nTo execute the walkthrough in this post, you need to have an AWS account and permissions to provision IoT things.\nWalkthrough\nFor the examples in this post, you will use a device with the name mqtt5. For device authentication you will use an X.509 certificate which is not issued by AWS IoT Core. Create a certificate with openssl and register it with AWS IoT Core without a CA. For ease of use, create an open IoT policy. In general, you should use permissions which follow the principle of least privilege.\nCreate a device\nUse the following commands to create your device.\n# assign the thing name to a shell variable \nTHING_NAME=mqtt5 \n# create the thing in the AWS IoT Core device registry \naws iot create-thing --thing-name $THING_NAME \n# create a key pair \nopenssl req -x509 -newkey rsa:2048 -keyout $THING_NAME.private.key -out $THING_NAME.certificate.pem -sha256 -days 365 -nodes -subj ""/CN=$THING_NAME"" \n# register the device certificate with AWS IoT Core \naws iot register-certificate-without-ca --certificate-pem file://$THING_NAME.certificate.pem --status ACTIVE > /tmp/register_certificate.json\nCERTIFICATE_ARN=$(jq -r "".certificateArn"" /tmp/register_certificate.json)\nCERTIFICATE_ID=$(jq -r "".certificateId"" /tmp/register_certificate.json) \n# create an IoT policy \nPOLICY_NAME=${THING_NAME}_Policy\naws iot create-policy --policy-name $POLICY_NAME \\\n  --policy-document \'{""Version"":""2012-10-17"",""Statement"":[{""Effect"":""Allow"",""Action"": ""iot:*"",""Resource"":""*""}]}\'\n# attach the policy to your certificate aws iot attach-policy --policy-name $POLICY_NAME \\   \n  --target $CERTIFICATE_ARN \n# attach the certificate to your thing\naws iot attach-thing-principal --thing-name $THING_NAME \\\n  --principal $CERTIFICATE_ARN\nBash\nIoT endpoint\nAssign your AWS IoT Core endpoint to a shell variable. This makes it easier to use your endpoint in the examples in the blog post.\nexport IOT_ENDPOINT=$(aws iot describe-endpoint --endpoint-type iot:Data-ATS --query \'endpointAddress\' --output text)\nBash\nRoot CA certificate\nDownload the root CA certificate that is used to sign AWS IoT Core\xe2\x80\x99s server certificate. Store the root CA certificate in the file AmazonRootCA1.pem.\nHiveMQ MQTT CLI\nThe MQTT CLI is an open source project backed by HiveMQ. It supports MQTT 3.1.1 and MQTT 5.0. You can use the MQTT CLI to interact with the AWS IoT Core message broker. The HiveMQ MQTT CLI is executed as mqtt.\nSubscribe\nSubscribe to the topic hivemq/with/aws with MQTT version 5.\nmqtt sub -h $IOT_ENDPOINT -p 8883 \\\n  --cafile AmazonRootCA1.pem \\\n  --cert mqtt5.certificate.pem \\\n  --key mqtt5.private.key \\\n  -d -V 5 -q 0 \\\n  -t hivemq/with/aws\nBash\nPublish\nLet the subscriber run and publish a message to the topic hivemq/with/aws. You should see the message arrive at the subscriber. The following command publishes one message. Execute the command multiple times to publish any number of messages.\nmqtt pub -h $IOT_ENDPOINT -p 8883 \\\n  --cafile AmazonRootCA1.pem \\\n  --cert mqtt5.certificate.pem \\\n  --key mqtt5.private.key \\\n  -d -V 5 -q 0 \\\n  -t hivemq/with/aws \\\n  -m ""{\\""mqtt5\\"": \\""arrived\\"", \\""client lib\\"": \\""hivemq\\"", \\""date\\"": \\""$(date)\\""}""\nBash\nYou will see all messages that you published arrive at the subscriber.\nMosquitto\nEclipse Mosquitto is an open source message broker and provides publish \xe2\x80\x93 mosquitto_pub \xe2\x80\x93 and subscribe \xe2\x80\x93 mosquitto_sub \xe2\x80\x93 clients.\nSubscribe with mosquitto_sub to a topic\nYou use mosquitto_sub to subscribe to a topic and mosquitto_pub to publish to the same topic. AWS IoT Core routes the messages from the publisher to the subscriber.\nSubscribe\nUse the mosquitto_sub client to subscribe to the topic mosquitto/with/aws.\nmosquitto_sub --cafile AmazonRootCA1.pem \\\n  --cert $THING_NAME.certificate.pem \\\n  --key $THING_NAME.private.key -h $IOT_ENDPOINT -p 8883 \\\n  -q 0 -t mosquitto/with/aws -i ${THING_NAME}-sub \\\n  --tls-version tlsv1.2 -d -V mqttv5\nBash\nPublish\nPublish multiple messages with the mosquitto_pub client. To publish multiple messages, create a file containing the messages and mosquitto_pub reads the messages from that file.\nCreate a file named messages.json with the following content.\n{""mqtt5"": ""arrived"", ""message"": ""1""}\n{""mqtt5"": ""arrived"", ""message"": ""2""}\n{""mqtt5"": ""arrived"", ""message"": ""3""}\nJSON\nPublish a message using a topic alias. A topic alias is an integer number that can be used instead of a topic name. The first publish request introduces a topic alias for a topic. All subsequent publishing requests then use the topic alias instead of the topic name. In the following example, you use the topic alias 2 for the topic mosquitto/with/aws.\ncat messages.json |mosquitto_pub --cafile AmazonRootCA1.pem \\\n  --cert $THING_NAME.certificate.pem \\\n  --key $THING_NAME.private.key -h $IOT_ENDPOINT -p 8883 \\\n  -q 0 -t mosquitto/with/aws -i $THING_NAME --tls-version tlsv1.2 \\\n  -d -V mqttv5 -D publish topic-alias 2 -l\nBash\nThe output from the publish requests should look similar to the following output:\nClient mqtt5 sending CONNECT\nClient mqtt5 received CONNACK (0)\nClient mqtt5 sending PUBLISH (d0, q0, r0, m1, \'mqtt5\', ... (36 bytes))\nClient mqtt5 sending PUBLISH (d0, q0, r0, m2, \'(null)\', ... (36 bytes))\nClient mqtt5 sending PUBLISH (d0, q0, r0, m3, \'(null)\', ... (36 bytes))\nClient mqtt5 sending DISCONNECT\nBash\nOnly the first publish request includes the topic name. For the subsequent requests you will get \'(null)\' as topic which means that the topic alias is used.\nAt the subscriber, you can observe incoming messages from the publisher.\nPaho Python Client\nThe following code snippets demonstrate how you can use AWS IoT Core Eclipse Paho Python Client library. Connect to AWS IoT Core first. Upon a successful connection, you can calculate the topic alias and subscribe to the topic. Then you can publish to a topic.\nMQTT Client\nCreate an MQTT version 5 client with handlers for a successful connection, and when a message arrives, connect to the AWS IoT Core endpoint. In this example, the root CA certificate, device certificate, device key, and endpoint are provided as command line options.\nmqttc = mqtt.Client(protocol=mqtt.MQTTv5)\nmqttc.tls_set(\n    ca_certs=args.ca,\n    certfile=args.certificate,\n    keyfile=args.key,\n    tls_version=2)\nmqttc.on_connect = on_connect\nmqttc.on_message = on_message\nmqttc.connect(args.endpoint, 8883, 60)\nPython\nConnection handler\nUpon connection, the MQTT client will receive a CONNACK from AWS IoT Core that includes the maximum usable topic alias. Based on the maximum usable topic alias, the code generates a random topic alias in the range from 0 to the maximum topic alias.\ndef on_connect(mqttc, userdata, flags, rc, properties=None):\n    global TOPIC_ALIAS_MAX\n    LOGGER.info(""connected to endpoint %s with result code %s"", args.endpoint, rc)\n    LOGGER.info(""userdata: %s, flags: %s properties: %s"", userdata, flags, properties)\n    LOGGER.info(""topic_alias_maximum: %s"", properties.TopicAliasMaximum)\n    TOPIC_ALIAS_MAX = properties.TopicAliasMaximum\n    mqttc.is_connected = True\n\n    LOGGER.info(\'subscribing to topic: %s\', args.topic)\n    mqttc.subscribe(args.topic, qos=0, options=None, properties=None)\n\ntopic_alias = random.SystemRandom().randint(0,TOPIC_ALIAS_MAX)\nPython\nWhen a message is received by the on_message handler, it will be logged.\ndef on_message(mqttc, userdata, msg):\n    LOGGER.info(\'received message: topic: %s payload: %s\', msg.topic, msg.payload.decode())\nPython\nTo define a topic alias for your topic name, you can publish the first message including the topic alias and topic name. All subsequent messages will be published in a while loop using the topic alias.\nproperties.TopicAlias = topic_alias\nmessage = json.dumps({""mqttv5"": ""has arrived"", ""date_time"": datetime.now().strftime(\'%Y-%m-%d %H:%M:%S\'), ""topic_alias"": topic_alias})\nLOGGER.info(\'publish: topic: %s message: %s\', args.topic, message)\nmqttc.publish(args.topic, payload=message, qos=0, retain=False, properties=properties)\n\nwhile True:\n    message = json.dumps({""mqttv5"": ""has arrived"", ""date_time"": datetime.now().strftime(\'%Y-%m-%d %H:%M:%S\'), ""topic_alias"": topic_alias})\n    LOGGER.info(\'publish: topic_alias: %s message: %s\', topic_alias, message)\n    mqttc.publish(\'\', payload=message, qos=0, retain=False, properties=properties)\n    time.sleep(2)\nPython\nMQTT.js\nIn the previous section you learned how to use the Paho Python Client. Paho also provides a JavaScript client that uses WebSockets to connect to the MQTT broker. The MQTT.js client library supports not only websockets, but also TLS connections with certificate based authentication. The following Node.js code snippets assume that you provide the root CA, device private key and certificate, as well as the AWS IoT Core endpoint and topic in the command line. In this example, you will also use a topic alias to publish messages. MQTT Client Build a client to connect to AWS IoT Core with MQTT version 5.\nconsole.log(\'building client\');\nconst client = mqtt.connect(\n    \'mqtts://\' + argv.e + \':8883\',\n    {\n        key:  fs.readFileSync(argv.k),\n        cert: fs.readFileSync(argv.c),\n        ca: [ fs.readFileSync(argv.ca) ],\n        protocolId: \'MQTT\',\n        protocolVersion: 5,\n    }\n);\nJavaScript\nConnection handler\nUpon a successful connection, get the maximum topic alias advertised by AWS IoT Core. Calculate the topic alias with a random function and set the publish properties to use the topic alias. Subscribe to the topic you are publishing to and publish a message using both the topic and topic alias.\nclient.on(\'connect\', function () {\n    topicAliasMax = client.topicAliasSend.numberAllocator.max;\n    topicAlias = Math.floor(Math.random() * (topicAliasMax - 0 + 1) + 0);\n    console.log(\'topicAliasMax: \' + topicAliasMax + \' topicAlias: \' + topicAlias);\n    console.log(\'subscribe to: \' + argv.t);\n    publishOptions.properties.topicAlias = topicAlias;\n\n    console.log(\'subscribe: topic: \' + argv.t);\n    client.subscribe(argv.t, function (err) {\n        if (err) {\n            console.log(\'subscribe error: \' + err);\n        } else {\n            var message = generateMessage();\n            console.log(\'publish first message to set topicAlias: \' + topicAlias + \' topic: \' + argv.t + \' message: \' + message);\n            client.publish(argv.t, message, publishOptions);\n        };\n    });\n});\nJavaScript\nReceive messages\nMessages received will be logged to the console.\nclient.on(\'message\', (topic, message) =&gt; {\n  console.log(\'message received: subscription topic: \' + argv.t + \' topic: \' + topic + \' message: \' + message.toString());\n});\nJavaScript\nPublish messages\nPublish messages continuously using the topic alias.\nsetInterval(function () {\n    var message = generateMessage();\n    console.log(\'publish: topic: \' + argv.t + \' message: \' + message);\n    client.publish(\'\', message, publishOptions);\n}, 5000);\nJavaScript\nYou should see messages arriving at your subscriber, which logs them to the console.\nCleaning Up\nDelete the thing that you created, and delete the associated certificate and IoT policy. You can find detailed steps in the How to manage things with the registry documentation.\n'"
24,Training the Amazon SageMaker object detection model and running it on AWS IoT Greengrass – Part 3 of 3: Deploying to the edge,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/part-3-1024x569-1.png,https://aws.amazon.com/blogs/iot/sagemaker-object-detection-greengrass-part-3-of-3/,"b'Post by Angela Wang and Tanner McRae, Senior Engineers on the AWS Solutions Architecture R&D and Innovation team\nThis post is the third in a series on how to build and deploy a custom object detection model to the edge using Amazon SageMaker and AWS IoT Greengrass. In the previous 2 parts of the series, we walked you through preparing training data and training a custom object detection model using the built-in SSD algorithm of Amazon SageMaker. You also converted the model output file into a deployable format. In this post, we take the output file and show you how to run the inference on an edge device using AWS IoT Greengrass.\nHere\xe2\x80\x99s a reminder of the architecture that you are building as a whole:\nFollowing the steps in your AWS account\nYou are welcome to follow the upcoming steps in your own AWS account and on your edge device. Parts 1 and part 2 are not prerequisites for following this section. You can use either a custom model that you have trained or the example model that we provided (under the CDLA Permissive license).\nSet up environment and AWS IoT Greengrass Core on an edge device\nBefore you get started installing AWS IoT Greengrass core on your edge device, make sure you check the hardware and OS requirements. For this post, we used an Amazon EC2 instance with the Ubuntu 18.04 AMI. Although it\xe2\x80\x99s not a real edge device, we often find it helpful to use an EC2 instance as a testing and development environment for AWS IoT use cases.\nDevice setup\nFor GPU-enabled devices, make sure you have the GPU drivers, such as CUDA, installed. If your device only has CPUs, you can still run the inference but with slower performance.\nAlso make sure to install MXNet and OpenCV, which is required to run the model inference code, on your edge device. For guidance, see documentation here.\nNext, configure your device, and install the AWS IoT Greengrass core software following the steps in Set up environment and install AWS IoT Greengrass software.\nAlternately, launch a test EC2 instance with the preceding setup completed by launching this AWS CloudFormation stack:\nCreate an AWS IoT Greengrass group\nNow you are ready to create an AWS IoT Greengrass group in the AWS Cloud. There are few different ways to do this and configure AWS Lambda functions to run your model at the edge:\nUsing Greengo, an open-source project for defining AWS IoT Greengrass resources in a config file and managing deployment through command line: this is the option detailed in this post.\nUsing the AWS IoT Greengrass console: For steps, see Configure AWS IoT Greengrass on AWS IoT.\nUsing AWS CloudFormation: For an example setup, see Automating AWS IoT Greengrass Setup With AWS CloudFormation.\nIn this post, we walk you through setting up this object detection model using Greengo. Our team prefers the Greengo project to manage AWS IoT Greengrass deployment, especially for use in a rapid prototyping and development setting. We recommend using AWS CloudFormation for managing production environments.\nOn a macOS or Linux computer, use git clone to download the sample code that we provided if you haven\xe2\x80\x99t done so already. The commands shown here have not been tested on Windows.\nIn the greengrass/ folder, you see a greengo.yaml file, which defines configurations and Lambda functions for an AWS IoT Greengrass group. The top portion of the file defines the name of the AWS IoT Greengrass group and AWS IoT Greengrass cores:\nGroup:\n  name: GG_Object_Detection\nCores:\n  - name: GG_Object_Detection_Core\n    key_path: ./certs\n    config_path: ./config\n    SyncShadow: True\nYAML\nFor the initial setup of the AWS IoT Greengrass group resources in AWS IoT, run the following command in the folder in which you found greengo.yaml.\npip install greengo\ngreengo create\nBash\nThis creates all AWS IoT Greengrass group artifacts in AWS and places the certificates and config.json for AWS IoT Greengrass Core in ./certs/ and ./config/.\nIt also generates a state file in .gg/gg_state.json that references all the right resources during deployment:\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 .gg\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 gg_state.json\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 certs\n\xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 GG_Object_Detection_Core.key\n\xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 GG_Object_Detection_Core.pem\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 GG_Object_Detection_Core.pub\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 config\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 config.json\nCopy the certs and config folder to the edge device (or test EC2 instance) using scp, and then copy them to the /greengrass/certs/ and /greengrass/config/ directories on the device.\nsudo cp certs/* /greengrass/certs/\nsudo cp config/* /greengrass/config/\nBash\nOn your device, also download the root CA certificate compatible with the certificates Greengo generated to the /greengrass/certs/ folder:\ncd /greengrass/certs/\nsudo wget -O root.ca.pem https://www.symantec.com/content/en/us/enterprise/verisign/roots/VeriSign-Class%203-Public-Primary-Certification-Authority-G5.pem\nBash\nStart AWS IoT Greengrass core\nNow you are ready to start the AWS IoT Greengrass core daemon on the edge device.\n$ sudo /greengrass/ggc/core/greengrassd start\nSetting up greengrass daemon\nValidating hardlink/softlink protection\nWaiting for up to 1m10s for Daemon to start\n...\nGreengrass successfully started with PID: 4722\nBash\nInitial AWS IoT Greengrass group deployment\nWhen the AWS IoT Greengrass daemon is up and running, return to where you have downloaded the code repo from GitHub on your laptop or workstation. Then, go to the greengrass/ folder (where greengo.yaml resides) and run the following command:\ngreengo deploy\nBash\nThis deploys the configurations you define in greengo.yaml to the AWS IoT Greengrass core on the edge device. So far, you haven\xe2\x80\x99t defined any Lambda functions yet in the Greengo configuration, so this deployment just initializes the AWS IoT Greengrass core. You add a Lambda function to the AWS IoT Greengrass setup after you do a quick sanity test in the next step.\nMXNet inference code\nAt the end of the last post, you used the following inference code on a Jupyter notebook. In the run_model/ folder, review how you put this into a single Python class MLModel inside model_loader.py:\nclass MLModel(object):\n    """"""\n    Loads the pre-trained model, which can be found in /ml/od when running on greengrass core or\n    from a different path for testing locally.\n    """"""\n    def __init__(self, param_path, label_names=[], input_shapes=[(\'data\', (1, 3, DEFAULT_INPUT_SHAPE, DEFAULT_INPUT_SHAPE))]):\n        # use the first GPU device available for inference. If GPU not available, CPU is used\n        context = get_ctx()[0]\n        # Load the network parameters from default epoch 0\n        logging.info(\'Load network parameters from default epoch 0 with prefix: {}\'.format(param_path))\n        sym, arg_params, aux_params = mx.model.load_checkpoint(param_path, 0)\n\n        # Load the network into an MXNet module and bind the corresponding parameters\n        logging.info(\'Loading network into mxnet module and binding corresponding parameters: {}\'.format(arg_params))\n        self.mod = mx.mod.Module(symbol=sym, label_names=label_names, context=context)\n        self.mod.bind(for_training=False, data_shapes=input_shapes)\n        self.mod.set_params(arg_params, aux_params)\n\n    """"""\n    Takes in an image, reshapes it, and runs it through the loaded MXNet graph for inference returning the top label from the softmax\n    """"""\n    def predict_from_file(self, filepath, reshape=(DEFAULT_INPUT_SHAPE, DEFAULT_INPUT_SHAPE)):\n        # Switch RGB to BGR format (which ImageNet networks take)\n        img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n        if img is None:\n            return []\n\n        # Resize image to fit network input\n        img = cv2.resize(img, reshape)\n        img = np.swapaxes(img, 0, 2)\n        img = np.swapaxes(img, 1, 2)\n        img = img[np.newaxis, :]\n\n        self.mod.forward(Batch([mx.nd.array(img)]))\n        prob = self.mod.get_outputs()[0].asnumpy()\n        prob = np.squeeze(prob)\n\n        # Grab top result, convert to python list of lists and return\n        results = [prob[0].tolist()]\n        return results\nPython\nTest inference code on device directly (optional)\nAlthough optional, it\xe2\x80\x99s always helpful to run a quick test on the edge device to verify that the other dependencies (MXNet and others) have been set up properly.\nWe have written a unit test test_model_loader.py that tests the preceding MLModel class. Review the code in this GitHub repository.\nTo run the unit test, download the code and machine learning (ML) model artifacts to the edge device and kick off the unit test:\ngit clone https://github.com/aws-samples/amazon-sagemaker-aws-greengrass-custom-object-detection-model.git\ncd amazon-sagemaker-aws-greengrass-custom-object-detection-model/greengrass/run_model/resources/ml/od\nwget https://greengrass-object-detection-blog.s3.amazonaws.com/deployable-model/deploy_model_algo_1-0000.params\ncd ../../..\npython -m unittest test.test_model_loader.TestModelLoader\nBash\nAfter the unit tests pass, you can now review how this code can be used inside of an AWS IoT Greengrass Lambda function.\nCreating your inference pipeline in AWS IoT Greengrass core\nNow that you have started AWS IoT Greengrass and tested the inference code on the edge device, you are ready to put it all together: create an AWS IoT Greengrass Lambda function that runs the inference code inside the AWS IoT Greengrass core.\nTo test the AWS IoT Greengrass Lambda function for inference, create the following pipeline:\nA Lambda function that contains the object detection inference code is running in AWS IoT Greengrass core BlogInfer.\nThe AWS IoT topic blog/infer/input provides input to the BlogInfer Lambda function for the location of the image file on the edge device to do inference on.\nThe IoT topic blog/infer/output publishes the prediction output of the BlogInfer Lambda function to the AWS IoT message broker in the cloud.\nChoose lifecycle configuration for AWS IoT Greengrass Lambda function\nThere are two types of AWS IoT Greengrass Lambda functions: on-demand or long-lived. For doing ML inference, you must run the model in a long-lived function because loading an ML model into memory can often take 300 ms or longer.\nRunning ML inference code in a long-lived AWS IoT Greengrass Lambda function allows you to incur the initialization latency only one time. When the AWS IoT Greengrass core starts up, a single container for a long-running Lambda function is created and stays running. Every invocation of the Lambda function reuses the same container and uses the same ML model that has already been loaded into memory.\nCreate Lambda function code\nTo turn the preceding inference code into a Lambda function, you created a main.py as the entry point for Lambda function. Because this is a long-lived function, initialize the MLModel object outside of the lambda_handler. Code inside the lambda_handler function gets called each time new input is available for your function to process.\nimport greengrasssdk\nfrom model_loader import MLModel\nimport logging\nimport os\nimport time\nimport json\n\nML_MODEL_BASE_PATH = \'/ml/od/\'\nML_MODEL_PREFIX = \'deploy_model_algo_1\'\n\n# Creating a Greengrass Core sdk client\nclient = greengrasssdk.client(\'iot-data\')\nmodel = None\n\n# Load the model at startup\ndef initialize(param_path=os.path.join(ML_MODEL_BASE_PATH, ML_MODEL_PREFIX)):\n    global model\n    model = MLModel(param_path)\n\ndef lambda_handler(event, context):\n    """"""\n    Gets called each time the function gets invoked.\n    """"""\n    if \'filepath\' not in event:\n        logging.info(\'filepath is not in input event. nothing to do. returning.\')\n        return None\n\n    filepath = event[\'filepath\']\n    logging.info(\'predicting on image at filepath: {}\'.format(filepath))\n    start = int(round(time.time() * 1000))\n    prediction = model.predict_from_file(filepath)\n    end = int(round(time.time() * 1000))\n\n    logging.info(\'Prediction: {} for file: {} in: {}\'.format(prediction, filepath, end - start))\n\n    response = {\n        \'prediction\': prediction,\n        \'timestamp\': time.time(),\n        \'filepath\': filepath\n    }\n    client.publish(topic=\'blog/infer/output\', payload=json.dumps(response))\n    return response\n\n# If this path exists, then this code is running on the greengrass core and has the ML resources to initialize.\nif os.path.exists(ML_MODEL_BASE_PATH):\n    initialize()\nelse:\n    logging.info(\'{} does not exist and you cannot initialize this Lambda function.\'.format(ML_MODEL_BASE_PATH))\nPython\nConfigure ML resource in AWS IoT Greengrass using Greengo\nIf you followed the step to run the unit test on the edge device, you had to copy the ML model parameter files manually to the edge device. This is not a scalable way of managing the deployment of the ML model artifacts.\nWhat if you regularly retrain your ML model and continue to deploy newer versions of your ML model? What if you have multiple edge devices that all should receive the new ML model? To simplify the process of deploying a new ML model artifact to the edge, AWS IoT Greengrass supports the management of machine learning resources.\nWhen you define an ML resource in AWS IoT Greengrass, you add the resources to an AWS IoT Greengrass group. You define how Lambda functions in the group can access them. As part of AWS IoT Greengrass group deployment, AWS IoT Greengrass downloads the ML artifacts from Amazon S3 and extracts them to directories inside the Lambda runtime namespace.\nThen your AWS IoT Greengrass Lambda function can use the locally deployed models to perform inference. When your ML model artifacts have a new version to be deployed, you must redeploy the AWS IoT Greengrass group. The AWS IoT Greengrass service automatically checks if the source file has changed and only download the new version if there is an update.\nTo define the machine learning resource in your AWS IoT Greengrass group, uncomment this section in your greengo.yaml file. (To use your own model, replace the S3Uri with your own values.)\nResources:\n  - Name: MyObjectDetectionModel\n    Id: MyObjectDetectionModel\n    S3MachineLearningModelResourceData:\n      DestinationPath: /ml/od/     \n      S3Uri: s3://greengrass-object-detection-blog/deployable-model/deploy_model.tar.gz\nYAML\nUse the following command to deploy the configuration change:\ngreengo update && greengo deploy\nBash\nIn the AWS IoT Greengrass console, you should now see an ML resource created. The following screenshot shows the status of the model as Unaffiliated. This is expected, because you haven\xe2\x80\x99t attached it to a Lambda function yet.\nTo troubleshoot an ML resource deployment, it\xe2\x80\x99s helpful to remember that AWS IoT Greengrass has a containerized architecture. It uses filesystem overlay when it deploys resources such as ML model artifacts.\nIn the preceding example, even though you configured the ML model artifacts to be extracted to /ml/od/, AWS IoT Greengrass actually downloads it to something like /greengrass/ggc/deployment/mlmodel/<uuid>/. To your AWS IoT Greengrass local Lambda function that you declare to use this artifact, the extracted files appear to be stored in/ml/od/ due to the filesystem overlay.\nConfigure the Lambda function with Greengo\nTo configure your Lambda function and give it access to the machine learning resource previously defined, uncomment your greengo.yaml file:\nLambdas:\n  - name: BlogInfer\n    handler: main.lambda_handler\n    package: ./run_model/src\n    alias: dev\n    greengrassConfig:\n      MemorySize: 900000 # Kb\n      Timeout: 10 # seconds\n      Pinned: True # True for long-lived functions\n      Environment:\n        AccessSysfs: True\n        ResourceAccessPolicies:\n          - ResourceId: MyObjectDetectionModel\n            Permission: \'rw\'\nYAML\nYou didn\xe2\x80\x99t specify the language runtime for the Lambda function. This is because, at the moment, the Greengo project only supports Lambda functions running python2.7.\nAlso, if your edge device doesn\xe2\x80\x99t already have greengrasssdk installed, you can install greengrasssdk to the ./run_model/src/ directory and have it included in the Lambda deployment package:\ncd run_model/src/\npip install greengrasssdk -t .\nBash\nUsing GPU-enabled devices\nIf you are using a CPU-only device, you can skip to the next section.\nIf you are using an edge device or instance with GPU, you must enable the Lambda function to access the GPU devices, using the local resources feature of AWS IoT Greengrass.\nTo define the device resource in greengo.yaml, uncomment the section under Resources:\n  - Name: Nvidia0\n    Id: Nvidia0\n    LocalDeviceResourceData:\n      SourcePath: /dev/nvidia0\n      GroupOwnerSetting:\n        AutoAddGroupOwner: True\n  - Name: Nvidiactl\n    Id: Nvidiactl\n    LocalDeviceResourceData:\n      SourcePath: /dev/nvidiactl\n      GroupOwnerSetting:\n        AutoAddGroupOwner: True\n  - Name: NvidiaUVM\n    Id: NvidiaUVM\n    LocalDeviceResourceData:\n      SourcePath: /dev/nvidia-uvm\n      GroupOwnerSetting:\n        AutoAddGroupOwner: True\n  - Name: NvidiaUVMTools\n    Id: NvidiaUVMTools\n    LocalDeviceResourceData:\n      SourcePath: /dev/nvidia-uvm-tools\n      GroupOwnerSetting:\n        AutoAddGroupOwner: True\nYAML\nTo enable the inference Lambda function to access the device resources, uncomment the following section inside the ResourceAccessPolicies of the Lambda function.\n         - ResourceId: Nvidia0\n           Permission: \'rw\'\n         - ResourceId: Nvidiactl\n           Permission: \'rw\'\n         - ResourceId: NvidiaUVM\n           Permission: \'rw\'\n         - ResourceId: NvidiaUVMTools\n           Permission: \'rw\'\nYAML\nConfigure topic subscriptions with Greengo\nLastly, to test invoking the inference Lambda function and receiving its outputs, create subscriptions for inputs and outputs for the inference Lambda function. Uncomment this section in your greengo.yaml file:\nSubscriptions:\n# Test Subscriptions from the cloud\n- Source: cloud\n  Subject: blog/infer/input\n  Target: Lambda::BlogInfer\n- Source: Lambda::BlogInfer\n  Subject: blog/infer/output\n  Target: cloud\nYAML\nTo deploy these configurations to AWS IoT Greengrass, run the following command.\ngreengo update && greengo deploy\nBash\nWhen the deployment is finished, you can also review the subscription configuration in the AWS IoT Greengrass console:\nAnd if you check the Lambda function that was deployed, you can see that the ML resource is now affiliated with it:\nTest AWS IoT Greengrass Lambda function\nNow you can test invoking the Lambda function. Ensure that you download an image (example) to your edge device, so that you can use it to test the inference.\nIn the AWS IoT Greengrass console, choose Test, and subscribe to the blog/infer/output topic. Then, publish a message blog/infer/input specifying the path of the image to do inference on the edge device:\nYou should have gotten back bounding box prediction results.\nTake it to real-time video inference\nSo far, the implementation creates a Lambda function that can do inference on an image file on the edge device. To have it perform real-time inference on a video source, you can extend the architecture. Add another long-lived Lambda function that captures video from a camera, extracts frames from video (similar to what we did in part 1), and passes the reference of the image to the ML inference function:\n  Resource cleanup\nKeep in mind that you are charged for resources running on AWS, so remember to clean up the resources if you have been following along:\nDelete the AWS IoT Greengrass group by running greengo remove.\nShut down the Amazon SageMaker notebook instance.\nDelete the AWS CloudFormation stack if you used a test EC2 instance to run AWS IoT Greengrass.\nClean up S3 buckets used.\n'"
25,Your guide to find AWS IoT for Automotive at CES 2023,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2023/01/03/blog-image-1024x576.png,https://aws.amazon.com/blogs/iot/your-guide-to-find-aws-iot-for-automotive-at-ces-2023/,"b'Overview\nThe Consumer Electronics Show (CES) 2023 will take place Jan 5-8 in Las Vegas, USA. CES is one of the most influential global technology events, covering nearly every aspect of the technology sector. You can find Amazon Web Services (AWS) alongside Amazon Smart Vehicles in the \xe2\x80\x9cAmazon for Automotive\xe2\x80\x9d exhibit to check out the newest vehicle technology and latest innovations from Amazon, AWS, and AWS Partners.\nYou can find the Amazon for Automotive exhibit at booth #4001 in the West Hall of the Las Vegas Convention Center (LVCC) \xe2\x80\x93 that hall is entirely dedicated to Vehicle Technology. Multiple AWS representatives will be on site to host informational meetings. If you\xe2\x80\x99re looking to have a deeper discussion, you can request a meeting with AWS here.\nAWS IoT for Automotive demos\nThere will be many great demos on display at the Amazon for Automotive booth and throughout the event. If you want to learn about the latest from AWS IoT for Automotive and AWS IoT FleetWise, be sure to check out these demos:\nGoing from OBD to EVD \xe2\x80\x93 standardize EV data collection with AWS IoT FleetWise\nAmazon for Automotive | LVCC West Hall | Booth 4001\nThe On-Board Diagnostics (OBD) standard has helped automakers collect diagnostic data from internal combustion engine vehicles in a standardized way, but the same standards don\xe2\x80\x99t exist for Electric Vehicle Data (EVD). EV manufacturers, suppliers, systems integrators, and charging infrastructure providers have proprietary and siloed data, making it difficult to continuously detect anomalies, predict remaining useful life, and improve range estimates.\nIn this demo, you\xe2\x80\x99ll learn how AWS IoT FleetWise enables standardized data collection that scales across fleets of EVs. To demonstrate one of the many use cases enabled by standardized EV data, we will walk you through how AWS IoT FleetWise can help collect and interpret battery cell-level data across a fleet of EVs, for the purposes of continuously monitoring EV battery health.\nEnabling software-defined vehicles \xe2\x80\x93 accelerate vehicle software development with the cloud\nAmazon for Automotive | LVCC West Hall | Booth 4001\nAutomotive manufacturers and suppliers are dealing with complexities that arise from the use of traditional processes to develop software for modern, Software-Defined Vehicles (SDVs). Early and extensive testing utilizing the power of the cloud is the new paradigm that companies must adopt. It provides the agility to enhance the driver and passenger\xe2\x80\x99s experience throughout the entire lifecycle of the vehicle.\nEnvironmental parity is the main prerequisite to make this vision possible. It allows developers to reproduce in the cloud an environment where an onboard workload could run, without noticing differences from its ultimate home within the vehicle. This demo showcases how a real automotive workload that connects to a Controller Area Network (CAN bus) using AWS IoT FleetWise can be developed in the cloud and deployed on an Arm-based vehicle component leveraging the Scalable Open Architecture for Embedded Edge (SOAFEE) Framework.\nDigital customer experience \xe2\x80\x93 frictionless parts, service scheduling, and payments\nAmazon for Automotive | LVCC West Hall | Booth 4001\nBuild a direct and continuous brand relationship with vehicle owners while creating data-driven programs and campaigns that generate value and excite customers with personalized service experiences in and out of the vehicle, including predictive and pre-emptive maintenance notifications and scheduling.\nIn this demo, you\xe2\x80\x99ll see how \xe2\x80\x98always-on\xe2\x80\x99 customer relationships are enabled with Amazon, Salesforce, and Stripe for an entirely new customer lifecycle experience. Attendees will learn how Salesforce and AWS IoT FleetWise manage vehicle exception events with frictionless service scheduling and how to address customer needs during vehicle ownership, including purchase experience, accessorizing, part installation, maintenance, and repair.\nConnected vehicles made easier with AWS and Automotive Grade Linux\nAutomotive Grade Linux | LVCC West Hall | Booth 4141\nTraditional methods of vehicle data collection and storage are unable to scale with the needs of modern automotive Original Equipment Manufacturers (OEMs). There is a demand for cost-effective solutions to remotely deploy vehicle software and collect near real-time data at scale for fleet management and autonomous driving use cases.\nThis hands-on demo showcases how connected vehicle solutions with AWS and Automotive Grade Linux (AGL) help OEMs collect, transform, and transfer near real-time vehicle data to the cloud, including remote deployment and management. You will test drive a simulated vehicle and experience how AWS IoT FleetWise capabilities extend across various vehicle connectivity systems, including the NXP GoldBox and Renesas R-Car, while running an AGL distribution. You\xe2\x80\x99ll also learn how AWS IoT FleetWise leverages custom event-driven campaigns and storage options to optimize costs for OEMs.\nIntegration of the neoVI Red 2 data logger with AWS IoT FleetWise\nIntrepid Control Systems | LVCC North Hall | Booth 3761\nIntrepid Control Systems is excited to demonstrate the integration of AWS IoT FleetWise with Intrepid data loggers, enabling real-time data collection and analysis for automaker fleets. This powerful solution allows for improved efficiency and effectiveness in operations, resulting in cost savings and enhanced customer satisfaction. With the ability to wirelessly log data in a standalone fashion, Intrepid data loggers provide a comprehensive solution for automaker fleet management and analytics using the advanced capabilities of AWS IoT FleetWise.\nHow NXP is enabling intelligent connected EVs\nNXP | LVCC Central Plaza | Booth CP-18\nThis demo showcases how NXP provides end-to-end automotive processing platforms for intelligent connected vehicles from the battery and e-motor to the cloud. It integrates NXP\xe2\x80\x99s battery management solution, traction inverter control, GreenBox real-time development platform, GoldBox vehicle networking reference design, and OrangeBox connectivity domain controller development platform. The S32G GoldBox includes the GoldVIP vehicle integration platform, which integrates AWS IoT Greengrass to support edge run-time and cloud services, AWS IoT SiteWise for cloud visualization of vehicle data, and AWS IoT FleetWise to intelligently collect electric vehicle data. With GoldVIP, NXP customers can immediately start using AWS cloud services out-of-the-box to rapidly prototype connected EV applications.\n'"
26,Enable compliance and mitigate IoT risks with automated incident response,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/enable-compliance-and-mitigate-iot-risks-with-automated-incident-response/,"b'Introduction\nInternet of Things (IoT) devices can present unique security challenges ranging from malware, DDoS attacks, and logical or physical compromise. You can prepare for such events by having a process in place to mitigate these risks when they occur. The IoT Lens of the Well-Architected Framework provides high-level guidance on how to be prepared for incidents that impact your IoT devices. In addition, various compliance frameworks such as Payment Card Industry Data Security Standard (PCI DSS), Health Insurance Portability and Accountability Act (HIPAA), and NIST Special Publication 800-53 include requirements to maintain actionable incident response plans for systems.\nAWS IoT Device Defender can audit, monitor, and detect potential security incidents. These capabilities help secure IoT application deployments using Amazon Web Services (AWS) IoT Core. However, a complete incident response typically requires properly tracking the incident, coordinating response across multiple teams, and ensuring execution of predefined incident response runbooks. This post provides a working example of preparing for and automating the incident response workflow for AWS IoT-managed devices. It helps to quickly mitigate risks and respond to security events that could arise throughout your IoT infrastructure.\nSolution\nThe following solution provides an example of automating your response to incidents involving IoT devices by implementing AWS IoT Device Defender and AWS Systems Manager (AWS SSM) Incident Manager. Use AWS CloudFormation to deploy this automated solution to manage your IoT incident response as code.\nIoT Response Automated Workflow\nAWS IoT Device Defender detects a Security Profile violation on an IoT device and sends an Amazon Simple Notification Service (Amazon SNS) alert.\nThe alert invokes an AWS Lambda Function to initiate the incident process in Incident Manager, a capability of AWS Systems Manager, using a predefined response plan.\nThe Incident Manager response plan starts the incident response workflow using a custom runbook (automation document) for handling IoT incidents.\nA Lambda function is invoked to start containment procedures, which adds affected thing(s) to a Quarantine Thing Group where they can be isolated using AWS IoT Core Policies. The Deployment Steps of this blog post contain instructions on how to create a static Thing Group for Quarantining devices.\nThe second step in the runbook notifies the predetermined point(s) of contact of the IoT incident, where a team member can acknowledge the incident and begin mitigation and analysis procedures defined as instructions in the runbook\nAn escalation point of contact engages within a configured duration if the incident is not acknowledged.\nIoT Incident Response Lifecycle\nPreparation\nPreparation is critical for effectively responding to an incident when it happens and enabling faster mitigation. It involves defining the personnel who will respond to an incident, the roles and responsibilities of those involved, ensuring necessary tools are available, enabling logs, and automating repetitive tasks.\nThe example solution creates an AWS Systems Manager Automation document representing a runbook for IoT-specific responses. A runbook is the documented form of an organization\xe2\x80\x99s procedures for conducting a series of tasks and can involve both manual and automated actions. This document is standardized in YAML and can be modified, updated, and version controlled. It orchestrates automation with human activities in response to an IoT device incident. The runbook in the provided example should be tailored based on your specific requirements and use cases.\nDetection\nAny deviation of a device\xe2\x80\x99s normal security baseline can be considered a security incident. This example uses AWS IoT Device Defender to detect those deviations using preconfigured security profiles that define how a device should behave. The example implements incident response for the following common types of scenarios:\nUnauthorized configurations (rule-based) \xe2\x80\x93 A secure IoT device should limit accessible TCP/UDP ports to only those necessary. Any unexpected TCP/UDP services listening on a device indicates a security risk due to compromise or a misconfiguration. A rule-based security profile monitors such events.\nAnomalies in behavior (Machine Learning based) \xe2\x80\x93 AWS IoT Device Defender can detect deviations from normal device behavior through machine learning. This capability includes connection attempts, network traffic, and authorization failures. A machine learning-based security profile monitors such events.\nBehavior that deviates from a defined security profile in either scenario of this solution will trigger a violation in AWS IoT Device Defender, automatically initiating an incident response plan.\nContainment, Analysis and Recovery\nFor this solution, AWS SSM Incident Manager initiates a response plan using a predefined SSM automation document for IoT security violations. The automation document consists of multiple steps to be taken as a response, which can involve automated and manual actions.\nContainment\nThe first step in the example SSM automation document will invoke a Lambda function which performs actions to prepare the device for further investigation and mitigation. In this example solution, the IoT device will automatically be placed on a separate IoT Quarantine group for isolation to isolate and prepare the device for further investigation.\nAnalysis and Mitigation\nAfter containment, the incident response plan will orchestrate the manual steps of the response, such as notifying appropriate personnel and providing instructions for investigation and resolution. Next, the containment Lambda function engages with the predefined security point(s) of contact. Those contacts will receive and acknowledge a new incident email notification.\nInvestigating any incident typically involves determining basic answers to who, what, when, where, and why. Detecting compromised data is essential for IoT incident response to confirm data validity and accuracy.\nPerform forensic analysis on the device in either online or offline mode.\nOnline analysis. AWS IoT SSH access can optionally be enabled through a secure tunnel for a security engineer to access and evaluate the device.\nOffline access. Analysis can be performed using collected logs, data, and messages sent to IoT topics from the device.\nThe incident response in this solution provides links and other important information under Related Items of the incident when opening the Incident Manager console. This feature enables quick access for responders to the information they need.\nDirect links to query logs collected on the IoT devices in Amazon CloudWatch Logs Insights are included.\nRecovery\nThe recovery strategy for IoT incident response must consider several factors:\nIs the device mission critical? What happens if it becomes completely unavailable?\nAre there redundant devices that mitigate this unavailability?\nDoes the device contain sensitive data? What is the risk of keeping it online?\nIs the device currently operating and online? Can the resource be physically accessed?\nThese factors must be considered based on IoT use case(s) and documented as part of the incident response runbook before an incident occurs.\nPost-Incident Analysis\nAfter resolving any critical incident, a post-incident analysis should document the root cause, update stakeholders, identify the impact, and capture lessons learned. This post analysis can provide feedback for improvement in an organization\xe2\x80\x99s incident response. It will identify opportunities to update the response process.\nUpon resolution of an incident, AWS SSM Incident Manager will prompt to create a post-incident analysis with information on the event. Click Create analysis to begin the process.\nDeployment Steps for Automated Solution\nThis section reviews the steps to implement the example solution using AWS CloudFormation.\nSetup AWS Systems Manager (SSM) Incident Manager\nSuppose this is the first time using SSM Incident Manager in the account you will be deploying this solution. In that case, you must follow these steps to configure the service.\nOpen the Incident Manager console\nOn the Incident Manager service homepage, select Get prepared.\nChoose General settings.\nRead the onboarding acknowledgment. If you agree to Incident Manager\xe2\x80\x99s terms and conditions, check the I have read and agree to the AWS Systems Manager Incident Manager terms and conditions checkbox. Then select Next.\nSet up the replication using either an AWS Owned or a Customer Managed AWS Key Management Service (AWS KMS) key. All Incident Manager resources are encrypted. To learn more about how your data is encrypted, see Data Protection in Incident Manager. See Using the Incident Manager replication set for more information about your replication set.\nIf you want to use the AWS Owned key, choose Use AWS owned key, and then choose Create.\nIf you want to use a Customer Managed AWS KMS key, choose Choose a different AWS KMS key (advanced).\nYour current Region appears as the first Region in your replication set. Search for an AWS key in our account. If you have not created a key or need to create a new one, select the Create an AWS KMS key button.\nTo add more Regions to your replication set, choose Add Region.\nSelect the Create button to create your replication set and contacts. To learn more about replication sets and resiliency, see Resilience in AWS Systems Manager Incident Manager.\nCreate an AWS Simple Systems Manager (SSM) Contact\nAfter logging into an AWS account with the appropriate permissions, go to the AWS Systems Manager Incident Manager console\nSelect Contacts, and then select Create contact\nChoose the Create Contact button.\nType the full name of the contact and provide a unique and identifiable alias.\nDefine a Contact channel. We recommend having two or more different types of contact channels.\nChoose the type: email, SMS, or voice.\nEnter an identifiable name for the contact channel.\nProvide the contact channel details, such as email\nDefine the Engagement Plan\nIn the Contact channel name drop down, select one of the contact channels from step e, then add the Engagement time in minutes this contact should be notified after stage start\nClick Add engagement to optionally select any other contact channel from step e, along with the Engagement time\nClick Create to create the contact. The contact channel(s) will need to be activated through confirmation email/SMS/voice to be fully functional.\nCopy the Amazon Resource Name (ARN) of the contact you created for use when launching the SAM application\nCreate an IoT Thing Group for Quarantined Things\nGo to the AWS IoT console and select Manage > Thing Groups.\nUnder Create Thing Group, select Create a static thing group, then click Next.\nEnter the name QUARANTINED for the Thing group name, and leave other options in the default state.\nSelect the Create thing group button.\nPrerequisites for Launching the CloudFormation Stack\nThe code in GitHub provides a working example of the solution using AWS Serverless Application Module (SAM). Ensure you have met the following prerequisites to deploy the solution using SAM:\nAn AWS Account\nAWS Command Line Interface (AWS CLI) installed and configured. User guide here.\nAWS Serverless Application Model (SAM) installed. Overview and user guide here.\nAn Amazon Simple Storage Service (S3) Bucket for storing SAM-generated packaged templates. Overview here.\nLaunching the CloudFormation Stack\nInitialize the SAM project from the GitHub source repository\nsam init --location gh:aws-samples/aws-iot-incident-response-example\nIn the file samconfig.toml, modify the ssmEngagementContact field with the ARN of the contact you created in previous step \xe2\x80\x9cCreate an AWS Simple Systems Manager (SSM) Contact\xe2\x80\x9d\nPackage the SAM application\nsam package \\\n--template-file template.yaml \\\n--s3-bucket <S3_BUCKET_NAME> \\\n--output-template-file packaged-template.yaml\nDeploy the SAM application\nsam deploy \\\n--template-file packaged-template.yaml \\\n--stack-name aws-iot-incident-mgmt \\\n--capabilities CAPABILITY_IAM\nAfter launching the product, it can take from 3 to 5 minutes to deploy. When the product is deployed, it creates a new CloudFormation stack with a status of CREATE_COMPLETE as part of the provisioned product in the AWS CloudFormation console.\nIntegrating IoT Devices with the Automated Incident Response Workflow\nThis example solution deploys an incident response workflow which, by default, will be invoked when any IoT device violates the preconfigured Device Defender security profiles by the CloudFormation template.\nTesting the Automated Incident Response\nThis example requires IoT devices to be enabled to send device-side metrics to the IoT service. To test the solution using an Amazon EC2 instance:\nFollow the steps in the guide to Create a virtual device with Amazon EC2\nInstall the IoT Device Client on the virtual device created in Step 1\nFollow the Quick Start steps in the Device Client installation guide as listed\nDuring the client setup (when running setup.sh), ensure you specify y when prompted to Enable Device Defender feature?\nTrigger a security profile violation by opening an authorized port on the instance\nConnect to the EC2 instance using Session Manager\nInstall Netcat\nsudo yum install nc -y\nStart listening on an unauthorized port:\nsudo nc --listen 123\nValidate a rule violation for an unauthorized port has started the incident response process\nCheck the AWS IoT console after the AWS IoT Device Defender heartbeat time has elapsed (default is 300 seconds) to verify the \xe2\x80\x9cDeviceRuleBaseline\xe2\x80\x9d security profile has detected a violation\nCheck the Incident Manager console to verify a \xe2\x80\x9cCritical IoT Device Incident\xe2\x80\x9d has been created\nView the QUARANTINED Thing Group in the console. Under \xe2\x80\x9cThings\xe2\x80\x9d, verify that this group contains the thing representing the EC2 instance\nSummary\nIncident response is critical to mitigating risks and ensuring compliance with industry standards and regulations. Lack of an effective incident response process can lead to incidents having a longer recovery time and increased risk of compromise to data or system availability. Using AWS IoT Device Defender and AWS Systems Manager Incident Manager can help establish an automated workflow for quickly mitigating IoT incidents and ensuring devices maintain a secure configuration.\nTry out the AWS IoT Workshop dive deeper with AWS IoT Device Defender and check out the AWS Systems Manager Incident Manager documentation to learn more about what it offers.'"
27,How to reduce latency with Amazon Kinesis Video Streams – Part 2,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-reduce-video-latency-with-amazon-kinesis-video-streams-part-2/,"b'In this, part 2 on how to reduce latency in media managed by Amazon Kinesis Video Streams (KVS) I describe the techniques in which to configure KVS, the media producer and the media player for optimal latency settings. Then, I introduce the Amazon Kinesis Video Stream Web Viewer and perform a number of experiments on KVS to validate the latency figures you can expect to achieve under a variety of conditions.\nIn part 1, I covered the fundamentals of streaming media, KVS Operation, common design patterns and the leading contributing factors to latency in streaming media managed by KVS.\nReducing Latency of KVS Live Media\nThe most effective means of reducing latency of streaming media in KVS are the following:\nOptimize KVS provided HLS Playlist settings for live media,\nReduce the fragment length set by the KVS media producer,\nWhere supported by the media player:\nProgrammatically reduce fragment buffering by the media player,\nSet the playback speed to slightly above x1 (i.e x1.05 / x1.1) to keep up with the live edge of the media at all times.\nBe aware that adjusting buffer and fragment settings for low-latency typically comes as a trade off with video quality and re-buffering, especially during network instability. It\xe2\x80\x99s recommended to thoroughly test applied settings against the range of expected network conditions.\nFor robust live video quality with low-latency across a variety of network conditions:\nProvide 5 \xe2\x80\x93 10 fragments in the HLS Media Playlist and\nUse fragment length of 1 second.\nTo aggressively tune for latency (where network quality and / or media player supports):\nProvide 3 fragments in the HLS Media Playlist,\nUse fragments length of 0.5 seconds,\nProgrammatically limit the media player buffer to 2 \xe2\x80\x93 3 fragments depending on network quality and\nSet the media playback speed to slightly above x1 (x1.05 / x1.1) so as to keep up with the live edge of the media even during dropped fragments (this can cause more frequent re-buffering).\nRef: Latency too high between producer and player\nOptimizing KVS HLS Playlist Settings for Live Media\nThe KVS Archived Media API supports the GetHLSStreamingSessionURL call to request the HLS Media Playlist and access media fragments as shown in the following (simplified) sequence:\nFigure 1 \xe2\x80\x93 KVS Request (HLS) Playlist URL process flow.\nWhen an application requests the HLS Playlist URL from KVS, a number of settings are available to optimize for low latency streaming media. The below example is a simple python script that makes a request to the KVS GetHLSStreamingSessionURL API to return the URL of the HLS Media Playlist for the requested stream and settings:\nimport boto3\n\nKVS_STREAM_NAME = \'[ENTER_KVS_STREAM_NAME]\'\nREGION = \'[ENTER_AWS_REGION]\'\n\n#=====================================================\n# Create the AWS Kinesis Video client\nkvs = boto3.client(""kinesisvideo"", region_name=REGION)\n\n#=====================================================\n# Get the KVS endpoint for this stream\nendpoint = kvs.get_data_endpoint(\nAPIName=""GET_HLS_STREAMING_SESSION_URL"",\nStreamName=KVS_STREAM_NAME)[\'DataEndpoint\']\n\nprint(f\'\\nKVS ENDPOINT: {endpoint}\')\n\n#=====================================================\n# Get the KVS Archive media client\nkvam = boto3.client(""kinesis-video-archived-media"", endpoint_url=endpoint, region_name=REGION)\n\n# Get LIVE HLS URL\nhls_playback_url = kvam.get_hls_streaming_session_url(\nStreamName=KVS_STREAM_NAME,\nPlaybackMode=""LIVE"",\nMaxMediaPlaylistFragmentResults=3,\nExpires=43200)[\'HLSStreamingSessionURL\']\n\nprint(f\'\\nLIVE HLS_STREAMING_SESSION_URL: {hls_playback_url}\\n\')\nPython\nThe output of this script is the URL for the KVS Stream HLS Master Playlist (.m3u8) file. This URL can be passed directly as a link in supporting browsers such as Safari or to desktop media players like VLC to play the KVS media stream with the selected parameters. The HLS URL is returned with a SessionToken that provides time limited access to the KVS media so be careful with how you manage this URL.\nIn the above code, there are two parameters in particular to consider:\nPlaybackMode: When set to LIVE, the HLS media playlist is continually updated with the latest fragments as they become available. This will typically display the live notification in the media player and in some players will select preconfigured fragment buffer settings more suitable to low-latency media.\nMaxMediaPlaylistFragmentResults: The maximum number of fragments that are returned in the HLS media playlists. Limiting this can also limit fragment buffering by the media player and reduce latency. When the PlaybackMode is LIVE, the most recent fragments are returned up to this value. When the PlaybackMode is ON_DEMAND , the oldest fragments available are returned, up to this maximum number.\nTherefore; to reduce latency when requesting the KVS HLS Playlist URL, ensure the PlaybackMode is set to LIVE and it\xe2\x80\x99s recommended that MaxMediaPlaylistFragmentResults is set to at least 3 for low latency with robust media quality.\nReduce the Fragment Length Set by the KVS Media Producer\nFragment length of a media stream impacts latency as it determines the initial buffering and fragmentation time on the producer and the buffering time on the media player. Fragment lengths are set at the KVS producer and are preserved through the KVS service. And so, the fragment length created by the producer is what will be received and buffered by the media player or consumer. Below is an example of how to set the fragment length using a simple GStreamer media pipeline to KVS.\nUsing the GStreamer KVS Plugin:\nThe below GStreamer pipeline preforms a live screen capture on a MacOS device (avfvideosrc plugin), encodes the raw video to H.246 frames (vtenc_h264_hw plugin) and passes the encoded stream to the KvsSink plugin which ingests it to KVS. In the example, the requested frame rate from the camera and the key-frame interval on the encoder are both 20 FPS resulting in 1 second fragments.\ngst-launch-1.0 avfvideosrc capture-screen=true \\\n! videoconvert \\\n! videoscale \\\n! video/x-raw,width=1280,height=720,framerate=20/1 \\\n! vtenc_h264_hw allow-frame-reordering=FALSE realtime=TRUE max-keyframe-interval=20 \\\n! h264parse \\\n! video/x-h264,stream-format=avc,alignment=au,profile=baseline \\\n! kvssink stream-name=$STREAM_NAME aws-region=$REGION access-key=$ACCESS_KEY secret-key=$SECRET_KEY retention-period=$RETENTION_HRS\nBash\nTo reduce the fragments to 0.5 seconds, adjust the key-frame interval to 10 by adjusting the max-keyframe-interval value. With a key-frame interval of 10 and a frame-rate of 20 fps this will trigger 0.5 second fragments by the kvssink element. It\xe2\x80\x99s also valid in this example to increase the frame-rate to 40 fps by adjusting the framerate value if it\xe2\x80\x99s supported by the camera but this will have a much greater impact on the network bandwidth and KVS consumption costs for the media stream.\nUsing the KVS Producer Libraries:\nIf using the KVS Producer Libraries, you as the developer are responsible for the number of frames per fragment and the fragment length using the programmatic means available to adjust key-frame interval and frame rate ingested to KVS.\nProgrammatically Reducing Media Player Fragment Buffering\nIf developing a custom web or mobile application for consuming KVS media, most popular media player libraries support programmatic tuning of settings such as the number of fragments to buffer. An example of a KVS integrated web application is the Amazon Kinesis Video Streams Web Viewer, an AWS provided code sample you can host in your own AWS account to test and consume KVS media.\nKVS Web Viewer Demo Application:\nFigure 2 \xe2\x80\x93 KVS Web Viewer Application Screen Shot.\nThe KVS Web Viewer uses the react-player which calls on HLS.js library to play HLS based media such as presented from KVS. The KVS Web Viewer exposes all of the programmatic settings available in the hlsConfigs.js file. In particular, the hlsConfig.js parameters liveSyncDurationCount and liveMaxLatencyDurationCount have been reduced from the defaults to optimize for lower latency.\nUsing this example, you can deploy a KVS consumer web application with HLS and buffer settings exposed via a simple configuration file for test and development in your environment.\nSetting the Media Playback Speed to Slightly Above x1\nMedia players will often slip behind the live edge of the streaming media adding to video latency. This can be due to slight imperfections in timing between media producer and consumers or due to lost seconds during media re-buffering or network instability. Because this effect is accumulative, the impact is proportional to the length of the playback session and so the longer the media is expected to run in live playback mode the higher the impact. Therefore, this is especially relevant where a media source is displayed permanently on live monitor such as for a security camera or similar.\nOne technique to reduce latency being introduced due to media player falling behind the live edge is to set the media playback speed to slightly above x1 (i.e: x1.05 / 1.1 depending on media player support). This puts the media player into \xe2\x80\x98Catch-Up\xe2\x80\x99 mode that is constantly trying to out run the live edge. This keeps the media player as close to the live edge as possible but will in some cases cause the media to overrun the current fragment which will result in the media player being choppy. Because if this, it\xe2\x80\x99s only recommended to use this technique for long running or permanently monitored media sources.\nThe KVS Web Viewer discussed supports both x1.05 and x1.1 playback speeds, use this as a means to test the increased playback speed technique in your environment.\nValidating KVS Latency Values\nIn this section, I will test the described KVS HLS settings, fragment lengths, the custom KVS Web Viewer compared to direct viewing of a KVS stream in the Safari web browser and across global networks to validate latency values achievable under these specific conditions.\nTest Set-Up:\nThis test uses the above described GStreamer pipeline to ingest a live screen capture from a MacOS device to KVS. The Mac screen displays a millisecond accuracy stopwatch and the same KVS stream is consumed on a second monitor for comparison. The test is being performed from Melbourne, Australia using the AWS Sydney Region across a physical distance of ~900Kms and therefore an ~1800 Km round trip.\nFigure 3 \xe2\x80\x93 KVS latency test set-up and distance.\nUsing KVS Recommended Settings for Robust Video Quality:\nHLS PlaybackMode: Live\nHLS MaxMediaPlaylistFragmentResults: 7\nFragment Length: 1 Second\nFigure 4 \xe2\x80\x93 KVS latency test for robust video quality results.\nUsing the KVS Web Viewer with latency optimized buffer configuration, the recommended KVS HLS settings for robust video quality and 1-Second fragment length, latency was measured at 1.95 Seconds.\nThis exact test was run consuming the KVS HLS Playlist URL directly in the Safari web browser and measured 4.072 seconds. This difference is due to the fact that we can\xe2\x80\x99t control the number of fragments the Safari browser buffers and browsers are typically tuned for Video on Demand with media quality being a priority over low latency.\nAnd finally, this test was run again with the KVS Web Viewer but in the N.Virginia region, a round trip from Melbourne Australia of over 30,000Kms (20,000 mi) which measured 3.32 seconds end to end latency. This gives an approximate scale to the impact of distance on media latency. This could be reduced further by using services like the AWS Global Accelerator.\nUsing KVS Latency Optimized Settings:\nHLS PlaybackMode: Live\nHLS MaxMediaPlaylistFragmentResults: 5\nFragment Length: 0.5 Seconds\nFigure 5 \xe2\x80\x93 KVS latency test for latency optimised settings results.\nBy reducing the Fragment length to 0.5 seconds we were able to achieve an end to end latency of 1.412 seconds. Here, because we are using the KVS Web Viewer that allows us to programmatically configure the number of buffered fragments the MaxMediaPlaylistFragmentResults value that can otherwise influence media player buffer settings is not a leading contributor.\nRunning this same test but consuming the KVS media directly from the Safari web browser resulted in latency of 3.55 seconds.\n'"
28,How to reduce latency with Amazon Kinesis Video Streams – Part 1,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-reduce-video-latency-with-amazon-kinesis-video-streams-part-1/,"b'In this two part series I describe how to reduce latency of streaming media managed by Amazon Kinesis Video Streams and how less than 2-second latency can be delivered with robust video quality across a variety of network conditions. Then, I provide a practical demonstration showing that with the Amazon Kinesis Video Stream Web Viewer, latency of 1.4 seconds is possible with Amazon Kinesis Video Streams (KVS).\nIn this, part 1, I cover the fundamentals of streaming media, KVS Operation, common design patterns and the leading contributing factors to latency in streaming media managed by KVS.\nIn part 2, I describe the techniques in which to configure KVS, the media producer and the media player for optimal latency settings. Finally, I introduce the Amazon Kinesis Video Stream Web Viewer and perform a number of experiments on KVS to validate the latency figures you can expect to achieve under a variety of settings and configurations.\nAmazon Kinesis Video Streaming Media Format\nMedia is ingested into KVS using the GStreamer KVSSink plugin, KVS Producer Libraries or the KVS API but in all cases, the underlying ingress media format is Matroska (MKV) containerized segments. On the consumer side, live media is most commonly exposed to web and mobile applications using HTTP Live Streaming (HLS) delivered as fragmented MP4. Both the producer and consumers in this common KVS design pattern rely on streaming media techniques. This blog focuses on how to reduce end to end latency of streaming media using using this common KVS design pattern.\nFigure 1 \xe2\x80\x93 KVS Ingestion and storage of media presented as HLS to client applications.\nContributing Factors of Latency for Live Media on KVS\nEnd to end latency of streaming media via KVS is the sum of video encoding/decoding, fragmentation delay, network latency, KVS buffering and fragment buffering by the media player. To put a scale to these factors, the table below shows indicative latency values for a KVS media stream using parameters not well selected for live media resulting in a total latency of just less than 9.5 seconds.\nTable 1 \xe2\x80\x93 Indicative latency values for a KVS stream with settings poorly selected for live media.\nWhile the numbers presented here are representative, they do express a common start point for many new users of KVS and clearly show that to improve latency, we must consider video fragmentation and fragment buffering in more detail.\nStreaming Media and Video Fragmentation\nFor reliable and timely transmission of live media over the Internet, groups of encoded video frames are containerized in one of a number of formats such as MPEG-4 (MP4), QuickTime Movie (MOV) or Matroska (MKV). As each group of frames is wrapped in a media container, it becomes a self-contained transmissible unit known as a fragment which forms the basis of what we refer to as streaming media. The time it takes for a frame to be recorded, transmitted, buffered and displayed is what the end user experiences as latency.\nFigure 2 \xe2\x80\x93 H.264/265 encoded frames transmitted as streaming media fragments.\nVideo Encoding and Fragment Length\nH.264 / H.265 video encoders achieve a high compression ratio by only transmitting pixels that have changed between frames. Each fragment must start with a key-frame (or I-Frame) which contains all data (pixels) and provides a reference for proceeding Predicted-Frames (P-Frames), and Bi-directional Frames (B-Frames). It\xe2\x80\x99s enough to understand for this purpose that these frame types work together to describe the changing picture without transmitting unchanged data until the next key-frame is scheduled.\nThe number of frames between each key-frames is set by the encoder and is referred to as the key-frame interval. It\xe2\x80\x99s common in streaming media and KVS in particular, to trigger a new fragment on the arrival of each key-frame and so fragment length (measured in seconds) can generally be calculated as:\nFragment Length (secs) = Key-Frame Interval (# of frames) / Frames Per Second (fps).\nFigure 3 \xe2\x80\x93 H.264/265 frames types.\nFor example, a media stream with a key-frame interval of 30 and a frame rate of 15 fps will receive a key-frame every 2-seconds which with KVS video producers will generally result in 2-second fragment lengths. This is relevant as fragment length has a direct relationship to latency in streaming media.\nMedia Player Fragment Buffering\nAll media players will buffer some number of fragments to avoid degraded video quality during network instability. Media players include desktop players such as QuickTime and VLC, application libraries such as react-player used in custom web and mobile applications and the default media players found in the various web browsers.\nMedia player application libraries often expose the fragment buffer settings programmatically, whereas desktop and browser-based media players use preconfigured settings for live and on-demand video playback respectively.\nFragment buffering sits directly between the received media and the consumer and will contribute as much as 30 seconds latency if not specifically configured for live video. Fragment buffering by the media player is by far the leading contributor to latency for streaming media and can be calculated as shown in the following:\nFragment Buffer Latency (Secs) = Number of buffered fragments X Fragment length (secs).\nFigure 4 \xe2\x80\x93 Media player buffer induced latency.\nTherefore, to reduce latency; we must reduce the number of buffered fragments in the media player. Interestingly, most media player buffer settings are based on number of fragments, not total buffering time and so reducing the fragment length has a similar effect of reducing latency in streaming media.\nHLS Playlist\nHTTP Live Streaming (HLS) is an adaptive bitrate streaming protocol that exposes media fragments to media players via  HLS Media Playlist (.m3u8) file. This is a clear-text manifest file that contains media configuration tags and URL links to the required media fragments. Below is an extract of a HLS Media Playlist:\n#EXTM3U\n#EXT-X-VERSION:7\n#EXT-X-PLAYLIST-TYPE:EVENT\n#EXT-X-TARGETDURATION:1\n#EXT-X-MEDIA-SEQUENCE:1\n#EXT-X-INDEPENDENT-SEGMENTS\n#EXT-X-DISCONTINUITY\n#EXT-X-MAP:URI=""getMP4InitFragment.mp4?SessionToken==...&TrackNumber=1&SequenceNumber=1""\n#EXTINF:0.498,\ngetMP4MediaFragment.mp4?FragmentNumber=91343852333181769835329731216345997453612345678&SessionToken=...&TrackNumber=1&SequenceNumber=1""\n#EXT-X-DISCONTINUITY\n#EXTINF:0.5,\ngetMP4MediaFragment.mp4?FragmentNumber=91343852333181769840281491373487518686823456789&SessionToken=...&TrackNumber=1&SequenceNumber=1""\n#EXT-X-DISCONTINUITY\n#EXTINF:0.5,\ngetMP4MediaFragment.mp4?FragmentNumber=91343852333181769845233251530629039917934567890&SessionToken=...&TrackNumber=1&SequenceNumber=1""\nThe #COMMAND fields are configuration tags. For example, the #EXT-X-PLAYLIST-TYPE:EVENT tag indicates that fragments will continue to be appended to the manifest for as long as the live media producer is active. When set, the media player will continually poll the Playlist for updated fragments until an #EXT-X-ENDLIST tag (the HLS End Event) is received.\nThe getMP4MediaFragment.mp4 fields are appended to the base URL to create complete links to individual media fragments in KVS.\nKVS provides the means to request a HLS Media Playlist with a latency optimized configuration to support low latency media, even when users consume video on the device and media player of their choice.\n'"
29,Managing Docker container lifecycle with AWS IoT Greengrass,b'Yuri Chamarelli',2023-01-19T02:26:47+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/11/09/iot-blog-feature-img-1024x574.png,https://aws.amazon.com/blogs/iot/managing-docker-container-lifecycle-with-aws-iot-greengrass/,"b'Introduction\nIn this post, we will be discussing how to manage Docker container lifecycle using an AWS IoT Greengrass custom component. There are five phases in a Docker container lifecycle: create, run, pause/unpause, stop, and kill. The custom component interacts with the Docker Engine via the Docker SDK for Python to manage processes based on your use case, such as user initiated commands or an application sending commands.\nAWS IoT Greengrass is an open source Internet of Things (IoT) edge runtime and cloud service that helps you build, deploy and manage IoT applications on your devices. You can use AWS IoT Greengrass to build edge applications using pre-built software modules, called components, that can connect your edge devices to AWS services or third-party services.\nAWS IoT Greengrass components can represent applications, runtime installers, libraries, or any code that you would run on a device. You can configure AWS IoT Greengrass components to run a Docker container from images stored in the following locations:\nPublic and private image repositories in Amazon Elastic Container Registry (Amazon ECR)\nPublic Docker Hub repository\nPublic Docker Trusted Registry\nAmazon S3 bucket\nWhile Greengrass components have lifecycles of their own that you may interact with, these lifecycles do not support containerized processes. To start, stop, pause and resume a Docker container running on AWS IoT Greengrass, you can use commands such as Docker pause and Docker unpause via a Greengrass component running on a Greengrass core device. The custom lifecycle component, which we will refer to as the \xe2\x80\x98lifecycle component\xe2\x80\x99, consists of a Python script that subscribes to an AWS IoT Core MQTT topic and interacts with the Docker Engine.\nSolution Overview\nBelow is an example workflow and architecture for one possible implementation. With these building blocks in hand you can further expand to fit your specific use case.\nA user deploys a Docker container component and the lifecycle component to the Greengrass core device.\nThe application publishes a MQTT message to an AWS IoT Core topic. The MQTT message specifies the container name and desired action to be performed. In this example, we send a start command to the container named env.\nThe custom lifecycle component is subscribed to the topic.\nThe lifecycle component receives the message and then interacts with the Docker Engine via the Docker SDK for Python and executes the desired command on the container name specified.\nBased on the command received from the lifecycle component, the Docker Engine will pause, unpause, start, or stop the specified container.\nSolution Diagram\nImplementation Instructions\nPrerequisites\nThe AWS CLI is installed and configured.\nAWS Greengrass Core installed on your device.\nDocker Engine is installed and running.\nDeploy a Docker container to a Greengrass Core device\nFollow the instructions on how to run a Docker container with AWS Greengrass or optionally create and run a container with the Docker Engine itself. Be sure to provide a name for the container, in this example we use the name of env.\nVerify you have a running Docker container and that it has the desired name:\ndocker container ls\nBash\nCreate the custom lifecycle component\nTo create a Greengrass component we need to create the Python script that will contain our code and also a Greengrass recipe which will specify the deployment details when the component is deployed to a Greengrass Core device.\nCreate an empty folder and script file named customlifecycle.py.\nmkdir -p ~/artifacts && touch ~/artifacts/customlifecycle.py\nBash\nIn your favorite Integrated Development Environment (IDE), open customlifecycle.py and paste the following code. Be sure to save the file. Note: the code snippet below is under an MIT-0 license and is available on Github.\n#Imports\nimport time\nimport json\nimport traceback\nimport docker\nimport subprocess\nimport awsiot.greengrasscoreipc\nimport awsiot.greengrasscoreipc.client as client\nfrom awsiot.greengrasscoreipc.model import (\n    IoTCoreMessage,\n    QOS,\n    SubscribeToIoTCoreRequest\n)\n\nTIMEOUT = 10\nipc_client = awsiot.greengrasscoreipc.connect()\ntopic = ""docker""\nqos = QOS.AT_MOST_ONCE\n\n#IPC Stream Handler\nclass StreamHandler(client.SubscribeToIoTCoreStreamHandler):\n    def __init__(self):\n        super().__init__()\n\n    def on_stream_event(self, event: IoTCoreMessage) -> None:\n        message = json.loads(event.message.payload.decode())\n        \n        try:\n            client = docker.from_env()\n            name = message[""name""]\n            command = message[""command""]\n        \n            if command == ""start"":\n                container = client.containers.get(name)\n                container.start()\n                print(""Starting container: "" + name)\n        \n            elif command == ""pause"":\n                container = client.containers.get(name)\n                result = json.loads(container.pause())\n                print(result)\n                print(""Pausing container: "" + name)\n                \n            elif command == ""unpause"":\n                container = client.containers.get(name)\n                print(container.unpause())\n                print(""Unpausing container: "" + name)\n                \n            elif command == ""stop"":\n                container = client.containers.get(name)\n                container.stop()\n                print(""Stopping container: "" + name)\n                \n            else:\n                print(""Error"")\n            \n        except:\n            with tempfile.TemporaryFile() as tmp:\n            tmp.write(""Docker Error"")\n                \n    def on_stream_error(self, error: Exception) -> bool:\n        message_string = ""Error!""\n\n        return True\n\n    def on_stream_closed(self) -> None:\n        pass\n        \n#Initiate Subscription\nrequest = SubscribeToIoTCoreRequest()\nrequest.topic_name = topic\nrequest.qos = qos\nhandler = StreamHandler()\noperation = ipc_client.new_subscribe_to_iot_core(handler)\nfuture = operation.activate(request)\nfuture_response = operation.get_response()\nfuture_response.result(TIMEOUT)\n\nwhile True:\n    time.sleep(1)\n\noperation.close()\nPython\nCreate a bucket and retrieve your bucket name using the following command.\nEPOCH_TIME=$(date +""%s"") && S3_BUCKET=lifecycle-component-$EPOCH_TIME && aws s3 mb s3://$S3_BUCKET\nBash\nExecute the following command to create a folder and a file to put the recipe into.\nmkdir -p ~/recipes && touch ~/recipes/customlifecycle-1.0.0.json\nBash\nOpen the created recipe file customlifecycle-1.0.0.json and paste the following contents. Replace [YOUR BUCKET NAME] with the bucket name retrieved in the step 3.\n{\n    ""RecipeFormatVersion"": ""2020-01-25"",\n    ""ComponentName"": ""Docker-lifecycle-component"",\n    ""ComponentVersion"": ""1.0.0"",\n    ""ComponentType"": ""aws.greengrass.generic"",\n    ""ComponentDescription"": ""A component that interacts with Docker daemon."",\n    ""ComponentPublisher"": ""Amazon"",\n    ""ComponentConfiguration"": {\n      ""DefaultConfiguration"": {\n        ""accessControl"": {\n          ""aws.greengrass.ipc.mqttproxy"": {\n            ""docker_lifecycle:mqttproxy:1"": {\n              ""policyDescription"": ""Allows access to subscribe to all topics."",\n              ""operations"": [\n                ""aws.greengrass#SubscribeToIoTCore""\n              ],\n              ""resources"": [\n                ""*""\n              ]\n            }\n          }\n        }\n      }\n    },\n    ""Manifests"": [\n      {\n        ""Lifecycle"": {\n          ""Install"": ""pip3 install awsiotsdk"",\n          ""Run"": ""python3 -u {artifacts:path}/customlifecycle.py""\n        },\n        ""Artifacts"": [\n          {\n            ""Uri"": ""s3://[YOUR BUCKET NAME]/customlifecycle.py""\n          }\n        ]\n      }\n    ]\n  }\nJSON\nUpload the component artifacts to Amazon Simple Storage Service.\naws s3 cp --recursive ~/artifacts/ s3://$S3_BUCKET/\nBash\nNext, we will publish the Greengrass component by running the following command.\ncd ~/recipes && aws greengrassv2 create-component-version --inline-recipe fileb://customlifecycle-1.0.0.json\nBash\nYou can now see this has been added to your AWS IoT Console -> Greengrass -> Components -> My Components.\nDeploy the custom lifecycle component\nNow we will deploy the custom lifecycle component to your Greengrass Core device using the AWS CLI. Deployments may be applied to Things or Thing Groups. In this case, we will apply the deployment directly to the Greengrass Core thing entity.\nCreate a deployment manifest folder and file using the command below.\nmkdir -p ~/deployments && touch ~/deployments/gg_deployment.json\nBash\nIn your IDE, copy and paste the below into the gg_deployment.json file. Update the [targetARN] with your Thing ARN. You may retrieve your Thing ARN from the AWS IoT Core console. Be sure to save the file.\n{\n  ""targetArn"": ""[targetArn]"",\n  ""deploymentName"": ""Deployment for Custom Docker Lifecycle"",\n  ""components"": {\n    ""Docker-lifecycle-component"": {\n      ""componentVersion"": ""1.0.0""\n    }\n  }\n}\nJSON\nCreate the deployment with the following command.\ncd ~/deployments && aws greengrassv2 create-deployment --cli-input-json file://gg_deployment.json\nBash\nVerify that the component is now running on your Greengrass Core device. It may take several minutes for it to instantiate.\nsudo /greengrass/v2/bin/greengrass-cli component list\nBash\nTest the Custom Lifecycle component\nGo to  AWS IoT Core console, select the MQTT test client.\nSelect Publish to topic.\nIn the Topic name, enter docker\nIn the Message payload, copy in the message below. The command syntax will depend on the name and current state of your container.\n{\n  ""command"":""start"",\n  ""name"":""env""\n}\nJSON\nVerify that the state of your container has changed.\ndocker container ls\nBash\n'"
30,Introducing the new AWS IoT Core Device Location feature to support Asset Tracking solutions,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/introducing-the-new-aws-iot-core-device-location-feature-to-support-asset-tracking-solutions/,"b'Introduction\nAWS IoT Core Device Location is a new managed feature of AWS IoT Core that enables customers to choose the appropriate location technology that works within their business and engineering constraints, without relying on Global Positioning System (GPS) hardware. With location data, customers can optimize business processes, simplify and automate maintenance efforts, and unlock new business use cases such as asset tracking solutions across several industry verticals including retail, farming, transportation and more.\nLocation information is important for Internet of Things (IoT) applications. Historically, GPS has been widely used for locating an IoT device, but not all IoT devices can be equipped with a GPS hardware due to its high power requirements, relatively larger device footprint, and higher integration costs. New technologies such as cloud-assisted Global navigation satellite system (GNSS), WiFi, and cellular triangulation have become popular alternatives to obtain location data for IoT devices. However, the challenge with these technologies is that they do not directly provide location data in a usable format. This means you will have to first calculate the Geo-coordinates based on data received from devices running on one of these technologies, and then use a mapping service to place a dot on the map. AWS IoT Core Device Location is integrated with solutions offered by AWS Partners, such as Semtech, HERE, and MaxMind. Their technology enables the use of cloud-assisted GNSS, WiFi scan, cellular triangulation, and reverse IP lookup techniques to determine Geo-coordinates for a device in a standard format. You can use the new Location Action feature from AWS IoT Core Rules Engine, launched in Oct 2022, to route the Geo-coordinates to Amazon Location Service where you can add maps and points of interest, track resources, define Geo-fencing models, and visualize device location information.\nAWS IoT core Device location is generally available for AWS IoT Core. In this blog, we will look at how you can use AWS IoT Core for LoRaWAN and AWS IoT Core Device Location to calculate location data (i.e. Geo-coordinates), when the devices do not have a built-in GPS module. Subsequently, we will discuss how you can use AWS IoT Rule Location action and Amazon Location Service to build a location-based application.\nLoRaWAN is a Low Power Wide Area (LPWA) protocol for battery-operated, remote monitoring and control applications, standardized by LoRa Alliance. LoRaWAN technology provides robust indoor and outdoor coverage for IoT applications. Lately, LoRaWAN has been applied to a variety of applications including smart water metering, smart buildings, safety and compliance monitoring, smart agriculture, health monitoring, smart electrical metering, construction and mining operations, and smart homes.\nIntegration with AWS IoT Core for LoRaWAN\nAWS IoT Core for LoRaWAN is a fully-managed feature that allows you to connect and manage wireless devices that use LoRaWAN connectivity with the AWS Cloud. Using AWS IoT Core for LoRaWAN, you can setup a private LoRaWAN network by connecting the LoRaWAN devices and gateways to the AWS Cloud. This eliminates the undifferentiated work and operational burden of managing a Network Server(NS), and enables you to quickly connect and secure LoRaWAN device fleets at scale.\nThe sections below illustrate how devices connect and publish data to AWS IoT Core for LoRaWAN and AWS IoT Core Device Location, gather decoded location data from various log-stream sources, and use third party location solvers to show a dot on the map without developing custom code or application.\nReference architecture\nFigure 1 \xe2\x80\x93 Architecture for AWS IoT Core Device Location\nThe devices communicate to AWS IoT Core for LoRaWAN. The payload is processed by AWS IoT Core Device Location which resolves the position to give you the location of your tracker. An IoT Rule is triggered upon the incoming data from the tracker and sent to Amazon Location Service to see the location point on the map.\nOEM Partners\nWe have partnered with three original equipment manufacturers (OEM) who have developed LoRaWAN trackers that are qualified to work AWS IoT Core Device Location without the need to write custom code or application.\nRYODEN and SMK developed an edge device that uses energy harvesting feature, and lower communication costs, thanks to the use of LoRaWAN technology. This device connects to AWS IoT Core for LoRaWAN from their LoRaWAN gateway to reduce the server maintenance resources. Using the GNSS Solver function, the solution is also capable of supporting the asset tracking feature.\nMiromico has developed a TrackIt Kit that works with AWS IoT Core Device Location to help customers track location assets.\nMIKROTIC has developed asset trackers based on AWS IoT Core Device Location. Their devices are expected to be made available for shipment in 2023.\nBrowen has developed asset trackers based on AWS IoT Core Device location, and device is available now.\nUsing AWS IoT Core Device Location\nPre-requisites\nAWS IoT Core permissions to provisioning IoT things\nAWS IoT Core for LoRaWAN compatible gateway device\nAWS IoT Core location compatible device\nStep 1: Setup LoRaWAN gateway referring to the instructions LoRaWAN gateway in AWS IoT Core for LoRAWAN\nStep 2: Provision LoRaWAN device\nAdd a wireless device\nFor LoRaWAN specification, select OTAA v1.0x\nProvide DevEUI \xe2\x80\x93 The 16-digit hexadecimal DevEUI value found on your wireless device.\nProvide AppKey \xe2\x80\x93 The 32-digit hexadecimal AppKey value that your wireless device vendor provided.\nProvide AppEUI \xe2\x80\x93 The 16-digit hexadecimal AppEUI that your wireless device vendor provided.\nFigure 2 \xe2\x80\x93 Add device details\nFor Wireless device name, enter \xe2\x80\x98tracker\xe2\x80\x99\nFor Wireless device profile, refer to add device profiles section\nFigure 3 \xe2\x80\x93 Device profile\n3. For Service profile, refer to add service profiles section\n4. For destination, refer to add a destination section\nFigure 4 \xe2\x80\x93 Add destination\n5. Choose Next\n6. In the Geo-location section, enable activate positioning\n7. Select  Add device\nFigure 5 \xe2\x80\x93 Activate positioning\nStep 3: Verify device connectivity\nAfter the device is added, navigate back to LoRaWAN devices list, check if the device is sending up-links.\nFigure 6 \xe2\x80\x93 LoRaWAN devices\nStep 4: Visualize your tracker\nAfter you have added the device in AWS IoT Core for LoRaWAN, the tracker GNSS/WiFi scan will resolve and provide Geo-location output. Check the location of your tracker in the map that is embedded in the device details page shown below. Here you can see the latitude and longitude, and a blue pin on the map representing your tracker\xe2\x80\x99s location.\nFigure 7 \xe2\x80\x93 Tracker location on map\n'"
31,Introducing new MQTTv5 features for AWS IoT Core to help build flexible architecture patterns,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/11/27/aws-iot-mqttv5-blog-post-image-1024x576.png,https://aws.amazon.com/blogs/iot/introducing-new-mqttv5-features-for-aws-iot-core-to-help-build-flexible-architecture-patterns/,"b'Introduction\nWe are excited to announce that AWS IoT Core now supports MQTTv5 features that help enhance communications of large-scale device deployments and innovate device messaging patterns. Customers who already have MQTTv3.1.1 deployments can make use of the new MQTTv5 features as AWS IoT Core provides seamless integration between both versions and supports heterogeneous deployments during migrating. In this blog post, we summarize some of MQTTv5 features with bite-sized implementation examples in real-world IoT scenarios to show how you can design more flexible and efficient IoT architecture patterns. We also show how MQTTv5 brings new possibilities for your existing device fleet running AWS IoT Core.\nAfter a successful run with MQTTv3.1.1, OASIS (Organization for the Advancement of Structured Information Standards) improved the specifications with a key goal of enhancing for scalability and large-scale systems. These enhancements resulted in the release of MQTT version 5 (MQTTv5) as the new standard in March 2019. Refer to the MQTT 5 supported features documentation page for details.\nPrerequisites\nAWS account\nA development environment, or computer with AWS CLI and Python 3 installed.\nGetting Started\nAccess example scripts: Example script files provided in this blog post are stored in aws-samples/aws-iot-mqttv5-examples git repository. Navigate to the git repository link to download to your development environment.\nDownload an MQTT client library: In this blog post, we use open-source Eclipse Paho\xe2\x84\xa2 MQTT Python Client library.\nInstall pip by running the following command, if not installed:\npython -m ensurepip --upgrade\nInstall paho-mqtt library by running the following command:\npip install paho-mqtt\nYou can also check the paho-mqtt source code repository and other installation options of the client.\nObtain AWS IoT Core device data endpoint: AWS IoT Core device data endpoint is your AWS account\xe2\x80\x99s region-specific AWS IoT Core endpoint that your devices connect to.\nNavigate to the AWS IoT Core console.\nOn the left navigation menu, choose Settings.\nUnder Device data endpoint, copy Endpoint.\nOn later sections of this blog, you\xe2\x80\x99ll be asked to provide this endpoint as a parameter for the example scripts.\nCreate an AWS IoT thing, obtain and place certificates:\nCreate an AWS IoT thing and download device certificates.\nFollow instructions in Create AWS IoT resources page to use Amazon Root certificate authority (CA) signed client certificates.\nIf you use AWS IoT Core with choosing your root or intermediate certificate authorities (CA), follow instructions in Create your own client certificates page.\nExample scripts on this blog post expect certificates in \xe2\x80\x9ccertificates\xe2\x80\x9d folder by default, but you can also override this with --certificates-path parameter.\nRename the certificate files as following:\nRename the certificate file as \xe2\x80\x9cclient-cert.pem\xe2\x80\x9d\nRename the downloaded root certificate file as  \xe2\x80\x9cAmazonRootCA1.pem\xe2\x80\x9d\nRename the downloaded private key as \xe2\x80\x9cprivate-key.pem\xe2\x80\x9d\nNow, you\xe2\x80\x99re ready to start experimenting with new features of MQTTv5 that AWS IoT Core now supports.\n1. More transparent messaging with the Request/Response pattern\nThe Request/Response messaging pattern is a method to track responses to client requests in an asynchronous way. It\xe2\x80\x99s a mechanism implemented in MQTTv5 to allow the publisher to specify a topic for the response to be sent for a particular message. Therefore, when the subscriber receives the request, it also receives the topic to send the response. It also supports the correlation data field that allows tracking of packets, e.g. request or device identification parameters.\nFor example, a smart home application with a connected door lock can benefit from the request/response pattern. Suppose a user is interacting with the door lock via a mobile app that sends MQTT messages to open/close the lock. Any messages exchanged between the app and the door lock must be acknowledged and be traceable whether the packets were delivered. Also, the door lock command needs to pass with the context, e.g. requester user identity.\nTo experiment with this feature, check the ./aws-iot-mqttv5-examples/01_request_response_example.py script file in the git repository you downloaded on the Getting Started step. Run the following command by specifying your device data endpoint you obtained on the Getting Started step with --endpoint parameter, replacing <AWS-IoT-Device-Data-Endpoint> with, for example: abcd123456z-ats.iot.region.amazonaws.com\n$ python3 01_request_response_example.py --endpoint <AWS-IoT-Device-Data-Endpoint>\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c1, k60) client_id=b\'TestThing01\' properties=None\nDEBUG:__main__:Received SUBACK: 4, ""request_id"": ""eb1bd30a-c7e6-42a4-9e00-d5baee89f65c""}\'], ...  (4 bytes)\nDEBUG:root:Received a message on topic: \'home07/main_door/lock\', payload: \'LOCK\'\nDEBUG:root:Main door LOCK request with parameters: \'b\'{""user_profile_id"": 4, ""request_id"": ""eb1bd30a-c7e6-42a4-9e00-d5baee89f65c""}\'\'\nDEBUG:__main__:Sending PUBLISH (d0, q0, r0, m3), \'b\'home07/main_door/status\'\', properties=[CorrelationData : b\'{""user_profile_id"": 4, ""request_id"": ""eb1bd30a-c7e6-42a4-9e00-d5baee89f65c""}\'], ... (25 bytes)\nDEBUG:__main__:Received PUBLISH (d0, q0, r0, m0), \'home07/main_door/status\', properties=[CorrelationData : b\'{""user_profile_id"": 4, ""request_id"": ""eb1bd30a-c7e6-42a4-9e00-d5baee89f65c""}\'], ...  (25 bytes)\nDEBUG:root:Received a message on topic: \'home07/main_door/status\', payload: \'USER_IS_NOT_AUTHENTICATED\'\nDEBUG:root:Main door status: \'USER_IS_NOT_AUTHENTICATED\'\' with parameters: \'b\'{""user_profile_id"": 4, ""request_id"": ""eb1bd30a-c7e6-42a4-9e00-d5baee89f65c""}\'\'\nBash\nFigure: Request/Response messaging pattern for door lock with mobile application\nThe mobile app\xe2\x80\x99s MQTT client subscribes to the response topic. Then, a lock request package is published to home07/main_door/lock topic with expected response topic as home07/main_door/status and a correlation data object contains the requester user_profile_id and request_id.\nWhen the door lock receives the lock request on home07/main_door/lock, it processes the MQTT packet, including the response topic and correlation data.\nThe door lock makes the decision and responds by publishing to the topic with passing the correlation data.\nThe subscriber function receives the response on home07/main_door/status, and logs that the decision with the correlation data. Further actions can be taken by the requester using the user_profile_id and request_id.\n2. More flexible device messaging with the user properties feature\nThe user properties feature allows connected devices or subscriber applications to pass custom information by appending custom key-value pairs to MQTT packets including publish and connect. The feature provides similar functionality with HTTP headers and can be used as long as a total of 8KB size is not exceeded in the header.\nFor example, you can use the user properties feature for a multi-vendor sensor deployment use-case. Assume a case with multiple sensors from different vendors deployed in an industrial or a smart home application. In these cases, the individual sensors could send their data using various encodings, which are specified in user properties. Depending on the user property value, subscribers of the messages can take specific actions to process them.\nTo experiment with this feature, check the ./aws-iot-mqttv5-examples/02_user_properties_example.py script file in the git repository you downloaded on the Getting Started step. Run the following command by specifying your device data endpoint you obtained on the Getting Started step with --endpoint parameter, replacing <AWS-IoT-Device-Data-Endpoint> with, for example: abcd123456z-ats.iot.region.amazonaws.com\n$ python3 02_user_properties_example.py --endpoint <AWS-IoT-Device-Data-Endpoint>\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c1, k60) client_id=b\'TestThing02\' properties=NonerandX-rev8.2\')]], ... (8 bytes)\nDEBUG:__main__:Sending PUBLISH (d0, q0, r0, m4), \'b\'sensors/gateway01/sensor03\'\', properties=None, ... (4 bytes)\nDEBUG:__main__:Received PUBLISH (d0, q0, r0, m0), \'sensors/gateway01/sensor01\', properties=[UserProperty : [(\'Content-Type\', \'text/plain\'), (\'Hardware-Revision\', \'brandX-rev1.17c\')]], ...  (4 bytes)\nDEBUG:root:Received a message on topic: \'sensors/gateway01/sensor01\'\nDEBUG:root:Message has user properties: [(\'Content-Type\', \'text/plain\'), (\'Hardware-Revision\', \'brandX-rev1.17c\')]\nDEBUG:root:Received message with Content-Type: \'text/plain\'\nDEBUG:root:Plain text payload: \'23.4\'\nDEBUG:__main__:Received PUBLISH (d0, q0, r0, m0), \'sensors/gateway01/sensor02\', properties=[UserProperty : [(\'Content-Type\', \'base64\'), (\'Hardware-Manufacturer\', \'brandX-rev8.2\')]], ...  (8 bytes)\nDEBUG:root:Received a message on topic: \'sensors/gateway01/sensor02\'\nDEBUG:root:Message has user properties: [(\'Content-Type\', \'base64\'), (\'Hardware-Manufacturer\', \'brandX-rev8.2\')]\nDEBUG:root:Received message with Content-Type: \'base64\'\nDEBUG:root:Raw payload: \'MjMuNw==\', Decoded base64 payload: \'23.7\'\nDEBUG:__main__:Received PUBLISH (d0, q0, r0, m0), \'sensors/gateway01/sensor03\', properties=[], ...  (4 bytes)\nDEBUG:root:Received a message on topic: \'sensors/gateway01/sensor03\'\nDEBUG:root:No User Property specified, raw payload: \'24.4\'\nBash\nThis example script shows three sensors for different brands, publishing to their topics using different data encodings. The subscriber processes a raw sensor value and a base64 encoded sensor value by evaluating their Content-Type user property values.\nProcessing MQTT packets with user properties on AWS IoT Core topic rules\nAWS IoT Core\xe2\x80\x99s topic rules feature allows configuring/setting up rules to forward and ingest MQTT messages from AWS IoT Core to various AWS services. You can define processing logic using AWS IoT rule SQL statements. This allows data transformation across multiple vendors to a standardized and vendor-agnostic form on the AWS IoT topic rule by implementing corresponding processing to each data schema, and forwarding it to any AWS service.\nSELECT CASE get_user_property(""Content-Type"")\n WHEN ""base64"" THEN decode(decode(encode(*, \'base64\'), \'base64\'), \'base64\')\nELSE decode(encode(*, \'base64\'), \'base64\') END as sensor_value,\n FROM sensors/#\'\nSQL\nThe AWS IoT Core topic rules feature provides the get_user_property() function that allows accessing user property values of the MQTT packets in rule definitions. The rule SQL provided above applies base64 decoding operation if it\xe2\x80\x99s base64-encoded. Check the Creating an AWS IoT Rule documentation page to create a topic rule. Also, check the documentation page for AWS IoT SQL Reference and Working with binary payloads.\n3. More efficient use of device bandwidth with the topic aliases feature\nCellular IoT devices and sensors use mobile networks to communicate with their back-end services. These devices are mostly designed to operate on the lowest possible bandwidth because of their metered data services. Assuming cellular connected sensor devices are designed to operate on farmlands, they would be expected to operate with low data communication and long battery life. Also, larger data packets often lead to more power consumption. Considering these sensors publish only a few bytes of sensor values, long MQTT topics become an overhead for device messaging.\nThe topic aliases feature allows MQTT clients to assign numeric aliases to topics and then refer to the alias when publishing further messages. This allows reduction in the transmitted MQTT packet size by referencing the topic with a single number instead of the topic itself.\nExample sensor value: 23.2\nExample MQTT topic (83 bytes): sensors/field/field001/equipments/a804e598-ee90-4f89-9cde-458f8fe9b980/temperature\nTo experiment with this feature, check the ./aws-iot-mqttv5-examples/03_topic_alias_example.py script file in the git repository you downloaded on the Getting Started step. Run the following command by specifying your device data endpoint you obtained on the Getting Started step with --endpoint parameter, replacing <AWS-IoT-Device-Data-Endpoint> with, for example: abcd123456z-ats.iot.region.amazonaws.com\n$ python3 03_topic_alias_example.py --endpoint <AWS-IoT-Device-Data-Endpoint>\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c1, k60) client_id=b\'TestThing03\' properties=None\nDEBUG:__main__:Sending PUBLISH (d0, q0, r0, m1), \'b\'sensors/field/field001/equipments/a804e598-ee90-4f89-9cde-458f8fe9b980/temperature\'\', properties=[TopicAlias : 1], ... (4 bytes)\nDEBUG:__main__:Sending PUBLISH (d0, q0, r0, m2), \'b\'\'\', properties=[TopicAlias : 1], ... (4 bytes)\nDEBUG:__main__:Sending PUBLISH (d0, q0, r0, m3), \'b\'\'\', properties=[TopicAlias : 1], ... (4 bytes)\nBash\nThe script publishes the first temperature value to a topic with setting the topic alias as \xe2\x80\x9c1\xe2\x80\x9d, which is valid until the end of the current connection. For the next publish operation, only the topic alias is referenced without specifying the actual topic. All messages will be received to the same topic on broker. Refer to AWS IoT Core message broker and protocol limits and quotas documentation for limits.\n4. Better control of device behavior using message expiry, session expiry, and clean start features\nMQTTv5 has a set of session and message expiration parameters to allow better control of device behavior. With the new session and message expiration parameters, the broker provides and mandates better session controls instead of depending on the client\xe2\x80\x99s implementation.\nSession expiry feature allows you to define fixed intervals, after which the broker removes the session information for a particular client.\nMessage expiry feature defines a set interval that the broker uses to store published messages for any matching subscribers that are not currently connected. The session expiry interval overrides the message expiry when used together. Also, the message expiry interval overrides any AWS IoT Core message retention intervals. Check AWS IoT Core message broker and protocol limits and quotas page for limits.\nA clean start is a flag that can be set in tandem with the session expiry interval. Setting this flag in the packet indicates the session should start without using an existing session.\nA connected car is a good example for a device with irregular connectivity patterns and requires resilience when the connection is recovered. A connected car use-case with a mobile app to interact with the car\xe2\x80\x99s systems such as the air conditioning and the door lock can showcase these features. It could be a case of using a remote command to unlock/lock the doors remotely for a delivery service or for a car sharing. These remote commands issued by the mobile app need to be processed within a specific time window. You can specify a message expiry interval that says if the car does not receive the command within a short interval, i.e. within 10 seconds of sending, then the message must expire. You can specify a second type of message for less time-critical remote commands, such as controlling the air conditioning systems. In that case, you can set the remote command for turning on the AC with 2 minutes of message expiry.\nTo experiment with this feature, we use one publisher script which will behave as the mobile app client that sends remote commands, and one subscriber script which will behave as the connected car client to perform actions. Check the ./aws-iot-mqttv5-examples/04_message_session_expiry_clean_start_publisher_example.py and ./aws-iot-mqttv5-examples/04_message_session_expiry_clean_start_subscriber_example.py scripts. During the experiment, we will run these two scripts in different intervals to demonstrate online and offline states of the connected car. Run the following commands by specifying your device data endpoint you obtained on the Getting Started step with --endpoint parameter, replacing <AWS-IoT-Device-Data-Endpoint> with, for example: abcd123456z-ats.iot.region.amazonaws.com\nFirst, run the subscriber with 300 seconds of session expiry interval. This will create a session instance with the subscription in the AWS IoT Core MQTT broker and allow queuing messages for 300 seconds when the device goes offline.\n$ python3 04_message_session_expiry_clean_start_subscriber_example.py --endpoint <AWS-IoT-Device-Data-Endpoint> --session-expiry-interval 300\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c0, k60) client_id=b\'TestThing04-Sub\' properties=[SessionExpiryInterval : 300]\nDEBUG:__main__:Received CONNACK (0, Success) properties=[SessionExpiryInterval : 0, ServerKeepAlive : 60, ReceiveMaximum : 100, TopicAliasMaximum : 8, MaximumQoS : 1, RetainAvailable : 1, MaximumPacketSize : 149504, WildcardSubscriptionAvailable : 1, SubscriptionIdentifierAvailable : 0, SharedSubscriptionAvailable : 1]\nDEBUG:__main__:Sending SUBSCRIBE (d0, m1) [(b\'vehicle/#\', {QoS=1, noLocal=False, retainAsPublished=False, retainHandling=0})]\nDEBUG:__main__:Received SUBACK\nBash\nNow, stop the client. When stopped, 300 seconds of the session expiry clock will start ticking. So, our connected car is now offline and it will be able to receive messages if it goes back online in 300 seconds, before the message expiry intervals have passed. Now run the publisher to publish two remote commands while the connected car is offline:\n$ python3 04_message_session_expiry_clean_start_publisher_example.py --endpoint <AWS-IoT-Device-Data-Endpoint>\nBash\nAfter seeing Received PUBACK logs for two messages, run the subscriber script.\n$ python3 04_message_session_expiry_clean_start_subscriber_example.py --endpoint <AWS-IoT-Device-Data-Endpoint> --session-expiry-interval 300\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c0, k60) client_id=b\'TestThing04-Sub\' properties=[SessionExpiryInterval : 300]\nDEBUG:__main__:Received CONNACK (1, Success) properties=[SessionExpiryInterval : 0, ServerKeepAlive : 60, ReceiveMaximum : 100, TopicAliasMaximum : 8, MaximumQoS : 1, RetainAvailable : 1, MaximumPacketSize : 149504, WildcardSubscriptionAvailable : 1, SubscriptionIdentifierAvailable : 0, SharedSubscriptionAvailable : 1]\nDEBUG:__main__:Sending SUBSCRIBE (d0, m1) [(b\'vehicle/#\', {QoS=1, noLocal=False, retainAsPublished=False, retainHandling=0})]\nDEBUG:__main__:Received PUBLISH (d0, q1, r0, m1), \'vehicle/air_conditioner/set\', properties=[MessageExpiryInterval : 116], ...  (8 bytes)\nDEBUG:root:Received a message on topic: \'vehicle/air_conditioner/set\', payload: \'PRE_HEAT\'\nDEBUG:__main__:Sending PUBACK (Mid: 1)\nDEBUG:__main__:Received PUBLISH (d0, q1, r0, m2), \'vehicle/driver_door/lock\', properties=[MessageExpiryInterval : 6], ...  (6 bytes)\nDEBUG:root:Received a message on topic: \'vehicle/driver_door/lock\', payload: \'UNLOCK\'\nDEBUG:__main__:Sending PUBACK (Mid: 2)\nDEBUG:__main__:Received SUBACK\nBash\nAs seen on the script log outputs, two remote commands were published while the connected car was offline and were received when it went back online. Notice that the vehicle/driver_door/lock message has 6 seconds remaining, and vehicle/air_conditioner/set message has 116 seconds remaining. So, the connected car went back online within this period to receive both remote commands before expiration.\nNow, stop both scripts and run the same publish and subscribe experiment again. For this case, wait 15 seconds after the publish before subscribing to the messages. You will notice that only the vehicle/air_conditioner/set message is received as expected. While the connected car was offline, the vehicle/driver_door/lock message expired.\nAs a last experiment on this feature set, run the subscriber with 10 seconds of session expiry. In that case, the connected car\xe2\x80\x99s session in the AWS IoT Core MQTT broker will be removed along with queued messages. Even if the message expiry intervals allow queuing messages, they won\xe2\x80\x99t be received by the connected car since the session is removed after 10 seconds.\nRun the subscriber with 10 seconds of session expiry and stop it after seeing Received SUBACK log. Then, run the publisher to send remote commands and wait 15 seconds. Then, run the subscriber again:\n$ python3 04_message_session_expiry_clean_start_subscriber_example.py --endpoint <AWS-IoT-Device-Data-Endpoint> --session-expiry-interval 10\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c0, k60) client_id=b\'TestThing04-Sub\' properties=[SessionExpiryInterval : 10]\nDEBUG:__main__:Received CONNACK (0, Success) properties=[SessionExpiryInterval : 0, ServerKeepAlive : 60, ReceiveMaximum : 100, TopicAliasMaximum : 8, MaximumQoS : 1, RetainAvailable : 1, MaximumPacketSize : 149504, WildcardSubscriptionAvailable : 1, SubscriptionIdentifierAvailable : 0, SharedSubscriptionAvailable : 1]\nDEBUG:__main__:Sending SUBSCRIBE (d0, m1) [(b\'vehicle/#\', {QoS=1, noLocal=False, retainAsPublished=False, retainHandling=0})]\nDEBUG:__main__:Received SUBACK\nBash\nAs seen on log outputs, nothing has been received by the connected car since the session is already removed.\n5. Enhanced device connectivity flow using reason codes and server disconnect features\nReason codes allow a sender to determine the type of error (if any) in the transaction between the publisher and the subscriber. View the full list in OASIS specs for MQTT Version 5.0.\nThe server disconnect feature is a response from the server with the reason code as to why the connection was closed. This feature is helpful when analyzing the reason why the disconnect/reject happened, which you can use for various debugging purposes.\nAn example use case could be an edge sensor gateway that integrates with various services running in the cloud. When MQTT clients are disconnected, they are often configured to attempt reconnects automatically. With MQTTv3.1.1, misconfigurations between the gateway\xe2\x80\x99s subscription topics and the IoT device policy were leading to connect/disconnect loops when the device attempted to perform unauthorized MQTT actions in the absence of the reason code for the disconnect. With MQTTv5, the device knows why it was disconnected, and it won\xe2\x80\x99t try to subscribe to that topic when the reason from the server for disconnect is specified as authentication. The device can report the issue and try taking appropriate remedial actions using the reason code.\nTo experiment with this feature, check the ./aws-iot-mqttv5-examples/05_reason_codes_example.py script file in the git repository you downloaded on the Getting Started step. Run the following command by specifying your device data endpoint you obtained on the Getting Started step with --endpoint parameter, replacing <AWS-IoT-Device-Data-Endpoint> with, for example: abcd123456z-ats.iot.region.amazonaws.com\n$ python3 05_reason_codes_example.py --endpoint <AWS-IoT-Device-Data-Endpoint>\nDEBUG:__main__:Sending CONNECT (u0, p0, wr0, wq0, wf0, c1, k60) client_id=b\'TestThing05\' properties=None\nDEBUG:__main__:Received CONNACK (0, Success) properties=[SessionExpiryInterval : 0, ServerKeepAlive : 60, ReceiveMaximum : 100, TopicAliasMaximum : 8, MaximumQoS : 1, RetainAvailable : 1, MaximumPacketSize : 149504, WildcardSubscriptionAvailable : 1, SubscriptionIdentifierAvailable : 0, SharedSubscriptionAvailable : 1]\nDEBUG:root:Connected {\'session present\': 0}\nDEBUG:__main__:Sending PUBLISH (d0, q1, r0, m1), \'b\'sensors/field/field001/equipments/9e6282ff-c8f0-49cd-b3a0-fa17ad6b84a7/temperature\'\', properties=None, ... (4 bytes)\nDEBUG:__main__:Sending PUBLISH (d0, q1, r0, m2), \'b\'sensors/field/field001/equipments/46be210d-8a83-4e92-a3fe-4f989704d21e/temperature\'\', properties=[TopicAlias : 14], ... (4 bytes)\nDEBUG:__main__:Received DISCONNECT Topic alias invalid [ReasonString : DISCONNECT:Topic alias is out of range.:e3392cff-a031-4887-5b87-59eae249b6c4]\nDEBUG:root:Received Disconnect with reason: Topic alias invalid\nDEBUG:root:The disconnect is caused by the topic alias. Logging the issue for further analysis and exiting.\nBash\nWhen the script starts, it first publishes a message without a topic alias successfully. Then, the script publishes the second message with a topic alias set to 14. Since the current limit of topic aliases is 8; the broker rejects the packet with the reason for the disconnect as well. The client receives the reason code 148 which is \xe2\x80\x9cTopic Alias invalid\xe2\x80\x9d for DISCONNECT packet, as specified in OASIS specs for MQTT Version 5.0. After the reason code 148, the client stops gracefully.\n'"
32,Reduce building maintenance costs with AWS IoT TwinMaker Knowledge Graph,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/11/17/Figure-7-2-1024x519.png,https://aws.amazon.com/blogs/iot/reduce-building-maintenance-costs-with-aws-iot-twinmaker-knowledge-graph/,"b""Introduction\nThe shift from in office work to hybrid and fully remote work is causing revenue and valuation pressure on commercial building owners. As a result, building managers are exploring ways to optimize their expenses by reducing maintenance costs while still providing a premier tenant experience.\nBuilding managers are responsible for maintenance and providing a comfortable space for tenants while balancing the cost of both. They often maintain multiple properties. The maintenance crew may not be physically present in all buildings, or familiar with the building that needs servicing. Therefore, having the right tools to troubleshoot and find the root cause can improve maintenance efficiency.\nBuilding maintenance is typically reactive and driven by tenant reported issues or alarms. The HVAC Maintenance and Energy Savings report states that non-reactive maintenance on HVAC systems can reduce the operational cost by 10% \xe2\x80\x93 20%. Scheduling regular service is simple, but detecting issues with sensors, economizers, or long-forgotten override settings requires a data-driven solution. Proactive building managers will identify issues before they arise, which involves having an effective method to search the buildings and identify equipment under similar conditions or failure modes.\nIn this blog, we will expand on the use case from our prior post on Cognizant\xe2\x80\x99s 1Facility solution and demonstrate how TwinMaker Knowledge Graph, a new feature in AWS IoT TwinMaker, makes it easier to find and troubleshoot issues. In the prior post, Cognizant describes how AWS IoT TwinMaker enables them to visualize the building for customers and adds value by fusing multiple data sources in one location. We assumed that the building manager knew the building, rooms, and the equipment as well as the location and available sensors in each room. In this blog, we will walk through the use case of troubleshooting HVAC issues in a building. We will describe how customers use TwinMaker Knowledge Graph to contextualize the alarms, and demonstrate how it empowers building managers to generate insights.\nUse case walk through: troubleshooting uncomfortable tenant conditions\nIn this example, the building manager will focus on only one of the buildings they manage. A tenant reported an uncomfortable environment in room 1.1E, specifically noting that the room was hot and humid.\nFrom the digital twin of this building, the building manager learns it is a multi-story building with 2 HVAC zones per floor, aligned to East and West. Then, the building manager examines a dashboard displaying all room temperatures in the building, and confirms the temperature in room 1.1E is higher than the setpoint. Analyzing this room\xe2\x80\x99s humidity sensor data, the building manager corroborates the report that the room is also humid.\nThe building manager isn\xe2\x80\x99t familiar with this building and is puzzled as to why only a single room has high temperature and humidity. To investigate further, the building manager uses the digital twin dashboard to look at the rooms in the East HVAC zone, where room 1.1E is located. By inspecting the sensor data in those rooms in the East HVAC zone, they discover that all the other rooms in the East HVAC zone are cooler than the temperature set point and drier than expected. By examining the 3D model of the building, the building manager discovers room 1.1E is different from the others because it doesn\xe2\x80\x99t have a window. They visit the nearby rooms in the East HVAC zone and validate the hypothesis. They also discover occupants in other rooms opened their windows to make the rooms comfortable. The exterior air lowered the temperature and humidity level of the rooms below the set point, but not enough to trigger an alarm in the building monitoring system.\nNow, it is clear there is an issue in the eastern HVAC zone with the abnormal conditions in room 1.1E. To find the root cause of the issue, he used the digital twin dashboard to inspect sensor values for the east HVAC zone. The building manager selects a view to display all the sensor data for the east HVAC zone. He inspects measurements from sensors (time-series data), such as the floor 1 return air temperature, floor 2 return air temperature, supply air temperature, outside air temperature and humidity, as well as other controlled values such as the desired fan speeds, economizer position, and the damper position on each floor. With access to all of these data points, the building manager can compare trends and identify abnormal behavior. Then he discovers that supply air temperature doesn\xe2\x80\x99t change when the economizer command is changed. This indicates that the economizer is malfunctioning, and the outside air is not being mixed with the return air before being recycled into the building.\nNext, the building manager scans through the historical data to identify when the economizer started to malfunction. Now the building manager will be familiar with the details of the economizer issue before submitting a repair order to the HVAC company maintaining the system. These insights reduce the time to diagnose the problem and accelerate time to resolution. As a follow-up, he proactively checks the status of the economizer for the other HVAC units in this building and other buildings he manages. These actions not only mitigate a potential tenant comfort issue, but also help to reduce the operational cost of the HVAC system if other economizer issues are identified and proactively repaired. This is the value of proactive maintenance.\nTechnical implementation using TwinMaker Knowledge Graph\nTwinMaker Knowledge Graph is a new feature for AWS IoT TwinMaker. Existing AWS IoT TwinMaker customers enable this feature by selecting the standard pricing plan on the settings page in the AWS console. All new customers will be on standard pricing plan by default and have TwinMaker Knowledge Graph enabled. With the feature, users execute queries using the open source PartiQL query language with SQL like syntax. Customers use the relationship property to describe how the entities are related to each other physically or logically. They can then query the entities in their workspace and the relationship between these entities. For example, customers can query all entities with a name containing \xe2\x80\x9ctemperature,\xe2\x80\x9d or find all entities connected to an entity of interest. These capabilities enable customers to build dashboards to view performance trends for the same type of equipment in one site, or find the root cause of an issue by traversing through all entities related to the issue.\nIn this section, we will walk through the steps of how the root cause analysis use case is implemented using TwinMaker Knowledge Graph.\nThe application developer creates entities to represent physical things, such as a room or an air handling unit, and then adds a component that is instantiated from a component type. A component includes the attributes or properties that describe the physical thing. For example, a property can be a descriptor such as the floor number, or a time-series data stream like temperature measurement stored in an external data store. A relationship property captures how this entity is related to another entity in the context of the component. A component may contain multiple relationships or none, and each relationship can connect to one or multiple entities. To define a relationship property, a relationship type must be specified along with entity IDs that are referenced by that relationship.\nTo create entities, components, and properties, you can use the AWS IoT TwinMaker console or call the CreateEntity API. You can also use an onboarding script or cloud formation template that describes the layout of the building and the relationships between the physical objects. The figure below illustrates an entity representing a room with a user-defined component assigned to it; the JSON object describing the attributes\xe2\x80\x99 relationships is overlaid onto the figure. In this user defined component, three properties define relationships, \xe2\x80\x9cfeed,\xe2\x80\x9d \xe2\x80\x9cisLocationOf,\xe2\x80\x9d and \xe2\x80\x9cisMonitoredBy,\xe2\x80\x9d and two other properties, \xe2\x80\x9croomNumber\xe2\x80\x9d and \xe2\x80\x9croomFunction,\xe2\x80\x9d define the attributes.\nWe will assume that the application developer has created the components, entities, and relationships that represent the building. The figure below illustrates the TwinMaker Knowledge Graph query editor representation of the building and how the HVAC zones serve the building.\nThe image below shows a more detailed view of the TwinMaker Knowledge Graph for the East HVAC zone.\nWe will also assume the application developer has uploaded and configured a relevant 3D model of the building via scene composer, and that the dashboard is available to the end user using Amazon Managed Grafana. For step-by-step instructions on how to import a 3D model and visualize it in Amazon Managed Grafana, please see this hyperlinked blog.\nWith the digital twin of the building created in AWS IoT TwinMaker, let\xe2\x80\x99s dive into how the TwinMaker Knowledge Graph helps the building manager to troubleshoot the environmental condition issue. For the first part of the use case, the building manager wants to view all relevant sensor data for rooms in the East HVAC zone. The user calls the GetPropertHistory API to get sensor data with entity IDs and component name as inputs. The first step is to identify all relevant entities that the building manager is interested in.\nPrior to TwinMaker Knowledge Graph, the user had to apply business logic to each entity from the ListEntities API and determine whether the entity is a sensor in a room in the East HVAC zone. The user had to process multiple pages of results, parse the relationship data, and traverse the relationship with a number of recursive API calls. With TwinMaker Knowledge Graph, the user can construct a query as shown below. The query returns the entity IDs of all sensors related to rooms of the East HVAC loop. The query below can be executed via ExecuteQuery API or the query editor in AWS console.\nSELECT e3.entityId\nFROM EntityGraph\nMATCH (e1)-[]->{1,5}(e2)-[:isMonitoredBy]->(e3)\nWHERE e1.entityName = 'AHU_East' AND e2.entityName LIKE 'Room%'\nAND e3.entityName LIKE '%_Sensor'\nIn the query above, the PartiQL language allows the user to specify a variable hop query and a multi-hop query. Specifically, MATCH (e1)-[]->{1,5}(e2) is a variable hop query which will identify all entities between 1 and 5 hops away from the East Air Handling Unit which start with the string \xe2\x80\x9cRoom\xe2\x80\x9d. The multi-hop query, (e2)-[:isMonitoredBy]->(e3) enables us to specify that we are specifically interested in entities that end with the string sensor and have a direct (single hop) relationship with the rooms. Note that :isMonitoredBy further constrains the results by only allowing entities with that specific relationship to be returned. This use case is returning all sensors attached to a room in the East HVAC loop instead of all sensors on the East HVAC loop.\nThen, the application logic iterates through the entity list (i.e. room sensors) IDs and calls the GetPropertyValue API to retrieve the latest sensor value. These results are presented back to the user as the single-point-in-time data on the dashboard, as shown in the image above. Now, the building manager realizes that the humidity and temperature in all rooms were deviating slightly from the setpoint.\nThis undifferentiated heavy lifting of identifying room sensors of the east HVAC zone is handled by TwinMaker Knowledge Graph rather than complex business logic. It reduces application development complexity and enables the application developer to focus on improving features. For example, by comparing the time-series data for supply air temperature and the economizer position, the building manager was able to identify the failed economizer as the root cause.\nIn this use case, the building manager decides to proactively explore other buildings they manage to determine if more HVAC Air Handling Units have a failing economizer. He will follow the same steps using the digital twin for other buildings. A similar query is used to retrieve the entity IDs, and then the GetPropertyValueHistory API is used to retrieve a range of data. Then, he creates and reviews the graphs of the supply air and economizer position.\n"""
33,Improve your security posture with AWS IoT Device Defender direct integration with AWS Security Hub,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/11/16/architecture1.png,https://aws.amazon.com/blogs/iot/improve-your-security-posture-with-aws-iot-device-defender-direct-integration-with-aws-security-hub/,"b'Introduction\nWe are excited to announce that AWS IoT Device Defender is now integrated with AWS Security Hub. This integration allows you to ingest alarms and their attributes from audit and detect features in one central location, without custom coding. This will help you offload or reduce complexity of managing disparate workflows from multiple security consoles when you review devices monitored by AWS IoT Device Defender.\nYou can use AWS IoT Device Defender to audit and monitor your IoT devices and can use AWS Security Hub to centralize and prioritize security findings from across AWS accounts, services, and supported third-party partners to help analyze security trends and identify the highest priority security issues. With the direct integration of AWS IoT Device Defender to AWS Security Hub, you can view AWS IoT Device Defender alarms alongside events from other AWS security services to centrally view and improve the security posture of your IoT solution.\nAWS Security Hub ingests findings from multiple AWS services, including Amazon GuardDuty, Amazon Inspector, Amazon Macie, AWS Firewall Manager, AWS Identity and Access Management (IAM) Access Analyzer, and AWS Systems Manager Patch Manager. With the AWS AWS IoT Device Defender integration to AWS Security Hub, you can ingest AWS IoT Device Defender alarms into AWS Security Hub. Findings from each service are normalized into the AWS Security Finding Format (ASFF), so that you can review findings in a standardized format and take action quickly. You can use AWS Security Hub to provide a centralized view of all security-related findings, where you can set up alerting and automatic remediation.\nSolution overview\nFigure 1: Solution architecture\nPrerequisites\nYou must have AWS Security Hub set up in the Region where you\xe2\x80\x99re deploying the solution. To set up, refer to the Setting up AWS Security Hub documentation page.\nAWS IoT Core Console MQTT test client access.\nNote that for device-side metrics and custom metrics, you will need to setup a device side agent with our sample agent in Python or use AWS IoT Device SDK.\nSolution walk-through\nAWS Security Hub integrations allow aggregating security finding data from several AWS services and from supported AWS Partner Network (APN) security solutions. The Integrations page in the AWS Security Hub console provides access to all of the available AWS and third-party product integrations. The AWS Security Hub API also provides operations to allow you to manage integrations.\nFigure 2: AWS Security Hub console showing AWS IoT Device Defender integrations\nNavigate to AWS IoT Security Hub > Integrations page to see and accept findings from AWS IoT Device Defender service for your use case.\nUnder Integrations section, filter for integrations, enter Device Defender.\nChoose Accept findings for both audit and detect integrations.\nCongratulations! You have enabled accepting AWS IoT Device Defender audit and detect findings to AWS Security Hub. You can continue with following experiment sections to try and test integrations in your AWS account.\nExperimenting AWS IoT Device Defender audit findings integration with AWS Security Hub\nAn AWS IoT Device Defender audit looks at account and device related settings and policies to ensure security measures are in place. To experiment an audit finding, you can create an overly permissive device policy and run the audit on demand to be able to generate findings right away.\nNavigate to AWS IoT > Security > Policies.\nChoose Create Policy\nUnder Policy properties section, for Policy name, specify a name for the policy.\nUnder the Policy document, prepare an overly permissive statement using the following:\nFor Policy effect, choose Allow\nFor Policy action, choose * (all AWS IoT Actions)\nFor Policy resource, enter * (corresponds to all AWS IoT resources)\nChoose Create.\nNow you\xe2\x80\x99ve created an overly permissive device policy in your AWS account. It will be detected as a security finding with critical severity for the next AWS IoT Device Defender Audit run. You can run an on-demand audit to see the results right away.\nNavigate to AWS IoT > Security > Audit > Schedules.\nUnder Scheduled audits, choose Create.\nOn the following page, under Available checks, select all checks.\nUnder Set schedule, for Recurrence, choose Run audit now (once).\nThe audit is started and will turn from in-progress to not compliant within a few minutes. Choose the latest audit, on the audit Report page, review the Non-compliant checks section.\nFigure 3: AWS IoT Device Defender audit report\nYour recently created overly permissive IoT policy is detected by the AWS IoT Device Defender audit. Now you can navigate to AWS Security Hub console to check the findings reported by AWS IoT Device Defender audit.\nNavigate to AWS IoT Security Hub > Integrations page.\nUnder Integrations section, for filter integrations, enter Device Defender.\nUnder AWS IoT Device Defender \xe2\x80\x93 Audit, choose See findings.\nFigure 4: AWS IoT Device Defender audit findings in AWS Security Hub\nCongratulations! You have integrated AWS Security Hub with AWS IoT Device Defender audit findings. Findings in AWS Security Hub are identified by the audit check type as the title and the checked resource identifier. In this example, you will notice \xe2\x80\x9cAwsIotPolicy\xe2\x80\x9d and \xe2\x80\x9cAwsIotAccountSettings\xe2\x80\x9d were the non-compliant resource types. Also, audit sends check summaries to AWS Security Hub, which include status, number of resources checked, percentage of non-compliance about an audit task for each check type. The summaries can be identified by its\xe2\x80\x99 title or resource type \xe2\x80\x9cAwsIotAuditTask\xe2\x80\x9d. You can click each finding and check finding details and trigger workflow actions.\nFigure 5: AWS IoT Device Defender audit finding details in AWS Security Hub\nYou can continue to the following section to also experiment detect findings.\nExperimenting AWS IoT Device Defender Detect findings integration with AWS Security Hub\nWith AWS IoT Device Defender Detect, you can identify unusual behavior that might indicate a compromised device by monitoring the behavior of your devices. You create security profiles, which contain definitions of expected device behaviors, and assign them to a group of devices or to all the devices in your fleet. To experiment with a detect finding, you can create a security profile with a simple expected AWS IoT Core thing behavior, and then connect using an IoT device client that conflicts with the expected behavior.\nNavigate to the Security Profiles section of the AWS IoT Device Defender Console: AWS IoT > Manage > Security > Detect > Security Profiles\nChoose Create Security Profile and choose Create Rule-based anomaly detect profile\nFor Target, choose All things\nSpecify a Security Profile name\nClear all Cloud-side metrics, except Message size\nChoose Next\nUnder the Define metric behaviors section, specify the following parameters for Message size:\nCheck type: Absolute\nOperator: Less than\nValue: 8\nKeep the others as default, and Choose Next.\nChoose Create.\nThis defines a device behavior that expected message size is less than 8 bytes.\nNow, use your IoT devices with AWS IoT device client/SDKs or AWS IoT Core Console MQTT test client to publish messages bigger than 8 bytes on average.\nWithin five minutes time frame, an AWS IoT Device Defender detect finding will be produced. Navigate to AWS IoT > Security > Detect > Alarms and view produced findings under All alarms.\nNow you can navigate to the AWS Security Hub console to view the findings reported by AWS IoT Device Defender Detect.\nNavigate to AWS IoT Security Hub > Integrations page.\nUnder Integrations section, for filter integrations, enter Device Defender.\nUnder AWS IoT Device Defender \xe2\x80\x93 Detect, choose See findings.\nFigure 6: AWS IoT Device Defender Detect findings in AWS Security Hub\nCongratulations! You have integrated AWS Security Hub with AWS IoT Device Defender Detect findings. You will notice that findings for violations are sent to AWS Security Hub in near real time. Violations can be identified by their Thing name and Behavior name in the Title and time that the violations are detected. After a violation goes out of alarm, the corresponding Security Hub finding is immediately archived. You can click each finding and check finding details and trigger workflow actions.\nFigure 7: AWS IoT Device Defender Detect finding details in AWS Security Hub\nNote that, you can also use AWS IoT Device Defender ML Detect to set the normal device behavior. AWS IoT Device Defender then identifies anomalies and triggers alarms using the Machine Learning (ML) models. These alarms are sent to AWS Security Hub and can be seen in the AWS Security Hub console as described earlier.\n'"
34,Connect to remote devices using AWS IoT Secure Tunneling,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-browser-secure-tunneling/,"b'Introduction\nWhen devices are deployed behind restricted firewalls at remote sites, you need a way to gain access to those devices for troubleshooting, configuration updates, and other operational tasks. This is where, secure tunneling, a feature of AWS IoT Device Management has been helping customers to do remote tasks.\nTo help elevate customers even further, AWS has made some significant updates to the offering. First, the price of AWS IoT Device Management secure tunneling feature has been reduced by 80% while retaining the maximum tunnel duration at 12 hours. With improved cost efficiencies, customers can now scale secure tunneling to access a fleet of devices deployed behind restricted firewalls for troubleshooting, configuration updates, training, and other operational tasks to meet the need of their growing IoT workloads on AWS.\nSecondly, AWS has made it even easier to communicate to remote devices using Secure shell Protocol(SSH), Virtual Network connectivity (VNC) or Remote desktop protocol(RDP), enabling support for multiple simultaneous TCP connections. With multiple simultaneous Transmission Control protocol(TCP) connections, you can establish tunnels to access HTTP-based applications that typically make several connections. For example, you can now remotely access a web application that is running on a device to gain real-time telemetry or perform administrative tasks in a web-based Graphic User Interface(GUI).\nThe third improvement is the introduction of single-use token. Previously, when a secure tunnel was established, a token could have been stored and reused, making it susceptible to malicious use. With the updated security improvement, you can now revoke client access tokens (CAT) after a successful connection. When the connection drops, instead of saving CATs to a local device and establishing a token re-delivery method. You can call the RotateTunnelAccessToken API to deliver a new pair of CATs to the source and destination devices and resume connection with the original device in the predefined tunnel period. Depending on where the customer runs into connection issues, token rotation supports rotating CATs in source, destination, or both modes. Once reconnected, you can securely access and continue troubleshooting remote devices using secure tunneling feature. Additionally, the new CATs will be published to destination devices through their subscribed MQTT topic.\nFinally, we added support to browser-based SSH. Previously, you could only connect to a destination device (end destination remote device) using proxy connections through the command line interface (CLI) at source device (operators device). Starting today, you can connect to these destination devices right from the embedded SSH terminal through the AWS Console without the need for a local proxy from source device (AWS IoT Secure tunneling console). This feature improves the on-boarding experience significantly by eliminating the need to compile and install a local proxy on the operators\xe2\x80\x99 device. This streamlined experience allows you to easily scale your use of secure tunneling for remote tasks such as conducting routine operational maintenance.\nUsing AWS IoT Secure Tunneling\nIn this blog post we will setup the IoT Device (Destination device) and we will connect to this destination device using our browser based interface right from AWS IoT Console. You can also reference this video for a live demo.\nStep 1:  Setup destination device\nPlease setup IoT Device (Destination device), for this walk-through you can either use AWS IoT Device Client or AWS IoT Greengrass, once you have setup \xe2\x80\x9cDestination device\xe2\x80\x9d and you can see data arriving from this device into AWS IoT Core, then let\xe2\x80\x99s proceed forward and setup a secure tunnel from browser to this end device (destination device).\nStep 2: Browser based tunneling\nFrom AWS IoT Console choose\nManage\nAll devices\nThings\nSelect the thing, In the image below, a previously created test thing has been selected. You will need to select the specific thing you created.\nStep 3: Create tunnel\nSelect \xe2\x80\x9cCreate secure tunnel\xe2\x80\x9d\nUse \xe2\x80\x9cQuick setup\xe2\x80\x9d and select \xe2\x80\x9cNext\xe2\x80\x9d\nYou can \xe2\x80\x9cedit\xe2\x80\x9d details if you like, for now we will use default settings and \xe2\x80\x9cconfirm and create\xe2\x80\x9d tunnel.\nWhen using browser-based secure tunneling, the client access token for source will be automatically delivered to you through the embedded SSH terminal, and the destination access token will be delivered to the reserved tunnel MQTT topic for devices connected AWS IoT. That procedure eliminates the need to download tokens, if you plan to deliver the destination token using a home-grown solution or establish the tunnel through a local CLI, you can you can download the tokens.\nOnce you have the tunnel created, Choose \xe2\x80\x9cConnect via browser CLI\xe2\x80\x9d authentication option. For our test we will use \xe2\x80\x9cUse private key\xe2\x80\x9d\nIn the pop up, select your \xe2\x80\x9cUsername\xe2\x80\x9d and \xe2\x80\x9cPrivate key\xe2\x80\x9d and select \xe2\x80\x9cConnect\xe2\x80\x9d\nOnce authentication succeeds, you can see the following terminal window showing \xe2\x80\x9cdestination device\xe2\x80\x9d terminal.\nIn this example I have used an AWS IoT Greengrass device we can \xe2\x80\x98CAT\xe2\x80\x99 the logs here to show we are connected to \xe2\x80\x9cdestination device\xe2\x80\x9d\nYou can carry out the tasks needed on this destination device. If the connection is dropped, you can \xe2\x80\x9cSend new access tokens\xe2\x80\x9d to both the source/destination devices to regain access. Once you are done, you can close and delete the tunnel and conclude the connection to the end device (destination device).\nStep 4: Conclude and delete tunnel\nConfirm \xe2\x80\x9cdelete\xe2\x80\x9d and \xe2\x80\x9cDelete tunnel\xe2\x80\x9d\nAlso to avoid any ongoing charges, delete any infrastructure you have created for this test, such as IoT things or EC2 instances.\n'"
35,Impacting Food Waste & Foodborne Illness with AWS IoT Core for LoRaWAN Cold-Chain Sensors,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/connectedfresh-aws-iot-lorawan-food-travel/,"b'Introduction\nImpacting Food Waste & Food-borne Illness with AWS IoT Core for LoRaWAN Cold-Chain Sensors\nInnovative ideas and technologies allow us to improve the efficiency and safety of the food industry. In that sense, ConnectedFresh\xe2\x80\x99s IoT solutions provide the ability to continuously monitor food temperatures throughout production, processing, transportation, and retailing.\nThis blog will highlight how AWS IoT Core for LoRaWAN services are leveraged to effectively reduce food waste and improve food safety through the use of sensors, including temperature monitors. According to the CDC, \xe2\x80\x9cWhen food sits in the \xe2\x80\x98Danger Zone\xe2\x80\x99 between 40\xc2\xb0F and 140\xc2\xb0F, which includes room temperature, bacteria that can cause food poisoning grows quickly.\xe2\x80\x9d Damage to food products due to temperature issues is prevalent and costly, and can be prevented with cold-chain monitoring technology.\nIoT technology is the natural ally to increase our ability to prevent, detect and respond to the health threats associated with unsafe food. Due to their flexible nature, AWS IoT solutions can be applied in countless ways to help the food industry.\nManual Temperature Monitoring\nIn many hospitality operations today, team members are walking around manually noting temperatures of refrigerators and freezers to ensure they are operating effectively. However, it\xe2\x80\x99s often the case that by the time a cooler temperature issue is found, it\xe2\x80\x99s too late to fix it before the damage is done to the product inside, leading teams to operate re-actively to issues that arise.\nIn addition to the product quality and availability as well as the costs due to loss of product, labor also has a large role. This manual activity of taking temperature logs every few hours \xe2\x80\x93 which is limited in its effectiveness, can cost each restaurant location $14,000 per year in productive time (ConnectedFresh).\nReal-time data gathered by IoT devices, including temperature sensors, makes it possible to closely monitor food safety parameters, thus reducing the risk of food-borne illness outbreaks and the loss of product.\nAchieving effective food safety systems is a shared responsibility that requires all stakeholders across the chain to collaborate and work together. It is a serious matter, and it is everyone\xe2\x80\x99s business. However, it can be more complicated than it seems without a data-backed process that provides real-time knowledge to make better decisions.\nRoots in Produce and AWS IoT Expertise\nThe founders of ConnectedFresh worked for Deloitte Consulting, helping to build their industrial IoT capabilities and delivering transformational projects to large manufacturers globally, all focused on preventative maintenance and early detection of issues.\nWith food waste and food-borne illness statistics in mind, ConnectedFresh uncovered an exciting opportunity to implement AWS IoT Core for LoRaWAN cold-chain sensor technology close to home. Within their family produce distribution business, they implemented IoT sensor solutions and reduced food waste, improved food safety, and ensured compliance for the health department, distributors, and partners.\nConnectedFresh implemented dozens of LoRaWAN-enabled smart temperature sensors throughout the distribution facility, and built a real-time data dashboard for managers and executives. This digital transformation allowed leadership to have remote visibility into operations, even when they weren\xe2\x80\x99t on site, increasing transparency across the entire organization.\nFood Industry \xe2\x80\x93 Ripe for LoRaWAN Sensor Solutions\nIn 2019, ConnectedFresh helped their family produce business shift from a purely reactive business model to a predictable, preventative and proactive one. Later that year, they took their solution to Germany and won First Place at the international 2019 Momenta LoRaWAN Startup Challenge. The judging panel in Berlin recognized not only ConnectedFresh\xe2\x80\x99s deep IoT expertise, but also the untapped potential within the global food industry to scale their innovative LoRaWAN sensor solutions, and deliver meaningful business impacts.\n\xe2\x80\x9cTo effectively reduce food waste, companies must invest at every level. \xe2\x80\xa6 This includes an investment in staff training, integrating technology, working with suppliers to streamline the supply chain...\xe2\x80\x9d\n\xe2\x80\x93 Slow Road to Zero\nAs ConnectedFresh has continued to expand, they\xe2\x80\x99ve stayed close to their roots and have strategically chosen to specialize in the Hospitality, Grocery and Food & Beverage industries. Their most popular data automation solution utilizes cold-chain temperature/humidity sensors, but they offer a vast range of data sensors, from energy monitoring, to door open status, to leak detection.\nEverything that ConnectedFresh deploys is ready to go right out of the box, made possible by a highly reliable and scalable infrastructure built on AWS.\nLeveraging AWS IoT Core for LoRaWAN\nLoRaWAN Network Options\nWhen building their platform, ConnectedFresh explored multiple LoRaWAN network options, looking for enterprise-ready solutions with scalability. Expanding their AWS footprint to AWS IoT Core for LoRaWAN was a natural next step because it seamlessly integrated into other hosted services and provided the long-term scalability and reliability they needed.\nScalability and Reliability Driven by AWS Services\nAll solutions that ConnectedFresh deploys are \xe2\x80\x9con-and-go;\xe2\x80\x9d everything is pre-configured and ready to connect. A customer\xe2\x80\x99s local team will receive a package that includes a gateway and their sensor devices. Once they plug in the gateway and turn on the LoRaWAN devices, the network activates the encrypted devices and immediately begins sending data. They can even communicate through cellular gateways, completely segmenting the solution from the customer\xe2\x80\x99s network.\nConnectedFresh\xe2\x80\x99s AWS private network and API-driven architecture allows messages to travel through to their dashboards, fully encrypted at every stage in transit and at rest. Their advanced rules engines decode data and provide contextualization for customer-facing readings, persisting for both long and short-term analytics. And their highly resilient network of services and APIs make data accessible for users via real-time dashboards and alerts over email, SMS, phone calls, messaging integrations, and more.\nAWS\xe2\x80\x99 models are based on \xe2\x80\x9cpay what you use\xe2\x80\x9d, allowing ConnectedFresh to quickly and seamlessly scale up and down services based on immediate needs. AWS is the industry cloud leader and continues to define modern understanding of cloud services. The ConnectedFresh platform is developed and hosted on AWS private cloud using AWS native services to provide highly scalable and resilient server-less & micro-services driven architecture. It creates data processing pipelines using AWS Lambda and Amazon SQS with redundancy, persistence and exception handling at each processing stage, improving data integrity and security at scale.\nApplications use server-less infrastructure while keeping data security in place using end to end data encryption in transit and at rest. All applications are hosted in a private sub-net for network segregation and minimizing external exposure. Applications use active load balancers to manage and distribute network traffic at scale to provide high fault tolerance. The platform uses Amazon RDS services to provide highly reliable and fault tolerant data persistence. Customer applications are deployed in self-managed containers using Amazon ECS to provide scale, security and highly dynamic CI/CD with AWS CodePipeLine.\nSuccess Stories and Immediate Savings Delivered\nChick-fil-A Hollywood\nChick-fil-A Hollywood\nEarly in 2020, a Chick-fil-A franchisee with Hollywood locations heard about ConnectedFresh. They already had a temperature monitoring solution in place but were looking for some improvements in usability, reliability, and support. Repeatedly changing batteries and needing to keep up on connectivity statuses made it feel like the system was another thing to manage rather than working quietly in the background, notifying them when they needed to act.\nConnectedFresh worked with Chick-fil-A to start a pilot program to implement sensors alongside their current solution to compare them side-by-side. The onsite team was very happy with the system\xe2\x80\x99s reliability and scalability, and ConnectedFresh quickly earned the team\xe2\x80\x99s trust.\nAs deployments expanded to additional locations, the team was able to see first-hand how easy the ConnectedFresh solution was to deploy at scale. Each store received a box in the mail with everything included. They simply plugged in the gateway and turned on the devices, and data was already flowing to the platform for them to view in real time.\nThe ConnectedFresh team worked with Chick-fil-A to understand what types of alerts and escalation paths were needed for the team, allowing them to change these parameters as they continued to grow. This ensured the right team members would be alerted at the right times, via their preferred methods; email, SMS, phone calls, Slack messages, etc. For example, if a freezer\xe2\x80\x99s temperature went above best practice parameters set by the team, alerts would automatically be sent to specific individuals who could take immediate action to protect their inventory and ensure fresh chicken for their customers.\nIn the end, ConnectedFresh provided both excellent customer service and an impactful product, and proved to be the trusted partner Chick-fil-A Hollywood had been searching for.\n\xe2\x80\x9cThe pandemic created stressors at every stage of the process, from labor to supply chain. We were stretched thin in juggling the complexities of running a restaurant in the middle of a crisis.\nConnectedFresh helped us win back that time, automating food safety processes to allow us to focus first and foremost on our guests and then our team. While we are moving out of crisis, ConnectedFresh\xe2\x80\x99s solutions will remain a critical component of our restaurants. We didn\xe2\x80\x99t know what we didn\xe2\x80\x99t know; just how much of a benefit they would be to our time and energy until we had them in place.\xe2\x80\x9d\n\xe2\x80\x93 Caleb G, Chick-fil-A Hollywood\nImmediate Catches\nIt\xe2\x80\x99s incredible what information lies beneath the surface, waiting to be found. It is not uncommon for customers to immediately realize benefits and savings from ConnectedFresh, brought to light instantly through AWS services.\nA brewery in Ohio with a large walk-in refrigerator was able to see through data that their door was accidentally being propped open with a container in the wrong location. They found this discrepancy within 24 hours of setting up their sensors.\nAnother Chick-fil-A location saved $700 worth of chicken product after being notified of a temperature fluctuation, realizing that they had inadvertently unplugged the refrigerator during cleaning. This was also caught within 24 hours of setting up their sensors.\nIt\xe2\x80\x99s not uncommon for customers to realize benefits immediately, many of which provide immediate ROI that pays for itself for many months, if not years. That\xe2\x80\x99s the goal with IoT and advanced analytics \xe2\x80\x93 finding issues before they become problems, allowing customers to become proactive rather than reactive.\nWhat\xe2\x80\x99s next for AWS IoT Core for LoRaWAN\nAWS IoT Core for LoRaWAN and other enabling services will continue to evolve, deploying the latest standards and expanding reach to deliver features that are in beta stages today. Power optimization, enhanced mobility, and industrial grade improvements are all in the future, further enabling solutions to become even more robust and insightful so customers can focus on what they do best: hospitality.\nYou can review our solution offering at AWS Marketplace and have Public AWS customer references.\nAuthors\nTushar Agrawal CTO of ConnectedFresh. A certified AWS solution architect, Tushar helps customers design innovative, scalable and enterprise ready solutions using the breadth and depth of AWS capabilities to deliver measurable business outcomes. Has in-depth experience designing IoT and IIoT systems across industries like travel & hospitality, energy management, smart manufacturing, smart cities, automation and IT/OT convergence. Worked with Hitachi Vantara, Deloitte and other large enterprises to help serve their customers in digital transformation.\nJake Simon CEO of ConnectedFresh, passionate about delivering impactful and affordable solutions for customers without the fuss of a large implementation. \xe2\x80\x9cMaking things more efficient through the use of technology\xe2\x80\x9d has been the mantra and guide to starting ConnectedFresh. Prior to ConnectedFresh, Jake has held numerous senior consulting and product development roles, all focused around IoT offerings for customers. He graduated from the University of Southern California with focuses on business, entrepreneurship, and technology.\nMahesh Pakala Global Principal Architect at Amazon Web Services. He is the trusted advisor to premier AWS partners to provide architectural guidance and strategy for successful partner engagements. Provide technology enablement & business strategy to assist them deliver migration & modernization solutions on AWS platform. He has been speaker in conferences and published blog posts. Prior life was an entrepreneur and worked for Dell, Oracle Corporation, and Ingres.'"
36,Importing AWS IoT Device Defender audit and detect findings into Security Hub,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/importing-aws-iot-device-defender-audit-and-detect-findings-into-security-hub/,"b'Introduction\nIn this post, you\xe2\x80\x99ll learn how the integration of IoT security findings into AWS Security Hub works, and you can download AWS CloudFormation templates to implement the solution. After you deploy the solution, every AWS IoT Device Defender audit and detect finding will be recorded as a Security Hub finding. The findings within Security Hub provide an AWS IoT Device Defender finding severity level and direct link to the AWS IoT Device Defender console so that you can take possible remediation actions. If you address the underlying findings or suppress the findings by using the AWS IoT Device Defender console, the solution will automatically archive any related findings in Security Hub.\nIn this previous blog on implementing security monitoring across OT, IIoT and cloud with AWS Security Hub, we discussed how a siloed approach to OT, IIoT and cloud security monitoring, could result in blind spots. Bad actors could exploit these blind spots, and that\xe2\x80\x99s why it is important to implement security monitoring across the entire attack surface including edge and cloud as well on-site and off-site assets. We used AWS Security Hub to gain a centralized view of security findings across both factory and cloud environments when implementing IIoT solutions.\nIn a previous blog How to import AWS IoT Device Defender audit findings into Security Hub, we discussed how to import AWS IoT Device Defender audit findings into Security Hub. In this blog, we added AWS IoT Device Defender detect findings and show you how to import AWS IoT Device Defender audit and detect findings into Security Hub using a custom solution.\nAWS Security Hub provides a comprehensive view of the security alerts and security posture in your accounts. In this blog post, we show how you can import AWS IoT Device Defender audit and detect findings into Security Hub. You can then view and organize IoT and IIoT security findings in Security Hub together with findings from other integrated AWS services, such as Amazon GuardDuty, Amazon Inspector, Amazon Macie, AWS Identity and Access Management (IAM), Access Analyzer, AWS Systems Manager, and more. In addition, you can integrate security events from OT Intrusion Detection Solutions (IDS) like Dragos, Claroty and Nozomi into AWS Security Hub. You can use AWS Security Hub to provide a centralized view of all security-related findings, where you can set up alerting and automatic remediation.\nWith AWS IoT Device Defender detect, customers can monitor for intellectual property theft, data exfiltration, impersonation, cloud infrastructure abuse, denial-of-service (DoS), lateral threat escalation, surveillance, cryptocurrency mining, command and control, malware and ransomware. How can you send these security findings to AWS Security Hub?\nSolution scope\nFor this solution, we assume that you are familiar with how to set up an IoT environment and set up AWS IoT Device Defender. To learn more how to set up your environment, see the AWS tutorials, such as Getting started with AWS IoT Greengrass and Setting up AWS IoT Device Defender\nThe solution is intended for AWS accounts with fewer than 10,000 findings per scan. If AWS IoT Device Defender has more than 10,000 findings, the limit of 15 minutes for the duration of the serverless AWS Lambda function might be exceeded, depending on the network delay, and the function will fail.\nThe solution is designed for AWS Regions where AWS IoT Device Defender, serverless Lambda functionality and Security Hub are available; for more information, see AWS Regional Services. The China (Beijing) and China (Ningxia) Regions and the AWS GovCloud (US) Regions are excluded from the solution scope.\nSolution overview\nWith this solution, you can configure AWS IoT Device Defender audit, rules detect and ML detect.\nThe templates that we provide here will provision an Amazon Simple Notification Service (Amazon SNS) topic notifying you when the AWS IoT Device Defender report is ready, and a Lambda function that imports the findings from the report into Security Hub. Figure 1 shows the solution architecture.\nFigure 1. Solution architecture\nSolution workflow:\n1.     AWS IoT Device Defender detects a misconfiguration (audit finding) or a behavioral anomaly from the monitored IoT device\n2.     AWS IoT Device defender publishes the event to an SNS topic.\n3.     As a result, an AWS Lambda function processes the generated finding (AWS IoT Device Defender audit) or anomalies (AWS IoT Device Defender Detect).\n4.     If it\xe2\x80\x99s an audit finding, the Lambda function gets additional details using AWS IoT Device Defender API. If it\xe2\x80\x99s an detect violation, it tries to get the severity from the name of the behavior that triggered the anomaly. You can customize each behavior\xe2\x80\x99s severity directly in the AWS CloudFormation templates.\n5.     Finally, the Lambda function imports a new finding into Security Hub. An example of findings in Security Hub is shown in Figure 3.\nAdditionally, when a security operator marks the alarm as either \xe2\x80\x9cFalse positive\xe2\x80\x9d or \xe2\x80\x9cBenign positive\xe2\x80\x9d through AWS IoT alarms console:\n1.     An Amazon Event Bridge rule monitoring AWS Cloudtrail event triggers an AWS Lambda function\n2.     The Lambda function archives the related finding in AWS Security Hub.\nPrerequisites\nYou must have Security Hub turned on in the Region where you\xe2\x80\x99re deploying the solution.\nYou must also have your IoT environment set. (To use test environment, you can use the following workshop \xe2\x80\x93 Get Started with AWS IoT )\nWalkthrough\nTo get started, you need to setup the sample solution.\n1. Log in to your AWS account if you haven\xe2\x80\x99t done so already. Choose Launch Stack to launch the CloudFormation console with the sample template. Choose Next.\nAdditionally, you can download the latest solution code from GitHub.\n2. Configure your stack parameters as shown in Figure 2. If you haven\xe2\x80\x99t configured any AWS IoT Device Defender on-going audits or security profiles, change to true the following parameters:\nCreate security profile BY creating rules of expected device behavior\nEnable on-going audits for your fleet\n3. Optionally, you can deploy additional AWS IoT Device Defender configurations using the following AWS CloudFormation parameters:\nCreate a security profile using machine learning models.\nAdjust the confidence level for ML-based anomalies (if enabled we can tweak the ML model).\nExtend the created security profiles (ML or rules) to monitor device-side metrics.\nSpecify your own subset of IoT devices ARNs to monitor for anomalies. By default, the solution monitors all devices using the deployed security profiles.\nWe\xe2\x80\x99ll use rule-based behavior to test the solution is working in the next step.\nFigure 2. AWS CloudFormation parameters\nTest the solution\nWe\xe2\x80\x99re going to simulate a security event that will trigger an AWS IoT Device Defender rule-based security profile. The rule-based profile has defined two behavior rules for Connection attempts and disconnects that are triggered after one occurrence. For this test, we\xe2\x80\x99ll use the MQTT test client, which acts as an IoT device that can publish and subscribe to MQTT topics.\nGo to AWS IoT Core console, and select MQTT test client. Select Subscribe to a topic and enter # (all topics) in Topic Filter. Finally, under Subscriptions\nSelect the cross to disconnect from topic. This should trigger a disconnect event that will trigger AWS IoT Device Defender rule-based alarms.\nYou can then go to AWS Security Hub console, under the navigation panel select Findings and then order findings based on \xe2\x80\x9cUpdated at\xe2\x80\x9d to find these related findings. Under the description, you\xe2\x80\x99ll find the profile, rule and criteria related to the alarm.\nFigure 3. AWS Security Hub findings\nNext, we\xe2\x80\x99ll mark the anomaly as a false positive to archive its finding in AWS Security Hub.\nGo to AWS IoT Core console, under the Security navigation panel, expand Detect and select Alarms. Select the alarm that has been triggered and then press the Mark verification state button. Select FALSE_POSITIVE and add any description. When you to return to AWS Security Hub findings console, search for Workflow status is SUPPRESSED to find the suppressed finding related to the anomaly.\nFigure 4. Marking alarm as false positive\n'"
37,Designing a Single Pane of Glass for Securing your Globally Deployed IoT-Workload,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/11/03/Screenshot-2022-11-03-at-09.12.46-1024x575.png,https://aws.amazon.com/blogs/iot/designing-a-single-pane-of-glass-for-securing-your-globally-deployed-iot-workload/,"b'Introduction\nCompanies are investing in large-scale Internet of Things (IoT) projects and deploying global scale IoT platform such as Deutsche Bahn or Carrier. Enterprises are looking for a solution that offers a multi-tenant Single Pane of Glass Device Lifecycle Management (DLM) which caters to both IT and OT operations.\nIn this blog we will focus on giving perspective guidance on how to architect a multi-tenant Single Pane of Glass IoT Platform for cyber-security posture. Enterprises of all shapes and sizes from different industry can benefit from such platform. From an IT point-of-view this platform would standardize enterprise IoT related cyber-security features such as device on-boarding, visibility and governance. From an OT point of view the platform would accelerate time to production since all the heavy lifting (account management, workload management, security etc.) is baked into the platform from day one.\nAWS Services\nIn this guidance blog we will be referencing several AWS Services. These services are integral parts of the reference architectures and best practices for the Single Pane of Glass approach.\nAWS Organizations is an account management service that enables you to consolidate multiple AWS accounts into an organization that you create and centrally manage. AWS Organizations includes account management and consolidated billing capabilities that enable you to better meet the budgetary, security, and compliance needs of your business. For more information go to AWS Organizations.\nAWS IoT Core lets you connect billions of IoT devices and route trillions of messages to AWS services without managing infrastructure. AWS IoT Core supports a number of communication protocols and connectivity methods. For more information go to AWS IoT Core.\nAWS IoT Device Defender is natively integrated with AWS IoT Core, and it is a security service that allows you to audit the configuration of your devices, monitor connected devices to detect abnormal behavior, and mitigate security risks. For more information about go to AWS IoT Device Defender.\nAWS Security Hub is a cloud security posture management service that performs security best practice checks, aggregates alerts, and enables automated remediation. It provides you with a comprehensive view of your security state in AWS and helps you check your environment against security industry standards and best practices. For more information go to AWS Security Hub.\nAmazon EventBridge is Amazon EventBridge is a server-less event bus service that you can use to connect your applications with data from a variety of sources. EventBridge delivers a stream of real-time data from your applications, software as a service (SaaS) applications, and AWS services to targets such as AWS Lambda functions, HTTP invocation endpoints using API destinations, or event buses in other AWS accounts. For more information go to Amazon EventBridge.\nUse Case Introduction\nFigure 1. Architecture introducing the high level solution\nFigure 1 shows a high level view on the issue we want to solve. We are displaying three example workloads: Refinery, Fuel Cells and Lubricants. Each of these use cases has their own IoT deployment in a distinct AWS region. Two different personas are displayed within the architecture: The Business User on a per use case level as well as the IoT Platform Administrators. Each Business User Persona needs access to their own IoT workload deployment. In this case the Refinery Business User needs the authentication as well as authorization to access the Refinery Deployments. The Lubricants Business User needs access to the Lubricants IoT workload, but not others like the Refinery. On the other hand we have the IoT Platform Admins that need access to all the workloads, no matter the region, account or use case. Additionally, the IoT Security Admin also will need to access and gain visibility into the security posture of all workloads deployed and be aware of e.g. expiring certificates.\nTenancy Model\nFigure 2. Illustration the tenancy type for this architecture\nFor the above-mentioned use-case we are will lay a foundation of our design by employing a style of tenancy which provides complete isolation of the IoT workloads. The highly isolated tenancy design provides cost, data and workload isolation. This allows easier management of resources deployed in an AWS account and setups the foundation for isolated IoT workloads for our OT business users while providing global insight for the IT Platform admins and security personas. This tenancy style also reduces the blast radius from a security point of view since the business users and their devices are accessible through their own tenant workload. This type of tenancy comes with its own challenges related to meshing of the tenants, cost visibility and implementing Single Pane of Glass IoT platform for global device management.\nControl, Data and Edge Plane\nFigure 3. Visualization of Control, Data and Edge Plane\nFrom the above illustrations in figure 1 & 2 we can compartmentalize the components in such a way where all control related use-cases are achieved through a single common interface called the IoT platform. This component serves as the Single Pane of Glass IoT device management portal for all personas. Since this component is control related, we can house this component in a conceptual boundary known as \xe2\x80\x9cControl Plane\xe2\x80\x9d.\nThe distinct tenant specific workloads component is specified as \xe2\x80\x9cIoT workload\xe2\x80\x9d. Since these are isolated workloads where devices connect to and send their telemetry these isolated tenant specific components can be housed in a conceptual boundary known as the \xe2\x80\x9cData/Telemetry plane\xe2\x80\x9c. All devices managed by individual business deployed across their businesses can be housed in a conceptual boundary known as the \xe2\x80\x9cEdge Plane\xe2\x80\x9d.\nThe individual IoT workload can comprise of (n) number of accelerators. These accelerators can perform a unique function such as provisioning a device, control & commanding a device, patching device, provisioning AWS IoT Greengrass Core etc. To learn more about function or use-case specific accelerator refer to the AWS Connected Device Framework for more information. This framework can serve as the foundational building block for this architecture.\nIsolating Accounts using AWS Organizations\nFigure 4. Account and Access management using AWS Organizations and Organizational Units\nWe now extend the guidance through the use of AWS specific services. AWS Organizations in this case allows customers to use Organizational Units (OUs) that provide capabilities to the accounts within those OUs. All OUs apply their own guardrails for the accounts as well as governance for the tenant accounts. We utilize three different OUs in Figure 4.\n1/ Shared Services Organizational Unit\nThe Single Pane of Glass resides within the Shared Services OU. It has its own account which hosts the aggregated dashboard. The OU in this case provides the capabilities to the own platform and grants access to the different user types to access the data they are allowed to see.\n2/ Workloads Organizational Unit\nThe workloads OU hosts has multiple accounts, one account per tenant. It permits the users coming from the Single Pane of Glass access to their workloads and the outbound and inbound data from IoT Devices.\n3/ Suspended Organizational Unit\nWorkloads in the suspended OU are no longer active but still part of the setup within AWS which allows for later investigation as well as deletion once no longer needed. That suspension can occur automatically base on criteria defined by the system administrators.\nEvent Driven Solution\nFigure 5. Amazon EventBridge and AWS IoT Core integration.\nIn section we add the use of Amazon EventBridge integrated with AWS IoT Core. That approach allows for an event driven solution which will interact with the control pane or Single Pane of Glass. The control plane account will have Amazon EventBridge set up to send and receive messages to and from the individual workload OU accounts. This integration allows to invoke the different IoT workloads in the accounts and also the collection of data from the individual devices up to a aggregated view in the control plane account. Cross account interactions require specific permission which can be understood in more detail in the Service control policies (SCPs) documentation.\nThe workload OU accounts subscribe to the messages coming from the control plane side, and vice versa. Each workload is isolated by an individual tenant account, which also allows for cost isolation and thus achieves the tenancy model we needed.\nSingle Pane of Glass Architecture\nFigure 6. Final Architecture for monitoring and managing a multi-region multi-account IoT workload\nFinally we can focus on a diagram (Figure 6) with all the elements of the Single Pane of Glass architecture.\nStarting from the right side we have multiple devices connected to AWS IoT Core. First, we focus our attention to the connection from AWS IoT Core into the workload. As the workload interacts with IoT devices through AWS IoT Core, Amazon EventBridge can be configured to react to specific events. Those events will then be passed onto the Single Pane of Glass accounts, where the user has access only to the relevant data and alarms.\nNow we turn our attention to the connection from AWS IoT Core on the right side to AWS IoT Device Defender. Natively integrated with AWS IoT Core, AWS IoT Device Defender will execute auditing and monitoring tasks, reporting any anomalies or non-compliance to the reporting pipeline. Also, AWS IoT Device Defender natively integrates with AWS Security Hub and can be configured to deliver the audit finding to this service (read more about the native integration here). Respectively, AWS Security Hub is integrated cross account, delivering the alarms to IT administrators and delegating actions to operations if necessary.\nThis architecture allows the security operations team as well as IoT platform admins access to security insights and findings across the different accounts and regions.\nFew examples of deviations that should be shared with security operation teams using AWS Security Hub are:\nMQTT-based data exfiltration: Data exfiltration occurs when a malicious actor carries out an unauthorized data transfer from an IoT deployment or from a device. The attacker launches this type of attacks through MQTT against cloud-side data sources.\nImpersonation: An impersonation attack is where attackers pose as known or trusted entities in an effort to access AWS IoT cloud-side services, applications, data, or engage in command and control of IoT devices.\nCommand and control, malware and ransomware: Malware or ransomware restricts your control over your devices, and limits your device functionality. In the case of a ransomware attack, data access would be lost due to encryption the ransomware uses.\nIf you want to find out more about the different security use cases covered by AWS IoT Device Defender you can access here.\n'"
38,Integrating AWS IoT SiteWise and Fleet Hub with IAM Identity Center and Okta,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/10/22/iot-blog-featureimage.png,https://aws.amazon.com/blogs/iot/integrating-aws-iot-sitewise-and-fleet-hub-with-iam-identity-center-and-okta/,"b'Introduction\nMany organizations are using an external identity provider to manage user identities. With an identity provider (IdP), you can manage your user identities outside of AWS and give these external user identities permissions to use AWS resources in your AWS accounts. External identity providers (IdP), such as Okta Universal Directory, can integrate with AWS IAM Identity Center (successor to AWS Single Sign-On) to be the source of truth for AWS IoT SiteWise and Fleet Hub for AWS IoT Device Management (Fleet Hub).\nAWS IoT SiteWise Monitor and Fleet Hub support a single sign-on (SSO) experience with AWS IAM Identity Center authentication. Users can access AWS IoT SiteWise Monitor and Fleet Hub with their existing corporate credentials. Identity provider administrators can continue to manage users and groups in their existing identity systems which can then be synchronized with AWS IAM Identity Center. AWS IAM Identity Center enables administrators to connect their existing external identity providers.\nIn this post, we show you step-by-step guidance to set up SSO with AWS IoT SiteWise Monitor and Fleet Hub with Okta Universal Directory.\nPre-requisites\nYou need to set up AWS IAM Identity Center and connect to Okta Universal Directory to use the same Okta user login for AWS IoT SiteWise Monitor and Fleet Hub. For instructions, see Single Sign-On between Okta Universal Directory and AWS\nThe high-level steps are as follows:\nEnable IAM Identity Center on the AWS Management Console. Create this IAM Identity Center account in the same AWS Region as AWS IoT SiteWise.\nAdd IAM Identity Center as an application Okta users can connect to.\nConfigure the mutual agreement between IAM Identity Center and Okta, download IdP metadata in Okta, and configure an external IdP in IAM Identity Center.\nEnable identity synchronization between Okta and IAM Identity Center.\nThis setup ensures that when a new account is added to Okta and connected to the IAM Identity Center, a corresponding IAM Identity Center user is created automatically.\nAfter you complete these steps, you can see the users assigned on the Okta console as shown below.\nYou can also see the users on the IAM Identity Center console, on the users page as shown below.\nConfigure AWS IoT SiteWise Monitor with IAM Identity Center authentication\nFollow the steps below to complete the AWS SiteWise Monitor with IAM Identity Center as the authentication method.\n1.From the AWS IoT SiteWise console, choose  Monitor  from the left navigation and then choose Portals. Click on Create portal button to create a IoT SiteWise portal.\n2.For Portal configuration, enter the following:\nUnder Portal details for Portal name, enter okta-iot-sitewise\nUnder User authentication, choose AWS IAM Identity Center\nUnder Support contact email, enter your email ID\nUnder Permissions, choose Create and use a new service role\n3.Under Additional features \xe2\x80\x93 optional screen, choose only Enable alarms and then, choose Create to complete the portal creation.\n4.Under Invite administrators, choose users from your Okta identity store and then choose Assign Users to complete the portal configuration.\n5.Once you complete all above steps, the system will create a unique URL for your AWS IoT SiteWise Monitor access through an external identity provider like Okta.\nConfigure Fleet Hub for AWS IoT Device Management with IAM Identity Center authentication\nFollow the steps below to complete the Fleet Hub for AWS IoT Device Management with IAM Identity Center as the authentication method.\n1.From the Fleet Hub for AWS IoT Device Management console, choose Create application. It will redirect to set up access in IAM Identity Center screen as shown below and then choose Next.\n2.For Index AWS IoT data, keep all default options and then,choose Next.\n3.For Configure application:\nUnder Application role, choose Create a new service role\nUnder Role name, Enter Fleethubrole\nUnder Application details, for Application name enter Fleethub-Okta                                                                                                                                                                      \n Click on Add users and choose your external identity provider users as shown below\nChoose Add selected users to complete the access assignments. Now the Fleet Hub application is ready for use and you can use your external identity provider Okta credentials to access Fleet Hub.\nAccessing AWS IoT SiteWise Monitor and Fleet Hub via IAM Identity Center\nAs a user, you can start in one of three ways:\nAWS IoT SiteWise\n1.Start from the Okta user portal page, select IAM Identity Center application and choose AWS IoT SiteWise Monitor.\n2.Start from the IAM Identity Center user portal and it will redirect to the Okta login page for authentication and then,choose Fleet Hub.\n3.Use the AWS IoT SiteWise Monitor Portal URL as shown above and it will redirect to the Okta login page for authentication.\nFleet Hub\n1.Start from the Okta user portal page, select IAM Identity Center application and choose Fleet Hub.\n2.Start from the AWS Identity Center user portal and it will redirect to the Okta login page for authentication and then, choose Fleet Hub.\n3.Use the Fleet Hub Portal URL as shown above and it will redirect to the Okta login page for authentication.\nCleanup\nIf you followed along with this solution, we suggest that you complete the following steps to avoid incurring charges to your AWS account once you have completed the walk through.\nDeleting AWS IoT SiteWise\nDeleting Fleet Hub\nDeleting your okta account (if needed)\nDeleting IAM Identity Center\n'"
39,Detect Cryptocurrency Mining Threats on Edge Devices using AWS IoT,b'Sunitha Eswaraiah',2022-11-30T21:07:01+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/10/18/NIS251-blogpost-diagram_v2-11-1024x474.png,https://aws.amazon.com/blogs/iot/detect-cryptocurrency-mining-threats-on-edge-devices-using-aws-iot/,"b'Introduction\nMachine learning (ML) at the edge requires powerful edge requires powerful edge devices with a unique set of requirements. The availability, safety, and security requirements for the edge differ from cloud since they are located at the customer site, outside the data center, and interface directly with operational technology (OT) and the internet. Since edge locations often lack the physical security that data centers have and lack the security controls available in the cloud, they have become attractive targets for bad actors such as cryptocurrency miners. In many cases, edge devices don\xe2\x80\x99t have anti-malware defenses making it even more difficult to detect cryptocurrency mining activity.\nAn end-to-end security model that protects edge devices from hostile networks and protects sensitive data and ML models is paramount for a successful deployment. Customers can use AWS IoT Device Defender to help audit and monitor their edge device fleet. In this blog post, we show you the steps involved in helping to detect and mitigate cryptocurrency mining threats on edge devices using AWS IoT Device Defender custom metrics.\nCryptocurrency mining use case\nCryptocurrency, sometimes called crypto-currency or crypto, is any form of currency that exists digitally or virtually and uses cryptography to secure transactions. Cryptocurrency mining is a process of creating new digital coins and is a compute intensive activity that has been on the rise in recent years.\nCryptojacking is a type of cybercrime that involves the unauthorized use of devices (edge computers, smartphones, tablets, or even servers) to mine for cryptocurrency and illicitly create currency. As cryptocurrency prices rise and more powerful edge devices with GPU capabilities are used to run ML at the edge use cases, there is an increasing threat of cryptojackers to exploit security vulnerabilities on edge devices. When this happens, edge computing resources are used to mine crypto currency resulting in higher CPU/GPU usage and a degradation in performance of edge applications and an increase in ML at the edge inference processing times.\nIn this blog, we show you how to monitor CPU/GPU usage and ML at the edge inference processing time with custom metrics that can help indicate crypto currency mining activity on edge devices. AWS IoT Device Defender custom metrics are metrics you define that are unique to your devices and use case. In this cryptocurrency mining cyber security use case, you can monitor for anomalies using two custom metrics \xe2\x80\x93 CPU/GPU usage metric and average ML at the edge inference time metric. More information about using AWS IoT Device Defender for detecting cryptocurrency mining can be found here. Note that to investigate an anomaly, you need to correlate the alarm details with other contextual information such as device attributes, device metric historical trends, security profile metric historical trends, standard metrics, and logs to determine if a security threat is present.\nSolution prerequisites\nAWS account\nA development environment/computer with docker and AWS CLI installed.\nAWS role or user with ability to create a new IAM user or role for AWS IoT Greengrass minimal IAM policy.\nA computer with the latest browser.\nBasic understanding of Linux such as creating directories, setting file permissions, and programming.\nSolution architecture and overview\nOur edge security solution for detecting cryptocurrency mining threats implements edge application management with AWS IoT Greengrass, custom metrics data collection and ingestion to the cloud with AWS IoT Greengrass custom components and AWS IoT Device Defender for security profile definition and monitoring.\nThe steps to implement the solution are as follows:\nCreate an AWS IoT Greengrass device\nCreate and deploy a custom AWS IoT Greengrass component for AWS IoT Device Defender\nDefine security profiles with custom metrics for GPU resources and average ML at the edge inference time in AWS IoT Device Defender\nSimulate the GPU load and ML at the edge average inference time metric changes for a cryptocurrency mining situation\nCheck and acknowledge AWS IoT Device Defender service\xe2\x80\x99s alarm status\n\nFigure: Solution architecture to help monitor and detect edge devices for crypto currency mining threats\nSolution walk through\n1. Prepare and Publish AWS IoT Device Defender component with custom metrics\nConnect to your development computer using AWS CLI or AWS Cloud9 instance. This blog post deploys the solution to the us-east-1 (N. Virginia) region by default. You\xe2\x80\x99ll see instructions to change the region in case you want to deploy to another region.\nFirst, run the following to install AWS IoT Greengrass Development Kit to test and publish custom AWS IoT Greengrass components.\npython3 -m pip install -U git+https://github.com/aws-greengrass/aws-greengrass-gdk-cli.git@v1.1.0\nBash\nWe use a slightly modified version of a public and open source AWS IoT Device Defender component for AWS IoT Greengrass. The modifications are mainly enhanced debugging/logging for easier development workflow and custom metrics definitions for simulated GPU resource metrics and ML at the edge inference time metrics.\nThe public AWS IoT Device Defender component is deployed from the central AWS IoT Greengrass component repository, but the modified version will be stored in your own account.\nClone the Git repository of this blog post and run the component repository build script:\ncd ~/environment\ngit clone https://github.com/aws-samples/aws-iot-blogs-greengrass-device-defender-custom\ncd aws-iot-blogs-greengrass-device-defender-custom\nchmod +x build.sh\n./build.sh\nBash\nRun the following to build and publish the AWS IoT Greengrass component. To change the default region us-east-1, modify region section in the com.awsiotblog.DeviceDefenderCustom/gdk-config.json file.\ngdk component build\ngdk component publish\nBash\nGo to AWS IoT Greengrass console > Components to confirm your component is published.\n2. Create and deploy a containerized AWS IoT Greengrass device\nIn this section, we\xe2\x80\x99ll use docker containers to create an AWS IoT Greengrass device to simulate and represent your edge device.\nThe Dockerfile in the repository will allow us to get the base AWS IoT Greengrass container image and build it with some GPU resource metric measurement files.\nRun the following to build the AWS IoT Greengrass device container.\ncd ~/environment/aws-iot-blogs-greengrass-device-defender-custom\ndocker build -t gg-awsiotblog-image .\nBash\nThe AWS IoT Greengrass container requires AWS credentials to provision these resources and deploy the local development tools. Create an IAM user with Minimal IAM policy for installer to provision resources or retrieve temporary AWS credentials from a role that has the same minimal IAM policy to provide it to the container. For details, see Run AWS IoT Greengrass in a Docker container with automatic resource provisioning.\nCreate a folder where you place your credential file.\ncd ~/environment/\nmkdir ./greengrass-v2-credentials\nBash\nCreate a configuration file named credentials in the ./greengrass-v2-credentials folder. Add your AWS credentials to the credentials file in the following format.\n[default]\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\naws_session_token = AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\nInclude aws_session_token for temporary credentials only.\nRun the following to create, provision and initialize an AWS IoT Greengrass device. This container will represent your edge device with GPU resources.\ndocker run -v $(pwd)/greengrass-v2-credentials:/root/.aws/:ro \\\n-e GGC_ROOT_PATH=/greengrass/v2 \\\n-e AWS_REGION=us-east-1 \\\n-e PROVISION=true \\\n-e THING_NAME=gg-awsiotblog-01 \\\n-e THING_GROUP_NAME=gg-awsiotblog \\\n-e TES_ROLE_NAME=GGBlogTokenExchangeRole \\\n-e TES_ROLE_ALIAS_NAME=GGBlogTokenExchangeRoleAlias \\\n-e COMPONENT_DEFAULT_USER=ggc_user:ggc_group \\\n--name gg-awsiotblog-01 \\\ngg-awsiotblog-image:latest\nBash\nAfter running the docker container, you\xe2\x80\x99ll see the final log output as the following; this indicates your virtual AWS IoT Greengrass device is provisioned and started successfully.\n\xe2\x80\xa6\nLaunching Nucleus\xe2\x80\xa6\nLaunched Nucleus successfully..\nNOTE: After creating the first container, you can run the command with different THING_NAME inputs to create more virtual edge devices.\nYou can go to AWS IoT > Manage > Greengrass devices > Core devices to see the created AWS IoT Greengrass devices.\n3. Deploy components to the AWS IoT Greengrass simulated device fleet\nNow, it\xe2\x80\x99s time to deploy some components to your newly created device, including the custom/modified AWS IoT Device Defender component.\nBefore deploying the component, run the following command to allow the AWS IoT Greengrass device to download component artifacts from Amazon Simple Storage Service (Amazon S3).\ncd ~/environment/\naws iam put-role-policy --role-name GGBlogTokenExchangeRole --policy-name GGComponentArtifactPolicy --policy-document file://component-artifact-policy.json\nBash\nThe deployed virtual device is added into gg-awsiot-blog thing group. So, you\xe2\x80\x99ll create a deployment that targets the gg-awsiot-blog thing group.\nGo to AWS IoT > Manage > Greengrass devices > Deployments\nChoose Create, specify a deployment name\nSelect the target name as gg-awsiotblog, choose Next\nOn Step 2:\nSelect com.awsiotblog.DeviceDefenderCustom under My components\nSelect aws.greengrass.Cli and aws.greengrass.Nucleus under Public components\nOn Step 3 \xe2\x80\x93 Configure components, you should see your 3 selected components.\nChoose \xe2\x80\x9ccom.awsiotblog.DeviceDefenderCustom\xe2\x80\x9d component and select Configure component\nOn the right pane, enter the following for Configuration to merge\n{\n""EnableGPUMetrics"": true\n}\nJSON\nFor the next steps, proceed by selecting Deploy.\nAfter creating the deployment, your device will receive the deployment, apply it and report the status to the cloud. Finally; you\xe2\x80\x99ll see the Core devices section in the deployment details page as your device reported as Healthy.\nNow, you have your AWS IoT Greengrass device reporting device-side metrics and custom metrics to AWS IoT Device Defender. You can check the actual payloads that the component publishes.\ndocker exec -it gg-awsiotblog-01 grep ""stdout. Publishing metrics:"" /greengrass/v2/logs/com.awsiotblog.DeviceDefenderCustom.log\nBash\nCopy and paste the output JSON to your favorite JSON parser/viewer to check the metrics published from your devices.\n4. Create a security profile for custom GPU resource metric and average ML at the edge average inference time metric.\nFirstly, you\xe2\x80\x99ll start with definition of the custom metrics in AWS IoT Device Defender:\nGo to AWS IoT > Manage > Security > Detect > Metrics and choose Create.\nCreate a custom metric for GPU load.\nFor name, specify gpu_load_per_inference\nFor type, choose number.\nCreate a custom metric for inference time.\nFor name, specify avg_inference_time\nFor type, choose number.\nNow, AWS IoT Device Defender is able to monitor two defined custom metrics from the edge devices.\nYou can proceed to create a security profile that uses custom the GPU metric and the ML at the edge average inference time metric to evaluate the cryptocurrency threat situation.\nNavigate to the Security Profiles section of the AWS IoT Device Defender Console: AWS IoT > Manage > Security > Detect > Security Profiles\nChoose Create Security Profile and choose Create Rule-based anomaly Detect profile\nFor Target, choose gg-awsiotblog\nSpecify a Security Profile name\nClear all Cloud-side metrics to keep the focus.\nSelect two Device-side custom metrics that you just created; gpu_load_per_inference and avg_inference_time.\nChoose Next\nUnder the Define metric behaviors section, specify the following parameters:\nMetric: gpu_load_per_inference\nOperator: \xe2\x80\x9cLess Than\xe2\x80\x9d\nValue: \xe2\x80\x9c40\xe2\x80\x9d\nDuration: \xe2\x80\x9c5 minutes\xe2\x80\x9d\nMetric: avg_inference_time\nOperator: \xe2\x80\x9cLess Than\xe2\x80\x9d\nValue: \xe2\x80\x9c100\xe2\x80\x9d\nDuration: \xe2\x80\x9c5 minutes\xe2\x80\x9d\nChoose Next\nChoose Create\n5. Run the cryptocurrency mining condition simulation\nNow our simulated AWS IoT Greengrass device runs in a container and publishes device side metrics along with custom metrics to AWS IoT Device Defender service. Current values of custom metrics are within the expected behavior of the device.\nIn each container, there are two files that represent custom metrics as /var/gpu_load_fb and /var/gpu_inference_fb; similar to other available system metrics like CPU temperature, load \xe2\x80\xa6 etc. The custom AWS IoT Device Defender component is configured to read metric values from those files for each metric publish operation.\nNow, you\xe2\x80\x99ll update the values in those files to simulate the condition of a cryptocurrency mining activity on your GPU-powered device, along with your ML model. Increase of GPU load and average ML model inference time will represent this situation as an abnormality.\ndocker exec -it gg-awsiotblog-01 bash -c ""echo 85 > /var/gpu_load_fb; echo 180 > /var/gpu_inference_fb""\nBash\nAfter running the update, you can check the published payloads for the device to see the increasing custom metrics in the payload, using the following command.\ndocker exec -it gg-awsiotblog-01 grep ""stdout. Publishing metrics:"" /greengrass/v2/logs/com.awsiotblog.DeviceDefenderCustom.log\nBash\nOnce metrics are delivered to the AWS IoT Device Defender service and evaluated by the service, you\xe2\x80\x99ll see the alarm status on the Security Profile page.\nCongrats! You made the AWS IoT Device Defender service monitor and detect an abnormal behavior by configuring your edge device to send GPU load and ML at the edge inference time custom metrics to help detect cryptocurrency mining threat at the edge.\nLastly, note that we\xe2\x80\x99ve created the security profile with no automated actions. In this case, the alarm status appears only on the AWS IoT Device Defender console and you are able to start a mitigation action on the console. You can also create and set an Amazon Simple Notification Service in the security profile to notify users or other services and take customized automated actions in case of an AWS IoT Device Defender alarm. Check the documentation for the AWS IOT Device Defender Mitigation Actions for more information.\nCleanup\nStop and remove the docker container by running docker stop gg-awsiotblog-01 and docker rm -v gg-awsiotblog-01 commands.\nDelete the created AWS IoT Greengrass device.\nDelete the created custom AWS IoT Greengrass component.\nDelete the security profiles and custom metrics in AWS IoT Device Defender.\n'"
40,How to use your own data source in AWS IoT TwinMaker,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/10/18/Asset-2-1024x536.png,https://aws.amazon.com/blogs/iot/own-data-source-aws-iot-twinmaker/,"b'Introduction\nAWS IoT TwinMaker makes it easier for developers to create digital twins of real-world systems such as buildings and factories with the ability to use existing data from multiple sources.\nAWS IoT TwinMaker uses a connector-based architecture that you can connect data from your own data source to AWS IoT TwinMaker without needing to re-ingest or move the data to another location. AWS IoT TwinMaker provides built-in data connectors for AWS services such as AWS IoT SiteWise and Amazon Kinesis Video Streams. You can also create custom data connectors to use with other AWS or third-party data sources, such as Amazon Timestream, Amazon DynamoDB, Snowflake, and Siemens Mindsphere.\nIn this blog, you will learn how to use your own data source in AWS IoT TwinMaker using the AWS IoT TwinMaker data connector interface.\nOverview\nThe connection between a data source and AWS IoT TwinMaker is described in Components. A component accesses an external data source by using a Lambda connector. A Lambda connector is a Lambda function that you specify in the component definition.\nHere are the steps to create a data connector for Amazon DynamoDB using a Schema initializer connector to fetch the properties from the underlying data source and a DataReader connector to get the time-series values of these properties. Once the data connector is created, you will receive direction on how to create a component for this data connector and attach it to entities.\nAmazon DynamoDB is used as data source in this post but the concepts described are applicable for any other data source.\nPrerequisites\nTo setup and execute the steps in this blog, you need the following:\nAn AWS account. If you don\xe2\x80\x99t have one, see Set up an AWS account.\nAn AWS IAM Identity Center (successor to AWS Single Sign-On) user with the permissions to create the resources described in the blog.\nRead the section What is AWS IoT TwinMaker? of the documentation to understand the key concepts of AWS IoT TwinMaker.\nWalkthrough\nIn this walkthrough, you will perform 6 steps in order to connect your Amazon DynamoDB data source to AWS IoT TwinMaker:\nCreate a DynamoDB table. This table is only for the purpose of this post. You can easily adapt the instructions to use an existing database.\nCreate a Lambda Function for the Schema initializer connector.\nCreate a Lambda Function for the DataReader. You will need to give to the function\xe2\x80\x99s execution role the permissions to read from the table.\nCreate a TwinMaker Workspace. You will need to add to the workspace role the permissions to invoke both functions.\nCreate a TwinMaker Component.\nTest the component. Before testing the component, you will create a TwinMaker entity and attach the component to the entity.\nStep 1: Create a DynamoDB table\nFor the purpose of this post, you will create a DynamoDB table named TwinMakerTable that contains the key thingName of type String as partition key and the key timestamp of type Number as Sort key. See how to create a DynamoDB table for more information.\nThe table you created would store air quality measurements from sensors. You will keep it simple for this post and create items in the table corresponding to measurements from a sensor identified by its name (stored as partition key thingName). In addition to the name of the sensor, each measurement has the following properties of type Number: timestamp (stored as sort key timestamp that is the Unix timestamp in milliseconds of the measurement); temperature, humidity and co2.\nLet\xe2\x80\x99s create 5 items in the table, corresponding to 5 measurements of a sensor named airTwin. For the timestamp you can receive the current timestamp in milliseconds from this website and then derive 5 timestamps by subtracting 10000 per measurement. You can then enter random values for the properties: temperature, humidity and co2.  See Write data to a table using the console to learn more.\nNow that you have the table created with data, you will create two Lambda functions. The first one for the Schema initializer connector and the second one for the DataReader connector.\nStep 2: Create a Schema initializer connector\nThe Schema initializer connector is a Lambda function used in the component type or entity lifecycle to fetch the component type or component properties from the underlying data source. You will create a Lambda function that will return the schema of the TwinMakerTable.\nYou create a Node.js Lambda function using the Lambda console.\nOpen the Functions page.\nOn the Lambda console, choose Create function.\nUnder Basic information, do the following:\nFor Function name, enter TwinMakerDynamoSchemaInit.\nFor Runtime, confirm that Node.js 16.x is selected.\nChoose Create function.\nUnder Function code, in the inline code editor, copy/paste the following code and choose Deploy:\nexports.handler = async (event) => {\n    let result = {\n          properties: {\n                temperature: {\n                  definition: {\n                      dataType: {\n                          type: ""DOUBLE""\n                      },\n                      isTimeSeries: true\n                  }\n                },\n                humidity: {\n                  definition: {\n                      dataType: {\n                          type: ""DOUBLE""\n                      },\n                      isTimeSeries: true\n                  }\n                },\n                co2: {\n                  definition: {\n                      dataType: {\n                          type: ""DOUBLE""\n                      },\n                      isTimeSeries: true\n                  }\n                },\n              \n          }\n        }\n    \n    return result\n}\nJavaScript\nThis function sends the definition of each property of our table and specifies the type. In this case all properties are of type \xe2\x80\x9cDOUBLE\xe2\x80\x9d and are time-series data. You can check the valid types in the documentation.\nNote: here the properties are hard-coded in the function. You could design a function that retrieves automatically the properties and their types from an Item for example.\nNow let\xe2\x80\x99s create the DataReader connector.\nStep 3: Create a DataReader connector\nDataReader is a data plane connector that is used to get the time-series values of properties in a single component.\nYou create a Node.js Lambda function using the Lambda console.\nOpen the Functions page.\nOn the Lambda console, choose Create function.\nUnder Basic information, do the following:\nFor Function name, enter TwinMakerDynamoDataReader.\nFor Runtime, confirm that Node.js 16.x is selected.\nChoose Create function.\nUnder Function code, in the inline code editor, copy/paste the following code and choose Deploy:\nconst TABLE = \'TwinMakerTable\'\nconst aws = require(\'aws-sdk\')\nconst dynamo = new aws.DynamoDB.DocumentClient()\n\n\nexports.handler = async (event) => {\n    try {\n \n        let {workspaceId, entityId, componentName, selectedProperties, startTime, endTime } = event\n        \n        \n        // QUERY THE DATABASE WITH THE SELECTED PROPERTIES\n        const {Items} = await dynamo.query({\n            TableName: TABLE,\n            ProjectionExpression: `${selectedProperties}, #tmsp`,\n            KeyConditionExpression: `thingName = :hashKey AND #tmsp BETWEEN :startTime AND :endTime`,\n            ExpressionAttributeNames: {\n                \'#tmsp\': \'timestamp\'\n            },\n            ExpressionAttributeValues: {\n                \':hashKey\': entityId,\n                \':startTime\': (new Date(startTime)).getTime(), \n                \':endTime\': (new Date(endTime)).getTime() \n            }\n        }).promise()\n\n        let results = { propertyValues: [] }\n        let res = []\n        Items.forEach(item => {\n    \n            selectedProperties.forEach(prop => {\n                if(!res[prop]){\n                    res[prop] = {\n                        entityPropertyReference:{\n                            propertyName: prop,\n                            componentName,\n                                   entityId: event.entityId\n\n                        },\n                        values: []\n                    }\n                }\n                res[prop].values.push({\n                    time: (new Date(item[\'timestamp\'])).toISOString(),\n                    value: {doubleValue: item[prop]}\n                })\n            })\n    \n        })\n    \n        for (let key in res){\n            results.propertyValues.push(res[key])\n        }\n    \n        console.log(results)\n        return results\n    } catch (e) {\n        console.log(e)\n    }\n\n}\nJavaScript\nThe TwinMaker component will use this DataReader connector to fetch the data from the DynamoDB table. The component provides in the request two properties startTime and endTime (ISO-8601 timestamp format) that are used by the connector to fetch only the data in this time range. You can check the request and response interfaces in the Data connectors section of the documentation.\nBefore moving to the next step, you need to grant the function the access to the table. See Allows a Lambda function to access an Amazon DynamoDB table to learn more.\nNow you can move to the step of creating a workspace in AWS IoT TwinMaker.\nStep 4: Create a Workspace in AWS IoT TwinMaker\nOn the AWS IoT TwinMaker console, create a workspace named AirWorkspace. You can follow the instructions of the section Create a workspace of the AWS IoT TwinMaker documentation.\nOnce the workspace is created, you should have an Amazon Simple Storage Service (Amazon S3) bucket created. AWS IoT TwinMaker will use this bucket to store information and resources related to the workspace.\nYou should also have an IAM Identity Center role created. This role allows the workspace to access resources in other services on your behalf.\nBefore creating the component, you must provide permissions to invoke both lambda functions (created in the previous steps) to the workspace role. See Permissions for a connector to an external data source for an example of giving permission to the service role to use a Lambda function.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""VisualEditor0"",\n            ""Effect"": ""Allow"",\n            ""Action"": ""lambda:InvokeFunction"",\n            ""Resource"": [\n                ""arn:aws:lambda:{{AWS_REGION}}:{{ACCOUNT_ID}}:function:TwinMakerDynamoDataReader"",\n                ""arn:aws:lambda:{{AWS_REGION}}:{{ACCOUNT_ID}}:function:TwinMakerDynamoSchemaInit""\n            ]\n        }\n    ]\n}\nJSON\nYou can now create your component.\nStep 5: Create an AWS IoT TwinMaker component\nSelect the workspace you have created. In the workspace, choose Component types and then choose Create component type.\nCopy the following JSON document in the Request section and replace the ARN of the DataReader and Schema initializer functions respectively with the ones you created before:\n{\n  ""componentTypeId"": ""com.dynamodb.airQuality"",\n  ""description"": ""Connector for DynamoDB \xe2\x80\x93 Use case Air Quality"",\n  ""propertyDefinitions"":{\n   },\n  ""functions"": {\n      ""dataReader"": { \n            ""implementedBy"": {\n                             ""lambda"": {\n                                    ""arn"": ""arn:aws:lambda:{{AWS_REGION}}:{{ACCOUNT_ID}}:function:TwinMakerDynamoDataReader""\n                              }\n             }\n      },\n      ""schemaInitializer"": {\n            ""implementedBy"": {\n                             ""lambda"": { \n                                   ""arn"": ""arn:aws:lambda:{{AWS_REGION}}:{{ACCOUNT_ID}}:function:TwinMakerDynamoSchemaInit""\n                               }\n            }\n       }\n  }\n}\nJSON\nChoose Create component type. Now the component is created, you can create an entity to test the component.\nStep 6: Create an entity and test the component\nYou will now create an entity and attach the component you created to it.\nOn the Workspaces page, choose your workspace, and then in the left pane choose Entities.\nOn the Entities page, choose Create, and then choose Create entity.\nIn the Create an entity window, enter airTwin for the entity name and also for the entity ID of your entity.\nChoose Create entity.\nOn the Entities page, choose the entity you just created, and then choose Add component.\nEnter a name for the component. You can call it dynamoAirComponent.\nIn Type, select the component com.dynamodb.airQuality created previously.\nChoose Add component.\nThe component is attached to the entity with the ID airTwin. Now the only step that remains, is to test the component. When testing the component (or when calling the GetPropertyValueHistory API action), the component will send to the DataReader Lambda connector a request including the ID for the entity. The Lambda connector will use the ID to query the measurements of the sensor with the name corresponding to the ID. In this case, it will be measurements from the airTwin sensor.\nOn the Entities page, choose the entity airTwin, and then select the component com.dynamodb.airQuality.\nThen choose Actions and View component details.\nIn the tab Test, select the properties you want to retrieve and a time range. Make sure that the time range selected includes the timestamp of the measurements.\nFinally, choose Run test to test our component.\nYou should see the measurements of your sensors in the Time-series result section.\nYou can now call the GetPropertyValueHistory API action to retrieve the measurements from your sensors stored in your DynamoDB table.\nCleaning up\nTo avoid incurring future charges, delete the resources created during this walk-through.\n'"
41,Utilizing AWS Services to Quickly Build Solutions for Robotics Use Cases,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/10/11/robotics-use-cases.gif,https://aws.amazon.com/blogs/iot/utilizing-aws-services-to-quickly-build-solutions-for-robotics-use-cases/,"b'Introduction\nAutonomous mobile robots (AMRs) are widely used in many industries like logistics and manufacturing. However, there are various challenges in developing and operating autonomous robots. To develop autonomous robots, a wide range of technologies are required, and the process is complex and time-consuming. Integration with the cloud is also required to develop and operate the robots effectively. However, many robot builders are not familiar with the benefits of cloud robotics or lack cloud development expertise that can help them bring smarter robots to market faster.\nBy reading this article, you will learn how to solve the common challenges in developing and operating autonomous robots with AWS services. You can also understand which services are required to realize your use case and where to start your prototype.\nChallenges in developing and operating autonomous robots\nLet us consider the challenges of autonomous robot development in three phases: build, test, and deploy.\nThe development of robots requires expertise in a wide range of domains. For example, artificial intelligence (AI) and machine learning (ML) technologies are used for autonomous navigation; cloud connectivity is required for application integration; and video streaming is used for remote monitoring and operation.\nDuring the testing phase, repeated trials are necessary to ensure the robots work correctly in various situations and environments. However, the availability of robot hardware can be limited and testing in a physical environment is costly and time consuming.\nOnce in production, robot engineers and operators need to monitor and manage the fleet, including robot health and status. A mechanism to deploy applications on the device and control the robot remotely are required. In some cases, interoperability across multiple types of robots and systems are also a requirement.\nBecause of these challenges, development of autonomous robots is laborious and time-consuming. AWS provides various services that can be used to develop, test, and operate such robot applications faster. With these services, you can quickly build your prototypes and easily operate a large number of robots in production. In the following section, I will introduce how you can utilize these services in robot development and solve the challenges.\nAWS Services for Robotics\nCommunication between robot and cloud: AWS IoT Core\nAn autonomous robot is supposed to operate by itself in various environment, and unforeseen circumstances requires help by operators. In that case, the following capabilities are required. For example, operators can remotely control the robot via the cloud and developers can troubleshoot using the logs collected from robots. You can utilize AWS IoT Core to develop these features.\nAWS IoT Core is a managed cloud platform for connected devices to interact with cloud applications and other devices easily and securely. Devices can be connected via lightweight protocols such as MQTT and communicate with the cloud and other devices. The messages collected from the device can be routed to other AWS services such as database, storage, analytics and AI/ML services.\nFor example, you can integrate AWS IoT Core and other AWS services to collect sensor data and log data from robots, store the data into a data lake for analysis and troubleshooting, and create dashboards for near real-time visualization. This article shows major patterns of data collection and visualization with AWS IoT services. For example, Pattern 6 in the article can be used for near real-time visualization use case.\nYou might also want to interact with your robots using web or mobile apps. You can also use Device Shadow feature to synchronize state between the robot and the cloud. This allows the user or application to know the latest status of the robot and send command to the robot even when the robot is offline.\nFigure 1. Using AWS IoT Core for the communication between robot and application\nSoftware Deployment and Execution: AWS IoT Greengrass\nTo run the developed applications on actual robots, a mechanism to deploy and manage the software is necessary. It might be also necessary to keep improving applications and deploying updates even after robots have been shipped. However, it is difficult to create a mechanism to manage the application software, deploy to multiple robots at once, and modify the application configuration depending on the type of robot.\nAWS IoT Greengrass is an IoT open source edge runtime and cloud service that helps you build, deploy, and manage device software. You can manage the developed applications in the cloud, deploy and run the applications on a specific robot or multiple robots. Applications can be developed in popular programming languages or run on Docker containers. You can setup multiple software configurations for different types of robot fleets. With these features, you don\xe2\x80\x99t need to develop your own mechanism to deploy and manage the applications running in the robot and can concentrate on developing the applications\nAWS IoT Greengrass also provides a mechanism called components, which are pre-provided by AWS and the community to make device-side development efficient. For example, with Greengrass component, applications running on Greengrass can communicate with AWS IoT Core, and machine learning inferences at the edge such as image recognition can be easily implemented. You can also deploy and manage ROS based application with Greengrass and Docker. AWS IoT Greengrass allows you to quickly deploy and run your application on the robot, allowing developers to focus on developing the application itself. You can get started from AWS IoT Greengrass V2 Workshop.\nFigure 2. Using AWS IoT Greengrass for robot software deployment and management\nMachine Learning at Edge: Amazon SageMaker and Amazon SageMaker Edge\nTo make a robot work autonomously, the robot have to recognize the environment correctly. For example, tasks such as obstacle detection and avoidance, human and object detection or mapping are necessary. These tasks are often needed to run at the edge due to several reasons like unstable network connection, network bandwidth and cost. In this use case, customers want to train machine learning (ML) models, deploy and make inference at the edge.\nFigure 3. ML model workflow with Amazon SageMaker and SageMaker Edge\nTo collect raw data like image, rosbag or telemetry for ML model training, you can use AWS IoT Greengrass stream manager. With stream manager, you can transfer high-volume IoT data to the AWS Cloud efficiently and reliably. Stream manager works in environments with unstable connectivity and you can configure the AWS services such as Amazon S3 and Amazon Kinesis Data Streams to export data.\nAfter collecting the raw data, you can use Amazon SageMaker to build your ML model. Amazon SageMaker is a service to build, train, and deploy ML models for any use case with fully managed infrastructure, tools, and workflows. For example, you can annotate the images collected by your robots with Amazon SageMaker Ground Truth and train your custom ML model with SageMaker.\nOnce you build your custom ML model, you can utilize Amazon SageMaker Edge to optimize and deploy your ML model to edge device. Amazon SageMaker Edge enables machine learning on edge devices by optimizing, securing, and deploying models to the edge, and then monitoring these models on your robot fleet. You can optimize your ML model at cloud and deploy it as a Greengrass component with Amazon SageMaker Edge Manager. After the model and SageMaker Edge Manager are deployed to the robot, SageMaker inference engine will start and your robot applications can use the inference result at the edge.\nRemote Control and Monitoring: Amazon Kinesis Video Streams\nAMRs are used to move materials in environments like warehouses. They can navigate by themselves because they are equipped with cameras and other sensors to recognize people, obstacles, and other objects. However, in case of stuck, for example, you can use the video from the cameras to monitor and operate the robots remotely. In some cases, you want to store the video in the cloud for analysis and troubleshooting purposes. However, it is difficult to develop an infrastructure to stream and collect large amount of video data in real time.\nAmazon Kinesis Video Streams makes it easy to securely stream media from connected devices to AWS for storage, analytics, machine learning (ML), playback, and other processing. Amazon Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming media from millions of devices. Users can collect video from cameras of robots, playback for real-time monitoring or on-demand troubleshooting. Amazon Kinesis Video Streams also supports ultra-low latency two-way media streaming with WebRTC, as a fully managed capability, for the use case like remote control which require sub-second latency.\nAmazon Kinesis Video Streams provides SDKs for the devices that can ingest video from the camera of robot to the cloud or stream over peer-to-peer connection using WebRTC. You can use either the Amazon Kinesis Video Streams Producer SDK or WebRTC SDK, depending on the use case. For example, if you need to collect and store video in the cloud for on-demand playback and analysis, you should use Producer SDK. On the other hand, if you need real-time playback with sub-second latency for remote control or bi-directional media streaming, you can use WebRTC SDK. These SDKs make it easy to securely stream media.\nYou can try Amazon Kinesis Video Streams Producer SDK, video play back and video analysis with Amazon Kinesis Video Streams Workshop. If you want to learn how to use Amazon Kinesis Video Stream with WebRTC, there is Amazon Kinesis Video Streams WebRTC Workshop.\nFigure 4. Using Amazon Kinesis Video Streams for remote monitoring and control\nSimulation for Testing Robot Applications: AWS RoboMaker\nWhen developing autonomous robot application, it can be challenging to verify that the application performs as expected in a variety of environments. During the development phase, the number of robot hardware is often limited and it is difficult to prepare various test environments. Therefore, simulation environments are often used to test robot applications.\nAWS RoboMaker is a fully managed service that enables you to easily create simulation worlds and run simulation jobs without provisioning or managing any infrastructure. You can run general simulation applications or ROS-based simulation applications on Docker. While the simulation is running in the cloud, you can check the simulation status by accessing graphical user interface (GUI) applications and terminals from your browser.\nBuilding a simulation environment is costly, time consuming and required skills in 3D modeling. However, with RoboMaker WorldForge, you can create a number of 3D virtual environments by simply specifying parameters. You can also run multiple simulations in parallel at the same time, or start and stop simulations via RoboMaker APIs. These features makes it easier to build a CI/CD environment for robot applications that automatically and simultaneously test the developed application against a variety of simulation environments. You can try RoboMaker simulation example by following Preparing ROS application and simulation containers for AWS RoboMaker.\nFigure 5. Running simulations on AWS RoboMaker\nSeamless Coordination of Heterogeneous Robots: AWS IoT RoboRunner\nWhen autonomous robots are utilized to perform tasks such as material handling, several different types of robots may be required to work together. However, when coordinating multiple types of robots, it becomes very complex to develop an application to orchestrate tasks integrating with different robot fleet management systems and work management system.\nAWS IoT RoboRunner provides an infrastructure for managing multiple robots from a single system view. By collecting data from multiple types of robot fleet management systems into a centralized repository, AWS IoT RoboRunner provides data of robot, system status and tasks in a standardized format. This makes it easier to develop a software that allows autonomous robots to work together.\nFigure 6. Coordinating multiple types of robots using AWS IoT RoboRunner\n'"
42,Developing a Remote Job Monitoring Application at the edge using AWS IoT Greengrass (part 1),b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/29/threepages-1.jpg,https://aws.amazon.com/blogs/iot/developing-a-remote-job-monitoring-application-at-the-edge-using-aws-iot-greengrass-part-1/,"b'Introduction\nMany modern industrial operations require extensive monitoring and real-time decision making for efficiency and safety reasons. To reduce the unexpected network interruption and delay in IoT data processing, edge computing becomes a desirable option for real-time IoT data processing and monitoring. Edge computing is a system of micro computing/storage devices that are installed at the edge of the network to efficiently process data locally. For industrial sites, such as remote power plants, oil rigs, and factory floors, an edge application with a user interface (UI) component offers great advantages to automate localized operations and improve workforce experience.\nHowever, traditional IoT applications at the edge can experience some challenges, such as lack of centralized life-cycle management and a long development cycle. AWS IoT Greengrass V2, the latest open source edge run time from AWS, offers a pathway to address the above-mentioned challenges. With AWS IoT Greengrass, you can access pre-built software components to improve the modularity of your application and accelerate your development efforts. AWS IoT Greengrass also offers centralized security measures through a built-in log manager to facilitate edge component deployment. Moreover, the integration of AWS IoT Greengrass with AWS IoT Device Management enables you to monitor and manage your device fleet at scale.\nSince AWS IoT Greengrass V2 launched, AWS is actively helping AWS Partner, TensorIoT, to develop various functional applications at the edge using this service. Such applications cover use cases such as: connection to industrial systems and IoT devices, low latency data processing and analytics to derive operational insights, and artificial intelligence (AI)/machine learning (ML) applications at the edge. In this blog, we will showcase a UI application at the edge with AWS IoT Greengrass V2, a jointly developed solution by TensorIoT and AWS Professional Services. This UI application at the edge contains multiple custom AWS IoT Greengrass components to achieve flexible data ingestion, and IoT data analytics and visualization at the edge. The application deployment and updates on multiple edge devices can be efficiently implemented via AWS IoT Greengrass runtime.\nIn this blog, we will showcase how to use this UI at the edge to address the following remote industrial job monitoring use cases:\nUse case 1 (part 1 of the blog)\nOperators on factory floors may have some reports or IoT job metadata that cannot be ingested via a pre-defined IoT data model to the cloud. This UI provides a file upload page, that uses a front-end AWS IoT Greengrass V2 component to ingest a JSON file, and sends the file data to a back-end component. Then the back-end component will send the data to an AWS IoT Greengrass V2 pre-built component: stream manager. The stream manager component makes it easier and more reliable to transfer high-volumes IoT data from the edge to the cloud. As a pre-built component, it offers flexible target destinations in the cloud, including Amazon Simple Storage Service (Amazon S3), Amazon Kinesis, AWS IoT SiteWise and AWS IoT Analytics. It is designed to work in environments with intermittent or limited connectivity. You can define multiple data exportation configurations when the edge device is connected or disconnected. You can also define bandwidth use, timeout behavior, and set priorities, so that the critical data can be exported first when internet connection resumes.\nThis stream manager component will achieve two goals:\nlocal data storage;\nsending data from the local edge device to AWS.\nIn this use case, the unmapped data will land in Amazon S3. A variety of data analytics tools (Amazon Glue and Amazon Athena) /BI tools can be used to analyze this metadata with other IoT time series data in a flexible manner.\nUse case 2 (part 2 of the blog)\nOperators need to make judgements with streaming IoT data in a near-real time fashion. The data will help operators make the right decisions if it can be shown in an interactive UI application with low latency. In part 2 of this blog, you will learn how to build a UI application at the edge to show streaming IoT job data.\nThe images below highlight the UI application developed by AWS Professional Services and TensorIoT. You can use this app to remotely monitor IoT job status in near-real time.\nFigure 1: UI application at the edge developed by AWS Professional Services and TensorIoT for remote IoT job monitoring in near-real time.\nThe following walk through contains detailed steps to develop this UI application at the edge with AWS IoT Greengrass V2. To build a UI solution based on the instructions shared in this blog, you don\xe2\x80\x99t need specialized data analytics or IoT data processing experience.\nTime to read 30 minutes\nTime to complete 120 minutes\nCost to complete\n(estimated)\n~$2 (at publication time)\nLearning level Advanced (300)\nServices used\nAmazon EC2 instance, AWS Greengrass V2,\nAmazon S3, Amazon CloudWatch\nSolution overview\nHere is the solution architecture of this workflow at the edge. Four user-defined components will be built in this two-part blog:\nA front-end AWS IoT Greengrass UI component written in ReactJS, which contains all UI pages used in both use cases (part 1 of blog);\nA JSON file upload component written in Python, that collects file data from the front-end UI, and sends the JSON information to Amazon S3 via stream manager (part 1of blog);\nA dummy publisher publishes wind turbine data at a rate of one message every 10 seconds, and sends the message to a WebSocket component via IPC protocol (part 2 of blog);\nA WebSocket component serves the IoT messages from the dummy publisher component to the UI component via a WebSocket server (part 2 blog).\nBesides these custom components, there are two pre-built AWS IoT Greengrass V2 components deployed with this solution:\nLog manager for application monitoring\nStream manager for edge device data exportation\nIn this blog, an Ubuntu 22.04 LTS EC2 instance with AWS IoT Greengrass v2 runtime is used to simulate an edge device with AWS IoT.\nFigure 2: The overall diagram of the UI application at the edge.  \nPrerequisites\nFor this walk through, you should have the following prerequisites:\nAn AWS account. If you don\xe2\x80\x99t have an AWS Account, follow the instructions to create one, unless you have been provided event engine details.\nA user role with administrator access (service access associated with this role can be constrained further when the workflow goes to production).\nRecent modern browser (Latest version of Firefox or Chrome)\nNo specialized knowledge is required to build this solution, but basic Linux and Python knowledge will help.\nWalk Through\nThis two-part post contains the following walk through steps and will provide detailed instructions for developing this solution:\nPart 1 for setting up runtime and building a JSON file upload application (this post):\nStep 1: Setup Amazon S3 bucket\nStep 2: Setup AWS IoT Greengrass V2 and dependencies\nStep 3: Launch a UI component\nStep 4: Launch a file upload application\nStep 5: Test the file upload application\nPart 2 for building the IoT job monitoring application:\nStep 1: Launch a dummy publisher\nStep 2: Launch a WebSocket component\nStep 3: Configure deployment for log manager\nStep 4: Test IoT job monitoring UI page\nPlease note that this post features the key solution milestones for conciseness, but readers should visit the GitHub repository for a full walk through and source code.\nStep 1: Setup an Amazon S3 bucket\nFirst, create a bucket in Amazon S3 using the AWS Management Console. Please use these instructions to create an Amazon S3 bucket and take a note of the bucket name. You need to provide this Amazon S3 parameter to the JSON file upload component in Step 4 of this walk through.\nSecond, you can use similar steps to create an Amazon S3 bucket for saving edge component artifacts. Please take a note of this Amazon S3 bucket so you can use it in the component deployment steps.\nStep 2: Setup AWS IoT Greengrass V2 on an Amazon Elastic Cloud Compute (Amazon EC2)  instance\n1. Install dependencies on the Amazon EC2 Instance\nSet up the Amazon EC2 instance of type t2.medium with ubuntu 22.04 base image in the AWS account with the following user data:\nsudo su\napt-get update\napt-get install -y python3-pip zip jq\ngit clone https://github.com/aws/aws-iot-device-sdk-python-v2.git\npython3 -m pip install ./aws-iot-device-sdk-python-v2\nBash\nAfter the Amazon EC2 instance status changes to running, use these instructions to setup an AWS session manager access role to access this Amazon EC2 instance without SSH. Next, use Connect with the Amazon EC2 instance via AWS Systems Manager Session Manager (SSM) section of this blog to access the Amazon EC2 instance via SSM. Finally, install AWS Command Line Interface (CLI) V2 on the Amazon EC2 instance:\nwget https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\nunzip awscli-exe-linux-x86_64.zip\nsudo ./aws/install\nBash\n2. Install AWS IoT Greengrass on the Amazon EC2 instance\nYou can use Install Greengrass on Amazon EC2 instance section of this blog to install AWS IoT Greengrass on the edge device.\nBefore you launch the following custom components, please ensure you add the necessary Amazon S3 access policy (e.g. PutObject and GetObject) to the AWS IoT Greengrass role alias so that this IoT device can access Amazon S3 according to these instructions.\nStep 3: Launch the UI component\nComponents are building blocks that enable easy creation of complex workflows such as local data processing, messaging, data management and machine learning inference. With the latest IoT Thing Group definition from AWS IoT Greengrass V2, any updates made by UI designer can be efficiently orchestrated to all destination targets by revising the component deployment on the AWS IoT Thing group.\nThe following steps show how to deploy the previous packaged ReactJS UI code as an edge component on AWS Greengrass V2.\n1. Change the directory to components/edgeui/aws-gg-deploy in the directory where the GIT repository was cloned to the Amazon EC2 instance.\n2. Modify the deployment script deploy-edge.sh by replacing the following placeholders with your customized values in _setEnv() section:\nYOUR_AWS_ACCOUNT_NUMBER\nYOUR_AWS_REGION\nROLE_ARN\nS3_BUCKET for edge component artifacts\nBash\nPress Ctrl-X, then press Y to save the modified deploy.sh file with the same name.\n3. Run the following script to deploy this component:\nexport AWS_ACCESS_KEY_ID=REPLACE-WITH-YOUR-AWS_ACCESS_KEY_ID\nexport AWS_SECRET_ACCESS_KEY= REPLACE-WITH-YOUR-AWS_SECRET_ACCESS_KEY\nexport AWS_SESSION_TOKEN= REPLACE-WITH-YOUR-AWS_SESSION_TOKEN\nchmod 744 deploy-edge.sh\n ./deploy-edge.sh\nBash\nThis bash script takes approximately 90 seconds to finish. Once it exists, please confirm that you have the following component created in your AWS IoT Greengrass V2 console, and its latest status is shown as running:\nFigure 3: UI component status shown in AWS IoT Greengrass console.\nPlease note this UI component contains all UI pages used in both use cases of this two-part blog.\nStep 4: Launch a JSON file upload application\nNext, the JSON file upload component can be launched. This component uses a Flask application to receive the JSON file data from the front UI component. Once it receives the JSON file, it will send the JSON file to Amazon S3 by using the stream manager component. The stream manager component will be launched with the file upload component by defining it as a component dependency in the recipe file as:\nComponentDependencies:\n  aws.greengrass.StreamManager:\n    VersionRequirement: \'^2.0.0\'\n  aws.greengrass.TokenExchangeService:\n    VersionRequirement: \'^2.0.0\'\n    DependencyType: HARD\nYAML\nTo launch the JSON file upload component, you can use the same step as Step 3 to modify the deployment script deploy-edge.sh  in components/com.fileUploader/aws-gg-deploy folder.\nNext, modify the recipe-file-template.yaml file in the same directory by adding arguments of your S3 bucket name that was setup in Step 1 in Run command of Manifests section as:\nRun: Script: python3 -u {artifacts:decompressedPath}/$artifacts_zip_file_name/$artifacts_entry_file -b=""Replace with your Amazon S3 bucket name""\nBash\nPlease replace the default Amazon S3 bucket name with your own Amazon S3 bucket you created in step 1. Save this recipe template file with Ctrl-X, then press Y to save the modified recipe file with the same name.\nFinally, run the same commands as shown in Step 3, to execute deploy-edge.sh.\nThis bash script takes approximately 30 seconds to finish. Once it exists, please confirm that you have the following component created in your AWS IoT Greengrass V2 console, and its latest status is shown as running:\nFigure 4: Status of the JSON file upload component shown in AWS IoT Greengrass console.\nStep 5: Test the JSON file upload application\nOpen a web browser on your laptop, and log in UI with the following address:\nhttp://localhost:8080/fileUpload\nThe following file upload UI page should be shown:\nFigure 5: JSON file upload UI page.\nSelect Upload run configuration file from the middle box of the UI and upload a JSON file of your choice. There is one sample JSON file provided in the Github repository (in the folder: jsonfile_sample)for you to upload for testing purposes, and it contains sample metadata for a wind turbine inspection job. Once you select the file, choose Start inspection to send the file data to the com.fileUploader component and the file data will be uploaded to the Amazon S3 bucket under the folder ggstreamdata as:\nFigure 6: JSON file uploaded to S3 by using the Filer Uploader application.\nSummary of part 1\nThis blog shows a UI application at the edge, jointly developed by AWS Professional Services and AWS Partner, TensorIoT, for remote industrial job monitoring and processing. In part 1 of this two-part series, you learned how to use the latest AWS IoT Greengrass V2 run time to develop a file upload application for ingesting unmapped IoT metadata. With AWS IoT Greengrass V2 run time and pre-built components, you can accelerate your development efforts for an IoT application at the edge. The modularized components developed in this application can be easily deployed and updated to multiple IoT devices.\nIn part 2, you will learn how to develop a second IoT application at the edge to monitor remote IoT jobs with a custom Greengrass component for processing real-time IoT data. Next, you will learn how to use a pre-built Greengrass component, log manager, for monitoring Greengrass component health. Finally, you will be able to test the functionality of the IoT application at the edge.\nCall to action\nPlease finish the whole solution by visiting part 2 of this blog post series.\nAbout the author\nJulia Hu is a Sr. AI/ML Solutions Architect with Amazon Web Services. She has extensive experience in IoT architecture and Applied Data Science, and is part of both the Machine Learning and IoT Technical Field Community. She works with customers, ranging from start-ups to enterprises, to develop AWSome IoT machine learning (ML) solutions, at the Edge and in the Cloud. She enjoys leveraging latest IoT and big data technology to scale up her ML solution, reduce latency, and accelerate industry adoption.\nMartin Lehofer is Practice Manager for Industrial Data with Amazon Web Services. Martin has extensive Industrial IoT experience in a wide range of verticals and applications; from Predictive Maintenance, Data Analytics, Distributed Computing to Artificial Intelligence. At AWS Professional Services, Martin leads a team of architects and engineers helping strategic industrial customers to achieve their business outcomes using data analytics.\nJoyson Neville Lewis is an IoT Data Architect at AWS Professional Services. He has worked as a Software/Data engineer before diving into the Conversational AI and Industrial IoT space where he works with companies to connect the dots between business and AI using Voice Assistant/Chatbot and IoT solutions.\nTanya Lobo Parmar is a Director with TensorIoT, overseeing operations in the EMEA region. She is focussed on getting more customers in European markets to modernize and grow using AWS Cloud. She also enjoys managing challenging projects in IoT, Machine Learning and Managed AI.\nVidya Ramaswamy is a Senior Software Engineer at TensorIoT, an AWS Partner and has 8+ years of experience in software development. She enjoys coding and developing various IoT solutions.\nRajeev Pulleti is a Frontend Engineer from TensorIoT with proficient knowledge in Swift, Objective-C, and Javascript.'"
43,Developing a Remote Job Monitoring Application at the edge using AWS IoT Greengrass (part 2),b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/29/threepages.jpg,https://aws.amazon.com/blogs/iot/developing-a-remote-job-monitoring-application-at-the-edge-using-aws-iot-greengrass-part-2/,"b'Introduction\nIn this second-series blog post, we will continue to showcase a user interface (UI) application at the edge with AWS IoT Greengrass V2, a jointly developed solution by AWS Partner, TensorIoT, and AWS Professional Services. This UI application at the edge contains multiple custom AWS IoT Greengrass V2 components to achieve flexible IoT data ingestion, and streaming data analytics and visualization at the edge.\nPart 1 of the blog contains the following steps for use case 1 of this application: ingest IoT job metadata via a JSON file upload component and a UI application.\nHow to setup an Amazon Simple Storage Service (Amazon S3) bucket, AWS IoT Greengrass V2 and dependencies;\nHow to launch UI and JSON file upload applications at the edge device.\nIn this part 2 post, you will continue building the following use case 2 of this UI application at the edge.\nSolution overview of use case 2\nOperators need to make judgements with streaming IoT data in a near-real time fashion. The data will help operators make the right decisions if it can be shown in an interactive UI application with low latency. With this application, operators can make sound decisions on-site without delay and improve plant operation efficiency.\nIn this edge UI application, there is a dummy publisher component that simulates outputs from a wind turbine facility. The publish frequency from this dummy publisher is once every 10 seconds. A WebSocket component subscribes to streaming data from the dummy publisher via Inter-process communication (IPC) pubsub with AWS IoT AWS IoT Greengrass V2, and sends the data to the edge UI app via WebSocket communication. Since the front-end app does not support IPC pubsub communication, we chose WebSocket communication to stream real-time IoT data continuously from the back-end server via asyncio to the front-end app hosted on the edge. Considering the speed of streaming data received from the publisher component, the python module queue is used to store the message using First-In-First-Out before serving it to back-end server. Besides WebSocket communication, now you can also use a local broker, such as the JavaScript MQTT client library, for your web application.\nPlease note, this dummy publisher component is used for demonstration purposes only. In the industrial plant setting, it would be replaced by a suitable industrial data connector to wind turbines (e.g. SCADA system).\nIn this blog, we will also show how to manage the health status of this AWS IoT Greengrass V2 component with AWS IoT Greengrass V2 pre-built log manager component and Amazon CloudWatch.\nThe following Steps 6 to 9 will guide you through how to:\nLaunch a dummy publisher component that simulates outputs from a wind turbine facility. The publish frequency from this dummy publisher is once every 10 seconds.\nLaunch a WebSocket component that subscribes to streaming data from the dummy publisher via IPC pubsub with AWS IoT Amazon Greengrass V2 and sends the data to the edge UI app via WebSocket communication.\nConfigure deployment for log manager component to monitor edge components\xe2\x80\x99 health.\nTest the IoT job monitor application.\nPrerequisites\nTo build this UI application for use case 2, you will need to have AWS IoT Greengrass V2 and dependencies installed on the edge device, as explained in part 1. You will also need the customer UI component from part 1 to be launched on the edge device. If you haven\xe2\x80\x99t completed these steps, review part 1, Step 1-5 before proceeding.\nWalk- through of use case 2\nThe following walk through steps will provide detailed instructions on developing a UI app at the edge for real-time IoT job monitoring. Please note that this post features the key solution milestones for conciseness, but readers should visit the GitHub repository for details and source code.\nStep 6: Launch dummy publisher\nTo simulate wind turbine outputs, the dummy publisher component will publish some random data related to the following measurements for wind turbine: quality control, tool status, operating parameter, power curve, lv active power, wind speed, and wind direction.  Please use the following steps to launch this component:\n1. Change the directory to components/com.example.Publisher/aws-gg-deploy in the directory where the GIT repository was cloned to the Amazon Elastic Compute Cloud (Amazon EC2) instance.\n2. Modify the deployment script deploy-edge.sh by replacing the following placeholders with your customized values in _setEnv() section:\nYOUR_AWS_ACCOUNT_NUMBER \nYOUR_AWS_REGION \nS3_BUCKET for edge component artifacts \nROLE_ARN\nBash\nPress Ctrl-X, then press Y to save the modified deploy3-edge.sh file with the same name.\n3. Run the following script to deploy this component:\nexport AWS_ACCESS_KEY_ID=REPLACE-WITH-YOUR-AWS_ACCESS_KEY_ID\nexport AWS_SECRET_ACCESS_KEY= REPLACE-WITH-YOUR-AWS_SECRET_ACCESS_KEY\nexport AWS_SESSION_TOKEN= REPLACE-WITH-YOUR-AWS_SESSION_TOKEN\nchmod 744 deploy-edge.sh\n./deploy-edge.sh\nBash\nThis bash script takes approximately 10 seconds to finish. Once it exists, please confirm the dummy publisher component publishes messages by checking its AWS IoT Greengrass component log file:\nsudo tail \xe2\x80\x93200f ./greengrass/v2/logs/com.uipublisher.log\nBash\nYou can see the log is updated with new JSON messages published at a frequency once of every 10 seconds. The message will send to an IPC topic: runscreen/topic, for the WebSocket component to subscribe to.\nFig 1: log file shows messages published by the publisher component\nStep 7: Launch the WebSocket component\nThe WebSocket component subscribes to the IPC topic: runscreen/topic and receives messages with measurements. This component will then serve the message data via the asyncio server, so the UI can receive data from the WebSocket server.\nTo launch the WebSocket component:\n1.Change the directory to components/com.websocketApp/aws-gg-deploy in the directory where the GIT repository was cloned to the Amazon EC2 instance.\n2. Modify the deployment script deploy-edge.sh by replacing the following placeholders with your customized values in _setEnv() section:\nYOUR_AWS_ACCOUNT_NUMBER\nYOUR_AWS_REGION\nS3_BUCKET for edge component artifacts\nROLE_ARN\nBash\nPress Ctrl-X, then press Y to save the modified deploy3-edge.sh file with the same name.\n3. Run the following script to deploy this component:\nexport AWS_ACCESS_KEY_ID=REPLACE-WITH-YOUR-AWS_ACCESS_KEY_ID\nexport AWS_SECRET_ACCESS_KEY= REPLACE-WITH-YOUR-AWS_SECRET_ACCESS_KEY\nexport AWS_SESSION_TOKEN= REPLACE-WITH-YOUR-AWS_SESSION_TOKEN\nchmod 744 deploy-edge.sh\n./deploy-edge.sh\nBash\nThis bash script takes approximately 10 seconds to finish. Once it exists, please confirm that you have the following component created in your AWS IoT Core console:\nFig 2: the WebSocket component status \nStep 8: Configure log manager component deployment\nThe log manager component (aws.greengrass.LogManager) uploads component logs from AWS IoT Greengrass core devices to Amazon CloudWatch logs. This pre-built component can effectively monitor custom component status with minimal developer efforts. The log manager component can be added to the current deployment from AWS IoT Core by selecting the component from the list of public components.\nFig 3: the log manager component status\nChoose the log manager component and select configure component to modify its configuration.\nIn the configuration merge, add the following configurations of component logs of individual components:\n{\n  ""logsUploaderConfiguration"": {\n    ""componentLogsConfigurationMap"": {\n      ""com.example.Publisher "": {\n        ""minimumLogLevel"": ""INFO"",\n        ""diskSpaceLimit"": ""20"",\n        ""diskSpaceLimitUnit"": ""MB"",\n        ""deleteLogFileAfterCloudUpload"": ""false""\n      },\n      ""com.WebsocketApp "": {\n        ""minimumLogLevel"": ""INFO"",\n        ""diskSpaceLimit"": ""20"",\n        ""diskSpaceLimitUnit"": ""MB"",\n        ""deleteLogFileAfterCloudUpload"": ""false""\n      },\n      ""com.fileUploader "": {\n        ""minimumLogLevel"": ""INFO"",\n        ""diskSpaceLimit"": ""20"",\n        ""diskSpaceLimitUnit"": ""MB"",\n        ""deleteLogFileAfterCloudUpload"": ""false""\n      }\n    }\n  }\n}\nJSON\nFig 4: the log manager component configuration updates\nFor more configuration modification choices, please refer to this doc.\nAfter redeploy with the log manager, component logs can be found in the Amazon CloudWatch logs as:\nFig 5: component logs in CloudWatch log groups\nDevelopers can also develop component health dashboards by setting up Amazon CloudWatch metrics to monitor component logs and visualize the metrics with a dashboard in Amazon CloudWatch.\nStep 9: Test the IoT job monitor UI Page\nIn part 1, a JSON file can be uploaded to provide IoT job metadata. After the JSON file is uploaded via the UI page: http://localhost:8080 /Job,  the UI application will be automatically switched to the second UI page: http://localhost:8080 /Job. This page shows the streaming data fetched from the WebSocket server, including sensor data, e.g. power curve, wind speed, wind direction and LV active power. When the inspection job status is shown as normal, the UI page shows relevant job information in green font as below:\nFigure 6: Job page shows job status as normal.\nWhen the inspection job status is abnormal, the UI page will be shown in red, and the quality control outcome will be shown as Action Needed:\nFigure 7: Job page shows job status as abnormal.\nThis http://localhost:8080 /Job UI page allows inspectors to perform remote job monitoring with near-real time streaming sensor data. They can also gain quality control information from the UI to help performing detailed diagnosis.\nClean up\n(1) AWS IoT\nOpen the AWS IoT Core console, under AWS IoT\nUnder AWS IoT Greengrass Core Device tab, select the DemoJetson core device and hit delete on top right.\nUnder Manage > Thing Group, delete DemoJetsonGroup from Thing Group\nDelete things under Manage > Things: DemoJetson\nUnder Policies > delete GreengrassV2IoTThingPolicy and GreengrassTESCertificatePolicyGreengrassV2TokenExchangeRoleAlias\nUnder Secure > Role Aliases delete GreengrassV2TokenExchangeRoleAlias\n(2) Amazon S3\nNavigate to the Amazon S3 console and locate the component bucket you used earlier in the blog.\nEmpty the component bucket.\nDelete the component bucket.\nEmpty the bucket with data from the stream manager.\nDelete the bucket with data from the stream manager.\n(3) Amazon EC2 termination\nNavigate to the Amazon EC2 console.\nStop the instance by selecting Stop Instance under Instance State.\nAfter the instance stops, select Terminate Instance under Instance State.\n(4) IAM Roles\nNavigate to IAM console\nDelete IAM role created from Ubuntu EC2 instance\nDelete AWS EC2 SSM access policy\nDelete IAM user created for Amazon Greengrass V2\nDelete policy that was attached to Amazon Greengrass V2 user.\n(5) Amazon CloudWatch\nDelete relevant CloudWatch metrics from the Amazon CloudWatch console\nThis completes the deletion of the resource created for the blog.\nCall to action\n1. In this blog, the wind turbine data source is simulated by using a dummy publisher for demonstration purpose. When this application is implemented in industrial settings, various data sources can be used, e.g. PLC, controller, conventional data servers, etc. There are several Greengrass community components can be used as data source connectors. Such community components can be deployed to edge devices via AWS IoT Greengrass v2.\n2. The WebSocket component explained in this blog can be further extended to include custom data analytics workflow. Such data analytics can enrich the wind turbine data to generate more operational insights.\n'"
44,Detect water leaks in near real time using AWS IoT,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/10/06/Architecture-diagram.png,https://aws.amazon.com/blogs/iot/detect-water-leaks-in-near-realtime-using-aws-iot/,"b'Introduction\nWater is one of the most precious resources needed for the sustenance of life. However, only 2% of the global water supply is suitable for human consumption. The United States Environmental Protection Association (EPA) estimates that 1.7 trillion gallons, roughly 30 percent of all treated water, is wasted every year in the United States.\nAccording to New York City Department of Environmental Protection, a leaking fire hydrant can waste up to 1,000 gallons of water per minute. Utilities have to deploy manual resources to identify these leaks, which can be a time consuming and labor-intensive process. Moreover, if these leaks are not addressed, then utilities can be penalized with heavy fines for non-compliance with environmental laws. These risks are an outcome of the water supply infrastructure seen in most cities, where supply lines are run underground, creating natural challenges to quickly identify and repair leaks. In most instances, leaks are never detected until the next scheduled maintenance call or during an emergency situation where use of fire hydrant is verified. A typical maintenance call can take up to 3 months and may require a minimum of 3 visits. Imagine how much water is wasted during this period. The solution described in this blog can help reduce leakage waste and maintenance costs for the utilities.\nSolution overview\nConsider a scenario, where water is flowing through fire hydrants across cities and rural areas, and somewhere along such long routes, a minor leak occurs. The leak remains undetected for several weeks to months. Even after the leak is detected, it could take a few more weeks to identify the exact location and then fix it. Today, most fire hydrants can be upgraded with an IoT sensor to communicate statistics on the status and usage of the fire hydrant. These sensors can help identify water leaks in almost real time to trigger proactive maintenance actions. In the proposed architecture, an IoT-enabled, 5G-capable fire hydrant communicates using MQTT protocols to AWS. These fire hydrants use AWS IoT Core to authenticate with AWS.\nArchitecture diagram\nBefore we deep dive into the architecture, let\xe2\x80\x99s understand the 4 stages represented by the architectural diagram.\nThe first stage establishes communication from IoT devices to AWS over MQTT protocol.\nThe second stage stores the collected data and maintains it for long-term compliance reasons.\nThe third stage dispatches notifications to field teams for active leak situations and enables them to take actions ASAP.\nThe fourth stage provides back-office operators control over the entire system. Back-office operators can utilize Amazon QuickSight dashboards to view active leaks and actions being performed, device health, and much more based on the collected data.\nStage 1: IoT Communications\n5G-capable fire hydrants can establish communications with AWS over MQTT protocols.\nAWS IoT Core helps establish communication. Bulk on-boarding of devices is possible with AWS IoT Device Management.\nAWS IoT Device Management will securely access IoT devices, monitor health, detect and remotely troubleshoot problems, and manage software and firmware updates.\nAWS IoT Device Defender helps maintain security of all on-boarded IoT devices, monitors security metrics, and generates alerts based on deviations from the expected behavior of each device.\nOnce this communication is established, the fire hydrant can send hydrant health status, geo-location and water flow data over secure MQTT protocol in JSON format to AWS.\nStage 2: Storage\nOnce IoT devices start sending events, there will be more data to collect and process.\nEvents are stored into Amazon Simple Storage Service (Amazon S3) and then periodically offloaded to an archival service such as Amazon S3 Glacier.\nStage 3: Dispatch & Fix\nEvents contain vital information about possible leaks. Now, connected fire hydrants can communicate with AWS so back-office teams can be notified in near real-time and alert field workers for immediate action.\nFire hydrant publishes a notification to AWS IoT Core over an MQTT protocol after a set interval.\nAWS IoT Core Rules Engine retrieves the notification from the MQTT topics.\nAWS IoT Core Rules Engine then sends the notification to AWS IoT Events.\nAWS IoT Events has a detector model that monitors incoming IoT events, (e.g. a fire hydrant\xe2\x80\x99s water flow and pressure level), by sending a request back to the AWS IoT Core MQTT topic.\nAWS IoT Events detects the water flow and pressure abnormalities based on defined thresholds. If the water pressure and flow fall outside of defined thresholds, AWS IoT Events sends a notification message to an Amazon Simple Notification Service (Amazon SNS) topic.\nThe field operations team receives a notification message to inform field operators of the possible leak situation.\nIn addition to triggering an alert, AWS IoT Events sends the same message to Amazon DynamoDB to create a support case. The back-office team tracks the status of fire hydrants using an Amazon QuickSight dashboard.\nOnce the leak is fixed, the field operations team updates the status of the support case.\nStage 4: Insight Reporting\nAll the collected events stored in Amazon S3 enable reporting capabilities.\nAmazon Athena is used to analyze and query on collected events.\nAmazon QuickSight supports insightful dashboards for back-office operators to help them visualize active leaks, actions being performed for active leaks, geographical distribution of leaks, as well as help them monitor health status for devices and much more.\nPrerequisites\nTo follow along and set up the asset inspection solution, be sure to have the following:\nAn AWS account.\nA device or laptop/computer with an access to your AWS account, Python version 2.7.18+ installed, and the AWS IoT Device SDK for Python version 1.3.1+.\nSetting up AWS IoT Events to manage fire hydrant leaks\nAn AWS IoT rule needs to be configured to forward device data from AWS IoT Core (MQTT topic) to AWS IoT Events.\nGo to the AWS Management Console and select AWS IoT Core.\nSelect Message Routing, then Rules, and then choose Create rule. Rule description is an optional field.\nIoT Rule set up\nSet the Name for the rule and set the rule query statement to SELECT * FROM \xe2\x80\x98iot/topic\xe2\x80\x99. Sample query below.\nSample Query\nChoose Add rule action.\nSelect IoT Events option and enter Input name.\nSelect the Input previously created.\nSelect Create new role and enter a role name.\nSelect Add rule action.\nSelect Create rule.\nA sample of the rule created in AWS Console.\nCreate Rule\nIn AWS IoT Events, create the following components to start the fire hydrant\xe2\x80\x99s water flow and pressure:\nSelect AWS IoT Events from the services menu. On the AWS IoT Events page, select an industry-specific template from the section shown following.\nCreate Detector Model\nFrom that screen select Simple Alarm and choose Start.\nIoT Event template selection\nCreate a detector model with 3 states each, with 2 transitions as shown following.\nCreate Detector Model\nUpon receipt of a notification, the device state is changed to \xe2\x80\x9cActiveLeak\xe2\x80\x9c. This state is used to trigger the alert to field worker and back-office dashboard.\nCreating an input in AWS IoT Events\nYou can create an input in AWS IoT Events by following the guide to create an input. In our example, we create an input with the following details:\nAn example Input name set to \xe2\x80\x9cdeviceNotificationInput\xe2\x80\x9d\nUpload a JSON file with following example JSON payload:\n{\n""geoLocation"": ""42.3928258265305, -71.07754968042828"",\n""timeStamp"": ""2022-05-31 08:47:44.870092"",\n""cityName"": ""Boston"",\n""state"": ""MA"",\n""deviceId"": ""BOS0\xe2\x80\x9d,\n""sensorHealth"": ""OK"",\n""inputFlow"": ""10"",\n""outputFlow"": ""10""\n}\nCreate Device Notification Input\nCreating and publishing a detector model in AWS IoT Events\nIn our example, we create a detector model with the following details and you can find a sample at AWS IoT Events Developer Guide.\nThree states (Normal, ActiveLeak and Snooze).\nEach with transitions that switches the device from one state to another.\nUpon receiving a notification from the device, the normal transition triggers the sending of a notification to the outbound AWS IoT Core\xe2\x80\x99s MQTT topic and changes the device state to out_of_range and pushing state to ActiveLeak.\nIf the repair is taking longer, then device state could be pushed to Snooze state while the fix is being performed.\nNormal State ActiveLeak State Snooze State\nStates for the detector model\nCreating a detector model\nCreate an IAM role for the Detector Model. For more information, see the documentation for setting up permissions for AWS IoT Events.\nCreate the sample detector model as shown in the previous image with states and transitions.\nAnalyzing data using Amazon QuickSight\nFollowing are the type of visualizations you can create with the data using Amazon QuickSight.\nDevice health status: The below chart shows the device status along with device locations of fire hydrants. These charts will assist back-office teams to identify faulty fire hydrants and send geolocation to field operators to fix those faulty devices.\nDevice health report \xe2\x80\x93 Keeps back office up to date with compliance and device health status near real time.\nActive leaks: The below chart shows water leaks across 3 example cities \xe2\x80\x93 New York, Chicago, and Boston.\nActive leak report \xe2\x80\x93 Shows active leaks across cities for the back office\nGeo-locations of active leaks: The below chart shows active water leaks on a map, plotted using device Geo coordinates. This could be useful for back-office teams to actively look at streets where there is an issue.\nGeo location of fire hydrants \xe2\x80\x93 Shows fire hydrants in map/street view with their status\nCleaning up\nTo avoid incurring unwanted charges, delete the following resources:\nClean up IoT devices as explained in this guide.\nDelete AWS Kinesis Delivery Streams as explained in this guide. .\nDelete Amazon S3 bucket as explained in this guide.\nDelete Amazon DynamoDB tables as explained in this guide.\nDelete Amazon Athena schema as explained in this guide.\nDelete Amazon QuickSight charts/visuals as explained in this guide. Delete Dashboard explained in this guide, and delete account explained in this guide.\nDelete Amazon SNS topics as explained in this guide.\n'"
45,Build an efficient development environment for AWS IoT Greengrass,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/build-an-efficient-development-environment-for-aws-iot-greengrass/,"b'Introduction\nThis post shows you how to set up a clean and efficient development environment for AWS IoT Greengrass. With this environment you can rapidly iterate on your ideas and automate your process to build edge compute systems from scratch. Building a repeatable development environment for edge systems can take a long time. These tools will reduce the amount of time it takes you to get started and give you a base to build your production applications.\nOverview\nThe Ubuntu 20.04 based virtual machine that you build can:\nStart from scratch in minutes\nConnect to real USB devices\nInteract with AWS services using your AWS credentials\nCapture images from a USB camera and save them to your host system\nRun AWS IoT Greengrass with a single component\nWe will use GreenEyes to implement a digital video recorder (DVR) platform. This platform utilizes multiple AWS services for edge computing, like AWS IoT Greengrass and FreeRTOS.\nPrerequisites\nAll operating systems\nYou must have the AWS Command Line Interface v2 installed and have credentials set up in the default location $HOME/.aws. The project will bring these credentials into the VM so you can interact with AWS right away.\nMacOS and Linux\nYou must have git and bash installed. All recent versions of Linux and MacOS should have these installed already.\nWindows\nYou need a shell that can run bash scripts. We recommend Git Bash which comes with Git for Windows. If you have Windows Terminal installed make sure you enable the Git Bash profile for Windows Terminal during the Git for Windows install process. You can then select Git Bash from the Windows Terminal drop-down instead of using the default terminal.\nTools overview\nVirtualization with VirtualBox\nYou need a virtualization platform. It is possible to do a lot in containers and many people prefer them. In this case though you need to load some kernel modules and access USB devices which isn\xe2\x80\x99t always possible in container based systems. Additionally, one goal is to make the experience to be as similar as possible across Windows, MacOS, and Linux.\nThe virtualization platform you are going to use is VirtualBox. VirtualBox is cross-platform, free, and supports USB passthrough. Tests show that the performance is sufficient for single stream video capture and processing.\nAutomated builds with Vagrant\nYou need tools to make setting up virtual machines as easy as possible. Being able to start, stop, and rebuild machines on the command-line will save time and avoid manual configuration steps.\nVagrant automates building and configuring your VMs. Vagrant is a cross-platform, and can use VirtualBox as a back-end which supports USB passthrough.\nVagrant can also share files between the host and the guest operating system. Results show up immediately and you can monitor your system right from the host.\nCamera selection\nUSB cameras are not all equal. Luckily all UVC webcams should be equal. UVC stands for USB video class. This is a standard that provides a standard interface to capture video. Some webcams do not support this standard and require additional software.\nFor simplicity, this post limits the scope to UVC webcams only. This system can be adapted to use other cameras but that is beyond the scope of this post.\nA reliable UVC camera that you can start with is the Logitech C922. It can be found online at various stores either new or used. There are also some variations of the C922 like the C920s, and the C920e. These should work as well and we will add information to the documentation to indicate when we\xe2\x80\x99ve tested them to be sure.\nAs long as the camera you\xe2\x80\x99re using is on the UVC device list or claims to support UVC it should work. However, the default code uses the Logitech C922. If you use another camera there are some changes you\xe2\x80\x99ll need to make to the configuration. Once you set up VirtualBox and Vagrant you can test the camera and validate your setup.\nInstall tools\nVirtualBox\nVirtualBox is one of the easiest dependencies for you to set up. You can go to the VirtualBox wiki\xe2\x80\x99s downloads page and click on whichever VirtualBox platform corresponds to the platform you\xe2\x80\x99ll be running on. You will need administrator access to install VirtualBox so make sure you use a computer that you have full control over.\nThis post is based on VirtualBox 6.1.32 on MacOS. If you are on a different platform or are using a newer version some of the screens may be slightly different. If you run into issues feel free to share screenshots with us by filing an issue in our GreenEyes repo.\nVirtualBox extension pack\nYou also need to add support for USB 3.x so that your USB camera will work correctly. To get support for USB 3.x you need to install the Oracle VM VirtualBox Extension Pack which can be found at the same download page you downloaded VirtualBox from.\nNOTE: If you already have the VirtualBox GUI open when you install the extension pack you will need to close and re-open it.\nVagrant\nHead over to the Vagrant downloads page and install the build appropriate for your operating system. Some operating systems can install Vagrant with a package manager (Homebrew, apt, etc.), some require downloading a binary build.\nCode\nGreenEyes repository overview\nThe GreenEyes repository contains scripts and documentation for each post in this series. Scripts that are meant to be run on the host are in the greeneyes/blog-posts/001/host directory. Scripts that are meant to be run on the guest are in the greeneyes/blog-posts/001/guest directory.\nIn the host directory for this post there is only a Vagrantfile. There are no additional scripts to run.\nCloning the GreenEyes repository\nNavigate in your shell to a directory where you\xe2\x80\x99d like to store the repository and clone it like this:\ngit clone https://github.com/awslabs/greeneyes/\nBash\nEnvironment\nInitializing the environment\nIf your system is running MacOS or Linux then you are ready to go and all of the dependencies are present.\nIf your system is running Windows then Hyper-V needs to be enabled if it isn\xe2\x80\x99t already. Enable Hyper-V in an administrator terminal session with this command:\npowershell Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All\nPowerShell\nStarting the VM\nNOTE: Any time you use a vagrant command you must be in the greeneyes/blog-posts/001/host directory for this blog post.\nRun vagrant up in the greeneyes/blog-posts/001/host directory. When this completes the VM is bootstrapped with the necessary kernel modules and USB 3.0 will be enabled. This command can take a while depending on a number of factors including your Internet bandwidth, CPU, RAM, etc. On the low end you can expect about three and a half minutes.\nIf the VM fails to provision\nIt is possible for the VM to fail to run the provisioning steps due to temporary network connectivity issues. When this happens an error is printed that looks like this:\nThe SSH command responded with a non-zero exit status. Vagrant\nassumes that this means the command failed. The output for this command\nshould be in the log above. Please read the output to determine what\nwent wrong.\nIf you see this message, run vagrant destroy to delete the VM and then run vagrant up again. Otherwise the VM will not have the proper dependencies and configuration to continue.\nValidating USB 3.0 support\nRun vagrant ssh and you\xe2\x80\x99ll be dropped into a shell in the VM. To verify that USB support is working run this command:\ndmesg | grep -i xhci\nBash\nThe output should contain some lines similar to this:\n[    1.287174] usb usb3: Product: xHCI Host Controller\n[    1.287928] usb usb3: Manufacturer: Linux 5.4.0-107-generic xhci-hcd\nIf those lines are there (there may be more as well) then USB 3.0 support is working. Exit the shell by running the exit command.\nNow run vagrant halt to stop the VM so you can set up USB passthrough for your webcam.\nConfiguring USB passthrough\nNOTE: The default Vagrant configuration configures USB 3.0 passthrough and adds a device filter for the Logitech C922. You can skip this section if you are using the Logitech C922. Otherwise, follow this section to add a device filter for your webcam.\nPlug your USB camera into your computer. You will need to select it from a list on one of the next screens and it\xe2\x80\x99s better to have it ready to go instead of reloading the interface.\nStart the VirtualBox GUI. The interface should look like this:\nNow choose the \xe2\x80\x9cSettings\xe2\x80\x9d, then \xe2\x80\x9cPorts\xe2\x80\x9d, and then \xe2\x80\x9cUSB\xe2\x80\x9d.\nThe screen should have \xe2\x80\x9cEnable USB Controller\xe2\x80\x9d checked, \xe2\x80\x9cUSB 3.0 (xHCI) Controller) selected, an empty \xe2\x80\x9cUSB Device Filters\xe2\x80\x9d list, and two USB icons on the right side.\nChoose the icon with the USB cable and the plus sign as shown here:\nSelect the camera you connected from the list and it will show up in the list like this:\n\nChoose \xe2\x80\x9cOK\xe2\x80\x9d and you are ready to restart your instance and test it.\nTesting USB passthrough\nIt is time to get into your VM and try to capture a picture from your camera.\nRun vagrant up to start the VM. Open a terminal in the VM by running vagrant ssh.\nIn the shell run a capture test with this command:\n~/guest/bash-capture-loop/capture-one\nBash\nThe output from the capture test is just a single < character if it was successful. You should see a new .jpg in the ~/shared directory. The name of the file will be a number that represents the UNIX epoch time at which the image was captured. That image is a single frame from your camera. You can view this on the host\xe2\x80\x99s shared directory and verify the image is valid. Vagrant provides a shared directory feature that maps ~/shared on the VM to shared on your host.\nTesting your AWS credentials\nOpen a terminal in the VM, if you haven\xe2\x80\x99t already, by running vagrant ssh. In the terminal run this command:\naws sts get-caller-identity\nBash\nIf your credentials are loaded correctly you should see output like this:\n{\n  ""UserId"": ""AXXXXXXXXXXXXXXXXXXXXX"",\n  ""Account"": ""123456789012"",\n  ""Arn"": ""arn:aws:iam::123456789012:user/me""\n}\nJSON\nIf your credentials are missing you will see output like this:\nUnable to locate credentials. You can configure credentials by running ""aws configure"".\nValidate your AWS credentials by trying this same command on your host system. If it does not work review the Configuration basics documentation and set your credentials up again if necessary.\nInstalling AWS IoT Greengrass\nOpen a terminal in the VM, if you haven\xe2\x80\x99t already, by running vagrant ssh. In the terminal run this command:\ngg-install\nBash\nThis script will download the latest version of the AWS IoT Greengrass Nucleus and provision AWS IoT Greengrass on your VM. When it completes you should see a message like this:\nSuccessfully set up Nucleus as a system service\nGreengrass S3 access policy created [...] for bucket [...]\nYou can monitor all the AWS IoT Greengrass logs by running:\ngg-logs\nBash\nThe gg-logs script will also pick up new log files when they are created so you don\xe2\x80\x99t need to restart it to see what a component is doing.\nNOTE: To exit the gg-logs script press CTRL and backslash (CTRL+\\).\nDeploy the Bash Capture Loop component\nThe capture-one program you ran before is actually a Bash script. There is another program called capture-loop that wraps capture-one in a loop, captures an image once per second, and keeps the last 10 images in the shared directory.\ncapture-loop is also a Bash script. It was written as a Bash script to demonstrate that components can be written in any language you like.\nTo deploy the Bash Capture Loop component first make sure you have a terminal open that is monitoring the logs with the gg-logs command you ran before. Then open a new terminal and run this command:\ngg-cloud-deploy\nBash\nAfter a few seconds you should see log messages that look like this:\n2022-04-29T15:31:37.495Z [WARN] (Copier) greeneyes.BashCaptureLoop: stderr. <. {scriptName=services.greeneyes.BashCaptureLoop.lifecycle.Run, serviceName=greeneyes.BashCaptureLoop, currentState=RUNNING}\nThis indicates that the Bash Capture Loop is running. You should also see images showing up on your host computer in the shared directory.\nUnderstanding the cloud deploy command\nThe gg-cloud-deploy command uses the AWS IoT Greengrass Development Kit Command-Line Interface, also known as GDK, to build, publish, and deploy any AWS IoT Greengrass components in the guest directory for you automatically using the AWS IoT Greengrass cloud services.\nIt does the following:\nValidates that the AWS IoT Greengrass CLI from the dev tools package is installed. This is done in the initial deployment by the gg-install script with the --deploy-dev-tools true option.\nLocates any components in the guest directory that are compatible with GDK. It does this by looking for a gdk-config.json or gdk-config.json.template file.\nIf gdk-config.json is present but not gdk-config.json.template then it uses gdk-config.json without making any modifications. This allows it to support components that are not part of this post.\nIf there is a gdk-config.json.template file it populates the any placeholder values and then overwrites gdk-config.json with the updated information. This makes it easier to reuse a component\xe2\x80\x99s configuration across multiple AWS IoT Greengrass VMs without having to update the Amazon Simple Storage Service (S3) bucket each time.\nBuilds each component with the gdk component build command. This creates a ZIP archive of the components that can be published to S3.\nPublishes each component with the gdk component publish command. This uploads the ZIP archive to S3.\nDeploys the latest version of each component with gg-cli deployment create. To get the latest version it queries your privately deployed Bash Capture Loop component with the AWS CLI.\nAdditional convenience scripts\nIn addition to gg-cloud-deploy and gg-install there are several convenience scripts in the greengrass directory. By default the greengrass directory is in the vagrant user\xe2\x80\x99s PATH so you can use these tools from anywhere inside of the VM. The other scripts that you can use are:\ngg-cli \xe2\x80\x93 Runs the AWS IoT Greengrass CLI\ngg-names \xe2\x80\x93 Prints the names that are used to configure and manage the current VM\xe2\x80\x99s instance of AWS IoT Greengrass\ngg-password \xe2\x80\x93 Prints the username and password information for the AWS IoT Greengrass local developer console.\ngg-start \xe2\x80\x93 Starts AWS IoT Greengrass using systemd\ngg-status \xe2\x80\x93 Shows the AWS IoT Greengrass status using systemd\ngg-stop \xe2\x80\x93 Stops AWS IoT Greengrass using systemd\nCleanup\nThe cleanup process is to remove the AWS resources that the scripts created and then to destroy the Vagrant VM.\nThe resources created by installing AWS IoT Greengrass and running the cloud deploy script are:\nOne S3 bucket for AWS IoT Greengrass deployment artifacts\nOne S3 object per deploy\nOne thing group\nOne AWS IoT certificate\nTwo AWS IoT policies\nOne for the token exchange service to get AWS Security Token Service (STS) credentials from the AWS Identity and Access Management (IAM) role using the AWS IoT Greengrass Core\xe2\x80\x99s certificate\nOne for the AWS IoT Greengrass core to access AWS IoT and AWS IoT Greengrass services\nOne IAM role that can be assumed with the AWS IoT Greengrass core certificate\nTwo IAM policies\nOne default policy created by AWS IoT Greengrass to allow it to send logs to CloudWatch Logs\nOne policy created by gg-install to allow AWS IoT Greengrass to access the S3 bucket gg-cloud-deploy creates for deployment artifacts\nOne AWS IoT role alias to point the AWS IoT Credentials Provider service to the IAM role\nOne AWS IoT Greengrass core device\nOne AWS IoT thing\nIf you would prefer to delete these resources manually you can run the gg-names script to find the names of the resources.\nTo do an automated cleanup you can use the Superfluid tool. Download the tool and run this command:\nsuperfluid greeneyes cleanup THING_NAME\nReplace THING_NAME with the name of the thing reported by gg-names. This queries AWS for the thing, finds the resources related to that thing for this post series, and cleans them up automatically for you. It first displays what resources it wants to clean up, prompts for confirmation, and then cleans the resources up. It also logs if operations failed so the resources can be cleaned up later.\nRecap\nIn this post, you set up an AWS IoT Greengrass component development environment. Using an Ubuntu VM and Vagrant, you deployed an AWS IoT Greengrass component that can capture images from a camera. The VM has a USB passthrough to connect to a USB web camera. You can modify the code for the component inside the VM and redeploy it to see your changes immediately.\nAuthors\nTim Mattison is a Principal Technologist in the IoT Ecosystem Services group at Amazon Web Services. Originally a firmware engineer, he has moved up and down the stack from Linux kernel drivers to GUIs. He enjoys the challenges involved with removing friction for developers and is always on the lookout for ways to improve. He primarily works on AWS IoT content that shows how to weave multiple services together across the product lifecycle from rapid prototyping to production.\nNenad Ilic is an Internet of Things specialist with more than a decade of experience. Currently, he works as a Senior Developer Advocate at Amazon Web Services, where he helps developers across the industry accelerate their Edge Software Development and builds infrastructure so other developers can express themselves through code. In his free time he likes to experiment with electric skateboards and share his experience with the broader community.'"
46,Digital Twins on AWS: Driving Value with L4 Living Digital Twins,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/07/DigitalTwin_L4Living.jpg,https://aws.amazon.com/blogs/iot/l4-living-digital-twins/,"b'Introduction\nIn working with customers, we often hear of a desired Digital Twin use case to drive actionable insights through what-if scenario analysis. These use cases typically include operations efficiency management, fleet management, failure predictions, and maintenance planning, to name a few. To help customers navigate this space, we developed a concise definition and four-level Digital Twin leveling index consistent with our customers\xe2\x80\x99 applications. In a prior blog, we described the four-level index (shown in the figure below) to help customers understand their use cases and the technologies required to achieve their desired business value.\nIn this blog, we will illustrate how the L4 Living Digital Twins can be used to model the behavior of a physical system whose inherent behavior evolves over time. Continuing with our example for electric vehicle (EV) batteries, we will focus on predicting battery degradation over time. We described the L1 Descriptive, L2 Informative, and L3 Predictive levels in previous blogs. In this blog, you will learn about the data, models, technologies, AWS services, and business processes needed to create and support an L4 Living Digital Twin solution.\nL4 Living Digital Twin\nAn L4 Living Digital Twin focuses on modeling the behavior of the physical system as it changes over time by using real-world data to update the model parameters. Examples of real-world operational data include continuous data (time-series), measurements (sensors), or observations (visual inspection data or streaming video). The capability to update the model makes it \xe2\x80\x9cliving\xe2\x80\x9d so that the model is synchronized with the physical system. This can be contrasted with an L3 Predictive Digital Twin, where the operational data is used as input to a static pretrained model to obtain the response output.\nThe workflow to create and operationalize an L4 Digital Twin is shown in the figure below. The first step is to build the model using first-principles methods (\xe2\x80\x9cphysics-based\xe2\x80\x9d), historical operational data, or hybrid modeling techniques. The second step is to perform a sensitivity analysis of the model parameters to select which parameters will be updatable and confirm that the selected subset captures the variation in the real-world data. Afterward, the model\xe2\x80\x99s parameters are calibrated using a probabilistic calibration algorithm, and the model can then be deployed in production.\nOnce in production, the deployed model is used to predict the measured values, which are compared against the actual measured values, in order to calculate the error term. If the error is less than a preset threshold, then no adjustments are made, and the model is used to predict the next measured values. If the error is larger than the threshold, then the probabilistic Bayesian calibration algorithm is used to update the model parameters reflecting the latest data observations. This updating capability is what makes the L4 Digital Twin \xe2\x80\x9cliving.\xe2\x80\x9d\nTo help customers build and deploy L4 Digital Twins, AWS (Iankoulski, Balasubramaniam, and Rajagopalan) published the open-source aws-do-pm framework on AWS Samples. Technical details are provided in the GitHub readme files and a detailed 3-part blog by the authors showing an example implementation for EV battery degradation that we will leverage in this blog. In summary, the aws-do-pm framework enables customers to deploy predictive models at scale across a distributed computing architecture. The framework also allows users to probabilistically update the model parameters using real-world data and calculate prediction uncertainty while maintaining a fully auditable history for version control.\nIn our example, we will show how to create L4 Digital Twins for a fleet of EV batteries using the aws-do-pm framework and integrate it with AWS IoT TwinMaker. These L4 Digital Twins will make predictions of the battery voltage within each route driven, taking into account battery degradation over time. Since each vehicle takes a different route and has different charging and discharging cycles over the months, the battery degradation for each vehicle will be different. The EV battery Digital Twins must have two attributes: 1/ the EV battery DTs must be individualized for each battery; 2/ the EV battery DTs must be updated over the battery\xe2\x80\x99s life to reflect the degraded performance accurately.\nInitial model building and calibration\nThe first thing we need to build a model is an operational dataset. For this example, we will use same EV fleet model published by Iankoulski, Balasubramaniam, and Rajagopalan in the aws-do-pm GitHub. Following the documentation, we created two synthetic datasets to mimic the operations of 100 vehicles, each driving 100 routes, using the example code in aws-do-pm. In practice, these datasets would be obtained from actual vehicles in operation. The first synthetic dataset mimics the routes that are traveled by each of the vehicles. Each route is characterized by trip distance, trip duration, average speed, average load (weight), rolling friction, and aerodynamic drag that are preassigned by sampling from probability distributions for each characteristic. Once the routes are set, the second synthetic dataset calculates the battery discharge curves for each of the 100 vehicles as they travel their 100 routes. Each vehicle is assumed to have a new battery initially. To mimic real-life battery degradation, the example used a simple phenomenological degradation model applied as a multiplier to the voltage discharge curves as each vehicle drives its 100 routes. The degradation model is a function of the route duration, route distance, and average load so that each vehicle experiences a different degradation depending on its driving history. This synthetic time-series dataset of degrading battery discharge for each vehicle is our starting point mimicking real-life operational data. The figure below shows the complete voltage versus time charge-discharge cycles for Vehicle 1 over several months as it drives its assigned 100 routes, and we can see how the battery degrades over time.\nNow that we have representative operational data, the first step is to build the model that predicts the voltage as the vehicle drives along its route. The model can be built in several ways. It could be a physics-inspired model where the functional form of the model equation is based on underlying scientific principles, a purely empirical model where the functional form of the model equation is based on a curve fit, a strictly data-driven model such as a neural network, or a hybrid model such as a physics-inspired neural network. In all cases, the model coefficients or parameters are exposed and can be used to calibrate the model. In our example, we trained a neural network using the first trip of each of the 100 vehicles to represent the behavior of a new battery. To make the example more realistic, we trained the model to predict battery voltage as a function of quantities that can be measured in real-life \xe2\x80\x93 specifically average velocity, distance traveled within the route, and average load. Details of this model are available in the aws-do-pm blog.\nThe second step is to run a sensitivity analysis to determine which model parameters to calibrate. The aws-do-pm framework implements the Sobol index for sensitivity analysis because it measures sensitivity across the entire multi-variate input space and can identify the main effect and 2-way interactions. The details are covered in the aws-do-pm documentation and the corresponding technical blog and briefly summarized here. The graph on the left shows the result for the main effects plot, indicating that trip_dist_0, bias_weight_array_2, and bias_weight_array_4 are the key parameters needed to be included in the calibration. The graph on the right shows the chord plot for 2-way interactions indicating the additional parameters to include in the calibration.\nThe third step is calibrating the battery model using the parameters that had the most significant impact on the output voltage. The model calibration in aws-do-pm employs the Unscented Kalman Filter (UKF) method, which is a Bayesian technique for parameter estimation of non-linear system behavior. UKF is commonly applied for guidance, navigation, and control of vehicles, robotic motion planning, and trajectory optimization \xe2\x80\x93 all of which represent use cases where real-world data is used to update the control of the system. In our application, we\xe2\x80\x99re using UKF in a similar manner, except this time, we\xe2\x80\x99ll use real-world data to update the model parameters of the L4 Digital Twins. The details on performing the calibration within the aws-do-pm framework are covered in the aws-do-pm documentation, as well as the corresponding technical blog.\nIn-production deployment of L4 EV battery digital twin\nNow that we have a trained and calibrated model of a new battery for each of the vehicles, we deploy the models into production. As shown in the architecture diagram below, this solution is created using AWS IoT SiteWise, and AWS IoT TwinMaker and builds on the solution developed for the L3 Predictive level.\nThe vehicle data, including trip distance, trip duration, average speed, average load (weight), and additional parameters, are collected and stored using AWS IoT SiteWise. Historical maintenance data and upcoming scheduled maintenance activities are generated in AWS IoT Core and stored in Amazon Timestream. AWS IoT TwinMaker can access the time series data stored in AWS IoT SiteWise through the built-in AWS IoT SiteWise connector and the maintenance data via a custom data connector for Timestream. For the predictive modeling, we export the EV data to Amazon Simple Storage Service (Amazon S3) to generate a dataset in CSV format, from where it is picked up by aws-do-pm.\nAws-do-pm runs a service on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster responsible for the execution of tasks, such as the updating of individual battery models, and the persistence and synchronization across different data stores. We added a custom task that periodically checks for new trip data placed on Amazon S3. This data is used to perform new predictions and update individual battery models as required. The predictions are then fed back to an S3 bucket and then to AWS IoT SiteWise. From there, they are forwarded to AWS IoT TwinMaker and displayed in the Amazon Grafana dashboard.\nWe simulated in-production real-world operations by having the vehicles \xe2\x80\x9cdrive\xe2\x80\x9d the routes as per the synthetic datasets generated earlier. We then used the calibrated model of the new EV battery in the predict-measure-recalibrate loop we described earlier. In this manner, the EV battery model for each vehicle evolves over time, with different model parameters being estimated based on the routes driven. For example, the figures below show the model error calculated between the model prediction and the measured voltage at three different points over the course of many routes. We can see the error is calculated at the end of each route (blue dot) and if the error is above the threshold, then a model update is triggered (red dot). The error for the non-updated model prediction (blue line) drifts higher, whereas the updated model prediction stays near or below the threshold.\nThe complete voltage versus time history for a single route of the above figures is shown below. The left figure shows the non-updated model prediction (red line) and prediction uncertainty band (red shaded area), which is well above the actual observed data (dashed line). The right figure shows the updated model prediction (blue line) and uncertainty band (blue shaded area) overlapping the observation data (dashed line).\nThis example demonstrates the value of the L4 Living Digital Twin as the behavior of the degraded EV battery is correctly modeled over time. The lower voltage output from the battery and the resulting lower battery capacity directly translates into shorter ranges for the EV as the battery ages. Range anxiety (e.g., fear of being stranded due to a dead EV battery) and reduced battery capacity are key drivers in the market value of EVs and research in the automotive industry. In a future blog, we\xe2\x80\x99ll extend the concepts in this example to show how to use an L4 Living Digital Twin to calculate EV remaining range (to address range anxiety) and battery State of Health (SoH), which determines the value of the EV battery (and therefore the EV) on the second-hand market.\nSummary\nIn this blog, we described the L4 Living level by walking through the use case of point-by-point prediction of in-route voltage for an EV battery as it degrades over time. We leveraged the aws-do-pm framework published by Iankoulski, Balasubramaniam, and Rajagopalan and showed how to integrate their example EV fleet model with AWS IoT TwinMaker. In prior blogs, we described the L1 Descriptive, the L2 Informative, and the L3 Predictive levels. At AWS, we\xe2\x80\x99re excited to work with customers as they embark on their Digital Twin journey across all four Digital Twin levels, and encourage you to learn more about our new AWS IoT TwinMaker service on our website, as well as our open-sourced aws-do-pm framework.\nAbout the authors\nDr. Adam Rasheed is the Head of Autonomous Computing at AWS, where he is developing new markets for HPC-ML workflows for autonomous systems. He has 25+ years experience in mid-stage technology development spanning both industrial and digital domains, including 10+ years developing digital twins in the aviation, energy, oil & gas, and renewables industries. Dr. Rasheed obtained his Ph.D. from Caltech where he studied experimental hypervelocity aerothermodynamics (orbital reentry heating). Recognized by MIT Technology Review Magazine as one of the \xe2\x80\x9cWorld\xe2\x80\x99s Top 35 Innovators\xe2\x80\x9d, he was also awarded the AIAA Lawrence Sperry Award, an industry award for early career contributions in aeronautics. He has 32+ issued patents and 125+ technical publications relating to industrial analytics, operations optimization, artificial lift, pulse detonation, hypersonics, shock-wave induced mixing, space medicine, and innovation.\nDr. David Sauerwein is a Data Scientist at AWS Professional Services, where he enables customers on their AI/ML journey on the AWS cloud. David focuses on forecasting, digital twins and quantum computation. He has a PhD in quantum information theory.\nSeibou Gounteni is a Specialist Solutions Architect for IoT at Amazon Web Services (AWS). He helps customers architect, develop, operate scalable and highly innovative solutions using the depth and breadth of AWS platform capabilities to deliver measurable business outcomes. Seibou is an instrumentation engineer with over 10 years experience in digital platforms, smart manufacturing, energy management, industrial automation and IT/OT systems across a diverse range of industries\nPablo Hermoso Moreno is a Data Scientist in the AWS Professional Services Team. He works with clients across industries using Machine Learning to tell stories with data and reach more informed engineering decisions faster. Pablo\xe2\x80\x99s background is in Aerospace Engineering and having worked in the motorsport industry he has an interest in bridging physics and domain expertise with ML. In his spare time, he enjoys rowing and playing guitar.\n '"
47,Building an EV Battery Monitoring solution with AWS IoT FleetWise (Part 1/2),b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/28/Screenshot-2022-09-28-at-09.11.18-1024x524.png,https://aws.amazon.com/blogs/iot/building-an-ev-battery-monitoring-solution-with-aws-iot-fleetwise-part-1-2/,"b'Introduction\nAutomakers, fleet operators, and automotive suppliers are recognizing the potential of vehicle data to transform their business models and optimize their operations. However, implementing data-driven use cases is often challenging. Proprietary vehicle data formats, high costs of data ingestion and implementation complexity can slow down innovation.\nAWS IoT FleetWise is a service that makes it easier for automakers to collect, transform, and transfer vehicle data to the cloud. Once transferred, customers can use breadth and depth of AWS analytics and machine learning services to extract value from the vehicle data. If you have no previous experience with AWS IoT FleetWise, please consider starting with the blog Generating insights from vehicle data with AWS IoT FleetWise. You will learn about use cases, technical capabilities, and a logical architecture for AWS IoT FleetWise. In the same blog, we also introduced an Electric Vehicle (EV) battery monitoring solution.\nThis post will walk you through building that EV battery monitoring solution with AWS IoT FleetWise. First, you will deploy an EV simulation on an Amazon Elastic Compute Cloud (Amazon EC2) instance in your AWS account. Then, you will configure AWS IoT FleetWise to collect, transform, transfer, and store the CAN bus signals from the vehicle. Finally, you will query the collected data using the Amazon Timestream service.\nUse case\nLithium-ion batteries (LiBs) are widely used as energy storage systems for EVs. When operating EV fleets, continuous monitoring and protection of battery cells is an important consideration.\nFor EV manufacturers and fleet operators, the ability to detect and predict battery issues such as overcurrent, overcharge or overheating is crucial. For example, it can improve efficiency and safety of fleet operations by enabling timely planning for battery replacement. Another example is that it allows EV manufacturers to collaborate with battery suppliers on battery improvement initiatives, by evaluating the conditions of the battery in different scenarios.\nThe purpose of this blog is to demonstrate how you can use AWS IoT FleetWise to collect and transfer BMS parameters to the cloud. For that purpose, we will use an example of overcurrent detection use-case. After the data is transferred, it will be stored in a database, ready to be used for monitoring, alarming and ML model traning.\nSolution architecture\nThe following diagram shows the architecture of the solution. We also indicate the scope of this blog post, that we will implement following the step-by-step walkthrough. The remaining part of the architecture will be covered in part 2 of this blog series.\nSolution Architecture\nPlease refer to the previous part of this blog series for a detailed description of the solution architecture.\nImplementation approach\nThe following sample implementation utilizes two vehicles and two data collection campaigns.\nVehicles\nThe vehicles will be simulated by one Amazon EC2 instance each. The EC2 instance will run a script generating CAN bus messages to simulate BMS. Both vehicles will intentionally use slightly different CAN signal encodings to demonstrate the ability of AWS IoT FleetWise to provide unified access to heterogeneous vehicle fleets.\nSide remark: the vehicle simulation can be easily adopted to reproduce any previously recorded CAN or OBD-II signals on a simulated environment. This can be useful in a prototyping phase of solutions based on AWS IoT FleetWise. For example, you could record CAN data from your vehicles using the tool of your choice. Once recorded, you could replay the vehicle data on a simulated environment for AWS IoT FleetWise testing. You can learn more about simulating your own vehicle data in the GitHub repository.\nData collection campaigns\nTo learn how to configure the data collection features of AWS IoT FleetWise, you will set up two data collection campaigns:\nA data collection campaign for continuous, low frequency (1 second sampling rate) monitoring of EV battery pack current and battery cell temperature. For the sake of simplicity, we will include only one single battery cell in our example.\nA conditional data collection campaign to collect a high-resolution (50 ms sampling rate) snapshot of multiple Battery Management System (BMS) signals. This campaign will only collect data under condition that the shunt current (represented by the signal EVBatterySample.BMS.BatteryPack01.ShuntPlusCurrent_a) is above 450 amperes, i.e. in overcurrent scenario.\nIntroducing the AWS IoT FleetWise logical data model\nTo deploy a solution based on AWS IoT FleetWise, you will configure data collection, transformation, and transfer from your vehicle fleet. AWS IoT FleetWise provides APIs to achieve that. You can invoke these APIs by using the AWS Management Console, AWS SDKs, or AWS CLI.\nMost of the APIs you will use in this blog follow the CRUD (Create, Read Update, Delete) paradigm. For example, you can use the API action CreateCampaign to configure a new data collection campaign, or UpdateCampaign to change the status of the campaign.\nThe CRUD operations refer to the following key elements of the logical data model of AWS IoT FleetWise: Signal Catalog, Vehicle Model, Campaign, Vehicle, Fleet and DecoderManifest. The following diagram introduces these elements and explains their relationships:\nLogical data model of AWS IoT FleetWise\nPlease follow the guidelines in this blog to learn how to create each of these data model elements using the AWS IoT FleetWise APIs.\nIn this blog you will use AWS CLI to interact with AWS IoT FleetWise APIs. You can also use the AWS IoT FleetWise Management console to manage AWS IoT FleetWise.\nDeploying the solution\nOpen AWS CloudShell\nPlease click on this link to open AWS CloudShell (a browser-based shell). Please ensure to change your AWS region to one of the regions supported by AWS IoT FleetWise (e.g. Europe Frankfurt or US East Virginia).\nClone the repository\nPlease clone the GitHub repository with the resources for this blog by running the following commands:\ngit clone https://github.com/aws-samples/aws-iot-fleetwise-evbatterymonitoring\nBash\nCreate Amazon EC2 keypair\nPlease run the following command to create and store a new Amazon EC2 keypair. You will use it to establish an SSH connection to an Amazon EC2 instance with vehicle simulation in a later step.\naws ec2 create-key-pair --key-name fleetwiseblogec2key | \\\njq -r .KeyMaterial > fleetwiseblogec2key.pem\n\nchmod 0600 fleetwiseblogec2key.pem\nBash\nDeploy a solution for vehicle simulation\nIn this step, you will deploy an AWS CloudFormation stack to set up the simulation for two vehicles. This stack will provision the required resources in your AWS account.\nDeploying this solution may incur costs on your AWS bill, e.g., for Amazon EC2, AWS IoT and Amazon Timestream services. Please remember to remove these resources by deleting the AWS CloudFormation stack to avoid unintended costs. You will find instructions for deleting the stack at the end of this blog.\nPlease change the directory:\ncd aws-iot-fleetwise-evbatterymonitoring\nBash\nPlease deploy the stack.\naws cloudformation deploy \\\n--template-file simulatedvehicle/ec2simulation/template.yaml \\\n--stack-name vehiclesimulation --disable-rollback \\\n--parameter-overrides Ec2KeyPair=fleetwiseblogec2key IoTCoreRegion=$AWS_REGION \\\n--capabilities ""CAPABILITY_NAMED_IAM""\nBash\nPlease continue with the guidelines of this blog while the deployment of AWS CloudFormation stack runs (approx. 20 minutes). If you experience problems with the stack deployment, please consider the troubleshooting guidelines.\nYou can use \xe2\x80\x9cNew tab\xe2\x80\x9d function in AWS CloudShell \xe2\x80\x9cActions\xe2\x80\x9d menu to create a new tab for next steps .\nCreate AWS CLI input files\nTo improve the readability of this blog, we will provide input to AWS CLI commands in JSON format. To create these JSON files specialised for your account and region, run the following commands which will do that task for you:\ncd ~/aws-iot-fleetwise-evbatterymonitoring/cloud\n./prepare_templates.sh\ncd cli-inputs\nBash\nCreate an AWS IAM role\nFirst, we will create an AWS Identity and Access Management (IAM) role for the AWS IoT FleetWise service with the right permissions to write to the Amazon Timestream database:\naws iam create-role --role-name AWSIoTFleetWiseServiceRole\\\n    --assume-role-policy-document file://1_setup/trustpol.json\n\naws iam create-policy --policy-name AWSIoTFleetwiseIAMUserPolicy \\\n                      --policy-document file://1_setup/policy.json\n\naws iam attach-role-policy --cli-input-json file://1_setup/policy_attach.json\nBash\nPlease review the AWS IAM role policy to learn more about the necessary permissions.\nInitial AWS IoT FleetWise configuration\nIn this step, you configure AWS IoT FleetWise with the IAM role you created earlier and the Amazon Timestream database and table names. You need to perform this configuration once for the respective AWS region before you can use AWS IoT FleetWise.\naws iotfleetwise register-account \\\n    --cli-input-json file://1_setup/account_registration.json\n# Check if registration is successfull\naws iotfleetwise get-register-account-status\nBash\nYou can learn more about the initial configuration by reviewing the input file account_registration.json . Please review to RegisterAccount API for details.\nCreate signal catalog\nThe signal catalog is a definition of standardized vehicle signals. To create a new signal catalog, please run the following command:\naws iotfleetwise create-signal-catalog\\\n    --cli-input-json file://2_signal_catalog/create-signal-catalog.json\nBash\nYou can learn about the structure of the signal catalog by reviewing the input file create-signal-catalog.json. Please refer to the CreateSignalCatalog API for details.\nCreate vehicle model manifest\nLet\xe2\x80\x99s review the concept of a vehicle model in AWS IoT FleetWise. The purpose of vehicle model is to enforce consistent data structure across multiple vehicles of the same type, so that you can process data from fleets of vehicles. With AWS IoT FleetWise, we use the term \xe2\x80\x9csignal\xe2\x80\x9d referring to the vehicle data.\nFor example, a fleet operator may have a fleet of two vehicles types \xe2\x80\x93 EVs and electric scooters. Both EVs and scooters may generate some common data (also called \xe2\x80\x9cvehicle signals\xe2\x80\x9d). An example for that is \xe2\x80\x9ccurrent vehicle speed\xe2\x80\x9d. However, the EVs may generate signals which are not applicable for the scooters, for example tire pressure. To differentiate between data schemas for EVs and electric scooter, the fleet operator can create two vehicle models in AWS IoT FleetWise.\nThe model manifest formally describes the schema of the data to be collected from a specific type of vehicle. Please review the model manifest examples in files vehicle-model1.json and vehicle-model2.json .\nPlease note that a newly created model manifest must be activated before further use. Once activated, no further changes of the model manifest are possible. To create and activate model manifests for two vehicle models, please run the following commands.\n# Model 1\naws iotfleetwise create-model-manifest\\\n    --cli-input-json file://3_model_manifest/vehicle-model1.json\naws iotfleetwise update-model-manifest --status ACTIVE --name blog-modelmanifest-01\n# Model 2\naws iotfleetwise create-model-manifest\\\n    --cli-input-json file://3_model_manifest/vehicle-model2.json\naws iotfleetwise update-model-manifest --status ACTIVE --name blog-modelmanifest-02\nBash\nPlease refer to the CreateModelManifest documentation for details.\nPlease note that while there is overlap between the signals for both models, some signals are only available for the specific model. For example, \xe2\x80\x9cEVBatterySample.BMS.Relay01.Status\xe2\x80\x9d is only available for the first model, not the second model. This is to demonstrate how you can model heterogeneous vehicle fleets while providing consistent access to the common signals.\nCreate decoder manifest\nThe decoder manifest describes the decoding rules for signals of a particular vehicle. To create and activate decoder manifests, please run the following commands:\n# Decoder manifest 1\naws iotfleetwise create-decoder-manifest\\\n    --cli-input-json file://4_decoder_manifest/decoder-manifest1.json\naws iotfleetwise update-decoder-manifest --status ACTIVE --name blog-decodermanifest-01\n# Decoder manifest 2\naws iotfleetwise create-decoder-manifest\\\n    --cli-input-json file://4_decoder_manifest/decoder-manifest2.json\naws iotfleetwise update-decoder-manifest --status ACTIVE --name blog-decodermanifest-02\nBash\nYou can learn about the model manifest by reviewing the input files decoder-manifest1.json and decoder-manifest2.json.\nPlease note that encoding for the signal \xe2\x80\x9cEVBatterySample.BMS.BatteryPack01.ShuntPlusCurrent_a\xe2\x80\x9d is different between the first and the second decoder manifest. This is to demonstrate how AWS IoT FleetWise creates an abstraction of decoding from the vehicle model. This allows you to handle different encodings while providing consistent access to vehicle signals.\nPlease review CreateDecoderManifest API for details. Please note that you can also use the ImportDecoderManifest API to create a decoder manifest using a DBC file.\nCreate a vehicle\nThe vehicle is an instance of a vehicle model, representing a physical vehicle. To create vehicles, please run the following commands:\naws iotfleetwise create-vehicle --cli-input-json file://5_vehicle/vehicle01.json\naws iotfleetwise create-vehicle --cli-input-json file://5_vehicle/vehicle02.json\nBash\nYou can learn about the vehicle by reviewing the input files vehicle01.json and vehicle02.json . Please review the CreateVehicle API for details.\nCreate a fleet and associate vehicles with the fleet\nWith AWS IoT FleetWise, you can target a campaign either towards a specific vehicle or a fleet, i.e. a set of vehicles. To create an example fleet and associate both vehicles with the fleet, please run the following commands:\naws iotfleetwise create-fleet --cli-input-json file://6_fleet/fleet.json\naws iotfleetwise associate-vehicle-fleet --fleet-id blog-fleet\\\n    --vehicle-name blog-vehicle-01\naws iotfleetwise associate-vehicle-fleet --fleet-id blog-fleet\\\n    --vehicle-name blog-vehicle-02\nBash\nYou can learn about the fleet by reviewing the input file fleet.json. Please review the CreateFleet and AssociateVehicleFleet API for details.\nInitiate data collection campaigns\nIn this section, you will implement two typical use cases for vehicle data collection. For this purpose, you will create two data collection campaigns.\nTo initiate a data collection campaign with AWS IoT FleetWise, create a new campaign by calling CreateCampaign API and then approve the campaign calling UpdateCampaign API . By approving the campaign, you instruct AWS IoT FleetWise to send the configuration for data collection campaigns and decoders to the vehicles. Based on this configuration, the AWS IoT FleetWise Edge Agent starts collecting, transforming, and transferring data to the AWS.\nLet us take a look at the individual campaigns.\nCampaign 1: continuously collect battery pack current and cell temperature\nThis campaign will use a time-based collection scheme, i.e. the Edge Agent will continuously collect vehicle data and transfer it to the cloud in the specified time period. To create this campaign, please run the following commands:\naws iotfleetwise create-campaign \\\n    --cli-input-json file://7_campaign/continious-monitoring-campaign.json\n# Please wait 15 seconds before running the next command to allow for campaign creation to complete\naws iotfleetwise update-campaign --action APPROVE\\\n    --name continious-monitoring-campaign\nBash\nYou can learn more about this campaign by reviewing continious-monitoring-campaign.\nCampaign 2: conditionally collect a high-resolution (50 ms sampling rate) snapshot of multiple Battery Management System (BMS) signals.\nAn example of a use case for this campaign is the analysis of potential problems with the battery packs of a pre-production vehicle fleet. To perform an analysis, vehicle quality engineers may need a high-resolution snapshot for multiple signals (e.g., temperature development of specific battery cells). However, let us assume that the vehicle engineers are only interested in the data if overcurrent event occurs.\nTo implement this use case, you will create a campaign with a condition-based collection scheme. The Edge Agent will evaluate an expression that you can define (for example, $variable.`EVBatterySample.BMS.BatteryPack01.ShuntPlusCurrent_a` > 450.0). Only if this expression evaluates to true does the Edge Agent collect vehicle data and transfer it to the cloud.\nTo create this campaign, please run the following commands:\naws iotfleetwise create-campaign\\\n     --cli-input-json file://7_campaign/conditional-snapshot-campaign.json\n# Please wait 15 seconds before running the next command to allow for campaign creation to complete\naws iotfleetwise update-campaign --action APPROVE\\\n    --name conditional-snapshot-campaign\nBash\nYou can learn more about this campaign by reviewing conditional-snapshot-campaign.json.\nTesting the solution\nYou have successfully deployed a simulation and configured the AWS IoT FleetWise service. Now it\xe2\x80\x99s time to see the overall solution in action. Please follow the instructions below.\nStep 1: Connect to the simulated vehicle\nIn this step, you will connect to the Amazon EC2 instance that simulates the vehicle. You will then review the output of two software components: Edge Agent and the CAN bus simulation script. Please complete the following steps:\n1. Get the output of the stack\naws cloudformation describe-stacks \\\n    --stack-name vehiclesimulation \\\n    --query ""Stacks[0].Outputs[?OutputKey==\'Ec2Instance1SSH\'].OutputValue"" \\\n    --output text\nBash\nIf you see \xe2\x80\x9cNone\xe2\x80\x9d as output, it means that stack deployment has not completed yet. Please retry in few minutes. If you experience problems with the stack deployment, please consider the troubleshooting guidelines.\n2. SSH into the Amazon EC2 instance\nPlease copy and paste the SSH command from the stack output above and run it. When asked if you want to connect to the instance, please confirm with \xe2\x80\x9cyes\xe2\x80\x9d:\nssh -i ~/fleetwiseblogec2key.pem ubuntu@<Value of Vehicle1EC2PublicIP>\nBash\n3. View CAN messages\nPlease view the CAN data generated by the vehicle simulation script that runs as a system service.\ncandump vcan0\nBash\nYou can exit the output mode using Ctrl-C command.\n4. You can view Edge Agent output\nsudo journalctl -fu fwe@0\nBash\nYou can safely ignore error message \xe2\x80\x9cFailed to receive VIN from Engine ECU\xe2\x80\x9d.\nStep 2: Review collected vehicle data in Amazon Timestream\nIn this step, you will review the results of the data collection campaigns stored in the Amazon Timestream table.\n1. Open the Amazon Timestream Console\nPlease navigate to \xe2\x80\x9cAmazon Timestream\xe2\x80\x9d service in AWS management console or click on this link. Next, select the Query editor menu item.\nAmazon Timestream console\n2. Review vehicle data collected by campaign 1 \xe2\x80\x9cContinuously collect battery pack current and cell temperature\xe2\x80\x9d\nIn the text field for the query, enter the following sample query and choose Run :\nSELECT time, vehicleName, measure_name, measure_value::double, VehicleVIN\nFROM ""FleetWiseDatabase"".""FleetWiseTable""\nWHERE campaignName = \'continious-monitoring-campaign\' AND\n      time between ago(15m) and now()\nORDER BY time DESC LIMIT 10\nSQL\nYou can now view the collected vehicle data as you see in example below:\n\nIn spite of the fact that both vehicles encode the CAN message for the signal EVBatterySample.BMS.BatteryPack01.ShuntPlusCurrent_a in different ways (see DBC files for vehicle 1 and vehicle 2), you can access and analyze the vehicle data under a uniform name!\nWe suggest to run your own experiments with visualizing the vehicle data by using Amazon Managed Grafana with example dashboards, as you can see in the example below:\n3. Review vehicle data collected by campaign 2\nLet\xe2\x80\x99s query the statistics of a specific cell temperature. Enter the following query and select Run :\nSELECT vehicleName, measure_name,\n       hour(time) as hour, minute(time) as minute,\n       max(measure_value::double) as MaxTemperature,\n       min(measure_value::double) as MinTemperature\nFROM ""FleetWiseDatabase"".""FleetWiseTable""\nWHERE campaignName = \'conditional-snapshot-campaign\'\n      AND measure_name = \'EVBatterySample.BMS.BatteryPack01.Cell001.CellTemperature\'\n      AND (time between ago(10m) and now())\nGROUP by vehicleName, measure_name, hour(time), minute(time)\nORDER by vehicleName,hour(time), minute(time)\nSQL\nYou can now view the aggregated vehicle data as you see in example below. According to the campaign configuration , the data was transferred only when battery pack shunt current was over 450 amperes. For 19:42 and 19:43, shunt current was below 450 amperes, so no data was transferred.\nWe suggest to run your own experiments with the vehicle data by following Amazon Timestream Query Language reference guidelines or by creating Amazon Managed Grafana dashboards like below using provided examples:\nCleaning up\nPlease ensure to exit the SSH session to the Amazon EC2 instance before you continue. Please run the following commands in AWS CloudShell to remove the created resources from your AWS account:\naws cloudformation delete-stack --stack-name vehiclesimulation\nsh ~/aws-iot-fleetwise-evbatterymonitoring/cloud/automation/fleetwise-cleanup.sh\nBash\nSummary and next steps\nYou have learned how to use AWS IoT FleetWise to implement the collection, conversion, transmission, and storage of CAN bus signals and how to query these signals using Amazon Timestream. In the next part of this blog series, we will introduce you to how you can use AWS services to analyze stored data.\nVisit the AWS IoT FleetWise webpage to learn more.\nSpecial thanks\nGeoffrey Phillips (Senior Software Development Engineer) contributed major parts of the AWS CloudFormation template and the CAN Interactive Generator library.\nAbout the authors\nAndrei Svirida is Senior Specialist Solutions Architect at Amazon Web Services. He is passionate about enabling companies of all sizes and industries to become data-driven businesses. To that end, he helps AWS customers to architect and build secure and scalable solutions on AWS, focusing on IoT, Analytics and Data Engineering. Prior to joining AWS, Andrei worked at KUKA AG as Head for IoT Delivery and as VP in in-house consulting at Deutsche Telekom AG. Andrei has a computer science background and more then 18 years of industry experience.\n\nSuvendu Rath is Senior Engagement Manager at Amazon Web Services. He is passionate about robust innovation strategies for Automotive customers. He helps AWS customers to run innovation projects from initial brief through to final deliverable, focusing on IoT, AI/ML and Data Engineering. Prior to joining AWS, Suvendu worked as Software Project Lead at BMW AG and as Software Engineer in Automotive/Avionics industry . Suvendu has an Electrical Engineering background and more than 15 years of industry experience in Automotive and Avionics domain.\nKatja-Maja Kroedel is IoT Specialist Solution Architect at Amazon Web Services. She works with AWS customers to provide guidance on cloud adoption, migration, and strategy in the area of IoT. She is passionate about technology and enjoys building and experimenting in the cloud with innovative services, such as AWS IoT FleetWise. Katja has a Computer Engineering background and already worked at different roles within AWS, starting with her Masterthesis as well as her role as Generalist Solutions Architect in Germany, helping small- and middle-sized customers grow and learn about the cloud.'"
48,Monitoring your IoT fleet using CloudWatch,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/monitoring-your-iot-fleet-using-cloudwatch/,"b'Introduction\nIn this blog we will show you how to monitor your IoT (Internet of Things) fleet and alert when conditions reach or exceed normal thresholds that you consider to be normal operational limits. We will go through the steps to setup Amazon CloudWatch dashboards based on AWS IoT metrics, create alarms from metrics, and then query log data to gain additional insights into your fleet activity or assist in troubleshooting.\nAs per the AWS Well-Architected Framework, after you implement your workload, you must monitor its performance so that you can remediate any issues before they impact your customers. Monitoring metrics should be used to raise alarms when thresholds are breached.\nAmazon CloudWatch is a monitoring and observability service that provides you with data and actionable insights to monitor your workload, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. CloudWatch collects monitoring and operational data in the form of logs, metrics, and events from workloads that run on AWS and on-premises servers.\nThe steps we will follow to setup our IoT monitoring are:\nPrerequisites\nEnable logging for AWS IoT Core\nCreate a CloudWatch dashboard\nCreate custom IoT alarms and metrics\nView custom metrics and create alarms\nTroubleshoot an issue that created the alert\nPrerequisites\nThe steps in this blog will use the AWS Command Line Interface (AWS CLI) for demonstration purposes. To configure basic settings please refer to the AWS CLI Quick setup.\nEnable logging for AWS IoT Core\nYou can configure AWS IoT logging by using the AWS Management Console, AWS Command Line Interface (AWS CLI), or the AWS IoT Core API. In order to configure logging for specific thing groups or specific devices you will need to use the AWS CLI or the IoT Core API.  For additional information, please refer to IoT Device Logging.\nUse the set-v2-logging-options command to set the logging options for your account.\naws iot set-v2-logging-options \\\n--role-arn <logging-role-arn> \\\n--default-log-level <log-level>\nLog-levels:\nERROR \xe2\x80\x93 Any error that causes an operation to fail. Logs include ERROR information only.\nWARN \xe2\x80\x93 Anything that can potentially cause inconsistencies in the system, but might not cause the operation to fail. Logs include ERROR and WARN information.\nINFO \xe2\x80\x93 High-level information about the flow of things. Logs include INFO, ERROR, and WARN information.\nDEBUG \xe2\x80\x93 Information that might be helpful when debugging a problem. Logs include DEBUG, INFO, ERROR, and WARN information.\nDISABLED \xe2\x80\x93 All logging is disabled.\nIn addition to thing groups, you can also log targets such as a device\xe2\x80\x99s client ID, source IP, and principal ID.\nThing group\nDevice level (Client ID, Source IP, principal ID)\nUsing the set-v2-logging-level command to configure resource-specific logging.\naws iot set-v2-logging-level \\\n\xe2\x80\x93log-target targetType=THING_GROUP, targetName=<thing_group_name> \\\n\xe2\x80\x93log-level <log-level>\nIn the following example the logging level for a single device with the clientID beta_device123 has been set to DEBUG:\naws iot set-v2-logging-level \\\n--log-target ""{\\""targetType\\"":\\""CLIENT_ID\\"",\\""targetName\\"":\\""beta_device123\\""}"" \\\n--log-level DEBUG\nAdjusting the log-level to INFO or DEBUG for specific thing groups is useful when deploying new features or firmware. After a successful deployment you drop the log-level back to your standard logging level.\nAWS IoT Monitor dashboard\nThe Monitor dashboard allows you to view CloudWatch metrics for AWS IoT from all devices registered in your AWS account. In this dashboard below, you can see the number of messages published and received by your devices aggregated by protocol, type, and direction, the number of messages published by your devices over time, and other metrics. It is available in the monitor section of the AWS IoT Core page in the AWS console.\nCreate a CloudWatch dashboard\nAmazon CloudWatch (CloudWatch) dashboards are customizable home pages in the CloudWatch console that you can use to monitor your resources in a single view, even those resources that are spread across different Regions.\nWhen you interact with AWS IoT, the service sends the following metrics to CloudWatch every minute.\nRule metrics\nMessage broker metrics\nDevice provisioning metrics\nFleet indexing metrics\nConsider setting up a dashboard that includes metrics that are important to your deployment. For example, if you have a fleet with a steady messaging rate along with an expected number of IoT Rule executions you could have them as part of your dashboard. Another dashboard could display the status of IoT jobs deployed to your fleet showing the number of queued jobs, successful jobs, and failed jobs. As your fleet changes over time, the dashboards may need to be updated to reflect the new status or metrics for your fleet.\nIn the CloudWatch metrics picture below you can see an examples of AWS IoT metrics. For this specific region the CloudWatch is retrieving metrics for the number of devices successfully registered, certificates creation related metrics, and the number of times devices failed to provision due to a client side or server side error.\nNow, below you can see how a user can browse through the available metrics and add it to a dashboard. In this case, select the specific certificate Id, then click Add to dashboard using the drop-down Actions menu at the top right.\nThis displays how many Things have been registered successfully at the selected time period window of one hour. You can change this to different interval period of time.\nBelow is a custom made dashboard created in Amazon CloudWatch with the basic metrics for your fleet of IoT devices. This can be used by the operations teams to understand the status of the fleet.\nCreate custom AWS IoT metrics\nAWS IoT sends many standard metrics and dimensions to CloudWatch.  You can also search and filter the log data coming into CloudWatch Logs by creating one or more metric filters. Metric filters define the terms and patterns to look for in log data as it is sent to CloudWatch Logs. CloudWatch Logs uses these metric filters to turn log data into numerical CloudWatch metrics that you can graph or set an alarm on.\nIn the Amazon CloudWatch Console, in the left side navigation pane, expand Logs and select Log Groups. Click on the AWSIotLogsV2 log group.\nIn the below picture you can see the AWSIoTLogsV2 Log group detail.\nClick the Search Log Group button and type the search string below into the filter events dialog box and choose 30 minutes as the time period. For more information on how to query log events in CloudWatch refer to Search log data using filter patterns \xe2\x80\x93 Amazon CloudWatch Logs.\nType the following into the search box.\n{ $.eventType = RuleExecution && $.status = Failure }\nBelow we have an example of several failed rule executions over the past 30 minutes.\nClick on the Create Metric Filter button to create a metric based on this search pattern. In the picture below, I am naming the filter something descriptive and also creating a new metric namespace called MyIotApplication.\nAs you add more metrics you can group them by application, workload, projects, or any grouping that your organization has chosen. The metric value is set as one, as it is sent to the metric filter each time the filter pattern matches. Other fields are left at default. Click the Create button to continue. Once this metric filter has been created you can use it just as you would other CloudWatch metrics by adding it to a graph, dashboard, or creating an alarm.\nView custom metrics and create alarms\nNow we navigate to the CloudWatch console and select All Metrics from the left side menu. In the main window select the Browse tab and you will see the new custom namespace you just created. In this example it is called MyIotApplication. Click on the MyIotApplication link then the Metric with no dimension. The output below shows the number of failed rule executions over the time period selected.\nBy clicking on the Graphed Metrics tab and you will see more details about the metric and allow you to change the type of graph, time period, and more. You can add this metric to your dashboard or a new dashboard using the Action drop down button at the top right of the screen.\nYou can also click on the bell icon to create an alarm. Let\xe2\x80\x99s do that now.\nAfter clicking the bell icon, you will see the following form which will allow you to make adjustments to the alarm configuration.\nThis allows you to set thresholds for your alarm. We will set a threshold of two or greater within five minutes. Under Additional configuration leave these at default. This allows the alarm to go back to a normal state if the threshold value drops below the alarm threshold for one period of time\xe2\x80\x94in this case five minutes.\nClick Next and select an Amazon Simple Notification Service (Amazon SNS) topic that will receive the notification when in an ALARM state. This assumes you have already configured an Amazon SNS topic. Additional information can be read in Creating an Amazon SNS Topic.\nSelect a name for your alarm and click Next.\nOn the next screen click on the Create Alarm if everything looks correct. Your alarm is now created.\nYou can test your alarm and notifications by setting the alarm to ALARM using the AWS CLI. Below we show the commands to set the alarm to ALARM and back to OK.\naws cloudwatch set-alarm-state --alarm-name IoTRuleExecutionFailures --state-reason ""testing alarm"" --state-value ALARM\naws cloudwatch set-alarm-state --alarm-name IoTRuleExecutionFailures --state-reason ""testing alarm"" --state-value OK\nTroubleshoot an issue that created an alert\nNext, we show the steps you could perform when you have an alarm or device behavior that is outside of expected thresholds. CloudWatch Logs and CloudWatch Logs insights provide powerful search functions to assist you in identifying possible root causes of the alarms or unexpected behaviors.\nAWS IoT logs are stored in the AWSIotLogsV2. If you navigate to this log group you will see the events stored in various log streams. By clicking on the Search log group button you can filter these logs by query and time frame.\nIf you are expecting rules to be evaluated and actions to be performed you can verify this by filtering for event type RuleMatch as follows:\n{ $.eventType = RuleMatch }\nIf you want to search for any rules that have failed in the past 30 minutes I would add the following to the filter field. This example shows how to filter for RuleExecution events, but only the events that have a status of failure:\n{ $.eventType = RuleExecution && $.status = Failure }\nCloudWatch logs Insights enable you to interactively search and analyze your log data in CloudWatch logs. You can perform queries to help you more efficiently and effectively respond to operational issues. If an issue occurs you can use CloudWatch Logs Insights to identify potential causes and validate deployed fixes.\nCloudWatch Log Insights can be used as a tool to help you understand patterns of usage. Let\xe2\x80\x99s take an example where you want to list the top 10 topics being published to.\nfields @timestamp, topicName\n| stats count(*) as numPublishIn by (eventType=""Success"") , topicName\n| sort numPublishIn desc\n| limit 10\nTop 50 Publishers by clientID\nfilter eventType=""Publish-In""\n| stats count(*) as numPublishIn by clientId\n| sort numPublishIn desc\n| limit 50\nCloudWatch Log Insights allows you to build queries against the logs. If you received a connection throttle alert you may want to run a query to show the clients with the highest number of connections during the past 30 minutes:\nfilter eventType=""Connect""\n| stats count(*) as NumConnections by clientId\n| sort NumConnections desc\n| limit 20\n'"
49,Managing Organizational Transformation for Successful OT/IT Convergence,b'Ali Benfattoum',2022-10-18T16:17:13+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/16/OT-IT-Blog-Title-Photo.jpeg,https://aws.amazon.com/blogs/iot/managing-organizational-transformation-for-successful-ot-it-convergence/,"b'Introduction\nIndustrial organizations are facing a new challenge as they try to merge the traditional physical world (Operational Technology or OT) and the digital world (Information Technology or IT). In our experience, companies who prioritize organizational change management when implementing digital solutions get better results from their investments. This is even more true when building Industrial Internet of Things (IIoT) systems due to the complexities inherent in bringing together OT and IT organizations. Advances in technologies such as IIoT, Industry 4.0, data analytics, machine learning (ML), artificial intelligence (AI) and cloud platforms are making it possible for the digital information world to see, understand, and influence the physical operational world. The data collected from physical equipment and IIoT devices (sensors, cameras, gateways, and other equipment) can be used to identify problems and improve operational efficiencies in the physical world. However, OT/IT convergence can also open new avenues for cyber-events. Therefore, doing things faster, more cost-efficiently, and more sustainably carries risk, which can be mitigated with proper planning and implementation across all aspects of business \xe2\x80\x93 people, process, and technology.\nThis blog provides supportive guidance on how to approach OT/IT convergence from an organizational transformation perspective and mitigate the increased risk with robust cybersecurity measures.\nChallenges with OT/IT convergence\nOT and IT are generally divided due to different priorities, competencies and operational practices. OT deals with mission critical and life-critical systems. OT professionals generally focus on uptime, reliability, stability, and safety. They typically did not prioritize cybersecurity as most of their equipment was isolated from the internet to reduce risk. OT networks are typically designed to be time critical, run perpetually, and failures can be catastrophic, impacting machines, safety, and the environment. Change in OT is perceived as a source of risk. Therefore, software patching or running network scans requires more rigor in planning and impact assessment. Many OT systems are autonomous, self-contained, often vendor-dependent, and run on proprietary software. Organizationally, OT teams are typically siloed, autonomous, and operate under local /factory leadership.\nOn the other hand, IT deals with business-critical systems. IT professionals tend to focus on confidentiality, integrity and availability. They typically practice agile methodologies and are more open to change as compared to OT teams. IT security personnel are cybersecurity savvy and have established processes to keep networks protected but lack an industrial engineering background. IT networks can sustain downtime. A failure typically is a temporary recoverable disruption with loss of data. IT systems are intrinsically interconnected, have limited autonomy, and utilize standard operating systems. Software patching or running a network scan is considered business as usual. Organizationally, IT teams typically roll up under a centralized corporate leader, the CIO.\nWith so many differences between OT and IT teams and the challenges thereof, one might wonder if it is worth bringing them together. IDC predicts that the potential return on investment from advanced technology deployments in operations has crossed a critical threshold, and companies can no longer ignore the transformational opportunities presented by OT/IT convergence. By digitizing processes, industrial firms can boost productivity, make faster decisions, proactively remove bottlenecks, increase agility, and reduce waste, while assuring regulatory compliance.\nBest practices for managing organizational transformation to accelerate OT/IT convergence\nLeadership\nA committed and engaged senior leadership is required to overcome culture issues, which often is the real challenge in OT/IT convergence. Leaders can develop a collaborative culture where open dialogue and trust are encouraged. Clarifying roles and responsibilities and establishing accountability between teams is crucial. \xe2\x80\x9cTechnology\xe2\x80\x9d is mentioned in both operational and information contexts, but it\xe2\x80\x99s dramatically different and can be confusing. OT can be viewed more as a business function, enabled by IT \xe2\x80\x93 the technology service provider. OT leaders can benefit by realizing that a connected, smart industrial operation can simplify their work without compromising uptime, safety, security and dependability. Likewise, IT leaders can demonstrate business value through IIoT innovation, when they understand the uniqueness of OT requirements.\nWorking backwards from business objectives\nThe ultimate success of an industrial digital transformation initiative is dependent on the business benefits it produces. According to a McKinsey Global Institute study, manufacturers can use IIoT data to reduce product development costs by up to 50%, reduce operating costs by up to 25%, and increase gross margins by up to 33%. However, each business is unique; hence their business objectives will be different. All OT/IT convergence initiatives need to tie back to business objectives. For example, consider a manufacturing facility that experiences frequent unplanned equipment outages. A digital initiative to install sensors that proactively notify OT operators about equipment status, health, and performance would be a game-changer, as timely actions can be taken to prevent equipment failures, reduce costly downtime, and ensure workplace safety.\nBuilding trust\nBuilding trust between the OT and IT teams is critical for successful convergence. Mobilizing teams toward shared goals and establishing a safe environment where open communication, and collaboration are encouraged without judgement or fear of reprisal, can foster synergy between the two teams. One of the ways to start building confidence is to consider digitizing non-critical processes using familiar tools and technologies. IT personnel can demonstrate how digital tools provide data sets and actionable insights. This can ultimately develop OT champions of IT. For example, secondary sensing and everyday manufacturing operations, such as weighing, can be an excellent starting point for demonstrating the value of digitization and data analytics. See how KAMAX used IoT sensors to free up their operators\xe2\x80\x99 time.\nManaging risk\nIn a striking prediction, Gartner said that within three years, cyber criminals could weaponize OT assets and it predicts that the financial impact of cyber physical system compromises will reach over $50 billion by 2023. The integration of IT and OT introduces risk since systems built for usage in hostile networks are integrated with those that were not. Additionally, standard security solutions that work in IT cannot be directly applied to OT systems. Besides quality risk, production risk, reputational risk, personnel safety risk and regulatory risk, the growing OT skill gap is a matter of concern, as OT specialists are hard to find. As part of their digital transformation, organizations should consider a comprehensive cybersecurity plan covering staff training, plant security, network security, software security, workplace safety, system integrity, and incident response and recovery. A 7-step approach to assess OT and IIoT cybersecurity risk is covered in Assessing OT and IIoT cybersecurity risk.\nCenter of Excellence (COE) approach\nMeaningful OT/IT convergence requires focused and organized effort, which a COE can facilitate. A COE is a multi-disciplinary team of passionate OT and IT subject matter experts (SMEs) who act as change agents to accelerate IIoT adoption by standardizing and evangelizing best practices, developing repeatable patterns to scale implementation, driving governance, and providing thought leadership. The COE can start small with 3-5 members, cross-trained in both IT and OT aspects and can scale as needed. For a COE to be successful, it requires executive sponsorship and ability to act autonomously. The COE can focus on making incremental improvements instead of a big-bang approach. A prioritization framework is used to identify pilot use cases starting with low-risk, high value, and low effort use cases with measurable success metrics. After the pilot use cases are deployed and business value demonstrated, this activity continues cyclically to implement the pipeline of prioritized use cases.\nGovernance\nA robust governance strategy across people, process and technology covering both internal teams and vendors can help run business efficiently. From a people perspective, well-documented policies and processes, role clarity with measurable goals, and a transparent decision-making framework are essential. Process-wise, a business case-driven approach to selecting investments, proven program management methodology, financial discipline, and a robust risk framework are key. And, from a technology perspective, a technology architecture blue-print for IIoT adoption, playbooks/runbooks/drills for operational functions such as maintenance, telemetry, incident response and disaster recovery with assigned ownership are crucial.\nMeasuring success\nKey Performance Indicators (KPIs) can serve as critical navigation tools, assisting organizations in understanding how well they are performing in terms of delivering on their strategic goals and provide timely opportunities to correct course. Most often, a single KPI does not provide the full story about performance. For example, if your objective is to improve equipment availability, just tracking uptime hours is not enough. You will also need to measure the number of times the system goes offline. Furthermore, building consensus within the organization on how the KPIs are set and measured, is equally important. Ideally, you would want to baseline the current as-is state, to allow for a data driven comparison with pre-transformation KPIs.\nTraining and education\nInvesting in employees\xe2\x80\x99 fluency and continuous learning with a focus on innovation, results in a greater appreciation of digital transformation. Misconceptions such as IIoT automation is a threat to an OT personnel\xe2\x80\x99s job have to be dispelled. For example, with IIoT enabling predictive maintenance, staffing is still required to perform the actual maintenance. OT personnel will need to be trained on how to interpret and act on data from the connected factory. IT personnel need to trained to understand that routine IT practices won\xe2\x80\x99t necessarily apply to OT. More apprenticeship-style learning and job rotations can be considered as a supplement to classroom instruction to overcome the OT skills gap and aging workforce. The U.S Department of Energy\xe2\x80\x99s National Cyber-Informed Engineering Strategy, provides useful guidance on how to build a culture of cyber security in OT teams.\nOwnership of Industrial Control Systems (ICS)/OT cybersecurity\nWith OT/IT convergence, the lines of distinction between IT and OT continue to fade and the attack surface of interconnected systems continues to widen. With IT\xe2\x80\x99s skill in network security, we recommend that IT be responsible for securing OT as a first line of defense. This needs to be done thoughtfully using a phased approach, by combining the respective intellectual power, know-how, and experience of both teams. IT teams will need to understand the unique requirements for OT networks and system, the Purdue model, and standards such as NIST,  ISA/IEC 62443, NERC CIP, MITRE ATT&CK for ICS. Additionally, we recommend working with partners with deep technical security expertise and proven customer success to help accelerate adoption.\nFinal thoughts\nSuccessful implementation of OT/IT convergence for industrial digital transformation requires strategic management of organizational change as it is not just about technology integration. Although OT and IT teams tend to have different priorities, they can be brought together by driving them towards shared organizational goals and working backwards from these goals to prioritize digital initiatives and building trust.\nAdditional Reading\nIoT Lens \xe2\x80\x93 AWS Well-Architected Framework\nSecuring Internet of Things (IoT) with AWS\nIndustrial Internet of Things\nSmart Manufacturing\nSecurity Best Practices for Manufacturing OT\nHow to implement zero trust IoT solutions with AWS IoT\nTen security golden rules for Industrial IoT solutions\nBuilding an industrial Internet of Things (IIoT) digital transformation strategy\nAbout the authors\nRyan Dsouza is a Principal Solutions Architect for industrial IoT at AWS. Based in New York City, Ryan helps customers design, develop, and operate more secure, scalable, and innovative solutions using the breadth and depth of AWS capabilities to deliver measurable business outcomes. Ryan has more than 25 years of experience in digital platforms, smart manufacturing, energy management, building and industrial automation, OT/IT convergence and IIoT security across a diverse range of industries. Before AWS, Ryan worked for Accenture, SIEMENS, General Electric, IBM, and AECOM, serving customers for their digital transformation initiatives.\nNurani Parasuraman is part of the Customer Solutions team in AWS. He is passionate about helping enterprises succeed and realize significant benefits from cloud adoption, by driving basic migration to large scale cloud transformation across people, process and technology. Prior to joining AWS, he held multiple senior leadership positions and led technology delivery and transformation in a variety of industries including financial services, retail, telecommunications, media and manufacturing. He has an MBA in Finance and BS in Mechanical Engineering.'"
50,Implementing time-critical cloud-to-device IoT message patterns on AWS IoT Core,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/22/FeaturedImageDiagram-1024x539.png,https://aws.amazon.com/blogs/iot/implementing-time-critical-cloud-to-device-iot-message-patterns-on-aws-iot-core/,"b'Introduction\nWidely adopted Internet of Things (IoT) communication standards for device-to-cloud and cloud-to-device are typically asynchronous, enabling event-driven patterns to ensure resilience, cost savings, and failure tolerance. However, customers across industries need to enable synchronous communication patterns to ensure time-critical logic in their edge devices.\nAutomotive manufacturers, for example, want their connected vehicles to be operated remotely and ensure their customers can trigger operations such as lowering side-windows or deactivating a car alarm in a timely and efficient manner. This typically requires that messaging between the vehicle and the cloud happens in real time in order to execute the customer\xe2\x80\x99s command. However, this process is typically challenging to achieve with classic asynchronous IoT communication patterns, which are designed for disconnected scenarios where messages can persist until the device comes back online.\nIn the case of synchronous communications, this persistence is not required, and instead, messages must be executed immediately, otherwise they are discarded.\nThis post will walk you through the implementation of a synchronous communication pattern on AWS using AWS IoT capabilities. Customers will use an HTTP client to call an Amazon API Gateway endpoint. This action forwards the request to an AWS Lambda function, that will invoke logic running into edge applications.\nSolution overview\nWe are proposing a solution where there is an application running on an IoT device which performs some tasks and returns a response after the execution ends. This solution enables an HTTP client to perform a request to the IoT device, waiting for immediate feedback. The application also needs to execute within a specific time window before a set time-out time, otherwise, it will fail, returning an HTTP error to the client.\nThe following steps represent the flow of a generic request that starts from an HTTP client and returns when when the device logic consumes it, or fails if no response is returned after a specific timeout (e.g. the device is not connected or there is no edge logic implemented for that specific request).\nThe HTTP client performs a request to your Amazon API Gateway instance, which exposes your AWS Lambda function externally.\nThe Amazon API Gateway instance forwards the request to your AWS Lambda function.\nThe AWS Lambda function creates an MQTT client instance, which will be used as the channel to exchange the HTTP request received with the AWS IoT Core instance.\nOnce the MQTT client is connected to your AWS IoT Core instance, it will forward the request to the AWS IoT Core topic, which is dedicated to exchanging the request\xe2\x80\x99s payload with the device.\nWhen the AWS IoT Core instance receives a request from the AWS Lambda function, that\xe2\x80\x99s the moment where the synchronous approach is simulated according to the following steps:\nAWS IoT Core forwards the MQTT request to the device.\nThe AWS Lambda function instance waits for a response from the device, or fails to a timeout.\nThe device reads the request, runs the business logic associated with it and creates the response.\nThe device publishes the MQTT payload containing the acknowledgment message and the optional response back to AWS IoT Core, to be forwarded back to the HTTP client.\nThe MQTT client on the AWS Lambda function receives the response from AWS IoT Core, containing the MQTT response.\nThe AWS Lambda function takes information from the MQTT response and generates the HTTP response to be returned to the Amazon API Gateway.\nThe Amazon API Gateway forwards the response to the client.\nThe client receives the HTTP response containing either the response generated by the device or the timeout generated by the AWS Lambda Function.\nThe following image shows the minimal architecture needed to implement this solution:\nImplementing the solution in your AWS Account\nPrerequisites\nTo execute this solution, you must satisfy the following prerequisites.\nKnowledge of IoT Communication scenarios, MQTT protocol and event-driven/asynchronous patterns.\nAn AWS account.\nA Linux-like terminal.\nAWS Command Line Interface (CLI) installed. See AWS CLI Documentation for instructions on how to install and configure AWS CLI.\nAWS SAM CLI. See AWS SAM CLI Documentation for instructions on how to install and configure AWS SAM CLI.\nAn AWS Identity and Access Management (IAM) user with the credentials for creating AWS resources through CLI.\nA Python 3.9 environment installed on your machine.\nA target IoT Device or a device simulator to implement the callback logic.\nAn HTTP client to execute tests. In this walk-through we shall use cURL.\nImplementation specifications\nIn this walk-through we implement an example API for synchronous invocation that allows us to specify the following:\nMethod: Indicates an action to execute on the target device.\nTarget: Indicates the target device where we want to execute our action (eg. the ThingName).\nTimeout: Indicates the timeout that we want to have for the execution of the command and the response.\nTopic structure:\nOutbound topic: sends a request to the IoT device.\nACK Topic: sends the ack from the IoT device to the AWS Lambda function.\nThe levels that compose the topics are the following:\ntarget: the target device (eg. ThingName), inherited from the Target parameter from API call. The target device must subscribe to messages in the root topic space \xe2\x80\x9c{target}/#\xe2\x80\x9d\nmethod: the identifier of the method to execute, inherited from the Target parameter from the API call. This identifier must be recognized by the device, in order to provide a response.\nclient_prefix: an identifier for the api in the cloud (eg. \xe2\x80\x9cinvocation\xe2\x80\x9c), constantly defined within the application stack as Lambda environment variable\nm_id: a random generated value for each new request through a UUID4, which ensures that multiple requests sent to the same device are managed separately by each requester.\nThe setup for implementing this solution involves the following steps:\nStep 1: Deployment of an AWS Lambda function implementing a synchronous client to AWS IoT Core.\nStep 2: Deployment of an HTTP API through Amazon API Gateway and integration with a Lambda function as the back-end.\nStep 3: Get the AWS Lambda function endpoint.\nAs part of this blog post, we propose a deploy-able sample implementation for Steps 1 and 2 to use for testing purposes in a non-production account.\nImplementation design principles\nThe following section summarizes the main design principles of the Lambda back-end of our proposed API:\nAWS IoT Device SDK 2 for Python is used for a simple implementation of connecting, subscribing, and publishing of MQTT messages through Websockets.\nA Websockets based MQTT client is used due to the simpler and more efficient authentication mechanism provided through IAM instead of X.509 certificates. This approach is advantageous as you don\xe2\x80\x99t have to maintain the lifecycle of a client certificate for connecting to AWS IoT Core.\nYou can explore the IAM Role associated with the AWS Lambda function by visiting the template.yml file in the GitHub repository.\nThe application is deployed using AWS Serverless Application Model (SAM), which simplifies the process of defining cloud-native applications based on AWS Lambda and Amazon API Gateway.\nDeploying an AWS IoT Core synchronous client in AWS Lambda\nThe following steps will guide you on creating an AWS Lambda function that is able to communicate with your AWS IoT Core instance through the MQTT protocol with Websockets.\nStep 1 \xe2\x80\x93 Setup environmental variables\n1 \xe2\x80\x93 Open the command line terminal window.\n2 \xe2\x80\x93 Create a working directory in your machine that will be used to run commands. We will take /tmp/aws as an example for the rest of the blog post.\n3 \xe2\x80\x93 Checkout the following repository into your working directory /tmp/aws:\ngit clone https://github.com/aws-samples/time-critical-cloud-to-device-iot-message-patterns-on-aws-iot-core iot_direct_invocations\nThe result should be that you have blog post contents into /tmp/aws/iot_direct_invocations.\n4 \xe2\x80\x93 Define AccountID and Region environmental variables which will be used in the next steps.\nAccountID: run the following command to get the AWS Account ID configured in your awscli:\naws sts get-caller-identity\nYou should receive a response like the following (in case of errors, please refer to the \xe2\x80\x9cConfigure the AWS CLI\xe2\x80\x9d guide):\n{\n    ""UserId"": ""AIDASAMPLEUSERID"",\n    ""Account"": ""123456789012"",\n    ""Arn"": ""arn:aws:iam::123456789012:user/DevAdmin""\n}\nCopy the \xe2\x80\x9cAccount\xe2\x80\x9d field value and export it into the environmental variable:\nexport AccountID=""123456789012""\nRegion: choose the region where you want to work (e.g. eu-west-1) and use the following command to export it:\nexport Region=""eu-west-1""\n5 \xe2\x80\x93 Define FunctionName environmental variable that will specify the name of your AWS Lambda function instance (e.g. iot-lambda-function):\nexport FunctionName=""iot-lambda-function""\nNote: be sure that you don\xe2\x80\x99t already have an AWS Lambda function with this name or you will get an error in the deployment phase due to name collision.\n6 \xe2\x80\x93 Define IoTCoreEndpoint environmental variable that contains the URL of the AWS IoT Core instance that you will use later on.\nRun the following command:\naws iot describe-endpoint --endpoint-type iot:Data-ATS\nYou should get a response like the following:\n{\n    ""endpointAddress"": ""<instance_id>-ats.iot.<your_region>.amazonaws.com""\n}\nCopy the endpointAddress value and export it like this:\nexport IoTCoreEndpoint=""<instance_id>-ats.iot.<your_region>.amazonaws.com""\nStep 2 \xe2\x80\x93 Deploy the AWS Lambda function\nNow that your environment is configured to deploy the AWS Lambda function in your AWS Account, open the terminal and place the prompt into the directory /tmp/aws/iot_direct_invocations/sam/iot-lambda-client/\xcb\x9b\nInside this folder, you will find the SAM artifacts and templates which will be used to deploy the following elements:\nIAM roles and policies.\nAPI Gateway instance.\nAWS Lambda function with code (you will find the Python code in the /tmp/aws/iot_direct_invocations/sam/iot-lambda-client/)\xcb\x9b\n1 \xe2\x80\x93 Build the CloudFormation template with SAM: before deploying all the elements needed by the AWS Lambda function to be exposed, you need to build the resulting CloudFormation template with the following command:\nsam build\nIf you see the statement Build Succeeded, you are ready to go to the next stage.\n2 \xe2\x80\x93 Deploy the CloudFormation stack: once the build process completes successfully, you are ready to deploy the AWS Lambda function environment with the following command:\nsam deploy \\\n    --resolve-s3 \\\n    --stack-name iot-lambda-client \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides \\\n        AccountID=${AccountID} \\\n        Region=${Region} \\\n        LambdaName=${FunctionName} \\\n        IoTCoreEndpoint=${IoTCoreEndpoint} \\\n        ClientIDPrefix=invocation_client\nThe output of the command will tell you if the process ended successfully.\nNote: the command is idempotent, so you can run it as many times as you want and the result will not change as long as the SAM templates/artifacts don\xe2\x80\x99t change. However, in this case, the output will report a message like Error: No changes to deploy. Stack iot-lambda-client is up to date, this does not mean that your deployment failed, it means that there were no changes to deploy.\nStep 3 \xe2\x80\x93 Get the AWS Lambda function endpoint\nAfter deploying your AWS Lambda function, you need to retrieve the URL to use with you HTTP client in order to invoke it. To do that, use the following command:\naws cloudformation describe-stacks --stack-name iot-lambda-client\nThis command retrieves information that describes the AWS CloudFormation stack with name iot-lambda-client, which is the one created by SAM in the previous step. The output represents a json object containing the nested array \xe2\x80\x9c.Stacks[].Outputs\xe2\x80\x9d. Inside this array, you will find some key-value pairs, look for ""OutputKey"": ""InvokeApi"" and get the value of the related ""OutputValue"". You should find something like this:\n""https://<id>.execute-api.<region>.amazonaws.com/Prod/invoke/""\nThis is the URL you will use to invoke the AWS Lambda function from internet. Export it in an environment variable in order to be used later on tests:\nexport APIEndpoint=""https://<id>.execute-api.<region>.amazonaws.com/Prod/invoke/""\nTesting the solution\nTesting the solution requires two different steps:\nCreating an instance of a simulated AWS IoT Thing device listening for a direct request\nPerforming an authenticated request to the AWS Lambda function.\nPreparing the Simulated AWS IoT Thing device\nAn effective way to test the solution is to create a software client which will simulate interactions with our scenario, connecting to the AWS IoT Core instance described above. This client will be represented by an AWS IoT thing and will respond to invocations coming from the AWS Lambda function.\nIn our example, we set up an IoT thing in the AWS IoT Core registry and associate a device certificate and an IoT policy to the IoT thing. The device certificate and the device private key will be provided to the device to communicate with AWS.\nAs a best practice, a real production provisioning flow should allow you to avoid sharing the private key over the public internet, and it is advised that you embed a provisioning flow as part of your IoT device design.\nAWS has a list of options for device provisioning as part of AWS IoT Core documentation and a whitepaper on \xe2\x80\x9cDevice Manufacturing and Provisioning with X.509 Certificates in AWS IoT Core\xe2\x80\x9d that explains in depth each option in respect to real customer scenarios.\n1 \xe2\x80\x93 Go the the device simulator\xe2\x80\x99s working directory /tmp/aws/iot_direct_invocations/sam/test-client/.\n2 \xe2\x80\x93 Open a command line terminal window and run the following command to generate a device certificate and a key pair, the files will be created in the working directory. Copy your certificateArn and certificateId from the output of the command:\naws iot create-keys-and-certificate \\\n    --certificate-pem-outfile ""TestThing.cert.pem"" \\\n    --public-key-outfile ""TestThing.public.key"" \\\n    --private-key-outfile ""TestThing.private.key"" \\\n    --region ${Region} \\\n    --set-as-active\nThe output of the previous command should be something like the following:\n{\n    ""certificateArn"": ""arn:aws:iot:<region>:<account_id>:cert/<certificate_id>"",\n    ""certificateId"": ""<certificate_id>"",\n    ""certificatePem"": ""-----BEGIN CERTIFICATE-----\\n<certificate_data>\\n-----END CERTIFICATE-----\\n"",\n    ""keyPair"": {\n        ""PublicKey"": ""-----BEGIN PUBLIC KEY-----\\n<public_key_data>\\n-----END PUBLIC KEY-----\\n"",\n        ""PrivateKey"": ""-----BEGIN RSA PRIVATE KEY-----\\n<private_key_data>\\n-----END RSA PRIVATE KEY-----\\n""\n    }\n}\nTake note of the certificateArn and export it to an environmental variable in order to use it in the next step:\nexport CertificateArn=""arn:aws:iot:<region>:<account_id>:cert/<certificate_id>""\nNote: according to AWS security policies, the private key will never be transferred to the cloud environment. If you lose it, you\xe2\x80\x99ll need to generate it again.\n3 \xe2\x80\x93 Now it\xe2\x80\x99s time to prepare the SAM script, which will create what you need to prepare the AWS IoT thing representing the simulator device. To do that, you need to open the terminal windows and go to the working directory /tmp/aws/iot_direct_invocations/sam/test-client/ and build the SAM template:\nsam build\n4 \xe2\x80\x93 Once the build process terminates without issues, you can proceed with the deployment of the AWS CloudFormation template generated in the previous step. To do that, deploy the IoT thing creation with SAM using this command:\nsam deploy \\\n     --resolve-s3 \\\n    --stack-name test-iot-thing \\\n    --parameter-overrides \\\n        Region=${Region} \\\n        AccountID=${AccountID} \\\n        ClientIDPrefix=invocation_client \\\n        TestingIoTThingCertificateARN=${CertificateArn}\nYou should see the registered thing, policy and device certificate in your AWS account through the AWS IoT Console.\n5 \xe2\x80\x93 Once the AWS IoT thing device is provisioned into the cloud environment, you just need to run the simulator. To do that, run the following command:\npython index.py \\\n    --endpoint ${IoTCoreEndpoint} \\\n    --cert TestThing.cert.pem \\\n    --key TestThing.private.key \\\n    --client-id Device001\nIf everything has been set up correctly, you should see the client stopping to the message Waiting for command .... This python script is simulating a device waiting for a command to be forwarded to the AWS IoT Core instance.\nPerform an authenticated request to the AWS Lambda function endpoint\nYou need to perform an HTTP request towards the Amazon API Gateway endpoint which is exposing the AWS Lambda function API to test the interaction with the simulated device defined in the previous step.\n1 \xe2\x80\x93 Prepare the Amazon API Gateway endpoint URL:\nThe URL representing the GET request to be performed will be composed like this:\nexport ENDPOINT=""${APIEndpoint}?request=my_request_1&method=reqid-ABCD&target=Device001&timeout=3""\nNote the following parameters:\nrequest: it\xe2\x80\x99s a string representing the value of the request passed to the AWS Lambda function that is forwarded directly to the device\xe2\x80\x99s logic. The AWS Lambda function does not enter into the merits of the parameter value. We suggest to pass a base64 encoding in order to avoid issues with URL compatible parameters in the request.\nmethod: it represents the identifier of the method triggered into the device\xe2\x80\x99s logic.\ntarget: it\xe2\x80\x99s the client id used to map the request to a specific device. It must be the same used on step 5 (\xe2\x80\x93client-id).\ntimeout: it\xe2\x80\x99s the value of the period of time the AWS Lambda function will wait the device to respond before returning a timeout to the caller.\n2 \xe2\x80\x93 Prepare the authenticated request:\nAs a security best practice, you should never expose APIs without any kind of authentication. That\xe2\x80\x99s why in this example, we deployed the API endpoint using the AWS IAM authentication mechanism. This basically means that the exposed invoke API resource is configured to accept execute-api:Invoke requests only from IAM users which have proper policy attached to them.\nWhat you need to do ensuring that the IAM credentials that you are using in this example are associated to an IAM user which has proper policies attached as per this documentation. Then, every request performed to the endpoint generated in step 1 must be properly signed according to the Signature Version 4 signing process.\n3 \xe2\x80\x93 Use the http python client to perform the request:\nFor you convenience, we provided a tool which implements the logic behind the signing process. It\xe2\x80\x99s a Python script called perform_authenticated_request.py which can be found in the repository root folder /tmp/aws/iot_direct_invocations/.\nSo, what you need to do now is placing the terminal in the root folder of the repository (e.g. /tmp/aws/iot_direct_invocations/) and run the following command to perform an authenticated request:\npython perform_authenticated_request.py $ENDPOINT\nThe output of this request depends on the following scenarios:\nThe device simulator is connected:\n{\n    ""result"": ""ok"",\n    ""elapsed"": ""383"",\n    ""response"": ""Your request was \'my_request_1\'. Some random response: \'333.0155808661127\'""\n }\nThe device simulator is not connected:\n{\n    ""result"": ""timeout"",\n    ""elapsed"": ""3795""\n}\nCleaning up your resources\nTo help prevent unwanted charges to your AWS account, you can delete the AWS resources that you used for this walk-through. These AWS resources include the AWS IoT Core things and certificates, AWS Lambda function, and Amazon API Gateway. You can use the AWS CLI, AWS Management Console, or the AWS APIs to perform the cleanup. In this section, we will use the AWS CLI approach. If you want to keep these resources, you can ignore this section.\nCleaning up AWS IoT Core resources\n1 \xe2\x80\x93 Detach the device certificate from the IoT policy:\naws iot detach-policy --target ""arn:aws:iot:<your_region>:<your_account_ID>:cert/<certificate_id>"" --policy-name ""TestPolicy""\n2 \xe2\x80\x93 Delete the IoT policy\naws iot delete-policy --policy-name TestPolicy\n3 \xe2\x80\x93 Detach the device certificate from the test IoT thing\naws iot detach-thing-principal --thing-name TestThing --principal arn:aws:iot:<your_region>:<your_account_ID>:cert/<certificate_id>\n4 \xe2\x80\x93 Delete the device certificate from AWS IoT Core\naws iot delete-certificate --certificate-id <certificate_id>\n5 \xe2\x80\x93 Delete the IoT thing from AWS IoT Core\naws iot delete-thing --thing-name TestThing\nCleaning up API Gateway and Lambda resources via SAM\nDelete the SAM stack associated with the synchronous invocation resources\nsam delete --stack-name iot-lambda-client\n'"
51,How Trend Micro improved their velocity and agility using AWS IoT Core Device Advisor,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/14/Res_AWS-IoT-Core_Device-Advisor_48@5x_Dark.png,https://aws.amazon.com/blogs/iot/how-trend-micro-improved-their-velocity-and-agility-using-aws-iot-core-device-advisor/,"b'Introduction\nDeveloping an IoT device or client can be a significant undertaking. Development efforts, ranging from design, prototyping, testing, quality assurance and more, can take months, if not years. Improving the development velocity and agility is obviously attractive for product cost and time-to-market. However, any acceleration should not compromise on quality, and deliver a device or client that is reliable, performant and secure.\nTrend Micro, a multinational cyber security company that offers a wide range of internet security and antivirus software products and solutions, faced similar challenges when developing their Cloud One security platform. Cloud One is a comprehensive SaaS (S\noftware as a Service) solution that helps customers secure their cloud infrastructure by delivering Trend Micro security solutions on a single platform, and provides a seamless cloud journey. The SaaS solution includes an agent that is deployed on a computer to provide application control, anti-malware, firewall protection and more. This agent connects to AWS IoT Core and continuously collects metrics and events for the purposes of threat analytics and management, preventing and responding to cybersecurity incidents immediately.\nAWS IoT Core Device Advisor is a cloud-based, fully managed tool for validating IoT devices or clients that connect to AWS IoT Core, such as the Cloud One agent. Trend Micro used pre-built test cases in AWS IoT Core Device Advisor to accelerate the development of their Cloud One platform and to automate regression testing through their in-house Cloud One Continuous Integration/Continuous Deployment (CI/CD) pipeline.\n\xe2\x80\x9cBefore we automated this process, a person would have to dedicate an hour to manually run all the test cases, which made it impractical to test every build. Now, the process runs automatically on every build and completes within half an hour without any human intervention. The feedback is fast, and the manual test effort is greatly saved.\xe2\x80\x9d said Shan Rao, Automation Test Engineer at Trend Micro.\nChallenges\nBefore adopting AWS IoT Core for the Cloud One security agent, Trend Micro used a traditional API-based client-and-server architecture. The API-based client-and-server model is a familiar and straightforward way of building an application like Cloud One.\nHowever, as the number of clients grows to hundreds of thousands, or even millions, the solution can be challenging to scale. The costs associated with infrastructure and maintenance can rise quickly, and the architecture design may not easily cope with the number of concurrent connections. Trend Micro faced these issues with their Cloud One product, which required reliable and stable infrastructure to serve the incoming requests from Cloud One agents. Furthermore, Trend Micro aims to rapidly deliver new features and updates to protect their customers against vulnerabilities and unauthorized changes.\nConsequently, they chose AWS IoT Core to build their next-generation Cloud One agents because it allows them to connect billions of IoT clients and route trillions of messages to AWS services, without managing infrastructure. With AWS IoT Core, Trend Micro simplified their Cloud One architecture, reduced operational complexity and focused more on product feature development and differentiation.\nFigure 1: Simplified Cloud One Agent architecture\nUpon selecting AWS IoT Core, Trend Micro then needed tools to improve their development process and verify compatibility between AWS IoT Core and the Cloud One agent. AWS IoT Core Device Advisor is purpose-built for this validation and can be used to validate both physical devices and soft clients. It was therefore a logical choice.\nSolution Overview\nAWS customers can use AWS IoT Device SDKs to build IoT clients. These SDKs are already qualified against AWS IoT Core Device Advisor, reducing the development burden for customers. Alternatively, customers can use a third-party MQTT client of their choice to connect to AWS IoT Core, or even develop their own client.\nTrend Micro elected to develop the Cloud One agent using a custom MQTT client library. To aid the development of the agent, Trend Micro integrated AWS IoT Core Device Advisor as an automation test workflow within the agent\xe2\x80\x99s CI/CD pipeline. This verifies that every build of the agent can securely connect to AWS IoT Core, and can handle retry and back-off scenarios. Moreover, any functional regressions are immediately identified, allowing for fast correction and preventing serious regressions from ever reaching the field.\nTest Cases\nThe CI/CD pipeline implements a test suite that uses a selection of pre-built TLS test cases and MQTT test cases in AWS IoT Core Device Advisor. The test suite includes both happy path and sad path test cases, and can quickly identify common device software issues during the development process.\nThe following test cases are used to validate that the agent can complete TLS handshake with AWS IoT Core and that the agent presents a valid cipher suite in the TLS Client Hello message:\nTLS Connect\nTLS Support AWS IoT Cipher Suites\nThe agent should close the connection if the server certificate doesn\xe2\x80\x99t meet requirements. The following test cases present invalid server certificates to the agent, ensuring that the agent only connects to an endpoint that presents a valid certificate:\nTLS Unsecure Server Cert\nTLS Incorrect Subject Name Server Cert\nThese test cases validate the agent\xe2\x80\x99s MQTT implementation, confirming that the agent can establish a connection with the MQTT broker, and publish a message and subscribe to a topic:\nMQTT Connect\nMQTT Publish\nMQTT Subscribe\nThe following test cases validate that the agent uses the proper jitter and exponential back-off while connecting with the broker:\nMQTT Connect Jitter Retries\nMQTT Connect Exponential Back-off Retries\nMQTT Reconnect Back-off Retries On Server Disconnect\nSome of the test cases run for a long time, but these automated tests provide fast feedback and are more efficient than manual tests.\nWorkflow\nThe CI/CD pipeline automated test is based on the AWS IoT Core Device Advisor workflow and can be summarized as follows:\nFigure 2: Cloud One Agent automated test workflow.\nFor each pipeline execution, the automation test job uses the AWS SDK to create an IoT Thing, create an X.509 certificate, attach the certificate to the Thing, and attach an AWS IoT policy. The test job uses the AWS CLI to create test suites, start the suite running, and poll the suite status.\nWhen tests take longer than expected, the test job stops the test suite. The stopped test suites are seen as failed tests and are kept in the AWS management console, along with the failed tests, so that developers can access the Amazon CloudWatch logs for deeper investigation and troubleshooting.\nIn this particular CI/CD pipeline, design choices were made to automatically delete test suite runs that were successful. Therefore, only the stopped and failed test suite runs are kept for developers to investigate, and hence no successful test runs are seen in the AWS management console:\nFigure 3: Failed and stopped tests in the AWS Management Console.\n'"
52,How to develop distributed IoT applications using the AWS IoT Greengrass PubSub SDK,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-the-aws-greengrass-pubsub-sdk-to-develop-distributed-iot-pubsub-applications/,"b'Introduction\nIoT applications are synonymous with the Publish / Subscribe (PubSub) model where distributed services communicate via event triggered messages. The PubSub model offers flexibility in design and is well suited to event-driven distributed IoT systems. However, this flexibility puts many design decisions in the hands of the developer that creates dependencies across systems, services and teams. In this post, you will learn how to accelerate and simplify the development of distributed IoT PubSub applications deployed and managed by AWS IoT Greengrass using the AWS IoT Greengrass PubSub SDK for Python.\nSolution Overview\nThe AWS IoT Greengrass PubSub SDK for Python (referred to here as the SDK) provides a highly opinionated IoT PubSub application architecture delivered as a Python library for AWS Greengrass V2 Components. The SDK abstracts the AWS IoT Greengrass PubSub functionality and defines a data-driven message format to automatically route AWS IoT Greengrass IPC / MQTT messages to user defined application call-backs. In doing so, the SDK delivers a No/Low-Code messaging service that decouples the PubSub topic schema from the desired interface functionality.\nThe following diagram provides a high level overview of the AWS IoT Greengrass PubSub SDK for Python architecture:\nIn a typical IoT PubSub service, the message payload format and the topic schema are tightly coupled to the APIs functionality. Using this approach creates complex and difficult to manage upstream dependencies. A final challenge is the repeated development of boilerplate code to manage PubSub message processing and routing.\nThe following diagram describes a typical distributed IoT application service interface with tight integrations and dependencies between message formats and topics and the individual service functions.\nThe AWS IoT Greengrass PubSub SDK for Python solves these key dependencies and challenges by providing:\nDefined Message Format: The SDK provides a defined but extendible message format with control fields that support data-driven message routing to decouple PubSub topics from interface functionality.\nSimplified Topic Schema: The SDK defines a simple but extendible topic schema consisting of just a single ingress and egress topic made possible by data-driven message routing.\nMessaging Service Boilerplate Code: The SDK abstracts the AWS IoT Greengrass IPC and MQTT PubSub functionality to process and route PubSub messages to user-defined application call-backs.\nThe below diagram displays a similar service interface when using the AWS IoT Greengrass PubSub SDK with message formats and topic schema no longer coupled to service functionality. This is made possible by data driven message routing and removes the upstream dependency and change management on these public facing service attributes.\nPubSub Message Process and Routing\nMessage Format\nThe SDK message routing is controlled by the route field in the prescribed message format shown below:\n{\n  ""sdk_version"": ""0.1.0"",\n  ""message_id"": ""20220403170948930231"",\n  ""status"": 200,\n  ""route"": ""MyPubSubMessageHandler.pubsub_message_callback_function"",\n  ""message"": {\n    ""my-message-param01"": ""param01"",\n    ""my-message-param02"": ""param02""\n  }\n}\nJSON\nThe route field describes a route target that is a (Plain Old Python) call-back function in your application logic using Class.Function namespace convention.\nsdk_version: Provides message version control across distributed systems. By default, the SDK will reject messages with a different major version.\nmessage_id: This is typically a timestamp but can be any user defined string. Its is used to track messages across asynchronous Request / Response patterns.\nstatus:  Status of the message request, response or update. When used with message_id, this allows asynchronous Request / Response messages to report a given status without the need for success / failure topics and message formats.\nroute: As described, is used by the SDK to route PubSub messages to user defined application call-backs in Class.Function namespace convention.\nmessage: User defined payload field for SDK formatted messages. The SDK will forward this unchanged to the user defined callbacks along with the other described fields.\nThe below diagram describes in more detail how the SDK defined message format is used to route messages from the wire to the user defined application call-backs:\nAn AWS IoT Greengrass component deployed with the SDK receives a well-formatted message with a valid route field of SystemMessageHandler.health_check.\nThe SDK processes the message, checks for validity, SDK version and determines if the route matches a user defined application call-back and routes the message accordingly.\nThe PubSub message is forwarded to the health_check function with all SDK message fields parameterized for processing by user application logic.\nHere we assume the health_check function creates a well formatted response with the system health in the payload, a new valid route and reflects the message_id for upstream systems.\nSDK receives the message publish request from the health_check function and forwards the message to the appropriate PubSub topic.\nThis data driven message routing allows you to update service interface functionality with only minor changes needed. For example, to add the interface to support the described system health check request; just add the appropriate callback function in your application message handler and then advertise the given route to upstream services. There is no change to PubSub topic schema, very minimal code changes and is non-breaking and backwards compatible with existing interface functionality.\nTopic Schema\nDue to the message-based routing fields, the SDK base topic schema can consist of just two topics, the Ingress and Egress topics:\nIngress Topic: BASE_TOPIC/AWS_IOT_THING_NAME/ingress\nEgress Topic: BASE_TOPIC/AWS_IOT_THING_NAME/egress\nWhere BASE_TOPIC is a user defined parameterized field provided when initializing each SDK based AWS Greengrass Component. It is typically set to the component name.\nThis simple topic schema is extensible via parameter injection from the component recipe (JSON) file thus allowing topic schema changes and custom subscriptions without the need for code changes. In this way, the SDK manages the interface contract between services so you as the developer can focus exclusively on delivering quality application logic.\nDeploying the AWS IoT Greengrass PubSub SDK\nThe easiest way to get started and deploy the AWS IoT Greengrass PubSub SDK is to replicate the sample component provided in the SDK GitHub repository and deploy via the AWS IoT Greengrass Development Kit (GDK). There are two resources that describe this process in detail:\nSDK Sample Directory: The SDK provides a sample AWS IoT Greengrass component with the SDK installed. Follow the guide provided in the Samples directory to deploy a single component and to send a simple MQTT PubSub Request / Response message.\nBuild a Distributed IoT Application with the AWS IoT Greengrass PubSub SDK workshop: This workshop builds a Smart Factory distributed IoT PubSub Application with integrations to Amazon SQS using the SDK.\nFurther Reading\nThe AWS IoT Greengrass PubSub SDK comes with a detailed developer\xe2\x80\x99s guide and API docs provided in the below links:\nDeveloper Guide\nAPI Docs\nPyPi AWS Greengrass PubSub SDK Library\nFor further reading on AWS IoT Greengrass and AWS IoT more broadly see the following links:\nAWS Greengrass V2 Developer Guide\nAWS IoT Core Documentation\nAWS Dev Blog\n'"
53,Build a digital twin of your IoT device and monitor real-time sensor data using AWS IoT TwinMaker (Part 2 of 2),b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/12/2_26.png,https://aws.amazon.com/blogs/iot/build-a-digital-twin-of-your-iot-device-and-monitor-real-time-sensor-data-using-aws-iot-twinmaker-part-2-of-2/,"b'Introduction\nThis post is the second of the series on how to use AWS IoT TwinMaker to create a digital twin of a Raspberry Pi device connected to a sensor that collects temperature and humidity data, and integrate it with an Amazon Managed Grafana dashboard. This allows users to visualize the 3D environment where the digital twin lives together with collected data that influences the device status and 3D model representation in real time.\nIn Part 1, we introduced the idea together with the general architecture shown below. If you followed Part 1 already, you have completed the configuration of the Amazon Timestream database that will host your data, the setup of the IoT Thing, and the wiring of the sensor that collects and transmits temperature and humidity to your Raspberry Pi device.\n\n\nFigure 1: The high-level architecture of the solution\nIn this second part, you will continue with the setup of the Amazon Managed Grafana dashboard that will be used to visualize data. You will create the AWS Lambda function to read data from the Amazon Timestream database and most importantly, you will setup AWS IoT TwinMaker and integrate it with the dashboard in Amazon Managed Grafana to display your 3D Model together with real time data you will collect.\n1. Setup of Amazon Managed Grafana Dashboard workspace\nFrom the console, search and select Amazon Managed Grafana from the list of AWS services. Choose Create Workspace. Use TempHumidTwinmaker as name for your Grafana workspace and optionally provide a description. Choose Next.\nFor Step 2 Configure Settings, from the Authentication access section, select AWS IAM Identity Center (successor to AWS SSO). For the Permission Type choose Service managed. Note that you may need to create a user if this is the first time you have configured SSO.\nChoose Next and leave the default (Current account, without selecting any data source) in the next page. Choose Next then Create Workspace.\nNote: AWS IoT TwinMaker is not listed as data source. However, the plugin is already installed on all Amazon Managed Grafana workspaces. You will add it later on.\nWait a few minutes for the workspace to be created. When the Amazon Managed Grafana workspace is ready, it will have created an IAM service role. You will be able to see it from the Summary tab once you have selected your workspace. Take note of this IAM service role as you will need it later. It should be something like arn:aws:iam::[YOUR-AWS-ACCOUNT-ID]:role/service-role/AmazonGrafanaServiceRole-[1234abcd]\n\n\nFigure 2: The Amazon Managed Grafana workspace is ready. IAM role is displayed in the top right corner\nNext, create the user that will access the dashboard.\nIf you have already performed these actions in your AWS account, you can skip this step. Otherwise, select AWS IAM Identity Center (successor to AWS SSO) from the console search bar, then choose Users \xe2\x86\x92 Add user. Enter your username, choose how you would like to get the password, enter your email address along with your first and last name.\nChoose Next, skip the Groups section by choosing Next (as you don\xe2\x80\x99t want to assign this user to one or more groups) and confirm by choosing Add user. You will receive an invitation email at the address specified and you will need to accept the invitation in order to access the AWS SSO portal. When the invitation is accepted, you will be asked to change your password depending on the setting you chose when creating the user.\nBack in the Amazon Managed Grafana workspace, choose the Authentication section and then Configure users and user groups in the AWS IAM Identity Center (successor to AWS SSO) section. Select the user you just created and choose Assign users and groups.\n\n\nFigure 3: Assign a user to the Amazon Managed Grafana workspace\nYou now have a user to access the dashboard you\xe2\x80\x99re going to create at the end of this post. You need to make them an admin so they will be able to change settings in Amazon Managed Grafana and use the AWS IoT TwinMaker plugin. To do so, select the user and choose the Make Admin button.\n\n\nFigure 4: Making your user an admin\n2. Creation of Lambda function to read data from Amazon Timestream\nNext you will need to create a Lambda function to retrieve data from your Amazon Timestream database. This Lambda function will be used within AWS IoT TwinMaker when you create an AWS IoT TwinMaker component.\nFirst create the IAM role required for the Lambda function to access Amazon Timestream and Amazon CloudWatch logs. From the console open the IAM service, then move to Roles. Choose Create Role. Choose AWS Service as Trusted Entity Type and select Lambda from the Use Case section. Choose Next and add the AWSLambdaBasicExecutionRole and AmazonTimestreamReadOnlyAccess permissions policies. Choose Next, give the role the name ReadTimestreamFromLambda then review the details and click Create Role.\nNote: For this blog, the AmazonTimestreamReadOnlyAccess policy was used, which allow read operations to Timestream. As a best practice, you would restrict read access only to the TimeStream database (and even table) you have created.\nNext, create the Lambda function: from the Lambda homepage choose Create function then select the Author from scratch option. Name the function timestreamReader and select Python 3.7 as Runtime. In the Permissions tab, choose \xe2\x80\x9cUse an existing role\xe2\x80\x9d and select the role ReadTimestreamFromLambda created before. Choose Create function.\n\n\nFigure 5: Creating the Lambda function to read data from Amazon Timestream\nWhen the function is created, move to the Configuration section and in the General configuration change the Memory to 256 MB and timeout to 15 min. Remember to Save.\nStill in the Configuration section, choose Environment variables and add the following two environment variables:\nKey: TIMESTREAM_DATABASE_NAME, value TempHumidityDatabase\nKey: TIMESTREAM_TABLE_NAME, value TempHumidity\nNow move to the code section. Copy and paste the following python code.\nimport logging\nimport json\nimport os\nimport boto3\n\nfrom datetime import datetime\n\nLOGGER = logging.getLogger()\nLOGGER.setLevel(logging.INFO)\n\n# Get db and table name from Env variables\nDATABASE_NAME = os.environ[\'TIMESTREAM_DATABASE_NAME\']\nTABLE_NAME = os.environ[\'TIMESTREAM_TABLE_NAME\']\n\n# Python boto client for AWS Timestream\nQUERY_CLIENT = boto3.client(\'timestream-query\')\n\n\n# Utility function: parses a timestream row into a python dict for more convenient field access\ndef parse_row(column_schema, timestream_row):\n    """"""\n    Example:\n    column=[\n        {\'Name\': \'TelemetryAssetId\', \'Type\': {\'ScalarType\': \'VARCHAR\'}},\n        {\'Name\': \'measure_name\', \'Type\': {\'ScalarType\': \'VARCHAR\'}},\n        {\'Name\': \'time\', \'Type\': {\'ScalarType\': \'TIMESTAMP\'}},\n        {\'Name\': \'measure_value::double\', \'Type\': {\'ScalarType\': \'DOUBLE\'}},\n        {\'Name\': \'measure_value::varchar\', \'Type\': {\'ScalarType\': \'VARCHAR\'}}\n    ]\n    row={\'Data\': [\n        {\'ScalarValue\': \'Mixer_15_7e3c0bdf-3b1c-46b9-886b-14f9d0b9df4d\'},\n        {\'ScalarValue\': \'alarm_status\'},\n        {\'ScalarValue\': \'2021-10-15 20:45:43.287000000\'},\n        {\'NullValue\': True},\n        {\'ScalarValue\': \'ACTIVE\'}\n    ]}\n\n    ->\n\n    {\n        \'TelemetryAssetId\': \'Mixer_15_7e3c0bdf-3b1c-46b9-886b-14f9d0b9df4d\',\n        \'measure_name\': \'alarm_status\',\n        \'time\': \'2021-10-15 20:45:43.287000000\',\n        \'measure_value::double\': None,\n        \'measure_value::varchar\': \'ACTIVE\'\n    }\n    """"""\n    data = timestream_row[\'Data\']\n    result = {}\n    for i in range(len(data)):\n        info = column_schema[i]\n        datum = data[i]\n        key, val = parse_datum(info, datum)\n        result[key] = val\n    return result\n\n# Utility function: parses timestream datum entries into (key,value) tuples. Only ScalarTypes currently supported.\ndef parse_datum(info, datum):\n    """"""\n    Example:\n    info={\'Name\': \'time\', \'Type\': {\'ScalarType\': \'TIMESTAMP\'}}\n    datum={\'ScalarValue\': \'2021-10-15 20:45:25.793000000\'}\n\n    ->\n\n    (\'time\', \'2021-10-15 20:45:25.793000000\')\n    """"""\n    if datum.get(\'NullValue\', False):\n        return info[\'Name\'], None\n    column_type = info[\'Type\']\n    if \'ScalarType\' in column_type:\n        return info[\'Name\'], datum[\'ScalarValue\']\n    else:\n        raise Exception(f""Unsupported columnType[{column_type}]"")\n\n# This function extracts the timestamp from a Timestream row and returns in ISO8601 basic format\ndef get_iso8601_timestamp(str):\n    #  e.g. \'2022-04-06 00:17:45.419000000\' -> \'2022-04-06T00:17:45.419000000Z\'\n    return str.replace(\' \', \'T\') + \'Z\'\n\n# Main logic\ndef lambda_handler(event, context):\n    selected_property = event[\'selectedProperties\'][0]\n\n    LOGGER.info(""Selected property is %s"", selected_property)\n\n    # 1. EXECUTE THE QUERY TO RETURN VALUES FROM DATABASE\n    query_string = f""SELECT measure_name, time, measure_value::bigint"" \\\n        f"" FROM {DATABASE_NAME}.{TABLE_NAME} "" \\\n        f"" WHERE time > from_iso8601_timestamp(\'{event[\'startTime\']}\')"" \\\n        f"" AND time <= from_iso8601_timestamp(\'{event[\'endTime\']}\')"" \\\n        f"" AND measure_name = \'{selected_property}\'"" \\\n        f"" ORDER BY time ASC""\n            \n    try:\n        query_page = QUERY_CLIENT.query(\n            QueryString = query_string\n        )\n    except Exception as err:\n        LOGGER.error(""Exception while running query: %s"", err)\n        raise err\n\n    # Query result structure: https://docs.aws.amazon.com/timestream/latest/developerguide/API_query_Query.html\n\n    next_token = None\n    if query_page.get(\'NextToken\') is not None:\n       next_token = query_page[\'NextToken\']\n    schema = query_page[\'ColumnInfo\']\n\n    # 2. PARSE TIMESTREAM ROWS\n    result_rows = []\n    for row in query_page[\'Rows\']:\n        row_parsed = parse_row(schema,row)\n        #LOGGER.info(\'row parsed: %s\', row_parsed)\n        result_rows.append(row_parsed)\n\n    # 3. CONVERT THE QUERY RESULTS TO THE FORMAT TWINMAKER EXPECTS\n\n    # There must be one entityPropertyReference for Humidity OR one for Temperature\n    entity_property_reference_temp = {}\n    entity_property_reference_temp[\'componentName\'] = \'timestream-reader\'\n    entity_property_reference_temp[\'propertyName\'] = \'temperature\xe2\x80\x99\n    entity_property_reference_temp[\'entityId\'] = \'[ENTITY_ID]\'\n\n\n    entity_property_reference_hum = {}\n    entity_property_reference_hum[\'componentName\'] = \'timestream-reader\'\n    entity_property_reference_hum[\'propertyName\'] = \'humidity\xe2\x80\x99\n    entity_property_reference_hum[\'entityId\'] = \'[ENTITY_ID]\'\n\n\n    values_temp = []\n    values_hum = []\n\n    for result_row in result_rows:\n        ts = result_row[\'time\']\n        measure_name = result_row[\'measure_name\']\n        measure_value = result_row[\'measure_value::bigint\']\n\n        time = get_iso8601_timestamp(ts)\n        value = { \'doubleValue\' : str(measure_value) }\n\n        if measure_name == \'temperature\':\n            values_temp.append({\n                \'time\': time,\n                \'value\':  value\n            })\n        elif measure_name == \'humidity\':\n             values_hum.append({\n                \'time\': time,\n                \'value\':  value\n            })\n\n    # The final structure ""propertyValues""\n    property_values = []\n\n    if(measure_name == \'temperature\'):\n        property_values.append({\n            \'entityPropertyReference\': entity_property_reference_temp,\n            \'values\': values_temp\n        })\n    elif(measure_name == \'humidity\'):\n        property_values.append({\n            \'entityPropertyReference\': entity_property_reference_hum,\n            \'values\': values_hum\n        })\n    LOGGER.info(""property_values: %s"", property_values)\n\n    # marshall propertyValues and nextToken into final response\n    return_obj = {\n       \'propertyValues\': property_values,\n       \'nextToken\': next_token\n       }\n\n    return return_obj\nNote: The code contains a reference to \xe2\x80\x98[ENTITY_ID]\xe2\x80\x99 which is the Id of the TwinMaker entity representing your sensor. You are going to create this in the next section, for now leave the placeholder in the code.\nThis code is the implementation of an AWS IoT TwinMaker connector against Timestream. Remember to Deploy your Lambda function.\n3. Configuration of AWS IoT TwinMaker\nIn the previous paragraph you created and configured an Amazon Managed Grafana workspace and a Lambda function to read data from the Amazon Timestream database. You can now move to the configuration of the digital twin.\nConfigure the IAM policy and roles that will be used by AWS IoT TwinMaker\nFrom the console select the IAM service, then move to Roles. Choose Create Role. Choose Custom trust policy and paste the policy below. AWS IoT TwinMaker requires that you use a service role to allow it to access resources in other services on your behalf. Choose Next.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""Service"": ""iottwinmaker.amazonaws.com""\n      },\n      ""Action"": ""sts:AssumeRole""\n    }\n  ]\n}\nIn the next step, choose Create Policy, a new tab opens up. Select JSON tab and paste the following code:\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n    \n    ""Action"": [\n        ""iottwinmaker:*"", \n        ""s3:*"", \n        ""iotsitewise:*"", \n        ""kinesisvideo:*""\n    ],\n    ""Resource"": [ ""*"" ],\n    ""Effect"": ""Allow""\n},\n{\n    ""Action"": [   \n        ""lambda:invokeFunction""\n    ],\n    ""Resource"": [""*""],\n    ""Effect"": ""Allow""\n},\n{\n    ""Condition"": {\n    ""StringEquals"": {\n        ""iam:PassedToService"": ""lambda.amazonaws.com""\n        }\n    },\n    ""Action"": [""iam:PassRole""],\n    ""Resource"": [""*""],\n    ""Effect"": ""Allow""\n}]}\nYou are giving AWS IoT TwinMaker the ability to work with Amazon Simple Storage Service (Amazon S3), AWS IoT SiteWise, and Amazon Kinesis services and also the ability to invoke the Lambda function to read data from the database. You can modify this policy to be more restrictive in a production environment.\nChoose Next (Tags), then Next (Review). Give this policy the name TwinMakerWorkspacePolicy and choose Create Policy. When done, go back to the page of the role you were creating and look for your new policy in the list. Choose Refresh if you don\xe2\x80\x99t see it immediately. Choose Next, and give the role the name TwinMakerWorkspaceRole then review the details and click Create Role.\nCreate the AWS IoT TwinMaker workspace\nFrom the console, search and select AWS IoT TwinMaker from the list of AWS services. Choose Create workspace. When creating the workspace, you first need to provide some basic information: type \xe2\x80\x9cTempHumidWorkspace\xe2\x80\x9d as Workspace Name and insert an optional Description. From the Amazon S3 bucket dropdown, select Create a new S3 bucket. From the Execution Role dropdown, select the TwinMakerWorkspaceRole role you created in the previous step. Choose Next.\n\n\nFigure 6: Creating the AWS IoT TwinMaker workspace\nNow you will refer to the Grafana dashboard that you created before. From the Dashboard management page, select Amazon Managed Grafana. From the Grafana authentication provider dropdown, select the Grafana service role that has been created before \xe2\x80\x94 the one with name like AmazonGrafanaServiceRole-[1234abc]. Click Next.\nFrom the Dashboard role page, leave No video permissions selected. You will create an IAM policy and role to be used by the dashboard to access the AWS IoT TwinMaker workspace\xe2\x80\x99s Amazon S3 bucket and resources. Copy the policy code provided in the page, then click Create Policy in IAM.\n\n\nFigure 7: Creating the Amazon Managed Grafana dashboard role and policy\nIn the new page, select JSON tab and paste the code for the policy you just copied. Choose Next (Tags), then Next (Review). Give this policy the name TempHumidWorkspaceDashboardPolicy and choose Create Policy.\nGo back to the AWS IoT TwinMaker workspace creation page and choose Create dashboard role in IAM. In the new page, select Custom trust policy and paste the following trust policy JSON:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Principal"": { \n                ""AWS"": ""*""\n            },\n            ""Action"": ""sts:AssumeRole""\n        }\n    ]\n}\nChoose Next and then select the IAM policy you just created (named TempHumidWorkspaceDashboardPolicy). Choose the refresh button if you don\xe2\x80\x99t see it immediately. Choose Next, then give this role the name TwinMakerDashboardRole and choose Create Role. You will receive an alert that the trust policy is overly permissive, but you will change that later. For now, choose Continue.\nWhen done, go back to the AWS IoT TwinMaker workspace creation page and select the dashboard role you just created from the list. Choose the refresh button if you don\xe2\x80\x99t see it immediately.\nNext, copy the code provided in the Update dashboard role policy tab. You are going to apply this policy in the TwinMakerDashboardRole you have just created. Choose Update trust policy in IAM and paste the code replacing what is present already to apply the trust policy in the role. With this, you are changing the overly permissive permission by applying it only to a specific AWS Principal, the service role used by Amazon Managed Grafana. Choose Update Policy.\n\nFigure 8: Creating the Amazon Managed Grafana dashboard role and policy (continued)\nWhen done, go back to the AWS IoT TwinMaker workspace creation page and choose Next, then Create Workspace.\n\n\nFigure 9: Review of the Amazon Managed Grafana workspace creation\nYou now have the AWS IoT TwinMaker workspace ready with all the permissions required to use it from the Grafana dashboard.\nCreate AWS IoT TwinMaker Component & Entity\nWith your AWS IoT TwinMaker workspace selected, move to Component types section to create a component. AWS IoT TwinMaker components provide context for properties and data for their associated entities. You will now create a component that will access your device\xe2\x80\x99s temperature and humidity data. The component will be the link between the AWS IoT TwinMaker workspace and the Lambda function used to read values from the Timestream database.\nChoose Create component type and paste the following code in the Request section.\n{\n  ""workspaceId"": ""[YOUR_TWINMAKER_WORKSPACE]"",\n  ""isSingleton"": false,\n  ""componentTypeId"": ""com.blog.DHT11sensor"",\n  ""propertyDefinitions"": {\n    ""humidity"": {\n      ""dataType"": {\n        ""type"": ""DOUBLE""\n      },\n      ""isTimeSeries"": true,\n      ""isRequiredInEntity"": false,\n      ""isExternalId"": false,\n      ""isStoredExternally"": true,\n      ""isImported"": false,\n      ""isFinal"": false,\n      ""isInherited"": false\n    },\n    ""temperature"": {\n      ""dataType"": {\n        ""type"": ""DOUBLE""\n      },\n      ""isTimeSeries"": true,\n      ""isRequiredInEntity"": false,\n      ""isExternalId"": false,\n      ""isStoredExternally"": true,\n      ""isImported"": false,\n      ""isFinal"": false,\n      ""isInherited"": false\n    }\n  },\n  ""functions"": {\n    ""dataReader"": {\n      ""implementedBy"": {\n        ""lambda"": {\n          ""arn"": ""[YOUR_LAMBDA_ARN]""\n        },\n        ""isNative"": false\n      },\n      ""isInherited"": false\n    }\n  },\n  ""creationDateTime"": ""2022-05-19T14:58:42.140Z"",\n  ""updateDateTime"": ""2022-05-19T14:58:42.140Z"",\n  ""arn"": ""arn:aws:iottwinmaker:[YOUR_REGION]:[YOUR_AWS_ACCOUNT]:workspace/[YOUR_TWINMAKER_WORKSPACE]/component-type/com.blog.DHT11sensor"",\n  ""isAbstract"": false,\n  ""isSchemaInitialized"": false,\n  ""status"": {\n    ""state"": ""ACTIVE"",\n    ""error"": {}\n    }\n  }\nIMPORTANT: Make sure you replace the value between brackets [YOUR_TWINMAKER_WORKSPACE], [YOUR_LAMBDA_ARN], [YOUR_REGION] and [YOUR_AWS_ACCOUNT].\nWhen ready, choose Create component type.\nNow it\xe2\x80\x99s time to create an Entity for your sensor. You could potentially create a structure or hierarchy of entities representing your environment, but in this case for simplicity, only a single entity representing the device/sensor will be created. To do so, move to the Entities section and choose Create entity. Give the entity a name (eg TempHumiditySensor) and choose Create entity.\nIMPORTANT: This entity is the one you need to use in your Lambda function. Copy the Entity id and replace the [ENTITY_ID] you have in your Lambda function created before.\nSelect now the Entity from the list of Entities and choose Add component on the right.\n\n\nFigure 10: Creating the AWS IoT TwinMaker entity\nSelect the type com.blog.DHT11sensor and give the component a name. You will see the properties of the components in the table (like temperature and humidity). When done, choose Add component.\n\n\nFigure 11: Adding the AWS IoT TwinMaker component to the Entity\nCreate AWS IoT TwinMaker Resource & Scene\nNext, import the 3D model to represent your device or sensor in the virtual environment. AWS IoT TwinMaker supports a variety of files like BIN, GLB, GLTF, PNG, PDF, JPG, JPEG, and MP4. In this case, a Raspberry Pi4 model was used. You should be able to find free models in websites like CGTrader, Sketchfab or TurboSquid.\nWith your workspace selected, go to Resource library and choose Add resources and upload your file.\n\n\nFigure 12: Uploading the 3D model\nFinally, you will setup your Scene. With your workspace selected, go to Scenes and choose Create scene. Give it an ID (name) and choose Create scene. Once created, you will be presented with a view containing 3 main sections (see screenshot below). On the left, a section containing 3 tabs:\nHierarchy: your objects in the scene\nRules: how to change items in the scene depending on the data received (we\xe2\x80\x99ll use it in this exercise)\nSettings\nIn the center part, there is a section containing the 3D world, with the possibility to move around, pan, zoom, tilt the view etc. On the right, you have a section with the Inspector, to see details of what is selected in the scene.\n\n\nFigure 13: The UI of the AWS IoT TwinMaker scene\nYou will start by creating the Rules for the item in the scene. Choose the Rules section on the left side panel and check the rules that are already present. Create two new rules, one for humidity data and another for temperature data. Define temperatureIconRule as RuleID and choose Add New Rule. Select the rule and click Add new statement to define some expressions to have the target icon change from Info to Warning to Error as shown below.\nIMPORTANT: Make sure that the Expression you write uses the exact word that you used to name the property coming from the sensor and stored in the database (i.e. \xe2\x80\x9ctemperature\xe2\x80\x9d and \xe2\x80\x9chumidity\xe2\x80\x9d).\n\n\nFigure 14: Rules that will make your tag change color or icon depending on the data received\nWhen you are done with temperature rules, repeat the same process adding a new rule for humidity.\nNext, add the 3D model. In the center part of the screen, click on the + icon and select Add 3d model, selecting from the resource library the 3d object that you uploaded before.\n\n\nFigure 15: Adding your 3D model to the scene\nOnce loaded, you can scale the model with the Transform section in the right panel. Most likely once you add it in the scene, the object will be dark. To fix that, you can adjust the lighting by clicking on Settings and choosing an Environmental Preset. Another way to add a light would be clicking on the + icon and selecting Add light. You can then select it and move it around with your mouse to light up your scene and the 3d model imported.\n\n\nFigure 16: Make sure your model has proper lighting\nFinally, you will add a tag to handle the humidity and temperature data and make sure that what is received affects what is shown in the scene. Click on the + icon and choose Add tag. Using the Inspector section, define its name as Temperature and choose a Default Icon. Select your Entity as EntityId and your component as ComponentName. Select temperature as PropertyName and temperatureIconRule as RuleId. Repeat the same action creating a new tag for Humidity with humidity as PropertyName and humidityIconRule as RuleId.\nNote: Move the two tags close to the 3D model but distant enough to make them visible in the scene.\n\n\nFigure 17: Positioning tags in the scene\n4. Create an Amazon Managed Grafana dashboard with AWS IoT TwinMaker plugin\nYou are finally ready to create a dashboard in Amazon Managed Grafana to visualize the digital twin and your data. From the console, select Amazon Managed Grafana and then your Amazon Managed Grafana workspace. Access your Amazon Managed Grafana workspace from the link provided in the page at Amazon Managed Grafana workspace URL. You\xe2\x80\x99ll be asked to access with the credentials you have setup when configuring the AWS IAM Identity Center (successor to AWS SSO). Since your user was set in admin, you should be able to access the Amazon Managed Grafana settings page.\nFirst, you need to add the AWS IoT TwinMaker data source. To do so, go to Configuration and choose Add data source, then search for TwinMaker and select AWS IoT TwinMaker.\n\n\nFigure 18: Configure AWS IoT TwinMaker as datasource for your dashboard\nThen, make sure that all the Connection Details are correct in the Settings of the data source. This includes the authentication provider and the ARN of the role that AWS IoT TwinMaker assumes to access the dashboard and the AWS region (TwinMakerDashboardRole). Here also is configured the AWS IoT TwinMaker workspace.\n\n\nFigure 19: Connection details\nChoose Save & Test to verify that the connection between Grafana and the AWS IoT TwinMaker workspace is setup correctly.\nThen, move to the creation of the dashboard. From the left sidebar, click Create \xe2\x86\x92 Dashboard.  We\xe2\x80\x99ll start by adding an empty panel first. Choose Add a new panel.\nOn the right, select the type of Visualization to use. In the search bar type TwinMaker and select AWS IoT TwinMaker Scene Viewer. Using the controls in the right part of the screen, give this panel a name and select the AWS IoT TwinMaker workspace and Scene. Your 3D model should appear in the preview.\n\n\nFigure 20: Adding AWS IoT TwinMaker Scene Viewer to the dashboard\nNow you make sure that the connection between what is shown in the dashboard and your data is defined. To do so, create two queries, one for the temperature data and the other for the humidity. These queries will use the AWS IoT TwinMaker component you created, which in turn, uses the Lambda function to read from the Timestream database.\nIn the query section, make sure that AWS IoT TwinMaker is selected as Data source and define a new query of type Get Property Value History by Entity. Select your Entity (TempHumiditySensor) and Component (DHTComponent), then choose the temperature property. Repeat the same adding a new query of same Type and with same Entity and Component but this time selecting the humidity property. When done, save your panel and click Apply then Save.\n\n\nFigure 21: The query needed to read data with the component\nAside from the AWS IoT TwinMaker panel, you can also create other panels to represent your data in various visualization formats, for example a Gauge or Time series, to show your temperature and humidity data. You will need to configure the same query mechanism to make sure you are able to retrieve data. The little red corner on the upper-left of each panel will inform you in case of issues with the component reading data. In this case, it just alerts us that no data is coming \xe2\x80\x93 that\xe2\x80\x99s because you haven\xe2\x80\x99t started the python script in your Raspberry Pi to send data to cloud.\n\n\nFigure 22: Adding panels to the dashboard\n5. The final result\nIf you now start the Python script again in your Raspberry Pi device, you should be able to see temperature and humidity data populating your dashboard\xe2\x80\x99s panels. Since you have defined rules in your AWS IoT TwinMaker workspace, the tags associated with the Entity represented in the dashboard (the two blue dots) will change icons (info, warning, error), or color if you define a color-based rule, whenever the temperature or humidity data received is above/below the threshold defined in your rules.\n\n\nFigure 23: The final result. Temperature tag is showing a warning icon as the threshold defined in the rule was 23\xc2\xb0\nCleaning up\nIf you followed along with this solution, complete the following steps to avoid incurring unwanted charges to your AWS account.\nAWS IoT Core\nIn the Manage \xe2\x86\x92 All devices, delete the Thing and Thing type.\nIn the Manage\xe2\x86\x92 Security section, remove the Policy and Certificate.\nIn the Manage \xe2\x86\x92 Message Routing section, clean up the Rule.\nAmazon Timestream\nDelete the table and the database.\nAmazon Managed Grafana\nDelete the Amazon Managed Grafana workspace.\nAWS IAM\nDelete the roles created along the way.\nAWS IoT TwinMaker\nDelete the AWS IoT TwinMaker workspace\n'"
54,Build a digital twin of your IoT device and monitor real-time sensor data using AWS IoT TwinMaker (Part 1 of 2),b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/09/14/architecture-1024x517.png,https://aws.amazon.com/blogs/iot/build-a-digital-twin-of-your-iot-device-and-monitor-real-time-sensor-data-using-aws-iot-twinmaker-part-1-of-2/,"b'Introduction\nA digital twin is a living digital representation of a physical system that is dynamically updated to mimic the structure, state, and behavior of the physical system to drive business outcomes. Building one is usually not an easy task \xe2\x80\x93 to solve this challenge, we launched a new service, AWS IoT TwinMaker. AWS IoT TwinMaker connects data from a variety of sources like equipment sensors, video feeds, and business applications and creates a knowledge graph to model real-world systems and generate real-time insights from the digital twin.\nSome customers are using AWS IoT TwinMaker to optimize maintenance schedules by quickly pinpointing and addressing equipment and process anomalies, or to give field workers a consolidated view of all asset and operational data. Another common use case is enhancing the user experience and improving occupant comfort in buildings by monitoring live and historical data about temperature, occupancy or air quality within rooms.\nThis blog post series addresses this last scenario: monitoring temperature and humidity of a room in real time while being able to control the location and status of sensors.\nTo simulate this scenario, you will learn how to use AWS IoT TwinMaker to create a digital twin of a Raspberry Pi device connected to a sensor that collects temperature and humidity data. You will integrate with an Amazon Managed Grafana dashboard to visualize the 3D environment where the digital twin lives together with collected data that influences the device status and 3D model representation in real time.\nPart 1 (this blog post) covers an overview of the solution, the setup of the time-series database, which will host your data, and the configuration of the IoT Thing. It also covers the wiring of the sensor to the Raspberry Pi device.\nIn Part 2, you will continue with the setup of the Amazon Managed Grafana dashboard that will be used to visualize data. You will create the AWS Lambda function to read data from the time-series database and most importantly, you will setup AWS IoT TwinMaker and integrate it with the Amazon Managed Grafana dashboard to display your digital twin together with real time data you will collect.\nSolution Overview\nThe diagram below shows a high-level architecture overview. Data generated from the sensor attached to the Raspberry Pi device is sent via a Python script to AWS IoT Core, that easily and securely connects devices through the MQTT and HTTPS protocols. From here, using AWS IoT Core rules, data is streamed to an Amazon Timestream database. On the AWS IoT TwinMaker side, you will create the workspace environment where a virtual entity is defined together with its 3D model representation. A component will also be created, which uses a Lambda function to read data from Amazon Timestream, so that your digital twin is in sync with data arriving from the sensor. For the visualization part, you will leverage the AWS IoT TwinMaker Grafana dashboard integration to create a dashboard which presents data together with the 3D model. The dashboard is accessible in SSO via AWS IAM Identity Center (successor to AWS SSO). Finally, you will create AWS IoT TwinMaker rules to be able to easily see changes in the dashboard whenever the temperature or humidity goes below or above the thresholds defined.\n\n\nFigure 1: The high-level architecture of the solution\nPrerequisites\nAn AWS account\nRaspberry Pi 4 Model B with a pre-installed Operating System SD card and a power cable\nDHT sensor (or similar, to retrieve temperature/humidity data)\nBreadboard with male to male (M2M) jumper wires, and resistor. You would also need female to female (F2F) jumper wires if you\xe2\x80\x99re not going to use an extension board like I did (see note in section 3 \xe2\x80\x93 Raspberry Pi setup)\nImplementation\nBelow are the macro-steps you will perform in this blog post series:\n(Part1)\nSetup of the time-series database Amazon Timestream, which will store your temperature and humidity data\nSetup of AWS IoT Thing with certificates and rules to make sure that data collected will be sent to the database\nConfiguration of Raspberry Pi device: wiring of the sensor and creation of the Python file used to send data to AWS\n(Part2)\nSetup of the Amazon Managed Grafana dashboard that will be used to visualize data\nCreation of AWS Lambda function to read data from Timestream\nSetup of AWS IoT TwinMaker role, policy, bucket destination and workspace. Definition of the telemetry component to read from database. Import of the 3D model and definition of the scene\nCreation of the dashboard in Amazon Managed Grafana with AWS IoT TwinMaker plugin.\nIMPORTANT: Some of the services used are not yet available in all the AWS regions. Make sure you create all your resources in us-east-1 or eu-west-1 (depending if you prefer US or Europe region).\n1.  Setup of Amazon Timestream Database\nLet\xe2\x80\x99s start by configuring the database for the temperature and humidity data. The use case is clearly related to collecting time-series data, so the right \xe2\x80\x9ctool\xe2\x80\x9d in this case is Amazon Timestream.\nTo create a database:\nChoose Timestream in the AWS Management Console.\nChoose Create database.\nEnter the following information:\nConfiguration: Standard database\nName: TempHumidityDatabase\nConfirm by choosing Create database.\n\nFigure 2: Creation of Timestream database\nThen, create a table.\nChoose the Tables tab, and choose Create table.\nSet the following values:\nDatabase name: TempHumidityDatabase\nTable name: TempHumidity\nData retention:\nMemory: 1 Day\nMagnetic: 1 Month(s)\nCreate table\nThe database is ready to receive data.\n2. Connecting Raspberry Pi to AWS IoT Core\nIn this section, you will prepare the \xe2\x80\x9cconnection\xe2\x80\x9d between the Raspberry Pi device and AWS IoT Core by creating a policy and certificates, then registering the device as a \xe2\x80\x9cThing\xe2\x80\x9d. Next, you will define the rules to send data to the Amazon Timestream database and route potential errors to logs in Amazon CloudWatch.\nCreate a policy\nAWS IoT Core policies are JSON documents and follow the same conventions as AWS Identity and Access Management (IAM) policies. AWS IoT Core policies allow you to control access to the AWS IoT Core data plane. The AWS IoT Core data plane consists of operations that allow you to connect to the AWS IoT Core message broker, send and receive MQTT messages, and receive or update an AWS IoT thing\xe2\x80\x99s device shadow.\nYou will now create a policy to allow the publication and subscription of a specific IoT topic (/raspberry/temphumid). This policy will be attached to a certificate used by the AWS IoT thing.\nOpen the AWS Management Console of your AWS account.\nNavigate to the AWS IoT Core service, then from the left menu choose Manage > Security > Policies section.\nChoose Create Policy.\nEnter the following values:\nPolicy properties \xe2\x86\x92 Policy name: TempHumidityPolicy\nPolicy statements \xe2\x86\x92 Policy document \xe2\x86\x92 select JSON\nPaste the following Json replacing your AWS region and AWS account\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:[AWS_REGION]:[AWS_ACCOUNT]:topic/raspberry/temphumid""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:[AWS_REGION]:[AWS_ACCOUNT]:topicfilter/raspberry/temphumid""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""*""\n    }\n  ]\n}\nJSON\nchoose Create\nCreate an AWS IoT Thing and generate a certificate\nIn the console, choose AWS IoT Core.\nFrom the Manage > All devices > Things section on the left, choose Create Things.\nSelect Create a single thing.\nEnter a name for the thing (eg RaspberryPi) and leave the Device Shadow section with No Shadow. Choose Next.\nIn Configure Device Certificate, select Auto-generate a new certificate (recommended) and choose Next.\nIn Policies, select the policy created before (TempHumidityPolicy) and choose Create Thing.\nDownload the Device certificate (crt) along with public and private key (pem.key) and Root CA 1 certificate in a folder on your local machine. You will use the certificate and private keys later, on your Raspberry Pi device. You won\xe2\x80\x99t need the public key or the Amazon Root CA 3.\nWhen the download is complete, choose Done.\n\nFigure 3: An IoT thing has been created to represent your Raspberry Pi\nCreate a rule to send data to Amazon Timestream and errors to Amazon CloudWatch\nChoose AWS IoT Core in the console.\nIn the Manage > Message Routing > Rules section, choose Create rule, and then enter the following:\nName: TempHumidityRule\nDescription: Rule to handle temperature and humidity message. Choose Next.\nRule query statement:\nSELECT * FROM \'raspberry/temphumid\'\nChoose Next.\nIn the \xe2\x80\x9cRule actions\xe2\x80\x9d panel, choose Timestream table \xe2\x80\x93 Write a message into the Timestream table. Next, select the Timestream database TempHumidDatabase and table TempHumidity you created before.\n\nFigure 4: The IoT Core rule to write data in Amazon Timestream\nYou need to enter the dimension name (minimum of 1 is required). Define a dimension with dimension name DeviceName and dimension value Rpi4.\nNext, you need to create an IAM role to allow the AWS IoT Core service to access the database. Choose Create new role, and then enter the following name: TempHumidityDBRole\nIn the \xe2\x80\x9cError action\xe2\x80\x9d panel, choose Add error action. Select CloudWatch logs \xe2\x80\x93 Send message data to CloudWatch logs.\nChoose Create CloudWatch Log group \xe2\x80\x93 you\xe2\x80\x99ll be redirected in a new tab to CloudWatch. Create a log group named TempHumidityRuleErrors. You can access log groups from the left menu Logs > Logs group. You can leave Expiration to never as default.\nGo back to AWS IoT Core and refresh the Log group name list and select the newly created log group.\nCreate an IAM role to allow the service to access CloudWatch: choose Create new role, then enter the following name TempHumidityCloudwatchRole\n\nFigure 5: The IoT Core error rule action will send errors to Amazon CloudWatch\nChoose Next.\nReview the inputs and confirm the rule creation by choosing Create\nYou now have a valid IoT rule that will route temperature and humidity data sent by the sensor to the Timestream database. Errors will be sent to Amazon CloudWatch logs.\n3. Raspberry Pi setup\nNow that you have defined the database and prepared the AWS IoT thing that represents your Raspberry Pi, it\xe2\x80\x99s time to wire the sensor to the Raspberry Pi and then send some data to AWS IoT Core.\nWire the sensor\nIn this post we use a DHT11 sensor to collect temperature and humidity data from the environment. The DHT11 is a basic, low-cost digital temperature and humidity sensor. It uses a capacitive humidity sensor and a thermistor to measure the surrounding air and generates a digital signal on the data pin\nNote: This blog was created using a Raspberry Pi 4 Model B mounted on a case box kit. This box kit neatly packages the Pi and prevents damage, but is not required. The same is true for the expansion board, which makes it easier to work on the breadboard rather than using the Raspberry Pi pins directly. You don\xe2\x80\x99t need it if you want to connect wires directly to your device.\nThe DHT11 sensor is connected to the breadboard as shown in the pictures following.\n\nFigure 6: Raspberry Pi wiring of the DHT11 sensor\n\nFigure 7: Raspberry Pi with extension board and DHT11 sensor wired\nSend data from Raspberry Pi to AWS IoT Core\nNow that you have the sensor correctly wired to your Raspberry Pi device, you will try to send some temperature and humidity data to AWS. First, you need to copy the Raspberry Pi certificates that you downloaded when you configured the AWS IoT thing, so that Raspberry Pi knows where to connect and send the generated data. There are several options to connect with Raspberry Pi and copy over files. You could use SFTP and save the certificates in a Raspberry Pi safe folder, where you can reference them in the code later.\nOnce you have the certificates in place, you can move to the next step. You will create a Python file in the Raspberry Pi that will include the Python code below to collect data from the DHT11 sensor. This script will collect data and send it to AWS.\nOn your Raspberry Pi device, create a file named temphumid.py and paste the Python code below\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\nimport json\nimport time\nimport board\nimport adafruit_dht\n\n# MQTT config (clientID must be unique within the AWS account)\nclientID = ""XXXX-XXXX-XXXXX-XXXXX""\nendpoint = ""XXXXXXXX.[AWS_REGION].amazonaws.com"" #Use the endpoint from the settings page in the IoT console\nport = 8883\ntopic = ""raspberry/temphumid""\n\n# Init MQTT client\nmqttc = AWSIoTMQTTClient(clientID)\nmqttc.configureEndpoint(endpoint,port)\nmqttc.configureCredentials(""certs/AmazonRootCA1.pem"",""certs/raspberry-private.pem.key"",""certs/raspberry-certificate.pem.crt"")\n\n# Send message to the iot topic\ndef send_data(message):\n    mqttc.publish(topic, json.dumps(message), 0)\n    print(""Message Published"")\n\n# Loop until terminated\ndef loop():\n     #Init the dht device with data pin connected\n     dhtDevice = adafruit_dht.DHT11(board.D17)\n\n     while(True):\n          try:\n               temperature = dhtDevice.temperature\n               humidity = dhtDevice.humidity\n               print(""Temp: {:.1f} C    Humidity: {}% "".format(temperature, humidity)) \n               \n               message = {\n                         \'temperature\': temperature,\n                         \'humidity\': humidity\n                         }\n                    \n               # Send data to topic\n               send_data(message)\n\n               time.sleep(3)\n          except RuntimeError as error:     # Errors happen fairly often, DHT\'s are hard to read, just keep going\n               print(error.args[0])\n\n# Main\nif __name__ == \'__main__\':\n    print(""Starting program..."")\n    try:\n        # Connect\n        mqttc.connect()\n        print(""Connect OK!"")\n\n        # Main loop called\n        loop()\n    except KeyboardInterrupt:\n        mqttc.disconnect()\n        exit()\nLet\xe2\x80\x99s examine the code above:\nImported some libraries (time, json) plus the library specific for the DHT sensor \xe2\x80\x93 in this case Adafruit_DHT. You will need to install the dependency (e.g. with sudo pip3 install Adafruit_DHT)\nConnected the Raspberry Pi to AWS IoT Core by setting up a name for MQTT client, which needs to be unique for the AWS account.\nDefined the source for certificates, make sure you have them in your Raspberry device.\nCreated a loop to:\nRead temperature and humidity data.\nCreate a message composed by temperature and humidity.\nSend data to the MQTT topic.\nAs you probably noticed, the code needs to be adjusted to include your unique clientID (you can choose a unique string) and most importantly, your IoT endpoint. To find it, in the console, select AWS IoT Core and then navigate to Settings > Device data endpoint. Copy the endpoint URL you see in the page and paste it in the Python script.\nOnce you followed the steps above in the temphumid.py file, do not forget to save it, then run it. If everything is set up correctly, you will see a message like the following:\n\nFigure 8: Output example of the temphumid.py python script\nTo make sure that data sent to AWS IoT Core is correctly routed to the Amazon Timestream database, open Amazon Timestream in the console and check that the table TempHumidity contains data. You can navigate to the query editor in Amazon Timestream to have a preview of your data by choosing the three dots close to your table name and choose Preview Data \xe2\x80\x93 by default, it will retrieve the last 15 minutes of data.\n\n\nFigure 9: Preview data in Amazon Timestream\n\n\nFigure 10: Humidity and temperature sent to Amazon Timestream via AWS IoT Core\nIf data is not there, refer to the error logs you have in the CloudWatch log group you created before.\nFor now, you can stop the Python script. You will run it again later.\n'"
55,Create insights by contextualizing industrial equipment data using AWS IoT SiteWise (Part 2),b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/create-insights-by-contextualizing-industrial-equipment-data-using-aws-iot-sitewise-part-2/,"b""Introduction\nIn the first part of this blog series Create insights by contextualizing industrial equipment data using AWS IoT SiteWise (Part 1) we focused on asset modelling and real-time analytics in AWS IoT SiteWise. We created a dashboard in AWS IoT SiteWise Monitor to get a real-time overview of our furnace heating cycles. But we concluded that a more in-depth analysis was needed to find the root cause of the abnormal heating cycle of Furnace1. In this second part of the blog, we will show how customers can use the AWS IoT SiteWise cold tier storage feature to export the raw, aggregated and meta-data to AWS IoT Analytics for further analysis.\nEnable AWS IoT SiteWise cold tier storage and AWS IoT Analytics export\nAWS IoT SiteWise cold tier storage feature makes it easy to consume historical data in downstream AWS analytic services. Additionally, it will also lower your storage cost on AWS IoT SiteWise by exporting historical data to Amazon S3. Customer can freely define how long the data will be kept in the time-series optimized AWS IoT SiteWise data before being exported into S3 by setting a data retention threshold.\nEnabling AWS IoT SiteWise cold tier storage\nTo enable AWS IoT SiteWise S3 export, open the AWS IoT SiteWise console, choose Settings, Storage, Edit in the navigation pane and check Enable Cold tier storage,\nEnter an existing S3 bucket location in the same AWS region,\nCheck Enable AWS IoT Analytics data store, type iotsitewise as the Data store name and choose Save\nFor this walk through we will use AWS IoT Analytics to query the data and visualize it in Amazon QuickSight.\nThe AWS IoT SiteWise S3 export feature exports information on asset properties from the asset model into the asset-metadata S3 prefix when the model change. Once the status of the S3 export is enabled, you should see a line delimited JSON file per asset in your S3 bucket. The raw data is exported every 6 hours and will be placed into the raw S3 prefix. For more details on the export format and location, see File paths and schemas of data saved in the cold tier.\nCreate an AWS IoT Analytics dataset to analyze the raw data\nWe can now start to analyze the AWS IoT SiteWise exported data with AWS IoT Analytics. Open the AWS IoT Analytics console, choose Datasets in the navigation menu and choose Create dataset, Create SQL. This will open a wizard that will guide you through the Dataset creation. On the first screen name your data set and choose the iotsitewise data store that was created by the AWS IoT SiteWise cold tier export wizard.\nChoose Next to open the Author SQL query dialog, copy and past the sample query below.\nThe query used some advanced Athena SQL features and also demonstrated how AWS IoT Analytics Dataset queries can be used to join data from different AWS IoT Analytics data stores. For this analysis, we want to query the metric Last Holding Cycle Time for all our assets in the current month. To accomplish this, the query starts from the raw data store filtered by a specific month. It joins the asset_metadata data store to retrieve the property metadata like the asset name. Finally, it joins the asset_metadata again, but this time grouped by asset ID. This last JOIN statement retrieves all static attribute of the corresponding AWS IoT SiteWise asset and adds it to the result row. This data is crucial for our analysis, because we will use it in our last step as dimensional data.\nSELECT \n    from_unixtime(data.timeinseconds + (data.offsetinnanos / 1000000000)) ts, \n    metadata.assetname,  metadata.assetpropertyname, metadata.assetpropertydatatype, \n    data.doublevalue,  \n    latesValue['Location'] as Location , latesValue['Manufacturer'] as Manufacturer, \n    latesValue['YearOfConstruction'] as YearOfConstruction, latesValue['Setpoint'] as Setpoint\nFROM iotsitewise.raw  as data\n-- Join the meta data table \nINNER JOIN iotsitewise.asset_metadata as metadata\nON data.seriesid = metadata.timeseriesid\n-- Join sub query that retrieves all asset attributes and latest values    \nLEFT JOIN (\n  SELECT assetid, map_agg(assetpropertyname, latestvalue) latesValue from (\n    SELECT assetid,  assetpropertyid, assetpropertyname,\n            coalesce (\n            max_by(data.stringvalue, data.timeinseconds),\n            max_by(cast(data.integervalue as VARCHAR), data.timeinseconds),\n            max_by(cast(data.doublevalue as  VARCHAR), data.timeinseconds)\n            ) latestvalue\n    FROM iotsitewise.raw data  \n    INNER JOIN iotsitewise.asset_metadata metadata\n    ON data.seriesid = metadata.timeseriesid\n    GROUP BY assetid, assetpropertyid, assetpropertyname) \n  GROUP BY assetid) as dim\nON metadata.assetid = dim.assetid\nWHERE data.startyear = year(current_date)\nAND data.startmonth = month(current_date)\nAND metadata.assetpropertyname = 'Last Holding Cycle Time'\nSQL\nTo test the query, choose Test query. If the query contains no syntax errors, you should see a preview of the data in the Result preview section.\nLeave the rest of the steps 3-6 with the default value by choosing Next and choose Create dataset on the last review step 7.\nTo validate if everything is correctly setup, navigate to your newly created dataset\nChoose Run now and wait until the result content appears on the Content tab with Succeeded. When you choose the Result link, the console shows you a preview of the query result:\nThe result shows the Last Holding Cycle Time metric by time. The query also added the AWS IoT SiteWise model information, like the asset name and model name, and the asset attribute values to each row. Such flattened data rows make it easier to analyze the data in BI tools. In the next step we will use Amazon QuickSight to analyze the IoT Analytics dataset.\nAnalyze the result in Amazon QuickSight\nAs a final step, we will analyze the data in Amazon QuickSight. Amazon QuickSight comes with a built-in connector for AWS IoT Analytics, so it\xe2\x80\x99s easy to visualize the data.\nOpen the Amazon QuickSight console and chose New Analysis, when prompted for a data sources, create a new one by choosing New Dataset. Choose AWS IoT Analytics and select the SiteWise AWS IoT Analytics dataset holdingcycletimereport we created in the previous step. To create the data source choose Create Data Source.\nChoose Visualize to start using Amazon QuickSight Visual Types to display the data set.\nIn this specific use case, we want understand how the Manufacture and the Construction Year influences the HOLDING cycle duration, the Amazon QuickSight heat map is a good choice to visualize this data.\nAnd from this view, we can clearly identify that the furnaces manufactured by Furnace Corp in 1999 have the longest cycle time (>=88) and need to be prioritized for replacement.\n"""
56,Create insights by contextualizing industrial equipment data using AWS IoT SiteWise (Part 1),b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/25/SiteWiseContextualizeFeaturedImage.jpg,https://aws.amazon.com/blogs/iot/create-insights-by-contextualizing-industrial-equipment-data-using-aws-iot-sitewise-part-1/,"b'Introduction\nMore and more customers in the manufacturing industry want to collect data from machines and robots located in different facilities into a centralized AWS cloud-based IoT data lake. But the data produced by industrial equipment is often raw data points like temperature and pressure time series. Feeding those raw data streams directly into your industrial data lake, will make it difficult for your data analysts to get insights out of the ingested equipment data. A data analyst might need information that is not directly contained in the raw data streams to analyze the performance of industrial equipment. Metadata like the construction year, location or the manufacture of an equipment could have an impact on the performance metrics.\nAWS IoT SiteWise is a managed AWS service that simplifies collecting, organizing, and analyzing industrial equipment data and can help to contextualize the raw data streams captured from your industrial equipment using the AWS IoT SiteWise asset modeling capabilities. In part 1 of this blog series, and based on a fictional industrial use case, we will showcase how customer can use the asset modelling feature of AWS IoT Sitewise to manage such industrial equipment meta-data. And we will see how to use the AWS IoT SiteWise built-in library of operators and functions to perform real-time analytics to compute aggregated metrics. In part 2, we will show how we can export the ingested data to AWS IoT Analytics to perform complex batch analytics by combining the raw, meta and aggregated data to understand the root cause of an observed performance degradation.\nSample use case\nTo get you started, let\xe2\x80\x99s consider a simple industrial scenario where the goal is to remotely monitor industrial furnaces. Your company owns furnaces across different production sites that perform the same industrial process like e.g. annealing metal workpieces. You\xe2\x80\x99ve noticed a difference in manufacturing time and quality across your production sites.\nYou want to model your furnace in AWS IoT SiteWise with the following properties, and you use AWS IoT SiteWise Edge to collect those data points e.g over Modbus TPC from your furnaces.\nFurnace Asset Model\nProperty Name Property Type Property Value Type Unit Sample Data\nFurnace location ATTRIBUTE STRING none Paris factory, Chicago factory\nFurnace manufacturer ATTRIBUTE STRING none Furnace Corp, Heat&Metal Corp\nFurnace temp set point ATTRIBUTE INT C\xcb\x9a 760\nFurnace construction year ATTRIBUTE INT Year 1999\nCurrent Kw Power Consumption MEASUREMENT DOUBLE kW 51\nCurrent furnace temperature MEASUREMENT DOUBLE C\xcb\x9a 399\nThe Furnace state MEASUREMENT STRING none IDLE, HEATING,HOLDING, COOLING\nLast HOLDING cycle duration TRANSFORMATION DOUBLE Duration in s 4h5m3s\nAvg Holding cycle last 24h METRIC(1day) DOUBLE Duration in s 4h5m3s\nYou have a suspicion that the efficiency issue is linked to the heterogeneous machine park, so you want to compare the heating and holding duration across all furnaces grouped by manufacture and construction year. The next section shows you step-by-step instructions on how to use AWS IoT SiteWise and AWS IoT Analytics to generate the desired report.\nModel and create an industrial asset in AWS IoT SiteWise\nThe first section explains on a high level how to create the furnace asset model in AWS IoT SiteWise. For details on how to model industrial assets in AWS IoT SiteWise, see Modeling industrial assets.\nCreate a furnace asset model\nSign in to the AWS Management Console and navigate to the AWS IoT SiteWise console.\nOn the navigation bar, choose Build, Model to create a new Model, call it Furnace and define the static attributes and default value as describe in the table before:\nNext define the asset model measurement as depicted below. The furnace operates in four different processing states State moving from IDLE to HEATING, over HOLDING and COOLING. The Temperature measurement shows the current furnace temperature and Power the current power consumption in kW.\nThe next step is to define AWS IoT SiteWise transforms to perform computation on the raw measurements. We use some advanced temporal AWS IoT SiteWise functions here to detect the state change from HOLDING to COOLING and store the HOLDING cycle duration into the Metric Last Holding Cycle Time . The formula below is triggered when the State measurement changes value and the previous value was HOLDING: if(pretrigger(State)==""Holding"", ... . In this situation, it computes the duration of the holding time by subtracting the current change timestamp from the previous change timestamp: timestamp(State) - timestamp(pretrigger(State). To learn more about AWS IoT SiteWise temporal functions, see Temporal functions\n\nA furnace operator might be interested in monitoring the evolution of the holding cycle duration over time. To do so, let\xe2\x80\x99s create a last metric to calculate the average Last Holding Cycle Time for a time window of 5-minute, in a real scenario a daily roll-up might be more appropriate to compare variations over a longer time period.\n\nAWS IoT SiteWise allows users to define asset model hierarchies to create logical associations between the asset models in your industrial operation. As a last step, create a model named Factory to represent a factory and create a hierarchy definition pointing to the Furance model. A factory will later on, through a hierarchical structure, represent a group of furnaces placed in one production site. We will use this hierarchy later in AWS IoT SiteWise Monitor to visualize furnace performance metrics within a factory on a dashboard.\nCreate the furnace assets\nCreate assets based on the Furnace model by choosing Build, Assets in the navigation bar and choose Create asset. Create for example one Factory Asset named Paris Factory and 4 attached Furnace assets and populate the static asset attributes with random data of your choice.\nThis concludes the Asset modelling and creation part, and we can now start analyzing the data captured by AWS IoT SiteWise. In the next section, we will show you how to leverage the built-in AWS IoT SiteWise time-series optimized data store to monitor our furnaces in real-time.\nAnalyzing the near-real time data using AWS IoT Sitewise\nTo test our AWS IoT SiteWise assets, we need to generate some sample data for the furnace temperature, power and state measurements. In this blog post we don\xe2\x80\x99t connect to a real Modbus data source but use a Python based data simulator that you can run on your laptop: https://github.com/aws-samples/sitewise-iiot-data-simulator . Follow the instructions in the README file to install and run the simulator.\nAWS IoT SiteWise Monitor is an easy way to visualize the measurements, transformations and metrics we defined in our Asset Model. The following screen capture shows what an operational dashboard could look like to compare the performance of two Furnaces in a Factory. AWS IoT SiteWise Monitor allows you to create no-code fully managed web applications by using drag and drop the asset model properties onto the dashboard. This blog post leaves it to the discretion of the reader to design their own dashboard. To get you started, here are some of the widgets we used to create the dashboard depicted below. The dashboard uses the timeline widget to visualize the current and previous state transitions, the line chart to plot the temperature and power consumption and a bar chart to depict the last HOLDING cycle time duration. Several KPI widgets allow operators to have quick glance at key Furnace KPIs. To learn more on how to set up an AWS IoT SiteWise Monitor Dashboard, see Getting started with AWS IoT SiteWise Monitor.\nUsing the AWS IoT SiteWise Monitor dashboard, we can clearly identify that the Avg. Holding Cycle time metric for Furnace001 is longer (87s vs 76.5s) than for Furnace002.\nThe holding time is also higher compared to the average (82s) across all furnaces in the Paris factory. But a more in-depth analysis is needed to understand the root cause of this discrepancy.\nClean up\nMake sure you stop the furnace data simulator to avoid incurring ongoing charges.\n'"
57,How to convert and compress OBJ models to GLTF for use with AWS IoT TwinMaker,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-convert-and-compress-obj-models-to-glb-gltf-for-use-with-aws-iot-twinmaker/,"b'Introduction\nTrying to get started with AWS IoT TwinMaker and need to convert your OBJ file to glTF? Perhaps you have performed a point cloud scan of your environment with Matterport and it\xe2\x80\x99s not clear how you can import the Matterpak bundle into AWS IoT TwinMaker. In this blog, you will apply a model conversion pipeline to compress and convert a Matterpak bundle into glTF format. This approach will provide up to date 3D models and improved scene load times in AWS IoT TwinMaker.\nOverview\nIn this blog post, several file extensions and model formats are referenced. Before getting started, it is good to understand the following:\nOBJ \xe2\x80\x93 Object file, a standard 3D image format that can be exported and opened by various 3D image editing programs.\nMTL \xe2\x80\x93 Material library file, contains one or more material definitions, each of which includes the color, texture, and reflection map of individual materials for objects in an OBJ model\nglTF \xe2\x80\x93 Graphics Language Transmission Format, a standard file format for three-dimensional scenes and models. A glTF file uses one of two possible file extensions: .gltf or .glb\nDraco Compression \xe2\x80\x93 A glTF extension for mesh compression. This Cesium library will compress and decompress 3D meshes to significantly reduce the size of 3D content. It compresses vertex positions, normals, colors, texture coordinates, and any other generic vertex attributes, improving the efficiency and speed of transmitting 3D content over the web.\nPoint Cloud Scans \xe2\x80\x93 A large collection of individual points (x, y, z coordinates) within a 3D space, captured using a 3D laser scanner and stored in ASCII (.xyz) or binary format.\nAWS IoT TwinMaker supports 3D assets in the glTF format, which is a 3D file format that stores 3D model information in JSON format or binary and enables efficient transmission and loading of 3D models in applications. The glTF format minimizes the size of 3D assets and the runtime processing needed to unpack and use them. The 3D models from traditional CAD applications, as well as point cloud scans, can be converted to glTF using AWS Partner solutions, such as those from Pixyz. In this blog, you will explore an alternative server-less approach to model conversion of Matterpak bundles to glTF using open source libraries by Cesium, including obj2gltf and gltf-pipeline.\nIn the architecture below, you will see how AWS Lambda can be used to detect a Matterpak zip bundle uploaded to an Amazon S3 bucket. This will trigger the conversion to glTF within a long running Lambda execution. The zipped file may contain OBJ, MTL, and JPG files.\nWithin a Matterpak bundle, there are several files including an OBJ, MTL, point cloud scan (xyz), and possibly many JPG files. Matterport in this example has converted the point cloud scan to an object mesh format, OBJ. The MTL and JPG files together provides colored texturing over the objects within the OBJ model. The xyz file will not be used in this conversion process as this has already been converted to OBJ in the Matterpak.\nModel Conversion Pipeline Architecture\nWhen working with point cloud scans such as Matterport, high resolution JPG textures are captured throughout the scan. Doing a simple conversion of the OBJ to glTF will still be quite large. To improve this, the Lambda function in this blog will first compress all JPG images prior to converting to glTF. In addition, this model will be compressed even further by using Draco Compression. As a result, the conversion will produce a much smaller glTF file as seen in this AWS IoT TwinMaker Scene below. Note, a glTF file uses one of two possible file extensions: .gltf or .glb. The glTF extension will be used in this blog.\nExample Matterport Scan in AWS IoT TwinMaker\nPrerequisites\nAn AWS account will be required to setup and execute the steps in this blog. An AWS Cloudformation template will configure and install the necessary AWS Lambda Function, IAM roles, and Amazon S3 bucket. It is recommended that you work in the Virginia region (us-east-1). You may incur cost on some of the following services:\nAmazon Simple Storage Service (S3) Storage costs\nAWS Lambda Model Convert Function\nSteps\nDownload Matterpak Sample Bundle\nDownload one of the Matterpak Bundles. Select one of the bundles, such as Pro2. This available list of bundles may change. The approximate file size for the Pro2 sample bundle is 178MB.\nInstall Model Convert Lambda Function\nDownload the sample Lambda Model Convert deployment package. The function code within this package will perform the following:\n\xe2\x80\x93 Download Matterpak bundle from S3\n\xe2\x80\x93 Extract to the Lambda /tmp directory\n\xe2\x80\x93 Compress all JPG images\n\xe2\x80\x93 Convert OBJ files to glTF\n\xe2\x80\x93 Convert glTF to Draco glTF\n\xe2\x80\x93 Upload Draco glTF model back to the S3 Bucket.\nLog into the Amazon S3 console\nCreate an S3 bucket or choose an existing one where you will upload the Lambda function you downloaded. Leave the file zipped as is.\nOnce the Lambda function has been placed in S3, launch this CloudFormation template\nChange the LambdaArtifactBucketName parameter value to the name of the bucket you uploaded the Lambda function to\nChange the S3BucketName parameter value to the name of a new bucket that will host your model files. This will be created for you. Be sure to select a name that is globally unique as it will fail during the creation of the stack otherwise.\nClick on Create Stack to set up the model conversion pipeline\nOnce complete, navigate to the new S3 bucket. A link can be found under the Resources tab\nCreate a folder in this bucket and name it paks\nUpload the Matterpak bundle that was downloaded in step 1 to the paks folder. Be sure to keep it zipped as the Lambda function will unzip it during processing. The conversion process will begin automatically and may take a few minutes.\nIf the model is converted successfully, you will see a glTF file in the root of the S3 Bucket. If not, check Amazon CloudWatch for any logs from the Lambda function.\nAdd Model to Scene (Optional)\nTo recap, you have successfully compressed and converted a nearly 180MB point cloud scan by Matterport to an 8MB glTF file. With the model converted, you can try to load this in your IoT TwinMaker workspace. Note that any Mattertags you have created in Matterport are not transferrable in this process. This must be recreated using IoT TwinMaker Tags in the Scene composer.\nIn your IoT TwinMaker Workspace, upload the glTF model in the Resources section. If you haven\xe2\x80\x99t already created a workspace, please follow the steps at Getting Started with AWS IoT TwinMaker.\nAdd this model to your scene or create one if it doesn\xe2\x80\x99t already exist. If you need guidance on this process, the documentation is available here. Don\xe2\x80\x99t forget to set environmental lighting as the model will appear all black.\nClean Up\nBe sure to clean up the work in this blog to avoid charges. Delete the following resources when finished in this order\nDelete the object files in the Lambda and Model S3 Buckets. Note, this is not the IoT TwinMaker Workspace bucket but rather the buckets created for this blog\nDelete the CloudFormation Stack\nDelete the model from your TwinMaker workspace\n'"
58,Planning a Seamless Migration to AWS IoT Core,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/08/26/image-3.png,https://aws.amazon.com/blogs/iot/seamless-migration-to-aws-iot-core/,"b'Introduction\nThe Internet of Things (IoT) ecosystem has evolved rapidly over the last several years with an explosion of connected devices and data. This has also resulted in a shift for some customers as they look to evolve and adapt their solutions to match their business needs, or simply transition away from less scalable and reliable IoT platforms. Then there is the challenge of customers being forced to move off from their original IoT platform due to discontinuation of the service from the service provider. These challenges can be disruptive, but also provide an opportunity to strengthen your offerings. Over the years, AWS has helped customers like BISSELL, LG, Traeger Grills, Belkin, Weissbeerger, and many others to quickly and easily migrate from their homegrown or third-party IoT platforms. These customers migrated to AWS IoT for added functionality, access to new or improved services, hardening of security needs, better technical support, improved disaster recovery options, and for cost efficiencies. However, migrating your IoT platform is a process where you will need to evaluate and address many considerations to align the process outcome with your business goals.\nConsiderations for your IoT migration\nWhether this is an opportunity for your company to rework your IoT solution from the ground-up or simply move your existing platform to AWS, here are some considerations to factor in:\nFunctionality: Think about how your new IoT platform can complement your business model and bring a packaged experience for your customers from the IoT edge device all the way to the cloud. Note that each connected device requires an operating system and associated libraries, a robust security architecture, a set of communication protocols, and over-the-air update mechanisms with a maintenance plan for security and feature updates.\nMaintaining data security and risk assessment: The foundation of an IoT solution must involve security throughout the process or else risk costly recalls or expensive retrofitting when poor security implementations lead to customer issues or downtimes. Narrow your choices to a platform that supports security and encryption of data while in transit to and from the cloud, or in transit from edge services to and from the device, along with robust authentication and access control support.\nMigration costs: It is important to determine how much data is being moved and the bandwidth available for the transfer of data. However, not all migrations need to be evaluated based on upfront expenses; you should factor in savings and efficiencies possible through managing your devices at scale. For example, if you are building new capabilities on your products such as video uploads, voice recognition, machine learning and artificial intelligence, then think about the savings you could realize from an IoT platform that supports your innovation cycle.\nManaging at scale: What a lot of people fail to understand is the complexity of managing a connected fleet of diverse devices and applications at scale, which only intensifies as you scale your portfolio. Developing custom software and provisioning infrastructure that can scale up and down to support a high volume of simultaneous connections between cloud services, mobile apps, and an array of devices can be difficult and time consuming.\nCompetencies to support migration: It\xe2\x80\x99s critical to realistically assess where your organization is on its IoT journey. We have seen organizations go down the build-it-yourself path and burn several months of time \xe2\x80\x93 a result of having underestimated the challenges of going it alone, along with lacking certain skills internally. Often, working with a partner is a more effective approach. Partners have done this before, which means they\xe2\x80\x99ve learned from past mistakes, created efficiencies through a set of reference architectures and best practices, and can help you keep your competitive edge.\nUnlocking benefits with AWS IoT\nAWS IoT gives you the flexibility to collect data and compute in the cloud (or wherever data is generated) in order to deploy smarter, faster-responding, and more cost-effective IoT applications. The mission of AWS IoT is to make sure you can know the state of every thing and can reason on top of that data to solve business problems.\nTaking advantage of the security, scalability, reliability, and breadth and depth of AWS IoT services to accelerate their innovation, many customers have migrated their solution to AWS IoT:\nImproved scale and elasticity: Customers like LG were able to expand the geographic reach of their offering, taking their products into new regions. Others, like iRobot, were able to take advantage of AWS IoT\xe2\x80\x99s elasticity to support their peak season loads.\nReduced disruptions: Traeger Grills was forced to migrate its customers as their legacy IoT vendor decided to sunset its platform. Traeger faced a time crunch to migrate customers and rebuild its solution, without disruption to current customers. With the help of AWS IoT Partner, OST, Traeger migrated over a hundred thousand devices to AWS IoT Core in just three months, and with zero downtime.\nReduced costs: Customers like Centrica with their Hive product line, and Kemppi have all seen reductions in the cost of running their IoT solutions after migrating to AWS IoT. Kemppi saw 50% cost savings on developing and delivering IoT software.\nEnhanced security: Customers like Rachio and SolarNow rely on AWS and AWS IoT services to achieve a high level of IoT security without building their own security infrastructure.\nImproved reliability: AbiBird migrated their IoT solution from a third-party service provider to AWS IoT to achieve better reliability and performance at scale.\nIncreased agility: Customers have been able to rapidly adapt to changing market conditions when using AWS IoT managed services, which ensure you have the capacity you need at the time it is required. BISELL migrated their legacy IoT platform to AWS to support their agile business expansion strategy with the ability to scale features and connect nearly 1 million devices rapidly and reliably.\nContinuous Innovation: AWS IoT continues to innovate and offer the latest features in the industry. In the last twelve months, AWS IoT has rolled out over 50 updates, announced price reductions to drive cost efficiencies, and launched new services such as AWS IoT ExpressLink, AWS IoT TwinMaker, and AWS IoT RoboRunner.\nSimplifying your migration with AWS IoT Core\nAWS IoT Core, launched in 2015, is a managed cloud service built to support connectivity for billions of devices, process trillions of messages, and route those messages to AWS endpoints and to other devices reliably and securely. AWS IoT Core includes a wide variety of capabilities that help reduce your development time but allow unlimited flexibility to simplify your IoT migration process:\nMulti-layered security that is proven at scale: AWS IoT offers services for all layers of security, including preventive security mechanisms like encryption and access control to securing device data at rest and in transit. Further, with AWS IoT Device Defender you can audit configurations, authenticate devices, detect anomalies, and receive alerts to help secure your IoT device fleet at scale.\nFlexibility to define your own authentications and authorizations: AWS IoT Core offers custom authorizers that give you the flexibility to define and retain your own authentication and authorization. For example, if you are migrating existing devices in the field to AWS IoT Core and these devices use a custom bearer token or MQTT user name and password to authenticate, you can migrate them to AWS IoT Core without having to provision new identities for them.\nRetain your existing domain names: In 2021, AWS launched Configurable Endpoints with Custom Domains for AWS IoT Core, which makes it simpler to onboard IoT applications with existing devices in the field. Configurable Endpoints can help you maintain a consistent interface for existing devices as you transition your IoT applications to AWS IoT Core, and reduces the need for you to perform software updates on them.\nScalable MQTT broker: AWS IoT Core supports MQTT message broker that securely transmits messages to and from all of your IoT devices and applications with low latency, and scales automatically with your message volume without requiring you to run any infrastructure. If you plan to migrate to AWS IoT Core, bridging your legacy MQTT broker to AWS IoT Core represents an easy transient solution that you could deploy quickly.\nRemotely managing devices at scale: With AWS IoT Device Management you can onboard your device information and configurations, organize your device inventory, remotely monitor and manage your fleet across many locations, and easily perform over-the-air updates.\nMoreover, AWS IoT Core offers you an entry point into the world of services provided by AWS. Using AWS IoT Core, you can interact with over 200 additional services provided by AWS in areas such as Databases, Analytics, and Machine Learning. Or, you can easily create serverless applications using AWS Lambda services. Regardless of your use case, AWS has services to help with your development and provide you with the innovation you need for the future.\nFigure 1: A representation of how AWS IoT acts as a gateway towards additional AWS services.\nThe migration process with AWS and AWS Partners\nAWS makes it easy, cost-effective, and quick to migrate your existing connected devices from your homegrown or legacy platforms. You can either migrate using a do-it-yourself approach, or with assistance from AWS Professional Services or AWS IoT Partners.\nHowever, all IoT platforms are different with varying business requirements, geographic reach, connectivity options, and device hardware. There is no one-size-fits-all migration, so AWS provides multiple options to help you migrate your devices to AWS IoT.\n1. IoT platform migration ideation workshops led by AWS IoT Partners can help you define your migration objectives, select migration targets with clear paths to production, and ensure business owners are bought-in to the idea and understand the value of investing in a move to AWS. These workshops are broken down into incremental steps to provide you structured guidance and outcomes throughout your migration journey. These steps include, initial assessment of your migration scope, a detailed plan towards your future state, options to build and operate your solution using managed services, and optimization through AWS IoT platform insights.\nFigure 2: An overview of support provided by AWS IoT partners towards your migration journey.\nYou can work with System Integrators (SIs) to get hands-on end-to-end application support. For example, AWS IoT Partner, Klika Tech, offers a phased migration approach based on a shared understanding of your project goals, objectives, and success criteria to help derive the right fit for your organization. Similarly, TensorIoT offers an IoT Performance Testing solution to help evaluate your IoT fleets at scale, and understand fleet performance before deploying live devices. Or, if you simply want to connect your devices to a ready-to-go tested platform, then you can leverage Independent Software Vendors (ISVs) to access pre-built solutions that can help accelerate your time to market. For example, EdgeIQ delivers a fully-baked, scalable DeviceOps platform with a natively integrated on-ramp to AWS that simplifies management, integration, and orchestration of your connected products. Likewise, ThingLogix offers a ready to deploy IoT and event driven application framework for AWS. Access the full list of AWS IoT Partners and their capabilities here.\n2. IoT migration discovery and design workshops from AWS Professional Services are a multi-day deep dive with you to perform a Migration Readiness Assessment that helps scope your proof of concept and migration plan. The AWS Professional Services organization uses a methodology based on Amazon\xe2\x80\x99s internal best practices, obtained through years of experience, to help complete projects faster and more reliably, while accounting for evolving expectations and dynamic team structures along the way.\nFigure 3: AWS Professional Services methodology and offerings to support IoT migrations.\n3. AWS Migration Acceleration Program is a comprehensive and proven cloud migration program based upon AWS\xe2\x80\x99s experience migrating thousands of enterprise customers to the cloud. The program offers tools that reduce costs and automate and accelerate execution, tailored training approaches and content, expertise from AWS Professional Services, a global partner ecosystem, and AWS investment. Moreover, for qualified migration projects, the program offers AWS promotional credits and other incentives to help offset some of the costs incurred during the migration.\n4. AWS Solutions-Focused Immersion Days are hands-on sessions with AWS products and services, such as IoT and migration, that help you develop the skills needed to build, deploy, and operate your infrastructure and applications in the cloud.\nGetting started\nWe understand that migrating to a new IoT platform is not an easy decision, however with AWS experts and AWS Partners you can offload some of the heavy lifting, and access a level of support that can help formulate and implement a successful migration plan in line with your critical business needs. Through a comprehensive repository of over 800 qualified partner devices and 60-plus pre-validated IoT uses cases, AWS and the AWS IoT Partner community is committed to help you drive success from edge to outcome and accelerate your IoT projects. To learn more about AWS IoT migration, listen to this online tech talk, and to get started, contact our team to schedule a time to walk through your use case.'"
59,Learn how to secure your IIoT solutions with AWS IIoT security workshop,b'Iacopo Palazzi',2022-09-16T16:58:17+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/18/workshoparchitecturefinal.jpg,https://aws.amazon.com/blogs/iot/learn-how-to-secure-your-iiot-solutions-with-aws-iiot-security-workshop/,"b'Introduction\nIndustrial digital transformation is driving changes to the Operational Technology (OT) landscape, making it more connected to the internet and IT systems and solutions. With OT/IT convergence, OT environments are leveraging more IT solutions to improve productivity and efficiency of production operations. Industrial customers can use AWS edge and cloud services to securely access OT data and use AWS IoT services, artificial intelligence, and machine learning capabilities to transform their operations. Continuous digitization and progressive inter-connectivity of the production environment is important to capture value from industrial IoT (IIoT) solutions. While this new and expanding \xe2\x80\x9cphysical meets digital\xe2\x80\x9d connectivity enables great rewards, it also introduces new cyber security risk, which needs to be properly managed. Industrial organizations should be aware of the risks that come with the benefits of this convergence and cloud adoption. To help companies plan their industrial digital transformation safely and securely, AWS recommends a multi-layered approach to secure industrial control systems and operational technology (ICS/OT), IIoT and cloud environments, which is captured in the Ten Security golden rules for IIoT solutions.\nIn this blog post, we introduce you to the AWS IIoT security workshop which can help you get started with hands on learning focused on how to secure your smart factory and IIoT solutions by implementing the IIoT security golden rules using AWS services.\nAWS IIoT Security workshop\nTo get started, see the AWS IIoT security workshop. This workshop provides you with hands on education focused on how to use AWS IoT services and AWS Security services to safely and securely deploy and monitor industrial IoT security solutions. Working through a scenario in a smart factory with computer numerical control (CNC) machines sending data to AWS, you will be able to detect and remediate data exfiltration from the factory using network anomaly detection and process anomaly detection. Detecting and responding to cyber events early can limit the damage to mission critical OT operations and can help you improve your organization\xe2\x80\x99s cyber security posture. Let\xe2\x80\x99s start by taking a look at the workshop architecture.\nAWS IIoT Security workshop architecture\nThe workshop architecture shows a factory with CNC machines sending data to an edge gateway for edge data processing. Data from the edge device is sent to AWS for data storage, processing, analytics, and visualization. In this workshop, we will emulate CNC machine data using an Ignition OPC UA server. OPC UA is a modern communications protocol for industrial automation which is used for data collection and control by IIoT and smart factory applications and platforms. It is an open standard, and allows the Ignition OPC UA server interface to seamlessly connect to the OPC UA client on AWS IoT SiteWise gateway. The OPC UA server sends data to a gateway device deployed on an Amazon EC2, which runs AWS IoT Greengrass. An AWS IoT SiteWise gateway component installed on AWS IoT Greengrass streams the data to AWS IoT SiteWise in the cloud.\nAWS IoT SiteWise Monitor is used to visualize the data in near real-time while AWS IoT SiteWise metrics are used to create custom aggregates and metrics. A malicious script will be injected into the gateway device to simulate a cyber event. AWS IoT Device Defender is used to audit and monitor your fleet of IoT devices. AWS IoT SiteWise metrics detect process anomalies, which could indicate a cyber event. We will also be looking into mitigation approaches as well. Once a security anomaly is detected, you will investigate and take mitigating actions, such as quarantining the anomalous device. AWS Security Hub can be used to provide a centralized view of security alerts across your factory and cloud environments when implementing IIoT solutions.\nPrerequisites\nTo conduct the workshop, you will need the following:\nAWS Account with admin privileges. If you don\xe2\x80\x99t have an AWS Account follow the instructions to create one. If you are participating in an AWS event, an account can be provided by AWS.\nBasic AWS IoT knowledge. For familiarity you can look at Getting started with AWS IoT workshop\nLaptop or computer with a browser installed\nAccess to a remote desktop client\nBasic Linux knowledge\nBasic Python skills\nKnowledge about AWS IoT SiteWise. For familiarity you can look at AWS IoT SiteWise workshop\nAWS IoT Greengrass V2. For familiarity you can look at Greengrass V2 workshop\nLearning objectives and services used\nIn this workshop you will learn how to:\nDetect data exfiltration from the smart factory using AWS IoT Device Defender device side metrics such as Bytes out, Packets out, and Destination IP\nInvestigate the data exfiltration security event and take a mitigation action to quarantine the device using AWS IoT Device Defender\nSecure gateway configuration by protecting the Ignition server authentication secret using AWS Secrets Manager and by configuring authentication and encryption between the Ignition OPC UA server and AWS IoT SiteWise Gateway OPC UA client to enable secure OPC UA communications\nDetecting process anomalies using AWS IoT SiteWise monitor and alarms\nAuditing against IoT security best practices using AWS IoT Device Defender Audit followed by importing the audit findings into AWS Security Hub\nYou will use the following key services:\nAWS IoT Greengrass V2\nAmazon IoT SiteWise\nIgnition OPC UA Server\nAWS IoT Core\nAWS IoT Device Defender\nAWS Security Hub\nAWS Secrets Manager\nSolution deployment\nAWS resources for the workshop are created with AWS CloudFormation. The CloudFormation stack that you are going to launch during the workshop works with nested stacks. Nested stacks are stacks created as part of other stacks. You will see more than one CloudFormation stack being launched. Nested stacks are marked as NESTED in the AWS CloudFormation console. The CloudFormation stacks will create the following resources:\nAmazon EC2 instance as your OPC UA server simulating industrial data.\nAWS Cloud9 environment as your workplace where you will install AWS IoT Greengrass V2 and the AWS IoT SiteWise components.\nNote: To streamline the installation process during the workshop, the CloudFormation template is configured to automatically deploy AWS IoT Greengrass V2 and AWS IoT SiteWise components on the AWS Cloud9 environment. Once the CloudFormation template is launched, a fully functional AWS IoT Greengrass environment will be running via a Docker container with the components deployed and running on the AWS IoT Greengrass core device. For more details you can check out AWS IoT Greengrass Accelerators project.\nS3 Bucket with an auto generated name.\nVPC with public subnet and Security Groups for Cloud9 and EC2 instances.\nIAM user to provide credentials for the Cloud9 environment.\nLambda function to create CNC machine model and asset in AWS IoT SiteWise.\nMosquitto based MQTT broker deployed on an EC2 instance. The Mosquitto MQTT broker is used as an external broker to receive the simulated malicious data.\nAmazon SNS topic to notify you when the AWS IoT Device Defender report is ready.\nLambda function that imports the Device Defender findings into AWS Security Hub.\n'"
60,Trigger AWS IoT Greengrass component deployments from AWS CodeCommit,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/trigger-aws-iot-greengrass-component-deployments-from-aws-codecommit/,"b'As computing power extends into Internet of Thing (IoT) devices, software becomes more and more crucial to making decisions, processing data, and providing insight to end users at the device. Devices are the backbone of many businesses and applications. Regardless of the use case, customers benefit from quick, widespread deployment of software updates and improvements across device fleets. With AWS IoT Greengrass V2, AWS customers can easily build, deploy, and manage custom device software as AWS IoT Greengrass components. AWS IoT Greengrass handles activities such as tracking the component versions, managing the fleets of devices, and orchestrating component updates.\nIn this blog, we will demonstrate how to automate the deployment of component changes on AWS IoT Greengrass. This solution reduces the time it takes developers to deploy custom device software across a fleet from minutes to seconds, saving developers valuable time and improving agility.\nIntroduction\nThis solution uses a centralized code repository with Continuous Integration and Continuous Deployment (CI/CD) to assist in following DevOps best practices. For more information about CI/CD and DevOps on AWS, reference the Practicing Continuous Integration and Continuous Delivery on AWS whitepaper.\nIn this article, we will present a method for automating the deployment of custom AWS IoT Greengrass components. AWS IoT Greengrass includes AWS-provided components to add common functionality to your devices and also allows for custom components creation. Custom components may analyze data, display a front-end dashboard, or run an application with intermittent connectivity to the cloud. For demonstration purposes, we will be using three pre-built components. However, this solution is easily adaptable to components you may already have running in your environment.\nThis solution clones a Github repository to an AWS CodeCommit repository as an example implementation. Other implementations can be used as long as the code is deployed to CodeCommit. At the beginning of the steps below, we will outline how to clone a repository from Github into AWS CodeCommit. However, other code repositories can be imported into AWS CodeCommit if necessary for your use case. For more information on migrating code to an AWS CodeCommit repo, see the documentation here.\nPrerequisites\nFor this walk through, you should have the following prerequisites:\nAn AWS account\nA basic understanding of:\nAWS CloudFormation\nAWS IoT Core\nAWS IoT Greengrass\nAWS CodeBuild\nAWS CodeCommit\nAWS CodePipeline\nInstall AWS CLI\nMake sure you have installed and setup AWS CLI with the necessary permissions:\nAWS CLI Setup\nInstall CDK\nHere is a guide to Get Started with AWS CDK:\nInstalling aws-cdk\nPlease verify the cdk package version installed is 2.x or higher.\nSolution Overview\nThe solution utilizes an AWS CodeCommit repo to store the component code, a Lambda function to trigger the build, and AWS CodeBuild to orchestrate the deployment of the updated component. Finally, AWS IoT Greengrass pushes the updated component out to the devices.\nA commit is made to the AWS CodeCommit repository. An Amazon CloudWatch Event event has been configured such that any time a commit is made to the configured repository, the event occurs.\nAn AWS Lambda function is triggered by the Amazon CloudWatch Event.  The AWS Lambda function first determines if the commit was made on a file that is part of the source code for the component. If that is the case, it saves the component name(s) as AWS CodeBuild Project Environment Variables and starts the AWS CodePipeline.\nAWS CodeBuild job is triggered by the AWS CodePipeline. The AWS CodeBuild job runs a shell script which deploys the component to the devices using the AWS IoT Greengrass API.\nAWS Cloud Development Kit (AWS CDK) is a framework for defining cloud infrastructure in code, and provisioning it via AWS CloudFormation. If you are new to the AWS CDK, follow the getting started guide. \nThe CDK will deploy the following resources in the AWS Account:\nAWS CodePipeline\nAWS Lambda\nCodeBuild\nAmazon S3\n[Optional] Amazon EC2\nAWS CLI v2\nAWS CDK v2\nDeploy the solution\nCreate and clone code repository\nCreate CodeCommit Project\nGo to AWS CodeCommit Console\nSelect Create Repository\nProvide name for the repository. For example ggv2-cdk-blog-test\nChoose Create\nClone the CodeCommit repository on your local machine, for example if the CodeCommit repository is named  ggv2-cdk-blog:\ngit clone codecommit::us-east-2://ggv2-cdk-blog\ncd ggv2-cdk-blog\nShell\nIn order to deploy the cdk you will need to copy the cdk contents from github repository:\nTo easily copy the contents of this github project to your new project, copy export.zip to your CodeCommit project directory, and unzip\nNote: The .gitignore file is part of export.zip, if you don\xe2\x80\x99t find the file after unzip check your settings to view hidden files in the IDE\nSource code updates\nPlease update following attributes in cdk.json file with appropriate values:\naccount\nAccount ID of your AWS account, for example: 1234567890\ncodecommit_repository_arn\nFor example: arn:aws:codecommit:us-east-1:111111111111:MyDemo*\nregion\nFor example: us-east-1\ncreate_core_device\nacceptable values are true or false\nEven if you choose false make sure to provide a name for an existing core device in the option core_device_name and core_device_group_name\ndefault_branch_name\n branch to track for the CodePipeline. For example: main\n  core_device_name\n The name of your new/existing Greengrass core device.\n core_device_group_name\nThe name of your new/existing Greengrass core device group.\n project_prefix\n Any string value\nDeploy CDK pipeline\nSet up your virtualenv for Python. You may need to use python3 in replacement of python, depending on your local python configuration.\npython3 -m venv .venv\nsource .venv/bin/activate\npython3 -m pip install -r requirements.txt\nBash\nBootstrap your account/region for CDK \xe2\x80\x93 replace the appropriate variables (i.e. ACCOUNT-ID, REGION, ADMIN-PROFILE) before executing.\nCommands to run:\nexport CDK_NEW_BOOTSTRAP=1 \nnpx cdk bootstrap --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\\naws://ACCOUNT-ID/REGION \nBash\n Note: Verify you have the AdministratorAccess policy in your AWS account or you can customize the policy to be used by AWS CDK in order to create AWS resources\nFor example, like this:\nexport CDK_NEW_BOOTSTRAP=1                                    \nnpx cdk bootstrap --cloudformation-execution-policies arn:aws:iam::aws:policy/<CustomPolicy> \\\naws://123456789/us-east-2\nBash\nCommit updates to the repository and deploy the CDK app. You may need to git push origin <main branch name> , instead of git push\ngit add --all\ngit commit -m ""initial commit""\ngit push\ncdk deploy\nBas\n Optional: To update export.zip in your own project, run the following:\ngit archive -o ./export.zip HEAD\nBas\nThe code repository for this blog has sample custom AWS IoT Greengrass components, that will display the message Hello World in the log file of the component. The next section will provide more information about building your own AWS IoT Greengrass components.\nAdding your own AWS IoT Greengrass components\nThe code in this blog uses Greengrass Development Kit (gdk cli) in order to build and publish Greengrass components. For more information please check this documentation.\nTo add new components to the project, create a new component directory in the components directory. Make sure your components include the following:\ngdk-config.json (GDK configuration file)\nbuildspec.yml (for CodeBuild)\nrequirements.txt (for Python dependencies; currently used by provided buildspec.yml examples)\nBuilding AWS IoT Greengrass components\nHere are 5 tips to build AWS IoT Greengrass v2 Components. For more information please refer below:\nDevelop AWS IoT Greengrass components\nUse the AWS IoT Device SDK to communicate with the Greengrass nucleus, other components, and AWS IoT Core\nCleaning Up\nCDK Cleanup\nRun the following command from your terminal on the path where the code repository exists (Example: Users/johndoe/desktop/ggv2-cdk-blog ~ %)\n cdk destroy\n'"
61,Connected vehicles telemetry – Processing Protobuf messages with AWS IoT Core,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/protobuf_with_aws_iot/,"b'Introduction\nIn connect vehicles applications, telemetry data is usually very extensive, containing structure and unstructured data. To send data over to the Cloud you can use Protocol Buffers (Protobuf \xe2\x80\x93 binary format). Protobuf provides the application with an efficient yet well structured compressing mechanism. The built-in protocol documentation makes data serialization and deserialization more manageable than JavaScript object notation (JSON). However, producer and consumer must operate on a defined shared schema to encode and decode it properly.\nIn this blog we will cover the best practices while using Protobuf to encoding and decoding. You will also learn step-by-step how to use AWS IoT Core and AWS Lambda to ingest and process Protobuf for consumption\nSolution Architecture\nFigure 1. Architecture diagram\nSolution overview\nYou will simulate a connected car and authenticate it to AWS IoT Core. The device will first encode the payload and send it over Message Queuing Telemetry Transport (MQTT) to AWS IoT Core\nOnce the message is received by AWS IoT Core you will use AWS IoT Rule which will invoke an AWS Lambda function in order to decode the payload.\nThe rule sends messages to Amazon Kinesis Data Firehouse and then stores it in Amazon S3\nEach time a new file is written on Simple Storage Service (Amazon S3), AWS Glue Crawler will crawl the data to infer the schema and make it available in the AWS Glue Data Catalog.\nWe will the use Amazon Athena to do Ad-hoc querying an visualize it in Amazon quick sight.\nAWS IoT Core\nAWS IoT Core securely connects your simulated IoT device and routes the encoded messages to AWS services without managing the underlying infrastructure. You can then use rules for AWS IoT to decode your payload data and forward it to Amazon Kinesis Data Firehose.\nAmazon Kinesis Data Firehose\nAmazon Kinesis Data Firehose captures the incoming data from your rule for AWS IoT and load it as batch in parquet format in our Amazon S3 Bucket.\nAmazon S3\nAmazon S3 serves as a data lake for your data that you can use for further analysis and visualization.\nAWS Glue\nThe AWS Glue Data Catalog is your persistent store for the metadata (e.g., schema and location of the data). It is a managed service that lets you store, annotate, and share metadata in the AWS Cloud.\nFor writing files to Amazon S3, you can use AWS Glue crawler to scan data, classify it, perform schema extractions, and store the metadata automatically in the AWS Glue Data Catalog.\nAmazon Athena\nAmazon Athena uses the metadata classification from AWS Glue Data Catalog to perform ad-hoc queries on the data.\nAmazon QuickSight\nYou can visualize your data and build a custom dashboard using Amazon QuickSight\nSolution Walkthrough\nPre-requisite\nYou need a PC with a web browser, preferably with the latest version of Chrome / FireFox\nYou must have access to an AWS account with Administrator Access privileges\nIf you don\xe2\x80\x99t have an AWS Account follow the instructions to create one.\nYou will use Cloud formation template to create the setup environment and you can delete the environment once done\nFollowing AWS services will be used:\nAWS IoT Core\nAmazon Kinesis Data Firehose\nAmazon S3\nAWS Glue\nAmazon Athena\nAmazon QuickSight\nAmazon Cloud9\nSetup solution\nCreating and setup AWS Cloud9 environment\nUse the following link to setup the test environment using AWS Cloud9 for this blog AWS IoT Device Client Workshop (IoT quickstart) (workshops.aws). You may  pick any region close to your location.\nSetup AWS IoT Thing and SDK\nOpen Cloud9 terminal and let\xe2\x80\x99s setup Python SDK for us to use.\nCreate the folder you will use to connect the  IoT thing using Cloud9 terminal window.\nmkdir -p /home/ubuntu/environment/protobuf-python-aws-iot-device/certs\ncd /home/ubuntu/environment/protobuf-python-aws-iot-device/\nBash\nSetup the dependencies:\ncopy and paste the following requirements.txt\nAWSIoTPythonSDK==1.5.2\nnumpy==1.19.5\nprotobuf==3.19.4\nand then run the following:\npython3 -m venv venv\nsource ./venv/bin/activate\npip install -r requirements.txt\ndeactivate\nSetup your AWS IoT Thing follow steps outlined here.\nOnce we have created the thing let\xe2\x80\x99s upload these certificates in our Cloud9 instance for us to connect from there.\nUpload the newly created certificates and RootCA into \xe2\x80\x98certs\xe2\x80\x99 folder created earlier.\nDevice and Schema\nHere is the Protobuf schema that we will use. Create file the following file automotive.proto file and copy and paste the following content.\nsyntax = ""proto2"";\npackage automotive;\nmessage Automotive {\n  required float battery_level = 1;\n  required float battery_health = 2;\n  required float battery_discharge_rate = 3;\n  required float wheel_rpm = 4;\n  required float mileage_left = 5;\n}\nYou will need to compile and generate the appropriate library, here is the corresponding file you can use and save into following file automotive_pb2.py\n# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: automotive.proto\n""""""Generated protocol buffer code.""""""\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n_sym_db = _symbol_database.Default()\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b\'\\n\\x10\\x61utomotive.proto\\x12\\nautomotive\\""\\x84\\x01\\n\\nAutomotive\\x12\\x15\\n\\rbattery_level\\x18\\x01 \\x02(\\x02\\x12\\x16\\n\\x0e\\x62\\x61ttery_health\\x18\\x02 \\x02(\\x02\\x12\\x1e\\n\\x16\\x62\\x61ttery_discharge_rate\\x18\\x03 \\x02(\\x02\\x12\\x11\\n\\twheel_rpm\\x18\\x04 \\x02(\\x02\\x12\\x14\\n\\x0cmileage_left\\x18\\x05 \\x02(\\x02\')\n\n\n_AUTOMOTIVE = DESCRIPTOR.message_types_by_name[\'Automotive\']\nAutomotive = _reflection.GeneratedProtocolMessageType(\'Automotive\', (_message.Message,), {\n  \'DESCRIPTOR\' : _AUTOMOTIVE,\n  \'__module__\' : \'automotive_pb2\'\n  # @@protoc_insertion_point(class_scope:automotive.Automotive)\n  })\n_sym_db.RegisterMessage(Automotive)\nif _descriptor._USE_C_DESCRIPTORS == False:\n  DESCRIPTOR._options = None\n  _AUTOMOTIVE._serialized_start=33\n  _AUTOMOTIVE._serialized_end=165\n# @@protoc_insertion_point(module_scope)\nBash\nLet\xe2\x80\x99s create our file that will execute our device simulation. Copy and paste the following content in a file named main.py\n\'\'\'\n/*\n * Copyright 2010-2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the ""License"").\n * You may not use this file except in compliance with the License.\n * A copy of the License is located at\n *\n *  http://aws.amazon.com/apache2.0\n *\n * or in the ""license"" file accompanying this file. This file is distributed\n * on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n * express or implied. See the License for the specific language governing\n * permissions and limitations under the License.\n */\n \'\'\'\n\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\nimport logging\nimport time\nimport argparse\nimport json\nimport automotive_pb2\nimport numpy as np\n\nAllowedActions = [\'both\', \'publish\', \'subscribe\']\n\n# Custom MQTT message callback\ndef customCallback(client, userdata, message):\n    print(""Received a new message: "")\n    print(message.payload)\n    print(""from topic: "")\n    print(message.topic)\n    print(""--------------\\n\\n"")\n\n\n# Read in command-line parameters\nparser = argparse.ArgumentParser()\nparser.add_argument(""-e"", ""--endpoint"", action=""store"", required=True, dest=""host"", help=""Your AWS IoT custom endpoint"")\nparser.add_argument(""-r"", ""--rootCA"", action=""store"", required=True, dest=""rootCAPath"", help=""Root CA file path"")\nparser.add_argument(""-c"", ""--cert"", action=""store"", dest=""certificatePath"", help=""Certificate file path"")\nparser.add_argument(""-k"", ""--key"", action=""store"", dest=""privateKeyPath"", help=""Private key file path"")\nparser.add_argument(""-p"", ""--port"", action=""store"", dest=""port"", type=int, help=""Port number override"")\nparser.add_argument(""-w"", ""--websocket"", action=""store_true"", dest=""useWebsocket"", default=False,\n                    help=""Use MQTT over WebSocket"")\nparser.add_argument(""-id"", ""--clientId"", action=""store"", dest=""clientId"", default=""basicPubSub"",\n                    help=""Targeted client id"")\nparser.add_argument(""-t"", ""--topic"", action=""store"", dest=""topic"", default=""sdk/test/Python"", help=""Targeted topic"")\nparser.add_argument(""-m"", ""--mode"", action=""store"", dest=""mode"", default=""both"",\n                    help=""Operation modes: %s""%str(AllowedActions))\nparser.add_argument(""-M"", ""--message"", action=""store"", dest=""message"", default=""Hello World!"",\n                    help=""Message to publish"")\n\nargs = parser.parse_args()\nhost = args.host\nrootCAPath = args.rootCAPath\ncertificatePath = args.certificatePath\nprivateKeyPath = args.privateKeyPath\nport = args.port\nuseWebsocket = args.useWebsocket\nclientId = args.clientId\ntopic = args.topic\n\nif args.mode not in AllowedActions:\n    parser.error(""Unknown --mode option %s. Must be one of %s"" % (args.mode, str(AllowedActions)))\n    exit(2)\n\nif args.useWebsocket and args.certificatePath and args.privateKeyPath:\n    parser.error(""X.509 cert authentication and WebSocket are mutual exclusive. Please pick one."")\n    exit(2)\n\nif not args.useWebsocket and (not args.certificatePath or not args.privateKeyPath):\n    parser.error(""Missing credentials for authentication."")\n    exit(2)\n\n# Port defaults\nif args.useWebsocket and not args.port:  # When no port override for WebSocket, default to 443\n    port = 443\nif not args.useWebsocket and not args.port:  # When no port override for non-WebSocket, default to 8883\n    port = 8883\n\n# Configure logging\nlogger = logging.getLogger(""AWSIoTPythonSDK.core"")\nlogger.setLevel(logging.DEBUG)\nstreamHandler = logging.StreamHandler()\nformatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\nstreamHandler.setFormatter(formatter)\nlogger.addHandler(streamHandler)\n\n# Init AWSIoTMQTTClient\nmyAWSIoTMQTTClient = None\nif useWebsocket:\n    myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId, useWebsocket=True)\n    myAWSIoTMQTTClient.configureEndpoint(host, port)\n    myAWSIoTMQTTClient.configureCredentials(rootCAPath)\nelse:\n    myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)\n    myAWSIoTMQTTClient.configureEndpoint(host, port)\n    myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)\n\n# AWSIoTMQTTClient connection configuration\nmyAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20)\nmyAWSIoTMQTTClient.configureOfflinePublishQueueing(-1)  # Infinite offline Publish queueing\nmyAWSIoTMQTTClient.configureDrainingFrequency(2)  # Draining: 2 Hz\nmyAWSIoTMQTTClient.configureConnectDisconnectTimeout(10)  # 10 sec\nmyAWSIoTMQTTClient.configureMQTTOperationTimeout(5)  # 5 sec\n\n# Connect and subscribe to AWS IoT\nmyAWSIoTMQTTClient.connect()\nif args.mode == \'both\' or args.mode == \'subscribe\':\n    myAWSIoTMQTTClient.subscribe(topic, 1, customCallback)\ntime.sleep(2)\n\n# Publish to the same topic in a loop forever\nloopCount = 0\nautomotive = automotive_pb2.Automotive()\ndataPointsSin = np.linspace(-np.pi, np.pi,100)\nwhile True:\n    if args.mode == \'both\' or args.mode == \'publish\':\n        # 100 linearly spaced numbers\n        automotive.battery_level = abs(dataPointsSin[loopCount % 100]) / np.pi\n        automotive.battery_health = 100 - loopCount % 100\n        automotive.battery_discharge_rate = 4.8\n        automotive.wheel_rpm = 3000\n        automotive.mileage_left = loopCount % 100\n        message = bytearray(automotive.SerializeToString())\n        myAWSIoTMQTTClient.publish(topic, message, 1)\n        if args.mode == \'publish\':\n            print(\'Published topic %s: %s\\n\' % (topic, message))\n        loopCount += 1\n    time.sleep(1)\n    # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0.\nPython\nLambda layer\nCreate a lambda layer that will be used to store protobuf libraries, then execute the following command:\nmkdir -p ./protobuf/python/custom\ncd ./protobuf/python\npip3 install protobuf --target .                                      \ncd custom\ncp ../../../automotive_pb2.py ./\necho \'custom\' >> ../protobuf-*.dist-info/namespace_packages.txt\necho \'custom/demo_pb2.py\' >> ../protobuf-*.dist-info/RECORD\necho \'custom\' >> ../protobuf-*.dist-info/top_level.txt\ncd ../../\nzip -r protobuf.zip .\naws lambda publish-layer-version --layer-name protobuf --zip-file fileb://protobuf.zip --compatible-runtimes python3.8\nBash\nSetup S3 bucket\nWe will in a first time create an S3 bucket where will store our data and which we will query it from. Create an S3 bucket, fill out a name, for the name will be \xe2\x80\x9cACCOUNT-ID-connected-evs\xe2\x80\x9d, leave the rest as default. and click on create bucket. Please note your bucket name as we will reusing it through the whole this blog.\nFigure 2.\nSetup Kinesis data firehose\nCreate a delivery stream, the delivery stream will write the received data from the connected cars to Amazon S3. Select source Direct PUT, destination Amazon S3, and fill out a name, for me it will be: \xe2\x80\x9cmy-delivery-stream-connected-evs\xe2\x80\x9c.\nFigure 3.\nIn destination settings, select the S3 bucket that you previously created, as bucket prefix, fill out \xe2\x80\x9craw\xe2\x80\x9c and error prefix as \xe2\x80\x9derrors\xe2\x80\x9c. Leave out the rest as default and wait few minutes before this completes.\nFigure 4.\nSetup AWS IoT Rule\nCreate the AWS IoT Rule, we will use the IoT rule during the lambda creation, please note your rule name. You need to select all data coming from the topic connected-cars/data, and then invoke the incoming data with a lambda function in order to decode the protobuf encoded payload. You first need to encode the binary string in base64. For the SQL statement please copy and paste the following, please replace ACCOUNT_ID with your account ID\nSelect Message Routing\nSelect Rules\nSelect Create rule\nGive Rule name (i.e. we are using \xe2\x80\x9cMyConnectedEVSRuleToFirehose\xe2\x80\x9d)\nGive Rule description\nUse the following query for the rule: SELECT aws_lambda(""arn:aws:lambda:us-east-1:ACCOUNT_ID:function:my-protobuf-decoder"", {""data"": encode(*, ""base64""), ""clientId"": clientId()}) as payload, timestamp() as p_time FROM \'connected-cars/data\'\nSelect Next\nIn Attach rule actions\nSelect settings as per Figure 6\nSelect Add action\nSelect Next\nIn Review and Create\nSelect Create\nFigure 5.\nFigure 6.\nSetup lambda\nCreate AWS Lambda function and give the same name as earlier when creating AWS IoT Rule. Pick Python 3.8 for runtime.\nFigure 7.\nAfter creating the layer for the protobuf part, please use the following code:\nimport json\nimport base64\nfrom custom import automotive_pb2\n\nprint(\'Loading function\')\n\ndef lambda_handler(event, context):\n    print(""Received event: "" + json.dumps(event, indent=2))\n\n    ret = {}    \n\n    data = event[""data""]\n    payload_data_decoded = base64.b64decode(data)\n    automotive = automotive_pb2.Automotive()\n    automotive.ParseFromString(payload_data_decoded)\n    elems = automotive.ListFields()\n    for elem in elems:\n        ret[elem[0].name] = elem[1]\n    ret[""clientId""] = event[""clientId""]\n    return ret\nPython\nIn the configuration tab and permissions, go to the resource-based policy and click on add permission. We need to add the necessary permission to allow the iot rule to invoke our function. when specifying the arn, please use the same name for the rule you created. Click on save.\nFigure 8.\nFinally, we will use the previously created layer, for that, go in the layer part and Select \xe2\x80\x98Add a layer\xe2\x80\x98.\nFigure 9.\nFigure 10.\nProtobuf decode/encode\nFollowing JSON will be used for further encoding as Protobuf binary message.\n{\n    ""battery_level"": 100,\n    ""battery_health"" : 50,\n    ""battery_discharge_rate"" : 4.8,\n    ""wheel_rpm"" : 3000,\n    ""mileage_left"" : 88\n}\nJSON\nLet\xe2\x80\x99s publish our first message and check if everything is working:\nSample command:\nUsing certificate and AWS IoT thing created earlier, these certificates used in the parameter to send the message (replace xxxx with relevant values for your setup).\nsource ./venv/bin/activate\npython3 main.py -e xxxx-ats.iot.us-east-1.amazonaws.com -c ./certs/xxxx-certificate.pem.crt -r ./certs/AmazonRootCA1.pem -t connected-cars/data -m eza -k ./certs/xxxx-private.pem.key --mode publish\nBash\nFigure 11.\nGo to your bucket after few minutes, you should see files being written.\nSetup AWS Glue Crawler\nWe\xe2\x80\x99re going to now create the Glue Crawler that will be responsible for creating and updating the schema of our data. You can create a crawler on the following link. For crawler name, mine will be: \xe2\x80\x98my_connected_evs_crawler\xe2\x80\x99.\nFor the Crawler source type pick Data stores, for Repeat crawls of S3 data stores pick Crawl all folders. In the Add Data store leave everything by default but for the include path select your S3 bucket and the raw folder. For me it will be s3://ACCOUNT_ID-connected-evs/raw. click on next. Do not add another datastore. Give a name to your role. For the frequency leave as default.\nFor Configure the crawler\xe2\x80\x99s output, click on add database, add a database name my_connected_evs_db and leave the rest blank. Leave the rest as default and click next.\nSelect your crawler, and click on run your crawler. The status of your crawler should be showing starting, When the status of your crawler is stopping, go check your table in your database. You should see the following for your raw table:\nFigure 12.\nSetup Amazon Athena\nGo to the Amazon Athena console, you can setup your Amazon Athena query results by following this link.\nSelect your database and table that you used for the crawler. Run the following query:\nSELECT * FROM raw;\nFigure 13.\nVisualize data using Amazon QuickSight\nTo setup QuickSight, please follow this link.\nIn QuickSight, let\xe2\x80\x99s first create our dataset.  Click on Dataset on the left. The source of our dataset will be Amazon Athena that we used previously to preview our data. If you want to check the other sources that are supported, please follow the following link. Please note that in our case we use Amazon Athena for simplicity to do ad hoc querying and rapid dash-boarding.\nFigure 14.\nOn the following screen, click on new dataset.\nFigure 15.\nThen click on Athena.\nFigure 16.\nThen give a name to your data source, for us, it will be: \xe2\x80\x98my-evs-athena-data-source\xe2\x80\x99. Make to sure to the validate connection. Then click on Create Data source.\nFigure 17.\nChose the AwsDataCatalog and our db my_connected_evs_db and the raw table. Click on Use custom SQL.\nFigure 18.\nWe will flatten the payload struct with the following query. Copy and paste the query and name the custom SQL query and click on Confirm query.\nSELECT payload.battery_level as battery_level, payload.battery_health as battery_health, payload.battery_discharge_rate as battery_discharge_rate, payload.wheel_rpm as wheel_rpm, payload.mileage_left as mileage_left, p_time, payload.clientId as client_id FROM ""my_connected_evs_db"".""raw"";\nSQL\nFigure 19.\nLeave the rest by default and click on visualize.\nFigure 20.\nHere are some examples of visualization\nClick on the lower left hand side on the table diagram and on each dimension. You should see your data in a table format.\nFigure 21.\n'"
62,How BISSELL migrated to a new IoT platform using AWS Connected Device Framework,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-bissell-migrated-to-a-new-iot-platform-using-aws-connected-device-framework/,"b'Introduction\nBISSELL is a family-owned business with over 145 years crafting premium cleaning products that exceed consumer expectations. BISSELL offers a full range of floor care and air treatment products. Connected vacuum cleaners \xe2\x80\x93 particularly robotic vacuums \xe2\x80\x93 are a growing segment of their business. BISSELL has 1 million registered vacuum devices in their existing IoT Platform powered by AWS IoT, and currently 25% of those devices are connected in the field. With increasing adoption of connected vacuum cleaners around the world, BISSELL is expecting 1 million devices to be connected in the field in the near future. BISSELL wanted to ensure its IoT platform could scale with this rapid expected growth across product categories.\nBISSELL\xe2\x80\x99s home-grown legacy IoT platform on AWS included a suite of REST APIs that enabled different members of their IoT ecosystem to access platform data. The legacy platform worked and performed well, but BISSELL anticipated future pain points scaling the platform with new products and users.\nIn this blog post, we show how BISSELL worked with AWS Professional Services to improve their legacy REST APIs as part of migrating their IoT platform to a new architecture based on the AWS Connected Device Framework (CDF). We identify pain points of the legacy REST API architecture and then describe how we redesigned it using CDF\xe2\x80\x99s micro-services approach of grouping related REST APIs into a single Lambda with proxy integration. Next, we highlight how the new architecture contributed to improving the scalability, performance, and cost efficiency of BISSELL\xe2\x80\x99s IoT platform.\nLegacy architecture challenges\nThe serverless REST APIs on BISSELL\xe2\x80\x99s legacy IoT platform were built using BISSELL\xe2\x80\x99s Onion Architecture, which is a serverless design pattern comprised of multiple concentric layers of Lambda functions interfacing with each other towards the data access layer in the core. BISSELL decided to create the Onion Architecture due to high code re-usability.\nThe domain layer of the architecture contains a set of Amazon API Gateways, and each Amazon API Gateway serves REST API requests originating from a specific domain. These domains represent clients of the BISSELL IoT platform such as a mobile app or a web portal. Underneath the domain layer is the service layer of the Onion Architecture that is comprised of Lambda functions, each of which are dedicated to service a specific REST API request. Finally, the data access layer of the Onion Architecture contains an additional set of Lambda functions that implement Data Access Object (DAO) interfaces. The data access layer Lambda functions access IoT data stored in Amazon DynamoDB tables using the DAO interfaces. The following image shows the different layers of the Onion Architecture.\nWhen a client invokes a REST API, the Amazon API Gateway first initiates the Lambda function in the service layer that handles the requested REST API operation. Next, this Lambda function invokes a set of Lambda functions in the data access layer as needed to complete the requested operation. Finally, the Lambda functions return results back to the calling Lambda function in the service layer, which constructs and returns the final response to the Amazon API Gateways.\nThe Onion Architecture promotes a highly reusable code base by allowing the service and data access layers to share Lambda functions. However, it also presents challenges when trying to add features and scale to hundreds of thousands of devices. First, maintaining more than 500 Lambda functions made it difficult for BISSELL to perform rapid and frequent updates to scale the existing REST APIs. Second, the growing chain of invocations between individual Lambdas coupled with inconsistent database design negatively impacted the platform\xe2\x80\x99s performance and cost efficiency. Furthermore, debugging issues became challenging with developers having to look across multiple Lambdas to find root causes.\nMigrating to the new architecture\nBISSELL and AWS Professional Services decided to migrate the legacy platform to a new solution developed using the AWS Connected Device Framework (CDF). CDF is an open source framework for building an enterprise IoT platform. It provides a set of production-ready micro-services called CDF modules, all architected and implemented using native AWS services and best practices. The CDF modules form a layer above the AWS building blocks as shown in the following architecture diagram.\nThe team began by addressing the inner-most data access layer of the Onion Architecture. The legacy IoT platform lacked a clearly defined device registry to manage a large fleet of devices and their relationships to other resources within the platform such as users, device types, and firmware. In the legacy platform, data for devices and other resources was scattered across multiple Amazon DynamoDB tables. This issue, coupled with both static and dynamic data coexisting across tables, led to increased system complexity, stale data, and cost inefficiency. For instance, BISSELL had to create a series of Amazon DynamoDB queries across multiple tables just to construct a list of devices owned by a particular user. This operation consisted of the following steps:\nThe Data Access Object (DAO) first need to query the \xe2\x80\x9cUsers Table\xe2\x80\x9d using a user ID as the sort key to obtain all groups that are associated with the user.\nFrom the returned groups, an array of device IDs is constructed by pulling out device ID from each group.\nThe DAO iterates over each device ID, having to query multiple tables to construct a complete device object on each iteration.\nThe diagram following illustrates this issue through a mock scenario.\nBISSELL and AWS Professional Services used the CDF Asset Library to build a comprehensive device registry defined as a single graph database using Amazon Neptune. During the re-implementation phase, the team migrated infrequently changing or otherwise static data (for example, device-friendly name, user email address) to the Asset Library. On the other hand, frequently changing data, such as device usage metrics, was maintained in Amazon DynamoDB tables. This resulted in a simplified data access layer that allowed the team to improve performance and cost of the upstream data consumption.\nThe diagram following illustrates how the CDF Asset Library is able to reduce the number of DynamoDB queries from the multiple queries required with the legacy setup to a single Neptune query.\nAfter optimizing the platform\xe2\x80\x99s data access layer with the CDF Asset Library, the team worked on migrating from the legacy Onion Architecture to a new architecture based on CDF\xe2\x80\x99s micro-services design paradigm. BISSELL migrated their legacy REST API architecture as part of the CDF Application Layer, also called the CDF Facade layer. The Facade layer is an application layer that contains BISSELL\xe2\x80\x99s unique business logic and orchestrates the underlying CDF Core modules. The CDF Core modules are implemented as a Lambda with proxy integration, which groups dispersed sets of Lambda functions into a single Lambda function for handling a common service such as the CDF Asset Library. The open source [AWS Serverless Express] Node Package Manager (NPM) package allows you to easily build serverless REST APIs using the Express framework on top of Amazon API Gateway.\nBISSELL\xe2\x80\x99s CDF architecture provides a Lambda configured with proxy integration that serves as a single point of entry for all API requests made by common clients such as the mobile and web applications. For instance, BISSELL\xe2\x80\x99s mobile application sends all requests to a dedicated Amazon API Gateway. From there, Amazon API Gateway uses proxy integration to route any requests to a Lambda dedicated to handling all API operations for the mobile application. The Lambda itself breaks down into three layers. When the Lambda is invoked, the API request first enters a controller, where it determines what service to call based on the request\xe2\x80\x99s endpoint. The service then calls the Data Access Object (DAO) to access the platform\xe2\x80\x99s databases hosted in Amazon Neptune and Amazon DynamoDB.\nBy migrating to the CDF architecture, BISSELL reduced the number of Lambda functions in the platform by 90 percent. The new controller, service, and DAO design consolidated the code base and reduced troubleshooting efforts. Another key benefit was the ability to deploy the Lambda as a local Express server, which contributed to speeding up development and troubleshooting issues even faster. This solution provided the BISSELL development team the ability to quickly deploy and test the API execution on a developer\xe2\x80\x99s local machine.\n'"
63,How SysAid manages agents behind restricted firewall rules with AWS IoT Core,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-sysaid-manages-agents-behind-restricted-firewall-rules-with-aws-iot-core/,"b'This blog post will outline how SysAid uses AWS IoT Core and the MQTT over WebSocket Secure communication protocol at scale for managing remote software agents and overcoming restricted firewall rules securely.\nSysAid is a global Software as a service (SaaS) automation company that provides IT Service Management (ITSM) and Asset Management solutions, which serve thousands of customers. Sysaid provides software for IT teams to control all aspects of service management.\nIntroduction\nSysAid software agents are installed at the customer\xe2\x80\x99s site. Agents collect telemetry and status from IT resources such as computers and printers and relay it to the SysAid SaaS service running on AWS. Occasionally, the SaaS backend needs to reach the agents, instructing them to take specific actions, such as configuration changes.\nTo enable communication, the simplest solution is for the agents to initiate connection with the cloud on specific allowed IPs and ports, periodically polling for the latest instructions. However, this approach generates a lot of network traffic.\nAs an example, if an agent polls once per second, that\xe2\x80\x99s 86,400 requests a day. Over thousands of customers, that can easily come to billions of requests a month or more. Additionally, since over 95% of the time the server has no message waiting for the agent, most of this traffic is redundant and unnecessary.\nFurthermore, corporate firewalls often restrict inbound and outbound traffic to be transmitted over a small range of TCP ports. This is done as a security measure to limit the attack surface for possible cyber-attacks. Standard ports for protocols like HTTPS traffic (port 443) are left open, but others that are used for less common protocols, such as MQTT (port 8883) may be intentionally blocked. If you are manufacturing IoT devices that will ultimately be used in IT environments that you do not control, this can cause serious headaches to negotiate separately with each customer IT department to open port 8883 in their firewall so that your devices can connect to your IoT application running on AWS IoT Core.\nAlthough AWS IoT Core supports MQTT with TLS client authentication on port 443, some SysAid clients only allow outgoing traffic to specific IP addresses. As AWS IoT Core endpoints will resolve to continuously changing IP address ranges over time, SysAid needed a solution, otherwise agents would not be able to connect behind the customer\xe2\x80\x99s firewall.\nThe following principles were critical for the solution:\nReduce agents\xe2\x80\x99 traffic by avoiding empty poll response.\nSupport a large scale of tens of thousands of agents and billions of messages.\nEncrypt traffic at transit.\nAbility to recover from disconnects.\nAbility to authenticate & authorize agents, allowing them to receive only the messages intended specifically for them.\nBe fully managed. Avoid undifferentiated heavy lifting of managing infrastructure.\nSolution overview\nSysAid chose AWS IoT Core for its solution as it allows secured connectivity with any number of devices to the cloud and to other devices without requiring the provisioning or management of servers.\nWith AWS IoT Core, they can manage authorization of devices and provision unique identities at scale. Furthermore, its Message Broker feature enables reliable and fast MQTT communication across SysAid agents\xe2\x80\x99 fleets.\nUsing MQTT\xe2\x80\x99s publisher/subscriber model allows SysAid to avoid redundant polling. Instead SysAid\xe2\x80\x99s servers send messages to the agent only when needed, drastically reducing traffic.\nBy using a topic structure like:\ncustomer-id/device-id/message-subject\nmessages can be sent directly to the agent customer-a in account customer-b. So, notifying a configuration change can be done by sending message to topic:\ncustomer-b/computer-a/configuration-changes\nThe agent on computer-a can receive all messages directed to it by subscribing to a topic filter like:\ncustomer-b/computer-a/#\nThe topic filters wildcard can be used by the agent to subscribe to multiple configuration topics. This should be handled with care to avoid overloading the agent if it cannot process all incoming messages.\nBut, devices are not always guaranteed to be connected. Sometimes backend services will send configuration changes to the device topic, but the device, being offline, will not be able to accept it.\nAWS IoT Core has two features which help overcome device connectivity issues:\nMQTT retained messages for AWS IoT Core \xe2\x80\x93 This feature allows you to store a single message per a given MQTT topic for delivery to any current and future topic subscribers.\nAWS IoT Device Shadow service \xe2\x80\x93 Shadows provide a reliable data store for devices, apps, and other cloud services to share data. They enable devices, apps, and other cloud services to connect and disconnect without losing a device\xe2\x80\x99s state.\nUsing retained messages, SysAid agents are able to receive their initial configuration message when re-subscribing to a topic after disconnection.\nAnd how does this improve security?\nThe security model is simple. AWS IoT provides a thing registry that helps you manage things. A thing is a representation of a specific device or logical entity. Every device connected to AWS IoT has a thing representation on the thing registry.\nFor a device to be able to authenticate using an x.509 certificate, the certificate must be registered and associated with an IoT policy.\nThe IoT policy sets the authorizations granted to the device. We can, for example, limit the device to specific actions such as: connect, publish, and subscribe on specific topics.\nBelow is an example policy allowing a device to publish and subscribe only to its own topics by using AWS IoT Core policy variables:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n  {\n      ""Action"": ""iot:Connect"",\n      ""Effect"": ""Allow"",\n      ""Resource"": ""arn:aws:iot:<regoin>:<account>:client/${iot:Connection.Thing.ThingName}""\n    },\n    {\n      ""Action"": [\n        ""iot:Receive"",\n        ""iot:Publish""\n      ],\n      ""Effect"": ""Allow"",\n      ""Resource"": [\n        ""arn:aws:iot:<regoin>:<account>:topic/customer-a/${iot:Connection.Thing.ThingName}/*""\n      ]\n    },\n    {\n      ""Action"": [\n        ""iot:Subscribe""\n      ],\n      ""Effect"": ""Allow"",\n      ""Resource"": [\n        ""arn:aws:iot:<regoin>:<account>:topicfilter/customer-a/${iot:Connection.Thing.ThingName}/*""\n      ]\n    }\n  ]\n}\nJSON\nNotice how this policy uses a thing policy variable to simplify authorization. Instead of having to generate a policy for each thing, we can have a single policy which takes the thing name as a variable and restricts that thing to its own topics.\nNow that security and scale concerns are addressed, SysAid still had to overcome the challenge of firewalls restricting outbound traffic for specific IP and port.\nThis is where the breadth and depth of AWS IoT Core comes in handy. AWS IoT Core supports a number of protocols and authentication methods allowing flexibility when connecting edge devices to AWS.\nUsing the MQTT over WebSockets protocol, the agent can relay messages to Web proxy servers attached to a static Elastic IP address, and listening on port 443, running at SysAid VPC.\nIn turn, the HTTP proxy forwards the traffic to AWS IoT endpoints.\nMQTT over WebSocket protocol supports two authentication methods:\nSignature Version 4 (SigV4)\nCustom authentication\nUsing SigV4 requires the agent to connect AWS IoT Core using SigV4 credentials rather than the device certificate. To acquire SigV4 credentials the agent uses AWS IoT Core credential provider, which allows using the built-in X.509 certificate as the unique device identity to authenticate AWS requests. This eliminates the need to store an access key ID and a secret access key on your device.\nArchitecture diagram:\nRequest flow:\nAgent resolves healthy static IP\nAgent acquires SigV4 credentials\nAgent signs a request and sends it to the Web proxy\nWeb proxy forwards the request to an AWS IoT Core endpoint\nWeb proxies DNS is managed using Route 53 DNS Fail-over configuration. In simple configurations, you create a group of records that all have the same name and type, such as a group of weighted records with a type of A for example.com. You then configure Route 53 to check the health of the corresponding resources. Route 53 responds to DNS queries based on the health of your resources.\n'"
64,Build resilient IoT device applications that remain active using the AWS IoT Device SDKs,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/build-resilient-iot-device-applications-that-remain-active-using-the-aws-iot-device-sdks/,"b'Introduction\nIn this blog post, we provide recommendations on how you can build resilient Internet of Things (IoT) device applications using AWS IoT Core, AWS IoT Device SDKs, and MQTT protocol. These recommendations cover: managing your MQTT client, publishing and reception of messages, initiating the device application process, setting up the network connection, performing software updates, and integrating hardware features for resilience.\nArguably, all IoT device applications will experience scenarios that can lead to a loss of service. Some examples are: loss of, or unstable network connectivity, loss of power, faults in your own software, device hardware faults, server-side disconnects, and authentication errors.\nAs an IoT device application builder, it is your responsibility to build your applications to be resilient to failure scenarios, so that you can avoid or mitigate any loss of service. When you deploy your device applications at the edge, on-site intervention can be impractical or impossible.\nThe goal of resilience is to make sure your IoT device application remains active and performs as per specification. If the application is not active, it will not be able to mitigate against failure. A resilient device application can seamlessly restore service quickly.\nTo help illustrate the recommendations, we first describe a basic IoT device application built on AWS IoT. Then we describe how you can incrementally apply the recommendations to the device application. When building your own device application, you can decide which recommendations to adopt, and when. You can achieve resilience early and increase resilience over time.\nTime to read 8 minutes\nLearning level Advanced (300)\nServices used\nAWS IoT Core\nAWS IoT Device Management\nAWS IoT Device SDKs\nBuilding a basic IoT device application\nYou can build a basic MQTT-based IoT device application using AWS IoT technologies. At a minimum, your application will need to support:\nApproach for provisioning with AWS IoT Core.\nConfiguration with your AWS IoT Core endpoint address.\nConfiguration of credentials to connect to that endpoint address.\nIntegration with an MQTT client that matches your chosen protocol, programming language and runtime environment.\nConnection to AWS IoT Core using the MQTT client and correct protocol (MQTT or MQTT over WebSocket).\nSubscription to MQTT topics, publish messages, and receive messages.\nWe recommend that you integrate your device application with an AWS IoT Device SDK and use the MQTT client from your chosen SDK. The AWS IoT Device SDKs have resilience features built-in and closely integrate with AWS IoT Core resilience functionality (see later).\nSee the tutorial Connecting a device to AWS IoT Core by using the AWS IoT Device SDK for a full guide on building a basic IoT device application with the AWS IoT Device SDK.\nAfter you have built your IoT device application, you can upload it to an edge device and run it. If you have correctly configured the application (with your endpoint & credentials) it will connect to AWS IoT Core and be able to publish and receive messages.\nSo far, so good. You have built a basic IoT device application and it is working. However, what if something bad happens? What if the network connection is lost? Or if the MQTT broker refuses the connection because of an authentication error? What if your application crashes?\nIf your device application does not specifically handle negative scenarios, it is likely to exit, leading to loss of service. This is where the following recommendations help.\nRecommendations:\n1) Manage your MQTT connection\nAWS IoT Core, the AWS IoT Device SDKs, and the MQTT protocol, were built with resilience in mind. After your MQTT client has established a connection with AWS IoT Core, your device application can publish and receive MQTT messages, despite transient connectivity interruptions.\nTo fine-tune the configuration of the MQTT client, you can setQuality of Service (QoS) on message delivery, or configure MQTT keep-alive, but you will need to do additional development work to achieve full resilience to negative scenarios.\nHere are some techniques for managing the MQTT connection for your IoT device application:\nTechnique Description\nTake advantage of AWS IoT Core and MQTT resilience features\nCarefully read the documentation for your MQTT client (e.g. AWS IoT Device SDK) and the AWS IoT Core MQTT protocol connections.\nThe following AWS IoT Core and MQTT features may help your device application achieve greater resilience.\nPersistent sessions \xe2\x80\x93 When your client reconnects after being temporarily disconnected, AWS IoT Core persistent sessions will restore topic subscriptions, and deliver messages published to your client with QoS 1.\nRetained messages \xe2\x80\x93 AWS IoT Core retained messages can deliver messages published to your client when it comes online, even after a significant period offline.\nLast Will and Testament (LWT) \xe2\x80\x93 AWS IoT Core LWT can deliver a message if your client disconnects abruptly, and your cloud application can act on this message.\nQoS \xe2\x80\x93 If your device application publishes messages with QoS 1, you will be able to check for success or failure of message delivery, and your application can react accordingly.\nEncapsulate the MQTT client In your device application software, encapsulate the MQTT client and fully control the life-cycle of the client, along with anything else required to create, configure, and start the client. After the client is fully encapsulated, you can create, configure, use, and ultimately destroy the client, multiple times, whilst your application is active.\nHandle MQTT client events Configure your device application to listen to MQTT client events, and act on them (see later). Useful events include: connect, disconnect, error, interrupt, and resume.\nTrack the MQTT connection state Maintain a flag which tracks state of the MQTT connection. Use the connect, disconnect, interrupt, and resume events for this. Adapt how your device application manages subscriptions and messages when there is no connection (see the next recommendation).\nRecover from server-side disconnects An MQTT broker might decide to disconnect your MQTT connection, and you should expect this to happen. This includes the AWS IoT Core Message Broker. Your device application should be ready to handle disconnects whenever and as often as they happen. However, in practice, MQTT connections should remain open for many days or weeks.\nRecover from authentication failure Do not assume that an authentication failure is fatal to your device application. Some authentication failures could be temporary, such as when the server-side policy is not yet active. Be sure that your application recovers if an authentication failure prevents connection (see technique on connection health checks).\nHandle MQTT client errors / exceptions Catch all MQTT client errors and exceptions. Observe which are fatal, and which are warnings or transient, and adapt accordingly. If the connection becomes unusable, disconnect the connection.\nPerform connection health checks on interval On interval, check the health of your MQTT connection, and remediate. For example:\nIf the credentials are missing, check again later.\nIf there is no MQTT client, try to create one.\nIf there is no MQTT connection, try to create one.\nIf the MQTT connection is not connected, try to connect it.\nDefine strategy for connection retries When retrying connection attempts, use an exponential backoff strategy. This can protect against excessive connection attempts when multiple clients are affected by the same underlying issue.\n2) Manage MQTT subscriptions and message flow\nWhen your main device application logic wants to publish a message, or is expecting to receive a message, the low-level resilience of the MQTT connection should not be a concern. By adopting a modular approach to your application design, your main application logic, and the MQTT client can be treated as separate concerns which are loosely coupled.\nTo enable this separation of concerns, you can introduce a software layer between the main device application logic, and the logic which manages the MQTT connection. This layer can buffer outbound messages until the connection is available, and it can verify that subscriptions for inbound messages are configured correctly, regardless of the state of the underlying MQTT client or connection.\nIf you decide to buffer outbound messages in your device application, you should consider how this will work when publishing messages using the AWS IoT Device SDK. Your application should track the success or failure of each message publish attempt, and use this to update the message buffer in your application. If your application is publishing messages with QoS 1, then you can expect the SDK to buffer those messages when the connection is momentarily offline. To help guide your implementation, refer to the documentation for your chosen AWS IoT Device SDK. Check how to use the SDK to publish messages with QoS 1, and how to receive the associated PUBACK response.\n3) Manage your IoT device application process\nNow that your IoT device application is internally resilient, you can shift focus to the environment your application runs in.\nThe specific runtime environment your IoT device application will run in might vary according to your requirements, but the following resilience techniques remain important for all types of runtime environment.\nTechnique Description\nProcess management (PM) Instead of managing your application process yourself, try to use well-known process management software. Examples include PM2 or Docker.\nGraceful start up and shut down All operating systems have mechanisms for starting up and shutting down applications. Your application should integrate with these mechanisms, in a way that is idiomatic to the operating system your application is deployed to. In particular, choose the correct runlevel for your application, so that any resources your application depends on are available, and for your application to start and stop at the appropriate moment.\nOperating system signals Operating systems can signal your application. Your application should respect these signals and react accordingly. For instance, if the operating system signals that your application should exit, then the application can tidy up resources before exiting. An example resource to tidy up would be to gracefully end the MQTT connection, and to flush any buffered messages to local storage.\nApplication logging and metrics Your application should log useful operational information. If there are negative scenarios to which your application should react, then logging the details of these can be helpful to verify that your application is resilient. Logging can also help you to learn of scenarios that you have not yet mitigated against.\n4) Manage your network connection\nIf there is no network connectivity on the device your IoT device application cannot establish an MQTT connection. Ensuring the network connection is carefully configured and managed, to achieve maximum connection uptime, is an important part of ensuring your device application is resilient to negative scenarios.\nWe recommend that you do not try to implement network connectivity resilience yourself, because this requires significant implementation, testing, and on-going maintenance effort. You can instead use existing solutions that are known to work. As an example, many systems come with the Network Manager and Modem Manager packages pre-installed. These packages work together to keep devices connected to networks and will mitigate against negative scenarios. You can configure connection failure fallback strategies to select an alternative network.\nIf you are using cellular networks for your network connectivity you might be able to take advantage of advanced features offered by your provider, such as roaming between networks. On the cloud-side, you might be able to inspect and analyze the connectivity status of your device fleet, and adjust device connectivity options for maximum resilience. Some vendors give you the capability to signal your devices, which you can use to perform recovery if your device application is stuck (such as initiating a remote boot).\n5) Manage your software updates\nThe ability to remotely update your IoT device application and device software is an important factor to support resilience in your IoT application.\nAn IoT device application is rarely finished when you deploy it to devices for the first time. You will need to deploy new features and bug fixes to your application with a software update. Similarly, the operating system on your devices will likely need updates, and it is especially important that you can rapidly deploy security fixes.\nYou can build a software update capability using the AWS IoT Device Management Jobs. You can use this to define remote operations that can be sent to and run on your devices in an agent device application that you create. When you implement software updates, you are likely to create an agent device application that runs separately from your main device application. This agent application also needs to be designed for resilience, similar to your main application.\n6) Enable device hardware resilience features\nCheck if your IoT device integrates technology that may assist with resilience, such as a watchdog timer or a UPS device.\nIf your device has a watchdog timer, then you can configure the watchdog to take action if your device becomes unresponsive or develops a fault, such as rebooting the device.\nIf your device is powered via an uninterruptible power supply (UPS) device, you might be able to configure it to signal your device application when the power supply will be lost. Your device application can initiate an ordered shutdown, or notify your cloud application of the situation.\n7) Adopt a strategy for Disaster Recovery and High Availability\nOur final recommendation is that you adopt a strategy for Disaster Recovery (DR) and High Availability (HA) for your IoT device application. A good starting point is the Disaster Recovery for AWS IoT Implementation Guide and the Disaster Recovery for AWS IoT solution. To understand how AWS IoT Core approaches resilience, you can read Resilience in AWS IoT Core.\n'"
65,How commercial IoT providers can build dynamic rules for real-time insights on AWS,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-commercial-iot-providers-can-build-dynamic-rules-for-real-time-insights-on-aws/,"b'This blog post introduces a real case from a world-class commercial IoT service provider that uses AWS IoT to run its telemetry data analytics business that fulfills diverse and real-time data analysis requirements for clients.\nThe key challenge the business faced was ingesting telemetry data in different formats to AWS IoT and generating real-time data analytics. Additionally, the business\xe2\x80\x99 solution needed to align to its client\xe2\x80\x99s specific aggregation rules so that end users could receive analytics results with business insights. To solve this, the business used AWS services to build its IoT data analytics solution, implement the composition of telemetry data with predefined analytics rules, and leverage the composition to generate business insights. This solution enabled the business to adjust telemetry data structures and aggregation rules and to generate real-time insights according to the new structures and rules.\nIn this blog, we walk through a reference architecture and describe how the commercial IoT solution uses AWS IoT Core to ingest telemetry data from devices and other systems and receive analytic rules from clients, and uses Amazon Kinesis to perform telemetry data analytics.\nIntroduction\nMany enterprises that have registered and monitored their devices and sensors on IoT platforms are seeking business insights from telemetry data analytics. Their use cases range from building management to smart offices, connected vehicles, smart cities, and more; all require real-time analytics based on various data types and analysis policies. The diversity of data analytics introduces challenges to commercial IoT service providers (CIoT) who service many IoT solution suppliers and their clients. CIoT service providers expect to ingest both telemetry data and analytic rules to aggregate the data instantly.\nThe collaboration between IoT solution suppliers and their clients on the platform owned by CIoT service providers is shown in Figure 1.\nFigure 1: CIoT service provider, IoT solution suppliers, and clients\n1) The IoT solution suppliers onboard their IoT solutions and devices to the platform in different ways and then offer specific services to their clients. Those solutions and devices generate a large quantity of telemetry data in specific types. All the data types and data sources from the suppliers must be supported, and real-time data processing and aggregation need to be fulfilled.\n2) The client runs their business on the solution and devices offered by the IoT solution supplier and needs data analytics from multiple points of view to gain valuable business insights from the solution. The client needs to define analytic rules based on the telemetry data structure and the solution from the supplier to deliver analytic results according to the rules.\n3) When the data is analyzed, the CIoT service provider must ensure the platform can integrate correct data with correct clients. For example, if a client uses a supplier\xe2\x80\x99s smart building solution on the CIoT service provider\xe2\x80\x99s platform, the platform must pick up that specific client\xe2\x80\x99s building data and analyze it according to rules for those specific buildings. Without this, the analytics will make no sense to the client, and might even cause negative consequences.\nSolution overview\nThe CIoT service provider requires a data ingestion and analytics solution running on its CIoT platform to orchestrate rules and data aggregation from multiple third party IoT solutions. The solution in this blog post supports these requirements by: 1) receiving telemetry data ingested from different types of data sources, 2) dynamically combining telemetry data and predefined analytic rules, 3) preprocessing telemetry data and performing real-time data aggregation.\nThe solution helps the CIoT service provider easily achieve three key benefits for their suppliers:\n1. The suppliers can connect their devices to the CIoT platform through AWS IoT Core. Those devices directly register in AWS IoT Core and send telemetry data to topics of AWS IoT Core.\n2. The suppliers can run their own IoT solutions on AWS, and leverage any approach such as AWS IoT Core to accept telemetry data sent by their devices. The suppliers can perform data filtering and cleaning before transmitting the data to the CIoT platform through Amazon EventBridge.\n3. The suppliers can operate their IoT solutions on their preferred cloud providers or on-premises data centers, and execute device management on their own. They only need to submit the telemetry data to the CIoT platform to leverage the data analytic functionality.\nCommercial IoT platform for telemetry data ingestion and analytics\nAs shown in the box framed by the black dotted line in Figure 2, the telemetry data from the devices or the suppliers\xe2\x80\x99 solutions is received by AWS IoT Core, Amazon EventBridge, Amazon Kinesis, or Amazon Simple Queue Service (SQS). The AWS Lambda functions behind those services preprocess the telemetry data for the analysis and publish the processed data into Amazon Kinesis Data Streams. Those data streams are entries of telemetry data to be analyzed.\nAs shown in the box framed by the blue dotted line, the clients of the IoT solutions suppliers define the analytic rules through APIs powered by Amazon API Gateway and AWS Lambda, and the rules are stored in Amazon DynamoDB tables. A lambda function periodically publishes those rules into Amazon Kinesis Data Streams, triggered by the timers generated in the event rule of Amazon EventBridge. Those data streams are entries of analytic rules used in data aggregation.\nIn the box framed by the orange dotted line, Amazon Kinesis Data Analytics as the analyzing executor in the CIoT platform absorbs telemetry data and aggregation rules from the data streams and uses the rules to aggregate the data. After the aggregation, the results are pushed into the data streams for aggregation results. A lambda function validates the formats of the results and detects abnormalities in the results such as empty values or out-of-range. Once an error is discovered, the lambda function invokes Amazon Simple Notification Service (Amazon SNS) to notify the analytic operators that there might be issues in data, rules, or their composition. Amazon Kinesis Data Firehose loads the telemetry data from Amazon Kinesis Data Streams, and stores the data into Amazon Simple Storage Service (Amazon S3) for analytics (e.g. analysis by year) in the future.\nFigure 2: Data analytics solution architecture on CIoT platform\nFlexible data aggregation on the CIoT platform\nWhen the rules are published to the data stream used for aggregation rules, Amazon Kinesis Data Analytics broadcasts them to all the downstream tasks, and the aggregation running on those tasks retrieves the rules locally and follows them to accumulate and compute the telemetry data. For example, the rule below defines the data aggregation method for a smart building solution. The lambda function produces the rules and invokes the APIs to write them to the data streams. The attributes tenantId, sourceId, and streamName are used to group telemetry data. Only the telemetry data including the same tenantId, sourceId, and streamName is put into the same group. A tenant is a client of the smart building solution, such as a hotel owner. The sourceId is the floor number in a certain hotel building, and streamName identifies environment data types such as humidity and temperature.\nruleId: 003,\ngroupingAttributes: [tenantId, sourceId, streamName],\naccumulatorAttribute: value,\naggregationFunction: AVG,\nwindowSizeInMs: 60000\nAs shown in Figure 3, after grouping the telemetry data, Amazon Kinesis Data Analytics uses a time window to accumulate telemetry data. The size of the time window is defined in the rule. In this example, we use 60 second and 180 second tumbling windows. Amazon Kinesis Data Analytics also supports the sliding window. For each telemetry data group, Amazon Kinesis Data Analytics maintains 2 tumbling windows to separately accumulate data every 60s and every 180s. Once the timer for the window starts, Amazon Kinesis Data Analytics caches telemetry data until the timer expires. The timer expiration triggers Amazon Kinesis Data Analytics to compute the cached data at the same time the window tumbles to clean the old data and cache new data. In this way, Amazon Kinesis Data Analytics frames the values of accumulatorAttribute of the telemetry data in a certain time range and computes those values in the function assigned in aggregationFunction, such as computing the average or maximum of the values. With data accumulation and computing, Amazon Kinesis Data Analytics completes data aggregation and publishes the results into the data streams for analytic result output.\nAs seen in the example in Figure 3:\nThe average humidity on the 1st floor of building #1 is output per minute. The maximum humidity of the 1st floor of building #1 is output every 3 minutes.\nThe average temperature of the 1st floor of building #1 is output per minute. The maximum temperature of the 1st floor of building #1 is output every 3 minutes.\nThe average temperature of the 18th floor of building #8 is output per minute. The maximum temperature of the 18th floor of building #8 is output every 3 minutes.\nFigure 3: Telemetry data aggregation according to predefined rules in Amazon Kinesis Data Analytics\nSummary\nBy leveraging the data analytics solution introduced in this blog, instead of building a dedicated analytics function for each IoT solution on the CIoT platform, the clients simply ingest analytic rules that dynamically control data aggregation. By doing so, the clients easily gain real-time insights specific to their business. IoT solution suppliers and CIoT platform owners no longer have to operate a large number of solution-specific data analytic modules, freeing them to focus on data analytic rule development for deeper business insights.\nWe look forward to seeing how you use this solution to start an IoT data analysis business with AWS. Get started with AWS IoT by going to the AWS Management Console and sending data to AWS IoT Core.\nAbout the author\nShi Yin is a senior IoT consultant from AWS Professional Services, based in California. Shi has worked with many enterprise customers to leverage AWS IoT services to build IoT solutions and platforms, e.g., Smart Home, Connected Vehicles, Commercial IoT, and Industrial IoT, etc.'"
66,Synadia builds next generation pill verification systems with AWS IoT and ML,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/synadia-builds-next-generation-pill-verification-systems-with-aws-iot-and-ml/,"b'U.S. prescription medications costs are approaching $500 billion a year and growing up to 7% annually, according to a House Ways and Means Committee report. In this market, billions of dollars in unused medicines are still wasted annually due to traditional packaging that usually contains more pills or tablets than those prescribed by physicians. Automated pill dispensing is the process of dispensing pills into a pouch/container using an automated process. This is an important step in optimizing this supply chain and avoiding pill wastage. Pharmaceutical companies use visual inspection systems to identify potential packaging errors that are then manually corrected by skilled pharmacists.\nThe introduction of these visual inspection systems for multiple pills in a single pouch introduced new challenges in this supply chain. Traditional machine vision applications often rely on rule-based inspection with static images. Over the last two decades, pharmaceutical companies have used these traditional image processing techniques to validate the contents of these pouches with mixed results. Static image validation created a high level of false negative and false positive results, which increased the need for additional manual controls and hardware calibration due to the sensitivity of the image validation. This lack of traceability and auditability proves that existing solutions do not achieve the high-standards the pharmaceutical market requires. The stand-alone nature of these visual inspection systems results in an inefficient process where pharmacists manually open and correct the contents of the prescription and generate higher waste in the process.\nExample of a Pill Pack\nThis blog post covers how Synadia Software b.v (Synadia) and Amazon Web Services (AWS) developed a new cloud-based quality assurance solution for pill validation using machine learning (ML) capabilities. Using AWS technology, the next generation of pill-dispensing machines can verify dispensed pills using self-learning algorithms that automatically adjust for new pills and adapt to local conditions. We present a cloud-based solution that contains machine learning algorithms that leverage all the image history to automatically learn and upgrade the latest pill recognition models and deploy them to the pill-dispensing machines.\nCurrent pill-dispensing challenges\nToday, pill-dispensing machines require canisters to be loaded with pills prior to executing a batch job. De-blistering, which is the action to remove a pill from its blister, is a separate manual, error-prone process which takes place before batch order execution and is performed by a group of trained and licensed professionals.\nMachines take pills from canisters and, based on the order, package pills into plastic pouches. When a batch is ready, strings of pouches are loaded into a separate machine, which performs quality checks to confirm that each pouch has the correct pills and amount. Each quality assurance (QA) machine needs separate training to perform the necessary QA checks. The QA machines flag when they detect discrepancies, which requires an expensive human intervention to resolve. The error rate of such machines is approximately 13%.\nSynadia has developed an automatic pill-dispensing machine for the European market. The solution is comprised of a centrally managed network of connected machines with the capability to dynamically receive input and then dispense and package the required types of pills into pouches. The automated process aims to provide higher accuracy for the de-blistering process to achieve consistent results. Using ML models, Synadia can set up a centralized QA mechanism for pill distribution. This eliminates the need to maintain QA models in each location.\nSolution walkthrough\nReference Architecture of the presented solution\nQA is setup in two steps:\nTrain: learn from existing data. This step requires massive computing resources and needs to be centralized; therefore, it is implemented on AWS.\nInference: make decisions about data. This step needs a lot less computing power and needs near-real time (1 sec) processing. This is achieved by ML Inference on AWS IoT Greengrass.\nEvery pill-dispensing machine has AWS IoT Greengrass installed. AWS IoT Greengrass has the ability to route messages locally among devices, between devices, and then the cloud, as well as run machine learning inferences on the device. A camera installed on the pill-dispensing machine takes pictures of the pills. To train the models, the images are sent to AWS IoT Core through AWS IoT Greengrass and stored on Amazon Simple Storage Service (Amazon S3). The images are used by Amazon SageMaker to train the QA model.\nThe model inferences get deployed to AWS IoT Greengrass and are executed through an AWS Lambda function. Based on the outcome of the inference and predefined rules, an action is taken on whether the pill recognition is correct, providing a notification to the customer.\nReporting on pill dispensing and supply chain is centralized and reported through Amazon QuickSight. Error codes and operating manuals are stored in Amazon S3 and available for quick search through Amazon Kendra.\nPill dispensing machine hardware\nCamera setup in the pill-dispensing machine\nThe initial setup consists of a camera connected to Programmable Logic Controller (PLC ) and local compute running AWS IoT Greengrass. To create ideal lighting conditions, a custom flashlight based on a Printed Circuit Board (PCB )that is positioned around the camera. When a pill is dropped at the camera position, the PLC sends an MQTT message to the broker at AWS IoT Greengrass, which executes a Lambda function to trigger the camera. When the image is received and processed, the PLC receives another MQTT message to start the next action.\nThis is a model of a next generation pill-dispensing machine that can collect one or more pills from their primary containers placed in the square boxes and dispense them into a pouch into the central outlet.\nThis is a zoomed version of the pill racks showing the placement of the pills in their primary containers.\nPill dispensing machine canister. A pill falls from the left-hand side conduct (01), and falls inside the canister (02), where a diaphragm waits to be opened for further processing (03).\nIngesting data into AWS\nData ingestion is done through MQTT protocol using AWS IoT Core. The main AWS IoT Greengrass and AWS Lambda application takes snapshots of pills, runs these through a classification model, and then sends this information via MQTT to AWS IoT Core.\nThe payload consists of a pill identification coupled with the classification probability. In scenarios where the probability is lower than a predefined threshold, the device can then upload the image to an Amazon S3 bucket for further investigation.\nRunning ML training in the cloud\nThere are many ways to identify the type of pill captured in the image. While the obvious choice would be to use an object detection model, we re-framed the solution to use an image classification model. Images are always expected to contain exactly one pill in a small canister. Hence, by setting up the camera so that it frames only the pill inside the canister large enough to be seen, an image classification model is able to recognize the pill features to discern among pill types. This enables us to use a well-known classification neural network model such as ResNet-50 to identify the pills.\nTo train the model, we take advantage of transfer learning to achieve high accuracy with very few samples. We work with a small sample of 200 images, split into 120 images for training, 40 images for validation, and the remaining 40 images for test, representing 8 different pill categories. Transfer learning carries most of the low-level feature detection, thanks to being trained on over 14 million images from the ImageNet dataset, containing 1,000 categories. We train the top portion of the network to learn the specific classifier layers, while freezing the remaining layers with the ImageNet-trained parameters.\nThe pill-dispensing machine has metadata about the pill type about to be dispensed, hence we use this as the label for our ground truth annotations. In order to avoid over-fitting on the small set of 120 training images, we use an augmentation protocol that will generate new data to help the model become more robust. After carefully analyzing the data, we observed that the pills were positioned on a circular canister centered in the image, so rotating the image by any angle would generate a new image with the same-looking canister and pill, but with the pill in a different position. We also considered a mirroring flip for robustness. With this simple augmentation protocol, we generated a few thousand images that would help train a more robust model.\nWe trained the model using only 5 epochs (iterations over data) with a learning rate of 0.0001, quickly achieving a training and validation accuracy of 100%. We could optionally increase the performance of the model by fine-tuning some of the frozen layers. It\xe2\x80\x99s possible to improve upon a 100% accurate model because models are not optimized against accuracy, but instead against a loss function that measures the confidence of the responses of the model, called categorical cross-entropy (e.g., this is ibuprofen with an 84% confidence). We wanted to improve these confidence percentage results to make the model more robust against images where a pill might look ambiguous and its confidence of prediction is low.\nIn order to fine tune the model, we unfroze the last 26 layers of the model and set a slower learning rate of 0.00001. We ran our training script for 5 more epochs, reducing the original validation loss of 0.0079 to 0.0016. The model was still 100% accurate, but became more confident in its predictions.\nPill identification with ML inference on the edge\nThere are two ways of deploying a model. In a cloud-based deployment, the input data (an image) is sent from the IoT device upstream, where the model runs inference and returns the result back downstream. This can be a costly and slow solution, since large files need to be sent and processed, increasing latency and costs related to data volume. An edge deployment, however, places the model in the IoT device itself. This way, latency and the costs related to data volume vanish, as images can be processed within the device, and only reporting upstream the responses of the model.\nWe deployed the trained model using AWS IoT Greengrass. In order to make inference faster on the edge, we optimize the model using Amazon SageMaker Neo, an AWS service that is able to compress the model parameters and allows for faster inference without losing performance. Amazon SageMaker Neo requires a much lighter framework to be installed in the edge device, allowing for a simpler setup. Using Amazon SageMaker Neo, we were able to improve the inference speed from 0.1 to 0.03 seconds, preserving the aforementioned 100% accuracy.\nWe also considered the inference on the edge as a source of information for continuously improving the model. Since the pill-dispensing machine can provide metadata with the pill type in the canister, we proposed the following approach to identify and improve wrong detections. First, we collected images predicted incorrectly and uploaded them to Amazon S3 with the correct label. Second, we collected images predicted correctly, but with confidence below a certain threshold.\nAfter collecting enough new images (e.g.,1000), we re-triggered a training process, re-using the latest network parameters to transfer all the pill classification learning to date. This helps the system correct future misclassification, while at the same time improve the confidence on low-scoring predictions. The following architecture illustrates the full process of continuously learning and improving the model by collecting the pill labels from the dispenser.\nAWS architecture of the re-training process for pill recognition model improvement\nKey learning\xe2\x80\x99s\nInitially, the sample size was small. Also, the sampling of pills was not uniform. To improve sample variance, we used data augmentation techniques to increase the amount of data by adding slightly modified copies of already existing data, or newly created synthetic data from existing data. This also helped us remove data bias towards pill categories with more initial samples.\nInitially, the image captures were zoomed out, which meant that the object of interest (i.e., the pill pack) was not in focus and rather small. After experimenting with the camera position and focus, we found the right level of depth for the captured image, which showed a much larger pill for the machine learning model to recognize its relevant features.\nAmazon SageMaker Neo allowed us to achieve real time inference while at the same time reduce the footprint of the model artifact and the inference framework in the target device, allowing for a faster and simpler deployment.\n'"
67,Automate global device provisioning with AWS IoT Core and Amazon Route 53,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/automate-global-device-provisioning-with-aws-iot-core-and-amazon-route-53/,"b'Introduction\nUse AWS IoT Core together with Amazon Route 53 to choose an AWS Region based on geo location or latency and register your devices automatically when they connect for the first time to AWS IoT Core.\nTime to read 10 minutes\nLearning level 300\nServices used AWS IoT Core,Amazon Route53, Amazon Certificate Manager Private Certificate Authority\nBackground\nIn an earlier version of a similar blog, we demonstrated how to use AWS IoT Core, AWS Lambda, Amazon DynamoDB and Amazon API Gateway. With the new approach you can now create a setup with a less complex architecture.\nSince the earlier blog, AWS IoT Core has launched new features like fleet provisioning (April 2020) and configurable endpoints (March 2021). Combining these features with Amazon Route 53 traffic policies allows you to provision your devices globally without the need to write code. Devices only use the light weight Message Queuing Telemetry Transport (MQTT) protocol as opposed to the HTTPS approach covered in the earlier blog.\nSolution\nTo provision your devices with AWS IoT Core or to interact with the service you need to have an endpoint. You can build configurable endpoints for AWS IoT Core with a custom domain configuration. This blog post uses the Fully Qualified Domain Name (FQDN) global.iot.example.com. You can replace the FQDN with your own when creating your setup. With Amazon Route 53 you can create a traffic based policy to resolve the FQDN, for example you can use geolocation or latency-based routing.\nThis blog uses geolocation routing where Amazon Route 53 responds to Domain Name System (DNS) queries based on the location of your devices. The examples in this blog use two AWS Regions:\nIreland (eu-west-1)\nN. Virginia (us-east-1)\nFor devices in North America (NA), the FQDN resolves them to the IoT endpoint in us-east-1. The endpoint in eu-west-1 is the default endpoint for devices which are not based in NA.\nArchitecture\nThe following architecture diagram shows the provisioning workflow:\n(Optional) When you use just-in-time Provisioning (JITP), register your Certificate Authority (CA), for example Amazon Certificate Manger Private CA with AWS IoT Core in both regions.\nYour IoT device uses Amazon Route 53 to resolve your custom IoT endpoint global.iot.example.com. The DNS lookup returns an IoT endpoint from one of both regions depending on your device location.\nThe IoT device connects to the AWS IoT Core endpoint it received from the DNS resolution. The device is then automatically registered in the related AWS Region.\nFigure 1: Architecture diagram\nCreate custom domain configurations\nCreate your own custom domain configuration for the two regions as described in the AWS IoT Core developer guide. You must register your server certificates in AWS Certificate Manager (ACM) in both regions. After registering your server certificates, create a custom domain configuration for AWS IoT Core in both regions.\nConfigure Amazon Route 53 geolocation\nThis blog assumes that the domain example.com is served by Amazon Route 53 as a public hosted zone. The domain example.com serves as a sample domain name for this blog. To setup your environment, replace example.com with your domain. DNS records are created as type CNAME pointing to the AWS IoT endpoint. Use the following commands to get your AWS IoT endpoints.\nFor the us-east-1 region: aws iot describe-endpoint \xe2\x80\x93endpoint-type iot:Data-ATS \xe2\x80\x93region us-east-1\n\nFor the eu-west-1 region: aws iot describe-endpoint \xe2\x80\x93endpoint-type iot:Data-ATS \xe2\x80\x93region eu-west-1\nTo create DNS geolocation based records in Amazon Route 53 which resolve to your IoT endpoints depending on your geographical location:\nNavigate to the Amazon Route 53 console.\nIn the left menu, choose Hosted zones.\nUnder Hosted zones, choose example.com and then choose Create record.\nUnder Record name, enter global.iot.\nUnder Record type, choose CNAME.\nUnder Value, enter your AWS IoT Core endpoint for us-east-1 which looks similar to 123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com.\nUnder Routing policy, choose Geolocation.\nUnder Location, choose North America.\nUnder Record ID, enter US East IoT Global Endpoint.\nChoose Add another record.\nUnder Record name, enter global.iot.\nUnder Record type, choose CNAME.\nUnder Value, enter your AWS IoT Core endpoint for eu-west-1 which looks similar to 123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com.\nUnder Routing policy, choose Geolocation.\nUnder Location, choose Default.\nUnder Record ID, enter Default IoT Global Endpoint.\nChoose Create records.\nWhen records have been created you will see a message stating Records for example.com were successfully created.\n\nTo verify if your IoT endpoint is resolved as expected, you can use the checking tool in the Amazon Route 53 console or use tools like host, dig or nslookup on systems in different geo locations. Depending on which location you resolve the FQDN global.iot.example.com it should either resolve to the endpoint in us-east-1 if you are in North America or to the endpoint in eu-west-1 otherwise.\nWhen you use the Amazon Route 53 checking tool, enter Resolver IP address from a geolocation from where you want to perform the lookup. You can find for example AWS IP address ranges for AWS Regions in the AWS General Reference.\nYou can also use AWS CloudShell to test if your FQDN global.iot.example.com resolves according to the location you are in. Open an AWS CloudShell for example in us-west-2 and eu-central-1.\nInstall the package bind-utils in both AWS CloudShell environments:\nsudo yum -y install bind-utils\nWhen you resolve global.iot.example.com in AWS CloudShell in the us-west-2 region it should resolve to your IoT endpoint in us-east-1. In AWS CloudShell in eu-central-1 it shoud resolve to the IoT endpoint in eu-west-1. The output of the DNS lookup should look similar to the examples below.\nAWS CloudShell in us-west-2:\n$ host global.iot.example.com\nglobal.iot.example.com is an alias for 123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com.\n123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com has address 18.213.191.210\n123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com has address 34.199.197.35\n123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com has IPv6 address 2406:da00:ff00::2cc1:6e4b\n123456aaaaaaaa-ats.iot.us-east-1.amazonaws.com has IPv6 address 2406:da00:ff00::3403:e3c\nAWS CloudShell in eu-central-1:\n$ host global.iot.example.com \nglobal.iot.example.com is an alias for 123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com.\n123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com has address 34.246.55.152\n123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com has address 52.214.209.63\n123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com has IPv6 address 2a01:578:3::34d6:9eb8\n123456aaaaaaaa-ats.iot.eu-west-1.amazonaws.com has IPv6 address 2a01:578:3::22f3:3c77\nProvisioning\nAWS IoT Core provides various options to provision your devices. You can provision your devices in advance or just-in-time when they connect for the first time to your IoT endpoint. When you use global device provisioning together with registering your devices in advance, you need to create your device resources in every region where the device can potentially connect to.\nIf you want your devices to only be provisioned when they come online and only want to provision them in the region where they operate, you can use just-in-time provisioning. This blog post describes two just-in-time provisioning approaches, fleet provisioning and just-in-time provisioning.\nTo walk through the provisioning process, you can use the fleet and just-in-time provisioning exercises from the AWS IoT Device Management workshop. You can launch two workshop environments, one in a US region and another in a region outside the US to test provisioning scenarios with your global IoT endpoint.\nSetup fleet provisioning\nWith AWS IoT fleet provisioning, AWS IoT can generate and securely deliver device certificates and private keys to your devices when they connect to AWS IoT for the first time. This blog covers the approach on how to provision by claim. Each device can store the same claim certificate and private key. When devices connect for the first time to AWS IoT Core they are provisioned and receive their final key and certificate.\nTo use the same claim certificate in multiple regions, use the RegisterCertificateWithoutCA Application Programming Interface (API). With this API you can register your claim certificate without a Certificate Authority (CA). Assuming you add your claim certificate into the file provision-claim.certificate.pem you can use the following AWS Command Line Interface (AWS CLI) commands to register the certificate in both regions:\neu-west-1:\naws iot register-certificate-without-ca \\\n    --certificate-pem \\\n    file://provision-claim.certificate.pem \\\n    --region eu-west-1\nus-east-1:\naws iot register-certificate-without-ca \\\n    --certificate-pem \\\n    file://provision-claim.certificate.pem \\\n    --region us-east-1\nDifferent from the instructions in the workshop:\nRegister the claim certificate in both regions\nCreate the required resources, thing-group, provisioning template, IoT policy in both regions. Resources in the IoT policy include the AWS Region. Replace the AWS Region with the region where you are creating the policy.\nWhen you start the fleet provisioning process with the command fleetprovisioning.py, replace $IOT_ENDPOINT with your global IoT endpoint, in this blog global.iot.example.com.\nAfter you perform the steps from the exercise, your IoT device will be automatically registered with AWS IoT Core based on your device geolocation.\nUse just-in-time provisioning\nYou can register your devices when they first attempt to connect to AWS IoT with JITP. To use JITP you must bring your own certification authority and register it with AWS IoT Core. Then you must enable automatic registration for your CA and associate a provisioning template with it.\nYou must register your CA in both regions. Your device stores one device certificate issued by your CA regardless of the connecting region.\nDifferent from the instructions in the workshop:\nYou only need one CA and it must not be setup in any of your global provisioning regions.\nRegister your CA in both global regions.\nEnable JITP for your CA in both regions\nWhen you connect with the mosquitto_pub command to AWS IoT Core replace $IOT_ENDPOINT with your global IoT endpoint, in this blog global.iot.example.com.\nAfter you perform the steps from the exercise, your IoT device can automatically register with AWS IoT Core based on your device geolocation.\n'"
68,Digital Twins on AWS: Understanding “state” with L2 Informative Digital Twins,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/23/DigitalTwin_L1Informative.jpg,https://aws.amazon.com/blogs/iot/l2-informative-digital-twins/,"b'In our prior blog, we discussed a definition and framework for Digital Twins consistent with how our customers are using Digital Twins in their applications. We defined Digital Twin as \xe2\x80\x9ca living digital representation of an individual physical system that is dynamically updated with data to mimic the true structure, state, and behavior of the physical system, to drive business outcomes.\xe2\x80\x9d In addition, we described a four-level Digital Twin leveling index, shown in the figure below, to help customers understand their use cases and the technologies needed to achieve the business value they are seeking.\nIn this blog, we will illustrate how the L2 Informative level describes the state of a physical system by walking through an example of an electric vehicle (EV). You will learn, through the example use cases, about the data, models, technologies, AWS services, and business processes needed to create and support an L2 Informative Digital Twin solution. In our prior blog, we described the L1 Descriptive level, and in future blogs, we will continue with the same EV example to demonstrate L3 Predictive and L4 Living Digital Twins.\nL2 Informative Digital Twin\nAn L2 Digital Twin focuses on describing the state of a physical system by connecting to data streams from the physical system (either directly or via intermediary data storage systems) so that a user can visualize what is presently happening with the system. The visualization can be in the form of well laid out dashboards, or experiential with a full 3D immersive environment. Dashboard monitoring is very common in the IoT world for complex facilities such as power plants and factories and can include simple analytics to trigger alarms. In the industrial world, this is the domain of IoT and Asset Management with integrations with enterprise asset management (EAM) or enterprise resource planning (ERP) systems to show configuration, maintenance history, and upcoming work orders on a single pane of glass. Although common in high-value facilities such as powerplants, we\xe2\x80\x99re seeing customers wanting similar levels of monitoring on lower-value equipment in every day use such as their vehicles. The advancements in low-cost sensors and wireless connectivity is making this a cost-effective opportunity. To illustrate L2 Informative Digital Twins, we will continue our example of the electric vehicle (EV) from the L1 Descriptive Digital Twin blog by focusing on three use cases: 1/ real-time monitoring of a single vehicle with simple alarms, 2/ real-time monitoring of a fleet of vehicles, and 3/ battery degradation monitoring over an extended time period.\n1. Single vehicle real time monitoring\nFor real-time monitoring of our EV, we\xe2\x80\x99ve used the AWS IoT TwinMaker service to connect the 3D representation of the vehicle with data notionally streamed in real-time from the vehicle. This view could, for example, be used by a concerned parent waiting for their teenager to come home late at night to make sure they have sufficient battery charge to make it home safely. An alarm could be triggered and a notification raised if the vehicle battery charge falls below a preset threshold. For the purposes of this example, we generated a synthetic telemetry dataset using the Maplesoft EV model described in the L1 Descriptive blog, however, in the real implementation, it would be streamed data from a live operating vehicle.\nIn the example below, we see a screenshot of the dashboard created in Grafana using AWS IoT TwinMaker. The solution pulls together 2 different data sources: the synthetic telemetry data from AWS IoT SiteWise, and the maintenance history information and scheduled maintenance from Amazon Timestream.\nBecause our parent is concerned that their teenager might be stranded out at night, we\xe2\x80\x99ve also set an alarm that is triggered when the battery state of charge (SoC) drops below 25%. SoC is the ratio of the amount of energy left in the battery (in Ampere-hours) compared to the amount of energy in a new fully charged battery (in Ampere-hours). The triggered alarm is shown in the image below. As a note, for real-life EVs, it is recommended to keep the battery charge between 20% and 90% to maintain long-term battery health, and most vehicle software prevents charging beyond 90% capacity (even when the indicator says battery is fully charged).\nThe solution implementation architecture is shown below. The synthetic data representing real electric vehicle data streams are read in using an AWS Lambda function. The vehicle data including vehicle speed, fluid levels, battery temperature, tire pressure, seatbelt and transmission status, battery charge, and additional parameters are collected and stored using AWS IoT SiteWise. Historical maintenance data and upcoming scheduled maintenance activities are generated in AWS IoT Core and stored in Amazon Timestream. AWS IoT TwinMaker is used to access data from multiple data sources. The time series data stored in AWS IoT SiteWise is accessed through the built-in AWS IoT SiteWise connector, and the maintenance data is accessed via a custom data connector for Timestream. Within AWS IoT TwinMaker, the EV is represented as an entity with subsystems such as the braking system represented by a hierarchy of entities corresponding to the physical assembly of the individual parts. AWS IoT TwinMaker components are used to associate data elements to each of the entities in the hierarchy. The AWS IoT TwinMaker built-in alarm capability is used to set the 25% threshold against the battery charge data component. The visualization is built using Amazon Managed Grafana and interfaces with AWS IoT TwinMaker via the built-in plug-in.\n2. Fleet real time monitoring\nExtending the EV example from monitoring a single vehicle to managing a fleet of vehicles is a common use case for commercial operations. We\xe2\x80\x99ll examine a fleet of 5 vehicles, with each vehicle driving a different route. The use case here is for the fleet operator to understand the battery SoC and to estimate if the vehicle will be able to complete its route using a very crude calculation. For this example, it is assumed that the SoC of a vehicle battery should not fall below 20% and that each vehicle is discharging at an average rate of 0.23 %/km. The remaining range is then calculated by:\nIf the calculated Remaining Range is below the Distance Remaining, then an alarm is triggered and the vehicle is flagged with a red color as shown in the Grafana dashboard created below. Note that this example uses a very crude equation that can be incorporated into an L2 Informative Digital Twin IoT system. It has the benefit of simplicity, but greatly lacks accuracy. The next blog focusing on L3 Digital Twins will demonstrate the use of a much more accurate predictive model as a virtual sensor to calculate the remaining range.\nAs shown in the following architecture diagram, this solution was created using AWS IoT FleetWise, AWS Timestream, and AWS IoT TwinMaker. The synthetic data representing the fleet of electric vehicles including route information, distance remaining, battery charge is ingested in AWS IoT FleetWise using an Edge agent installed on an EC2 instance and stored in Amazon Timestream. The time series data stored in AWS Timestream is accessed through a custom connector in AWS IoT TwinMaker. The visualization is built using Amazon Managed Grafana and interfaces with AWS IoT TwinMaker via the built-in plug-in.\n3. Battery degradation monitoring for a fleet\nWe extended the EV example to another common use case which is monitoring the battery degradation over time for a fleet of vehicles such as a fleet of vans used by a delivery service in a city. Over a several year period, each vehicle in the fleet will have experienced very different drive profiles, as well as battery charging and discharging cycles. As a result, the battery degradation for each vehicle will be different. The use case here is for the fleet operator to understand the battery health of a specific vehicle. In this case, the operator is not interested in watching the real-time battery discharge as the vehicle operates, but rather what is the health of the battery depending on its ability to charge fully (relative to a new battery). Knowing this information enables the operator to allocate the vehicles to the appropriate routes to make sure each vehicle will be able to meet its upcoming routing demands for the next day. This metric is typically called State of Health (SoH) and one way to calculate it is as a percentage of the maximum charge of a new battery. For example, a degraded battery that can only charge up to 94 kWhr (relative to a new battery which can charge to 100 kWhr) would have an SoH of 94%. In the industry today, an EV battery pack is generally considered end of life for EV applications when the SoH drops below 80%. In the dashboard below, we see that the SoH for Vehicle 3 has dropped below 80%, triggering an alarm showing that the vehicle battery has reached effective end-of-life. This dashboard was generated using the same prior solution architecture, this time adding the Battery SoH as one of the parameters shown.\nFor Vehicle 3, we see that the Battery State of Health has dropped below the 80% end-of-life threshold. Looking at historical data, we\xe2\x80\x99ve plotted the battery discharge curve (e.g., SoC versus time) at different points in the battery life as the vehicle aged. The first line (dark blue) corresponds to a new battery with 100% SoH. The second line corresponds to when the battery was roughly half-way through its useful life at SoH of 89%, and the third line corresponds to the latest route driven with the battery at 78% SoH. The lines show the characteristic of battery degradation where the maximum charge attainable is lower as the vehicle ages. The area under each line represents the battery total capacity, and we also see that the battery total capacity is decreasing as the battery ages. Diving further, the right graph shows the voltage versus time discharge curve for the same routes shown in the middle graph. We see that as the vehicle degrades, the battery is able to maintain the voltage for a certain time, but as the battery degrades, the sudden drop in voltage (representing the battery being fully discharged) occurs sooner and sooner \xe2\x80\x93 potentially leaving the vehicle stranded in the middle of its route. Note that this example only shows monitoring of battery degradation as it occurs based on sensor data from the vehicle. In a future blog focusing on L4 Living Digital Twins, we will demonstrate how to predict battery degradation using an updatable model.\nSummary\nIn this blog we described the L2 Descriptive level by walking through the use cases of real-time monitoring of a single vehicle, real-time monitoring of a fleet of vehicles, and monitoring battery degradation over a period of many months for an EV. In our prior blog, we described the L1 Descriptive level, and in future blogs, we will extend the EV example to demonstrate L3 Predictive and L4 Living Digital Twins. At AWS, we\xe2\x80\x99re excited to work with customers as they embark on their Digital Twin journey across all four Digital Twin levels, and encourage you to learn more about our new AWS IoT TwinMaker service on our website.\nAbout the authors\nDr. Adam Rasheed is the Head of Autonomous Computing at AWS, where he is developing new markets for HPC-ML workflows for autonomous systems. He has 25+ years experience in mid-stage technology development spanning both industrial and digital domains, including 10+ years developing digital twins in the aviation, energy, oil & gas, and renewables industries. Dr. Rasheed obtained his Ph.D. from Caltech where he studied experimental hypervelocity aerothermodynamics (orbital reentry heating). Recognized by MIT Technology Review Magazine as one of the \xe2\x80\x9cWorld\xe2\x80\x99s Top 35 Innovators\xe2\x80\x9d, he was also awarded the AIAA Lawrence Sperry Award, an industry award for early career contributions in aeronautics. He has 32+ issued patents and 125+ technical publications relating to industrial analytics, operations optimization, artificial lift, pulse detonation, hypersonics, shock-wave induced mixing, space medicine, and innovation.\nSeibou Gounteni is a Specialist Solutions Architect for IoT at Amazon Web Services (AWS). He helps customers architect, develop, operate scalable and highly innovative solutions using the depth and breadth of AWS platform capabilities to deliver measurable business outcomes. Seibou is an instrumentation engineer with over 10 years experience in digital platforms, smart manufacturing, energy management, industrial automation and IT/OT systems across a diverse range of industries.\nDr. David Sauerwein is a Data Scientist at AWS Professional Services, where he enables customers on their AI/ML journey on the AWS cloud. David focuses on forecasting, digital twins and quantum computation. He has a PhD in quantum information theory.\nAditi Gupta is a seasoned technology professional having more than 17 years of experience in management and R&D work developing high performing, scalable and available solutions on-premises and in cloud. She has Masters degrees in Computer Engineering, as well as Business Management. Aditi has been with Amazon Web Services for five years and currently working as IoT Specialist Solutions Architect. She is also an expert in Artificial Intelligence and Big Data. In her role, Aditi advises national governments and enterprises on architecture and cloud services. In the recent years, Aditi has provided architectural advice to large enterprises, government agencies, universities and research agencies in AMER and ASEAN regions.'"
69,How to securely connect an AWS IoT Greengrass v1 device to AWS IoT Core using AWS PrivateLink,b'Joyson Neville Lewis',2022-08-17T18:26:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/12/GreengrassOverallSolutionV2-1-1024x509.png,https://aws.amazon.com/blogs/iot/how-to-securely-connect-an-aws-iot-greengrass-v1-device-to-aws-iot-core-using-aws-privatelink/,"b'Introduction\nCompetitive environments generally result in bottom line pressure for manufacturers, driving leadership to explore additional innovations for revenue growth such as implementation of Industrial Internet of Things(IIoT) solutions. In this post, we discuss how to secure network traffic between a device running AWS IoT Greengrass on your Operational Technology (OT) network and your Internet of Things (IoT) services in the Cloud by accessing AWS PrivateLink over a dedicated connection. Increasingly, IT and OT leaders are adopting industry 4.0 solutions to drive revenue growth, streamline operations, and decrease costs. Managing security considerations while connecting your manufacturing plants to the cloud can be challenging. However, by following recommendations covered in the Security Best Practices for Manufacturing OT, you can establish secure connections with an AWS site-to-site VPN or AWS Direct Connect and Amazon VPC Endpoints and Amazon VPC Endpoint Services. Additionally, follow the guidelines in the Ten security golden rules for Industrial IoT Solutions, specifically rule 7 when connecting OT assets and industrial operations to AWS.\nAWS IoT Greengrass is an open source edge runtime for building, deploying, and managing device software as well as locally processing, filtering, and aggregating telemetry before sending it to the cloud. With an AWS IoT Greengrass runtime you gain access to innovative and highly scalable Cloud IT resources to enhance your OT technology investments. To establish a private network between AWS cloud and your OT environment, you can use AWS PrivateLink VPC Endpoints with AWS VPN or AWS Direct Connect which allows all communication to remain within your AWS environment without routing over the public internet. While AWS API endpoints are available over the public internet, configuring a VPC endpoint on a per service basis for AWS services allows the AWS IoT Greengrass edge runtime to connect over your private network. Endpoint Private DNS records and Amazon Route 53 Private Hosted Zones create alias records for service endpoints directing traffic to your interface endpoints.\nAs more customers are building IIoT solutions and are following security best practices based on their security and compliance practices they are asking, how can they establish a private connection to AWS for their IIoT solution and not need to use AWS public endpoints. This blog provides guidance on how to implement AWS IoT Greengrass with other AWS services using private endpoints.\nSolution Overview\nIn the following architecture, an Amazon Elastic Compute Cloud (Amazon EC2) instance is deployed into a private subnet to simulate an on-premises AWS IoT Greengrass edge runtime. The AWS IoT Greengrass edge runtime interacts with cloud based IoT services including AWS IoT Core, AWS IoT Greengrass, Amazon Simple Storage Service (Amazon S3), and Amazon CloudWatch to centralize activity like aggregation of telemetry from equipment into data lakes, issue remote commands, perform analysis and machine learning, and run jobs like firmware updates. You will setup private endpoints for these services to route traffic from the EC2 instance running AWS IoT Greengrass to AWS APIs without leaving the AWS private network; without these endpoints the default behavior of the AWS APIs is to resolve DNS over the public internet.\nWalkthrough\nPrerequisites\nBefore you begin configuring your VPC for private traffic, have a familiarity with AWS IoT Core, AWS IoT Greengrass, Amazon S3, Amazon CloudWatch, Amazon Route 53, Amazon EC2, and Amazon Virtual Private Cloud (Amazon VPC). We suggest you setup a dedicated VPC to manage your Greengrass private endpoints. If you plan to use the companion CDK stack, you should already be comfortable working with the AWS Cloud Development Kit (AWS CDK).\nYou should have setup a VPC named Greengrass VPC with a private subnet; when defining your subnets ensure the region and availability zones that you select support the IoT Core VPC Endpoint. You can follow the Modular and Scaleable VPC Architecture quick-start. If you plan to use the companion CDK stack, it will build a VPC for you.\nOnce you have a VPC, you\xe2\x80\x99ll need an EC2 instance in an isolated private subnet of your VPC with AWS IoT Greengrass version 1 runtime installed on the instance. You should be able to connect to this instance either using AWS Systems Manager or via a Bastion host. For instructions on how to install AWS IoT Greengrass version 1 refer to the developer guide Setting up an EC2 instance. To isolate your AWS IoT Greengrass edge runtime and private subnet you can remove any routes to a NAT Gateway that were used during AWS IoT Greengrass installation. Isolating your private subnet from the internet will ensure your AWS IoT Greengrass edge runtime cannot reach out of your network simulating a private OT and IT hybrid network of an industry 4.0 plant.\nYou can use the following instructions to configure your VPC in the AWS Console, or you can use the companion solution on GitHub to automate the configuration of your VPC. The readme file in this companion solution provides instructions for installation with the AWS CDK.\nStep 1: Setting up Security Groups\nAWS IoT Greengrass Endpoints Security Group\nA security group is a software defined firewall that implicitly denies inbound traffic and implicitly allows outbound traffic. You can explicitly define and configure allow rules for initiated traffic from the simulated device running AWS IoT Greengrass to each of the VPC Endpoints. AWS IoT Greengrass needs access to Amazon S3 for accessing assets as well as AWS IoT Core and Cloud side AWS IoT Greengrass MQTT for Jobs and Telemetry messaging.\n1.     From the AWS VPC console, choose Security Group from the left navigation under the Security heading and then choose Create security group\n2.     For Name enter iot-endpoints-security-group\n3.     For Description (optional) enter securing the endpoints used to create private connection with AWS IoT Greengrass\n4.     Select your AWS IoT Greengrass VPC\n5.     Choose Add under the Inbound Rules heading to configure four inbound rules as defined in the following table. Repeat the process for each rule and enter the corresponding value for each field in the column heading\nType Port Range Source Description\nHTTP 80 Enter EC2 Security Group name All Amazon S3 HTTP\nHTTPS 443 Enter EC2 Security Group name All Amazon S3 HTTPS\nCustomer TCP 8883 Enter EC2 Security Group name Allow AWS IoT Greengrass MQTT\nCustomer TCP 8443 Enter EC2 Security Group name Allow AWS IoT Core MQTT\n6.     Choose Create security group. Once complete, your configuration should look similar to the following screenshot\nAWS CloudWatch Endpoints Security Group\nFrom the AWS VPC console, choose Security Group from the left navigation under the Security heading and then choose Create security group\n1.     For Name enter logs-endpoints-security-group\n2.     For Description (optional) enter securing the endpoints used to create private connection with Cloudwatch logs\n3.     Select your AWS IoT Greengrass VPC\n4.     Choose Add under the Inbound Rules heading to configure four inbound rules as defined in the following table. Repeat the process for each rule and enter the corresponding value for each field in the column heading.\nType Port Range Source Description\nHTTP 80 Enter EC2 Security Group name Allow HTTP to CloudWatch\nHTTPS 443 Enter EC2 Security Group name Allow HTTPS to CloudWatch\n5.    Choose Create security group. Once complete your configuration should look similar to the following screenshot.\nStep 2: Creating Private Endpoints\nFrom the AWS VPC console, choose Endpoints from the left navigation under the Virtual Private Cloud heading and then choose Create endpoint\n1.     For Name enter, iot-core-endpoint\n2.     For Service Category, choose AWS services\n3.     For Services, enter iot in the search bar and choose search then select the iot endpoint that ends with iot.data, the Type is interface\n4.     Choose the VPC that your AWS IoT Greengrass edge runtime is located in\n5.     Open Expand Additional Settings and unselect Enable DNS Name\n6.     For Subnets, select the Availability Zone of your Private Subnet\xe2\x80\x99s and select the Private Subnet where your Greengrass instance is located\n7.     For Security group, select the endpoints-security-group and choose Create endpoint.\nAWS IoT Greengrass needs you to configure 3 more VPC endpoints. Follow the same steps that you used above for AWS IoT Core, but enter the corresponding value for each field matching the column heading for each value in the configuration table that follows.\nName Service Category Services Type VPC Additional Settings Enable DNS Name Subnets Security Group\nGreengrass-endpoint AWS services Greengrass Interface Greengrass VPC Selected AZ of your private subnets endpoints-security-group\ns3-endpoint(com.amazonaws.<region> AWS services S3 Interface Greengrass VPC Unselected AZ of your private subnets endpoints-security-group\nlogs-endpoint AWS services logs Interface Greengrass VPC Selected AZ of your private subnets cloudwatch-endpoints-security-group\nEach of the Summary screens for your VPC endpoints will look similar to the following screenshot for the AWS IoT Core endpoint.\nSetting up Route 53 for IoT Core\nEarlier when the AWS IoT Greengrass, and Amazon CloudWatch endpoints were created, the Enable DNS name was selected, but for AWS IoT Core it was not. To enable DNS for AWS IoT Core, you can configure a Route 53 entry.\nFrom the Route 53 console, choose Hosted Zone from the left navigation\n1.     Choose Create hosted zone\n2.     For Domain Name, enter iot.<AWS_REGION>.amazonaws.com. Replace the <AWS_REGION> with the region the VPC is deployed in. ex. .iot.us-east-2.amazonaws.com\n3.     For Description, enter Hosted Zone for IoT Core\n4.     For Type, select Private\n5.     Choose the Region and the VPC ID that were configured during the pre-requisite steps\n6.     Choose Create Hosted Zone\n7.     Select the recently created hosted zone and create two new records:\n8.     Create an A record for AWS IoT Core. The prefix will be the AWS IoT Core prefix (ours is: a23nouzhauflk3-ats, replace with yours) pointed to the IP address of the AWS IoT Core Endpoint IP that was created earlier, ours is 10.0.4.77. Your final record name would look similar to a23nouzhauflk3-ats.iot.us-east-2.amazonaws.com\n9.     Create an A record for AWS IoT Greengrass with the prefix as greengrass-ats, so the record name would equal greengrass-ats.iot.us-east-2.amazonaws.com pointed to the IP address of the AWS IoT Core Endpoint IP, 10.0.4.77\n10.  Choose Save\nSetting up Route 53 for S3\nEarlier when the AWS IoT Greengrass, and Amazon CloudWatch endpoints were created, the Enable DNS name was selected, but for S3 it was not. To enable DNS for S3, you can configure a Route 53 entry.\nFrom the Route 53 console, choose Hosted Zone from the left navigation\n1.     Choose Create hosted zone\n2.     For Domain Name, enter s3.<AWS_REGION>.amazonaws.com. Replace the <AWS_REGION> with the region the VPC is deployed in. ex: s3.us-east-2.amazonaws.com\n3.     For Description, enter Hosted Zone for S3\n4.     For Type, select Private\n5.     Choose Create Hosted Zone\n6.     Select the recently created hosted zone and create two new records:\n7.     Create an A record for S3 targeting your S3 VPC Interface Endpoint\n8.     Additionally create a wildcard A record for S3 targeting your S3 VPC Interface Endpoint. In this case for Record Name enter *.\n9.     Choose Save\nValidation\nAfter completing the above steps, the EC2 instance using AWS IoT Greengrass version 1 will be communicating entirely using private connections and will not send any data over the public internet. This statement can be made because the Internet Gateway and NAT Gateway are removed and therefore the only communication paths are the VPC Endpoints. A couple ways to test this are noted below as commands from a terminal interface on the EC2 instance running AWS IoT Greengrass; as an extension try these after the Prerequisites, but before completing the steps outlined in this blog:\nFrom the terminal of the EC2 instance running AWS IoT Greengrass type \xe2\x80\x98yum check-update\xe2\x80\x99 (or equivalent based on the OS used). Notice that this throws an error as only connectivity to the VPC Endpoints is available\nFrom the terminal of the EC2 instance running AWS IoT Greengrass type \xe2\x80\x98nslookup Greengrass-ats.iot.us-east-2.amazonaws.com\xe2\x80\x99. The result will be the IP address of the VPC Endpoint that was configured; note you can do similar with the Amazon CloudWatch Logs, IoT Core, and S3 endpoints\nTest the ability to interact with the AWS IoT Greengrass device as outlined in Module 3-Part 1 of the AWS IoT Greengrass version 1 quick start. If you have already completed this during the prerequisites modify the Lambda function code and re-deploy to the AWS IoT Greengrass device.\nConsiderations for your OT Network\nThe preceding configuration places the AWS IoT Greengrass edge runtime in your VPC for testing and demonstration purposes only. In practice your AWS IoT Greengrass runtime will run in your OT network and can access the private endpoints you\xe2\x80\x99ve configured through your secure AWS connection over AWS VPN or AWS Direct Connect. Details on configuration of the AWS Greengrass runtime in your OT network including DNS forwarding requirements will be explained in a follow up blog post.\nCleanup\nIf you followed along with this solution, we suggest that you complete the following steps if you wish to avoid incurring charges to your AWS account once you have completed the walkthrough.\nAmazon EC2\nTerminate the EC2 instance serving as the bastion host\nTerminate the EC2 instance running AWS IoT Greengrass\nAmazon CloudWatch\nDelete the relevant log groups\nAmazon Route53\nIn the Hosted Zone created for AWS IoT Core, delete the A records for AWS IoT Core Endpoint and AWS IoT Greengrass Endpoint\nDelete the Hosted Zone created for AWS IoT Core and S3\nAmazon Virtual Private Cloud\nDelete each of the four VPC Endpoints you created; AWS IoT Core, AWS IoT Greengrass, Amazon S3, and Amazon CloudWatch\nSecurity Groups\nDelete the endpoints-security-group and the cloudwatch-endpoints-security-group\n'"
70,Simplify multi-account device provisioning and certificate authority registration when using AWS IoT Core,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/simplify-multi-account-device-provisioning-and-certificate-authority-registration-using-aws-iot-core/,"b'Customers often manage multiple AWS accounts to separate their development, staging, and production environments. When deploying IoT workloads on AWS IoT Core, customers usually use unique X.509 certificates for identifying devices and certificate authorities (CAs) for validating the signature of device certificates during provisioning. In this blog, we will demonstrate how to use the newly launched capability of AWS IoT Core to simplify both device provisioning and CA registration for customers that use multiple accounts.\nIn the prior version, customers that manage different AWS accounts to differentiate between development and production workloads had to configure multiple CAs to connect the same device to multiple accounts during the development process. With this update, you can use the same CA across various accounts to simplify device provisioning when using Just-in-Time Provisioning (JITP) and Just-in-Time Registration (JITR) and improve security posture by having fewer CAs.\nThis update also simplifies the CA registration process for AWS IoT Core to validate the signature of device certificates during provisioning. Previously, to prove ownership before registering the CA, you had to have access to the CA\xe2\x80\x99s private key. However, these private keys are typically managed by device vendors or security teams of organizations that operate their own CAs, and are not shared with the developers, which makes it challenging for developers to prove ownership of the CAs. With this update, your development team can directly manage the registration of CAs and simplify the device provisioning process.\nThe new capability is specific to JITP and JITR provisioning methods that automatically provision devices on their first attempt to connect to AWS IoT Core and enhances these methods for multi-account use cases. In contrast, Multi-Account Registration (MAR) of device certificates enables customers to move devices between different AWS accounts without registering CA, but requires registering device certificates on AWS IoT Core for each account manually.\nCustomers are already benefiting from the new capabilities\nThe ability to register CAs in multiple accounts and simplification of CA registration with AWS IoT Core reduces complexity for customers and helps accelerate time-to-market.\niRobot: reducing the complexity of device identity provisioning in multi-account environments\niRobot designs and builds robots that empower people to do more inside and outside the home. iRobot uses multiple AWS accounts to separate their development, testing, and production environments. \xe2\x80\x9cWith the new capability of AWS IoT Core to register CA certificates in multiple accounts, we can provision identities on our development robots once and move them among the approved development accounts as needed without re-provisioning. This simplifies the development process, which in turn helps improve our security posture because we can have tighter control over the reduced number of CAs and associate the CAs with security boundaries,\xe2\x80\x9d said Ben Kehoe, Cloud Architect at iRobot.\nWirelessCar: accelerating time-to-market by simplifying security configuration\nWirelessCar is one of the world\xe2\x80\x99s leading innovators of digital vehicle services. They turn vehicle data into business value for consumers, mobility providers, vehicle makers, and society. WirelessCar uses Just-in-Time Provisioning for automating the provisioning of vehicles with X.509 certificate-based identities. \xe2\x80\x9cThe new simplification of the CA registration with AWS IoT Core helps our developers move faster without waiting for verification certificates from our security team,\xe2\x80\x9d said Henrik Str\xc3\xb6mberg, Solution Architect at WirelessCar. \xe2\x80\x9cOur security team can keep the strong security posture without becoming the bottleneck in our fast-paced development environment.\xe2\x80\x9d\nGetting started\nThe new capability allows registering a CA certificate in multiple accounts of the same region (and, of course, across multiple regions, which was possible before) without proving the ownership of the CA\xe2\x80\x99s private key. The capability is unlocked if a device can send the Server Name Indication (SNI) field, which communicates the endpoint it is attempting to connect to at the start of the Transport Layer Security handshaking process. The new capability enhances JITP and JITR device provisioning methods. You can now register CA certificates in one of the following two modes:\nDEFAULT: register a CA certificate with a verification certificate\nSNI_ONLY: register a CA certificate without a verification certificate\nAWS IoT Core registers device certificates in SNI_ONLY mode when you register the signing CA in SNI_ONLY mode.\nKey points:\nOnly one account can register a CA in DEFAULT mode in one region.\nMultiple accounts can register the same CA in SNI_ONLY mode in the same region. There is no limit on the number of accounts in the region where such CA is registered.\nMultiple accounts can register the same CA in either DEFAULT or SNI_ONLY modes if these accounts are in different regions \xe2\x80\x94 this was possible before.\nA CA can be in different modes across accounts. For example, one account can register it in DEFAULT mode and another account in SNI_ONLY mode.\nIn a given account, a CA can exist in only one mode. To change the mode of the registered CA, you need to delete the CA and register it again.\nLet\xe2\x80\x99s look at setting up this new feature and testing it in your accounts. We will show that we can register the same CA in multiple accounts through the following steps:\nWe will set up Cloud9 instances in two different accounts\nWe will set up CA in the first account in DEFAULT mode\nWe will set up CA in the second account in SNI_ONLY mode\nVerify that the CA is registered in both accounts to validate the feature\nSolution architecture\nSolution architecture \xe2\x80\x93 Figure 1\nSolution overview and implementation\nCreating the test environment\nUse the Get Started With IoT workshop to set up the AWS Cloud9 environment quickly. Pick any AWS region closest to your location. In this blog, we will use US-EAST-1. Set up two Cloud9 environments in the same region but two different accounts because we will test the multi-account nature of the introduced capability. After completing the setup using the AWS CloudFormation template from the workshop, let\xe2\x80\x99s begin setting up certificate authorities. Open the Cloud9 terminal (see the hint here), and let\xe2\x80\x99s set up the first CA certificate.\nSetup CA in Account 1\nLet\xe2\x80\x99s set up CA in this first account in DEFAULT mode. To register a DEFAULT CA certificate, follow our existing publicly available API docs here.\nCreate a CA certificate\nopenssl genrsa -out rootCA.key 2048\nBash\nYou should see a similar output:\ne is 65537 (0x010001)\nGenerating RSA private key, 2048 bit long modulus (2 primes)\n................................................................................................................................................................................+++++\n..+++++\nBash\nNow, let\xe2\x80\x99s create a config file to generate a CA certificate through OpenSSL. Create a file named rootCA_openssl.conf with the following contents:\n[ v3_ca ]\nbasicConstraints = CA:TRUE\nBash\nThis config file explicitly states that the certificate to be generated is a CA and not a leaf certificate. Once the rootCA_openssl.conf file is created, let\xe2\x80\x99s run the following commands to generate the rootCA.pem file and fill in the details accordingly:\nopenssl req -new -sha256 -key rootCA.key -nodes -out rootCA.csr\nBash\nopenssl x509 -req -days 1024 -extfile rootCA_openssl.conf -extensions v3_ca -in rootCA.csr -signkey rootCA.key -out rootCA.pem\nBash\nBy now, we should have two files, rootCA.key and rootCA.pem. We will use them in the steps below.\nRegister CA\nWe derived the instructions from our publicly available document for registering your CA certificate. First, we get a registration code from AWS IoT Core. We will use this code as the Common Name of the private key verification certificate.\naws iot get-registration-code --region us-east-1\nBash\nYou should see a similar output:\n{\n  ""registrationCode"": ""xxxxxxxxxxx7a60e19fxxxxxxxxxxxxxx8381dbd3457xxxxxxxxxxxxxx""\n}\nBash\nNow, let\xe2\x80\x99s generate a key pair for the private key verification certificate. We will get a file called verificationCert.key.\nopenssl genrsa -out verificationCert.key 2048\nBash\nYou should see a similar output:\ne is 65537 (0x01xxxx)\nGenerating RSA private key, 2048 bit long modulus (2 primes)\n................................................................................................................+++++\n.............................................+++++\nBash\nNext, we will execute the following command to create a CSR for the private key verification certificate. We will get a file called verificationCert.csr.\nopenssl req -new -key verificationCert.key -out verificationCert.csr\nBash\nNow, we need to set the Common Name field of the certificate with the registration code out from the earlier step. Populate the rest of the fields according to your details:\nCountry Name (2 letter code) [AU]:\nState or Province Name (full name) []:\nLocality Name (for example, city) []:\nOrganization Name (for example, company) []:\nOrganizational Unit Name (for example, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []: XXXXXXXREGISTRATION-CODEXXXXXXX\nEmail Address []:\nPlease enter the following \'extra\' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\nBash\nWe used the CSR to create a private key verification certificate. We will use this step\xe2\x80\x99s verificationCert.pem file when we register the CA certificate.\nopenssl x509 -req -in verificationCert.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out verificationCert.pem -days 500 -sha256\nBash\nUpon successful completion, we should see the following output:\nGetting CA Private Key\nBash\nLastly, we will call the register-ca-certificate CLI command to register the CA certificate.\naws iot register-ca-certificate --ca-certificate file://rootCA.pem --verification-cert file://verificationCert.pem --set-as-active --allow-auto-registration --region us-east-1\nBash\nNote: Take a note of the Certificate ID for use in the future verification step.\nWe should get a successful response with the returned Certificate ID and Certificate ARN.\nAfter registering the CA certificate, you can still call UpdateCACertificate API or update-ca-certificate CLI command to update the registered CA certificate, if needed.\nNow that we have registered the CA, let\xe2\x80\x99s make a control plane call to AWS IoT Core\xe2\x80\x99s endpoint and verify that it registered the CA. Run the following command (replace Certificate ID with the returned value from aws iot register-ca-certificate command):\naws iot describe-ca-certificate --region us-east-1 --certificate-id <<Certificate_ID>> \nBash\nYou should see a similar JSON output:\n{\n  ""certificateDescription"": {\n    ""certificateArn"": ""arn:aws:iot:us-east-1:YYYYYYYYYYYY:cacert/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",\n    ""certificateId"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",\n    ""status"": ""ACTIVE"",\n    ""certificatePem"": ""-----BEGIN CERTIFICATE-----xxxxxxxx\\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\n-----END CERTIFICATE-----\\n"",\n    ""ownedBy"": ""YYYYYYYYYYYY"",\n    ""creationDate"": 1655249872.319,\n    ""autoRegistrationStatus"": ""ENABLE"",\n    ""lastModifiedDate"": 1655249872.319,\n    ""customerVersion"": 1,\n    ""generationId"": ""7xxxxxxxxxxxxxxxxxxxxxxxxxxxxe9"",\n    ""validity"": {\n      ""notBefore"": 1655249071.0,\n      ""notAfter"": 1743722671.0\n    },\n    ""certificateMode"": ""DEFAULT""\n  }\n}\nJSON\nSetup CA in Account 2\nLet\xe2\x80\x99s open our second account and set up the Cloud9 environment as before.\nSince we will register the same CA in the second account as we did in the first account, we will use SNI_ONLY mode. In this mode, we do not need to carry out verification steps as we did for the first account.\nPlease copy rootCA.pem file from account one and then run the following command:\naws iot register-ca-certificate --ca-certificate file://rootCA.pem --certificate-mode SNI_ONLY --set-as-active --allow-auto-registration --region us-east-1\nBash\nVerify the CA has been registered\naws iot describe-ca-certificate --region us-east-1 --certificate-id <<Certificate_ID>>\nBash\nYou should see following output, which confirms the certificate mode is SNI_ONLY:\n{\n  ""certificateDescription"": {\n    ""certificateArn"": ""arn:aws:iot:us-east-1:ZZZZZZZZZZZZ:cacert/4xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx0"",\n    ""certificateId"": ""4xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx0"",\n    ""status"": ""ACTIVE"",\n    ""certificatePem"": ""-----BEGIN CERTIFICATE-----xxxxxxxxxxxx\\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\n-----END CERTIFICATE-----\\n"",\n    ""ownedBy"": ""ZZZZZZZZZZZZ"",\n    ""creationDate"": 1655252314.053,\n    ""autoRegistrationStatus"": ""ENABLE"",\n    ""lastModifiedDate"": 1655252314.053,\n    ""customerVersion"": 1,\n    ""generationId"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",\n    ""validity"": {\n      ""notBefore"": 1655249071.0,\n      ""notAfter"": 1743722671.0\n    },\n    ""certificateMode"": ""SNI_ONLY""\n  }\n}\nJSON\nNow you can use the CA certificate with SNI_ONLY certificate mode the same way as you would with DEFAULT mode.\n'"
71,Increase military readiness with AWS IoT for Defense and National Security,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/13/Blog-Tactical-Edge-IoT-1.jpg,https://aws.amazon.com/blogs/iot/increase-military-readiness-with-aws-iot-for-defense-and-national-security/,"b'In this post we discuss how AWS IoT for Defense and National Security (IoT4D) increases readiness by driving operational excellence for manufacturing and supply chains, improving sustainability for buildings and bases, improving equipment maintenance and uptime, and providing situational awareness at the tactical edge.\nIoT workloads securely collect, aggregate, and store data from fleets of physical assets, analyze IoT data using AI/ML tools at the edge or in the cloud, and enable organizations to take proactive action based on actionable insights. The source of data is increasingly coming from connected edge devices, which can range from small, low-power devices like sensors, to more powerful devices like edge gateways, and cameras.\nManaging these assets is relatively straightforward for physical assets that are stationary, easily accessed, and where the data is unclassified. However, when it comes to IoT4D, additional considerations apply. Assets like aircraft, ships, weapons systems, and ground equipment are often mobile, deployed in austere environments (where connectivity may be a challenge), and involve data that must be protected at the highest classifications \xe2\x80\x93 including Secret and Top Secret.\nAWS IoT provides services and capabilities to connect and manage billions of devices that let you collect, store, and analyze IoT data for industrial, commercial, and tactical edge workloads in defense and national security at confidential, secret, and top secret classification levels. AWS enables innovation by providing the a full range of IoT services. From secure device connectivity to management, storage, and analytics, AWS IoT has the broad and deep services you need to build complete solutions.\nIndustrial IoT4D  \nThe Industrial IoT4D segment encompasses depot management, warehouse operations, logistics and supply chain, smart factory, predictive maintenance, and factory automation. These use cases answer customer questions like: how to move from reactive to predictive maintenance, how to extract and migrate data securely, how to I optimize the supply chain to improve customer outcomes, and how to lower operating costs.\nBy delivering operational excellence through improved processes and procedures, readiness is increased, costs are managed, quality is improved, and supply chains serve the needs of the warfighter. Lockheed Martin\xe2\x80\x99s Intelligent Factory Framework (IFF) is an example of IoT applied in the industrial sector. The IFF lays the groundwork for faster and more agile production operations with a new, cybersecure and standards-based network that can automatically predict maintenance needs, analyze production performance, and monitor quality.\nCommercial IoT4D\nThe Commercial IoT4D segment provides capabilities to improve facility security, maintenance, and operations \xe2\x80\x93 leveraging digital twins that provide a virtual representation of the building, campus, or high-value asset, creating a virtual representation of any physical environment and creating a holistic view of operations.\nBy enhancing sustainability for buildings, campuses, and other physical facilities Commercial IoT4D answers questions like how to create a single source of asset data on all structures, how to keep my facilities secure, how to manage devices from multiple vendors, and how to reduce energy and maintenance costs.\nFor example, Novetta\xe2\x80\x99s Platform for Integrated C3 and Responsive Defense \xe2\x80\x93 PICARD \xe2\x80\x93 is being deployed across United States Air Force facilities, consolidating sensor data from multiple systems to improve security, access, and facility operations. PICARD uses an IoT approach to sensor fusion, integrating dispersed forces with intelligent systems to enable rapid decision-making across the full spectrum of defense operations.\nSiemens and Carrier are embedding AWS IoT TwinMaker to simplify and accelerate the deployment of digital twins that optimize energy and space usage, resulting in accelerated innovation and deployment cycles, reductions in energy and maintenance costs, and optimized occupancy management for safe, secure, and sustainable facilities, from permanent locations to forward operating bases. These capabilities enhance global sustainability initiatives by enhancing security, managing energy consumption, and making facilities more efficient.\nTactical Edge IoT4D\nAt the tactical edge, where connectivity may be austere, and decision-making needs to be accelerated, IoT provides command and control (C2) capabilities for reconnaissance, surveillance, multi-channel communications, condition monitoring and equipment maintenance, force protection, humanitarian assistance/disaster response, logistics optimization, and unmanned warfare. Key questions for these use cases include how to synchronize data in remote, disconnected locations, how to communicate incidents quickly and securely, how do leverage AI and ML to accelerate the data-to-decision process to support mission outcomes, and how to maintain situational awareness.\nAt the tactical edge, situational awareness is the outcome of connecting and integrating sensors for intelligence gathering and tactical response. For example, Novetta developed a solution to improve situational awareness during disaster response efforts, combining AWS storage, edge computing, loT technology, machine learning, long-range low-power wide area wireless networking (LoRaWAN), and Novetta\xe2\x80\x99s Ageon ISR software.\nThe value of AWS IoT for Defense and National Security\nAWS IoT increases operational excellence, sustainability, and situation awareness for meeting our defense needs and increasing readiness with integrated services to collect, store, and analyze IoT data for industrial, commercial, and tactical edge workloads.\nAWS IoT secures your IoT applications from the edge to cloud, providing application and device security and connectivity across all workloads and security levels.\nAWS IoT makes devices more intelligent by bringing artificial intelligence (AI), machine learning (ML), and IoT together, creating models in the cloud and deploying them to devices with up to 25x better performance and less than 1/10th the runtime footprint.\nFinally, AWS IoT enables you to scale easily and reliably to build innovative, differentiated solutions on secure, proven, and elastic cloud infrastructure that scales to billions of devices and trillions of messages.\nRead our recent blogs on how the cloud enables common operating picture and sustainability. To learn more about AWS Cloud Computing for Defense, visit our homepage or contact our team.\nPhil Silver is a retired U.S. Navy Captain. At AWS (Amazon Web Services) he is the Worldwide GTM Leader for IoT for Defense & National Security (IoT4D).'"
72,Drive efficiencies in sustainable waste management using AWS IoT Core,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/drive-efficiencies-in-sustainable-waste-management-using-aws-iot-core/,"b'According to the UK local government association, councils spend around \xc2\xa3852 million per year on waste collection. Therefore, even a small savings of 5% is considerable, amounting to \xc2\xa342.6 million.\nAdditionally, when it comes to food, globally, we waste almost 1 billion tonnes of food each year. According to WRAP charity, businesses and governments are not doing enough to tackle food waste, which is responsible for emitting up to 10% of global greenhouse gases. The wider legislative context is driving councils to become greener and consider their carbon footprint and impact on air pollution. As a result, councils are increasingly reluctant to send waste to landfills, favoring disposal options higher up the waste hierarchy, including waste prevention, minimization, reuse, and recycling.\nTo support the waste minimization initiatives from councils and governments, it is important to collect reliable, comprehensive, and consistent waste data before the waste is sent to landfills because you cannot manage what you are not measuring. The connected waste bin solution example in this blog captures the weight and types of waste generated. Councils, communities, and private sectors (e.g., restaurant chains) can benchmark their performance to identify areas of success against sustainable waste management objectives and targets.\nThe monitoring of waste avoids potential stockpiling of waste at depots and supports greater transparency for regulators. The regulators can make informed decisions on what types of waste are going to landfills and target specific waste or areas to reduce environmental impact by maximizing landfill diversions based on types of waste sent to recycling facilities.\nBy knowing how much waste a particular area generates over a specific period, you can avoid scheduling unneeded waste pick-ups, which helps streamline the waste management process, makes them more cost effective, and in turn reduces carbon footprint.\nBy installing connected waste bins in kitchens, restaurant chains get complete transparency on their food waste and gain insights from historical data to reduce food waste and costs. In commercial buildings / offices, the solution can help to identify waste types and point to the correct waste bin. Overall, the connected waste bin solution can become a crucial tool for sustainable waste management initiatives.\nThis blog post provides an example of how to build a connected waste bin solution using AWS IoT Core and Amazon Rekognition to achieve sustainability goals.\nOverview\nThis post describes AWS serverless key architecture components for provisioning devices, collecting waste weight data through AWS IoT Core into AWS IoT Analytics, and ingesting waste images directly into Amazon Simple Storage Service (S3). Once the data is in Amazon S3, the solution analyzes images using Amazon Rekognition to enrich waste data, which end users can then leverage to build reports such as area waste levels and waste heat maps using Amazon QuickSight.\nThis solution involves installing sensors and cameras, configuring AWS IoT Greengrass on a Raspberry Pi and connecting it to AWS IoT Core using fleet provisioning, building a machine learning model using Amazon Rekognition, and building a data pipeline and visualization using AWS IoT Analytics and Amazon QuickSight respectively.\nEnd-to-end sensor data flow to the cloud\nThe following section explains the steps numbered in the previous architecture diagram.\n The IoT gateway provisions itself into AWS IoT Core using a fleet provisioning mechanism and authenticates from there on using a unique X.509 device certificate issued by AWS IoT Core. It also starts the custom application component to read sensors. I explain further the custom component deployment in the section, Test remote application deployment.\nThe weight sensor monitors the waste bin. When weight goes up by a certain threshold, it triggers the camera.\nCamera takes a picture of the waste.\nCustom application then uploads waste image to an Amazon S3 bucket using AWS IoT Greengrass stream manager SDK.\nIt also sends weight data over the MQTT channel to AWS IoT Core.\nAWS IoT Core receives weight data. It then executes AWS IoT rules to ingest data into the AWS IoT Analytics pipeline.\nThe pipeline executes data transformation using an AWS Lambda function, which pulls uploaded waste images from the Amazon S3 bucket and analyses the image using pre-built machine learning models from Amazon Rekognition.\nFinally, store transformed payload in a data store backed by an Amazon S3 store\nUse Amazon QuickSight to generate the analytics reports.\nWaste bin sensor installation\nFor demonstration, we use a Raspberry Pi as the IoT device gateway, a gravity sensor to measure the weight of the waste, and a camera to take the still picture of waste when you drop an item in the bin. To connect the waste bin to the cloud, we wire sensors to the waste bin for our demo use case, as shown in the following image.\nBuild ML Model\nYou can use a pre-built Amazon Rekogntion model to analyze waste images and detect items in the waste by checking the labels returned by Amazon Rekognition.\nAlternatively, you can prepare custom labelled data sets for specific types of needs. Preparing those data sets involves collecting various waste images, e.g., typical waste in a household waste bin, and uploading those images to the custom project under the training and testing data set. After uploading, you need to label the waste images to train the model. You can use Amazon SageMaker Ground Truth Plus to automate data labeling.\nIn this blog post example, we use a pre-built model.\nPrerequisites\nAn AWS Account.\nAWS Identity and Access Management (IAM) administrator access.\nThe AWS Command Line Interface (AWS CLI).\nAn Amazon S3 bucket to upload all the artifacts from the cloned repository under src/greengrass-app-component directory.\nFor local development, an IDE, e.g., vscode and python3.\nAn IoT device with Linux OS to use as an AWS IoT Greengrass core device installed with JDK and other required dependencies for AWS IoT Greengrass core.\nRoot access on an IoT device to run AWS IoT Greengrass core software.\nA basic understanding of setting up a Raspberry Pi.\nHardware connections as explained in the section Waste bin sensor installation.\nRaspberry Pi\nGravity load cell sensor\nCamera\nA basic understanding of\nAWS Lambda\nAWS IoT Greengrass\nAWS IoT Core\nAWS IoT Analytics\nDeploy the solution\nFirst, upload AWS IoT Greengrass custom component artifacts to the Amazon S3 bucket. The solution source code is available on GitHub.\nClone repository from GitHub to your local\nOn AWS Console, choose Amazon S3 service\nChoose your bucket created as mentioned in prerequisite\nChoose Create folder\nEnter greengrass-app-component in folder name field and choose Create folder\nChoose the greengrass-app-component folder and choose Upload\nChoose Add files on the upload screen and choose all the files from the greengrass-app-component directory from the repository cloned on your local environment\nFinally, choose Upload\nPlease make sure that all the artifacts are under s3://<your bucket name>/greengrass-app-component. This is very important to ensure the path is correct for successful deployment on an edge gateway.\nWith the AWS CloudFormation template, you can now deploy the solution which sets up the below resources on AWS.\nAmazon S3 buckets for storing waste images and weight sensor data\nNecessary IAM roles and policies to install AWS IoT Greengrass core software with fleet provisioning, AWS IoT Core, AWS Lambda functions and AWS IoT Analytics.\nAWS IoT Analytics to collect, transform, and store sensor data\nAWS IoT Core rules to read data from MQTT topics and ingest into downstream AWS IoT Analytics services\nAWS Lambda functions on AWS\nIdentifyWasteType \xe2\x80\x93 to analyze waste images using Amazon Rekognition\nCertificate provisioner \xe2\x80\x93 to create claim certs and store them in AWS Secrets\nRoleAliasProvisioner \xe2\x80\x93 to create a role that points to the token exchange role\nCreate component software to be deployed on an IoT gateway to read sensors.\nThe smart bin demo app CloudFormation template automates the above steps for setting up cloud resources. If you run this script, please follow the steps on AWS Console to complete stack deployment. After the stack is deployed, please refresh the screen until status changes to CREATE_COMPLETE.\nDeploy the latest CloudFormation template by following the link below for your preferred AWS region.\nRegion Launch Template\nUS East (N. Virginia) (us-east-1)\nUS West (Oregon) (us-west-2)\nEU (Ireland) (eu-west-1)\nEU (Frankfurt) (eu-central-1)\nAP (Sydney) (ap-southeast-2)\nIf prompted, login using your AWS account credentials.\nYou should see a screen titled Create Stack at the Specify template step. The fields specifying the CloudFormation template are pre-populated. Choose Next at the bottom of the page.\nOn the Specify stack details screen, you can customize the following parameters of the CloudFormation stack:\nParameter label Default Description\nStack name smart-bin-demo-app This is the AWS CloudFormation name once deployed\nArtefactsBucketName Provide the Amazon S3 bucket name where you uploaded the artifacts in step 4 of the prerequisite section.\nProjectName smart-bin-demo-app smart bin app project name\nResourcePrefix demo The AWS resources are prefixed based on the value of this parameter. You must change this value when launching more than once within the same account.\nWhen completed, choose Next\nConfigure stack options if desired, then choose Next.\nOn the review screen, you must check the boxes for: These are required to allow CloudFormation to create a role to grant access to the resources needed by the stack and name the resources dynamically.\nI acknowledge that AWS CloudFormation might create IAM resources\nI acknowledge that AWS CloudFormation might create IAM resources with custom names\nI acknowledge that AWS CloudFormation might require the following capability: CAPABILITY_AUTO_EXPAND.\nChoose Create Stack\nWait for the CloudFormation stack to launch. Completion is shown when the Stack status is CREATE_COMPLETE.\nYou can monitor the stack creation progress in the Events tab.\nDeploy AWS IoT Greengrass on IoT gateway\nNow that we have set up all the required resources in the AWS account on cloud, we can prepare a package to install AWS IoT Greengrass v2 core software with AWS IoT fleet provisioning.\nTo prepare the package, all the steps are part of this script. You can execute this script on the IoT device gateway or your computer. Please make sure that you have installed AWS CLI v2 with access to your AWS account.\nFor this use case, I execute on my laptop to create a package in the build directory. You can then copy the package on your IoT gateway (e.g., Raspberry Pi). The script performs the following steps.\nCreate build directory\nmkdir build && cd build\nDownload AWS CA, claim certificates from AWS Secrets Manager\nDownload AWS IoT Greengrass and fleet provisioning plugin\nGet the endpoints and fleet provisioning template for AWS IoT Core\nPrepare config.yml.\nPrepare AWS IoT Greengrass start up command\nChange execution permission\nTest the solution\nAs we have configured the Raspberry Pi with AWS IoT Greengrass core software along with automatic fleet provisioning, let us now run the AWS IoT Greengrass service.\nTest device provisioning\nConnect (ssh) to IoT device gateway (e.g., Raspberry Pi) command line terminal and run the following command to start the AWS IoT Greengrass service to auto provision, authenticate, and establish a connection to AWS IoT Core.\nsudo build/fleet_provision.sh\nOn the AWS IoT Core Console, expand the Greengrass section from the left panel and choose the Core Devices option to verify the state of device. The device status should appear healthy as below.\nIf the device does not appear healthy, then please check the AWS IoT Greengrass service log for any errors under /greengrass/v2/logs folder and follow troubleshooting documentation.\nTest remote application deployment\nUnder the AWS IoT Greengrass section, choose Component for edge application deployment. Deploy monitor_wastebin_app custom component created in step 9 of the Deploy Cloud Section. Refer to the procedures in the diagram below.\nVerify the details of version 2.0.0 and choose Deploy.\nOn deployment stage, select Create new deployment.\nOn the specify target page, select Core device as target and enter the name of core device from step 2 in section Test Greengrass device provisioning. For the rest of fields, follow the instructions on the page.\nOn the select components page, please select the following components (My components and Public components) as shown screen shot.\nFinally, check component configuration and select Next. Then on Configure advanced settings, only choose Next and move to Review. On the Review stage, choose Deploy to finish the deployment.\nPlease note that if you are redeploying the same component, then select the changed component and select Configure component in the top right corner. Then in the Configuration to merge section as shown in the following screen shot, please enter some text, e.g., \xe2\x80\x9cdeployment7.\xe2\x80\x9d\nOn the AWS IoT Greengrass console, deployment should appear as completed. If not, then just restart greengrass service on Raspberry PI using below commands.\nsudo systemctl stop greengrass.service\nsudo systemctl start greengrass.service\nTest data flow\nOn the AWS IoT Core Console, choose Test from the left panel and subscribe to the \xe2\x80\x9cdemo/smart-bin\xe2\x80\x9d MQTT topic.\nTo test E2E flow, place waste bin on gravity sensor plates. Also, make sure you can focus the camera on the waste bin. Drop a waste item in the bin. As the weight of bin changes, app uploads the latest bin weight and picture of the waste to the AWS cloud.\nVerify that AWS IoT Core receives the waste data payload on MQTT topic as explained step 1.\nData Ingestion\nOn the AWS IoT Analytics Console, query demo_trash_dataset to verify the final enriched payload.\nPrepare reports\nIf you are new to Amazon QuickSight, sign up here by following steps and choose Standard edition.\nCreate a SPICE dataset\nBefore you build dashboards, you need to first create a Super-fast, Parallel, In-memory Calculation Engine (SPICE) data set, which is the robust, in-memory engine that Amazon QuickSight uses. It\xe2\x80\x99s engineered to perform advanced calculations and serve data.\nIn the Amazon QuickSight console, choose New Dataset\nChoose AWS IoT Analytics as the data source.\nEnter the name. Choose AWS IoT Analytics demo_trash_dataset to import into SPICE dataset. Then you are all set to play with data using Amazon QuickSight.\nCreate dashboards\nBeyond collecting waste data for reporting and analysis purposes, councils and restaurant chains can build waste analytics to justify several following rationales.\nBenchmarking performance against waste minimization targets periodically by aggregating data across different dimensions.\nPlanning collections cycles and shaping future strategies around waste minimization.\nIdentifying potential problems well in advance by understanding area wise waste heatmap and already stock piled waste at depots. Use this data for building the business case for securing funding for a new recycling facility.\nReducing food waste: Restaurants can identify particular food waste across a chain of restaurants, define goals to reduce food waste, and evaluate the performance of these goals.\nThe below sample dashboard shows post code wise and date wise aggregated waste data.\nClean up\nTo avoid incurring future charges, please clean up the resources created.\nTo delete the cloud formation stack successfully, please carry out the following steps first. Otherwise, stack deletion might fail.\nPlease delete all the contents of the demo-trash-bin to make them empty\nOn the AWS IoT Core Console, choose Things under the Manage section. Then choose DemoWasteBin.\nChoose the Certificates tab. Then choose each certificate and choose Detach.\nUnder the Secure section, choose Certificates\nFinally, revoke and delete all certificates one by one by selecting Revoke and Delete from the Actions drop down under the Secure section.\nRemove the stack\nDelete AWS IoT Greengrass from the IoT gateway (Raspberry Pi) using the steps explained in the Uninstall AWS IoT Greengrass section.\nOpen the AWS CloudFormation Console.\nChoose the smart-bin-demo-app project under the stacks, then select Delete Stack.\nYour stack might take some time to delete. You can track its progress in the Events tab.\nWhen it is done, the status changes from DELETE_IN_PROGRESS to DELETE_COMPLETE. It then disappears from the list. Because the stack deletion takes time, please refresh until it shows status as DELETE_COMPLETE.\n'"
73,Automating workflows for AWS IoT Greengrass V2 components,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/07/22/AWSArchitecture.png,https://aws.amazon.com/blogs/iot/automating-workflows-for-aws-iot-greengrass-v2-components/,"b'Introduction\nAWS IoT Greengrass V2 Development Kit Command-Line Interface (GDK CLI) was announced at AWS re:Invent 2021. With GDK CLI you can easily create AWS IoT Greengrass V2 components, flexibly define recipes, and publish these components to AWS IoT Greengrass V2. However, every time there is a change to the AWS Greengrass V2 component recipe, you typically have to manually provision it. For example, every new version of the component must be re-built and re-published, resulting in redundant tasks. Additionally, if the component is part of an automated workflow, the re-building and re-publishing task becomes inconvenient for overall development efforts.\nTo overcome these challenges, you can create an automated workflow using AWS CodePipeline along with AWS CodeCommit and AWS CodeBuild. The automated workflow will build and publish the components whenever a new change to the source is detected. The solution presented in this blog demonstrates this workflow with the use of an example.\nThe following image shows an outline of AWS services used in the automated workflow. AWS CodeCommit can be replaced with other Git repositories like GitHub or GitLab and eventually mirrored into AWS CodeCommit repositories.\n1. Getting Started\nThis section highlights the basic requirements like setting up AWS Identity and Access Management (IAM) policies for different services that are being used. IAM policies define the access granted to a resource. For example, AWS CodeBuild needs to have a read/write access to AWS IoT Greengrass V2 in order to publish components.\nPre-requisites\nThe following are requirements to proceed with the build solution:\nAn AWS profile with permissions to Amazon Simple Storage Service (S3), Amazon CloudWatch, Developer Tools (AWS CodeCommit, AWS CodeBuild, AWS CodePipeline, etc.)\nUnderstanding of Python and Bash scripts\n1.1 AWS CodePipeline\nAWS CodePipeline is used for creating and managing a continuous delivery service. You can use it to manage the processes by accessing AWS CodeCommit logs. Based on the changes pushed to AWS CodeCommit, the pipeline that runs AWS CodeBuild will be triggered to run the build commands as specified. To store the build artifacts, you will need Amazon S3 access which can be enlisted from the IAM policies.\nIAM policies:\n1.2 AWS CodeCommit\nAWS CodeCommit is the source control service used to host Git repositories. This can be accomplished in a couple of different ways as follows:\nCreate a Git repository in AWS CodeCommit directly \xe2\x80\x93 there are no additional IAM policy requirements\nMirror Git repositories currently present in GitLab or GitHub into AWS CodeCommit \xe2\x80\x93 need to configure your GitLab or GitHub repository to mirror into AWS CodeCommit or migrate a Git repository to AWS CodeCommit\n1.3 AWS CodeBuild\nAWS CodeBuild defines the source in AWS CodeCommit to build the project, therefore you must configure the default IAM policy to enable access to AWS CodeCommit to implement git pull. Furthermore, access to Amazon S3 is required to store build artifacts. This is optional but good to store the artifacts for future access. To build and publish AWS IoT Greengrass V2 components, additional permissions must be added to list and create components:\nIAM policies:\n1.4 AWS IoT Greengrass V2\nOnce the component is built and published to AWS IoT Greengrass V2, you will be able to access the component from the AWS IoT Greengrass V2 console or CLI. AWS IoT Greegrass V2 Deployments can be made as required once the right component is published and available.\n2. Managing Source and Build\nTo build and publish a component with GDK you can use Python and Bash scripts. This section demonstrates how a GDK Python sample can be used to accomplish building and publishing of a component.\n2.1 GDK\nStep 2.1.1: Using a GDK Python sample\nFor Python component, use GDK to create a basic sample. The command will create following files:\n- README.md - A standard Readme file\n- gdk-config.json - Used to define the GDK build parameters\n- recipe.yaml - Used to define the component run processes and related parameters\n- main.py - An example Python script that will be run once the component is deployed\n- src/ - Directory with a supporting script for main.py\n- tests/ - Directory with test scripts\nMarkup\nCommands to create a default Python based component:\n$ mkdir HelloWorldPython\n$ cd HelloWorldPython/\n$ gdk component init -l python -t HelloWorld\nBash\nStep 2.1.2: Modifying the GDK Python sample\nNext, modify the default main.py script and the src/greeter.py script as shown below. Add a sample run.sh bash script too. Currently, for examples, GDK supports Python and Java. However, if your applications require running binaries, Bash scripts, or any other Terminal/CMD commands, then you can use run.sh Bash script. Hence, instead of running main.py Python script directly, the run.sh Bash script can be used to execute it.\nHere is an example of the modified main.py script:\nimport sys\nimport src.greeter as greeter\n\ndef main():\n    args = sys.argv[1:]\n    if len(args) == 2:\n        print(greeter.get_greeting(args[0], args[1]))\n\nif __name__ == ""__main__"":\n    main()\nPython\nHere is an example of the modified src/greeter.py script:\ndef get_greeting(msg1, msg2):\n   """"""\n   Returns greeting string\n\n   Parameters\n   ----------\n       msg1(string): msg1 to append in the greeting.\n       msg2(string): msg2 to append in the greeting.\n\n   Returns\n   -------\n       string : Returns greeting for the name\n   """"""\n\n   print(\'The message is {} and {}!\'.format(msg1, msg2))\n   return \'{} {}!\'.format(msg1, msg2)\nPython\nHere is an example of what is contained in the run.sh script:\n#!/bin/bash\n\nprint_usage() { printf ""Usage: run.sh -a message1 -b message2"" }\n\nwhile getopts a:b: flag; do\n    case ""${flag}"" in\n        a) message1=${OPTARG} ;;\n        b) message2=${OPTARG} ;;\n        *) print_usage\n            exit 1 ;;\n    esac\ndone\n\necho ""Message #1 = $message1""\necho ""Message #2 = $message2""\n\necho ""Running main.py script ...""\npython3 -u main.py $message1 $message2\nBash\nHere is an example of what is contained in the updated gdk-config.json file:\n{\n  ""component"": {\n    ""com.example.HelloWorldPython"": {\n      ""author"": ""<PLACEHOLDER_AUTHOR>"",\n      ""version"": ""0.0.1"",\n      ""build"": {\n        ""build_system"": ""zip""\n      },\n      ""publish"": {\n        ""bucket"": ""<PLACEHOLDER FOR BUCKET>"",\n        ""region"": ""<PLACEHOLDER FOR REGION>""\n      }\n    }\n  },\n  ""gdk_version"": ""1.0.0""\n}\nJSON\nHere is an example of what is contained in the updated recipe.yaml file:\n---\nRecipeFormatVersion: ""2020-01-25""\nComponentName: ""{COMPONENT_NAME}""\nComponentVersion: ""0.0.1""\nComponentDescription: ""This is simple Hello World component written in Python.""\nComponentPublisher: ""{COMPONENT_AUTHOR}""\nComponentConfiguration:\n  DefaultConfiguration:\n    configMessage1: ""Hello""\n    configMessage2: ""World""\nManifests:\n  - Platform:\n      os: all\n    Artifacts:\n      - URI: ""s3://BUCKET_NAME/COMPONENT_NAME/COMPONENT_VERSION/HelloWorldPythonComponent.zip""\n        Unarchive: ZIP\n    Lifecycle:\n      Run: ""/bin/bash {artifacts:decompressedPath}/HelloWorldPythonComponent/run.sh -a {configuration:/configMessage1} -b {configuration:/configMessage2}\nYAML\nAdd a buildspec.yml file that will be used by AWS CodeBuild to run commands for pre-build, build, and post-build processes. Here is an example of a buildspec.yml file with the necessary commands:\nversion: 0.2\n\nphases:\n  install:\n    commands:\n      - apt-get update && apt-get install -y zip unzip build-essential wget git curl software-properties-common python3.7 python3-pip\n      - curl ""https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"" -o ""awscliv2.zip"" && unzip awscliv2.zip && ./aws/install && rm awscliv2.zip\n  build:\n    commands:\n      - python3 -m pip install -U git+https://github.com/aws-greengrass/aws-greengrass-gdk-cli.git@v1.1.0\n      - export PATH=$PATH:~/.local/bin\n      - CURRDIR=$(basename ""$PWD"")\n      - cd ../ && mv $CURRDIR HelloWorldPythonComponent && cd HelloWorldPythonComponent\n      - gdk component build\n      - gdk component publish\n      - mkdir package && cp -r greengrass-build package/. && cp -r zip-build package/.\n      - pwd && ls -al && ls -al ..\nartifacts:\n  files:\n    - package/**/*\n  name: gg-component-$(date +%Y-%m-%d-%H-%M-%S).zip\nYAML\n2.2. AWS CodeCommit\nTo create the AWS CodeCommit repository, from the Developer Tools, select CodeCommit and Create repository. This would prompt for details like Repository name, Tags, etc. Once created, you can push the code that has been previously created.\nThe following image shows an example of an AWS CodeCommit repository with the necessary files required for GDK CLI component build and publish commands. This also contains the modified scripts namely run.sh, main.py, src/greeter.py , recipe.yaml, gdk-config.json, and buildspec.yml.\n2.3. AWS CodeBuild\nThe next step is to setup AWS CodeBuild to use the above AWS CodeCommit repository as a source and use build commands provided in the buildspec.yml file to run the build process. For this, select CodeBuild from Developer Tools and create project. The process to setup the AWS CodeBuild is as follows:\nStep 2.3.1: Setting up build environment\nTo set the build environment for AWS CodeBuild, use the Amazon Elastic Container Registry (ECR) service with Ubuntu 18.04: public.ecr.aws/ubuntu/ubuntu:18.04. Following shows how the build environment is setup:\nStep 2.3.2: Selecting the source for build\nFor the source, connect the AWS CodeCommit repository and point it to the right Branch/Tag/Commit ID. In this example it will be connected to the master branch. Select the IAM policies that were provisioned earlier:\nStep 2.3.3: Selecting the commands to run the build\nNext, define the Buildspec which uses the commands to run the actual build. This buildspec is defined in the buildspec.yml which is a part of the source. Hence you need to provide the file name here. Optionally build commands can be added here if not using a buildspec.yml file.\nStep 2.3.4: Storing the build artifacts\nIn order to store the build artifacts, connect the right Amazon S3 bucket. Select zip as an option to save the build artifacts in a compressed package in the Amazon S3 location:\n2.4 Creating Pipeline\nTo manage the artifacts, GDK build, and to publish changes, you can create the build pipeline and automate the build processes.\nStep 2.4.1: Choosing pipeline settings\nFrom the Developer Tools, select CodePipeline and create a new Pipeline. For the service roles, select the role that was defined earlier.\nStep 2.4.2: Add source stage\nNext, choose the AWS CodeCommit repository and branch that was created earlier. Select Amazon CloudWatch Events in this section which would trigger the Pipeline to start if it detects any changes in the Amazon CloudWatch Events of the AWS CodeCommit repository mentioned here.\nStep 2.4.3: Add build stage\nNow, connect the AWS CodeBuild Project in this stage which would trigger the build from the source AWS CodeCommit changes.\nStep 2.4.4: Add deploy stage\nIf you are connecting the pipeline with the AWS CodeDeploy, you can use this section to add that part. Skip AWS CodeDeploy stage as this is not demonstrated here.\nStep 2.4.5: Review the pipeline\nNow that all the pieces are connected, you can create your pipeline. The pipeline when invoked through Amazon CloudWatch Events, it would trigger the build. The following image shows the flow that is defined in the AWS CodePipeline. Here, the source is connected to the build. Hence, the pipeline pulls from the source first and then runs the build commands mentioned in the AWS CodeBuild buildspec.yml.\n3. Deploy the component\n3.1. Check logs of AWS CodePipeline\nOnce AWS CodePipeline runs successfully, the component would be built and published.\nTo check the logs, go to AWS CodeBuild project and select the Build logs from the Build history.\nUpon checking the logs, you can make sure that the component is stored in the Amazon S3 bucket and is also published to AWS IoT Greengrass V2 Components.\n3.2. Checking the component in AWS IoT Greengrass V2\nOnce the component is available in AWS IoT Greengrass V2, it can be deployed on the IoT Things. You can do this by revising existing deployments using the updated component or by creating new deployment for the IoT Thing or Thing groups.\nUpon checking the component in the AWS IoT Greengrass V2 console, you can see the details like the \xe2\x80\x98Default configuration,\xe2\x80\x99 \xe2\x80\x98Lifecycle\xe2\x80\x99 details, and \xe2\x80\x98Artifacts\xe2\x80\x99 location in Amazon S3 bucket, all of which is based on the recipe.yaml script.\n4. Cleanup\nAWS CodePipeline is provisioned to listen to Amazon CloudWatch Events so every small update to the AWS CodeCommit repository will trigger the pipeline and it will build and publish components. Hence, the pipeline can be stopped by selecting the Stop execution.\nThis would also prevent updating build artifacts as well as component artifacts in Amazon S3.\n5. '"
74,Configuring near real-time notification for asset based monitoring with AWS IoT Events,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/configuring-near-real-time-notification-for-asset-based-monitoring-with-aws-iot-events/,"b'Introduction\nIn today\xe2\x80\x99s market, business success often lies in the ability to glean accurate insights and prediction. However, floor engineers and analysts have a hard time getting the information at the right instance to make an informed decision when there is a failure during operations.\nTo make it easy to detect and respond to events from IoT sensors and applications, AWS IoT Events allows you to detect events across thousands of IoT sensors sending different telemetry data. Events are patterns of data that could help identify more complicated circumstances than expected, such as changes in equipment when a belt is stuck, or motion detectors using movement signals to activate lights and security cameras. AWS IoT Events allows you to simply select the relevant data sources to ingest, define the logic for each event using simple \xe2\x80\x98if-then-else\xe2\x80\x99 statements, and select the alert or custom action to trigger when an event occurs. It continuously monitors data from multiple IoT sensors and applications, and integrates with other services, such as AWS IoT Core, to enable early detection and unique insights into events.\nIn this blog post, we explain how to design AWS IoT Events for two key issues faced by customers:\n1. How to monitor and send alerts for assets at scale.\n2. How to suppress repeated alerts during failures.\nSolution overview\nIn this post, we describe the configuration of AWS IoT Events and Amazon Simple Notification Service (SNS) to send near real-time notification during failures, and cover data analysis using Amazon Athena.\n  Architecture for near real-time notification using AWS IoT Events\nSolution walk through\n1) Prerequisites / Assumptions\nWe assume the following services are configured in your AWS environment, and devices are connected to AWS IoT core, for example a conveyor motor.\na) An on-premises edge gateway server where AWS IoT Greengrass service is running with required AWS IoT certificates and connected to AWS IoT Core as shown in the architecture. Additionally, your edge gateway sends data to the AWS IoT Core topic \xe2\x80\x98iot/topic\xe2\x80\x99 which can be routed to other permitted AWS services via AWS IoT Rules.\nb) An Amazon Simple Storage Service (Amazon S3) exists in your AWS account that you can use throughout this blog post. Throughout the blog post we assume the Amazon S3 bucket name is datalakes3bucket. We will use a sub-folder within that bucket that we call datastore. For security reasons we recommend turning on server-side encryption for your Amazon S3 bucket.\nc) An existing Amazon SNS topic with subscription pointing to desired email or mobile number in your AWS account. Throughout the blog post we assume that the topic name is \xe2\x80\x98iot/topic.\xe2\x80\x99\n2) Setting up the data lake\nThis section talks about setting up data analytics that can be used to run analytics on the stored data. Data received in AWS IoT Core on a topic in the message broker is then forwarded to Amazon Kinesis Data Firehose. Kinesis Data Firehose is an extract, transform, and load (ETL) service that reliably captures, transforms, and delivers streaming data to storage destinations like Amazon S3.\nStep 1: Configure AWS Key Management Service (AWS KMS) for encrypting data at rest in the Kinesis Data Firehose delivery stream.\na)  Sign in to the AWS Management Console\nb)  Search for AWS KMS\nc)   Select Create new\nd)  Choose the Key type to be Symmetric\ne)  Leave the rest as default and create the key\n                                                          Creating a symmetric key in AWS Key Management Service\nThis KMS key will be used while configuring Kinesis Data Firehose delivery stream in subsequent steps.\nStep 2: Configure Amazon CloudWatch log group and log stream which will store the Kinesis Data Firehose log information.\na)   Search Amazon CloudWatch\nb)   Select Log groups\nc)   Supply the log group name, in this blog post we will use <example>\nd)  Set the retention period according to your requirements\n                                                                  Setup Amazon CloudWatch log group for the Kinesis Data Firehose delivery stream\nStep 3: Create a role with permissions in Amazon Identity and Access Management (IAM) that allows the Kinesis Data Firehose delivery stream to access the AWS KMS Key as well as the S3 bucket.\na)  Search AWS IAM\nb)  Select Policies\nc)  Substitute below policy document\nHere and throughout this post, remember to replace the placeholder account ID with your own account ID, region with your own region, s3 bucket with your own bucket name.\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": [\n     {\n         ""Sid"": """",\n         ""Effect"": ""Allow"",\n         ""Action"": [\n             ""s3:AbortMultipartUpload"",\n             ""s3:GetBucketLocation"",\n             ""s3:GetObject"",\n             ""s3:ListBucket"",\n             ""s3:ListBucketMultipartUploads"",\n             ""s3:PutObjectAcl"",\n             ""s3:PutObject""\n         ],\n         ""Resource"": [\n           ""arn:aws:s3:::datalakes3bucket"",\n           ""arn:aws:s3:::datalakes3bucket/datastore/*""\n         ]\n     },\n     {\n        ""Sid"": """",\n        ""Effect"": ""Allow"",\n        ""Action"": [\n          ""kms:GenerateDataKey"",\n          ""kms:DescribeKey""\n      ],\n      ""Resource"": ""arn:aws:kms:<region>:123456789012:key/<s3 bucket kms key>""\n      },\n      {\n         ""Sid"": """",\n         ""Effect"": ""Allow"",\n         ""Action"": ""logs:PutLogEvents"",\n         ""Resource"": ""arn:aws:logs:<region>:123456789012:log-group:/aws/kinesisfirehose/kinesis-log-group:log-stream:kineis-log-stream""\n      }\n    ]\n}\nJSON\nNext we will create the role to for the Kinesis Data Firehose delivery stream will assume. We also will attach the permission policy created above.\na)   Select Roles\nb)  Choose Create role\nc)   Within the Use case selection menu, choose Kinesis and then Kinesis Firehose\nd)  In the Permission policies selection field, search and choose the permission policy created above.\ne)   Give the role a name, leave the rest as default and choose Create role\nStep 4: Configure the Kinesis Data Firehose delivery stream to send data to the S3 bucket.\na)   Search Amazon Kinesis\nb)   Choose Create delivery stream\nc)   Set source as Direct PUT\nd)  Set destination to Amazon S3\ne)  Set the Delivery stream name\nf)   Select your pre-created S3 bucket in the Destination settings\nSupply Destination settings\ng)   Go to Advanced settings\nh)  Enable Amazon CloudWatch Error logging\ni)  Enable Server-Side encryption with the AWS KMS key you created\nj)  In the Permissions section, Choose existing IAM role and select the role we created in Step 3\nk)  Leave all the other options as default and choose Create delivery stream\nConfigure the Advanced settings in the Kinesis Data Firehose delivery stream creation\nStep 5: Setup an AWS IoT Core rule to filter data received on a topic (iot/topic) and route it to the Kinesis Data Firehose delivery stream. Please see the example data below that might arrive on the topic:\n{\n""Plant"":\n""demo"",\n""MachineName"":\n""conveyor-motor"",\n""EngineName"":\n""engine1"",\n""MessageTimestamp"":\n""2022-01-01"",\n""temperature"": 90,\n""amps"": 15,\n""Vibration"": 100\n}\nJSON\nSample Data send from the edge device to the AWS IoT Core message broker\na) In the console, search AWS IoT Core and select Rules under Act\nb) Select Create rule and provide it with a Name and Description. Choose Next\nSupply AWS IoT Core rule name\nc) We use a SQL statement to filter the incoming data on the topic to only receive required fields from the messages. Copy and paste the below query statement into the field of the SQL statement\nSELECT MachineName, EngineName, MessageTimestamp, temperature, amps, Vibration FROM \xe2\x80\x98iot/topic\xe2\x80\x99\nd) Choose Next\ne)  In the section Rule actions, select Kinesis Firehose stream; search for the Kinesis Firehose stream we created prior\nf) Choose Create new role in the Field below IAM role to create a new role with the according permissions\nStep 6. We need to allow the Kinesis data firehose stream to use the AWS KMS key through adjusting the resource policy in AWS KMS.\na) Modify resource policy of the AWS KMS key associated with the Amazon S3 bucket to allow the Kinesis data firehose stream to use it\n{\n  ""Version"": ""2012-10-17"",\n  ""Id"": ""key-consolepolicy"",\n  ""Statement"": [\n    {\n      ""Sid"": ""Allow Kinesis to use the key"",\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""AWS"": "" arn:aws:iam::123456789012:role/firehoserole""\n    },\n    ""Action"": [\n      ""kms:GenerateDataKey*"",\n      ""kms:DescribeKey""\n    ],\n    ""Resource"": "" arn:aws:kms:<region>:123456789012:key/<s3 bucket kms key>""\n    }\n  ]\n}\nJSON\n3) Setup services for near real time alerting and notification\nStep 1. Let\xe2\x80\x99s configure AWS IoT Events for near real-time configuration\na) Search AWS IoT Events\nb) Select Inputs and Create input. For this Blog Post we chose the Input name to be Alert_Input.\nc)  Below you find the content for the JSON file you need to create and upload as part of the Input configuration\n{\n\n""MachineName"": ""<Machine Name/ID>"",\n\n""EngineName"": ""<Engine Name/ID>"",\n\n""MessageTimestamp"": ""<TimeStamp>"",\n\n""temperature"": <temp>,\n\n""amps"": <amps>,\n\n""Vibration"": <vibration>\n\n}\nJSON\nInput configuration within AWS IoT Events\nStep 2. Let\xe2\x80\x99s now setup the AWS IoT Rule to route incoming data to AWS IoT Events.\na) Search AWS IoT Core and select Rules under Act\nb) Enter the name for the AWS IoT Rule and choose Next\nc) Paste the SQL query to see below into the SQL statement field; replace the topic name placeholder in the FROM section with the topic where your data arrives\nd) Choose Next\nSELECT NodeID as MachineName, SubNodeID as EngineName, MessageTimestamp,<br />  get(get((SELECT Values FROM Data WHERE Name = \'engine1/temp\'), 0).Values, 0).Value AS<br />  temperature, get(get((SELECT Values FROM Data WHERE Name = \'engine1/amps\'), 0).Values, 0).Value AS amps,<br />   get(get((SELECT Values FROM Data WHERE Name = \'engine1/vib\'), 0).Values, 0).Value AS Vibration FROM \'iot/topic\'\nSQL\nIn the above query we are selecting the columns names from the topic. The get() function used to read the values from the zeroth element from the nested json object.\ne) As Rule actions, select IoT Event and choose the previously created Input name in the dropdown menu.\nStep 3. In this section, you define a detector model (a model of your equipment or process) using states. For each state, you define conditional (Boolean) logic that evaluates the incoming inputs to detect a significant event. When an event is detected, it changes the state and can trigger additional actions.\nIn your states, you also define events that can execute actions whenever the detector enters or exits that state or when an input is received (these are known as OnEnter, OnExit and OnInput events). The actions are executed only if the event\xe2\x80\x99s conditional logic evaluates to true. We are going to see how to send notification when threshold is breached and also set timer between subsequent alert notifications. In the following steps we will go through all the states, their definitions as well as connections needed to create the whole detector model.\na) Search AWS IoT Events.\nb) Select Create detector model, and then Create new\nc) The first detector state has been created for you. To modify it, select the circle with label State_1 in the main editing space and set the State name to \xe2\x80\x9cRunning\xe2\x80\x9d\nConfiguring the first AWS IoT Event state\nd) In the field of OnEnter choose Add event. On the OnEnter event page, enter an Event name and the Event condition. The name of the event is init and the event condition is true. This indicates that the event is always triggered when the state is entered.\ne) Choose Add action\nSelect Set variable\nFor Variable operation, choose Assign value\nFor Variable name, enter the name of the variable to set\nFor Variable value, enter the value 0 (zero)\nConfiguring OnEnter event for State Running\nf) Choose Save\ng) Create another state by dragging and dropping State button. Modify the state name to Danger_OverVibration. In this state, we are evaluating if vibration exceeded threshold, if so then the action is set to send alert event to Amazon SNS\nConfiguring Danger_OverVibration State\nh) Pause on the first state (Running). An arrow appears on the circumference of the state.\ni) Click and drag the arrow from the first state (Running) to the second state (Danger_OverVibration). A directed line from the first state to the second state (labeled Untitled) appears.\nj) Select the Untitled line. In the Transition event pane, enter an Event name and Event trigger logic.\n Event name: OverVibration\n Event Logic: $input.Alert_Input.Vibration > Threshold limit\n Event Actions:\n  Set variable:\n   Variable Operation: Assign Value\n   Variable name: vibThresholdBreached\n   Assign Value: $variable.vibThresholdBreached + 3\nk) Choose Save\nl) Pause on the second state (Danger_OverVibration). An arrow appears on the circumference of the state.\nm) Click and drag the arrow from the second state (Danger_OverVibration) to the first state (Running). A directed line from the second state to the first state (labeled Untitled) appears.\nn) Select the Untitled line. In the Transition event pane, enter an Event name and Event trigger logic.\n Event name: VibBackToNormal\n Event Logic: $input.Alert_Input.Vibration < Threshold limit && $variable.vibThresholdBreached <= 0\no) Choose Save\np) In the field of OnEnter choose Add event. On the OnEnter event page, enter an Event name and the Event condition. The name of the event is Vibration_Breached and the event condition $variable.vibThresholdBreached > 1\n1) Choose Add action\nEvent name: Vibration_Breached\nEvent condition: $variable.vibThresholdBreached > 1\nEvent actions:\n Set Variable:\n  Variable operation: Assign Value\n  Variable name: initVibNotification\n  Assign value: 1\n2) Choose Save\nq. In the field of OnInput choose Add Event. We need to create an event condition to send email alert, then start a timer (5 mins) so that during this period subsequent email alerts will not be triggered, and finally trigger email when timeout ends. This process will continue until the vibration drops below threshold thereby ensuring email notification but only once within the time limit.\n          1)    Choose Add action\nEvent name: Email Alert\nEvent condition: $variable.vibThresholdBreached > 2 && $variable.initVibNotification == 1\nEvent actions:\n Set Timer:\n  Select operation: Create\n  Timer name: vibTimer\n  Enter duration: 5 Minutes (This is the time during which alert will be disabled)\n Send SNS message\n  SNS Topic: arn:aws:sns: :<region>:123456789012:<Topic Name>\n  Select Default Payload\n  Payload Type: JSON\n Set Variable:\n  Variable operation: Assign Value\n  Variable name: initVibNotification\n  Assign Value: 0\n2)  Choose Save\n3)  Choose Add action\nEvent name: OverVibration\nEvent condition: $input.Alert_Input.Vibration > Threshold limit\nEvent actions:\n  Set Variable:\n    Variable operation: Assign Value\n    Variable name: vibThresholdBreached\n    Assign Value: 3\n4) Choose Save\n5) Choose Add action\nEvent name: TimerCheck\nEvent condition: timeout(""vibTimer"")\nEvent actions:\n  Set Variable:\n    Variable operation: Assign Value\n    Variable name: initVibNotification\n    Assign Value: 1\n6)  Choose Save\n7)  Choose Add action\nEvent name: Normal\nEvent condition: $input.Alert_Input.Vibration < <Threshold limit>\nEvent actions:\n  Set Timer:\n    Select operation: Destroy\n    Timer name: vibTimer\n  Set Variable:\n    Variable operation: Decrement\n    Variable name: vibThresholdBreached\n  Set Variable:\n    Variable operation: Assign Value\n    Variable name: initVibNotification\n    Assign Value: 1\n8)  Choose Save\nr)  In the field of OnExit choose Add event. On the OnEnter event page, enter an Event name and the Event condition. The name of the event is Normal_Vibration_Restored and the event condition true.\na) Choose Add action\nEvent actions:\n  Set SNS message:\n    SNS Topic: arn:aws:sns: :<region>:123456789012:<Topic Name>\n    Select Default Payload\n    Payload Type: JSON\nb)  Choose Save\n4) Analyzing Data using Amazon Athena\nAWS Glue is a serverless data integration service that makes it easy to discover, prepare, and combine data for analytics, machine learning, and application development. The AWS Glue Crawler recognizes the partition structure of the dataset and populates the AWS Glue data catalog. Once crawled, the AWS Glue catalog groups data into logical tables and makes partition columns available for querying through Athena, which can be connected to any preferred business intelligence tool for visualization.\n1. Search for AWS Glue\n2. Navigate to Crawlers\n3. Click on Add Crawler\n4. Create an AWS Glue table. See the screenshot below to get insights into the configuration used.\n    Crawler configuration\n5) Query the data using Athena\nDaily Data View: In the below example we are creating a view from the sample data by flattening the json data.\nCREATE OR REPLACE VIEW view_name AS<br />WITH<br />dataset AS (<br />SELECT<br />schemaversion<br />, nodeid<br />, CAST(""from_iso8601_timestamp""(messagetimestamp) AS timestamp) Message_TimeStamp<br />, CAST(""from_iso8601_timestamp""(messagetimestamp) AS date) Message_Date<br />, subnodeid<br />, compressed<br />, ""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 1) engine1_amp<br />, CAST(""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 2) AS double) value_engine1_amp<br />, ""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 3) engine1_vib<br />, CAST(""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 4) AS double) value_engine1_vib<br />, ""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 5) engine1_temp<br />, CAST(""split_part""(""replace""(""replace""(""replace""(""json_format""(CAST(data AS json)), \'""\', \'\'), \'[\', \'\'), \']\', \'\'), \',\', 6) AS double) value_engine1_temp<br />FROM<br />\xe2\x80\x9cathenaad\xe2\x80\x9c.""assetbasedmonitoring""<br />ORDER BY messagetimestamp DESC<br />)<br />SELECT *<br />FROM<br />dataset<br />WHERE (Message_Date = current_date)<br />ORDER BY Message_TimeStamp DESC\nSQL\nClean up the resources\nTo avoid incurring future charges, follow these steps to remove the example resources:\n1. Delete the IoT Events model. Search IoT Events, Under Detector models select the model created and select Delete.\n2. Delete the IoT Events Input. Search IoT Events, Under Inputs select the Input created and select Delete.\n3. Delete the AWS Glue database and table. Search Glue, under Tables select the table that was created, click on Action drop down and select Delete table.\n4. Delete AWS Athena. Search Athena, under Workgroups select the workgroup that was created, click on Action drop down and select Delete.\n'"
75,Scaling for Complexity – Architecting for Performant Embedded Devices at the Edge – Part 2,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/06/24/Screen-Shot-2022-06-25-at-12.11.21-AM-1024x327.png,https://aws.amazon.com/blogs/iot/scaling-for-complexity-architecting-for-performant-embedded-devices-at-the-edge-part-2/,"b'The following is a survey paper, published and presented to the Academic Congress of Embedded World 2022 at Nuremberg, Germany on June 21st 2022.\nPart 1 \xe2\x80\x93 Scaling for Complexity \xe2\x80\x93 Architecting for Performant Embedded Devices at the Edge \xe2\x80\x93 Part 1\nProvisioning Layer\nThe provisioning layer of your IoT workloads consists of the Public Key Infrastructure (PKI) used to create unique device identities and the application workflow that provides configuration data to the device. The provisioning layer is also involved with ongoing maintenance and eventual decommissioning of devices over time. IoT applications need a robust and automated provisioning layer so that devices can be added and managed by your IoT application in a frictionless way. When you provision IoT devices, you must install a unique cryptographic credential onto them. Typically, AWS IoT devices use X.509 certificates, while mobile applications use Amazon Cognito identities or other custom mechanisms.\nBy using X.509 certificates, you can implement a provisioning layer that securely creates a trusted identity for your device that can be used to authenticate and authorize against your communication layer. X.509 certificates are issued by a trusted entity called a certificate authority (CA). While X.509 certificates do consume resources on constrained devices due to memory and processing requirements, they are an ideal identity mechanism due to their operational scalability and widespread support by standard network protocols.\nAWS Certificate Manager Private CA helps you automate the process of managing the lifecycle of private certificates for IoT devices using APIs. Private certificates, such as X.509 certificates, provide a secure way to give a device a long-term identity that can be created during provisioning and used to identify and authorize device permissions against your IoT application.\nAWS IoT Just-In-Time Registration (JITR) enables you to programmatically register devices to be used with managed IoT platforms such as AWS IoT Core. With Just-In-Time Registration, when devices are first connected to your AWS IoT Core endpoint, you can automatically trigger a workflow that can determine the validity of the certificate identity and determine what permissions it should be granted.\nCommunication Layer\nThe Communication layer handles the connectivity, message routing among remote devices, and routing between devices and the cloud.\nThe Communication layer lets you establish how IoT messages are sent and received by devices, and how devices represent and store their physical state in the cloud. AWS IoT Core helps you build IoT applications by providing a managed message broker that supports the use of the MQTT protocol to publish and subscribe IoT messages between devices.\nThe AWS IoT Device Registry helps you manage and operate your things. A thing is a representation of a specific device or logical entity in the cloud. Things can also have custom defined static attributes that help you identify, categorize, and search for your assets once deployed.\nWith the AWS IoT Device Shadow Service, you can create a data store that contains the current, last reported, and desired state of a particular device. The Device Shadow Service maintains a virtual representation of each of your devices you connect to AWS IoT as a distinct device shadow. Each device\xe2\x80\x99s shadow is uniquely identified by the name of the corresponding thing.\nWith Amazon API Gateway, your IoT applications can make HTTP requests to control your IoT devices. IoT applications require API interfaces for internal systems, such as dashboards for remote technicians, and external systems, such as a home consumer mobile application. With Amazon API Gateway, you can create common API interfaces without provisioning and managing the underlying infrastructure.\nIngestion Layer\nA key business driver for IoT is the ability to aggregate all the disparate data streams created by your devices and transmit the data to your IoT application in a secure and reliable manner. The ingestion layer plays a key role in collecting device data while decoupling the flow of data with the communication between devices.\nWith AWS IoT rules engine, you can build IoT applications such that your devices can interact with AWS services. AWS IoT rules are evaluated and actions are performed based on the MQTT topic stream a message is received on.\nAmazon Kinesis is a managed service for streaming data, enabling you to get timely insights and react quickly to new information from IoT devices. Amazon Kinesis integrates directly with the AWS IoT rules engine, creating a seamless way of bridging from a lightweight device protocol of a device using MQTT with your internal IoT applications that use other protocols.\nSimilar to Kinesis, Amazon Simple Queue Service (Amazon SQS) should be used in your IoT application to decouple the communication layer from your application layer for critical event processing. Amazon SQS enables an event-driven, scalable ingestion queue when your application needs to process IoT applications where message order is not required.\nAnalytics Layer\nOne of the benefits of implementing IoT solutions is the ability to gain deep insights and data about what\xe2\x80\x99s happening in the local/edge environment. A primary way of realizing contextual insights is by implementing solutions that can process and perform analytics on IoT data.\nStorage Services\nIoT workloads are often designed to generate large quantities of data. Ensure that this discrete data is transmitted, processed, and consumed securely, while being stored durably.\nAmazon S3 is object-based storage engineered to store and retrieve any amount of data from anywhere on the internet. With Amazon S3, you can build IoT applications that store large amounts of data for a variety of purposes: regulatory, business evolution, metrics, longitudinal studies, analytics machine learning, and organizational enablement. Amazon S3 gives you a broad range of flexibility in the way you manage data for not just for cost optimization and latency, but also for access control and compliance.\nAnalytics and Machine Learning Services\nAfter your IoT data reaches a central storage location, you can begin to unlock the full value of IoT by implementing analytics and machine learning on device behavior. With analytics systems, you can begin to operationalize improvements in your device firmware, as well as your edge and cloud logic, by making data-driven decisions based on your analysis. With analytics and machine learning, IoT systems can implement proactive strategies like predictive maintenance or anomaly detection to improve the efficiencies of the system.\nAWS IoT Analytics makes it easy to run sophisticated analytics on volumes on IoT data. AWS IoT Analytics manages the underlying IoT data store, while you build different materialized views of your data using your own analytical queries or Jupyter notebooks.\nAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to manage, and customers pay only for the queries that they run.\nAmazon SageMaker is a fully managed platform that enables you to quickly build, train, and deploy machine learning models in the cloud and the edge layer. With Amazon SageMaker, IoT architectures can develop a model of historical device telemetry in order to infer future behavior.\nApplication Layer\nAWS IoT provides several ways to ease the way cloud native applications consume data generated by IoT devices. These connected capabilities include features from serverless computing, relational databases to create materialized views of your IoT data, and management applications to operate, inspect, secure, and manage your IoT operations.\nManagement Applications\nThe purpose of management applications is to create scalable ways to operate your devices once they are deployed in the field. Common operational tasks such as inspecting the connectivity state of a device, ensuring device credentials are configured correctly, and querying devices based on their current state must be in place before launch so that your system has the required visibility to troubleshoot applications.\nAWS IoT Device Defender is a fully managed service that audits your device fleets, detects abnormal device behavior, alerts you to security issues, and helps you investigate and mitigate commonly encountered IoT security issues.\nAWS IoT Device Management eases the organizing, monitoring, and managing of IoT devices at scale. At scale, customers are managing fleets of devices across multiple physical locations. AWS IoT Device Management enables you to group devices for easier management. You can also enable real-time search indexing against the current state of your devices through Device Management Fleet Indexing. Both Device Groups and Fleet Indexing can be used with Over the Air Updates (OTA) when determining which target devices must be updated.\nUser Applications\nIn addition to managed applications, other internal and external systems need different segments of your IoT data for building different applications. To support end-consumer views, business operational dashboards, and the other net-new applications you build over time, you will need several other technologies that can receive the required information from your connectivity and ingestion layer and format them to be used by other systems.\nDatabase Services \xe2\x80\x93 NoSQL and SQL\nWhile a data lake can function as a landing zone for all of your unformatted IoT generated data, to support all the formatted views on top of your IoT data, you need to complement your data lake with structured and semi structured data stores. For these purposes, you should leverage both NoSQL and SQL databases. These types of databases enable you to create different views of your IoT data for distinct end users of your application.\nAmazon DynamoDB is a fast and flexible NoSQL database service for IoT data. With IoT applications, customers often require flexible data models with reliable performance and automatic scaling of throughput capacity.\nWith Amazon Aurora your IoT architecture can store structured data in a performant and cost-effective open-source database. When your data needs to be accessible to other IoT applications for predefined SQL queries, relational databases provide you another mechanism for decoupling the device stream of the ingestion layer from your eventual business applications, which need to act on discrete segments of your data.\nCompute Services\nFrequently, IoT workloads require application code to be executed when the data is generated, ingested, or consumed/realized. Regardless of when compute code needs to be executed, serverless compute is a highly cost-effective choice. Serverless compute can be leveraged from the edge to the core and from core to applications and analytics.\nAWS Lambda allows you to run code without provisioning or managing servers. Due to the scale of ingestion for IoT workloads, AWS Lambda is an ideal fit for running stateless, event-driven IoT applications on a managed platform.\n'"
76,Scaling for Complexity – Architecting for Performant Embedded Devices at the Edge – Part 1,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/06/24/Screen-Shot-2022-06-25-at-12.11.21-AM-1024x327.png,https://aws.amazon.com/blogs/iot/scaling-for-complexity-architecting-for-performant-embedded-devices-at-the-edge-part-1/,"b'The following is a survey paper, published and presented to the Academic Congress of Embedded World 2022 at Nuremberg, Germany on June 21st 2022.\nAbstract\nEmbedded edge devices with multi-sensor data sources are proliferating at an accelerating rate. Devices must be designed, manufactured, installed, connected, and controlled through seven distinct logical layers to securely connect and interact with complementary cloud-based and edge-based components to deliver business value. These Internet of Things (IoT) applications must gather, process, analyze, and act on data generated by the connected devices. In this paper, you will discover how to make informed tradeoffs with end-to-end architecture challenges based upon your business and performance context. We will discuss the best practices and relations between the Design and Manufacturing, Edge, Provisioning, Communication, Ingestion, Analytics, and Application layers and how a properly designed edge architecture allows complex scaling scenarios.\nProliferation of Devices\nMore companies than ever are integrating connected devices and discovering new ways to use and manage business data. Companies that once looked at IoT as a theoretical concept today have made it a high priority.\nEvery second, hundreds of devices are being connected to the Internet for the first time. That\xe2\x80\x99s 10 million new devices every day, and a clear signal the demand for IoT is skyrocketing. As reports forecast, the number of IoT connected devices will jump by double digits this year alone. That is nearly double the growth seen in 2021.\nDespite the fears that economic slowdown would delay business adoption of IoT solutions, the markets are growing by leaps and bounds. Consider:\nIn 2025, as many as 150,000 IoT devices will be connecting to the internet every minute.\nThe number of cellular IoT connections is expected to reach 3.5 billion in 2023. Artificial Intelligence (AI), machine learning, and real-time data processes delivered by IoT solutions are driving cellular IoT devices boom.\nSmart factories in North America are expected to be worth more than $500 billion this year. The manufacturing process is being revolutionized with connected devices driving substantial productivity.\nBusinesses could spend up to $15 trillion in IoT by 2025. Businesses are well aware of IoT devices\xe2\x80\x99 potential to add value to their business and are investing heavily in technology.\nPerformant Architecture Model\nWith this acceleration of growth, it becomes even more important that IoT devices must be designed, manufactured, installed, connected, and controlled through the following seven distinct logical layers to securely connect and interact with complementary cloud and edge based components to deliver business value.\nThese layers are derived from a best practices outcome of architecting performant workloads, hence a Performant Architecture Model. These layers are very similar to the Open Systems Interconnection (OSI) model Networking Model. The OSI model is a conceptual model that describes the universal standard of communication functions of a telecommunication system or computing system, without any regard to the system\xe2\x80\x99s underlying internal technology and specific protocol suites.\nThis layered protocol approach can be applied to the IoT architecture stack as well. Where each layer can be modified as needed to achieve a specific level of service to the layer below it. Therefore, the objective is the interoperability of all diverse communication systems containing standard communication protocols, through the encapsulation and de-encapsulation of data, for all networked communication. In the OSI reference model, the communications between a computing system are split into seven different abstraction layers: Physical, Data Link, Network, Transport, Session, Presentation, and Application. Each intermediate layer serves a class of functionality to the layer above it and is served by the layer below it.\nThe IoT OSI Model\nIf there were an IoT OSI model, it may look something like the following, where the ultimate goal is to drive business value through IoT. After all, no customer ever approaches a vendor and asks to buy \xe2\x80\x9cIoT\xe2\x80\x9d, nor would an IoT provider sell just \xe2\x80\x9cIoT\xe2\x80\x9d. At AWS, we support our customers business needs by asking them a very fundamental question.\nIf you knew the state of every thing and could reason on top of that data\xe2\x80\xa6.  what [business] problems would you solve?\nOur mission is to make sure that you can know the state of every thing, all of your devices, and that you CAN reason on top of that data, so that you can truly solve the business problems.\nTherefore, if we group the functionalities provided in the Performant Architecture Model and translate it into the OSI Model, what we get is the concept of an IoT OSI Model. With this model we can substitute the layers as necessary to obtain the best business outcomes and value whilst still maintaining a very performant architecture. Further, we can group some of the OSI related layers into larger constructs to aggregate more business value.\nAt the top we would have People and Processes and the Applications that they use to derive the Business Value in one group. This group would consist of Layer 6 \xe2\x80\x93 where custom Applications would need to be created for presenting\nspecific Thing data. It would also include Layer 7 \xe2\x80\x93 where the transformational decisions for the business would be made based on the Thing Applications and Data.\nNext would be the Data Ingestion and Analysis, which is traditionally referred to as Big Data. This would consist of Layer 4 \xe2\x80\x93 which is responsible for the ingestion of the Thing data and harvesting specific trends. These trends are further evaluated at Layer 5 \xe2\x80\x93 which is responsible for various reporting, mining and extraction, and even running Machine Learning models against the stored data.\nBelow that construct is the Global Infrastructure of the business, also known as Layer 3. For simplicity we consider that to be the Cloud. That cloud infrastructure can be in the form of a public cloud, a private cloud, a hybrid, or managed. It can even be in the form of on-premise infrastructure.\nLastly, we have the Edge construct, consisting of the Connectivity and Edge Computing at Layer 2, and the actual Things at Layer 1, which includes various devices, sensors, controllers, etc.\nTogether these four constructs help to balance a Well Architected Framework for IoT implementations. The framework consists of Operational Excellence, Security, Reliability, Performance Efficiency, and Cost Optimization \xe2\x80\x9cpillars\xe2\x80\x9d\nThe Pillars of the AWS Well Architected Framework\nThe AWS Well Architected Framework helps you understand the pros and cons of the decisions you make when building systems on AWS. Using the Framework allows you to learn architectural best practices for designing and operating reliable, secure, efficient, and cost-effective systems in the cloud. The Framework provides a way for you to consistently measure your architectures against best practices and identify areas for improvement. We believe that having well-architected systems greatly increases the likelihood of business success.\nIn the context of IoT, we focus on how to design, deploy, and architect your IoT workloads in the AWS Cloud. To implement a well-architected IoT application, you must follow well-architected principles, starting from the procurement of connected physical assets (Things) to the eventual decommissioning of those same assets in a secure, reliable, and automated fashion. In addition to AWS Cloud best practices, the framework also articulates the impact, considerations, and recommendations for connecting physical assets to the internet.\nWhen architecting technology solutions, you must make informed tradeoffs between pillars based upon your business context. For IoT workloads, AWS provides multiple services that allow you to design robust architectures for your applications. Internet of Things (IoT) applications are composed of many devices (or things) that securely connect and interact with complementary edge-based and cloud-based components to deliver business value. IoT applications\ngather, process, analyze, and act on data generated by connected devices. As mentioned before, there are seven distinct logical layers to consider when building an IoT workload.\nDesign and Manufacturing Layer\nThe design and manufacturing layer consists of product conceptualization, business and technical requirements gathering, prototyping, module and product layout and design, component sourcing, and manufacturing. Decisions made in each phase impact the next logical layers of the IoT workload described below. For example, some IoT device creators prefer to have a common firmware image burned and tested by the contract manufacturer. This decision will partly determine what steps are required during the Provisioning layer.\nYou may go a step further and write a unique certificate and private key to each device during manufacturing. This decision can impact the Communications layer, since the type of credential can impact the subsequent selection of network protocols. If the credential never expires it can simplify the Communications and Provisioning layers at the possible expense of increased data loss risk due to compromise of the issuing Certificate Authority.\nEdge Layer\nThe edge layer of your IoT workload consists of the physical hardware of your devices, the embedded operating system that manages the processes on your device, and the device firmware, which is the software and instructions programmed onto your IoT devices. The edge is responsible for sensing and acting on other peripheral devices. Common use cases are reading sensors connected to an edge device, or changing the state of a peripheral based on a user action, such as turning on a light when a motion sensor is activated.\nAWS IoT Device SDKs simplify using AWS IoT Core with your devices and applications with an API compatible to your programming language or platform.\nAmazon FreeRTOS is a real time operating system for microcontrollers that lets you program small, low power, edge devices while leveraging memory-efficient, secure, embedded libraries.\nAWS IoT Greengrass is a software component that runs on the Linux or Windows Operating System on your IoT devices. AWS IoT Greengrass allows you to run MQTT local routing between devices, data caching, AWS IoT shadow sync, local AWS Lambda functions, and machine learning algorithms.\nPart 2 \xe2\x80\x93 Scaling for Complexity \xe2\x80\x93 Architecting for Performant Embedded Devices at the Edge \xe2\x80\x93 Part 2\nAbout the author\nChanna Samynathan\nChanna is a Specialist Solutions Architect, working on IoT and Robotics at Amazon Web Services (AWS) and part of the internal Technical Field Community for Telecom and IoT. Prior to AWS Channa has had an extensive career in Telecom, working with Tier 1 carriers around the world implementing various voice and messaging products for their SS7 networks. At AWS Channa works with Enterprise customers, and has built and presented IoT projects for re:Invent (2019/2020/2021), re:Inforce(2021/2022), Embedded World (2021/2022), and Hannover Messe (2021).'"
77,Empowering operations: A scalable remote asset health monitoring solution,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/empowering-operations-a-scalable-remote-asset-health-monitoring-solution-the-internet-of-things-aws-official-blog/,"b'Looking for ways to monitor the health of industrial remote assets and create a centralized dashboard? Perhaps your remote industrial assets are connected or ready to connect to AWS, but you haven\xe2\x80\x99t decided on how to present the data to operators and maintenance teams. Industrial remote assets are many and from different technological eras. Industrial customers need ways to equally visualize and monitor the status of those assets. Operation teams can then rely on a comprehensive dashboard and alerts to activate maintenance teams or remote actions, improving uptime and efficiency. In this blog post, you will learn how to use the data ingested to AWS IoT Core to enable field teams with a centralized Grafana dashboard and alerts table.\nOverview\nThis blog will work with a simulated dataset, the dataset will represent 10 remote pumping stations. You will build the end-to-end solution and running deployment scripts from the AWS Command Line Interface (AWS CLI). The goal of this post is to show the step-by-step process of building a remote asset monitoring solution in AWS. We have built an architecture which is scalable, completely serverless, and composed of an IoT data ingestion service. We are using AWS IoT Core for ingestion and simulation, AWS IoT SiteWise for asset modeling, and Amazon Managed Grafana for a centralized dashboard and alerts. In addition, you will interact with Amazon Simple Notification Service (Amazon SNS), where alarms assigned to different subscribers.\nScalable Architecture for Remote Asset health monitoring solution\nThis is the scalable architecture you will build in this blog. (Note: the Amazon Elastic Compute Cloud (Amazon EC2) instance is a simulation environment only)\nPrerequisites\nAn AWS account is required to setup and execute the steps in this blog, AWS service will be configured, and you must have the necessary Identity and Access Management (IAM) permission to do the following:\nSetup of an Amazon EC2 instance through Cloud9 environment for the IoT Device Simulator. The Amazon EC2 instance must have a role associated, which allows administrator access to the following services:\nAWS IoT Core\nAWS IoT SiteWise\nAWS Managed Grafana\nAmazon SNS\nAccess to IAM to create a role (or pre-created role).\nAn email box for the notification subscription.\nWork from a region which supports all the services pre-listed, we recommend us-east-1.\nGetting the environment ready\nCreate AWS Cloud9 environment\nLog into the AWS Cloud9 console.\nClick Create environment.\nEnter the name IoT Simulator and click next.\nSelect Create a new EC2 instance (direct access).\nSelect Instance type t3.small.\nSelect Amazon Linux 2 and click Next step.\nClick Create environment. The instance will start and the AWS Cloud9 environment will be ready for work. Note: You will execute commands from the AWS Cloud9 environment. Make sure the role attached to your Cloud9 provisioned instance has rights to execute AWS CLI commands for all services utilized in this blog. You can verify it from the Amazon EC2 console (go to  AWS Cloud9 \xe2\x86\x92 your environments \xe2\x86\x92 select IoT Simulator \xe2\x86\x92 View details \xe2\x86\x92 Click on instances in EC2. From EC2 select the AWS Cloud9 instance \xe2\x86\x92  Actions \xe2\x86\x92  Security \xe2\x86\x92 and Modify IAM role. At this point, you can check which is assigned to the instance, select a pre-created role or create a new one).\nThis step will clone the scripts and sample files we created for this blog post. From the terminal run the following commands:\ngit clone https://github.com/aws-samples/aws-iot-remote-asset-health-monitoring.git\ncd aws-iot-remote-asset-health-monitoring\nchmod +x bootstrap.sh\n./bootstrap.sh\nStart Simulator for AWS IoT Core ingestion\nWe have prepared a script to create the IoT Thing with the required resources for the simulation.\nNow execute the following commands:\npython create_thing.py\nnohup ./start.sh > iotconnection.log 2>&1 &\nNavigate to AWS IoT Core \xe2\x86\x92 Test \xe2\x86\x92 MQTT test client\nGot to Subscribe to a topic, type # and click Subscribe. You will see messages arriving under Topic as below:\nThe payload represents 10 pumping stations with different locations and anomalies. You will use part of the simulated values to build assets and dashboards.\nIngesting data into AWS IoT SiteWise\nCreating IAM role for SiteWise ingestion rules\nLog into IAM (Identy Access managment) \xe2\x86\x92 Roles and click Create Role\nSelect Custom trust policy and paste the below JSON snippet, click Next.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Principal"": {\n                ""Service"": ""iot.amazonaws.com""\n            },\n            ""Action"": ""sts:AssumeRole""\n        }\n    ]\n}\nJSON\nIn Permissions search for SiteWise and select the policy AWSIoTSiteWiseFullAccess and click next.\nIn Role Details, name the role with the following name \xe2\x80\x9c iot_to_sitewise\xe2\x80\x9d and Create a Role.\nClick on View Role\nCopy and save the Role ARN, as you will need it to run the rule creation script.\nCreating Rules to publish to AWS IoT SiteWise\nYou can find more on how to create IoT rules in AWS IoT Core Documentation and how to configure Actions to publish to AWS IoT SiteWise at AWS IoT SiteWise Documentation. In this blog, you will use the AWS CLI commands to create the rules from your AWS Cloud9 environment. We have prepared a python script which will create the rules using the previously created IAM role.\nGo to your AWS Cloud9 environment, from the ~/environment/aws-iot-remote-asset-health-monitoring directory. Now run the following command:\npython create_iotrules.py -r <the Role Arn here>\nThis script creates the IoT rules to ingest the simulation data into AWS IoT SiteWise. (Note: The policy used for this demonstration is over permissive and shouldn\xe2\x80\x99t be used in a production environment, for more information on scoping down policies check this AWS IoT policies overly permissive)\nNow navigate to AWS IoT Core \xe2\x86\x92 Message Routing\xe2\x86\x92 Rules\nYou will see the rules at the console as Active as below.\nNow navigate to AWS IoT SiteWise\xe2\x86\x92 Data streams\nAWS IoT SiteWise Data Streams is where ingested data, which is not yet assigned to an asset is automatically stored. For more information on Data Streams follow this link. Now verify the data arriving in AWS IoT SiteWise and being update periodically, you can also filter through all Alias prefix, use the /pumpingstation/{n} and All data streams to observe the data.\nAsset model and Assets in AWS IoT SiteWise\nCreating Asset Model\nNavigate to AWS IoT SiteWise\xe2\x86\x92 Models and click on Create model\nConfigure your model as following, note that it is important to respect the syntax (including upper case and lower case, we recommend coping and pasting through this section) as that will influence on the auto asset generation.\nName: PumpingStation;\nDescription: This is the digital model representation of all pumping station\nMeasurement definitions:\nname: Temperature; Unit:F; Data type: Integer\nname: Humidity; Unit:%; Data type: Integer\nname: Pressure; Unit: PSI; Data type: Integer\nname: Vibration; Unit: Hz; Data type: Integer\nname: Flow; Unit: m3/s; Data type: Integer\nname: rpm; Unit: rpm; Data type: Integer\nname: Voltage; Unit: V; Data type: Integer\nname: Amperage; Unit: A; Data type: Integer\nname: Fan; Unit: on/off; Data type: Boolean\nname: Location; Unit: State; Data type: String\nFinish by clicking on Create model, you will have your mode available on the list.\nNow your model will show as follows, copy the model ID and save it for the next steps, as we will need as an input for the creation scripts.\n\nCreating Assets\nThe next step is creating Assets from the model PumpingStation, for this step you will be running a python script which will automatically create 10 pumping station and associate the available Data stream to its match asset measurement. For more information on how to create Assets from Asset model refer to the AWS IoT SiteWise Documentation.\nNavigate back to the AWS Cloud9 environment.\nFrom the ~/environment/aws-iot-remote-asset-health-monitoring directory, execute the following commands:\nFrom your AWS Cloud9 terminal execute the following command:\npython create_iotsitewise_assets.py -i <your model Id here>\nThe Script will run for about 5 minutes. You can watch the responses from the AWS CLI commands.\nGo to AWS IoT SiteWise\xe2\x86\x92 Assets and confirm that all pumping stations were created and are active as below.\nSelect one of the Pumping Stations and go to measurements. Now confirm that your data is arriving in AWS IoT SiteWise and being updated periodically.\nCreating Dashboards in Amazon Managed Grafana\nCreating Amazon SNS notification\nBefore we work with Amazon Managed Grafana, we recommend that you create and configure the notification channel. Amazon Managed Grafana can directly send notifications to Amazon SNS given the ARN for the Amazon SNS Topic.\nNavigate to Amazon SNS (amazon.com) \xe2\x86\x92 Topics and click on Create Topic\nSelect Standard, Name it : All_Pumping_Stations\nGo to Access policy, and Select Everyone in both options, publish and subscribe, and click Create.(Note: an over-permissive policy is not recommended beyond this simulation environment)\nNavigate to your newly create topic All_Pumping_Stations and click on Create subscription.\nSelect Email, under Endpoint add your test email address, and click create subscription.\nThe Subscription will show as Pending confirmation Status, within a minute you will receive a confirmation link in your test email, after accepting it the subscription is ready. (shown as below).\nCopy the ARN for the topic and save it for later on your clipboard.\nCreating Amazon Managed Grafana workspace\nNavigate to AWS Grafana Console , click on Create workspace\nName: all_pumping_stations, Click next\nSelect AWS Single Sign-On (If AWS Single Sign-On is not enabled, you must enable it, follow this link for instructions. Amazon Managed Grafana also supports SAML authentication, you can find more information here)\nSelect Service managed, Click next\nSelect Current account\nUnder Data sources select AWS IoT SiteWise\nUnder Notification channels, select Amazon SNS, Click Next\nClick Create Workspace\nOnce your workspace is ready status under Authentication, you must assign a new user to your workspace. Click on Assign new user or group.\nIf you have enable AWS Single Sign-On (SSO), you will then see a user or group, select it and click Assign User, then Select the same user or group, and go to Actions and make Admin\nNavigate back to AWS Grafana Console \xe2\x86\x92 All workspaces \xe2\x86\x92 all_pumping_stations, look for the Grafana workspace URL and click on it.\nA new tab will open and you see the login page as below. Log in and you are ready for the next step.\nConfiguring Amazon Managed Grafana notification channel\nIn your Grafana workspace Navigate to Alerting\xe2\x86\x92 Notification channels.\nClick on Add Channel.\nName : all_pumping_stations\nType : AWS SNS\nTopic : <Paste the topic ARN from the previous section>. If you need to locate it again, Navigate to Simple Notification Service\xe2\x86\x92 Topics\xe2\x86\x92 all_pumping_stations, the ARN is located under details.\nAuth Provider: Workspace IAM Role\nMessage Body Format: Text\nUnder Notification setting, select Default\nClick Save. (Optionally, you can also click on the test to make sure your notification channel is correctly setup)\nConfiguring Grafana Data sources\nIn your Grafana workspace Navigate to Configuration\xe2\x86\x92 Data Sources\nClick on Add data Source.\nSearch for AWS IoT SiteWise and click on it\nUnder Connection Details keep the default except for Default Region. Select the region where you built your SiteWise assets.\nClick Save & test\nCreating Dashboards in Amazon Managed Grafana\nFor the monitoring dashboards and alerts we have created a python script which will automatically deploy one dashboard for each pumping station.\nNavigate to AWS Grafana Console\xe2\x86\x92 Workspaces\xe2\x86\x92 all_pumping_stations\nLook for the Grafana workspace URL and copy the ID before .grafana, as shown below.\nGo to your AWS Cloud9 environment, from the ~/environment/aws-iot-remote-asset-health-monitoring directory, run the following command:\npython create_grafana_dashboards.py -i <your workspace ID here> -r <your Model ID here>\nAfter the script is finished, navigate to the Grafana Workspace\xe2\x86\x92 Dashboards\xe2\x86\x92 Browse, confirm that all dashboards have been successfully created and the simulation data is being ingested as shown below.\nNavigate to pumpingstation9/Status/Time_series dashboard and confirm the temperature is high, and the alert is active. For this simulation data set, the Pumping Station 9 presents the anomalous temperature and triggers an alert to the notification channel every 2 minutes. Optionally navigate to any other pumping station dashboard and compare them.\nNow navigate to Alerting\xe2\x86\x92 Alert rules, and check that all the other alerts are healthy.\n'"
78,"Implement security monitoring across OT, IIoT and cloud with AWS Security Hub",b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/06/16/AWS-Security-Hub-SA-1.png,https://aws.amazon.com/blogs/iot/implement-security-monitoring-across-ot-iiot-and-cloud-with-aws-security-hub/,"b'Introduction\nIndustrial digital transformation can increase competitiveness and optimize processes and profitability through the use of big data, IoT, machine-to-machine communication, and machine learning. Continuous digitalization and progressive interconnectivity of the production environment is important to capturing value from industrial IoT (IIoT) solutions. While this new and expanding \xe2\x80\x9cphysical meets digital\xe2\x80\x9d connectivity enables great rewards, it also introduces new risk, which needs to be properly managed.\nIndustrial organizations should be aware of the risks that come along with the benefits of this convergence and cloud adoption. As this SANS whitepaper recommends, organizations should establish strategies to prevent, detect, respond, and recover across the entire attack surface which includes Operational Technology (OT), edge and cloud, and on-site and off-site assets. Traditionally, OT and IT/cloud teams have worked on separate sides of the air gap as laid out in the Purdue Model. This can result in siloed OT, IIoT and cloud security monitoring solutions, creating blind spots bad actors could exploit. In order to realize the full benefits of IT/OT convergence and IIoT, IT and OT teams are better off if they join forces to mount the most effective defense and build trust.\nIn this blog, we describe a new approach to security monitoring across OT, IIoT and cloud by integrating OT security solutions with AWS. This provides visibility of security events to teams responsible for security monitoring of IIoT solutions without the costly and often time-consuming effort needed to integrate OT security solutions into existing Security Operations Center (SOC) solutions. Deploying security monitoring and centrally managing alerts across OT, IIoT and cloud is one of the ten security golden rules for IIoT solutions.\nSolution Overview\nOne of the many challenges in securing complex heterogeneous factory and cloud environments when implementing IIoT solutions is the lack of visibility into security events across factory and cloud. This poses problems since cyber events could originate in OT and move to IT, or vice versa. This creates the need for a security monitoring solution across the attack surface and threat landscape. To address this challenge, we are providing a custom solution to integrate security events from OT Intrusion Detection Solutions (IDS) like Dragos, Claroty and Nozomi into AWS Security Hub.\nAWS Security Hub provides a centralized view of your security posture in AWS and helps check your environment against security standards and current AWS security recommendations. When combined with an OT IDS solution, you can get a centralized view of security events across OT and AWS, helping to improve your security posture across factory and cloud which is essential when implementing IIoT solutions.\nAWS Security Hub ingests findings from multiple AWS services, including Amazon GuardDuty, Amazon Inspector, Amazon Macie, AWS Firewall Manager, AWS Identity and Access Management (IAM) Access Analyzer, and AWS Systems Manager Patch Manager. Now with this solution to stream syslog data from OT IDS solutions, you can ingest security findings from your OT environment into AWS Security Hub. Findings from each service are normalized into the AWS Security Finding Format (ASFF), so that you can review findings in a standardized format and take action quickly. You can use AWS Security Hub to provide a centralized view of all security-related findings, where you can set up alerting and automatic remediation.\nCustomers using AWS IoT Device Defender to audit and monitor IIoT devices can import its findings into AWS Security Hub \xe2\x80\x93 learn how in this blog. With this, customers can correlate events across OT and IIoT devices. For example, if a new device is installed in the OT environment and discovered by the OT IDS solution, it is possible to cross check if this is an IIoT device provisioned by AWS IoT and monitored by AWS IoT Device Defender. This enables customers to quickly identify rogue devices present on the shop floor.\nSolution Architecture\nThe solution architecture includes Fluentd, Amazon Elastic Compute Cloud (Amazon EC2), Amazon Kinesis Data Streams, AWS Lambda, and AWS Security Hub.\nFluentd is an open source data collector that unifies data collection and consumption for better use and understanding. Fluentd unifies logging with JSON, and this allows unification of processing, collecting, filtering, buffering, and outputting logs across multiple sources and destinations. Fluentd was selected for the solution based on its robust support for syslog as an input and Amazon Kinesis Data Streams as an output. For production workloads, we recommend enabling TLS (Transport Layer Security) for syslog input transport by modifying the Fluentd configuration file in the project file lib/syslog-security-hub-stack.ts.\nAmazon Elastic Compute Cloud (Amazon EC2) is used to host Fluentd. The solution is configured by default with a t2.micro instance type, which is eligible for Free Tier. The t2.micro instance type offers 1 vCPU with 1 GiB Memory and is sufficient sizing for non-production workloads. An Elastic IP Address (EIP) is associated with the EC2 instance to assign a static public IPv4 address, which allows you to receive syslog events from any source permitted via the associated Amazon EC2 Security Group. By default, the Amazon EC2 Security Group only permits ingress traffic from the created Amazon Virtual Private Cloud (VPC). Production workload sizing will be based on the number of syslog events you stream to Fluentd, which is scalable up to 5,000 messages / sec with a single process. Review the following Fluentd performance tuning guide for more details.\nAmazon Kinesis Data Streams is a serverless streaming data service that makes it easy to capture, process, and store data streams at any scale. The solution uses an AWS Solutions Constructs package, aws-kinesisstreams-lambda, to simplify our CDK Project and ensure AWS best practices are followed. This AWS Solutions Constructs creates a Kinesis Data Stream with one shard, and associates a Lambda function. AWS Lambda polls the Kinesis Data Stream, and when it detects new records in the stream it invokes the Lambda function to parse and transform the received event into AWS Security Finding Format (ASFF) needed by AWS Security Hub.\nSolution Deployment\nIn order to get started, you will need an AWS account. We recommend testing this in a non-production environment. First, turn on AWS Security Hub in the AWS region you plan to deploy the solution. We recommend using AWS Cloud9 to eliminate the need to setup IAM permissions and install pre-requisites. AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. Cloud9 comes pre-configured with all the pre-requisites we require for this blog post, such as git, npm, and AWS Cloud Development Kit (CDK).\nTo get started, create a Cloud9 environment from the AWS console. Provide the required name for the environment, and select the appropriate values using the wizard. Once your Cloud9 environment has been created, you can open the IDE and access a terminal window.\nTo build and deploy the solution in your AWS account, follow the instructions provided in this aws-samples project to stream syslog from OT IDS solutions to AWS Security Hub. One thing to check is to make sure you are updating the company and product name fields to override the default values for custom integrations.\nThis project includes a sample syslog event from the Dragos Platform for testing purposes, and a custom AWS Lambda function for parsing and transforming ICS/OT/IIoT security events. Dragos is an industrial (ICS/OT/IIoT) cybersecurity company and is a member of the AWS Partner Network.\nThis sample is provided for demonstration purposes only, to serve as a starting point to help you customize for your source systems. To customize, you need a basic understanding of syslog and how the source system emitting syslog events maps its fields to syslog Common Event Format (CEF).\nThe cost to test the solution with sample security event/finding starts at approximately $2 USD / day, and more details on pricing can be found here: Amazon EC2, AWS Lambda, Amazon Kinesis Data Streams, and AWS Security Hub.\n'"
79,Digital Twins on AWS: Predicting “behavior” with L3 Predictive Digital Twins,b'Syed Rehan',2022-07-15T17:53:43+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/24/DigitalTwin_L3Predictive.jpg,https://aws.amazon.com/blogs/iot/l3-predictive-digital-twins/,"b'In our prior blog, we discussed a definition and framework for Digital Twins consistent with how our customers are using Digital Twins in their applications. We defined Digital Twin as \xe2\x80\x9ca living digital representation of an individual physical system that is dynamically updated with data to mimic the true structure, state, and behavior of the physical system, to drive business outcomes.\xe2\x80\x9d In addition, we described a four-level Digital Twin leveling index, shown in the figure below, to help customers understand their use-cases and the technologies needed to achieve the business value they are seeking.\nIn this blog, we will illustrate how the L3 Predictive level predicts behavior of a physical system by walking through an example of an electric vehicle (EV). You will learn, through the example use-cases, about the data, models, technologies, AWS services, and business processes needed to create and support an L3 Predictive Digital Twin solution. In prior blogs, we described the L1 Descriptive and L2 Informative levels, and a future blog, we will continue with the same EV example to demonstrate L4 Living Digital Twins.\nL3 Predictive Digital Twin\nAn L3 Digital Twin focuses on modeling the behavior of the physical system to make predictions of unmeasured quantities or future states under continued operations with the assumption that future behavior is the same as the past. This assumption is reasonably valid for short-time horizons looking forward. The predictive models can be machine learning based, first-principles based (e.g. physics simulations), or a hybrid. To illustrate L3 Predictive Digital Twins, we will continue our example of the electric vehicle (EV) from the L1 Descriptive and L2 Informative Digital Twin blogs by focusing on three use cases: 1/ virtual sensors; 2/ anomaly detection; and 3/ imminent failure predictions over very short time horizons. To illustrate how to implement on AWS, we have extended our AWS IoT TwinMaker example from the L2 Informative blog with components related to these three capabilities. In the next sections we will discuss each of them individually.\n1. Virtual Sensor\nFor our EV example, a common challenge is to estimate the remaining range of the vehicle given its battery\xe2\x80\x99s present state of charge (SoC). For the driver, this is a critical piece of information since getting stranded generally requires having your EV towed to the nearest charging station. Predicting the remaining range, however, is not trivial as it requires implementing a model that takes into account the battery state of charge, the battery discharge characteristics, the ambient temperature which has an impact on battery performance, as well as some assumptions on the expected upcoming driving profile (e.g., flat or mountainous terrain, defensive or aggressive accelerations). In our L2 Informative blog, we used a very crude calculation for Remaining Range that could easily be hardcoded into an embedded controller. In our L3 Predictive example below, we replaced the simple calculation with an extension of the EV simulation model provided by our AWS Partner Maplesoft in our L1 Descriptive blog. This time the model incorporates a virtual sensor that calculates the estimated range based on the key input factors described above. The virtual sensor based vehicle range is shown in the Grafana dashboard below.\n2. Anomaly Detection\nWith industrial equipment, a common use case is to detect when the equipment is running off-nominal performance. This type of anomaly detection is often integrated directly into the control system using simple rules such as threshold exceedances (e.g., temperature exceeds 100\xc2\xb0C), or more complex statistical process control methods. These types of rules-based approaches would be incorporated into L2 Informative use cases. In practice, detecting off-nominal performance in a complex system like an EV is challenging, because the expected performance of a single component is dependent on the overall system operation. For example, for an EV, the battery discharge is expected to be much greater during a hard acceleration compared to driving at constant speed. Using a simple rules-based threshold on the battery discharge rate wouldn\xe2\x80\x99t work because the system would think that every hard acceleration is an anomalous battery event. Over the past 15 years, we\xe2\x80\x99ve seen increased use of machine learning methods for anomaly detection by first characterizing normal behavior based on historical data streams, and then constantly monitoring the real time data streams for deviations from the normal behavior. Amazon Lookout for Equipment is a managed service that deploys supervised and unsupervised machine learning methods to perform this type of anomaly detection. The figure below shows a screenshot from the Grafana dashboard showing that the \xe2\x80\x9cCheck Battery\xe2\x80\x9d light has been illuminated due to anomalous behavior detected.\nTo understand the details of the anomaly, we examine the output of Amazon Lookout for Equipment in the AWS Management Console. The dashboard shows all the anomalies that were detected in the time window we examined \xe2\x80\x93 including the anomaly that led to the \xe2\x80\x9cCheck Battery\xe2\x80\x9d light turning red. Selecting the anomaly shown in the Grafana dashboard we see that the four sensors on which the model was trained all show anomalous behavior. The Amazon Lookout for Equipment dashboard shows the relative contribution of each sensor to this anomaly in per cent. Anomalous behavior of the battery voltage and the battery SoC are the leading indicator in this anomaly.\nThis is consistent with how we introduced the anomaly in the synthetic dataset and trained the model. We first used periods of normal operation to train an unsupervised Amazon Lookout for Equipment model on the four sensors shown. After that, we evaluated this model on a new dataset shown in the Amazon Lookout for Equipment dashboard above, where we manually induced faults. Specifically, we introduced an energy loss term in the data leading to a subtle faster decline of the SoC that also affects the other sensors. It would be challenging to design a rules-based system to detect this anomaly early enough to avoid further damage to the car \xe2\x80\x93 particularly if such behavior has not been observed before. However, Amazon Lookout for Equipment does initially detect some anomalous periods and from a certain point onwards flags anomalies over the whole remaining time. Of course, the contributions of each sensor to an anomaly could also be displayed in the Grafana dashboard.\n3. Failure Prediction\nAnother common use case for industrial equipment is to predict end of life of components in order to preplan and schedule maintenance. Developing models for failure prediction can be very challenging and typically requires custom analysis for failure patterns for the specific equipment under a wide variety of different operating conditions. For this use case, AWS offers Amazon SageMaker, a fully managed service to help train, build, and deploy machine learning models. We will show how to integrate Amazon SageMaker with AWS IoT TwinMaker in the next section when we discuss the solution architecture.\nFor our example, we created a synthetic battery sensor dataset that was manually labeled with its remaining useful life (RUL). More specifically, we calculated an energy loss term in our synthetic battery model to create datasets of batteries with different RUL and manually associated larger energy losses with shorter RULs. In real life such a labeled dataset could be created by engineers analyzing data of batteries that have reached their end of life. We used an XGBoost algorithm to predict RUL based on 2-minute batches of sensor data as input. The model takes features derived from these batches as input. For example, we smoothed the sensor data using rolling averages and compared the sensor data between the beginning and the end of the 2-minute batch. Note that we can make predictions at a granularity of less than 2 minutes by using a rolling window for prediction. In our example, the Remaining Useful Life of the battery is displayed in the dashboard under the Check Battery symbol. This vehicle is in a dire situation with a prediction of imminent battery failure!\n4. Architecture\nThe solution architecture for the L3 Predictive DT use cases builds on the solution developed for the L2 Informative DT and is shown in below. The core of the architecture focuses on ingesting the synthetic data representing real electric vehicle data streams using an AWS Lambda function. The vehicle data including vehicle speed, fluid levels, battery temperature, tire pressure, seatbelt and transmission status, battery charge, and additional parameters are collected and stored using AWS IoT SiteWise. Historical maintenance data and upcoming scheduled maintenance activities are generated in AWS IoT Core and stored in Amazon Timestream. AWS IoT TwinMaker is used to access data from multiple data sources. The time series data stored in AWS IoT SiteWise is accessed through the built-in AWS IoT SiteWise connector, and the maintenance data is accessed via a custom data connector for Timestream.\nFor the L3 virtual sensor application, we extended the core architecture to use AWS Glue to integrate the Maplesoft EV model by using the AWS IoT TwinMaker Flink library as a custom connector in Amazon Kinesis Data Analytics. For anomaly detection, we first exported the sensor data to S3 for off line training (not shown in diagram). The trained models are made available via Amazon Lookout for Equipment to enable predictions on batches of sensor data via a scheduler. Lambda functions prepare the data for the models and process their predictions. We then feed these predictions back to AWS IoT SiteWise from where they are forwarded to AWS IoT TwinMaker and displayed in the Grafana Dashboard. For failure prediction, we first exported the sensor data to S3 for training and labeled using Amazon SageMaker Ground Truth. We then trained the model using an Amazon SageMaker training job and deployed an inference endpoint for the resulting model. We then placed the endpoint inside a Lambda function that is triggered by a scheduler for batch inferencing. We feed the resulting predictions back to AWS IoT SiteWise from where they are forwarded to AWS IoT TwinMaker and displayed in the Grafana Dashboard.\n5. Operationalizing L3 Digital Twins: data, models, and key challenges\nOver the past 20 years, advances in predictive modeling methods using machine learning, physics-based models, and hybrid models have improved the reliability of predictions to be operationally useful. Our experience, however, is that most prediction efforts still fail because of inadequate operational practices around deploying the model into business use.\nFor example, with virtual sensors, the key task is developing and deploying a validated model in an integrated data pipeline and modeling workflow. From a cloud-architecture perspective, these workflows are straightforward to implement as shown in the EV example above. The bigger challenges are on the operational side. First, building and validating a virtual sensor model for complex equipment can take years. Virtual sensors are often used for quantities that cannot be measured by sensors, so by definition there is no real-world validation data. As a result, the validation is often done in a research laboratory running experiments on prototype hardware using a few very expensive sensors or visual inspections for limited validation data to anchor the model. Second, once deployed, the virtual sensor only works if the data pipeline is robust and provides the model with the data it needs. This sounds obvious, but operationally can be a challenge. Poor real-world sensor readings, data drop-outs, incorrectly tagged data, site-to-site variations in data-tags and changes made to the control system tags during overhauls are often causes for tripping up a virtual sensor. Insuring good quality and consistent data is foundationally a business operations challenge. Organizations must define standards, quality-checking procedures, and training programs for the technicians who are working on the equipment. Technology will not overcome poor operational practices in gathering the data.\nWith anomaly detection and failure predictions, the data challenges are even greater. Engineering leaders are led to believe that their company is sitting on a gold-mine of data and wonder why their data science teams are not delivering. In practice, these data pipelines are indeed robust, but were created for entirely different applications. For example, data pipelines for regulatory or performance monitoring are not necessarily suitable for anomaly detection and failure predictions. Since anomaly detection algorithms are looking for patterns in the data, issues such as sensor mis-readings, data dropouts, and data tagging issues can render the prediction models useless, but that same data can be acceptable for other use cases. Another common challenge is that data pipelines that are thought to be fully automated, are in fact not. Undocumented manual data corrections requiring human judgement are typically only discovered when the workflow is automated for scaling and is found not to work. Lastly, for industrial assets, failure prediction models rely on manually collected inspection data since it provides the most direct observation of the actual condition of the equipment. In our experience, the operational processes around collecting, interpreting, storing and integrating inspection data are not robust enough to support failure models. For example, we have seen inspection data show up in the system months after it was collected, long after the equipment has already failed. Or the inspection data consists of handwritten notes attached to an incorrectly completed inspection data record or associated with the wrong piece of equipment. Even the best predictive models will fail when provided incorrect data.\nFor L3 Predictive Digital Twins, we encourage our customers to develop and validate the business operations to support the Digital Twin\xe2\x80\x99s data needs at the same that the engineering teams are building the Digital Twins themselves. Having an end-to-end workflow mindset from data collection through to predictions and acting on the predictions is critical for success.\nSummary\nIn this blog we described the L3 Predictive level by walking through the use cases of a virtual sensor, anomaly detection, and failure prediction. We also discussed some of the operational challenges in implementing the necessary business processes to support the data needs of an L3 Digital Twin. In a prior blog, we described the L1 Descriptive and the L2 Informative levels. In a future blog, we will extend the EV use case to demonstrate L4 Living Digital Twins. At AWS, we\xe2\x80\x99re excited to work with customers as they embark on their Digital Twin journey across all four Digital Twin levels, and encourage you to learn more about our new AWS IoT TwinMaker service on our website.\nAbout the authors\nDr. Adam Rasheed is the Head of Autonomous Computing at AWS, where he is developing new markets for HPC-ML workflows for autonomous systems. He has 25+ years experience in mid-stage technology development spanning both industrial and digital domains, including 10+ years developing digital twins in the aviation, energy, oil & gas, and renewables industries. Dr. Rasheed obtained his Ph.D. from Caltech where he studied experimental hypervelocity aerothermodynamics (orbital reentry heating). Recognized by MIT Technology Review Magazine as one of the \xe2\x80\x9cWorld\xe2\x80\x99s Top 35 Innovators\xe2\x80\x9d, he was also awarded the AIAA Lawrence Sperry Award, an industry award for early career contributions in aeronautics. He has 32+ issued patents and 125+ technical publications relating to industrial analytics, operations optimization, artificial lift, pulse detonation, hypersonics, shock-wave induced mixing, space medicine, and innovation.\nSeibou Gounteni is a Specialist Solutions Architect for IoT at Amazon Web Services (AWS). He helps customers architect, develop, operate scalable and highly innovative solutions using the depth and breadth of AWS platform capabilities to deliver measurable business outcomes. Seibou is an instrumentation engineer with over 10 years experience in digital platforms, smart manufacturing, energy management, industrial automation and IT/OT systems across a diverse range of industries.\nDr. David Sauerwein is a Data Scientist at AWS Professional Services, where he enables customers on their AI/ML journey on the AWS cloud. David focuses on forecasting, digital twins and quantum computation. He has a PhD in quantum information theory.'"
80,How KAMAX connected their industrial machines to AWS in hours instead of weeks,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/27/Solution-Architecture-AWS-and-KAMAX-1024x465.png,https://aws.amazon.com/blogs/iot/how-kamax-connected-their-industrial-machines-to-aws-in-hours-instead-of-weeks/,"b'This post was co-authored by Praveen Rao, Principal GTM leader, Mfg and Supply Chain at AWS; Adrian Weiss, Product Manager and Senior Data Scientist at nexineer; Nicolas Byl, Director Software Engineering at nexineer; Jill Mannaioni, Vice President Americas at CloudRail; and Philip Weber, Senior Partner Manager, EMEA and APJ at CloudRail.\nEvery manufacturing customer these days is talking about Industry 4.0, digital transformation, or AI/ML, but these can be daunting topics for manufacturers. Historically, connecting industrial assets to the cloud has been a large and complicated undertaking. Older assets increase the complexity, leaving many manufacturers with legacy equipment stalled at the starting gate. KAMAX, a player for cold forming parts in the sector of steel processing, shows that it is not only possible to transform, but can be easy when working with the right partners. KAMAX wanted a fully managed shop floor solution to acquire data from industrial equipment, process the data and make it available fast, to improve their operational efficiency. KAMAX employed their subsidiary and digital incubator, nexineer digital, Amazon Web Services (AWS) and CloudRail to help. This Industrial IoT collaboration increased manufacturing efficiency and effectiveness within their plants by automating and optimizing traditionally manual tasks, increasing production capacity, and optimizing tool changeover times (planned downtimes) of machines. This solution helped KAMAX realize quantifiable time savings of 2.5% \xe2\x80\x93 3.5%.\nProduction challenges\nKAMAX aims to set standards in the areas of manufacturing innovation, quality, and profitability. To remain competitive while still increasing profits, KAMAX wanted to take advantage of advanced technologies that were unavailable when their plants were built. KAMAX and nexineer theorized that an Industrial IoT (IIoT) solution would help better manage and report on production output, better manage order fulfilment accuracy and could also increase production output by automating manual tasks. This would allow them to assign skilled operators to higher value tasks, a benefit in the current tight labor market. So, their search for an IIoT solution began.\nKAMAX manufactures fasteners and complex formed parts for mobility and beyond. A cold heading machine at KAMAX produces an average of 2 bolts per second, which fall directly from the machine onto a conveyor belt. Output was not tracked or managed in real-time, but relied on periodic bulk weight measurements. This entailed transferring the produced pieces in large containers across the factory to the scale. The manual weighing process took roughly 3 minutes and was done up to 16 times per shift in just one production facility. Not only was this process time consuming, it hindered KAMAX\xe2\x80\x99s ability to gain real-time insights into their production output, which delayed reporting by up to 60 minutes.\nSolution walkthrough\nKAMAX\xe2\x80\x99s goal was to eliminate the labor-intensive manual inventory count and redirect those employees and their efforts to higher value production tasks as well as to enable remote monitoring of their machines for production-related issues. KAMAX intended to count the bolts as they are produced rather than estimate the number by weighing them afterwards.\nnexineer\xe2\x80\x99s leadership narrowed its evaluation down to two types of potential solutions: either a camera-based system or a sensor-based system. Although the camera-based system worked well with a high degree of accuracy, it proved to be too high of an investment within the constraints of this project, from the initial startup costs to running costs and ongoing maintenance costs. In addition, a camera-based system posed many concerns and potential hurdles with the German labor unions and European data protection laws (GDPR), specifically regarding recording images of people working within a factory environment and privacy issues associated with that.\nnexineer\xe2\x80\x99s next move was to evaluate a sensor-based solution. They thought that collecting operational technology (OT) data from sensors and migrating it to AWS might be difficult and require additional investments in personnel and expertise. However, in collaboration with AWS and CloudRail, they learned this was not the case. To count the number of bolts, the machine was retrofitted with a light grid sensor that could detect a new object every 0.2ms. CloudRail\xe2\x80\x99s edge gateway provided a quick, secure, and efficient OT to AWS connectivity solution allowing KAMAX to connect their first machine and send piece counting data to AWS in a matter of hours.\nKAMAX\xe2\x80\x99s maintenance team installed the high-resolution light grid sensor on the machine. The sensor let them detect objects as small as 2 mm and conduct complex volume calculations with maximum precision and reliability. From there, the KAMAX team set up the CloudRail.Box gateway in a nearby cabinet along with an IO-Link Master and supplied it with internet access. Through the CloudRail Device Management Cloud (DMC), they completed the remote setup and configuration in minutes without requiring any IoT experts onsite.\nThe CloudRail.Box gateway runs and uses AWS IoT Greengrass to prepare the time series data before sending it to AWS IoT Core. Once in AWS IoT Core, KAMAX used AWS Lambda functions to generate production count KPIs and to monitor the overall machine performance. This data was shared through a mobile application, built using AWS Amplify, for production staff, and pushed into the SAP Enterprise Resource Planning (ERP) system through REST APIs for order fulfillment. With these changes KAMAX can now count exactly how many products are associated with each order vs estimating based on the weight as done before.\n\xe2\x80\x9cThe combination of AWS and CloudRail enable our development teams to setup and validate new use-cases within hours instead of days and weeks. With the heavy lifting of data ingestion taken away, they can focus on building applications and processes that bring the business forward instead of fighting with infrastructure topics. Together with the operational excellence AWS brings to the table, we can easily move these solutions forward and scale them throughout the whole global organization. With AWS and CloudRail we can live out our passion, to create lean, creative and successful digital solutions.\xe2\x80\x9d said Tobias Haungs, Managing Director of nexineer digital GmbH.\nSolution architecture\nBusiness benefits\nKAMAX saw several significant benefits after implementing the monitoring systems. First, the near real-time condition monitoring of the machines allowed operators to handle production-related issues proactively versus reactively. This freed up 2.5% \xe2\x80\x93 3.5% of the operators\xe2\x80\x99 time for higher value tasks. Second, KAMAX used the real-time insights to schedule the forklift routes (used to resupply the machines with raw materials and transport the produced goods to the next process step), further reducing unproductive waiting times. Third, the accurate real-time product tracking within the entire supply chain has allowed KAMAX to improve how they plan production operations, something that was not possible with the old, manual weighing process.\nCloudRail\xe2\x80\x99s fleet management capabilities that allow remote security patches combined with AWS\xe2\x80\x99 Well-Architected Framework will ensure that the solution continues to operate reliably and securely.\n\xe2\x80\x9cSpeed and flexibility are crucial for many matters. KAMAX is a solution partner for our customers and suppliers. We challenge innovation and digitalization on a high priority. With this target, we created our digital innovation force nexineer digital GmbH. Their solution with CloudRail and built on AWS is a great example. With this creative combination we easily scale transparency of our machine data, we automate our production, and we improve the throughput and quality of our core processes to create a highly flexible and integrated smart factory for KAMAX.\xe2\x80\x9d said J\xc3\xb6rg Steins, CEO KAMAX Group.\n'"
81,Assessing OT and IIoT cybersecurity risk,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/assessing-ot-and-iiot-cybersecurity-risk/,"b'This blog is co-authored by Ryan Dsouza, AWS and John Cusimano, Deloitte \nIntroduction\nInnovative and forward-looking oil and gas, electrical generation and distribution, aviation, maritime, rail, utilities, and manufacturing companies who use Operational Technology (OT) to run their businesses are adopting the cloud in many forms as a result of their digital transformation initiatives. Data lakes, Internet of Things (IoT), edge technology, machine-to-machine communication, and machine learning (ML) are enablers for this industrial digital transformation. This is driving changes to the OT landscape, and as these environments continue to evolve, OT environments are leveraging more IT solutions to improve the productivity and efficiency of production operations.\nIndustrial customers often start their digital transformation journey by sending OT data to the cloud for analysis and analytics without sending commands back to the industrial automation and control system (IACS). This process is often called \xe2\x80\x9copen loop\xe2\x80\x9d operations, since there is one-way communication from edge to cloud.  Customers generally find this relatively easy to secure and manage.\nHowever, one of the goals of Industrial Internet of Things (IIoT) solutions is to optimize operations by generating an automatic or operator-initiated response in the factory or plant, based on insights gained from cloud analytics. This process is often referred to as \xe2\x80\x9cclosed loop\xe2\x80\x9d operations with two-way communication between edge and cloud. The security and compliance practices for closed loop operations are more rigorous because closed loop operations manipulate OT devices remotely. Developing these practices should be rooted in a cyber risk assessment to help businesses understand and prioritize security concerns.\nThis convergence of IT and OT systems creates a mix of technologies that were designed to operate within hostile networks environments with ones that were not, which creates the need for new risk management considerations. When taking advantage of IT technologies in OT environments, it\xe2\x80\x99s important to conduct a cybersecurity risk assessment to fully understand and proactively manage risks, gaps, and vulnerabilities.\nIn the ten security golden rules for industrial IoT solutions, AWS provides recommendations including conducting a cyber-security risk assessment at the start of an IIoT digital transformation project and using it to inform system design. There is a well-defined and mature methodology that has been used in performing risk assessments on IT systems for decades called \xe2\x80\x98Threat Modeling,\xe2\x80\x99 which is further explained in an AWS Security Blog called How to approach threat modeling. In this post, we will help you apply this guidance specifically for an OT/IIoT use-case and audience as well as highlight the unique considerations in OT/IIoT environments.\nUnderstanding cybersecurity risk\nPeople often struggle with the term risk and what it means in the context of cybersecurity. Risk is generally defined as a function of probability and impact, where the probability is the likelihood of an event occurring, and the impact is a measure of the extent of the adverse circumstance (i.e., the consequence). The common formulaic way of expressing this is:\nRisk = Likelihood x Impact\nIn the field of information security risk management, the likelihood component in the above formula is broken down into its core elements: threats and vulnerabilities. The common formulaic way expressing this is:\nCybersecurity Risk = Threats x Vulnerabilities x Impact\nA good reference to learn more about cyber risk is the National Institute of Standards and Technology (NIST) cyber security framework which follows a risk-based logic: \xe2\x80\x9cidentify, protect, detect, respond, recover.\xe2\x80\x9d The NIST framework refers to the many common IT and OT security standards, such as ISO/IEC 27000, COBIT, ISA/IEC 62443. NIST states that, \xe2\x80\x9cRisk is a function of the likelihood of a given threat-source exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.\xe2\x80\x9d\n7-step approach to assessing OT and IIoT cybersecurity risk\nThere are several standards, best practices, and methodologies, such as ISA/IEC 62443, Cyber PHA, NIST, etc. that provide guidance on conducting cybersecurity risk assessments for IACSs. Most of them are generally in agreement with one another about the key points, so we have summarized the guidance from those sources into a 7-step approach that aligns with \xe2\x80\x9cwhat are we working on,\xe2\x80\x9d \xe2\x80\x9cwhat could go wrong,\xe2\x80\x9d and \xe2\x80\x9cwhat are we going to do about it,\xe2\x80\x9d as follows:\nDefine the system being assessed\nIdentify consequences of unintended access or behavior\nEnumerate known vulnerabilities\nIdentify threats\nEstimate likelihood\nRank the discovered risks\nDevelop a risk mitigation strategy\nLet\xe2\x80\x99s talk through each of these steps briefly.\nStep 1 \xe2\x80\x93 Define the system being assessed\nThis step aligns with \xe2\x80\x9cwhat are we working on.\xe2\x80\x9d Clearly documenting and defining the OT and IIoT system being assessed is a critical first step. It involves creating diagrams that describe both the logical and physical connectivity that cover the full application from sensors to cloud and everything in-between. Best practice from ISA/IEC 62443 standards is to partition the system into security zones and conduits. As per ISA/IEC 62443-3-2, Security Risk Assessment for System Design, a key step in the risk assessment process is to determine the scope of the risk assessment by partitioning the System Under Consideration (SUC) into separate Zones and Conduits. The intent is to identify those assets which share common security characteristics in order to establish a set of common security requirements that reduce cybersecurity risk. Partitioning the SUC into Zones and Conduits can also reduce overall risk by limiting the impact of a cyber incident. Part 3-2 requires or recommends that some assets are appropriately partitioned as follows:\nIsolate business and control system assets\nIsolate temporarily connected devices\nIsolate wireless devices\nIsolate safety-related devices\nIsolate devices connected via external networks (example: Internet)\nDefining the system also involves a functional description of system operations, an asset inventory, dataflows, and other information required for the assessment team to understand \xe2\x80\x98normal\xe2\x80\x99 operations.\nFigure 1: ISA/IEC 62443-3-2 Risk Assessment workflow (Courtesy of ISA)\nThe following example in Figure 2 shows the zones and conduits in a Data Flow Diagram (DFD) with different components in an IIoT system with Zone boundaries between IIoT device, IIoT Gateway, and Cloud and Trust Zones between different cloud services. For example, in AWS, customers can use multiple AWS accounts and AWS Virtual Private Cloud (Amazon VPC) to launch AWS resources in a logically isolated manner.\nFigure 2: Example of zones and conduits in IACS with IIoT systems\nStep 2 \xe2\x80\x93 Identify consequences of unintended access or behavior\nThe next step is considering what could go wrong if the IACS and IIoT system were to be accessed inappropriately. The access could result in one or more of the following consequences:\na) unauthorized access, theft, or misuse of confidential information\nb) publication of information to unauthorized destinations\nc) loss of integrity or reliability of process data and production information\nd) loss of system availability\ne) process upsets leading to compromised process functionality, inferior product quality, lost production capacity, compromised process safety, or environmental releases\nf) equipment damage\ng) personal injury\nh) violation of legal and regulatory requirements\ni) knock-on effects on critical systems at the local, regional, or national scale\nj) threat to a nation\xe2\x80\x99s security\nWhile many of these consequences are possible for both IT and IACS systems, consequences e, f, g, and i are more likely with cyber-physical systems that can change the physical domain. This is the characteristic that distinguishes IACS and IIoT systems from IT systems and defines the scope of the SUC.\nWhen performing this assessment, the team should evaluate and document the impact to process safety, reliability, and the environment in addition to evaluating the impact of data confidentiality, integrity, and availability (CIA) anywhere in the system, considering both data at rest and data in transit. Having defined security zone and conduits in Step 1 is beneficial because it enables the assessment team to compartmentalize the consequences by zone or conduit as shown in the example in Figure 2.\nStep 3 \xe2\x80\x93 Enumerate known vulnerabilities\nIn this step, which aligns with \xe2\x80\x9cwhat could go wrong,\xe2\x80\x9d the assessment team evaluates and documents known cybersecurity vulnerabilities in the system. This information can be gathered in a number of ways such as using vulnerability scanning tools and/or vulnerability research on the system components and their configuration. This doesn\xe2\x80\x99t necessarily need to be an exhaustive list of every common vulnerabilities and exposures (CVE), but it should at least include classes of vulnerabilities that unauthorized users may be able to exploit. Again, having partitioned the system into zones and conduits is beneficial as the team can organize their vulnerability discovery and documentation efforts by zone and conduit.\nStep 4 \xe2\x80\x93 Identify threats\nIn this step, which aligns with \xe2\x80\x9cwhat could go wrong,\xe2\x80\x9d the assessment team considers the credible threats (threat actors, threat sources, threat types) that could attempt to exploit the vulnerabilities identified in Step 3 and uses a model like STRIDE to enumerate \xe2\x80\x9cwhat could go wrong\xe2\x80\x9d in each element of the DFD. One good source to reference is the MITRE ATT&CK\xc2\xae for Industrial Control Systems (ICS) framework as MITRE provides broad guidance on describing the actions an adversary may take while operating within an ICS network. It highlights particular aspects of the specialized applications and protocols that ICS systems typically use, and that adversaries take advantage of, to interface with physical equipment. MITRE ATT&CK breaks down the lifecycle of a cyber incident using Tactics, where each Tactic describes a specific goal that an adversary may need to achieve using Techniques, which describes a specific method of achieving the related goal. For example, an unauthorized user may exploit a weakness in remote services (Technique) to gain initial access (Tactic) to the IIoT system. Using a combination of Tactics and Techniques can provide concrete guidance for an IIoT system threat modeling exercise.\nStep 5 \xe2\x80\x93 Estimate likelihood\nThis step aligns with \xe2\x80\x9cWhat are we going to do about it.\xe2\x80\x9d When attempting to assess cybersecurity risk, many people have difficulty estimating likelihood. While it\xe2\x80\x99s challenging, it can be estimated by decomposing likelihood into its core elements of threats and vulnerabilities and using semi-quantitative methods to define ranges of likelihood. A high-quality reference for this step is the Factor Analysis of Information Risk (FAIR) framework published by the FAIR Institute. They have developed a model for understanding, analyzing, and quantifying cybersecurity and operational risk. The FAIR framework factors security risk into its elements making it easier to understand and more practical to assess.\nStep 6 \xe2\x80\x93 Rank the discovered risks\nIn this step, which aligns with \xe2\x80\x9cwhat are we going to do about it,\xe2\x80\x9d threat scenarios are defined by describing how a threat can result in a consequence. Threat scenarios include threat actors, threat actions, and the vulnerabilities they may exploit to carry out the event. Once the scenario is defined, the risk can be scored and ranked based on the severity of the consequence and the likelihood of each threat. One good way to conduct this step is in a workshop setting where the assessment team walks through each zone and conduit and develops and analyzes credible threat scenarios. Ranking of the risks is typically guided by the use of a risk matrix which is a matrix of likelihood on one axis and impact on the other. Risk matrices are typically developed by corporate risk management or health, safety, and environmental organizations.\nFigure 3: Example Risk Matrix\nStep 7 \xe2\x80\x93 Develop a risk mitigation strategy\nThis step aligns with \xe2\x80\x9cwhat are we going to do about it.\xe2\x80\x9d Once the risk assessment is completed and its results analyzed, a report should be produced documenting the risks to the organization as well as a plan to mitigate risks to a tolerable level, providing decision makers with a concise risk and remediation picture. This plan is commonly based on safety, financial contribution, or even brand protection- whichever matters most to the organization. An effective remediation plan includes a prioritized list of actions, budgetary estimates, schedules, and resource requirements. Typically, these plans include short-term projects to mitigate high and critical risks and long-term projects that may involve many resources, modernizing the OT environment with new equipment, and training.\nFigure 4: Example Risk mitigation roadmap (click to enlarge)\n'"
82,Building machine learning pipelines with Amazon Kinesis Video Streams,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/building-machine-learning-pipelines-with-amazon-kinesis-video-streams/,"b'Introduction\nAmazon Kinesis Video Streams (KVS) makes it easy to securely stream video from connected devices to AWS for analytics, machine learning (ML), playback, and other processing. KVS automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions of devices. It durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. KVS enables you to play back video for live and on-demand viewing, and quickly build applications that take advantage of computer vision and video analytics. On May 4th, 2022, KVS announced new features that makes it easier to build scalable machine learning pipelines to analyze video data and deliver actionable insights to your customers. This blog post will walk you through the steps of setting up the required components that will enable you to convert your video data stored in KVS into image formats suitable for ML processing.\nBackground\nToday, customers want to add ML capabilities to their video streams to solve their business challenges. These challenges range from detecting people or pets, to domain specific challenges such as identifying defects in production. A common requirement in this process is converting video into image formats that can be delivered to ML pipelines. Prior to the launch of the image generation feature, customers who wanted to analyze their video stored in KVS needed to build, operate, and scale compute resources to transcode video into image formats such as JPEG and PNG. AWS offers many services to enable customers to build this solution on their own, however, building it from scratch would require many weeks of effort that ultimately wouldn\xe2\x80\x99t add any differentiation to your product.\nKVS now solves this problem by offering three key features:\nManaged delivery of images to Amazon S3\nOn Demand Image Generation API\nDelivery of stream events to an Amazon Simple Notification Service queue\nThis blog post will focus on the Managed delivery of images to Amazon S3. Please refer to the API documentation page for more information about the other features available.\nSolution Overview\nNote: Implementing this solution will incur charges to your AWS bill. Please consult the pricing page for detailed information on pricing.\nThere are 3 components involved in building this solution:\nThe Amazon S3 Service\nThe Amazon S3 service stores the generated images along with metadata including timestamps and the associated KVS fragment ID. The fragment ID can be used to obtain the original video data used to generate the image.\nKVS C++ Producer SDK\nThe KVS C++ Producer SDK is an open-source SDK available on Github. At a high-level, the purpose of the SDK is to segment video data into fragments and send the fragments to the KVS service where they are time indexed and stored. The Producer SDK provides a method named putEventMetadata that adds a tag to fragments. This tag is used to inform the KVS service to automatically generate images.  The sample application provided by the SDK will invoke this method automatically to test the image generation features of the service. Note: KVS offers Producer SDKs in Java and C; these SDKs also offer this tagging method.\nThe KVS service\nThe KVS service time indexes, and stores the video for a customer-defined retention period. Each camera in KVS is represented as a unique \xe2\x80\x9cstream.\xe2\x80\x9d The image generation feature of the KVS service must be configured on a per-stream basis. This configuration includes the image output format (JPEG, PNG), sampling interval, image quality, and the destination Amazon S3 bucket.\nThe following steps will guide you through the setup of each component. Let\xe2\x80\x99s get started!\nBuilding the Solution\nCreate an Amazon S3 Bucket\nThe KVS image generation feature requires an Amazon S3 bucket to be specified as part of the image generation configuration. The Amazon S3 bucket must be created in the same AWS region that you will use the KVS service. The example below specifies a bucket in us-east-1\naws s3 mb s3://sample-bucket-name --region us-east-1\nBash\nCheckout and compile the KVS C++ Producer SDK\nNote: This blog post uses the Kinesis Video Streams C++ Producer SDK along with a Raspberry Pi to demonstrate image generation with a real device. It is possible to compile the sample applications included with the KVS C++ Producer SDK on Mac, Windows, and Linux. Please refer to the FAQ section of the readme on Github for instructions on building for these platforms.\nThis process was tested on a Raspberry Pi 3 Model B Plus Rev 1.3 using the Raspberry Pi Camera V2.1. The Pi was imaged with Raspberry Pi OS \xe2\x80\x9cbullseye\xe2\x80\x9d using the image 2022-01-28-raspios-bullseye-arhmf-lite.img. At the time of writing, it is required to enable Legacy Camera support in raspi-config in order for the sample applications to access the camera module.\n1.   Install the required dependencies\nsudo apt-get install pkg-config cmake m4 git\nBash\nsudo apt-get install libssl-dev libcurl4-openssl-dev liblog4cplus-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-base-apps gstreamer1.0-plugins-bad gstreamer1.0-plugins-good gstreamer1.0-plugins-ugly gstreamer1.0-tools\nBash\n2.    Clone the KVS C++ Producer SDK version 3.3.0\ngit clone \xe2\x80\x94branch v3.3.0 https://github.com/awslabs/amazon-kinesis-video-streams-producer-sdk-cpp.git\nBash\n3.    Create the build directory\nmkdir -p amazon-kinesis-video-streams-producer-sdk-cpp/build\ncd amazon-kinesis-video-streams-producer-sdk-cpp/build\nBash\n4.    Build the SDK and sample applications\ncmake .. -DBUILD_GSTREAMER_PLUGIN=ON -DBUILD_DEPENDENCIES=OFF\nmake\nBash\nObtain IAM credentials for the sample application\nAfter building the SDK, the binary kvs_gstreamer_sample should be in the build directory.  This application requires IAM credentials in order to access the KVS APIs. The permissions for the credentials should allow the following actions:\n\xe2\x80\x9ckinesisvideo:PutMedia\xe2\x80\x9d\n\xe2\x80\x9ckinesisvideo:UpdateStream\xe2\x80\x9d\n\xe2\x80\x9ckinesisvideo:GetDataEndpoint\xe2\x80\x9d\n\xe2\x80\x9ckinesisvideo:UpdateDataRetention\xe2\x80\x9d\n\xe2\x80\x9ckinesisvideo:DescribeStream\xe2\x80\x9d\n\xe2\x80\x9ckinesisvideo:CreateStream\xe2\x80\x9d\n\xe2\x80\x9cs3:PutObject\xe2\x80\x9d\nAfter obtaining the permissions, you must export them prior to executing the kvs_gstreamer_sample.  An example is provided in the following section:\nexport AWS_ACCESS_KEY_ID=<your access key id> \nexport AWS_SECRET_ACCESS_KEY=<your secret access key> \nexport AWS_DEFAULT_REGION=<your region>\nBash\nConfiguring the KVS Service\nConfiguring the KVS service to enable the image generation feature requires 3 steps.\n1.    Create a KVS stream in the desired AWS region.\naws kinesisvideo create-stream --stream-name <stream name> \\\n--data-retention-in-hours 12 --region us-east-1\nBash\nThis example command creates a stream with a data retention of 12 hours.  Data will automatically be deleted after 12 hours. The image generation feature requires data retention to be greater than 0. Currently, 1 hour is the minimum configurable retention period.\n2.    Edit the following JSON with the StreamName, DestinationRegion, and Amazon S3 Bucket name. For more information on the other configuration items, please consult the KVS documentation page. Save this configuration using the filename update-image-generation-input.json.\n{\n ""StreamName"": ""<stream name>"",\n ""ImageGenerationConfiguration"": {\n  ""Status"": ""ENABLED"",\n  ""DestinationConfig"": {\n   ""DestinationRegion"": ""<region name>"",\n   ""Uri"": ""s3://<bucket name>""\n  },\n  ""SamplingInterval"": 3000,\n  ""ImageSelectorType"": ""PRODUCER_TIMESTAMP"",\n  ""Format"": ""JPEG"",\n  ""FormatConfig"": {\n   ""JPEGQuality"": ""80""\n  },\n  ""WidthPixels"": 320,\n  ""HeightPixels"": 240\n }\n}\nJSON\n3.    Use the AWS CLI to configure the image generation feature in the KVS service. If you change the preceding json file, simply call this AWS CLI command again.\naws kinesisvideo update-image-generation-configuration \\\n--cli-input-json file://update-image-generation-input.json\nBash\nGenerating Images\nAt this point you should have created an Amazon S3 bucket, compiled the KVS C++ Producer SDK sample application, obtained the appropriate credentials, exported them in your environment, and configured the KVS service to enable image generation.\nExecute the sample and pass the name of the stream created in a preceding section as the first argument.\n./kvs_gstreamer_sample <stream name>\nBash\nOpen the Amazon S3 console and you should see images being generated in your desired S3 bucket.\n'"
83,How to improve security at the edge with AWS IoT services,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-improve-security-at-the-edge-with-aws-iot-services/,"b'Introduction\nEdge computing, also known as fog computing and mobile computing, is a computing model that brings processing and data closer to the customer. By moving data closer to the customer, organizations need to review, and possibly expand, their security controls to ensure that their data is protected. In this blog I want focus on how AWS IoT Services, specifically AWS IoT Greengrass V2, AWS IoT Core, AWS IoT Device Defender, and AWS IoT Device Manager, can help organizations extend their security controls for encrypting, accessing and governing data that is outside their cloud or on-premises environment.\nUnderstanding AWS IoT Greengrass V2\nAWS IoT Greengrass V2 is an open source Internet of Things (IoT) edge runtime and cloud service that helps you build, deploy, and manage IoT applications on your devices. You can use AWS IoT Greengrass to build software that enables your devices to act locally on the data that they generate, run predictions based on machine learning models, and filter and aggregate device data. From an edge security perspective, it addresses data protection, device authentication and authorization, identity and access management, compliance validation, code integrity and configuration and vulnerability analyses. It enables devices to collect and analyze data closer to the source of information, react autonomously to local events, and communicate securely with each other on local networks. IoT devices can also communicate securely with AWS IoT Core, which is a managed service that lets connected devices interact easily and securely with cloud applications and other devices and exports IoT data to AWS.\nFigure 1- High level diagram showing the components of an IoT deployment\nAWS IoT Greengrass uses X.509 certificates, AWS IoT policies, and IAM policies and roles to secure the applications that run on devices in your local environment.\nFigure 2 \xe2\x80\x93 How AWS IoT Greengrass communicates with IoT devices\nUsing AWS IoT Greengrass with AWS IoT Core policies\nAs businesses use technology to transform their business processes, they may choose to deploy devices outside of traditional datacenters. For example, electrical utilities may install smart meters to provide real time data on electricity consumption. Prior to smart meters, electrical utilities sent crews across their network to manually read electric meters. This data would be hand written on forms, or more recently, input into a mobile device. In either case, the data was validated by a crew member and then sent to the datacenter for processing. With smart meters, electrical utilities need to ensure that the collected data hasn\xe2\x80\x99t been tampered with and that receiving the data doesn\xe2\x80\x99t pose a risk to downstream systems such as billing.\nElectrical utilities can use AWS IoT Greengrass to ensure that their data is protected when operating at the edge in 3 ways:\nFirst, AWS IoT Greengrass ensures that the devices accessing the data are trusted by using mutual TLS authentication using X.509 certificates. AWS IoT Greengrass core managed devices use certificates and AWS IoT Core policies to connect to AWS IoT Core for accessing cloud resources. When your device or other client attempts to connect to AWS IoT Core, the AWS IoT Core server will send an X.509 certificate that your device will use to authenticate to the server. Authentication takes place at the TLS layer through validation of the X.509 certificate chain. Client certificates need to be created and installed on the device before it can connect to AWS IoT Core. This ensures that only authorized devices can connect to IoT Core. AWS IoT Core helps customers create both server and client certificates and helps manage the lifecycle of the certificates. As a result, it reduces the security risk when operating at the edge.\nSecond, AWS IoT Greengrass helps customers create and enforce a least privileged security model for data access when operating at the edge, by using AWS IoT Core polices. AWS IoT Core policies are JSON documents and follow the same conventions as IAM policies. AWS IoT Core policies allow you to control access to the AWS IoT Core services such as AWS IoT Core message broker, send and receive MQTT messages, and get or update a device\xe2\x80\x99s shadow.\nThird, AWS IoT Greengrass ensures that when your data leaves the cloud for the edge, it remains secure through encryption in transit and at rest. All data sent to AWS IoT Core is sent over a TLS connection using MQTT, so it is secure by default in transit. AWS IoT Greengrass devices collect data and then send it to other AWS services for further processing. Additionally, electrical utilities can leverage FreeRTOS to ensure that data stored on the thing is encrypted, providing end-to-end encryption.\nWhen operating at the edge, AWS IoT Greengrass allows electrical utilities to create and enforce a more stringent data protection policy using a single platform. Based on this example, customers are able to benefit from AWS\xe2\x80\x99 security investments to ensure that their data is protected when residing outside of the cloud.\nUsing AWS IoT Greengrass with AWS IoT Device Defender and AWS IoT Device Management\nAs we look at how technology has become more pervasive in our lives, we realize that there are now a number of devices that are installed in our homes. Everything from smart thermostats to smart speakers, and televisions to gaming consoles, all require connectivity to the cloud. Different device manufacturers may take different approaches to device security. For example, a new company develops a device to monitor fitness. This company needs to deploy its new fitness monitor across different environments with varying network security controls. As a result, the company needs to ensure that its devices aren\xe2\x80\x99t compromised by a network-based attack or the physical introduction of malicious code. The company decides to leverage AWS IoT Greengrass and can use a complementary service called AWS IoT Device Defender to ensure that the IoT devices remain secure when operating at the edge. AWS IoT Device Defender helps the company audit the configuration of its devices, monitor connected devices to detect abnormal behavior, and mitigate security risks. It also helps the company enforce consistent security policies across its AWS IoT device fleet and respond quickly when devices are compromised.\nThe company can use AWS IoT Device Defender to help ensure its IoT devices maintain an acceptable level of trustworthiness. IoT devices operate in environments that are not all equally protected from malware. As a result, the company might need to audit its devices to ensure that they are not compromised. AWS IoT Device Defender can help the company validate device X509 certificates, determine if devices have been tampered with, and alert customers if a malicious IoT device is using an existing client ID for authentication. Additionally, AWS IoT Device Defender can generate an alert if roles have been modified to allow access to unrelated AWS services or if roles were altered to be overly permissive.\nAnother complementary service to AWS IoT Greengrass is AWS IoT Device Management, which offers a feature called Secure Tunneling. This feature allows the company to interact with its IoT devices without compromise. It works by creating client access tokens to establish a tunnel between the IoT device and the service. The company can then proxy traffic, such as SSH, over the tunnel to communicate with their IoT devices.\nBy using AWS IoT Greengrass in conjunction with AWS IoT Device Defender and AWS IoT Device Management, customers can monitor their devices for abnormal behavior while operating at the edge. If a problem is found, customers can use AWS IoT Service features to investigate the anomaly and take corrective action.\nUsing AWS IoT Greengrass with AWS IoT Core\nA smart lighting company that focuses on retail business security risk analysis reveals that additional security controls are needed to ensure the trustworthiness of their IoT devices. AWS IoT Greengrass has features that can mitigate this security concern: first, it enforces the use of the AWS IoT Core registry feature, and second, it integrates with AWS Identity and Access Management (IAM) to limit access to cloud resources. The registry feature of AWS IoT Core allows customers to track device information that helps determine the trustworthiness of the device. For example, registry can keep track of the MAC address and/or MQTT client id. As part of the authorization process, the customer can validate the device against the registry. As an added control, our lighting company can leverage the integration of IAM with AWS IoT polices to create an additional control to establish trustworthiness. IAM can be used to create a least privilege model for IoT devices accessing cloud resources. The lighting company can start with creating basic IAM polices that restrict access to only needed functions such as listing an IoT device\xe2\x80\x99s configuration. Additionally, the lighting company can add conditions that combine data from registry to ensure that only validated MQTT Client IDs can access cloud resources.\nThis example shows how customers can use the registry feature of AWS IoT Core to help lower the risk of operating at the edge in unmanaged networks by ensuring device identities are credible and that devices only have access to the resources they require.\n'"
84,Monitor AWS IoT connections in near-real time using MQTT LWT,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/monitor-aws-iot-connections-in-near-real-time-using-mqtt-lwt/,"b'In a connected device, you may need to monitor devices in near-real time to detect error and mitigate actions, Last Will and Testament (LWT) method for MQTT addresses this challenge. LWT is a standard method of MQTT protocol specification that allows to detect abrupt disconnects of devices and to notify other clients about this abrupt disconnections.\nIoT devices are often used in environments with unreliable network connectivity and/or devices might disconnect due to lack of power supply, low battery, loss of connection, or any other reason. This will cause abrupt disconnections from the broker without knowing if the disruption was forced by the client or truly abrupt, This is where LWT let\xe2\x80\x99s a client provide a testament along with its credentials when connecting to the AWS IoT Core. If the client disconnects abruptly at some point later (i.e. power loss), it can let AWS IoT Core deliver a message to other clients and inform them of this abrupt disconnect and deliver LWT message.\nMQTT Version 3.1.1 provides an LWT feature as part of the MQTT message and is supported by AWS IoT Core, so any client which disconnects abruptly can specify its LWT message along with the MQTT topic when it connects to the broker. When the client disconnects abruptly, the broker (AWS IoT Core) will then publish the LWT message provided by that client at connection time to all the devices which subscribed to this LWT topic.\nThe MQTT LWT feature enables you to monitor AWS IoT connections in near-real time to help you to take corrective actions. You can react to abrupt disconnection events by verifying status, restoring connections, and carrying out either edge-based (device side) actions or cloud-based actions to investigate and mitigate this abrupt disconnect of the device.\nIn this blog we will go through following steps:\nA simulated \xe2\x80\x98lwtThing\xe2\x80\x99 device connects to AWS IoT Core by giving Keep-alive time\nThe \xe2\x80\x98lwtThing\xe2\x80\x99 device, on the connection to AWS IoT Core, provides the following:\nTopic for LWT (i.e. /last/will/topic)\nLWT message\nQoS type either 0 or 1\n\xe2\x80\x98lwtThing\xe2\x80\x99 device disconnects abruptly from AWS IoT Core\nAWS IoT Core detects this and publishes the LWT message to all the subscribers of the topic (i.e. /last/will/topic)\nRules for AWS IoT (rule engine) picks up the trigger on the topic and invokes Amazon Simple Notifications Service (SNS)\nAmazon SNS sends a notification email\nWe will setup a virtual environment using a CloudFormation template (by using AWS IoT workshop setup instructions) and launch a virtual IoT thing (naming \xe2\x80\x98lwtThing\xe2\x80\x99) to create a real life simulation of the physical device.\nArchitecture\nWe will simulate the edge device using a script provided below and send the LWT message, showing abrupt disconnects and triggering AWS IoT rules and subsequently invoking Amazon SNS to send emails.\nSetup\nWe will use the following workshop setup to get quickly bootstrapped and test LWT. You can use the following link to setup AWS Cloud9 environment (pick any region closest to your location).\nOnce we have the environment setup using the workshop AWS CloudFormation pre-provided template, lets begin testing the ungraceful disconnects with AWS IoT Core (AWS MQTT broker on the cloud).\nNow open the Cloud9 terminal (see here) and let\xe2\x80\x99s setup Python SDK for us to use.\nCreate a folder for us to use to connect our IoT thing using the Cloud9 terminal window.\nmkdir -p /home/ubuntu/environment/lwt/certs\ncd /home/ubuntu/environment/lwt/\nBash\nSetup Python IoT SDK using full instructions here.\nQuick instructions:\ngit clone https://github.com/aws/aws-iot-device-sdk-python.git\ncd aws-iot-device-sdk-python\npython setup.py install\nGit\nNow, to setup your AWS IoT Thing follow steps outlined here.\nOnce we have created the thing, let\xe2\x80\x99s upload these certificates in our Cloud9 instance for us to connect from there.\nUpload the newly created certificates and RootCA into following folder (created earlier)\n/home/ubuntu/environment/lwt/certs\nBash\nLWT thing messages\nLet\xe2\x80\x99s copy the Python code to Cloud9 and execute as the simulated AWS IoT thing.\nCopy the following commands:\ntouch lwtTest.py\nBash\nOpen the file and copy the following code into it.\n\'\'\'\n/*\n * # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n * # SPDX-License-Identifier: MIT-0\n * \n */\n\n\n \'\'\'\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\nimport logging\nimport time\nimport argparse\nimport json\n\nAllowedActions = [\'both\', \'publish\', \'subscribe\']\n\n# Custom MQTT message callback\ndef customCallback(client, userdata, message):\n    print(""Received a new message: "")\n    print(message.payload)\n    print(""from topic: "")\n    print(message.topic)\n    print(""--------------\\n\\n"")\n\n# LWT JSON payload\npayload ={\n  ""state"": {\n    ""reported"": {\n      ""last_will"": ""yes"",\n      ""trigger_action"": ""on"",\n      ""client_id"": ""lwtThing""\n        }\n    }\n}\n \n# conversion to JSON done by dumps() function\njsonPayload = json.dumps(payload)\n \n# printing the output\n#print(jsonPayload)\n\n\n# Read in command-line parameters\nparser = argparse.ArgumentParser()\nparser.add_argument(""-e"", ""--endpoint"", action=""store"", required=True, dest=""host"", help=""Your AWS IoT custom endpoint"")\nparser.add_argument(""-r"", ""--rootCA"", action=""store"", required=True, dest=""rootCAPath"", help=""Root CA file path"")\nparser.add_argument(""-c"", ""--cert"", action=""store"", dest=""certificatePath"", help=""Certificate file path"")\nparser.add_argument(""-k"", ""--key"", action=""store"", dest=""privateKeyPath"", help=""Private key file path"")\nparser.add_argument(""-p"", ""--port"", action=""store"", dest=""port"", type=int, help=""Port number override"")\nparser.add_argument(""-w"", ""--websocket"", action=""store_true"", dest=""useWebsocket"", default=False,\n                    help=""Use MQTT over WebSocket"")\nparser.add_argument(""-id"", ""--clientId"", action=""store"", dest=""clientId"", default=""basicPubSub"",\n                    help=""Targeted client id"")\nparser.add_argument(""-t"", ""--topic"", action=""store"", dest=""topic"", default=""sdk/test/Python"", help=""Targeted topic"")\nparser.add_argument(""-m"", ""--mode"", action=""store"", dest=""mode"", default=""both"",\n                    help=""Operation modes: %s""%str(AllowedActions))\nparser.add_argument(""-M"", ""--message"", action=""store"", dest=""message"", default=""AWS IoT Thing connected message to IoT Core"",\n                    help=""Message to publish"")\n\nargs = parser.parse_args()\nhost = args.host\nrootCAPath = args.rootCAPath\ncertificatePath = args.certificatePath\nprivateKeyPath = args.privateKeyPath\nport = args.port\nuseWebsocket = args.useWebsocket\nclientId = args.clientId\ntopic = args.topic\n\nif args.mode not in AllowedActions:\n    parser.error(""Unknown --mode option %s. Must be one of %s"" % (args.mode, str(AllowedActions)))\n    exit(2)\n\nif args.useWebsocket and args.certificatePath and args.privateKeyPath:\n    parser.error(""X.509 cert authentication and WebSocket are mutual exclusive. Please pick one."")\n    exit(2)\n\nif not args.useWebsocket and (not args.certificatePath or not args.privateKeyPath):\n    parser.error(""Missing credentials for authentication."")\n    exit(2)\n\n# Port defaults\nif args.useWebsocket and not args.port:  # When no port override for WebSocket, default to 443\n    port = 443\nif not args.useWebsocket and not args.port:  # When no port override for non-WebSocket, default to 8883\n    port = 8883\n\n# Configure logging - we will see messages on STDOUT\nlogger = logging.getLogger(""AWSIoTPythonSDK.core"")\nlogger.setLevel(logging.DEBUG)\nstreamHandler = logging.StreamHandler()\nformatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\nstreamHandler.setFormatter(formatter)\nlogger.addHandler(streamHandler)\n\n# Init AWSIoTMQTTClient\nmyAWSIoTMQTTClient = None\nif useWebsocket:\n    myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId, useWebsocket=True)\n    myAWSIoTMQTTClient.configureEndpoint(host, port)\n    myAWSIoTMQTTClient.configureCredentials(rootCAPath)\nelse:\n    myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)\n    myAWSIoTMQTTClient.configureEndpoint(host, port)\n    myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)\n\n#########\n# Will Topic\n# Input parameters are: Topic, Last will message and finally QoS\nmyAWSIoTMQTTClient.configureLastWill(\'/last/will/topic\', jsonPayload, 0)\n#########\n\n\n# Connect and subscribe to AWS IoT\n# keep-alive connect parameter - setting 30s\nmyAWSIoTMQTTClient.connect(30) \nprint(""Connected!"")\nloopCount = 1\nwhile loopCount < 2:\n    if args.mode == \'both\' or args.mode == \'publish\':\n        message = {}\n        message[\'message\'] = args.message\n        messageJson = json.dumps(message)\n        myAWSIoTMQTTClient.publish(topic, messageJson, 1)\n        if args.mode == \'publish\':\n            print(\'Published topic %s: %s\\n\' % (topic, messageJson))\n            loopCount +=1\n#lets put the device to sleep so it creates disconnect after 60s\nprint(""--- Putting device to sleep now, so IoT core keep-alive time expires. ---"")\nprint(""--- We will abruptly disconnect the device after 60seconds. ---"")\ntime.sleep(60)\nPython\nLet\xe2\x80\x99s look at the following line which is doing all the work on setting the LWT Topic, JSON payload, and what level of QoS we are using.\nmyAWSIoTMQTTClient.configureLastWill(\'/last/will/topic\', jsonPayload, 0)\nJSON\nTopic used is : /last/will/topic\nQoS (Quality of Service) is: 0\nJSON Payload variable contains following payload:\n{\n  ""state"": {\n    ""reported"": {\n      ""last_will"": ""yes"",\n      ""trigger_action"": ""on"",\n      ""client_id"": ""lwtThing""\n        }\n    }\n}\nJSON\nThe above setup defines the LWT topic as well as what topic to post this message to, which will be understood and executed by AWS IoT rules once the device disconnects abruptly (The \xe2\x80\x9cLast Will\xe2\x80\x9d is\npublished by the server when its connection to the client is unexpectedly lost.) An AWS IoT rule will trigger the action on Amazon SNS to send an email upon its execution. You can read more on the other options in the SDK document.\nWe are setting keep-alive to 30seconds at connection to AWS IoT core so it keeps the session alive for the given time. Once the time runs out, the session is expired.\nAt the expiration of the session, we set the device to sleep for 60 seconds, Once 60 seconds finishes we abruptly disconnects the devices which in turn generates Last Will Testament (LWT) trigger from AWS IoT Core and message gets published to all topic subscribers who are listening to this LWT topic.\nSetup Amazon SNS\nLet\xe2\x80\x99s setup Amazon SNS and configure it to send email as its notification, From the Amazon SNS console do the following:\nSelect Topics\nSelect Create topic\nSelect Standard\nSelect Name (i.e. lwtSNSTopic)\nSelect Display name (i.e. lwtSNSTopic)\nSelect Create topic\nOnce topic is created\nSelect Create subscription\nSelect Email from Protocol dropdown\nFor Endpoint give the email address you would like to use\nSelect Create subscription\nYou should receive an email. Please confirm the subscription. If you have not confirmed the subscription, you will not be able to receive any emails.\nSetup Rules for AWS IoT Core\nFrom the AWS IoT Core console do the following:\nSelect Act\nSelect Rules\nSelect Create\nGive a name (i.e. lastWillRule) and description (My first LWT rule)\nIn Rule query statement enter following:\nSELECT * FROM \'/last/will/topic\' where state.reported.last_will = \'yes\' and state.reported.trigger_action = \'on\'\nIn Actions section\nSelect Add Action\nSelect Send a message to an SNS push notification\nSelect Configure action\nIn SNS target Select the SNS topic you created earlier (i.e. lwtSNSTopic)\nIn Message format, Select JSON\nSelect Create Role\nGive it a name (i.e. lwtRuleRole)\nSelect Add action\nLet\xe2\x80\x99s add another action here, we will republish the incoming LWT message to another topic to verify its incoming.\nIn Actions section\nSelect Add Action\nSelect Republish a message to an AWS IoT topic\nSelect Configure action\nUnder Topic\nSelect /lwt/executed\nwe can leave the Quality of Service default\nFor \xe2\x80\x98Choose or create a role to grant AWS IoT access to perform this action\nSelect lwtRuleRole\nSelect Update role\nSelect Add action\nThis concludes our rules setup section, let\xe2\x80\x99s proceed and setup sending LWT messages and execute our setup.\nSending LWT messages\nBefore we execute the simulated device (using python code) let\xe2\x80\x99s subscribe to the topic in the AWS IoT Core console.\nFigure 2\nNow that we have everything in place, let\xe2\x80\x99s execute the IoT Thing (simulated using Python code). You can use the sample execution command which may differ for you as your thingID might be different or your certificates path might be in a different location.\nSample command (replace xxxx with relevant values for your setup):\npython lwtTest.py -e xxxxxxxxxxxxxx-ats.iot.us-east-1.amazonaws.com -r /home/ubuntu/environment/lwt/certs/AmazonRootCA1.pem -c /home/ubuntu/environment/lwt/certs/xxxxxxxxxxxxxxxxxxxxxxxxxxxx-certificate.pem.crt -k /home/ubuntu/environment/lwt/certs/xxxxxxxxxxxxxxxxxxxxxxxxxxxx-private.pem.key -id lwtThing -t /lwt/connected/topic -m publish\nBash\nWhat we are passing as input parameters to the code is as follows:\n-e is referring to the end point of AWS IoT Core\n-r is the full file path where our Amazon Root CA is located\n-c is the full file path for our certificate location\n-k is the full file path for our private key\n-id is the ClientID we are using to send to AWS IoT Core (you should match this to what you have created the Thing in IoT Core as)\n-t is the topic we are providing to publish on when it first connects to AWS IoT Core\n-m is the mode we have defined in the code and we will use publish for this test. (available modes are: publish, subscribe or both)\nLet\xe2\x80\x99s look at the execution of the command, we should see that LWT is getting configured and what message we published to AWS IoT Core. You will also see abrupt disconnect after 60 seconds.\nFigure 3\nSwitching over to the AWS IoT Core console to see incoming messages, subscribe to following topics:\nTopic used for republishing of the message when the rule is executed (using as debug): /lwt/executed\nTopic used for when LWT message is published upon ungraceful disconnect of a client: /last/will/topic\nTopic /lwt/connected/topic you can see messages posted by the thing. This occurs when the client is connected to AWS IoT Core and sends the message to inform the broker I\xe2\x80\x99m here and connected.\nFigure 4\nUnder topic /last/will/topic we can see the message executed by AWS IoT Core once the device ungracefully disconnects.\nFigure 5\nWhen AWS IoT rule is executed for LWT we can see within topic /lwt/executed payload is published to this topic too, we configured this topic earlier to repost to when AWS IoT rule is executed upon device abrupt disconnection.\nFigure 6\nUpon successful execution of the AWS IoT rule we also triggered Amazon SNS email notification and if you have configured this correctly earlier you will see similar email in your inbox.\nFigure 7\n'"
85,Build IoT web applications using AWS IoT Application Kit,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/08/Featured-Image-1024x513.png,https://aws.amazon.com/blogs/iot/build-iot-applications-using-aws-iot-application-kit/,"b'On Mar 1, 2022, we announced AWS IoT Application Kit, an open-source UI components library for IoT application developers. With AWS IoT Application Kit, developers can build rich interactive web applications leveraging data from AWS IoT SiteWise. IoT application developers can deliver customized user experiences like industrial asset monitoring applications using web front-end frameworks like ReactJS, Vue.js or vanilla JavaScript along with reusable components from AWS IoT Application Kit.\nFigure 1: Screenshot of sample ReactJS application built with AWS IoT Application Kit\nWhat is AWS IoT Application Kit?\nAWS IoT Application Kit is an open-source, client-side library that enables IoT application developers to simplify the development of complex IoT applications. It leverages performant, reusable components that abstract critical technical considerations expected from a real-time web application; for example, handling streaming data, caching, preloading data, dynamic aggregation, and preventing request fragmentation. This abstraction allows IoT application developers to focus on building custom user experiences and worry less about underlying technical complexities.\nIn cases where customers require integrating and enriching their existing web applications for visualizing IoT data from AWS IoT SiteWise, AWS IoT Application Kit also allows customers to integrate the included components into their existing web application.\nGetting started with AWS IoT Application Kit\nAWS IoT Application Kit is currently available as a npm package \xe2\x80\x93 @iot-app-kit/components. You can install this package with:\nUsing npm\nnpm install @iot-app-kit/components\nBash\nFor additional details, please refer to the technical documentation for AWS IoT Application Kit.\nBuilding with AWS IoT Application Kit\nIn this blog post, we\xe2\x80\x99ll build a ReactJS web application with AWS IoT Application Kit and AWS IoT SiteWise for monitoring an industrial juice bottling line, displaying the telemetry (such as Machine Status and Production Count) from each of the constituent machines in the bottling line.\nWalkthrough\nPrerequisites\nThe following is required to build this solution:\nAWS CLI\nAWS CDK\nAn AWS CLI profile with permissions to deploy stacks via AWS CloudFormation\nA default VPC present in your AWS account\nStep 1: Simulate telemetry of an industrial bottling line\nThe industrial juice bottling line we want to model is comprised of the following interconnected machines (in order):\nTable 1: Ordered list of interconnected machines in simulated industrial juice bottling line\nOrder Machine Name Machine ID Description\n1st Washing Machine UN01 Washes, sanitizes and dries each incoming empty bottle.\n2nd Filling Machine UN02 Fills each incoming sanitized bottle to the configured quantity.\n3rd Capping Machine UN03 Caps and seals each incoming filled bottle.\n4th Labelling Machine UN04 Attaches and prints the product label on each capped bottle.\n5th Case Packing Machine UN05 Packs configured group of labelled bottles into a single case.\n6th Palletizing Machine UN06 Palletizes multiple cases of processed bottles into a pallet for shipment.\nFigure 2: Representation of machines in the industrial bottling line simulated with this demo\nEach of these machines emits the following data measurements as telemetry:\nTable 2: List of modeled OPC-UA tags\nMeasurement Name Measurement Unit Data Type Modeled Tag Description\nMachine State None Integer {Machine_ID}/Status/StateCurrent Current operational state of the machine. Possible values are listed in Table 3: Machine States Description.\nMachine Mode None Integer {Machine_ID}/Status/ModeCurrent The mode under which the machine is operating. Possible values are listed in Table 4: Machine Operating Modes.\nCurrent Speed Bottles per minute Double {Machine_ID}/Status/CurMachSpeed Current operational speed of the machine measured in bottles processed per minute.\nBlocked None Boolean {Machine_ID}/Status/Blocked Indicating whether the machine is blocked from operating due to downstream machine(s) conditions.\nStarved None Boolean {Machine_ID}/Status/Starved Indicating whether the machine is starved from operating due to upstream intake conditions.\nStop Reason None Integer {Machine_ID}/Admin/StopReasonCode Machine Stop Reason Code.\nProcessed Count None Integer {Machine_ID}/Admin/ProcessedCount Incremental counter of bottles processed by the machine, either successfully or unsuccessfully.\nDefective Count None Integer {Machine_ID}/Admin/DefectiveCount Incremental counter of bottles processed unsuccessfully by the machine.\nTable 3: Machine States Description\nStateCurrent Values Implied Machine State\n1 PRODUCING\n2 IDLE\n3 STARVED\n4 BLOCKED\n5 CHANGEOVER\n6 STOPPED\n7 FAULTED\nTable 4: Machine Operating Modes\nModeCurrent Values Implied Machine Mode\n1 AUTOMATIC\n2 MAINTENANCE\n3 MANUAL\nWe will use Node-RED hosted on an Amazon EC2 instance to create a flow which simulates an OPC-UA server allowing to read the modeled tags mentioned in Table 2: List of modeled OPC-UA tags for each of the machines in the industrial juice bottling line. To quickly setup the Node-RED environment, clone the accompanying AWS CDK infrastructure as code from github.\nClone the application to your local machine.\ngit clone https://github.com/aws-samples/aws-iot-app-kit-bottling-line-demo.git iot-app-kit-demo\nBash\nChange to the project directory.\ncd iot-app-kit-demo\nBash\nInstall dependencies for the AWS CDK. Note, this is for the infrastructure only.\nnpm ci\nBash\nConfigure your account and region for CDK deployment\nNote: Please use an AWS region where AWS IoT SiteWise is available.\ncdk bootstrap aws://<ACCOUNT-NUMBER>/<REGION>\nBash\nDeploy the cdk stack named OpcuaSimulatorStack. When prompted with \xe2\x80\x9cDo you wish to deploy these changes (y/n)?\xe2\x80\x9d Enter Y.\ncdk deploy OpcuaSimulatorStack\nBash\nFigure 3: Architecture diagram of AWS IoT Application Kit Bottling Line Demo\nSuccessful deployment of the OpcuaSimulatorStack should create an OPC-UA server, AWS IoT Greengrass V2 core, a corresponding AWS IoT SiteWise gateway along with asset models and derived assets (representing the machines in the juice bottling line). All of the application components i.e., OPC-UA Server, AWS IoT Greengrass V2 core and AWS IoT SiteWise gateway are deployed in an Ubuntu EC2 Instance created through the OpcuaSimulatorStack.\nDeploying the OpcuaSimulatorStack should take a few minutes and will be indicated by the output of the cdk deploy command. In Step 2, we will be building a ReactJS web application to monitor the assets created for the juice bottling line.\nStep 2: Build a custom application to visualize the industrial bottling line operation\nThe cloned code repository aws-iot-app-kit-bottling-line-demo.git contains a starter ReactJS application in the directory named assets/react-app. In this step, we will be adding our AWS IoT Application Kit components to the starter ReactJS application in incremental steps.\nChange to the ReactJS application directory.\ncd assets/react-app\nBash\nInstall required NPM dependencies\nnpm ci\nBash\nCreate a .env file in the root directory of the react-app i.e., assets/react-app/.env\ntouch .env\nBash\nEdit the .env file and add your AWS IAM credentials for programmatic access as environment variables prefixed with REACT_APP_ as shown in the snippet. The value for REACT_APP_AWS_SESSION_TOKEN is only required if you are using short-lived IAM credentials for programmatic access.\nREACT_APP_AWS_ACCESS_KEY_ID=<replace-with-aws-access-key-id>\nREACT_APP_AWS_SECRET_ACCESS_KEY=<replace-with-aws-access-key>\nREACT_APP_AWS_SESSION_TOKEN=<replace-with-aws-session-token>\nBash\nSave the .env file after editing.\nFrom here, we will begin adding AWS IoT Application Kit components one by one to demonstrate the usage of each component.\nAdd AWS IoT Application Kit NPM packages to ReactJS application dependencies.\nnpm install @iot-app-kit/components @iot-app-kit/react-components @iot-app-kit/source-iotsitewise\nBash\nOpen and edit src/App.tsx to import installed AWS IoT Application Kit components between the comment lines /* --- BEGIN: AWS @iot-app-kit and related imports*/and /* --- END: AWS @iot-app-kit and related imports*/ as shown below. Replace the value of awsRegion with the actual AWS region (where OpcuaSimulatorStack was deployed in Step 1).\n...\n/* --- BEGIN: AWS @iot-app-kit and related imports*/\nimport { initialize } from ""@iot-app-kit/source-iotsitewise"";\nimport { fromEnvReactApp } from ""./fromEnv"";\nimport {\n    BarChart,\n    LineChart,\n    StatusTimeline,\n    ResourceExplorer,\n    WebglContext,\n    StatusGrid,\n    Kpi,\n} from ""@iot-app-kit/react-components"";\nimport { COMPARISON_OPERATOR } from ""@synchro-charts/core"";\n\nimport ""./App.css"";\n\nconst { defineCustomElements } = require(""@iot-app-kit/components/loader"");\n\nconst { query } = initialize({\n    awsCredentials: fromEnvReactApp(),\n    awsRegion: ""<replace-with-aws-region>"",\n});\n\ndefineCustomElements();\n/* --- END: AWS @iot-app-kit and related imports*/\n...\nTypeScript\nRefer to the AWS IoT SiteWise console to populate the respective asset property ids between the comment lines /* --- BEGIN: Asset Id and Asset Property Ids from AWS IoT SiteWise*/ and /* --- END: Asset Property Ids from AWS IoT SiteWise*/ that need to be displayed with AWS IoT Application Kit\n...\n/* --- BEGIN: Asset Id and Asset Property Ids from AWS IoT SiteWise*/\n    \n// Asset Id of the AWS IoT SiteWise asset that you want to display by // default\nconst DEFAULT_MACHINE_ASSET_ID = \'<replace-with-sitwise-asset-id>\';\nconst [ assetId, setAssetId ] = useState(DEFAULT_MACHINE_ASSET_ID);\nconst [ assetName, setAssetName ] = useState(\'<replace-with-corresponding-sitwise-asset-name>\');\n    \n// Asset Property Ids of the AWS IoT SiteWise assets that you want to // query data for\n\n// Refer AWS IoT SiteWise measurements\nconst OEE_BAD_COUNT_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst OEE_TOTAL_COUNT_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst CURRENT_SPEED_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst MACHINE_STOP_REASON_CODE_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\n\n// Refer IoT SiteWise transforms\nconst MACHINE_STATE_ENUM_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst MACHINE_MODE_ENUM_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst STARVED_INDICATOR_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\nconst BLOCKED_INDICATOR_PROPERTY = \'<replace-with-corresponding-sitwise-asset-property-id>\';\n    \n\n/* --- END: Asset Property Ids from AWS IoT SiteWise*/\n...\nTypeScript\nSince we have several assets in our juice bottling line, let us first implement the ResourceExplorer component to allow filtering, sorting, and pagination of our assets. Add the following code between the comment lines {/* --- BEGIN: `ResourceExplorer` implementation*/} and {/* --- END: `ResourceExplorer` implementation*/} in src/App.tsx\n...\n{/* --- BEGIN: `ResourceExplorer` implementation*/}\n<ResourceExplorer\n    query={query.assetTree.fromRoot()}\n    onSelectionChange={(event) => {\n        console.log(""changes asset"", event);\n        props.setAssetId((event?.detail?.selectedItems?.[0] as any)?.id);\n        props.setAssetName((event?.detail?.selectedItems?.[0] as any)?.name);\n                }}\n    columnDefinitions={columnDefinitions}\n/>\n{/* --- END: `ResourceExplorer` implementation*/}\n...\nMarkup\nNext, we will implement StatusTimeline component to visualize the Machine State asset property of our various assets. Add the following code between the comment lines  {/* --- BEGIN: `StatusTimeline` implementation*/} and {/* --- END: `StatusTimeline` implementation*/}.\n...\n{/* --- BEGIN: `StatusTimeline` implementation*/}\n <div style={{ height: ""170px"" }}>\n    <StatusTimeline\n        viewport={{ duration: \'15m\' }}\n        annotations={{\n            y: [\n                { color: \'#1D8102\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'PRODUCING\' },\n                { color: \'#0073BB\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'IDLE\' },\n                { color: \'#D45200\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'STARVED\' },\n                { color: \'#DA4976\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'BLOCKED\' },\n                { color: \'#5951D6\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'CHANGEOVER\' },\n                { color: \'#455A64\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'STOPPED\' },\n                { color: \'#AB1D00\', comparisonOperator: COMPARISON_OPERATOR.EQUAL, value: \'FAULTED\' }\n            ]\n        }}\n        queries={[\n            query.timeSeriesData({\n                assets: [{\n                    assetId: props.assetId,\n                    properties: [{\n                        propertyId: props.machineStatePropertyId\n                    }]\n                }]\n            })\n        ]}\n    />\n</div>\n{/* --- END: `StatusTimeline` implementation*/}\n...\nMarkup\nNext, we will implement a LineChart component to visualize the following metrics defined in AWS IoT SiteWise for each of the machines in the juice bottling line:\nTotal Count of bottles processed every 15 minutes\nBad Count of bottles processed every 15 minutes\nAdd the following code between the comment lines {/* --- BEGIN: `LineChart` implementation*/} and {/* --- END: `LineChart` implementation*/}.\n...\n{/* --- BEGIN: `LineChart` implementation*/}\n<div style={{ height: ""170px"" }}>\n    <LineChart\n        viewport={{ duration: ""15m"" }}\n        queries={[\n            query.timeSeriesData({\n                assets: [\n                    {\n                        assetId: props.assetId,\n                        properties: [\n                            {\n                                propertyId: props.badPartsCountPropertyId,\n                                refId: ""bad-parts-count"",\n                            },\n                            {\n                                propertyId: props.totalPartsCountPropertyId,\n                                refId: ""total-parts-count"",\n                            },\n                        ],\n                    },\n                ],\n            }),\n        ]}\n        styleSettings={{\n            ""bad-parts-count"": { color: ""#D13212"", name: ""Bad Count"" },\n            ""total-parts-count"": { color: ""#1D8102"", name: ""Total Count"" },\n        }}\n    />\n</div>\n{/* --- END: `LineChart` implementation*/}\n...\nMarkup\nAdd WebglContext component between the comment lines {/* --- BEGIN: `WebglContext` implementation*/} and {/* --- END: `WebglContext` implementation*/}.\nNote: WebglContext should be declared only once throughout your ReactJS component tree.\n...\n{/* --- BEGIN: `WebglContext` implementation*/}\n<WebglContext/>\n{/* --- END: `WebglContext` implementation*/}\n...\nMarkup\nStart a local development server and view the revised ReactJS application by navigating to http://localhost:3000. Once launched, browse through the juice bottling line asset hierarchy and select the asset you want to monitor using the ResourceExplorer component. Upon selecting a particular asset, you can view the Machine State measurements in the displayed StatusTimeline component and Total Count and Good Count metrics in the LineChart components.\nnpm start\nBash\nAWS IoT Application Kit also includes components for the following visualization widgets:\nBarChart\nKpi\nScatterChart\nStatusGrid\nThe starter ReactJS application also contains sample implementations of BarChart, Kpi and StatusGrid components in the file src/App.tsx. You can refer to AWS IoT Application Kit documentation for details on how to use these components in your ReactJS application.\nFigure 4: Screenshot of demo application\nYou can also refer to the sample file src/App.completed.tsx for a completed implementation of AWS IoT Application Kit.\nYou can also host the ReactJS application built in this walkthrough with AWS Amplify. You can refer to AWS Amplify getting started hands-on guide to get started.\nCleaning up\nDelete the created AWS resources setup in this walkthrough by changing directory to the project directory and executing the following stack deletion commands. When prompted with \xe2\x80\x9cAre you sure you want to delete: (y/n)?\xe2\x80\x9d Enter Y.\ncd iot-app-kit-demo \ncdk destroy OpcuaSimulatorStack\nBash\n'"
86,Edge to Twin: A scalable edge to cloud architecture for digital twins,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/05/06/Overview_1-1024x442.png,https://aws.amazon.com/blogs/iot/edge-to-twin-a-scalable-edge-to-cloud-architecture-for-digital-twins/,"b'Are you seeking ways to get an immersive 3D view of your systems and operations to optimize efficiency, increase production, and improve performance? Perhaps you are generating all the data you need from various on-premise systems, but are unsure how to gain access to this information in a living virtual representation. In this blog post, you will learn how to build an end-to-end solution, from Edge to Twin, using AWS IoT TwinMaker. You will also learn how to configure various AWS services to pull telemetry data from an industrial mixer using Open Platform Communications United Architecture (OPC UA) at the edge and build its twin with AWS IoT TwinMaker.\nOverview\nThis blog will only work with one data source, but as you acquire multiple streams of data from an industrial environment, AWS IoT TwinMaker can help save time with an automatically generated knowledge graph that binds your data sources. Data sources can range from AWS IoT SiteWise, time series historians, alarming databases, Manufacturing Execution Systems (MES), Enterprise Resource Planning (ERP) systems, and other business systems. Binding these data sources can enable you to create virtual replicas of physical systems to accurately model real-world environments. Over time, your digital twin can grow to adopt Machine Learning (ML) capabilities for anomaly detection and predictive maintenance. The image below is an example of how you can bind various data streams into AWS IoT TwinMaker, including video.\nExample manufacturing dashboard for AWS IoT TwinMaker\nScalable Architecture for an Industrial Edge to Twin\nThis scalable architecture will be created in this blog and will allow you to manage thousands of entities and link their respective data sources\nPrerequisites\nAn AWS account will be required to setup and execute the steps in this blog with real-time simulation. Several services will be configured for the edge which will stream this real-time simulated data through AWS IoT SiteWise to AWS IoT TwinMaker. It is recommended that you work in the Virginia region (us-east-1). You may incur cost on some of the following services:\nSetup of OPC UA server on Amazon Elastic Compute Cloud (Amazon EC2) to simulate Mixer data\nSetup of AWS IoT SiteWise gateway on AWS IoT Greengrass\nSetup of AWS IoT SiteWise Asset Model and Asset for a Mixer\nSetup of AWS IoT TwinMaker Workspace, Entities, and Scene\nVisualize AWS IoT TwinMaker scene in Amazon Managed Grafana\nRunning on Amazon EC2 with Ubuntu\nLet\xe2\x80\x99s start with the telemetry simulation. For simplicity, you will use an Amazon EC2 instance, but this section may be replaced with your choice for edge computing. On the Amazon EC2 system, you will set up a gateway to ingest data from an asset using a common industrial protocol, OPC UA.\nThe next task is to log into the instance and install node.js and Node-RED. You will also install an OPC UA server node to simulate data. This is solely for the purpose of simulation. In reality, industrial assets and systems on-premise will likely support OPC UA.\nCreate the base Amazon EC2 image\nLog in to the Amazon EC2 console\nClick Launch Instance\nEnter the name Edge Gateway\nSelect the Ubuntu Quickstart\nSelect the Instance Type \xe2\x80\x93 t2.medium\nUse an existing Key pair or Create a new key pair and click Download key pair. Your browser will save the .pem file. Keep that safe!\nClick the Launch Instance button\nAfter a couple of minutes your Amazon EC2 instance will be running.\nConnect to your Instance using an SSH Client by following these steps here\nCopy and run the command below to install node red\nbash <(curl -sL https://raw.githubusercontent.com/node-red/linux-installers/master/deb/update-nodejs-and-nodered) --confirm-root --confirm-install --skip-pi\nRun these commands to install the OPC UA server node\nsudo systemctl start nodered.service\n sudo npm install --prefix ~/.node-red node-red-contrib-opcua-server &>/dev/null\n sudo systemctl restart nodered.service\n  Now run these final commands to install and run the OPC UA server simulation\ncurl -O https://iot-blog-files.s3.amazonaws.com/edge-to-twin/opcua_sim.json\n curl -vX POST http://127.0.0.1:1880/flows -d @opcua_sim.json --header ""Content-Type: application/json""\nServer should not be running and can proceed to the next step.\nSetup AWS IoT SiteWise Collector on AWS IoT Greengrass\nNext you will setup and install AWS IoT SiteWise Gateway. This gateway serves as the intermediary between your industrial assets and AWS IoT SiteWise. You can deploy the AWS IoT SiteWise gateway software on any supported platform for AWS IoT Greengrass.\nCreate an AWS IoT SiteWise Gateway\nNavigate to AWS IoT SiteWise\nNavigate to Edge->Gateways on the left and click on Create gateway and select Greengrass v2\nSelect Default Setup and hit Next until you reach add data sources\nClick Add data source\nConfigure the OPC Server as seen below and use opc.tcp://localhost:54845 for the local endpoint of Node Red\nHit Add and then Next\nIn the section, Review and generate an installer, change the Gateway device OS to Ubuntu and click on Generate\nInstall the AWS IoT SiteWise Gateway with AWS IoT Greengrass on the Amazon EC2 instance\nCopy the installer script to the Amazon EC2 instance. You may use the scp command like below:scp -i ""blog.pem"" Gateway-xxxxxxxx.deploy.sh ubuntu@ec2-xx-xxx-x-xx.compute-1.amazonaws.com:\nRun the shell script that was copiedsudo bash ~/Gateway-xxxxxxxx.sh\nYour AWS IoT SiteWise Gateway should be in sync within a couple minutes and collecting data. The image below shows data streams captured if the AWS IoT SiteWise gateway is in sync. If you do not see this, you can force the synchronization. To do so, edit the publisher configuration in your AWS SiteWise Gateway in the console, change the Publishing Order to Newest first to force a change. This will initiate a sync for the Publisher. If you still do not see streams, you may not have disassociated data ingestion enabled. To enable, go to Settings in the IoT SiteWise console, choose Data Ingestion, and then enable Disassociated data ingestion. You can verify that data streams are ingested in the AWS IoT SiteWise Console to proceed.\nSetup AWS IoT SiteWise Model and Asset\nYou have completed the configuration of the Edge node and are now collecting telemetry data from an OPC UA server. This is streamed to AWS IoT SiteWise in the cloud. Next, you will create models and assets and associate these unclaimed streams of data.\nCreate an Asset Model\nNavigate to AWS IoT SiteWise in the AWS Console.\nNavigate to Build->Models\nClick Create model\nFor the Name, type Mixer Model\nAdd 3 measurements:\nName: rpm, Unit: RPM, Data Type: Double\nName: temperature, Unit: Fahrenheit, Data Type: Double\nName: state, Unit: Leave_Blank, Data Type: String\nClick Create Model\nCreate an Asset from the Model and assign data streams\nAfter the model is created, you will see a section for Assets at the bottom of the Mixer Model. Click Create asset\nSelect the Mixer Model template and provide a name, Mixer_A\nReturn to the Data Streams section in AWS IoT SiteWise, select the 3 data streams and click on Manage Data Streams\nChoose each Measurement on the left and select the corresponding measurement on the right. Then click Choose.\nClick Update once complete\nNow return to your asset Mixer_A. You can verify that your asset is receiving data by checking the Latest value column\nBuilding your Twin\nNow that you have connected to an asset at the Edge and streamed this data into your AWS IoT SiteWise data source, you can now use AWS IoT TwinMaker to build your twin. Keep in mind, AWS IoT SiteWise is not a requirement for AWS IoT TwinMaker. Sources of telemetry data may come from other systems. For this blog, you are specifically handling telemetry data but an industrial twin is expected to be comprised of several data sources.\nCreate a workspace\nNavigate to AWS IoT TwinMaker\nClick Create workspace\nProvide a name MixerWorkspace\nSelect to create a new S3 bucket\nSelect to Auto-generate a new role, then click Skip to review and create\nClick Create Workspace\nCreate an Entity\nNavigate to Workspaces \xe2\x86\x92 Entities\nClick Create Entity\nProvide the name Mixers\nClick on the entity your created and create a child entity\nProvide the name Mixer_A. When building out a twin for a facility, you may create a hierarchy that is representative of your physical layout or process.\nSelect the Mixer_A entity and click to Add component\nProvide the name SiteWise and select the type com.amazon.iotsitewise.connector\nOnce the type is selected, you will see that you can select the asset model and asset that you configured in AWS IoT SiteWise. Just select the Mixer Model and Mixer_A asset. That\xe2\x80\x99s it! The data is now linked.\nScroll down and click Add component. See expected results below\nAdd a Resource\nDownload this CAD model from our Cookie Factory demo for a mixer.\nNavigate to Workspace\xe2\x86\x92Resource library\nClick Add resource\nChose the GLB model file you downloaded. You will use this later when creating the Scene for this mixer.\nAdd a Scene\nNavigate to Workspace\xe2\x86\x92Scenes\nProvide a Scene name Mixers and create the scene\nWithin the scene editor, click on plus \xe2\x80\x9c+\xe2\x80\x9d sign to add a 3D model\nRename the model from CookieFactoryMixer to Mixer_A\nClick the plus sign again and select Add light. Feel free to adjust angle of the light and intensity\nSelect Mixer_A from the left and click the plus sign to select Add model shader\nOn the right, select Mixer_A for the entity_id, SiteWise for the ComponentName, State for the PropertyName, and sampleTimeSeriesColorRule for the Rule Id\nSelect the Rules tab\nSelect the existing rule sampleTimeSeriesColorRule\nChange the 3 expressions as seen below and adjust colors to your preference. Proceed to visualize this scene in Grafana\nVisualize your Twin in Grafana\nAWS IoT TwinMaker supports Grafana integration through an application plugin. The AWS IoT TwinMaker plugin provides custom panels, dashboard templates, and a data source to connect to your digital twin.\nSetup Managed Grafana Workspace\nNavigate to Amazon Managed Grafana\nComplete the Getting Started guide to setup a workspace with SSO authentication\nUse this inline policy (inline_policy.json) to provide Grafana with permission to call APIs for AWS IoT SiteWise, AWS IoT TwinMaker, and Amazon S3. Replace the {account id} with your AWS account id and the Universally Unique Identifier (UUID) for both the Asset Model and Asset in Sitewise\nSetup AWS IoT TwinMaker Data source in Grafana\nClick on the workspace Grafana URL\nIn Grafana, setup your data source\nClick Add data source\nSelect AWS IoT TwinMaker\nSelect the MixerWorkspace click Save & test\nCreate an AWS IoT TwinMaker dashboard\nCreate a new dashboard in Grafana.\nIn a new Panel, select AWS IoT TwinMaker Scene Viewer\nSelect the Scene Mixers\nIn order to animate the shading of colors configured in the scene rules, you will need to add a query for the mixer state property value history as shown below. Animations will not work without this step\nThat\xe2\x80\x99s it! Feel free to create other panels to view data trends\nNote: In Grafana, you can take advantage of creating Variables in order to allow the dynamic switching between Entities you select within the dashboard.\nClean Up\nBe sure to clean up the work in this blog to avoid charges. Delete the following resources when finished in this order\nAWS Managed Grafana Workspace\nAWS IoT TwinMaker Scene, Resources, Entities, and Workspace\nAWS IoT SiteWise Gateway, Asset, and Asset Model\nAWS IoT Greengrass Core device under menu Greengrass\xe2\x86\x92Core devices\nCore Device Thing in AWS IoT Core under the menu Manage->Things\nTerminate the Amazon EC2 Instance\n'"
87,Grow your knowledge: a guide to IoT Solutions World Congress 2022,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/grow-your-knowledge-a-guide-to-iot-solutions-world-congress-2022/,"b'Overview\nWelcome to your guide for IoT Solutions World Congress, an event showcasing the game-changing solutions and technologies disrupting and transforming industries. Follow the digital conversations via the hashtag, #IOTSWC22.\nIoT Solutions World Congress will take place May 10-12 in Barcelona, Spain. Join AWS on-site in Barcelona for IoT leadership sessions and IoT device demonstrations to explore how industries are unlocking IoT data and accelerating business growth. IoT Solutions World Congress brings together AWS Partners and industry decision makers to learn and hear from AWS and other industry professionals on topics including digital twins, unlocking smart building insights, women and diversity in technology, leveraging the cloud for logistics, and effectively using industrial IoT data.\nAWS will showcase the AWS Partner Solutions Demonstration Wall at the AWS IoT Lounge located in Hall 4 | C381. This demo wall will include over two dozen of the latest AWS partner devices such as gateways/routers, starter kits, industrial PC, RF modules, Programmable Logic Controllers (PLC), sensors, and reference design from AWS partners like Advantech, Banner, Beckhoff, CloudRail, Dragino, Espressif Systems, IDEC Corporation, Infineon, Laird, miromico, Multi-Tech Systems Inc., OnLogic, Opto22, Pressac, Shoreline, Siemens, Softing Industrial Automation GmbH, STMicroelectronics, Tektelic, u-blox, Wago, and Yokogawa. Check out the latest AWS partner solutions to learn more about how you can scale your business using AWS IoT.\nMultiple AWS representatives will also be on site to host customer meetings in Hall 2 | Room B11. Are you looking to have a deeper AWS IoT discussion? Request a meeting with AWS here.\nSessions\nReview upcoming AWS sessions to help plan your visit to IoT Solutions World Congress. Please note days and times are subject to change. Refer to the IoT Solutions World Congress agenda for latest information.\nUnlock smart building insights to achieve sustainability goals with big data analytics\nPresented by: David Felker, Head of Solutions for Engineering, Construction, and Real Estate Solutions, AWS and Vera Groetzner, Software Product Manager for Siemens Smart Infrastructure, Siemens\nMay 10 | 11:40 AM \xe2\x80\x93 12:10 PM | Room 2\nReducing operating expenses, achieving sustainability goals, and improving the occupant experience are top of mind for building owners and operators. The challenge is that siloed building data can make it hard to gain insights across assets and take action to optimize building performance. In this session, learn how Siemens and AWS IoT have collaborated to help customers unlock disparate data sets so they can reliably track and analyze energy consumption to drive better outcomes for the business, environment, and building occupants.\nAWS Keynote address: Turnkey IoT: Strategies that scale and transform your enterprise\nPresented by: Yasser Alsaied, VP of IoT, AWS\nMay 11 | 10:00 AM \xe2\x80\x93 10:30 AM | Room: Auditorium\nBillions of IoT devices will connect with the cloud over the next five years. With IoT continuing to converge with AI, robotics, and 5G, enterprises are tackling big problems in infrastructure, production, and the environment using cloud technologies. But how do you get started on this cloud journey? In this session, through demos and customer stories, Yasser Alsaied, VP of IoT at AWS, introduces audiences to the new IoT and robotics technologies that are transforming building management, operations, and manufacturing. Dive deep into how customers like Volkswagen, Carrier, and Yara are increasing plant efficiency, automating processes, and acting upon real-time insights at scale.\nDigital eye in IoT: How CattleEye uses the cloud to improve animal wellness\nPresented by: Karen Hildebrand, Worldwide Tech Leader for Agriculture, AWS and Terry Canning, Chief Executive Officer, CattleEye\nMay 11 | 11:50 AM \xe2\x80\x93 12:20 PM | Room: Auditorium\nDairy cattle health, welfare, and production requires a scale that can exceed human capacity, which is where CattleEye comes in. The CattleEye team produces scores, including body condition and mobility scores, that farmers can use to understand the health of their herd. Early adopters of CattleEye technology have seen decreases in lameness levels from 30% to about 10% of the herd. Milk producers on average see a savings of \xc2\xa3350 each year through proactive treatments. In this session, learn how CattleEye uses the cloud, explore the scale of computer vision at the edge, and discover how to rapidly build IoT at the edge and in the cloud.\nVolkswagen Group takes production and logistics to the cloud\nPresented by: Alan Southall, Group BPM of Business Technology Platforms, AWS and Marc Geckeler, Group BPM of Business Technology Platforms, Volkswagen Group and Dirk Voigt, Head of Digital Production Platform, Volkswagen Group\nMay 11 | 3:50 PM \xe2\x80\x93 4:20 PM | Room CC4.2\nAWS and Volkswagen Group embarked on a multi-year collaboration to pioneer the creation of the Industrial Cloud that is reinventing automotive manufacturing, supply chain, and logistics for Volkswagen and its brands. By using IoT, machine learning, and sophisticated analytics to unlock data from machines and systems across all of their plants, Volkswagen continues to strengthen their production and ability to build cars more efficiently, for the benefit of their customers and the global environment. Through sustainable innovation across people, processes, and technology, learn how Volkswagen has been able to unlock new insights and accelerate business value through new digital solutions that have further increased plant efficiency and uptime, improved production flexibility, and increased vehicle quality.\nAgriculture company plants seeds for IIoT data insights with Emerson & AWS\nPresented by: Nishant Saini, Senior Partner Solutions Architect for Industrial Software, AWS and Martijn van der Meer, Business Architect, Emerson\nMay 12 | 11:35 AM \xe2\x80\x93 12:05 PM | Room CC4.2\nAn agriculture company\xe2\x80\x99s operational data was spread out across plant automation systems, plant data historians, laboratory systems, IoT sensors, and more. They wanted a way to release data from facility equipment and use it to improve throughput and productivity, predict equipment failures, and improve analytical insights. Learn about the short- and long-term value of centralizing, managing, and contextualizing operational data for advanced analytics use cases.\nAccelerating business outcomes with scalable digital twins\nPresented by: Bryan O\xe2\x80\x99Flaherty Wills, Principal Worldwide Go-To-Market Specialist for IoT, AWS and Dan Levine, Senior Director IoT, Cloud, and Software Engineering, Carrier\nStarting May 17 | Available on demand\nDigital twins represent an exciting technology that businesses are increasingly adopting to make better operational and strategic decisions in industries such as smart buildings, manufacturing, healthcare, life sciences, energy, power and utilities, and other industrial operations. Carrier is pushing to drive more innovation and connectivity to make buildings and the cold chain more sustainable, efficient, and comfortable. In this session, learn how AWS and Carrier are empowering customers to use digital twins alongside advanced machine learning and data analytics to decrease service costs, optimize maintenance schedules, and increase the reliability, efficiency, and profitability of their equipment.\nAsset performance management is much more than predictive maintenance\nPresented by: Praveen Rao, Principal Worldwide Go-To-Market Specialist for IoT, AWS and David Huber, APM Advisory Consultant, Hitachi Vantara\nStarting May 17 | Available on demand\nBeyond failure and diagnostic capabilities, smart manufacturing solutions provide greater insights into the remaining useful life of your assets, what-if analysis, identification of precursor events, and more. Remaining useful life and what-if analysis help to optimize decision-making in the moment and understand the root cause of a failure, both of which help to avoid failures in the future. In this session, AWS and Hitachi showcase existing case studies and discuss how their common customers achieve success and answer questions such as whether they\xe2\x80\x99re prepared to make it to the next planned outage. Additionally, explore common IoT deployment mistakes and learn best practices to avoid them.\nSummary\nEvent attendees can explore AWS IoT services and solutions and hear how AWS customers connect and manage billions of devices. If your business collects, stores, and analyzes IoT data for industrial, consumer, commercial, and automotive workloads \xe2\x80\x93 make sure you visit our IoT Solutions World Congress landing page to learn more. Follow the digital conversations via the hashtag, #IOTSWC22.'"
88,Creating and deploying a custom AWS IoT SiteWise MQTT connector with AWS IoT Greengrass,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/04/28/architecture-diagram.jpg,https://aws.amazon.com/blogs/iot/creating-and-deploying-a-custom-aws-iot-sitewise-mqtt-connector-with-aws-iot-greengrass/,"b'Efficiency, uptime, and the minimizing of costs are three of the most important pillars of a successful industrial operation. Understanding the operating state of equipment, overall efficiency of a piece of equipment, or a whole production line \xe2\x80\x93 as well as how these affect costs and revenue across multiple sites \xe2\x80\x93 requires a complete view of your operational data.\nAWS IoT SiteWise is a managed service providing the ability to collect, organize, and analyze industrial equipment data from edge to cloud. AWS SiteWise Edge is the edge component for reading data from industrial protocols, publishing to AWS IoT SiteWise in the cloud, storing and forwarding data in cases of disconnection with the cloud, and calculating transforms and metrics at the edge by using the optional data processing pack.\nAWS IoT Greengrass is a managed open source edge runtime and cloud service used as the foundation layer for AWS IoT SiteWise Edge enabled devices. MQTT (MQ Telemetry Transport) is a commonly used industrial communication protocol that follows the pub-sub pattern. MQTT clients like Paho python client or AWS IoT MQTT clients send messages and/or subscribe to topics to receive messages from MQTT servers (also called brokers). These servers in turn manage the connections, relaying of data, and subscriptions of the different clients.\nData flow between MQTT clients and the AWS IoT SiteWise service is enabled through use of an AWS IoT Greengrass connector. You can use this capability to integrate your industrial connectivity middleware and secondary sensors with AWS IoT SiteWise Edge to process data locally and then route it to the cloud.\nIn this post we provide an overview of how to configure and use the custom-built AWS IoT SiteWise MQTT connector on the Greengrass v2 edge runtime service to enable data flow and processing from equipment from the edge to the cloud.\nSolution overview\nThe solution deployed in this blog post will complete the following steps in your AWS account:\nFigure 1 following illustrates the deployed solution.\nArchitecture 1\nPrerequisites and assumptions\nTo follow the steps outlined in this blog post, you need the following:\nAn AWS account that provides access to AWS services.\nAWS CDK Toolkit (cdk command) setup on your local computer to setup the AWS IoT SiteWise asset models and assets. For more information on how to setup, check here.\nThe templates and code are intended to work in the US East-1 (N. Virginia) Region only.\nStep 1: Create sample AWS IoT SiteWise asset models and assets in your AWS account\nIn this step, we will setup the AWS IoT SiteWise asset models and assets. To do so, we will use an AWS CDK script that will generate asset models and assets in your AWS IoT SiteWise console.\nYou can use these downloadable scripts to setup the assets and asset models. Once you download this repo onto your local computer/mac, run the below commands.\nNote: Make sure you installed aws_cdk in your python environment before running the below commands. Otherwise, you will get \xe2\x80\x9cNo module named \xe2\x80\x98aws_cdk\xe2\x80\x99.\ngit clone git@github.com:aws-samples/sitewise-mqtt-custom-connector.git\ncd <Downloaded location>\ncd sitewise-mqtt-custom-connector/sitewise-assets-creation/\ncdk bootstrap aws://<YOUR_AWS_ACCOUNT_NUMBER>/<AWS_REGION> --profile <AWS_CLI_PROFILE_NAME>\ncdk deploy sitewise-assets-creation --profile <AWS_CLI_PROFILE_NAME>\nBash\nOnce the above CDK script execution is completed, it will create two AWS IoT SiteWise asset models named 1) generator-model and 2) hvac-model. You can check these models by logging into the AWS IoT SiteWise console in your AWS account.\nThis script also creates 100 assets of each model. You can check these assets by logging into AWS IoT SiteWise console and navigating into the \xe2\x80\x9cAssets\xe2\x80\x9d section.\nStep 2: Setup AWS IoT SiteWise gateways\nAWS IoT SiteWise gateways serve as the intermediary between your clients like Paho python client and AWS IoT SiteWise. It runs on AWS IoT Greengrass V2 and supports data collection and processing on premises. To install gateway software, the device must meet the requirements that are specified in this AWS documentation. Creating and configuring an AWS IoT SiteWise gateway has two steps. The first one is to configure gateway in the AWS IoT SiteWise console and the second step is run the installation script on the actual gateway device.\na) Create and configure a gateway:\nTo configure a gateway, navigate to the AWS IoT SiteWise console. In the navigation page, choose Gateways and click on create gateway button. Enter a name for Gateway or choose the generated name and select \xe2\x80\x9cDefault setup\xe2\x80\x9d for Greengrass core device. You can choose the generated name for Core device name or provide a name to core device. After providing the values, click on the Next button.\nIn the Configure edge capabilities page, select Data processing pack to enable the gateway device to process the data the edge. The data collection pack is enabled by default. Do not select the Edge LDAP configuration. Click on the Next button.\nIn the Add data sources page, click on the Next button.\nIn the Review and generate an installer page, select ubuntu operating system under Gateway device OS. Click on the Generate button and click on the Acknowledge button.\nYou will be prompted to save the installation script on your local mac or Windows machine (e.g., Laptop, desktop). Save the script file in a known location. We need to copy the installation script to your gateway device in the next step.\nb) Execute the installation script on your AWS IoT SiteWise gateway device:\nFor demonstration purpose, we will use an Amazon EC2 instance as our AWS IoT SiteWise gateway device. In your AWS web console, go to the Amazon EC2 section and create an Amazon EC2 instance. For this demo, we have selected m5.xlarge instance type with Ubuntu 18.04 as the operating system. The recommended disk space for the AWS IoT SiteWise gateway device is at least 256 GB.\nMake sure you have Python3.7 and pip3 installed on your local machine.\n> sudo apt update && sudo apt install software-properties-common && sudo add-apt-repository ppa:deadsnakes/ppa\n> sudo apt install python3.7\n> sudo update-alternatives --install /usr/bin/python python3 /usr/bin/python3.7 1\n> sudo update-alternatives --install /usr/bin/python python3 /usr/bin/python3.6 2\n> sudo update-alternatives --config python3\nChoose the selection number that uses python 3.7.\n> sudo rm /usr/bin/python3 && sudo ln -s /usr/bin/python3.7 /usr/bin/python3\nBash\n> sudo apt-get install python3-pip\nBash\nCopy the installation script that was generated by the SiteWise gateway to run on Amazon EC2 instance (your gateway device). Once the script is copied, provide execute permission to it and run the installer.\n> chmod +x path-to-installer.sh\n> sudo ./path-to-installer.sh\nBash\nIt will prompt you if any of the dependencies are missing. When prompted, select \xe2\x80\x9cyes\xe2\x80\x9d with the installation. This script will install the necessary dependencies, setup the Greengrass software and configures the AWS IoT SiteWise gateway.\nOnce the installer runs successfully, login to AWS IoT Console and go to Core devices. You will see your Greengrass core device in Healthy status.\nStep 3: Configure asset models for the edge\nFollow the below steps to configure an asset model for the edge. Our asset models creation script in Step 1 created two asset models for you with the names: a) generator-model and b) hvac-model.\nNavigate to the AWS IoT Sitewise console.\nChoose Models in the Build section. You will see \xe2\x80\x9cgenerator-model\xe2\x80\x9d and \xe2\x80\x9chvac-model\xe2\x80\x9d. We will enable asset models for both of these models.\nFirst select \xe2\x80\x9cgenerator-model\xe2\x80\x9d and click on \xe2\x80\x9cConfigure for edge\xe2\x80\x9d button.\nUnder \xe2\x80\x9cChoose the edge configuration for this asset model\xe2\x80\x9d, select \xe2\x80\x9cNo edge configuration\xe2\x80\x9d option. Since we do not have any metrics or transformations defined for our asset models, nothing will be computed at the edge. If you have metrics or transformations that needs to be computed at the edge, select either \xe2\x80\x9cCompute all properties at the edge\xe2\x80\x9d or \xe2\x80\x9cCustom edge configurations\xe2\x80\x9d options.\nSince we did not configure any \xe2\x80\x9cmetrics\xe2\x80\x9d or \xe2\x80\x9ctransformations\xe2\x80\x9d for this asset models, nothing will show up under the \xe2\x80\x9cConfigure metrics\xe2\x80\x9d and \xe2\x80\x9cConfigure transforms\xe2\x80\x9d section.\nUnder the \xe2\x80\x9cConfigure measurements\xe2\x80\x9d section, by default the options will be grayed. These measurements will be sent to cloud as well.\nClick on Save button.Repeat the same above steps for the \xe2\x80\x9chvac-model\xe2\x80\x9d as well.\nStep 4: Provision a publisher device to publish the messages to the AWS IoT Greengrass MQTT broker\nAs per the architecture diagram shown previously, we will assume that an external device (publisher) will be publishing the MQTT messages to an AWS IoT Greengrass core device\xe2\x80\x99s MQTT broker. The external device needs to use cloud discovery to find the AWS IoT Greengrass core and we need to configure the publisher\xe2\x80\x99s MQTT client to talk to AWS IoT Greengrass core.\nIn this blog post, let\xe2\x80\x99s use another Amazon EC2 instance as our publishing device. Launch a second Amazon EC2 instance as described in this document. I have selected t3.large instance type with Ubuntu 18.04 as the operating system.\nLet\xe2\x80\x99s register the publisher device and configure the certificates and keys to allow it to connect to AWS IoT Greengrass.\nIn the AWS IoT Console, choose Manage, and click on Things.\nClick on the Create things button.\nSelect Create single thing option and click on Next.\nIn the Specify thing properties page, provide a name to Thing name. Here in this case, I am using: Publisher_Device_SWGateway.\nNote: We will use this device name \xe2\x80\x9cPublisher_Device_SWGateway\xe2\x80\x9d in the below steps. Recommend to use the same name for the purposes of this demo.\nIn the Device Shadow section, select No shadow option and click on Next button.\nOn the Configure device certificate page, choose Auto-generate a new certificate.\nOn the Attach policies to certificate page, choose the AWS IoT policy to review and update. You can use the same IoT Policy that was attached to the Core device or you can create new policy with the below policy document.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Connect"",\n        ""iot:Publish"",\n        ""iot:Subscribe"",\n        ""iot:Receive"",\n        ""greengrass:*""\n      ],\n      ""Resource"": ""*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:GetThingShadow"",\n        ""iot:UpdateThingShadow"",\n        ""iot:DeleteThingShadow""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:region:account-id:thing/*""\n      ]\n    }\n  ]\n}\nJSON\nIn this case, select the same IoT policy that was used by the Greengrass core device. Click on \xe2\x80\x9cCreate thing\xe2\x80\x9d button.\nOn the \xe2\x80\x9cDownload certificates and keys\xe2\x80\x9d page, click on the Download buttons to download Device certificate, Public key file, Private key file and Amazon Root CA 1 certificates and click on Done button.\nOnce you download these files on to your local machine, copy the files to your publisher device (the Amazon EC2 instance that was created at the beginning of the Step 4).\n> cd <Downloaded location>\n> scp -r -p -i <pem-file-location.pem> <hash>-certificate.pem.crt ubuntu@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:/tmp/\n> scp -r -p -i <pem-file-location.pem> <hash>-private.pem.key ubuntu@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:/tmp/\n> scp -r -p -i <pem-file-location.pem> <hash>-public.pem.key ubuntu@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:/tmp/\n> scp -r -p -i <pem-file-location.pem> AmazonRootCA1.pem ubuntu@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:/tmp/\nBash\nOn the Amazon EC2 instance, create the below directory and copy the certificate files into that location.\n> mkdir -p ~/iot-certs/\n> cd /tmp\n> cp -r -p /tmp/<hash>-* ~/iot-certs/\n> cp -r -p /tmp/AmazonRootCA1.pem ~/iot-certs/\nBash\nEnable client device support\nTo enable a client/publisher device to connect to an AWS IoT Greengrass core device, the client device needs to retrieve the core device\xe2\x80\x99s IP addresses and certificates. Follow the steps described here to enable the client device support.\nNote: For \xe2\x80\x9caws.greengrass.clientdevices.Auth\xe2\x80\x9d component, use the below \xe2\x80\x9cConfiguration to merge\xe2\x80\x9d.\n{\n   ""deviceGroups"":{\n      ""formatVersion"":""2021-03-05"",\n      ""definitions"":{\n         ""MyDeviceGroup"":{\n            ""selectionRule"":""thingName: Publisher_Device_SWGateway*"",\n            ""policyName"":""MyClientDevicePolicy""\n         }\n      },\n      ""policies"":{\n         ""MyClientDevicePolicy"":{\n            ""AllowConnect"":{\n               ""statementDescription"":""Allow client devices to connect."",\n               ""operations"":[\n                  ""mqtt:connect""\n               ],\n               ""resources"":[\n                  ""*""\n               ]\n            },\n            ""AllowPublish"":{\n               ""statementDescription"":""Allow client devices to publish to all topics."",\n               ""operations"":[\n                  ""mqtt:publish""\n               ],\n               ""resources"":[\n                  ""*""\n               ]\n            },\n            ""AllowSubscribe"":{\n               ""statementDescription"":""Allow client devices to subscribe to all topics."",\n               ""operations"":[\n                  ""mqtt:subscribe""\n               ],\n               ""resources"":[\n                  ""*""\n               ]\n            }\n         }\n      }\n   }\n}\nJSON\nMake sure you provide the correct thingname. This blog uses \xe2\x80\x9cPublisher_Device_SWGateway\xe2\x80\x9d as device thing name. Use \xe2\x80\x9c*\xe2\x80\x9d for the wild card pattern at the end of the thingName.\nFor \xe2\x80\x9caws.greengrass.clientdevices.mqtt.Bridge\xe2\x80\x9d component, use the below \xe2\x80\x9cConfiguration to merge\xe2\x80\x9d. Make sure the topic name is \xe2\x80\x9cclients/+/mqttiot/sitewise\xe2\x80\x9d.\n{\n   ""mqttTopicMapping"":{\n      ""SiteWiseMQTTIotCoreMapping"":{\n         ""topic"":""clients/+/mqttiot/sitewise"",\n         ""source"":""LocalMqtt"",\n         ""target"":""IotCore""\n      },\n      ""localGGPubsubMapping"":{\n         ""topic"":""clients/+/mqttiot/sitewise"",\n         ""source"":""LocalMqtt"",\n         ""target"":""Pubsub""\n      }\n   }\n}\nJSON\nInstall the AWS IOT SDK v2 for Python on the publisher device and get the basicDiscovery.py sample function to get the Greengrass Group CA.\nMake sure you have Python3.7 and pip3 installed on your machine.\n> sudo apt update && sudo apt install software-properties-common && sudo add-apt-repository ppa:deadsnakes/ppa\n> sudo apt install python3.7\n> sudo update-alternatives --install /usr/bin/python python3 /usr/bin/python3.7 1\n> sudo update-alternatives --install /usr/bin/python python3 /usr/bin/python3.6 2\n> sudo update-alternatives --config python3\nChoose the selection number that uses python 3.7.\n> sudo rm /usr/bin/python3 && sudo ln -s /usr/bin/python3.7 /usr/bin/python3\nBash\n> sudo apt-get install python3-pip\nBash\nDownload the AWS IoT Device SDK v2 for Python to an appropriate location on your computer.\n> Login as root(sudo) user on the Publisher EC2 instance.\n> sudo su - \n> cd ~\n> git clone https://github.com/aws/aws-iot-device-sdk-python-v2.git\n> python3 -m pip install ./aws-iot-device-sdk-python-v2\nBash\nStep 5: Create an AWS IoT Greengrass component that collects the data stream from Greengrass core\xe2\x80\x99s MQTT broker and sends to AWS IoT Sitewise Edge\nOnce the data from industrial equipment sensors are ingested through MQTT client into the AWS IoT Greengrass MQTT broker, the custom AWS IoT Greengrass component writes the data to AWS IoT Greengrass stream SiteWise_Edge_Stream. The AWS IoT SiteWise edge processor continuously pulls data out of SiteWise_Edge_Stream and processes it. This service also writes this data to an AWS IoT Greengrass stream named SiteWise_Stream depending the configuration setting. The AWS IoT SiteWise publisher component continuously reads the data out of SiteWise_Stream and sends that data to AWS IoT SiteWise service in the cloud.\nLet\xe2\x80\x99s setup and deploy the AWS IoT Greengrass component that collects the messages from the AWS IoT Greengrass MQTT broker and sends to AWS IoT Sitewise in the cloud.\nThe code for the component can be found here.\nDownload the git repo code on to your local mac or windows machine. Make sure AWS CLI is setup and configured with your AWS account credentials so that you can run the \xe2\x80\x9caws\xe2\x80\x9d commands from the terminal/command prompt.\nRun the below steps on your mac/pc. The ddeploy-mqtt-connector.sh script will create an artifact compressed file, create an Amazon S3 bucket with prefix \xe2\x80\x9cggv2-mqtt-to-sitewise-component-\xe2\x80\x9d in your AWS account to store the artifacts, and prepare the deployment configuration file and the recipe files. Finally, it will deploy the component to your AWS IoT Greengrass core device.This script takes two arguments.\nFirst argument is your IoT Core name where your AWS IoT SiteWise gateway is running.\nSecond argument is your AWS Account number.\n> cd ~\n> git clone git@github.com:aws-samples/sitewise-mqtt-custom-connector.git\n> cd sitewise-mqtt-custom-connector/mqtt-to-sitewise-connector-component/\nBash\nExport AWS Credentials\n> export AWS_ACCESS_KEY_ID=""XXXXXXXXXXXXXXXXXXX""\n> export AWS_SECRET_ACCESS_KEY=""XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX""\nBash\nRun \xe2\x80\x9cddeploy-mqtt-connector.sh\xe2\x80\x9d script.\n> bash ./ddeploy-mqtt-connector.sh <IOT_CORE_NAME> <AWS_ACCOUNT_NUMBER>\nBash\nOnce the deployment is successful, you can login to the AWS IoT Greengrass core device and can check the component log files.\n> sudo su \xe2\x80\x93 \n> cd /greengrass/v2/logs\n> tail -f community.greengrass.MqttToSitewise.log\nBash\nYou will see the below messages in the log file.\n2021-08-25T20:28:50.793Z [INFO] (Copier) community.greengrass.MqttToSitewise: stdout. 2021-08-25 20:28:50,793 - dev - INFO - Total processed messages were : 0. {scriptName=services.community.greengrass.MqttToSitewise.lifecycle.Run, serviceName=community.greengrass.MqttToSitewise, currentState=RUNNING}\nStep 6: Configure the gateway credentials\nTo access the data or dashboards from the gateway, you need to access the gateway as described in this AWS documentation. In this blog post, we will use Linux credentials to access the gateway.\nRun the below commands on the AWS IoT SiteWise gateway device. Here, we are creating a Linux user with the name \xe2\x80\x9csweops1\xe2\x80\x9d.\n> sudo groupadd --system SWE_ADMIN_GROUP\n> sudo useradd sweops1\n> sudo passwd sweops1\nBash\nSupply the password\n> sudo usermod -a -G SWE_ADMIN_GROUP sweops1\nBash\nStep 7: Monitor AWS IoT SiteWise data at the edge.\nTo access the AWS IoT SiteWise Monitor at the edge, we will download and install the \xe2\x80\x9cOpsHub for AWS IoT Sitewise Application\xe2\x80\x9d on a Windows-based EC2 instance. In your AWS web console, go to the EC2 section and create an Amazon EC2 instance. For this demo, I have selected \xe2\x80\x9cMicrosoft Windows Server 2019 Base\xe2\x80\x9d AMI with an m5.xlarge instance type.\nOnce the Windows EC2 instance is created, use Remote Desktop Protocol (RDP) program to connect to the Amazon Windows EC2 instance. Download and install OpsHub for AWS IoT Sitewise Application on this Amazon Windows EC2 instance.\nNote: Make sure port 443 and 8443 ports are open to the Sitewise Gateway EC2 instance.\nOnce you open the OpsHub for AWS IoT Sitewise, it will show the below screen. This is your local gateway application.\nProvide \xe2\x80\x9cIP address/Host name\xe2\x80\x9d of the Gateway device/Greengrass core device. You can get the IP address of the gateway device by running the \xe2\x80\x9chostname -i\xe2\x80\x9d command.\nSelect Linux as Authentication method.\nProvide User name that was created above. In this case we have created the user \xe2\x80\x9csewops1\xe2\x80\x9d.\nProvide password for the user.\nSelect Sign In.\nOnce you connect to the OpsHub, you will see the following dashboard.\nStep 8: Run the test data simulator program to push data into the AWS IoT Greengrass V2 MQTT broker from the publisher host\nDownload a test data generator that will generate random values for the assets that were created in Step 1. It also sends the generated values to a topic (clients/+/mqttiot/sitewise) in the AWS IoT Greengrass MQTT broker that comes with Greengrass version 2.\nLogin to the second EC2 instance (publisher) that was created at the beginning of Step 4 and clone the repository and run the below commands.> cd ~\n> git clone git@github.com:aws-samples/sitewise-mqtt-custom-connector.git\n> cd sitewise-mqtt-custom-connector/mqtt-client-test/\n> cd config/\nBash\nNote: Change the values in conf.cfg file with your certs files that we copied in the ~/iot-certs folder.\nChange the below values in the conf.cfg file.\nNumer Property Change to\n1 CERTS_PATH This the cert file\xe2\x80\x99s location that you have created. If you follow the instructions in the blog the value will be /home/ubuntu/iot-certs\n2 host This will be your Greengrass core device host IP address. In this case, you can get the IP address of the Greengrass core device by logging into the 1st EC2 instance that was created in Step 2.\nRun the command: hostname -i to get the IP address of your Greengrass core device.\n3 root_ca_file This will be your root ca file. In our case it is AmazonRootCA1.pem. Make sure you have named the root ca file with this name, otherwise change this value as needed.o\n4 certificate_file This will be your thing\xe2\x80\x99s/device\xe2\x80\x99s certificate file. Replace the with your cert\xe2\x80\x99s hash value. This is also in your ~/iot-certs folder. The value will be: hash-certificate.pem.crt\n5 privatekey_file This will be your thing\xe2\x80\x99s/device\xe2\x80\x99s private key file. Replace the with your cert\xe2\x80\x99s hash value. This is also in your ~/iot-certs folder. The value will be: hash-private.pem.key\n6 thingName This will be your publisher device\xe2\x80\x99s thing name. In this case, our thing name is: Publisher_Device_SWGateway.\n7 topic This will be the topic name that you have set during the Enable Client device support in Step #3. In our case it was set to \xe2\x80\x9cclients/+/mqttiot/sitewise\xe2\x80\x9d. So you can replace \xe2\x80\x9c+\xe2\x80\x9d with \xe2\x80\x9cany value\xe2\x80\x9d. In this case, we will use: \xe2\x80\x9cclients/dev1/mqttiot/sitewise\xe2\x80\x9d.\n8 Region By default, this blog assumes all the previous assets were created in us-east-1 region. So the value will be \xe2\x80\x9cus-east-1\xe2\x80\x9d.\nExecute the test data generator program so that it will generate some data set and will send to the Greengrass MQTT broker. After updating the configuration values in the previous step, run the below commands.Make sure, the publisher/client device and AWS IoT Greengrass core device are in the same network. The publisher/client device needs to connect to Greengrass core device on port number 8883. If your client and Greengrass core devices are EC2 instances, then allow port 8883 in security groups.\n> cd ~/sitewise-mqtt/mqtt-client-test\n> chmod -R 755 TestDataGenerator.py\n> python3 TestDataGenerator.py\nBash\nThis will start publishing the messages. When you want to stop generating the data, just press \xe2\x80\x9cctrl+c\xe2\x80\x9d to exit out of the program.\nOnce data is flowing through AWS IoT Sitewise Edge, we can visualize it using AWS OpsHub for AWS IoT SiteWise for Windows\nStep 9: Verify the data is populating in the OpsHub gateway client\nIn the OpsHub tool, click on the \xe2\x80\x9cAssets\xe2\x80\x9d tab, and select \xe2\x80\x9cSiteWise assets.\xe2\x80\x9d Select one of the assets and go to the \xe2\x80\x9cMeasurements\xe2\x80\x9d tab. You should see the values getting populated under the \xe2\x80\x9cLatest value\xe2\x80\x9d column.\nStep 10: Verify the data is transmitting to AWS IoT SiteWise in the cloud\nWe can also verify if the data is populating to AWS IoT SiteWise in the cloud. Once the data is populated to AWS IoT SiteWise Edge, it will also be populated to AWS IoT SiteWise in the cloud.\nGo to the AWS IoT SiteWise console and see if the data is getting populated. Go to Assets, then select one of the assets where the data got populated from the above test data generator. Go to Measurements and you should see values under Latest value column.\nCleanup\nAfter completing and testing the solution, follow the instructions below to clean up the AWS resources you create.\nDelete AWS IoT SiteWise Gateway\nLogin to AWS console, go to AWS IoT SiteWise service, select the Gateway that was created and click on Delete button.\nClean up the AWS resources created by CDK.\n> cd sitewise-mqtt-custom-connector/sitewise-assets-creation/\n> cdk destroy sitewise-assets-creation --profile <AWS_CLI_PROFILE_NAME>\nBash\nFrom the AWS EC2 console page, delete the following EC2 instances that were created during the above setup.\nAWS IoT SiteWise gateway Amazon EC2 instance.\nPublisher Amazon EC2 instance that was used to publish test messages.\nAmazon EC2 instance (Microsoft Windows AMI) used to access the AWS IoT SiteWise Monitor at the edge.\nAWS IoT Greengrass core device: Go to AWS IoT Core console, and select Greengrass. Under that select Core devices, and select the core device that was created and click on Delete button.\n'"
89,How to store data with AWS IoT SiteWise Edge in many locations,b'Praveen Rao',2022-06-13T22:51:21+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-store-data-with-aws-iot-sitewise-edge-in-many-locations/,"b'Introduction\nIn this post, we discuss how AWS IoT SiteWise and AWS IoT SiteWise Edge can be used to store data not only in the AWS IoT SiteWise data store but also in many other locations. By default data is stored in the AWS IoT SiteWise data store on AWS.\nCustomers told us that they want to use AWS IoT SiteWise to collect their industrial data from OPC-UA data sources. But not all customers want to store their data solely in the AWS IoT SiteWise data store. In this blog post, we describe howto store data in other services like Amazon S3, Amazon Timestream or to consume the data in customers on-premise environment.\nAWS IoT SiteWise is a managed service that lets you collect, model, analyze, and visualize data from industrial equipment at scale. An AWS IoT SiteWise gateway collects data from industrial equipment and stores data in the AWS IoT SiteWise data store in the cloud.\nAWS IoT SiteWise Edge brings features of AWS IoT SiteWise in the cloud to the customer\xe2\x80\x99s premises. You can process data in the AWS IoT SiteWise gateway locally, and visualize equipment data using local AWS IoT SiteWise Monitor dashboards served from the AWS IoT SiteWise gateway.\nBy default, data is stored in the AWS IoT SiteWise data store on AWS.\nIn this blog post, we describe how customers can realize the benefits of the AWS IoT SiteWise Edge gateway to collect data but store data outside of the AWS IoT SiteWise data store.\nTime to read             8 min\nLearning level          300\nServices used           AWS IoT SiteWise Edge, AWS IoT Greengrass, Amazon Kinesis Data Streams, Amazon Timestream\nSolution\nDeploying AWS IoT SiteWise Edge gateway on AWS IoT Greengrass Version 2\nI am going to explain how the AWS IoT SiteWise Edge gateway is deployed on AWS IoT Greengrass Version 2.\nThe AWS IoT SiteWise Edge gateway runs in form of components on AWS IoT Greengrass Version 2. The Data Collection Pack includes two components, the SiteWiseEdgeCollectorOpcua and SiteWiseEdgePublisher. The Data Processing Pack includes the single component SiteWiseEdgeProcessor.\nThe Data Collection Pack collects your industrial data and routes it to AWS destinations. The Data Processing Pack enables the gateway communication with edge-configured asset models and assets. You can use edge configuration to control what asset data to compute and process locally. You can then send your data to AWS IoT SiteWise or other AWS services in the cloud.\nThe following screenshot shows an AWS IoT Greengrass V2 deployment with the Data Collection Pack and Data Processing Pack deployed.\nFigure 1: AWS IoT Greengrass V2 deployment\nUnderstanding AWS IoT SiteWise gateway architecture\nTo send data to locations other than the AWS IoT SiteWise data store, you first need to understand the default architecture of the AWS IoT SiteWise gateway.\nData is ingested into the AWS IoT SiteWise data store. Data is collected by the SiteWiseEdgeCollectorOpcua from OPC-UA sources and ingested into an AWS IoT Greengrass stream on the gateway, by default to the SiteWise_Stream. The SiteWiseEdgePublisher reads the data from the stream and transfers it to the SiteWise data store on AWS.\nFigure 2: AWS IoT SiteWise gateway architecture\nConfiguring destinations in the AWS IoT SiteWise gateway to store data in many locations\nTo send data to a destination other than the AWS IoT SiteWise data store, the gateway configuration allows you to configure the AWS IoT Greengrass stream name where the SiteWiseEdgeCollectorOpcua stores the data. You define the stream name for each data source in your AWS IoT SiteWise gateway. You can use the AWS IoT SiteWise console, the AWS CLI or AWS SDK to configure the stream name.\nYou can create your own custom stream on AWS IoT Greengrass V2 and point the destination for a data source to that stream. A stream can have an export definition, which defines the AWS destination to which your data will be transferred. Currently, AWS IoT SiteWise, AWS IoT Analytics, Amazon S3, and Amazon Kinesis Data Streams are supported as export configurations. When you export your data to Amazon Kinesis Data Streams, you have many options to read the data from Amazon Kinesis Data Streams and transfer it to another service. With consumers reading data from Amazon Kinesis Data Streams, you can send your data to different locations.\nIf you want for example to store your data in Amazon Timestream you can use an AWS Lambda function or Amazon Kinesis Data Analytics for Apache Flink as a consumer for Amazon Kinesis Data Streams and write the data into your Amazon Timestream table.\nWith such an architecture, you can not only store your data in Amazon Timestream but also in any location which is accessible from your Amazon Kinesis Data Streams consumer.\nIn case you are not using an export configuration for a custom stream, you can develop your own AWS IoT Greengrass component to consume data from your custom stream.\nFigure 3: Architecture to store data in many locations with AWS IoT SiteWise\nUnderstanding AWS IoT SiteWise Edge gateway architecture\nThe AWS IoT SiteWise Edge gateway architecture differs from the AWS IoT SiteWise gateway architecture in that it includes the SiteWiseEdgeProcessor, which allows you to serve AWS IoT SiteWise Monitor portals at the edge and also process data at the edge.\nFigure 4: AWS IoT SiteWise Edge gateway architecture\nTo send data from AWS IoT SiteWise Edge to many locations you cannot use the same approach as with AWS IoT SiteWise. A custom stream for a data source defines where the SiteWiseEdgeCollectorOpcua sends the data to. The Data Processing Pack already uses the custom stream name SiteWise_Edge_Stream. If you changed the stream name to your custom stream, then your data would not reach the SiteWiseEdgeProcessor.\nConfigure AWS IoT SiteWise Edge to store data in many locations\nThere are multiple options to send data from AWS IoT SiteWise Edge to many locations. If you do not want to send data to the AWS IoT SiteWise data store you must remove the SiteWiseEdgePublisher from your AWS IoT Greengrass deployment, because the SiteWiseEdgePublisher reads data from the SiteWise_Stream and stores it in the AWS IoT SiteWise data store.\nYou can use the API at the edge to retrieve data and store it, for example, in a stream on AWS IoT Greengrass for further processing. This option requires you to query the API for every single asset property, and if your asset properties change, you must also change your application or the application\xe2\x80\x99s configuration.\nAnother option is to develop a component to read data from the SiteWise_Stream. The component transfers the data to another destination such as another stream or a target in your on-premises environment.\nFigure 5: Architecture to store data in many locations with AWS IoT SiteWise Edge\nIn the following example we explain how you can read data from the SiteWise_Stream and in one case, ingest the data to a custom stream to be transferred to AWS, and in another case, publish the data to a local MQTT message broker. The custom stream is created with an export configuration to Amazon Kinesis Data Streams on AWS.\nThe following code snippets are based on an AWS IoT Greengrass V2 component written in Python. The code uses the AWS Greengrass Stream Manager SDK for Python and the Paho Python Client.\nThe following variables are used in the custom component.\nSTREAM_NAME_SOURCE is the name of the stream to read the data from.\nSTREAM_NAME_TARGET is the name of your custom stream where you want to send the data to.\nSTREAM_NAME_CLOUD is the name of Amazon Kinesis Data Streams on AWS. The stream STREAM_NAME_TARGET is created with an export configuration to the STREAM_NAME_CLOUD.\nFor example:\nSTREAM_NAME_SOURCE = ""SiteWise_Stream""\nSTREAM_NAME_TARGET = ""SiteWise_Anywhere_Stream""\nSTREAM_NAME_CLOUD = ""SiteWiseToKinesisDatastream""\nPython\nBefore starting the component you must create an Amazon Kinesis Data Stream with stream name STREAM_NAME_CLOUD on AWS.\nUpon start, the component checks if the stream STREAM_NAME_TARGET exists. If the stream does not exist, it is created with an export configuration to Amazon Kinesis Data Streams on AWS.\ntry:\n    response = stream_manager_client.describe_message_stream(STREAM_NAME_TARGET)\n    logger.info(""stream_name: %s details: %s"", STREAM_NAME_TARGET, response)\nexcept ResourceNotFoundException as error:\n    logger.info(""create message stream: %s error: %s"", STREAM_NAME_TARGET, error)\n    \n    exports = ExportDefinition(\n        kinesis=[KinesisConfig(\n            identifier=f""{STREAM_NAME_CLOUD}"",\n            kinesis_stream_name=STREAM_NAME_CLOUD,\n            batch_size=10,\n            batch_interval_millis=60000\n            )]\n        )\n    \n    stream_manager_client.create_message_stream(\n        MessageStreamDefinition(\n            name=STREAM_NAME_TARGET,\n            strategy_on_full=StrategyOnFull.OverwriteOldestData,\n            persistence=Persistence.File,\n            max_size=1048576,\n            export_definition=exports\n        )\n    )\nexcept Exception as error:\n        logger.error(""%s"", error)\nPython\nThe component reads messages from the STREAM_NAME_SOURCE. Once messages are available it iterates over the entries in a message and starts threads to store the entries in a custom stream and to publish them to an MQTT message broker.\nresponse = stream_manager_client.read_messages(\n            STREAM_NAME_SOURCE,\n            ReadMessagesOptions(\n                desired_start_sequence_number=LAST_READ_SEQ_NO + 1,\n                min_message_count=MIN_MESSAGE_COUNT,\n                read_timeout_millis=1000\n            )\n        )\n\nfor entry in response:\n    logger.info(""stream_name: %s payload: %s"",\n                STREAM_NAME_SOURCE, entry.payload)\n\n   # send data to another stream at the edge\n    thread_stream = Thread(\n        target=store_message_to_stream,\n        args=[entry.payload])\n    thread_stream.start()\n    logger.info(\'thread_stream started: %s\', thread_stream)\n    \n   # send data to a local MQTT message broker\n    thread_mqtt = Thread(\n        target=publish_message_to_mqtt_broker,\n        args=[entry.payload])\n    thread_mqtt.start()\n    logger.info(\'thread_mqtt started: %s\', thread_mqtt)\nPython\nThe following function code writes data to the custom stream STREAM_NAME_TARGET. Data ingested in this custom stream is transferred automatically to Amazon Kinesis Data Streams on AWS.\ndef store_message_to_stream(payload):\n    try:\n        sequence_number = stream_manager_client.append_message(stream_name=STREAM_NAME_TARGET, data=payload)\n        logger.info(\'appended message to stream: %s sequence_number: %s message: %s\',\n                    STREAM_NAME_TARGET, sequence_number, payload)\n    except Exception as error:\n        logger.error(""append message to stream: %s: %s"",\n                     STREAM_NAME_TARGET, error)\nPython\nThe following function code publishes data to the topic sitewise on an MQTT message broker.\ndef publish_message_to_mqtt_broker(payload):\n    try:\n        logger.info(\'MQTT: publish message: %s\', payload)\n        c_mqtt = paho.Client()\n        c_mqtt.mqtt_on_publish = mqtt_on_publish\n        c_mqtt.mqtt_on_disconnect = mqtt_on_disconnect\n        c_mqtt.connect(MQTT_BROKER, MQTT_PORT)\n        ret = c_mqtt.publish(""sitewise"", payload) \n        logger.info(\'MQTT: publish: ret: %s\', ret)\n        c_mqtt.disconnect()\n    except Exception as error:\n        logger.error(""MQTT: publish message: %s"", error)\nPython\n'"
90,Digital Twins on AWS: Driving value with L1 Descriptive Digital Twins,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/04/14/DigitalTwin_L1Descriptive-1.jpg,https://aws.amazon.com/blogs/iot/l1-descriptive-digital-twins/,"b'In our prior blog, we discussed a definition and framework for Digital Twins consistent with how our customers are using Digital Twins in their applications. In particular, we described a Digital Twin leveling index to help customers understand their use cases and the technologies needed to achieve the business value they are seeking. This Digital Twin leveling index is analogous to what we see in the self-driving cars space which uses an L0 through L5 system, where L0 is manual driving, L1 is cruise control, and L5 is a true autonomous self-driving car with no steering wheel.\nAs a recap, the figure below shows an overview of the four Digital Twin levels which we described in the prior blog. In this blog, we will illustrate the L1 Descriptive level by walking through an example of an electric vehicle (EV). You will learn, through the example use cases, about the data, models, technologies, AWS services, and business processes needed to create and support an L1 Descriptive Digital Twin solution.\nL1 Descriptive Digital Twin\nAn L1 Digital Twin focuses on describing the physical system and includes content ranging from the initial business case analysis and product requirements to the detailed engineering design and 3D visualizations. The intent of an L1 Digital Twin is to describe the structure so that the user can understand the components and the relationship between those components that make up the physical system. In many cases, for L1 Digital Twins, the physical system doesn\xe2\x80\x99t exist yet as it is still during the early design phase. Alternatively, the physical system might exist, and the L1 Digital Twin is used to understand the average behavior of the physical system under a specific set of operating conditions (such as in a computational fluid dynamic or solid mechanics analysis). Examples of L1 Descriptive Digital Twins that we\xe2\x80\x99ll describe below include 1/ asset models, 2/ engineering design, and 3/ immersive virtual reality environments.\nAsset Model\nWhen considering a physical entity (or an asset), the most basic description consists of identifying all the sub-assemblies and components that make-up the system. For example, in the diagram below, we show a hierarchical representation of an EV vehicle. The diagram shows the major systems, subsystems and components that make up the vehicle. Note the diagram below is for illustrative purposes only and is not exhaustive. This information describes the structure of the Digital Twin and is usually represented as an entity model in a graph database such as Amazon Neptune, and can be queried and aggregated with data from other sources using a knowledge graph. Note that many industries have developed standards to enable interoperability between different systems and across the life cycle of the asset. For example, ISO 19650 and UK 1192 are international standards developed for building information modeling. In practice, keeping the configuration details updated is a common challenge for equipment operators and knowing the configuration of an asset is key for use-cases such as maintenance scheduling, inventory planning, and issuing product recalls for safety reasons. AWS IoT TwinMaker is a service that makes it easier for developers to create digital twins of real-world systems such as buildings, factories, industrial equipment, and production lines. In particular, it makes it easy to connect to different data sources to create, update, and query the asset entity model. This data can then be displayed in a visualization or be routed as input data to a machine learning or physics-based model to make predictions.\nEngineering Design\nFrom an engineering design perspective, there are many automobile subsystems that need to be designed such as the structural frame, the power train, the electrical system, the steering and suspension, as well as the exterior (both for styling and aerodynamics), and the interior (for styling and comfort). Each of the subsystems are engineered using a variety of computational tools that have been validated over decades of experience. For example, the overall ride handling and vehicle dynamics is modeled using a physics-based multi-body dynamics simulation that models the stiffness of each of the structural components of the assembled vehicle.\nIn the example below, provided by AWS Partner Maplesoft, the tire-road contact interaction is modeled as the vehicle is driven over simulated uneven terrain. The inputs to the simulation include the vehicle speed and steering inputs, and the model provides the deflection of the vehicle suspension. The simulation takes into account the details of the tire stiffness and the design of the suspension to understand when the tire-road contact forces are too low to provide adequate traction. The vehicle dynamics and stability during maneuvers (such as braking on slippery roads) for an EV are quite different than for an internal-combustion engine for many reasons, including the bottom-heavy weight distribution of an EV (since the battery packs are under the floor) versus conventional vehicles where the engine is in the front. Dynamic system simulations enable the engineer to simulate the vehicle dynamics under different conditions to meet the engineering requirements for the design. In this case, we also provided a 3D rendering of the vehicle for enhanced visualization.\nFor EVs in particular, performance analysis of the electrical drivetrain is critical in order to make sure the vehicle meets customer\xe2\x80\x99s expectations in regards to charging times, acceleration, and range. For example, the battery range of an EV on a cold day driving up and down hills is very different than the range on a warm day on flat roads. To explore the EV powertrain performance, we modified the previous EV model as shown in the figure below. In this model, we included the relevant parts of the driveline and a simplified vehicle model for aerodynamics and terrain inclination. The graphs in the image show the key battery and motor parameters (voltage and current) as the vehicle follows the simulated drive cycle, and the battery state of charge (SOC) can be shown to decline as the battery discharges. This type of analysis enables the design engineer to understand if the electrical drivetrain has the right performance characteristics to meet or exceed the expected route profiles for the target customers. To interact with a variation of this model, please visit the Maplesoft website.\nOther examples of engineering analysis using different software tools include computational fluid dynamics of airflow over the vehicle to minimize aerodynamic drag, finite element analysis of the structural components to make sure they have the strength to endure the vehicle loads, and ride-comfort analysis to simulate the passenger vibration/comfort during vehicle operation. AWS Partners include a broad range of Independent Software Vendors (ISVs) that provide engineering simulation software for computationally intensive workloads such as computational fluid dynamics (CFD), finite element analysis (FEA), drug discovery, weather modeling, electronic design automation (EDA), and others. These ISV solutions can be deployed using AWS High Performance Computing (HPC) services such as AWS ParallelCluster or through AWS Marketplace. In addition, AWS HPC Competency Partners also provide a fully managed cloud HPC environment, and end-to-end cluster provisioning, deployment, management, and support for customers to run HPC workloads on AWS. Using simulations on AWS HPC infrastructure lets manufacturers reduce costs by replacing expensive development of physical hardware with virtual models during product development. More generally around the topic of engineering design, we\xe2\x80\x99re hearing a lot from our Original Equipment Manufacturers (OEM) customers about the desire to modernize their engineering workflows in their companies and are looking to AWS to provide guidance on digital transformation. AWS is investing in Digital Engineering efforts to address key pain points related to data and model-sharing across diverse engineering tools, across internal functional groups, and across the external supply chain with robust permissions management.\nImmersive Extended Reality Experience\nThe L1 Descriptive example above focused on the engineering description during the design of the vehicle by the OEM. Another compelling L1 use case is the application of extended reality (XR) technologies, such as high fidelity 3D, immersive virtual reality (VR), and interactive augmented reality (AR), to immerse users into a true to life vehicle experience during the customer engagement process. In this example, AWS Partners Cavrnus, Theia Interactive, and Epic Games have developed a metaverse solution to create an immersive collaborative replica of a showroom featuring an Audi\xc2\xa9 A5 convertible where brand representatives can create more meaningful interactions with their customers through an always-on and available virtual space.\nFor example, a vision for the future of car buying is to have the customer enter an immersive virtual showroom from the comfort of their home, and have a brand representative join in the same virtual showroom to guide them through the sales cycle in a metaverse experience. To highlight this, we\xe2\x80\x99ve taken screenshots from the Cavrnus immersive experience. We can see the customer viewpoint as they walk down the hallway to approach the vehicle, then see the vehicle in the showroom, and interact by opening the door and sitting inside the vehicle.\nThe Cavrnus experience enables multi-user collaborative environments where all users have full spatial 3D co-presence including voice and video streaming. The customer can invite their friends and family to join the immersive experience remotely from their own locations and interact together through avatars, voice and video. The customer is able to change the color of the vehicle, the trim level, wheels, and the interior per the configuration options available. All users will see the changes immediately, and can engage in collaborative conversations and use whiteboards to explain their ideas to each other. They can then render out their own personal commercial for their exactly configured vehicle.\nIn the images below, the customer continues to interact with the vehicle by opening the convertible roof and the trunk. The customer also modifies the vehicle color and interior trim options while engaged in collaborative discussions with their friends and family who can be seen via video and avatars.\nThis experience is fully interactive and the customer is able to use their controls to \xe2\x80\x9cwalk\xe2\x80\x9d around the virtual showroom as if they were there in-person. For a video showing the immersive experience, please visit the Cavrnus website and see for yourself!\nFor this solution, the digital showroom environment was created by Theia Interactive. The showroom assets were built by their digital artists using digital content creation tools. The vehicle and vehicle components originated from the original CAD and engineering data provided by Audi\xc2\xa9, and processed through a conversion/optimization workflow. The experience is powered by Cavrnus, and hosted on AWS infrastructure including the use of G4 and G4ad EC2 instances using Unreal Engine for rendering and streaming. The experience can also be pixel streamed from AWS GPU servers in the cloud to any end device via a web browser, including smart phones.\nAWS is continuing to work with customers across industries to simplify the process of 3D content generation, storage, hosting, and experiences. For example, Amazon Nimble Studio is a virtual studio, now available for digital content creators, providing virtual workstations, shared storage, and a built-in rendering solution that connects creative tools in media and entertainment production environments. Additionally, AWS in partnership with Epic Games, has recently begun offering an Unreal Engine Amazon Machine Image (AMI) available in the AWS Marketplace that makes the process of developing Unreal Engine based content turnkey.\nSummary\nWe, at AWS, are very excited to support our customers in their Digital Twin journey with a range of AWS services and ISV partnerships to support use cases across all four Digital Twin levels. In this blog we described the L1 Descriptive level by walking through an automotive example. In future blogs, we will extend the automotive example to demonstrate L2 Informative, L3 Predictive and L4 Living Digital Twins.\nAbout the author\nDr. Adam Rasheed is the Head of Autonomous Computing at AWS, where he is developing new markets for HPC-ML workflows for autonomous systems. He has 25+ years experience in mid-stage technology development spanning both industrial and digital domains, including 10+ years developing digital twins in the aviation, energy, oil & gas, and renewables industries. Dr. Rasheed obtained his Ph.D. from Caltech where he studied experimental hypervelocity aerothermodynamics (orbital reentry heating). Recognized by MIT Technology Review Magazine as one of the \xe2\x80\x9cWorld\xe2\x80\x99s Top 35 Innovators\xe2\x80\x9d, he was also awarded the AIAA Lawrence Sperry Award, an industry award for early career contributions in aeronautics. He has 32+ issued patents and 125+ technical publications relating to industrial analytics, operations optimization, artificial lift, pulse detonation, hypersonics, shock-wave induced mixing, space medicine, and innovation.\n '"
91,7 patterns for IoT data ingestion and visualization- How to decide what works best for your use case,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/7-patterns-for-iot-data-ingestion-and-visualization-how-to-decide-what-works-best-for-your-use-case/,"b'Introduction\nWhether you are just starting with your Internet of Things (IoT) journey, or already have millions of connected IoT devices, you might be looking for ways to maximize the value extracted from your IoT data. IoT devices data can contain a wealth of information within its reported telemetry data, metadata, state, and commands and responses. However, having the right reporting and visualization solution is key to gain insights needed to maximize your operational efficiency and deliver business outcomes.\nNo one solution can fit every use-case, hence frameworks like the AWS Well-Architected help you to choose a solution that best fits from a management, performance, cost, and operations perspective. You might be looking for a reporting and visualization solution that can deliver data in real time. Or, maybe you want a solution that can be fully customizable, and gives you the ability to search for insights.\nIn this blog post, we will walk through the different IoT reporting and visualization solutions at AWS. We will review 7 different architectural patterns that can deliver reporting in real time, near real-time, and on schedules. Additionally, we will provide you with data points on use cases, refresh interval, data ingestion process, architecture, and complexity for each of the solutions.\nArchitectural Patterns\nThe following diagram shows a consolidated view of all architectural patterns, and details of each pattern are covered in the subsequent sections.\nPattern 1: AWS Stream Manager\n  Overview:\nAWS IoT Greengrass stream manager makes it easier and more reliable to transfer high-volume IoT data to the AWS Cloud. Stream manager processes data streams locally and exports them to the AWS Cloud automatically. This feature integrates with common edge scenarios, such as machine learning (ML) inference, where data is processed and analyzed locally before being exported to the AWS Cloud or local storage destinations. Stream manager is designed to work in environments with intermittent or limited connectivity. You can define bandwidth use, timeout behavior, and how stream data is handled when the core is connected or disconnected.\nMetrics & Analytics:\nStream manager supports exporting to the following key AWS destinations.\nAWS IoT SiteWise: AWS IoT SiteWise lets you collect, organize, and analyze data from industrial equipment at scale.\nAmazon Kinesis Data Streams: Kinesis Data Streams is commonly used to aggregate high-volume data and load it into a data warehouse or map-reduce cluster.\nAWS IoT Analytics: AWS IoT Analytics lets you perform advanced analysis on your data to help make business decisions and improve machine learning models.\nAmazon S3 Objects: You can use Amazon S3 to store and retrieve large amounts of data.\nReporting:\nReports will vary based on AWS service used. For example, AWS IoT SiteWise pattern highlights AWS IoT SiteWise Monitor for real-time monitoring and Kinesis Data Firehose pattern highlights using QuickSight for reporting.\nWhy this pattern is useful?:\nFor systems that don\xe2\x80\x99t need fleet management or monitoring capabilities that AWS IoT Core provides, or don\xe2\x80\x99t need to modify the data at the edge before routing the data to other services, this could be a great cost-effective solution.\nTo support custom embedded offline management and buffering optimization. Your IoT applications can define policies for storage type, size, and data retention on a per-stream basis to control how stream manager processes and exports streams.\nPattern 2: AWS IoT SiteWise (+ AWS IoT SiteWise Monitor)\nOverview:\nAWS IoT Greengrass software installed on your device provides an open-source edge runtime and cloud service that helps you build, deploy, and manage intelligent device software. Using AWS IoT SiteWise components, you can integrate with Greengrass to send local device and equipment data to asset properties in AWS IoT SiteWise on AWS cloud. Through the AWS IoT SiteWise Edge software you can then easily collect, organize, process, and monitor equipment data on-premises.\nMetrics & Analytics:\nAWS IoT SiteWise supports computing performance metrics for your equipment and processes. These metrics can help identify various types of wastes such as equipment issues, production gaps, and quality defects. AWS IoT SiteWise data is available in AWS IoT Core and can be made available to AWS IoT Analytics or other analytics services like Amazon Kinesis via rules for AWS IoT Core\nReporting:\nAWS IoT SiteWise monitor can automatically discover and visualize data from assets that have already been ingested and modeled with AWS IoT SiteWise. It provides a fully managed web application out of the box without having to write code.\nAWS IoT SiteWise for Grafana plugin allows Grafana dashboards to monitor data stored by AWS IoT SiteWise in the AWS Cloud.\nWhy this pattern is useful?:\nImprove manufacturing operations: Monitor performance metrics from manufacturing lines, assembly robots, and factory equipment to discover and act on opportunities for improvement.\nOptimize asset maintenance: Prevent, detect, and resolve equipment issues faster through remote asset monitoring using historical and near-real-time data.\nView live trend charts of asset data (no-code, fully-managed web applications)\nPattern 3: AWS IoT Core + AWS IoT Analytics + Amazon QuickSight\nOverview:\nAWS IoT Core enables connected devices to easily and securely interact with cloud applications and other devices. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they are offline. Data collected from devices can be sent via MQTT messages to AWS IoT Core and an IoT rule can be used to ingest data to AWS IoT Analytics which helps to analyze the data.\nMetrics & Analytics:\nAWS IoT Analytics automates the steps required to analyze data from IoT devices. AWS IoT Analytics filters, transforms, and enriches IoT data before storing it in a time-series data store for analysis. You can set up the service to collect only the data you need from your devices, apply mathematical transforms to process the data, and enrich the data with device-specific metadata such as device type and location before storing it. Then, you can analyze your data by running queries using the built-in SQL query engine, or perform more complex analytics and machine learning inference.\nReporting:\nAWS IoT Analytics enables advanced data exploration through integration with Jupyter Notebook. AWS IoT Analytics also enables data visualization through integration with Amazon QuickSight. Amazon QuickSight is available in the following Regions.\nWhy this pattern is useful?:\nEase of use: AWS IoT Analytics is very well integrated with AWS IoT Core and helps to collect, process, store, analyze and build on IoT data. It\xe2\x80\x99s completely serverless and low-code (can be extended with Lambdas)\nPredictive maintenance: AWS IoT Analytics provides pre-built templates to help you easily build powerful predictive maintenance models and apply them to your fleet\nPerform comprehensive analysis: AWS IoT Analytics can automatically enrich IoT device data with contextual metadata using the AWS IoT Registry and other public data sources so that you can perform analysis that factors in time, location, temperature, altitude, and other environmental conditions\nAutomate anomaly detection: AWS IoT Analytics enables you to automate your anomaly detection workflow using Amazon SageMaker to gain insights via ML workflows. You can read more about using containerized Jupyter notebooks with AWS IoT Analytics here\nPattern 4: Amazon Timestream\n  Overview: \nIn this pattern you start by publishing time series data to AWS IoT core and then data can be pushed to Amazon Timestream through built in IoT rule and the data can be visualized using various dashboarding option.\nMetrics & Analytics: \nThe IoT rule for Amazon Timestream writes data from MQTT messages to an Amazon Timestream Database. You can then use tools like Amazon QuickSight to query and visualize data. For more details refer to Timestream rule action.\nTip for timestream: If you want to optimize the number of write operations on the DB, follow the batch write approach listed here.\nReporting: \nAlong with using Amazon QuickSight you can also use Amazon managed Grafana as your dashboarding and alerting tool. For more details refer to Timestream-Grafana integration.\nWhy this pattern is useful?:\nThis pattern is useful if you are looking to perform analytical functions on your device data such as such as smoothing, approximation, and interpolation (built-in support via Amazon Timestream). For example, a smart home device manufacturer can use Amazon Timestream to collect motion or temperature data from the device sensors, interpolate to identify the time ranges without motion, and alert consumers to take actions such as turning down the heat to save energy.\nPattern 5: AWS IoT Core + Amazon Kinesis + Amazon QuickSight\n  Overview:\nIn this pattern, you start by publishing data to AWS IoT core which integrates with Amazon Kinesis allowing you to collect process and analyze large bandwidth of data in real time. Data can be visualized using Amazon QuickSight.\nMetrics & Analytics:\nAmazon Kinesis Data Analytics allows you gain actionable insights from streaming data. With Amazon Kinesis Data Analytics for Apache Flink, customers can use Java, Scala, or SQL to process and analyze streaming data. The service enables you to author and run code against streaming sources to perform time-series analytics, feed real-time dashboards, and create real-time metrics.\nReporting:\nFor reporting you can use Amazon QuickSight for batch and scheduled dashboards. If the use-case demands a more real-time dashboard capability, you can use Amazon OpenSearch with OpenSearch Dashboards pattern\nWhy this pattern is useful?:\nIf your application involves high bandwidth streaming datapoints, then this pattern provides the ability to analyze that high bandwidth and real-time steaming data so that you can derive actionable insights.\nPattern 6: Amazon OpenSearch Service + OpenSearch Service Dashboards/Amazon Managed Grafana\nOverview:\nIn this pattern, you can start by publishing data to AWS IoT core and then data can be pushed to Amazon OpenSearch service through built in IoT rule and the data can be visualized using various dashboarding option.\nMetrics & Analytics:\nThe OpenSearch IoT rule action writes data from MQTT messages to an Amazon OpenSearch Service domain. You can then use tools like OpenSearch Dashboards to query and visualize data in OpenSearch Service. For more details refer to OpenSearch rule action.\nReporting:\nAlong with using Amazon OpenSearch Dashboards you can also use Amazon managed Grafana as the dashboarding options. With Amazon Managed Grafana, you can add the Amazon OpenSearch Service as a data source by using the AWS data source configuration option in the Grafana workspace console. For further information on how to set this up please refer to Grafana plugin for OpenSearch.\nWhy this pattern is useful?:\nIf you are  looking to monitor device heath or device metrics, then this pattern provides the ability to search on the underlying data, perform custom configurations and get real-time dashboard application.\nPattern 7: AWS IoT Core + AWS Lambda + Amazon DynamoDB + Amazon QuickSight / Custom Dashboards\nOverview:\nIn this pattern, you can visualize a real-time telemetry data sent directly from IoT devices via AWS IoT Core using AWS Lambda, Amazon DynamoDB, AWS AppSync and a custom dashboard of your choice.\nIoT Rules for AWS IoT Core will send the MQTT message to an AWS Lambda function. The Lambda function can format the message and then executes an AWS AppSync GraphQL mutation. The mutation call will save the message in an Amazon DynamoDB table, and broadcast the message in real-time to the custom dashboard. The custom dashboard subscribes to the AWS AppSync subscription which will receive the updated message. You can read more about this pattern here.\nMetrics & Analytics:\nThe IoT data will be stored in Amazon DynamoDB table. In order to perform advanced analytics, you need to export the data into an analytics platform. This can be achieved by building a data pipeline that transition the data into Amazon S3, and then use Amazon Athena, to run advanced analytics. For more details, refer to the Amazon Athena blog post that performs advanced analytics & visualizations.\nReporting:\nYou can easily create and launch custom dashboards and mobile applications using AWS Amplify. The custom dashboard can communicate with AWS AppSync through the AWS Amplify Framework such as iOS, Android, React Native, Flutter, React and Vue.\nWhy this pattern is useful?:\nThis pattern is a great fit for use cases when IoT data needs to be delivered to end users as soon as it changes via a custom real-time dashboard. Users can access data using custom and configurable front-end clients\nThis pattern is also a great fit for mobile applications that help consumers monitor their home appliances in real-time (can be activated only on-demand)\nConsiderations and caveats\nNo one size fits all \xe2\x80\x93 All the architectural patterns mentioned in this post are focusing on the most feasible path; however, every use case is different and so most of the patterns can be tweaked to add other relevant services to add additional capabilities or get over any deficiencies. If none of the patterns meet your requirement, look at the credential provider pattern to authorize direct calls and integrate with AWS services (including AWS IoT services)\nCosts: Every pattern has its own cost model and it can vary substantially based on the number of devices and amount of data in your application. It is important for you to factor in these considerations while choosing a pattern.\nRegion specific services: Not every service may be available in every region so do evaluate a service before choosing a pattern\n'"
92,Ingesting and managing data from industrial equipment with AWS IoT SiteWise,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/ingesting-and-managing-data-from-industrial-equipment-with-aws-iot-sitewise/,"b'AWS IoT SiteWise is a managed service that simplifies collecting, organizing, and analyzing industrial equipment data at scale. With AWS IoT SiteWise, customers can gather data reliably from multiple facilities, structure it, and make it accessible and understandable without developing additional software. With equipment data stored in AWS IoT SiteWise, customers can assess the performance of their industrial equipment remotely and across locations. This visibility across industrial facilities allows customers to streamline operations, as well as identify gaps in production and waste. In addition, AWS IoT SiteWise Edge runs on-premises, securely connecting to and reading data from equipment or local historian databases. On Nov 24th 2021, AWS IoT SiteWise announced three new enhancements that make it easier to ingest equipment data to the cloud. Prior to these enhancements, customers had to model their equipment before ingesting data to AWS IoT SiteWise. Now, Customers can ingest data into the cloud as soon as their equipment is connected to AWS IoT SiteWise. In the blog, we will cover details, benefits, and best practices for customers using AWS IoT SiteWise with disassociated data ingestion.\nImproved asset modeling experience\nCustomers use AWS IoT SiteWise to build models of their physical operations that represent their assets, processes, and facilities, which will help them understand industrial data in the context of their equipment. Once asset models are created, customers can define an asset hierarchy to accurately represent relationships between devices and equipment within a single facility or across multiple facilities. Our customers tell us that modeling production operation and equipment could be a lengthy process, and it changes and evolves over time. Now with the disassociated data ingestion feature, all data streams will be ingested to the cloud without the prerequisite of associating them to assets. Customers can ingest data streams through an AWS IoT SiteWise Edge gateway, AWS IoT Core, or directly using AWS IoT SiteWise batch PUT API. It also gives you the flexibility to model your production operation after data ingestion. As your production environment evolves, you can adapt to changes and update data stream and asset association without any data loss. It leads to a virtuous cycle of asset modeling experience as illustrated in the virtuous cycle of asset modeling below.\n          Virtuous cycle of asset modeling\nWhen you connect equipment to AWS IoT SiteWise, equipment data are represented as data streams. Each data stream represents a measurement that can be associated as a property for a virtual representation of equipment in AWS IoT SiteWise. An asset model is a virtual representation of a type of equipment and includes one or more properties that are measurements from the equipment. Using an asset model, you create an asset that represents a physical piece of equipment in your production operations. You can then define hierarchies of assets to organize virtual representations of equipment in your production environment. With the ability of disassociating and re-associating data streams to assets, you can continue to evolve asset modeling to represent the latest state of your production environment. For example, in discrete manufacturing, it\xe2\x80\x99s common for a piece of equipment to be physically moved to another location. In this scenario, you can update Hierarchy definitions in asset model to reflect the latest change on the manufacturing floor. In addition, all data you collected is still retained with no loss during the reconfiguration.\nEnabling disassociated data ingestion\nDisassociated data ingestion is enabled by default for new AWS IoT SiteWise customers (AWS accounts that have never used AWS IoT SiteWise service). Customers with an existing AWS IoT SiteWise setup can enable the feature with one simple step. In the AWS IoT SiteWise console under Settings, choose Data Ingestion, and then enable Disassociated data ingestion.\nEnabling the new data ingestion mode in AWS IoT SiteWise introduces a new resource called Data stream that is time series data. Data stream and asset are now resources in AWS IoT SiteWise that you can manage independently. Customers cannot disable the feature since access control to data streams and assets are managed independently. If you don\xe2\x80\x99t see \xe2\x80\x9cData Ingestion\xe2\x80\x9d setting, your account has this feature enabled already.\nYou can still disable the disassociated data ingestion from the gateway using access control (IAM), by writing a policy using the isAssociatedWithAssetProperty condition key. The value presented by this condition will be true if the PropertyAlias is associated with an AssetProperty, or otherwise false. This also enables a scenario where one gateway is the \xe2\x80\x9cdevelopment\xe2\x80\x9d gateway and allows all data streams, while another is the \xe2\x80\x9cproduction\xe2\x80\x9d gateways and does not allow disassociated data ingestion. This condition is only emitted for actions that get or put property values, such as BatchPutAssetPropertyValue.\nThe following example IAM policy would disable data ingestion of data streams not associated with any asset. This IAM policy consists of two statements. The first statement allows data streams that are associated to an asset property to be sent to AWS IoT SiteWise, while the second statement prevents data streams that are not associated to an asset property from being sent to AWS IoT SiteWise.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Sid"": ""AllowPutAssetPropertyValuesWithModeledPropertyAlias"",\n      ""Effect"": ""Allow"",\n      ""Action"": ""iotsitewise:BatchPutAssetPropertyValue"",\n      ""Resource"": ""arn:aws:iotsitewise:*:*:time-series/*"",\n      ""Condition"": {\n        ""StringLikeIfExists"": {\n          ""iotsitewise:isAssociatedWithAssetProperty"": ""true""\n        }\n      }\n    },\n    {\n      ""Sid"": ""DenyPutAssetPropertyValuesWithUnmodeledPropertyAlias"",\n      ""Effect"": ""Deny"",\n      ""Action"": ""iotsitewise:BatchPutAssetPropertyValue"",\n      ""Resource"": ""arn:aws:iotsitewise:*:*:time-series/*"",\n      ""Condition"": {\n        ""StringLikeIfExists"": {\n          ""iotsitewise:isAssociatedWithAssetProperty"": ""false""\n        }\n      }\n    }\n  ]\n}\nJSON\nData streams management\nYou can manage data streams and get instant feedback on ingested data streams through the AWS IoT SiteWise console. The data streams page has pagination and configurable page size to scale with a large number of data streams. You can filter data streams by using the prefix of the data stream name or by whether or not data streams are associated with assets. To ensure that all data streams are associated with assets, customers can use the AWS IoT SiteWise console or the ListTimeSeries API to filter for disassociated data streams. Then, you can associate those data streams with assets.\nThe following steps show how you can associate and disassociate data streams with asset properties.\nGo to the Data streams page and select the data streams you want to associate or disassociate with asset properties as shown below.\nClick \xe2\x80\x9cManage data streams\xe2\x80\x9d button on top right, and it will take you to \xe2\x80\x9cManage data streams\xe2\x80\x9d page.\nOn \xe2\x80\x9cManage data streams\xe2\x80\x9d page as shown in the following image, you will be able to add or remove asset properties for data streams.\nClicking the \xe2\x80\x9cUpdate\xe2\x80\x9d button will update all changes you made, as shown in Status column.\nEnhanced access control\nWhen you read or write time-series data in AWS IoT SiteWise, that data is part of a Data stream. AWS IoT SiteWise maintains associations between AssetProperty (a DataType in SiteWise that contains asset property information), PropertyAlias (the alias of the property), and Data Stream, providing a layer of indirection so that a Data Stream can be moved without having to copy data: that is called Model Mutability.\nA Data Stream must be bound to either an AssetProperty, a PropertyAlias, or both. If an AssetProperty is bound to a PropertyAlias, they both are also bound to the same Data Stream. Using the DisassociateTimeSeriesFromAssetProperty API, you can unbind a Data Stream from its AssetProperty, so that it is bound only to a PropertyAlias. Then, you can bind it to another AssetProperty by calling the AssociateTimeSeriesToAssetProperty API. You can combine this with the existing ability to change a PropertyAlias using the UpdateAssetProperty API to update your data organization within AWS IoT SiteWise with complete flexibility. You can also accomplish this through console as discussed above.\nThe Data Stream resource type can be used with IAM to apply different policies based on how the data are identified. When identified by PropertyAlias, a time series resource must be used. A resource for a time series looks similar to:\narn:aws:iotsitewise:region:123456789012:time-series/<DATA_STREAM_ID>\nWhen identified by AssetId and PropertyId, it is part of an Asset Resource. The asset resource ARN (Amazon Resource Name) looks similar to:\narn:aws:iotsitewise:region:123456789012:asset/<ASSET_ID>\nYou can configure access control using a Data stream ARN and the PropertyAliasPrefix condition so that your Gateway can only write to Data Streams matching a given prefix.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Sid"": ""PutAssetPropertyValuesAliasesSiteAPrefixOnly"",\n      ""Effect"": ""Allow"",\n      ""Action"": ""iotsitewise:BatchPutAssetPropertyValue"",\n      ""Resource"": ""arn:aws:iotsitewise:*:*:time-series/*"",\n      ""Condition"": {\n        ""StringLikeIfExists"": {\n          ""iotsitewise:propertyAlias"": ""/site-a/*""\n        }\n      }\n    }\n  ]\n}\nJSON\nCombine this with Gateway support for automatic prefixing and it becomes easy to isolate factory sites from each other within the same account. Add in the AssetHierarchyPath condition key, and it becomes easy to carve out roles with minimal rights for both administrators and operators.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Sid"": ""PutAssetPropertyValuesAssetsSiteBHierarchyOnly"",\n      ""Effect"": ""Allow"",\n      ""Action"": ""iotsitewise:BatchPutAssetPropertyValue"",\n      ""Resource"": ""arn:aws:iotsitewise:*:*:asset/*"",\n      ""Condition"": {\n        ""StringLikeIfExists"": {\n          ""iotsitewise:assetHierarchyPath"": ""/a1b2c3d4-5678-90ab-cdef-22222EXAMPLE/a1b2c3d4-5678-90ab-cdef-66666EXAMPLE""\n        }\n      }\n    }\n  ]\n}\nJSON\nThe AssetHierarchyPath is the asset\xe2\x80\x99s hierarchy path. It is a string of asset IDs each separated by a forward slash. This condition key value looks similar to:\n/a1b2c3d4-5678-90ab-cdef-22222EXAMPLE/a1b2c3d4-5678-90ab-cdef-66666EXAMPLE\nWith Disassociated Data Ingestion enabled, the AssetHierarchyPath condition is only emitted if the resource is identified in the request as an Asset; it is not emitted when identified as a Data Stream. The propertyAlias condition will be emitted if the resource is identified in the request as a Data Stream; it is not emitted when identified as an Asset.\nYou can look up the Data stream identifier by using the DescribeTimeSeries API or by reading metadata exported to Amazon S3. This identifier is created when data is first ingested for the Data Stream, so a caller must be authorized to the Resource arn:aws:iotsitewise:region:123456789012:time-series/*  in order to create new Data streams.\n'"
93,How to integrate AWS IoT Core with Amazon MSK,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-integrate-aws-iot-core-with-amazon-msk/,"b'Post by Milo Oostergo, Principal Solutions Architect and Doron Bleiberg, Senior Solution Architect, AWS Startups\nIntroduction\nMonitoring IoT devices in real time can provide valuable insights that can help you maintain the reliability, availability, and performance of your IoT devices. AWS IoT Core provides integrations with Amazon Kinesis Data Streams and Amazon Managed Streaming for Apache Kafka (\xe2\x80\x9cAmazon MSK\xe2\x80\x9d) to set up real-time streaming data pipelines. Amazon MSK is popular choice for customers who are familiar with Kafka, need infinite message retention, and are looking for the lowest latency. In this blog post, we describe how to set up AWS IoT Core to stream events to Amazon MSK and common asks from our customers.\nTime to read 15 minutes\nTime to complete 60 minutes\nLearning level 300\nServices used AWS IoT Core, AWS Identity and Access Management, Amazon Managed Streaming for Apache Kafka, Amazon Key Management Service\nCost to complete (estimated) <$2\nOverview\nThe diagram below illustrates the components and functionality you can build following this blog post or using this sample AWS CloudFormation template. As part of this solution, MQTT messages streamed to AWS IoT Core are routed to Amazon Managed Streaming for Apache Kafka (Amazon MSK) using AWS IoT Rules actions. Access to the Amazon MSK cluster is controlled using username and password that are securely stored in AWS Secrets Manager and encrypted using AWS Key Management Service.\nWalkthrough\nPrerequisites\nA VPC with at least 2 private subnets. If you don\xe2\x80\x99t have a VPC, follow the Amazon MSK getting started documentation to create one.\nStep 1: Setting up an Amazon MSK cluster\nTo deliver messages from IoT devices to Amazon MSK using AWS IoT Core rule actions, you need to enable authentication on your Amazon MSK cluster. IoT rule actions can authenticate with your Amazon MSK cluster with username and password authentication using the SASL framework or by using TLS client authentication through AWS Certificate Manager. In this blog post, we set up the cluster using SASL/SCRAM authentication method. Once a cluster is created, you can\xe2\x80\x99t modify the the authentication settings.\nTo create the Amazon MSK cluster with authentication enabled\nFrom the Amazon MSK console, choose Create Cluster.\nSelect, enter a cluster name, and keep the recommended Apache Kafka version.\nIn Networking, select your VPC and choose \xe2\x80\x9c2\xe2\x80\x9d for Number of Availability Zones. From the drop-downs, select the two Availability Zones in the VPC, and choose the private subnets for each.\nIn Access control method, choose SCRAM/SASL authentication.\nKeep the existing defaults and choose Create cluster. It takes up to 15 minutes to create the cluster and the status is displayed in the Cluster Summary panel.\nStep 2: Create credentials in AWS Secrets Manager  \nAfter the cluster is successfully created, we create a set of credentials that can be used by the IoT rule to connect with the Amazon MSK cluster. The credentials must be stored in AWS Secrets Manager and associated with the cluster. Before we create the credentials in AWS Secrets Manager, we first create a customer-managed key in AWS Key Management Service (KMS). Secrets encrypted with a AWS managed CMK cannot be used with an Amazon MSK cluster.\nOpen the AWS KMS console and choose Create key.\nChoose symmetric key and follow the wizard to create the key. You don\xe2\x80\x99t have to define the key administrative permissions or key usage permissions at this point. We set this up later.Now that the KMS key is created, we can store the credentials in AWS Secrets Manager.\nOpen the AWS Secrets Manager console and choose Store a new credential.\nChoose Other type of secrets (e.g. API key) for the secret type.\nEnter the user and password data, which must be in the following format:\n{\n   ""username"": ""msk"",\n   ""password"": ""msk-secret""\n}\nSelect the customer managed key you created in previous step.\nTo associate secrets with the Amazon MSK cluster, the secret name must have the prefix AmazonMSK_. In this example, we use the name AmazonMSK_secret.\nRecord the ARN (Amazon Resource Name) value for your secret.\nStep 3: Associate secret with Amazon MSK cluster\nOnce the secret is created in AWS Secrets Manager, we can associate the secret with our Amazon MSK cluster.\nGo back to the Amazon MSK console and select your cluster.\nChoose Associate secrets and copy-paste the ARN of the secret you created in previous step.\nStep 4: Set up AWS Identity and Access Management (IAM) role and policy for AWS IoT rule\nTo grant AWS IoT access to stream data to our Amazon MSK cluster, you must create an IAM role with a policy that allows access to the required AWS resources.\nTo create an IAM role using AWS CLI\nSave the following trust policy document, which grants AWS IoT permission to assume the role, to a file named iot-role-trust.json:\n{\n  ""Version"":""2012-10-17"",\n  ""Statement"":[{\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""Service"": ""iot.amazonaws.com""\n      },\n      ""Action"": ""sts:AssumeRole""\n  }]\n}\nUse the create-role command to create an IAM role specifying the iot-role-trust.json file. Make sure to replace the AWS account id and region placeholders.aws iam create-role --role-name IoT-Rule-MSK-Role --assume-role-policy-document file://iot-role-trust.json\nSave the following JSON into a file named iot-msk-policy.json.\n{\n   ""Version"":""2012-10-17"",\n   ""Statement"":[\n      {\n         ""Effect"":""Allow"",\n         ""Action"":[\n            ""ec2:CreateNetworkInterface"",\n            ""ec2:DescribeNetworkInterfaces"",\n            ""ec2:CreateNetworkInterfacePermission"",\n            ""ec2:DeleteNetworkInterface"",\n            ""ec2:DescribeSubnets"",\n            ""ec2:DescribeVpcs"",\n            ""ec2:DescribeVpcAttribute"",\n            ""ec2:DescribeSecurityGroups""\n         ],\n         ""Resource"":""*""\n      },\n      {\n         ""Effect"":""Allow"",\n         ""Action"":[\n            ""secretsmanager:GetSecretValue"",\n            ""secretsmanager:DescribeSecret""\n         ],\n         ""Resource"":"" ""arn:aws:secretsmanager:region:123456789012:AmazonMSK_*""\n      ]\n   }\n]\n}\nThis JSON is an example policy document that provides access to create and manage elastic network interfaces in your Amazon Virtual Private Cloud and retrieve the credentials to reach your Kafka brokers.\nUse the create-policy command to define the actions and resources that AWS IoT Core can access upon assuming the role, by passing in the iot-msk-policy.json file:aws iam create-policy --policy-name IoT-Rule-MSK-policy --policy-document file://iot-msk-policy.json\nUse the attach-role-policy command to attach your policy and grant AWS IoT access. Replace the placeholder ARN by the policy ARN returned in the previous step.aws iam attach-role-policy --role-name IoT-Rule-MSK-Role --policy-arn ""arn:aws:iam::123456789012:policy/IoT-Rule-MSK-policy""\n\nTo grant the IAM role access to the KMS key\nIn order to decrypt the secret stored in AWS Secrets Manager, we must add the IAM role to the list of key users for the Customer Managed KMS key we earlier created.\nGo to the AWS KMS console and select the KMS key you created in the previous step.\nIn Key users add the IAM role IoT-Rule-MSK-Role.\nStep 5 \xe2\x80\x93 Create VPC destination for AWS IoT core\nCreate a destination to your VPC where Apache Kafka clusters reside. This destination is used to route messages from devices to your Amazon MSK cluster.\nGo to AWS IoT console, choose Act, and then choose Destinations.\nChoose Create a VPC destination.\nSelect the VPC and same subnets that are used for your Amazon MSK cluster.\nSelect security group that is used for your Amazon MSK cluster.\nSelect the IoT-Rule-MSK-Role you created in the previous step.\nStep 6 \xe2\x80\x93 Create AWS IoT rule\nGo to AWS IoT console, choose Act, choose Rules, and create a new rule.\nIn Actions choose Add action and select Kafka.\nSelect the VPC destination you created in the previous step.\nSpecify the Kafka topic.\nSpecify the TLS bootstrap servers of your Amazon MSK cluster. You can view the bootstrap server URLs in client information of your MSK cluster details.\nAs we set up our Amazon MSK cluster with the SCRAM SASL authentication method, select SSL_SASL as security.protocol and select SCRAM-SHA512 as sasl.mechanism.\nSpecify the following variable in sasl.scram.username and replace the name AmazonMSK_secret with the name of the secret you stored in step 2.${get_secret(\'AmazonMSK_secret\', \'SecretString\', \'username\', \'arn:aws:iam::123456789012:role/iot-msk-role\')}\nSpecify the following variable in sasl.scram.password and save the IoT rule action.${get_secret(\'AmazonMSK_secret\', \'SecretString\', \'password\', \'arn:aws:iam::123456789012:role/iot-msk-role\')}\nTesting the AWS IoT rule\nAt this point, you have created the Amazon MSK cluster and set up an AWS IoT Core rule with the necessary IAM permissions. To verify IoT events are streaming to your Amazon MSK cluster, you create the Kafka topic on your Amazon MSK cluster, connect a Kafka consumer to your bootstrap servers and send an event to your IoT topic using the MQTT test client available in the AWS IoT console.\nTo create a Kafka topic on your Amazon MSK cluster, you can use the following commands to install the Apache Kafka client and create a new topic using the ZooKeeper Connection string from an EC2 instance in the same VPC as the MSK Cluster.\nsudo yum install java-1.8.0\nwget https://archive.apache.org/dist/kafka/2.6.2/kafka_2.12-2.6.2.tgz\ntar -xzf kafka_2.12-2.6.2.tgz\naws kafka describe-cluster --cluster-arn <MSK Cluster ARN>\n<path-to-your-kafka-installation>/bin/kafka-topics.sh --create --zookeeper <Zookeeper-connection-string> --replication-factor 2 --partitions 1 --topic <topic-name-used-in-step-6>\nOnce the Kafka topic is created, you can send an event to your IoT topic using the MQTT test client available in the AWS IoT console.\nThe Kafka consumer connected to your cluster can now receive messages on the Amazon MSK topic. To learn how you can connect to your Amazon MSK cluster, see the section Connecting to your cluster with a username and password in the Amazon MSK developer guide.\nSetting up the permissions incorrectly is a common issue resulting in customers not receiving events on their Amazon MSK cluster.  When AWS IoT is unable to deliver events, the rules engine triggers an Error action. For example, you can set up an error action to deliver the events to Amazon CloudWatch Logs and specify the CloudWatch log group to which the IoT rule action sends the data. When an error occurs while processing your rule, you can view the stream of log events in the log group in CloudWatch Logs.\nCleaning up\nIf you followed along with this solution, complete the following steps to avoid incurring unwanted charges to your AWS account.\nAWS IoT Core\nIn the Act section, delete the rule and VPC destination.\nAmazon MSK\nDelete your cluster.\nAWS KMS\nDelete the Customer Managed Key used to encrypt the secrets stored in AWS Secrets Manager.\nAWS Secrets Manager\nDelete the secret created to authenticate with your Amazon MSK cluster.\nAWS IAM\nDelete the policies and roles created along the way.\nAmazon CloudWatch\nDelete the relevant Log groups.\n'"
94,How to manage IoT device certificate rotation using AWS IoT,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/03/21/AWS-IoT-device-certificate-1.png,https://aws.amazon.com/blogs/iot/how-to-manage-iot-device-certificate-rotation-using-aws-iot/,"b'Introduction\nThe Internet of Things (IoT) is transforming business operations and customer experiences across a variety of industries. This unlimited opportunity enables business transformation, but if not implemented correctly, it also brings security, risk, and privacy concerns, compromising your data and brand. In industrial facilities, OT (Operational Technology) environments are leveraging more IT solutions to improve production output and efficiencies. As digital transformation initiatives continue to accelerate IT/OT convergence, they also blend risks between the IT and OT environments. With the growing number of connected devices in consumer, enterprise and industrial applications, and the data generated, the potential for security events raises questions about how to address security risks posed by IoT devices and device communication to and from the cloud.\nTo protect customers, devices, and companies, every IoT solution should start and end with security. The best IoT security solution offers multi-layered protection from the edge to the cloud, securing your IoT devices, connectivity, and data. Provisioning IoT devices and systems with unique identities and credentials is one of the core building blocks of any IoT solution. The AWS IoT security model requires that each connected device have a credential to interact with AWS IoT and that all traffic to and from AWS IoT be sent securely over Transport Layer Security (TLS).\nCustomers are responsible for managing device credentials (X.509 certificates, AWS credentials, Amazon Cognito identities, federated identities, or custom authentication tokens) and policies in AWS IoT.  X.509 certificates provide AWS IoT with the ability to authenticate client and device connections. AWS provides several different ways to provision a device and install unique client certificates on it. In addition to strong identity for IoT devices, AWS recommends the use of hardware protected modules such as Trusted Platform Modules (TPMs) or hardware security modules (HSMs) for storing credentials and performing authentication operations. X.509 certificates provide a strong, standardized mechanism with renewable, password-less authentication. These certificates must be provisioned from a trusted public key infrastructure (PKI) and have a renewal lifetime appropriate for the security posture of their business use. Their renewal must be automatic (often based on device health) to minimize any potential access disruption due to manual rotation.\nIn case TPM or HSM is not available on the device, consider rotating credentials more often based on the business use case. Any access granted to a device should be granted based on its strong identity. Credential audit and monitoring, rotation, and revocation must be supported to enable immediate removal of device access (for example, to respond to compromise). This blog provides prescriptive guidance on addressing security concerns related to the audit and rotation of device credentials on IoT devices and edge gateways which connect to AWS IoT.\nSolution overview\nIn this post, we describe the certificate rotation process based on the AWS managed Certificate Authority. We illustrate the overall solution in the following diagram.\nThe sequence diagram (click to enlarge) presents all steps involved in the certificate rotation process. Subsequent diagrams will use the step numbers from this sequence to illustrate parts of this process.\nSolution walk through\n1. Identify devices with certificates which are going to expire\nThe proposed solution for IoT Thing certificate rotation leverages the AWS IoT Device Defender Scheduled Audit functionality and best practices of serverless system design.\nThe AWS IoT Device Defender Audit, audits your device-related resources (such as X.509 certificates, IoT policies, and Client IDs) against AWS IoT security best practices (for example, the principle of least privilege or unique identity per device). We will use one of predefined audit checks DEVICE_CERTIFICATE_EXPIRING_CHECK. This check verifies if a device certificate is expiring within 30 days or has expired.\nYou can enable automation by configuring the Audit notifications to send Amazon SNS alerts and trigger automated actions.\nAmazon SNS Subscription with Lambda Endpoint automatically triggers a Lambda function when new message arrives.\nTriggered Lambda function receives an event including following attributes:\n{\n\xe2\x80\xa6\n""taskId"": ""e843de58c4f7536021030936fb83d04a"",\n""nonCompliantChecksCount"": 1,\n""checkName"": ""DEVICE_CERTIFICATE_EXPIRING_CHECK""\n\xe2\x80\xa6\n}\nUsing taskId, Lambda function queries the IoT Core to list the identifiers of expiring certificates, then finds the client ids associated with obtained principals (certificates).\nAt this stage, Lambda function gathered all required information to start the certificate rotation process.\n2. Device generates a new Certificate Signing Request (CSR)\nLambda sends a MQTT message for specified management topic:\nTopic: management/topic/{clientId}/csr_req\nMessage: {}\nDevice receives the CSR_REQ message and starts the certificate rotation routine.\nRotation of the Private Key used by IoT device is optional but recommended and should be applied when appropriate based on the business use case.\nDevice generates new CSR (Certificate Signing Request) and sends it as a payload of MQTT message:\nTopic: management/topic/{clientId}/csr_res\nMessage: {\'CSR\': CSR}\nAWS IoT Core uses Rules to forward MQTT messages to the appropriate Lambda function.\nBuilt-in clientid() function returns the Id of the MQTT client which sent the message.\nThis is important because we are using the single-level wildcard (\'+\') to match any client id in our Rule. This way we can use one IoT Rule to manage certificate rotation for every connected device in our fleet.\nRule query statement:\nSELECT clientid() as clientid, * FROM \'management/topic/+/csr_res\'\n3. New device certificate is created and sent to the device\nLambda calls AWS IoT Core to create a new certificate based on received CSR and attaches the same IoT Policy which was used by the expiring certificate. The process described leverages the Amazon Root certificate authority (CA) to sign certificates used by devices. It is possible to use the Customer owned certificate authority to sign certificates; in that case, the certificate rotation process needs to be implemented on the customer\xe2\x80\x99s side and Device Defender Audit can be used to trigger it.\nFinally, Lambda returns certificate to device as a payload of an MQTT message.\nDevice stores the new certificate and establishes a new MQTT session using rotated credentials.\nIf connection using new certificate was successful, device ends rotation process by sending following MQTT message:\nTopic: management/topic/{clientId}/crt_ack\nMessage: {}\nIn case of any issues, device connects to AWS IoT Core using existing credentials and reports errors:\nTopic: management/topic/{clientId}/crt_err\nMessage: {\'error\': error_msg}\nIoT Rule executes Lambda function for automated error resolution and sends notification to support team using the Amazon Simple Notification Service (SNS).\nAs the final step of successful certificate rotation, Lambda deactivates and deletes the old certificate previously used by the IoT device.\nThis solution is resilient in case of any disturbances in the certificate rotation process. If the IoT device crashes while receiving the new certificate (or encounters any other issues), it will appear in the Device Defender Audit results the next day, and the process will start from scratch.\nAudit check includes devices with certificates expiring within 30 days, so a device can operate without any impact on production workloads while support staff have time to investigate a potential rotation issue.\n'"
95,How to detect anomalies in device metrics and improve your security posture using AWS IoT Device Defender custom metrics,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/03/15/AWS-IoT-SA-1.png,https://aws.amazon.com/blogs/iot/how-to-detect-anomalies-in-device-metrics-and-improve-your-security-posture-using-aws-iot-device-defender-custom-metrics/,"b'Introduction\nIoT applications and devices can be diverse and are used across industries such as utilities, agriculture, manufacturing, mining, and consumer electronics. With the exponential growth of IoT devices and the increasing threat landscape, it also means that IoT security needs to be accounted for and designed into the solution from the ground up.\nAWS IoT Device Defender is a service that helps secure your IoT device fleet and can be used to audit and monitor your IoT devices at scale. By default, the service enables you to monitor 17 network-related metrics, such as changes in connection patterns, devices that communicate to unauthorized or unrecognized endpoints, and changes in inbound and outbound device traffic patterns. You can learn how to leverage these metrics to monitor your fleet of IoT devices.\nBut what happens if you need to monitor metrics that are unique to your device fleet or use case? For example, the number of devices connected to wi-fi gateways, charge levels for batteries, or security-related metrics such as domains being contacted by devices, detecting changes to running applications or processes on your devices, changes in configuration of your devices, remote logins, or any other application-specific behavior.\nIn this blog post, you will learn the steps involved in monitoring security metrics specific to your IoT application. As an IoT administrator, you\xe2\x80\x99ll be able to set up security profiles to define the expected behavior of your devices based on custom metrics, monitor behavior patterns, and receive alerts when devices violate the expected behavior. AWS IoT Device Defender custom metrics give you the flexibility to monitor operational health and security metrics that are unique to your device fleet or use case and enable you to respond to issues in a timely manner. It\xe2\x80\x99s easy to configure and use on devices which connect to AWS IoT Core and helps you improve the security posture of your IoT devices and system. Understanding the state of your devices is important for ensuring the reliability, security, health and performance of your IoT system. Device monitoring can provide the information you need to help your development and operations teams react to issues. It can help you understand your IoT system\xe2\x80\x99s state using a predefined set of metrics and custom metrics. We will now show you how to create a sample custom metric to monitor for changes in processes running on an IoT device.\nSolution overview and use case\nFor the purposes of this post, let\xe2\x80\x99s assume:\nYou are building a Linux-based device. Let\xe2\x80\x99s call this device mything1\nYou have authored an application myapp that performs all the business operation in the device.\nYou have identified that since myapp is communicating over the network, monitoring myapp\xe2\x80\x98s behavior is important. From a process behavior perspective, you know that myapp should never launch a child process. For example, launching a child process such as a shell that\xe2\x80\x99s controlled by an unauthorized user to execute arbitrary commands or a crypto-miner for mining cryptocurrency using the device\xe2\x80\x99s compute resources, are common indicators of compromise. With this context in mind, we will build a solution for monitoring the number of child processes launched by myapp and receive alerts from AWS IoT Device Defender when myapp launches any new process.\nSolution prerequisites\nAWS account\nYou can use the AWS IoT quick connect guide to register a thing, apply policies, attach certificates and download the sample device agent. Choose Python SDK for the AWS IoT Device SDK under step 2 of the above guide.\nAWS IoT Device Defender Agent SDK (Python)\nA computer with the latest browser \xe2\x80\x93 like Firefox or Chrome\nBasic understanding of Linux (e.g. create directories, set file permissions) and programming (compiling code)\nNote: You will find code screenshots to indicate where code additions need to be made in the existing AWS IoT Device Defender Agent SDK\nSolution architecture\nSolution walkthrough\nCloud-side changes\n1.     Create a custom metric representing the number of child processes of myapp:\na. Go to the Device Defender Detect Metrics section \xe2\x80\x93 Under AWS IoT on the left panel under Detect click Metrics.\nb. Click Create beside custom metrics.\nc. In the definition section, specify the name, a description and number as the metric type:\nd. Successful custom metric creation:\n2. Create security profile\na. Go to the Security profiles section, under the Detect drop down select Security Profiles\nb. Under Create Security Profile click on \xe2\x80\x9cCreate Rule-based anomaly Detect profile\xe2\x80\x9d\nc. Since we know that myapp should never launch a child process, you should define the expected behaviors by picking the Metric as: Number of Child Processes of myapp and setting the expected value to be less than or equal to 0:\nd. Also, add your custom metric by clicking the drop down \xe2\x80\x9cAdditional Metrics to retain\xe2\x80\x9d:\ne. Click Next. Keep default settings for Alert target section.\nf. Click Next. Attach Security profile to All things, if this rule is a fleet-wide expectation. Please note that you have the option to pick specific thing groups to apply this profile too.\ng. Click Next. Click Save and re-check all settings then click continue.\nh. The Security profiles page should list your newly created security profile:\n3. First check you are in the right region. Then update the IoT policy in the AWS IoT Policies page to allow Device Defender metrics scoping the privileges to things prefixed by mything1 only.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Publish"",\n        ""iot:Receive""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:eu-west-1:111122223333:topic/$aws/things/mything1/*""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Subscribe""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:eu-west-1:111122223333:topicfilter/$aws/things/mything1/*""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Connect""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:eu-west-1:111122223333:client/mything1""\n      ]\n    }\n  ]\n}\nJSON\nDevice-side change\n1. Download sample agent from Github:\ngit clone https://github.com/aws-samples/aws-iot-device-defender-agent-sdk-python.git\nGit\n2. Structure of the sample agent:\na. collector.py is the Python module responsible for\ni. Collecting metrics that you\xe2\x80\x99re interested in, in this case: the number of child processes of myapp. Note that the collection of metrics occurs at intervals defined by the command line argument: -i\nii. It formats the collected metrics in the format required by AWS IoT Device Defender Detect using the metrics.py module. metrics.py uses the tags.py module to specify the metric name to be sent to AWS IoT Device Defender Detect\nb. agent.py is the high-level module that combines the collector and the awsiot SDK used for communicating with AWS IoT\n3. Modify tags.py to include a new metric as a property of the class Tags:\n@property\ndef num_child_processes(self):\n    return ""num_child_procs_myap\nPython\n4. Modify metrics.py to include num_child_processes:\na. Update the constructor function (init) to set a default value: self.num_child_processes = []\nb. Create a member function of class Metrics to set up your metric for sending over the network\ndef add_num_child_processes(self, num_child_processes):\n    self.num_child_processes = {""number"": num_child_processes}\nPython\nc. Lastly, convert the metric to the previously specified Tag property in the member function _v1_metrics:\nif self.num_child_processes:\n    report[t.custom_metrics] = {t.num_child_processes: [self.num_child_processes] }\nPython\n5. Update collector.py  to include the functions required for finding the number of child processes of myapp:\na. We will use two functions here:\ni. one for finding the process object representing myapp . This function should be defined outside the collector class\ndef find_process(process_name):\n    # Return the first process object \n    # which matches `process_name` exactly\n    for proc in ps.process_iter():\n        if process_name == proc.name():\n            return proc\nPython\nii. one as a staticmethod member function of class Collector for finding myapp\xe2\x80\x98s child processes:\n@staticmethod\ndef get_num_child_processes(metrics):\n    process_name = ""myapp""\n    my_process = find_process(process_name)\n    num_child_processes = 0\n    if my_process:\n        num_child_processes = len(my_process.children(recursive=True))\n    metrics.add_num_child_processes(num_child_processes)\nPython\nb. In the member function collect_metrics, add a line to call get_num_child_processes if custom_metrics are enabled\n          c.if self._use_custom_metrics:\n self.get_num_child_processes(metrics_current)\n6. Install the package: pip install ./aws-iot-device-defender-agent-sdk-python --upgrade\n7. Test by running collector.py module independently just to ensure that there are no errors:\na. Note that I have passed the command line argument: -cm here to enable custom metrics collection\nb. Create a fake myapp by creating a copy of your current shell and renaming it to myapp:\n                       i. cp `which sh` ./myapp\n ii. Launch myapp: ./myapp\n                      iii.     Launch a long running process like cat that will wait for user input: cat\n8. Run agent.py to continuously monitor the number of process spawned by myapp with the required parameters, in addition to -cm (For enabling custom metrics):\npython aws-iot-device-defender-agent-sdk-python/AWSIoTDeviceDefenderAgentSDK/agent.py -f json -e <your-endpoint> -r <root_cert_path> -c <cert_path> -k <private_key_path> -cm -id mything1\nPython\n9. You should shortly be able to view the number of child processes of myapp by navigating to the Defender Metrics tab in the Things page (recheck you are in the right AWS region):\n10. You should also be able to see any alarms generated in case there are any violations:\n'"
96,How BISSELL migrated a million vacuum devices to a scalable IoT Platform on AWS,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-bissell-migrated-a-million-vacuum-devices-to-a-scalable-iot-platform-on-aws/,"b'This post was co-authored by Ramesh Chinnasamy, Principal Lead, IoT at AWS; John Rotach, Sr. Application Architect at AWS; and Mike Ply, Associate Director, IoT at BISSELL\nConsumers in countries around the world are finding value in connected vacuum cleaners to tackle life\xe2\x80\x99s everyday messes. As part of the Internet of Things (IoT), connected vacuums provide consumers enhanced functionality, value, and cleaning performance. Vacuum connectivity gives consumers the ability to remotely control and customize vacuum cleaner operations such as starting, stopping, or scheduling cleaning, tracking location, monitoring usage and battery charge, and overall enables an improved cleaning process.\nBISSELL is a family-owned business with over 145 years crafting premium cleaning products that exceed consumer expectations. BISSELL offers a full range of floor care and air treatment products. Connected vacuum cleaners \xe2\x80\x93 particularly robotic vacuums \xe2\x80\x93  are a growing segment of their business. BISSELL has 1 million registered vacuum devices in their existing IoT Platform powered by AWS IoT, and currently 25% of those devices are connected in the field. With increasing adoption of connected vacuum cleaners around the world, BISSELL is expecting 1 million devices to be connected in the field in the near future. BISSELL wanted to ensure its IoT platform could scale with this rapid expected growth across product categories.\nIn this blog, we discuss BISSELL\xe2\x80\x99s IoT platform and how BISSELL teamed up with AWS Professional Services and TensorIoT to create a scalable, high-performing, and cost-effective IoT platform in preparation for onboarding products and bringing new products to market.\nPlatform challenges\nPrior to working with AWS Professional Services, BISSELL built an IoT platform on AWS with various tradeoffs discussed below. They used this platform to perform end-to-end device management using a wi-fi + cloud + app strategy as shown in the image below.\nBISSELL built the platform using solutions from various providers but had challenges when trying to innovate and add features including:\nSolutions acquired through various partners limited opportunity for the BISSELL development team to \xe2\x80\x9cown\xe2\x80\x9d the platform.\nLimited visibility and traceability of device connection and data flow inefficiencies within the system.\nOperational and performance issues with running over 450 lambdas to support data transformation and data flow within the system.\nLack of data governance and data inconsistencies when storing device data to Amazon DynamoDB.\nLimited automated testing for platform integration.\nBISSELL engaged with AWS Professional Services and TensorIoT to help address these challenges and bring frameworks and best practices to:\nDecrease time to onboard devices to the platform.\nIncrease the stability of system.\nSimplify data analysis.\nImprove API response time and overall performance of BISSELL\xe2\x80\x99s OT systems.\nImprove device pairing success rate.\nImprove monitoring and logging to reduce production downtime.\nImprove troubleshooting of issues.\nImprove automated testing.\nOptimize usage of AWS capabilities.\nSolution walkthrough\nBISSELL, AWS Professional Services and TensorIoT migrated the existing production platform to a new platform developed using Connected Device Framework (CDF). They began by working backwards from the problems, developed a minimum viable product (MVP) feature set, and migrated only what was necessary to have a solid base of CDF services and other microservices to prove out scalability and agility. They repeated this process in subsequent phases by iterating on the base services and worked backwards to add necessary functionalities. Adding minimum security guardrails and optimizing cost and performance were also key focus areas in these phases. These migration strategies and deployment procedures created a seamless customer experience with minimal to no downtime.\nPhase 1 : Building baseline architecture to meet scalability and agility\nThe phase 1 goal was to put baseline components into place and build upon these components to implement an MVP feature set, which are common to all BISSELL connected device product categories and sufficient to operate a basic BISSELL device end-to-end. These MVP features were:\nDevice pairing \xe2\x80\x93 allowing a user to pair a connected device with their account using the BISSELL mobile application.\nData ingestion \xe2\x80\x93a data ingestion pipeline that allows the platform to consume data such as device cleaning schedules and fluid usage.\nData history \xe2\x80\x93 data storage and an API that allows users to view device history and metrics.\nThe team started by working backwards from the existing IoT backend system, diving deep to determine which features were essential in the new platform and which were unused or incomplete. Then, they produced an architecture which met the needs of the platform in the near-term but could also be extended for future use cases.\nThey first deployed foundational components from Connected Device Framework (CDF), including the Asset Library and Provisioning microservices. Next, they did upfront work to connect BISSELL\xe2\x80\x99s CI/CD system, which was key for the team to develop quickly.\nIn 3 months, the team completed development and replicated the MVP features called out above in the new platform. Keys to the team building the full MVP features in this time were:\nIncorporating baseline functionality \xe2\x80\x9cout of the box\xe2\x80\x9d from CDF.\nA modular architecture with minimal interdependency between components.\nDeep understanding and accompanying documentation produced from deep-dive sessions around existing platform.\nIncreased developer productivity attributed to the ability to stand up and run individual components locally on developer laptops.\nA clean, well-understood and documented new code base.\nPhase 2: Iterate feature set and optimize performance\nThe phase 2 goal was to build upon the MVP feature set, adding in features required by BISSELL\xe2\x80\x99s more complex connected products. These features included:\nCommand and control \xe2\x80\x93 ability for users to start and stop device cleaning schedules.\nDevice scheduling \xe2\x80\x93 ability for users to create cleaning schedules with the platform commanding cleaning schedules based on these schedules.\nAlong with the above features, the team needed to bring in other existing functionalities such as the complete suite of mobile APIs, device APIs, and the device management portal to enable the entire fleet to migrate to the new platform.\nFollowing the phase 1 blueprint, the team worked backwards from problems and held deep-dive sessions to understand functionality in the existing platform to determine what features to replicate in the new platform. By leveraging the productivity improvements realized in phase 1, the team also completed the phase 2 implementation in 3 months and was ready to begin full-platform testing and migration.\nOther key non-functional features implemented  in the new platform:\nImplementation of best practices across the entire code base in areas of security and monitoring and logging across all microservices.\nVisibility into feature usage and correlation with costs.\nAbility to auto deploy copies of the entire platform stack to other environments (development and test sandboxes).\nFully automated testing that included unit tests, integration tests (e.g. identity server interaction tests and API pairing tests to ensure correct writing of data to Amazon DynamoDB), and system tests (e.g. simulate actual user behavior at an HTTP level) to verify no deterioration in functionality and to ensure interactions between modules worked as expected.\nPhase 3: Migrating the fleet with zero downtime\nMigrating over 1 million registered IoT devices to a new cloud architecture is complex. Working with AWS Professional Services, BISSELL reviewed 3 options for migration:\nIterative deployment: deploy CDF features as they are completed.\nCoordinated big-bang deployment: deploy the new mobile application, device firmware, and cloud solution at the same time.\nCloud big-bang deployment: deploy the cloud solution as one complete deployment.\nEach solution posed different risks, complexities, feasibility, costs, and timelines. The team collaborated closely to arrive at a balanced solution that best meet the needs of BISSELL.\nThe team decided to move ahead with the cloud big-bang deployment. They would address remaining tech debt in post go-live activities. BISSELL went live with the new platform with zero down time for consumers and their call centers received zero calls on issues related to going live.\n'"
97,How the University of Technology Sydney is transforming stroke rehabilitation with biomedical robots and AWS IoT,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-the-university-of-technology-sydney-is-transforming-stroke-rehabilitation-with-biomedical-robots-and-aws-iot/,"b'Introduction\nIn this blog, we discuss how University of Technology Sydney (UTS) took on the challenge of at-home rehabilitation for stroke patients using biomedical engineering and robotics, and AWS solutions such as AWS Internet of Things (IoT).\nStroke is the third most common cause of death in Australia and a leading cause of disability according to the Australian Brain Foundation. A stroke occurs when blood clots or broken blood vessels cut off the blood supply to the brain.\nRehabilitation helps someone who has had a stroke relearn skills that are lost when part of the brain is damaged. The goal of rehabilitation is to improve or restore speech, cognitive, motor, or sensory skills.\nMost patient rehabilitation programs are delivered as inpatient, outpatient, or at skilled nursing facilities. These delivery methods are expensive, can mean absences from home, or require patients to travel long distances.\nAt-home rehabilitation solves some of the obstacles of facility-based programs but there are other challenges with these programs such as the need for expensive, specialised equipment, lack of real time monitoring, and immediate therapist feedback.\nStudents at the School of Biomedical Engineering at UTS decided to use robotics and cloud technology to overcome the challenges of at-home rehabilitation. Their goals were to deliver a low-cost solution which provides therapeutic movement training, with real time remote monitoring and feedback capability.\nImproving at-home rehabilitation with Franky, a robotic exoskeleton arm\nThe UTS solution is \xe2\x80\x9cFranky,\xe2\x80\x9d a robotic exoskeleton arm made of 171 carbon-reinforced pieces printed at the UTS \xe2\x80\x93 ProtoSpace. Franky is combined with a host of sensors connected to a touchscreen interface with wireless communication capabilities.\nFranky is worn as an exoskeleton that provides physical assistance to guide patients through therapeutic movements. Patients can use Franky without rehabilitation experts needing to be physically present. The exoskeleton\xe2\x80\x99s sensors can read the patient\xe2\x80\x99s movements by measuring the brain\xe2\x80\x99s electrical signals. Franky then relays this data to rehabilitation experts who can provide real-time feedback.\nFranky can detect if they are not performing exercises correctly and will demonstrate the correct way to perform these movements.\n\xe2\x80\x9cWe\xe2\x80\x99re using an industrial level communication interface that can receive around 100 different inputs and process them with machine learning,\xe2\x80\x9d says Kairui Guo, Chief Technology Officer of the program\nSeeing Franky in action\nTo control Franky, the biomedical engineering team uses a Raspberry Pi, as it provides high performance edge computing at low cost. AWS IoT Core connects the Raspberry Pi to the cloud and collects near-real time data as the patient exercises, sending the information to Amazon Simple Storage Services (S3). The data loads using Amazon Kinesis Data Firehose, a simple and reliable way to load streaming data into S3.\nIf you want to see more of Franky refer to this video  \xe2\x80\x93 https://youtu.be/IA0myITVreg\nA fast retrieval database is critical for the rehabilitation experts to access the data that patients generate during rehabilitation. Amazon DynamoDB  provides fast, flexible NoSQL database services at single-digit millisecond performance at any scale. Rehabilitation experts can monitor and communicate with a patient from anywhere in the world using a website hosted on S3 and Amazon CloudFront for low latency content delivery.\nThe following diagram provides a high-level overview of the AWS services used:\n'"
98,5 tips to build AWS IoT Greengrass v2 Components,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/5-tips-to-build-aws-iot-greengrass-v2-components/,"b'AWS IoT Greengrass v2, announced on December 2020, is an open source edge runtime service that you can use to build, deploy and manage edge software components and locally act on the data that your intelligent IoT devices capture. For example, you can run data prediction machine learning models, filter and aggregate device data as you desire, and use pre-built software components, features, and tools to effectively manage your device fleets at scale.\nWith AWS IoT Greengrass components, which consist of application and runtime libraries, you can develop custom applications, test and deploy them on your AWS IoT Greengrass core device \xe2\x80\x93 giving you more flexibility over AWS IoT Greengrass v1. Additionally, components can run outside of containers (new in 2.0), which allows you to work directly with local resources on your core devices. Also, in AWS IoT Greengrass v1, AWS Lambda functions define the software that runs on core devices while in AWS IoT Greengrass v2, components can consist of any software application you define.\nEvery component is composed of a recipe and artifacts. The recipe file defines the component\xe2\x80\x98s metadata. This includes the component\xe2\x80\x99s configuration parameters, component dependencies, lifecycle, and platform compatibility. The lifecycle defines the commands to install, run, and shut down the component. The recipe can be defined in YAML and JSON format. Artifacts are optional and consist of component binaries and may include scripts, compiled code, static resources, and any other files that a component consumes.\nIn this post, we are sharing 5 tips for you to consider while developing AWS IoT Greengrass v2 components. These tips and insights may help you define mechanisms for structuring AWS IoT Greengrass components. Also, this process helps you accelerate and improve your development workflow and get started more quickly with the component development.\nThe prerequisites for following this post are:\nYou have a fully functional AWS user account. For set up instructions, refer to our documentation.\nYou have a machine with AWS IoT Greengrass installed and fully operational. If you haven\xe2\x80\x99t done this yet, follow the installation instructions.\nLet\xe2\x80\x99s get started.\n1) Use Command Line Interface (CLI) commands\nDuring component development, there are a few CLI commands that give you quick and easy insights into the current status of AWS IoT Greengrass Core software and your components. All the commands in this blog post are for Linux or Unix based systems. If you use a different operating system, adjust those accordingly.\nBy default, the AWS IoT Greengrass Core software writes logs to only the local file system. You can view file system logs in real time to debug your AWS IoT Greengrass components. There are two log types that are especially important:\nThe AWS IoT Greengrass Core software log file. It contains real-time information about components and deployments. This is the first place to look when you start a deployment and want to know what is going on. The errors in the log file then might help you troubleshoot. Since the directory of the log-files is owned by root, we use sudo to access those files.\n$ sudo tail -F /greengrass/v2/logs/greengrass.log\nBash\n2.     AWS IoT Greengrass component log files. These files contain real-time information about the corresponding component that runs on the device. Generic and Lambda components write standard stdout and stderr to these log files, with your own components you can use these functionalities according to your needs.\n$ sudo tail -F /greengrass/v2/logs/<component-name>.log\n# Concrete example: Your component is named ggv2.custom-comp.logging\n$ sudo tail -F /greengrass/v2/logs/ggv2.custom-comp.logging.log\nBash\nTo get better insights into components and their status, there are some very useful AWS IoT Greengrass CLI commands to list and restart components. Before you can use the commands, you need to install the AWS IoT Greengrass CLI first (follow the instructions later in this Blog to do so). The list command gives you an output of component\xe2\x80\x99s name, its version, and its current state.\n$ sudo /greengrass/v2/bin/greengrass-cli component list\nComponents currently running in Greengrass:\nComponent Name: FleetStatusService\nVersion: 0.0.0\nState: RUNNING\nConfiguration: {""periodicUpdateIntervalSec"":86400.0}\nComponent Name: UpdateSystemPolicyService\nVersion: 0.0.0\nState: RUNNING\nConfiguration: null\nComponent Name: aws.greengrass.Nucleus\nVersion: 2.0.0\nState: FINISHED\nConfiguration: {""awsRegion"":""region"",""runWithDefault"":{""posixUser"":""ggc_user:ggc_group""},""telemetry"":{}}\nComponent Name: DeploymentService\nVersion: 0.0.0\nState: RUNNING\nConfiguration: null\nComponent Name: TelemetryAgent\nVersion: 0.0.0\nState: RUNNING\nConfiguration: null\nComponent Name: aws.greengrass.Cli\nVersion: 2.0.0\nState: RUNNING\nConfiguration: {""AuthorizedPosixGroups"":""ggc_user""}\nBash\nWhen you restart a component, the core device uses the latest changes.\n$ sudo /greengrass/v2/bin/greengrass-cli component restart \\\n--names ""<component-name>""\n# Concrete example: Your component is named ggv2.custom-comp.logging-1.0.1\n$ sudo /greengrass/v2/bin/greengrass-cli component restart \\\n--names ""ggv2.custom-comp.logging-1.0.1""\nBash\nYou can get more insights for monitoring AWS IoT Greengrass logs, how to enable logging those to Amazon CloudWatch, as well as useful AWS IoT Greengrass CLI commands.\n2) Develop components locally\nFor a great experience while developing components, we recommend doing so locally and then creating the component in the cloud to deploy to your AWS IoT Greengrass Core devices. Let\xe2\x80\x99s go through a simplified development process for our example component ggv2.custom-comp.logging. We can use this developed component later on to publish to the cloud and deploy to core devices.\nA/ Folder structure\nLets look at the sample folder structure used thoughout this blog post for our sample component ggv2.custom-comp.logging:\n~                                           <-- Your environment\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 GreengrassDev/\n\xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 deployment.json\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 components\n\xe2\x94\x82       \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 ggv2.custom-comp.logging\n\xe2\x94\x82           \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 recipes\n\xe2\x94\x82              \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 ggv2.custom-comp.logging.yaml\n\xe2\x94\x82           \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 artifacts\n\xe2\x94\x82              \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 ggv2.custom-comp.logging\n\xe2\x94\x82                 \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 1.0.0\n\xe2\x94\x82                    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 src\n\xe2\x94\x82                       \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 script.py\n\xe2\x94\x82                    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 main.py\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 GreengrassCore                          <-- GreengrassCore installation\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 README.md\nBash\nNext to the GreengrassCore directory, which gets created during installation of the AWS IoT Greengrass Core software, we create a GreengrassDev directory with the subdirectory components, which contains the folders recipes and artifacts. For our artifacts, it is important that the structure adheres to artifacts/<componentName>/<componentVersion>.\nB/ First deployment including AWS IoT Greengrass CLI\nTo make use of the AWS IoT Greengrass CLI, we have to create a deployment.json file with the following content:\n{\n   ""targetArn"": ""arn:aws:iot:<region>:<account-id>:thing/<thing-name>"",\n   ""deploymentName"": ""gg-iot-ggv2-bp-deployment"",\n   ""components"": {\n      ""aws.greengrass.Nucleus"": {\n         ""componentVersion"": ""2.9.3""\n      },\n      ""aws.greengrass.Cli"": {\n         ""componentVersion"": ""2.9.3""\n      }\n   }\n}\nJSON\nReplace the placeholders for your region, account, and thing-name with your actual values. In the following examples, we assume the region is eu-central-1, the account-id is 123456789 and the name of the core device is aws-iot-ggv2-bp-core. You also have the possibility to target groups of core devices in your deployment, which makes it easy to keep software on multiple devices up to date, which is one of the features launched with AWS IoT Greengrass v2 to improve the customer experience. So in the deployment.json file, the targetArn can point to the Amazon Resource Name (ARN) of a thing or a group.\nTo create a deployment to the cloud, we use the AWS CLI:\n$ aws greengrassv2 create-deployment --cli-input-json file://deployment.json\nBash\nCheck in the Console (or Logs) to see if the deployment was successful.\nC/ Development helpers: environment variables and functions\nLet\xe2\x80\x99s define all the important aspects around our component, its version, and folder structure:\n$ export COMPONENT_NAME=""ggv2.custom-comp.logging""\n$ export COMPONENT_VERSION=""1.0.0""\n$ export RECIPE_DIR=""~/GreengrassDev/components/${COMPONENT_NAME}/recipes""\n$ export ARTIFACT_DIR=""~/GreengrassDev/components/${COMPONENT_NAME}/artifacts""\nBash\nTo simplify our local development process, we create two helper functions. Helper function gg_deploy takes the exported variables and creates a deployment for our specified COMPONENT_VERSION. The second helper function gg_delete, deletes any previously deployed component-version. Instead of updating the versions with every new deployment, we delete the previously deployed component-version with this function, which allows us to deploy the new version using the same specified COMPONENT_VERSION thereafter. In both functions we use the AWS IoT Greengrass CLI deployment create commands with different parameters.\n#Deploy-Helper-Function\n$ gg_deploy(){\nsudo /greengrass/v2/bin/greengrass-cli deployment create \\\n--recipeDir $RECIPE_DIR --artifactDir $ARTIFACT_DIR \\\n--merge ""$COMPONENT_NAME=$COMPONENT_VERSION"";\n}\n\n#Remove-Helper-Function\n$ gg_delete(){\nsudo /greengrass/v2/bin/greengrass-cli --ggcRootPath /greengrass/v2 deployment create \\\n--remove ""$COMPONENT_NAME"";\n}\nBash\nLet\xe2\x80\x99s have a look into the files in our artifacts (~/GreengrassDev/components/artifacts/ggv2.custom-comp.logging/1.0.0) folder, which are our main.py and the script.py, which is placed in our src folder. The code in script.py looks like this (this is a simplified example):\nimport datetime\nimport time\n\ndef loopfunction():\n    while True:\n        message = f""Hello! Current time: {str(datetime.datetime.now())}.""\n    \n        # Print the message to stdout.\n        print(message)\n        \n        time.sleep(1)\nPython\nAs well as our main function in main.py:\nimport sys\nimport src.script as helloworld\n\ndef main():\n    helloworld.loopfunction()\n\nif __name__ == ""__main__"":\n    main()\nPython\nAlso, the content of your recipe file ggv2.custom-comp.logging.yaml is:\n---\nRecipeFormatVersion: ""2020-01-25""\nComponentName: ""{COMPONENT_NAME}""\nComponentVersion: ""{COMPONENT_VERSION}""\nComponentDescription: ""Sample Component""\nComponentPublisher: ""Me""\nManifests:\n  - Platform:\n      os: linux\n    Lifecycle:\n      Run: ""python3 -u {artifacts:path}/main.py""\nYAML\nAn example process for our component, with two changes that happen incrementally, could look like this:\n# Substitute the right component name and version into the recipe file\n$ sed -i \'s/{COMPONENT_NAME}/\'""$COMPONENT_NAME""\'/g\' $RECIPE_DIR/$COMPONENT_NAME.yaml\n$ sed -i \'s/{COMPONENT_VERSION}/\'""$COMPONENT_VERSION""\'/g\' $RECIPE_DIR/$COMPONENT_NAME.yaml\n# Deploy-Helper-Function\n$ gg_deploy\n# Do changes to the script.py\n$ gg_delete\n$ gg_deploy\n# Do changes to the script.py and the recipe file\n$ gg_delete\n$ gg_deploy\n# Once we are done and happy with our developed version, we can deploy using the cloud\n# I recommend using a last gg_delete to avoid a mismatch in versions\n$ gg_delete\nBash\nThis concludes the segment on local development. We create the component in the cloud and deploy it to the core devices.\n3) Create the component in the cloud and deploy to core devices using the AWS IoT Greengrass Development Kit (GDK)\nTo ease the development process for custom components, AWS published the AWS IoT Greengrass Development Kit (GDK) CLI, which is available open source under the Apache-2.0 license. It helps you create, build, and publish custom components. Refer to the links for the prerequisites when using the AWS GDK CLI, as well as the installation process.\nLet\xe2\x80\x99s look at the development process here. To get started, either use a template or a community component. In our case, we use helper functions and environment variables to use our previously created local component as basis for building and publishing the component with the GDK. The AWS IoT GDK CLI updates the version and artifact URIs for you each time you publish a new version of the component.\n#Prepare-GDK-Helper-Function\n$ gg_gdk_prepare(){\nmkdir -p $RECIPE_DIR/../greengrass-gdk-prepare/$COMPONENT_NAME && cd ""$_""\ncp -a $ARTIFACT_DIR/$COMPONENT_NAME/$COMPONENT_VERSION/. .\n\ncp -a $RECIPE_DIR/$COMPONENT_NAME.yaml ./recipe.yaml\nsed -i \'s/\'""$COMPONENT_VERSION""\'/{COMPONENT_VERSION}/g\' recipe.yaml\nsed -i \'s/{artifacts:path}/{artifacts:decompressedPath}\\/\'""$COMPONENT_NAME""\'/g\' recipe.yaml\n\ntouch gdk-config.json\n}\n# Execute the function\n$ gg_gdk_prepare\nBash\nBefore creating the component, we now need to update the recipe file to point to the Amazon S3 bucket by adding the Artifacts section to the Manifest-part of the recipe.yaml file:\n---\nRecipeFormatVersion: ""2020-01-25""\nComponentName: ""ggv2.custom-comp.logging""\nComponentVersion: ""{COMPONENT_VERSION}""\nComponentDescription: ""Sample Component""\nComponentPublisher: ""Me""\nManifests:\n  - Platform:\n      os: linux\n    Artifacts:\n      - URI: ""s3://BUCKET_NAME/COMPONENT_NAME/COMPONENT_VERSION/ggv2.custom-comp.logging.zip""\n        Unarchive: ZIP\n    Lifecycle:\n      Run: ""python3 -u {artifacts:decompressedPath}/ggv2.custom-comp.logging/main.py""\nBash\nFinally, let\xe2\x80\x99s copy the following code into the  gdk-config.json file. Replace all the PLACEHOLDER with the actual values:\n{\n  ""component"": {\n    ""<PLACEHOLDER_COMPONENT_NAME>"": {\n      ""author"": ""Me"",\n      ""version"": ""NEXT_PATCH"",\n      ""build"": {\n        ""build_system"": ""zip""\n      },\n      ""publish"": {\n        ""bucket"": ""<PLACEHOLDER_BUCKET>"",\n        ""region"": ""<PLACEHOLDER_REGION>""\n      }\n    }\n  },\n  ""gdk_version"": ""1.0.0""\n}\nBash\nAlternatively, export the region and bucket to environment variables and then use the gg_gdk_substitute function:\n#Existing S3 bucket that GDK uploads the artifacts to\n$ export BUCKET_NAME=""ggv2-blogpost-XXXXXXXXXX""\n$ export REGION=""eu-central-1""\n\n#Prepare-GDK-Helper-Function\n$ gg_gdk_substitute(){\nsed -i \'s/<PLACEHOLDER_COMPONENT_NAME>/\'""$COMPONENT_NAME""\'/g\' gdk-config.json\nsed -i \'s/<PLACEHOLDER_BUCKET>/\'""$BUCKET_NAME""\'/g\' gdk-config.json\nsed -i \'s/<PLACEHOLDER_REGION>/\'""$REGION""\'/g\' gdk-config.json\n}\n\n#Run the function\n$ gg_gdk_substitute\nBash\nNext step is to run the build (gdk component build) and publish (gdk component publish) commands, which results in the component being published as custom component to your own AWS account. For more detailed instructions and explanations, visit the documentation page. Last step is to deploy the component to our core, for which we use the deployment.json file and the AWS CLI.\n{\n    ""targetArn"": ""arn:aws:iot:eu-central-1:123456789:thing/aws-iot-ggv2-bp-core"",\n    ""deploymentName"": ""gg-iot-ggv2-bp-deployment"",\n    ""components"": {\n        ""aws.greengrass.Nucleus"": {\n            ""componentVersion"": ""2.9.3""\n        },\n        ""aws.greengrass.Cli"": {\n            ""componentVersion"": ""2.9.3""\n        },\n        ""ggv2.custom-comp.logging"": {\n            ""componentVersion"": ""1.0.0""\n        }\n    }\n}\nJSON\n$ aws greengrassv2 create-deployment --cli-input-json file://~/GreengrassDev/deployment.json\nBash\nFeel free to monitor the status of your deployment by trailing the log files and listing all running components.\nIf you get an PackageDownloadException with the reason Failed to head artifact object from S3, you need to adjust the Permission of your Role Alias (The Role Alias needs read-permissions for your S3 bucket that stores the artifact-files). For more details refer to Section 4 of this blog post.\n4) Understand permissions within AWS IoT Greengrass v2\nThere are three important aspects regarding permissions that you need to be aware of:\nThe AWS IoT Role Alias: Used when the AWS IoT Greengrass Core and deployed components interact with services outside of AWS IoT.\nInterprocess Communication (IPC) Authorisation for components when they want to interact with the nucleus and other AWS IoT Greengrass components.\nThe Thing and attached Certificate of the AWS IoT Greengrass Core device: Used to specify what the AWS IoT Greengrass Core Thing is allowed to do within AWS IoT. This also includes the permission to assume the AWS IoT Role Alias. To read up on AWS IoT Core policies, visit our documentation.\nSince the first two concepts are specific for AWS IoT Greengrass v2, we go deeper in the next two subchapters.\nA/ AWS IoT Role Alias\nDevices use their X.509 certificates to get temporary AWS credentials by calling the credential provider services, which reduces the need to store AWS access key ID and secret access key ID on the AWS IoT Greengrass core device. The AWS IoT role alias within AWS IoT Core points to the AWS Identity and Access Management (IAM) role that allows AWS IoT Greengrass to communicate with services outside of AWS IoT (Default role alias: GreengrassV2TokenExchangeRoleAlias). For more information, see Authorizing direct calls to AWS services in the AWS IoT Core Developer Guide.\nThe first point where you normally need permissions is when you upload your artifacts to S3 and want to deploy one of your components in the cloud to your device. In order for your device to download the S3 artifacts, the IAM role needs to allow s3:GetObject permissions for the bucket your artifacts got uploaded to. For more detailed information on permissions as well the default allowed operations, check out the documentation on the device service role. If docker is used, you need to additionally grant access to Amazon Elastic Container Registry (ECR).\nB/ Interprocess communication permissions\nIf you want to allow your components to interact with other components, the Greengrass nucleus, or AWS IoT Core, then they need to use Interprocess communication. To do so, the permission for that communication needs to happen on component level within the recipe file.\nThe accessControl section within the recipe may then be extended by blocks concerning the different IPC service identifier:\n{\n  ""accessControl"": {\n    ""<IPC service identifier>"": {\n      ""<unique identifier>"": {\n        ""policyDescription"": ""Allows access to [...]"",\n        ""operations"": [\n          ""<operation 1>"",\n          ""<operation 2>""\n        ],\n        ""resources"": [\n          ""*""\n        ]\n      }\n    }\n  }\n}\nJSON\nFor the different IPC service identifier as well as operations, refer to the documentation. Lets have a look at our component ggv2.custom-comp.logging. Let\xe2\x80\x99s assume that the component wants to publish to an AWS IoT Core cloud topic named dt/sensorA/temperature as well as subscribe to the local topic dt/sensorB/buttonvalue. Then our updated recipe file from before would look like:\n---\nRecipeFormatVersion: ""2020-01-25""\nComponentName: ""ggv2.custom-comp.logging""\nComponentVersion: ""1.0.0""\nComponentDescription: ""Sample Component""\nComponentPublisher: ""Me""\nComponentConfiguration:\n  DefaultConfiguration:\n    accessControl:\n      aws.greengrass.ipc.pubsub:\n        \'ggv2.custom-comp.logging:pubsub:1\':\n          policyDescription: Allows access to subscribe to local topic dt/sensorB/buttonvalue.\n          operations:\n            - \'aws.greengrass#SubscribeToTopic\'\n          resources:\n            - \'dt/sensorB/buttonvalue\'\n      aws.greengrass.ipc.mqttproxy:\n        \'ggv2.custom-comp.logging:mqttproxy:1\':\n          policyDescription: Allows access to publish to local topic dt/sensorB/buttonvalue.\n          operations:\n            - \'aws.greengrass#PublishToIoTCore\n          resources:\n            - \'dt/sensorA/temperature\'\nManifests:\n  - Platform:\n      os: linux\n    Artifacts:\n      - URI: ""s3://BUCKET_NAME/COMPONENT_NAME/COMPONENT_VERSION/ggv2.custom-comp.logging.zip""\n        Unarchive: ZIP\n    Lifecycle:\n      Run: ""python3 -u {artifacts:decompressedPath}/ggv2.custom-comp.logging/main.py""\nYAML\nYou can use wildcards in your accessControl section. Within a specified IPC service identifier, using a *-wildcard in the operation section means that all operations within that IPC service identifier are allows. Same goes for resources: using a wildcard in that section allows the specified operations for all topics. For more detailed information for each IPC service, refer to the documentation.\n5) Understand the process of updating the component configuration\nLet\xe2\x80\x99s have a look at how component configuration updates work. The general configuration updates merge the old configuration with the new ones, which can mean one of the following:\nYou are adding a new key with a new value. This key and value is then added to the existing configuration with the existing fields.\nYou have an existing key, which has a string or number value. If you change that value, the new configuration contains that old key with its new value.\nYou have an existing key, which contains a JSON subelement, where you specify one new value. Then the old key points to the old JSON, which has a new added field, which is your new value.\nTo remove a key from the configuration, you need to use the reset-functionality.\nLets take a simplified example for merging components:\nExisting Configuration Configuration Update Effective Configuration\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n},\n""key2"":""value2""\n}\nJSON\n{\n""key1"":{\n""subkey_1b"":""new_value1b""\n}\n}\nJSON\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""new_value1b""\n},\n""key2"":""value2""\n}\nJSON\nLets look at another example:\nExisting Configuration Configuration Update Effective Configuration\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n},\n""key2"":""value2""\n}\nJSON\n{\n""key1"":""new_string1""\n}\nJSON\n{\n""key1"":""new_string1"",\n""key2"":""value2""\n}\nJSON\nIf you want to delete a component configuration or a subfield, you need to use the reset functionality. You also need to use a JSON pointer to address the fields that you want to reset to default value or delete.\nExisting Configuration Configuration Update Effective Configuration\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n},\n""key2"":""value2""\n}\nJSON\n""configurationUpdate"": {\n""reset"": [""/key2""]\n}\nJSON\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n}\n}\nJSON\nLet\xe2\x80\x99s put this all together in the next example, that combines merge and reset in one configurationUpdate:\nExisting Configuration Configuration Update Effective Configuration\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n},\n""key2"":""value2""\n}\nJSON\n""configurationUpdate"": {\n""reset"": [""/key1/subkey_1a""],\n""merge"": ""{\\""key3\\"":\\""value3\\""}\n}\nJSON\n{\n""key1"":{\n""subkey_1b"":""value1b""\n},\n""key2"":""value2"",\n""key3"":""value3""\n}\nJSON\nIf we want to do a full reset of the entire configuration, we need to specify a single empty string as the reset update:\nExisting Configuration Configuration Update Effective Configuration\n{\n""key1"":{\n""subkey_1a"":""value1a"",\n""subkey_1b"":""value1b""\n},\n""key2"":""value2""\n}\nJSON\n""configurationUpdate"": {\n""reset"": [""""]\n}\nJSON\n{}\nJSON\nIf you want to know more about this, refer to the developer guide on merge updates.\nClean up\nTo uninstall the AWS IoT Greengrass Core software and delete the core device from the AWS IoT Greengrass service, follow the instructions in the documentation.\n'"
99,Digital Twins on AWS:  Unlocking business value and outcomes,b'Adam Rasheed',2022-04-20T20:17:30+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/04/04/DigitalTwin.jpg,https://aws.amazon.com/blogs/iot/digital-twins-on-aws-unlocking-business-value-and-outcomes/,"b'Every day, we hear from our customers about the desire to implement Digital Twins to improve operations, product offerings, and business value delivered to their own end customers. The concept of twins is not new and dates back to the early days of the space program. The Apollo 13 mission in the 1960s is an early use case of using twins to model the state of the damaged spacecraft and solve the problems necessary to return the astronaut crew safely back to Earth. In more recent times, the core ideas of Digital Twin as applied to product lifecycle management (PLM) are commonly attributed to Grieves who developed the concept throughout the 2000s, and Vickers who coined the term Digital Twin in 2010. Customers today are seeking to deploy Digital Twins across a broad range of applications including engineering design of complex equipment, 3D immersive environments, preventive maintenance, operations of industrial facilities, precision medicine, digital agriculture, manufacturing, city planning, and most recently metaverse-type applications.\nA challenge, however, is that the term Digital Twin is often applied broadly to describe any virtual model, inclusive of traditional methods such as engineering simulations, CAD models, IoT dashboards, or gaming environments. This has caused confusion for customers who are left pondering how simply renaming existing methods will drive new business value. To clarify, Digital Twins are more than just a new marketing term for legacy methods, but rather a new technology that has only become feasible in the past few years with the convergence of at-scale computing, modeling methods, and IoT connectivity. As you embark on your Digital Twin journey, the first place to start is to understand what a Digital Twin is, how to integrate existing modeling methods into Digital Twins, and how to work backwards from your business use case to deploy the correct technology for your solution.\nTo help customers navigate this space, we developed a framework that enables practitioners to understand their use cases and achieve the business value they are seeking. The first part of this framework is a concise definition of Digital Twin, and the second is a leveling index to help customers categorize their use case and understand the services, technologies, data, and models needed to build and deploy their Digital Twin at scale.\nIn this first part of our blog series, we will focus on our definition and leveling index for discussing Digital Twins along with example use cases for each of the levels. Subsequent blogs will demonstrate each of the levels in detail by working through an example of an electric vehicle.\nDefining Digital Twin\nIn understanding our customers\xe2\x80\x99 interpretations of Digital Twins, we found a range of concepts including analysis of a single physical component, predictive maintenance for a piece of equipment, performance optimization of a process, 3D virtual walkthroughs of a factory with automated operations, and everything in between. What these ideas all have in common is that a Digital Twin consists of a digital representation of something in the physical world, is updated with live data, and drives business outcomes. With this backdrop, we define Digital Twin as follows:\nA Digital Twin (DT) is a living digital representation of an individual physical system that is dynamically updated with data to mimic the true structure, state, and behavior of the physical system, to drive business outcomes.\nThe four key elements of a Digital Twin are the physical system, the digital representation, the connectivity between the two, and the business outcome. The first element, the physical system itself, can be an individual physical entity, an assembly of physical entities, a physical process, or even a person. It also doesn\xe2\x80\x99t have to be an industrial system, as it could be biological, chemical, ecological, or any other system. The second is the digital representation which is the model itself. In this case, by model, we don\xe2\x80\x99t mean just a collection of data such as a data model, which is needed to represent the structure (or configuration) of the physical system, or an IoT data dashboard, which is helpful to represent the current state of the physical system. We mean a model that emulates the behavior of the physical system, such as a simulation, so that when you give it an input, the model returns a response output. This leads to the third element, connectivity, which is emphasized by the reference to \xe2\x80\x9cliving.\xe2\x80\x9d The model must be regularly updated with data from the physical system (say, from sensors) to be a Digital Twin. A validated model provides a snapshot of behaviour of the physical system at a moment in time, but a Digital Twin extends the model to timescales where the physical system\xe2\x80\x99s behaviour changes significantly from the original time. The frequency of the updates is dictated by the rate at which the underlying phenomena evolves. Some use cases require near real-time updates, whereas other use cases require only weekly updates. Lastly, the Digital Twin must drive a specific outcome \xe2\x80\x93 some kind of economic or business value.\nThe key difference between a Digital Twin and existing modeling methods such as traditional 3D modeling (CAD), physics-based simulations, virtual worlds (3D/AR/VR), IoT dashboards of streaming sensor data, and realistic gaming environments is the information flow between the digital and physical systems. A common misconception is that a more complex, higher fidelity virtual representation is what makes a Digital Twin. Rather, it is the regular updating that is key, and directly impacts how data is collected throughout the life cycle and how the Digital Twins are constructed. A Digital Twin must consume the data streams to understand the present state of the system, learn from and update itself (or be updatable) with new observations of the system, and be able to make predictions of the current and future behavior of the system.\nFor example, a Digital Twin of a gas turbine blade ingests temperature and pressure IoT data to predict crack length, a non-observable quantity during operation. Visual borescope inspection results from periodic maintenance are used to update the Digital Twin. The Digital Twin is then used to make predictions of crack growth rate and remaining useful life (RUL) under different operational conditions and maintenance scenarios, enabling the operator to select the best dispatch schedule and maintenance plan. Output from the Digital Twin such as the crack length or RUL can then be shown to the user via a dashboard, a 3D rendering showing the crack in-situ, or some other context-relevant manner. Although the CAD models, IoT dashboards, 3D renderings/immersive walkthroughs, and gaming environments are not Digital Twins in themselves, they represent useful visualization building blocks of Digital Twin solutions, and often represent the first steps in a customer\xe2\x80\x99s Digital Twin journey.\nWhy Is now the time for Digital Twins?\nAs we look at the definition of Digital Twin, we begin to understand four key technologies needed to develop and deploy Digital Twins at-scale: data from the physical system, IoT connectivity, modeling methods, and at-scale computing. Each of these have been developed in parallel over the past 20 years, and its only in the 2020s, however, that we\xe2\x80\x99re seeing the convergence of these technologies needed for Digital Twins at scale.\nThe first technology has to do with measurements. With IoT sensors in particular, the average cost has dropped 50% from 2010 to 2020, and continues to decrease. Measurements that were cost-prohibitive just 10 years ago are now becoming a commodity. This will continue to drive more sensors gathering even more data. Second, is the ability to transmit this data so it can be analyzed and actioned on. If we look at wireless connectivity as a proxy, in 2010, 3G was the de-facto standard at less than 1 Mbps. Throughout the 2010s, it was replaced with 4G at 100 Mbps, and now 5G at 10 Gbps is becoming the norm. That is more than a 10000x increase in transmission speed. And 10 Gbps happens to be a milestone threshold for IoT devices as it is fast enough to gather IoT data in near-real time (<10ms latency).\nThe value of Digital Twins is using this data to derive actionable insights, which is achieved by modeling and at-scale computing, representing the third and fourth key technologies. The term \xe2\x80\x9cmodel\xe2\x80\x9d here is used in multiple contexts. For applications involving predicting future states and what-if scenario planning, we need scientific modeling techniques for predicting various phenomena (its behaviour) such as fluid flow, structural deformation, biochemical processes, weather, and logistics. Methods including machine learning, high performance computing, and hybrid approaches such as physics-inspired neural networks are becoming practical to deploy at scale because of compute power available. Another type of modeling is used for visualization and creating realistic immersive environments. Over the past decade, the advancements in the algorithms for spatial computing to create and manipulate 3D content is enabling immersive augmented reality, virtual reality, and the metaverse.\nLastly, the power of at-scale computing has been greatly enabled by the cloud. We\xe2\x80\x99ve seen compute power grow exponentially, both at the chip level itself, as well connecting the chips all together for massively scalable cloud computing, to the point where massive-scale, on-demand compute is becoming a commodity. No longer limited to governments and large corporations, now small startups and even individuals can access the necessary compute to innovate, invent new products and services, and improve our daily lives.\nPutting context to Digital Twin use cases in the leveling index\nIn our discussions with customers, we\xe2\x80\x99ve found a wide breadth of use cases requiring different AWS services, technologies, and data needed to enable them. To help our customers navigate this space, we developed a Digital Twin leveling index with 4 levels: 1/ Descriptive, 2/ Informative, 3/ Predictive, and 4/ Living, with Level 4 consistent with the definition described earlier. Levels 1 through 3 apply to different use cases with varying levels of complexity, with each driving their own business value. In many ways, this leveling index is analogous to what we see in the self-driving cars space, which uses an L0 through L5 system, where L0 is manual driving, L1 is cruise control, and L5 is a true autonomous self-driving car with no steering wheel. As a customer, mapping your use cases to the proper level will help you understand specific services and patterns that can accelerate business value and provide a roadmap for future growth.\nL1 Descriptive focuses on the engineering design and the visual representation of the physical system (its structure). It can be a 2D engineering diagram (such as a process or P&ID diagram), a building information model (BIM), or a complex high-fidelity 3D/AR/VR model. It also includes engineering analysis performed such as 1D analysis, systems dynamics, computational fluid dynamics, and structural mechanics. The purpose is to understand the design of the physical system and its components.\nTypical use cases include assessing new designs, assessing reconfigurations of brownfield sites, and personnel training under different scenarios. As an example, L1 includes the system analysis of a wind turbine, the CFD analysis of the air-flow over the blades, as well as the 3D/VR rendering or immersive walk-through of the inside of the wind turbine. For the engineering analysis use-cases, key AWS High Performance Computing (HPC) related services and solutions, which include AWS Batch, AWS ParallelCluster, Elastic Fabric Adapter (EFA), Amazon FSx For Lustre, NICE EnginFrame, and NICE DCV, in addition to compute optimized EC2 instances (e.g. Hpc6a, C5n, C6i, P4d). For immersive (AR/VR) use-cases, customers can leverage our Spatial Computing solutions including 3D asset management and partner solutions for AR/VR training (Motive, Innoactive), AR worker assist (Scope AR), immersive collaboration (Cavrnus), XR streaming (HoloLight, NVIDIA CloudXR), and location-based experiences (Immersal).\nL2 Informative focuses on integration of IoT sensor and maintenance data from the physical system and displaying it to the end-user in a context-relevant manner, such as a 2D dashboard or a 3D contextual visualization (e.g. its state). It enables the end user to understand the present condition of the physical system and can include simple analytics to trigger alarms. In the industrial world, this is the domain of IoT and Asset Management integrated with enterprise asset management (EAM) or enterprise resource planning (ERP) systems to show asset configuration, maintenance history, and upcoming work orders on a single pane of glass.\nTypical use cases are around real-time monitoring and alarms, root-cause analysis, and personnel training. As an example, L2 includes an IoT dashboard or 3D rendering showing gearbox temperature data with rules-based alarms as the wind turbine operates. Another example is an augmented reality (AR) overlay of engineering data and service history for a technician using a mobile device/tablet or wearing AR glasses while doing repairs, along with the ability to remotely beam what they\xe2\x80\x99re seeing in real-time to a remote expert who provides further assistance. This might sound futuristic, but it\xe2\x80\x99s happening today, with one of our AWS partners, Scope AR, offering this augmented reality visual knowledge capability to their end customers in the aerospace, energy, manufacturing, and healthcare industries. As you look to build your L2 Informative application, some of the key AWS services include AWS IoT TwinMaker, AWS IoT Core, AWS IoT Greengrass, AWS IoT SiteWise, AWS IoT Analytics, Amazon QuickSight, Amazon Textract, Amazon Rekognition, Amazon DynamoDB, and Amazon S3.\nL3 Predictive focuses on predictions of unmeasured quantities (e.g., virtual sensors, machine learning based anomaly detection), as well as using predictive models to understand future states under continued operations where the future behaviour is the same as past behaviour. These models can either be based on scientific first principles, purely data-driven (e.g., using AI/ML), or a hybrid of the two.\nTypical use cases include operational planning and predictive maintenance (Asset Performance Management) as well as Fleet Management. As an example, L3 includes hybrid models to predict quantities such as health (virtual sensor), and predict remaining useful life (RUL) under continued operations. The predictions from the models can be displayed in context-relevant visualizations (e.g., 2D dashboard/3D/AR/VR) from L1. A unique example is in agricultural commodity markets. AWS supports one of our customers, Descartes Labs, which uses satellite imagery to analyze crop health at continental scale coupled with price, supply & demand, and other market data to produce commodity market forecasts. These forecasts are used by their end customers to decide the best hedging or trading strategies \xe2\x80\x93 which can easily translate into millions of dollars of savings or trading profits. As you build your L3 Predictive applications, key AWS services include our Industrial AI portfolio (Amazon Lookout For Equipment, Amazon Lookout for Vision, Amazon Monitron, AWS Panorama), as well as our AWS High Performance Computing (HPC) related services, Amazon SageMaker, AWS Deep Learning AMIs, and AWS Deep Learning Containers for building and deploying your own custom machine learning models.\nL4 Living focuses on updatable models to drive actionable insights at the individual entity level that can be aggregated to the fleet level if desired. The L4 level represents the culmination of the Digital Twin journey, consistent with our complete definition of Digital Twin. The key distinction between L3 Predictive and L4 Living is the ability for the model itself to be updated based on the data from the physical entity and environment. From a business perspective, the model update capability of an L4 Digital Twin extends its use to timescales over which the behavior of the physical system changes significantly, whereas an L3 Digital Twin is useful for predictions at a moment in time (or very short time-scales thereafter). One way to understand is that a predictive model trained on historical data is, by definition, inaccurate the day it is deployed, since the change in the physical system is not in the training data set. Using this inaccurate model for a forward prediction, in practice, results in a large propagation of error such that the prediction becomes useless over time.\nTypical use cases includes scenario (\xe2\x80\x9cwhat-if\xe2\x80\x9d) analysis and prescriptive guidance on best actions to take. As an example, L4 includes a prediction of wind turbine gear box RUL along with the prediction uncertainty. The parameters within the model (e.g., shaft misalignment, bearing wear, lubrication film thickness) are updated based on IoT data to accurately reflect the degraded state, as opposed to its initial state when new. This model is then used in scenario analysis to determine the best preventative maintenance plan. Building out L4 Living Digital Twins is best accomplished using a variety of probabilistic estimation methods (which we will describe in a future blog), and the core AWS services needed will be Amazon EC2, Amazon S3, Amazon DynamoDB, AWS Lambda, Amazon SageMaker, AWS Deep Learning AMIs, and AWS Deep Learning Containers.\nWhat\xe2\x80\x99s Next for Digital Twins?\nToday, many of our customers are still early in their Digital Twin journey. They are working hard to connect their data across disparate sources and be able to contextually visualize that data in a dashboard or an immersive environment (L2 DT). To date, the first applications have been highly customized and only make financial sense for high value use-cases such as the operations of jet engines, powerplants, and industrial facilities. Over the next few years, we expect to see services such as AWS IoT TwinMaker lower the costs and simplify the deployment. This commoditization will drive adoption across a broad range of everyday contextual visualization use-cases. In parallel, we also expect to see the advanced predictive modeling methods (L4 DT) become more readily accessible for targeted high-value use cases. Today, these methods are currently available in the academic literature and are being used by niche R&D teams. Eventually, these methods will also become mainstream and easily applied for every-day use-cases, allowing anyone to make an L4 living Digital Twin. To begin this L4 DT journey, we will publish open-source code that we will describe in a future blog so that our customers can begin their exploration.\nSummary\nIn this blog, we provided an overview of the AWS definition for Digital Twin, as well as the L1-L4 Leveling Index to help customers categorize their use cases. In future blogs, we will walk through an Electric Vehicle (EV) example to demonstrate L1 Descriptive, L2 Informative, L3 Predictive and L4 Living Digital Twins.\nAbout the author\nDr. Adam Rasheed is the Head of Autonomous Computing at AWS, where he is developing new markets for HPC-ML workflows for autonomous systems. He has 25+ years experience in mid-stage technology development spanning both industrial and digital domains, including 10+ years developing digital twins in the aviation, energy, oil & gas, and renewables industries. Dr. Rasheed obtained his Ph.D. from Caltech where he studied experimental hypervelocity aerothermodynamics (orbital reentry heating). Recognized by MIT Technology Review Magazine as one of the \xe2\x80\x9cWorld\xe2\x80\x99s Top 35 Innovators\xe2\x80\x9d, he was also awarded the AIAA Lawrence Sperry Award, an industry award for early career contributions in aeronautics. He has 32+ issued patents and 125+ technical publications relating to industrial analytics, operations optimization, artificial lift, pulse detonation, hypersonics, shock-wave induced mixing, space medicine, and innovation.\n '"
100,Creating static IP addresses and custom domains for AWS IoT Core endpoints,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2022/02/07/architecture-1024x842.png,https://aws.amazon.com/blogs/iot/creating-static-ip-addresses-and-custom-domains-for-aws-iot-core-endpoints/,"b'The Internet of Things (IoT) describes services and solutions to monitor and control real world objects, such as industrial equipment, light switches, thermostats, sensors and actuators. AWS offers the AWS IoT Core service that allows such devices to connect to the AWS Cloud. The AWS IoT Message Broker is the central point to securely transmit messages to and from all your devices and applications using the HTTPS and MQTT protocols.\nWith devices deployed in a variety of different environments, locations, and scenarios, our customers want flexibility and security when integrating billions of smart devices into their corporate network. Industries, such as automotive, manufacturing, or food and chemical production, manage critical production facilities and need to assert tight control over their network egress. Network segmentation and strict access policies help secure traffic in offices, research facilities, manufacturing plants, and free-moving devices, such as cars, drones, or airplanes.\nThe Message Broker provides mutual Transport Layer Security (TLS) authentication to ensure that only trusted devices and applications are connecting to a trusted endpoint, which is a key component in securing IoT deployments. Industry compliance and local regulations provide customers with guidance on their network security policies, such as NIST\xe2\x80\x99s Guide to Industrial Control Systems Security, Section 5. Adding such security measures to explicitly allow traffic into and out of their network is another key component. Enterprise-grade network segmentation with firewalls and intrusion protection / detection systems can be configured with allow- and block-lists based on IP addresses and protocol ports. While the fully-managed Message Broker provides endpoints with well-known protocols and ports, the IP addresses themselves can change dynamically. This requires operational effort to keep the firewall allow-lists up to date and avoid connectivity issues for IoT devices. Keeping a static list of IP addresses should not be considered a stand-alone security measure, but can serve as an additional layer to monitor and restrict network access.\nIn this blog post, I will show you how to provision static IP addresses for your AWS IoT Core endpoint, and how to associate a custom domain with it. Elastic IP addresses, from Amazon Elastic Compute Cloud (EC2), are fixed (static) IP addresses allocated to your AWS account and are yours until you release them. You can use them to configure allow-list firewall entries. The custom domain, managed via your Amazon Route 53 Hosted Zone, lets you specify a fully qualified domain name for your IoT endpoint, instead of using the provided default AWS-managed domain. You can use an auto-created TLS server certificate for your IoT endpoint via the Amazon Certificate Manager service, or if you already have one, you can re-use it. You can deploy this solution within minutes by using the CDK app or CloudFormation template provided in this GitHub repository.\nWalkthrough\nIn this section, I will dive deep into the solution architecture, and walk you through the individual components and how they interact with each other. You can easily replicate this solution in your AWS account by using the provided infrastructure-as-code template. There are no other external dependencies apart from the mentioned resources.\nPrerequisites\nTo deploy this solution, you need the following prerequisites:\nAn AWS account.\nAn Amazon Route 53 public hosted zone for your domain.\nA certificate in Amazon Certificate Manager for your domain (optional).\nArchitecture deep-dive\nThis blog post assumes some familiarity with AWS networking fundamentals, Elastic Load Balancers, and Amazon Route 53. The following architecture diagram depicts the individual parts of the solution:\nIoT devices (also called clients or things) connect to your IoT device data endpoint, which is unique to your AWS account, e.g., example123.iot.eu-central-1.amazonaws.com. This domain name resolves to one or more IP addresses that are only valid for as long as the DNS record TTL has not expired. In consequence, clients should query for a fresh DNS record before connecting to the endpoint to ensure that they use a valid destination IP address and not a stale/outdated one. Firewalls and intrusion protection / detection systems need to be aware of these changing IP addresses, otherwise static allow-lists will lead to connectivity issues between devices and your endpoint.\nTo overcome this challenge with dynamic IP addresses, the proposed solution makes use of an Amazon Virtual Private Cloud (VPC) endpoint, fronted by a Network Load Balancer (NLB) with static Elastic IP addresses. A custom domain name (vanity domain) is used to resolve to the Elastic IP addresses via Route 53. Customers can then allow-list exactly these Elastic IPs in their firewalls or networking configuration without worrying about unexpected DNS updates.\nThe VPC endpoint creates Elastic Networking Interfaces (ENI) in one or more Availability Zones (AZ). For redundancy and high availability, this solution uses two different AZs with one ENI each. Each ENI receives a private IP address from the VPC subnet. These private IPs are then used in a Target Group for the NLB. Health checks take care of monitoring each ENI and distribute the traffic accordingly.\nThe internet-facing NLB receives traffic from the internet on the associated Elastic IPs, one per AZ. Using Elastic IPs instead of auto-assigned IPs, allows you to retain these IP addresses in your AWS account even after deleting the NLB. This can be vital for future migrations of your infrastructure.\nTo support all IoT connection methods, you can add one listener for each IoT endpoint protocol and port: HTTPS on tcp/443, Alt-HTTPS on tcp/8443, and MQTT on tcp/8883:\nEach listener forwards traffic to a corresponding Target Group, again one per protocol and port, which sends the traffic to the IP targets of the VPC endpoints:\nThe NLB and the VPC endpoint are transparent to the actual traffic. Source IP addresses of your devices will be translated to private VPC-based IPs, meaning that the Client IP preservation feature of NLB Target Groups cannot be used, and if enabled will interrupt traffic flow. The secure connection between your devices and the Message Broker only needs to be aware of the new domain name that your clients are using. When using the AWS SDKs, the necessary protocol headers are included automatically to establish TLS mutual authentication and perform the client and server certificate exchange. Neither the NLB nor your VPC have access to unencrypted traffic. The IoT endpoint allows for additional domain configurations with server certificates provided by AWS Certificate Manager.\nThe maximum number of concurrently connected devices can be scaled easily by adding multiple VPC endpoints for AWS IoT Core to the NLB. Please refer to the documentation pages on scaling and limitations. We recommend to monitor your NLB for port allocation errors to detect issues with devices connecting to your endpoints. You can scale the number of VPC endpoints based on your expected number of devices and connections.\nTo deploy this solution, you can use the resources from this GitHub repository, there are two equivalent implementations of the shown architecture: a CDK app and a CloudFormation template. You can bring your own VPC and subnets, or have them be auto-created. You need to provide a custom domain name with a corresponding Route 53 Hosted Zone ID. You can provide an existing certificate from ACM, or use the auto-generated certificate for this domain name. The Elastic IP addresses are retained even after deleting the CDK app or CloudFormation stack. The provided infrastructure as code resources are self-contained, apart from the required inputs and do not interact with other resources in your AWS account.\nAfter a successful creation of the CDK app or CloudFormation stack, the two newly assigned Elastic IP addresses are available as Outputs in your stack. You can use them to create allow-list entries in your corporate firewall. This enables your IoT devices to connect to the IoT endpoint via these static IP addresses.\nTesting with an IoT device\nIf you don\xe2\x80\x99t already have a device configured as AWS IoT Thing, you can get started connecting your device in the AWS Console. Follow the steps outlined for your platform and download the connection kit with all necessary files to get started. To test your newly created IoT endpoint, you can run the pubsub.py sample from the AWS IoT Device SDK v2 for Python and start it with your custom endpoint and the downloaded connection kit (containing certificate and key files). See these example shell commands:\nwget https://www.amazontrust.com/repository/AmazonRootCA1.pem\nwget https://raw.githubusercontent.com/aws/aws-iot-device-sdk-python-v2/v1.8.0/samples/pubsub.py\npython3 -m pip install awsiotsdk==1.8.0\npython3 pubsub.py \\\n--endpoint iot.example.com \\\n--port 8883 \\\n--cert TestThing.cert.pem \\\n--key TestThing.private.key \\\n--root-ca AmazonRootCA1.pem \\\n--client-id basicPubSub \\\n--topic sdk/test/Python \\\n--count 1\nBash\nA successful test will yield this output, before the command exits:\nConnecting to iot.example.com with client ID \'basicPubSub\'...\nConnected!\nSubscribing to topic \'sdk/test/Python\'...\nSubscribed with QoS.AT_LEAST_ONCE\nSending 1 message(s)\nPublishing message to topic \'sdk/test/Python\': Hello World! [1]\nReceived message from topic \'sdk/test/Python\': b\'""Hello World! [1]""\'\n1 message(s) received.\nDisconnecting...\nDisconnected!\nThis test established a connection to your new IoT endpoint with the custom domain iot.example.com. To view the resolved DNS records, you can run it again with \xe2\x80\x93verbosity Debug. After a secure MQTT session is established, it subscribes to a topic, publishes a message to the same topic, and waits for receiving this message via the subscription, before disconnecting and completing the test successfully.\nExtensions and alternatives\nThis solution can also be adapted for private networks by keeping all traffic away from the public internet. AWS Direct Connect and AWS Site-to-Site VPN are two services that provide private network connectivity between your on-premises environment and your AWS VPC. Instead of using public Elastic IP addresses on an internet-facing NLB, you can create an internal NLB to front your VPC endpoints. To send traffic from your devices to the internal private IP addresses of your NLB, simply add the necessary routes over Direct Connect or Site-to-Site VPN into your VPC.\nUsing an NLB with Elastic IPs exposes your IoT endpoint via its parent AWS Region. If your devices are globally distributed and network latency is of concern, you can use AWS Global Accelerator to optimize the network path by using the AWS global network. You create a new Accelerator, select the protocol and ports, and add the NLB in your region as new endpoint. The accelerator provides you with a new set of static anycast IP addresses that you can use in your Route 53 records.\nThe presented architecture covers the AWS IoT Core endpoints, for HTTPS and MQTT protocols. Any traffic to other AWS services, e.g., Amazon S3 or Amazon DynamoDB, is unaffected. If your devices connect to such services using dynamic IPs and your devices are Linux-based with sufficient compute resources, then this OpenVPN-based AWS Solutions Implementation provides a fully private VPN layer for your devices with static IP addresses on a single port to tunnel all traffic (including IoT endpoints) from your devices to the AWS cloud.\nCleaning up\nTo avoid incurring future charges, destroy the CDK app or delete the CloudFormation stack and manually release the Elastic IPs once you have ensured and verified that you no longer need them. If you created a new device with the \xe2\x80\x9cget started connecting\xe2\x80\x9d workflow, you can delete the associated thing, certificate, and policy.\n'"
101,"What actions customers can take to protect, detect, and respond to Log4j vulnerabilities in Operational Technology (OT) and Industrial Internet of Things (IIoT) environments",b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/what-actions-customers-can-take-to-protect-detect-and-respond-to-log4j-vulnerabilities-in-operational-technology-ot-and-industrial-internet-of-things-iiot-environments/,"b'In this post we will provide guidance to help industrial customers respond to the recently disclosed Log4j vulnerability. This post covers how to identify if you are susceptible to the issue, and then how to address the vulnerability in OT and IIoT environments.\nThe Log4j vulnerability (CVE-2021-44228, CVE-2021-45046) is a critical vulnerability (CVSS 3.1 base score of 10.0) in the ubiquitous logging platform Apache Log4j. This vulnerability allows an attacker to perform a remote code execution on the vulnerable platform. Version 2 of Log4j, between versions 2.0-beta-9 and 2.15.0, is affected. The vulnerability uses the Java Naming and Directory Interface (JNDI) which is used by a Java program to find data, typically through a directory, commonly an LDAP directory in the case of this vulnerability.\nLog4j is an open source Java logging library used extensively by developers. The use of third-party libraries in applications isn\xe2\x80\x99t just an IT problem but also an OT/IIoT problem as industrial digital transformation is driving changes to the OT landscape. As these environments continue to evolve, OT environments are leveraging more IT solutions to improve productivity and efficiency of production operations. It\xe2\x80\x99s no surprise that Log4j is embedded in Operational Technology (OT) and Industrial Internet of Things (IIoT) systems and OT/IIoT vendors have released advisories on how their products are impacted. A key challenge with Log4j in Industrial Control System and Operational Technology (ICS/OT) environments is that at this stage it\xe2\x80\x99s hard to identify exactly what\xe2\x80\x99s affected. In the weeks and months ahead, we will begin to understand the pervasiveness and extent of this particular vulnerability in OT infrastructure; but it is most certainly used to perform critical OT/IIoT logging functions making that system vulnerable to remote code execution. Additionally, adversaries can leverage this vulnerability in proprietary Supervisory Control and Data Acquisition (SCADA), engineering workstations, Human Machine Interfaces (HMI), Energy Management Systems (EMS), and IIoT systems, which use Java in their codebase.\nICS/OT vendors, and IIoT platform providers have started sharing exactly which of their systems are affected, releasing patches that will fix the vulnerability, and providing detailed mitigation plans. Customers should immediately act to identify assets affected by Log4j, upgrade Log4j assets to the latest version as soon as patches are available, and remain alert to vendor software updates. Customers also need to ensure they monitor and protect network access to these systems and implement cybersecurity best practices across their industrial operations to protect against exploitation of this vulnerability. Here are some mitigation steps customers can take to protect, detect, and respond to Log4j vulnerabilities in Operational Technology (OT) and Industrial Internet of Things (IIoT) environments.\nProtect \xe2\x80\x93 Patch your devices and to understand what you need to patch make sure you know what you have and where. Limiting the scope of network connectivity where possible reduces the risk/exposure from the Log4j vulnerability.\nIdentify the location of potentially affected digital assets. You can use your asset/software inventory to identify known applications that were published as vulnerable to Log4j. You can follow https://github.com/cisagov/log4j-affected-db#software-list to view a maintained vulnerable software list and it\xe2\x80\x99s important to track individual vendor sites for the most up to date information.\nScan ICS/OT assets. When asset/software inventory is not available or to augment the inventory, you can run a targeted scan of ICS/OT assets with tools like CERTCC\xe2\x80\x99s (published by CISA), both for Linux and Windows systems. Many OT Intrusion Detection System (IDS) vendors also provide vulnerability scanning tools for OT and IIoT assets, so check with your vendor and scan where feasible after taking the necessary precautions not to impact production operations.\nUnderstand software components in your systems \xe2\x80\x93 By understanding the software components in your systems, you can check if you have security vulnerabilities in your dependencies. If a flaw is discovered in one of the libraries your code depends on, you can view the dependency tree of the software you build/procure to determine if you are affected. Note that OT systems are typically proprietary in nature. A full software inventory of these systems is often not available. Work with your vendors to collect, maintain, and update software inventory to keep track of what components vendors may use in their systems.\nPatching \xe2\x80\x93 If you identify these vulnerabilities within an application or endpoint in your OT/IIoT environment, remediate as soon as possible through patching if available. Asset owners can rely upon vendors to provide patches to impacted software products. It\xe2\x80\x99s important to do a risk assessment and use an up to date network architecture to determine how these vulnerable systems can be accessed from external networks and to identify and patch the most critical assets first. When patching vendor systems, follow the steps provided by the vendor and conduct extensive testing of patches before applying them to production systems. AWS provides AWS IoT jobs to define a set of remote operations that you send to and execute on one or more IIoT devices connected to AWS IoT and AWS Systems Manager Patch Manager to patch on premise computers and edge gateways.\nQuarantine unsupported systems \xe2\x80\x93 With the longer hardware and software refresh cycles in ICS/OT environments, it is common to find ICS/OT products that are no longer under active support or whose software vendors no longer exist. OT environments typically have lots of equipment that can\xe2\x80\x99t be patched, End-of-Life (EOL), cyber fragile, or \xe2\x80\x9cinsecure by design.\xe2\x80\x9d In these cases, patching may not be possible. Quarantine any vulnerable asset that can\xe2\x80\x99t be patched such that it cannot be directly accessible (e.g., where there is a high likelihood of the affected software being probed by adversaries on the internet) or used within a larger networked system of systems. You can significantly reduce the risk of impact on industrial systems by using micro-network segmentation of the IT/OT networks and this is a general best practice regardless of the Log4j vulnerability.\nDetect \xe2\x80\x93 Monitor to detect whether this vulnerability exists in your environment, respond to alerts from OT/IIoT systems and pay particular attention to the IT environments that they connect to.\nSecurity Monitoring \xe2\x80\x93 If Intrusion Detection System (IDS) and network monitoring systems are deployed in the OT network, monitor for odd traffic patterns (e.g., JNDI LDAP/RMI outbound traffic, DMZ systems initiating outbound connections) and configure with Log4Shell indicators of compromise (IOCs) to detect and escalate the alerts for faster response to potential exploitation. Note the advisories from OT IDS vendors for information related to updates on their network-based detections for ICS based active Log4j exploitation. OT/IIoT systems closest to enterprise networks and the internet have the greatest risk exposure and could likely be used by a threat actor as a pivot point into OT. Similarly, threat actors can pivot into the enterprise or cloud environment through compromised OT/IIoT systems. Security monitoring should be comprehensive and cover the entire attack surface, which includes OT, industrial edge, IT, and Cloud. Customers can use AWS IoT Device Defender to audit and monitor their fleet of IoT devices and detect anomalies in device behavior, Amazon Inspector to look for Log4j vulnerability for all supported AWS Systems Manager managed instances including on premise computers and edge gateways and Amazon GuardDuty to detect indicators of compromise associated with exploiting the Log4j vulnerability in the cloud.\nRespond \xe2\x80\x93 Build automation to respond and quarantine assets where you see suspicious activity. Prepare an incident response plan/runbooks and test these regularly.\nInvestigation and Incident Response \xe2\x80\x93 Customers can investigate potential compromise and hunt for signs of malicious activity by using threat detection methods and tools like logs, SIEM, etc. and respond and remediate where applicable.\nCustomers can use AWS Security Hub with AWS IoT Device Defender, Amazon Inspector and Amazon GuardDuty to aggregate alerts and enable automatic remediation and response. In the short term, we recommend that you use Security Hub to set up alerting through AWS Chatbot, Amazon Simple Notification Service, or a ticketing system for visibility when Inspector finds this vulnerability in your environment. In the long term, we recommend you use Security Hub to enable automatic remediation and response for security alerts when appropriate. Here are ideas on how to setup automatic remediation and response with Security Hub.\nReview and monitor Apache Log4j Security Vulnerabilities webpage for AWS updates and mitigation guidance and work closely with your vendors to monitor any updates on affected systems. In addition, follow the Apache Log4j Vulnerability Guidance provided by CISA, AWS Security Bulletins and learn more about AWS security services to protect against, detect, and respond to the Log4j vulnerability.\nFinally, Plan to replace legacy unsupported systems as soon as possible. OT systems are likely to include components that are 20-30 years old, or even older. Some systems may be so old that they predate any and all concerns about cybersecurity, and other systems may simply have inadequate security measures or reached their end of life. If you find that aging OT infrastructure is presenting a significant risk to your operations, then the mitigation strategy might include a plan to upgrade, replace or decommission outdated assets. When considering a holistic risk management program, modernizing the OT environment can be a major enabler to reducing the risks facing an organization.\n'"
102,How to remote access devices from a web browser using secure tunneling,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-remote-access-devices-from-a-web-browser-using-aws-iot-secure-tunneling/,"b'Using firewalls is a common way to protect and secure access to IoT devices. Yet, it\xe2\x80\x99s challenging to access and manage devices deployed at remote sites, behind firewalls that block all inbound traffic. Troubleshooting devices can involve sending technicians onsite to connect to those devices. This increases the complexity and the cost of device management.\nSecure Tunneling is a feature of AWS IoT Device Management that helps customers accessing remote devices over a secure connection that is managed by AWS IoT. Secure Tunneling does not require updates to your existing inbound firewall rules, so you can keep the same security level provided by firewall rules at a remote site.\nIn this post, you learn how to use secure tunneling to start a Secure Shell (SSH) session to remote devices from web application. This connection can be used for configuration, troubleshooting, and to complete other operational tasks.\nYou can download the source code of this implementation from GitHub.\nSolution overview\nI will walk you through the steps for building a web based local proxy to gain access to remote devices using secure tunneling.\nThe local proxy is a software proxy that runs on the source, and destination devices. The local proxy relays a data stream over a WebSocket secure connection between the Secure tunneling service and the device application.\nThe local proxy can work in source, or destination mode. The source is usually the laptop or the desktop computer you use to initiate a session with the destination device. The destination device is the remote device you want to access.\nFor an overview of the process, review the following diagram.\nWhen you create a tunnel, a pair of tokens (one for the source and one for the destination) is created. The source and destination devices use these tokens to connect to the secure tunneling service.\nThe local proxy establishes a secure WebSocket connection with the tunneling feature using the source or the destination token, depending on the mode used. The token is specified in the request either via cookie, named awsiot-tunnel-token, or an HTTP request header, named access-token.\nThe implementation of WebSockets inside web browsers doesn\xe2\x80\x99t support custom headers. So you must set an awsiot-tunnel-token cookie using the instruction in the secure tunneling protocol guide.\nFor security reasons, a website can only set a cookie for its own domain, or any higher-level DNS domain it belongs to. For example, if the domain name of a web application is mylocalproxy.com, it could not set a cookie for the secure tunneling endpoint named data.tunneling.iot.{aws-region}.amazonaws.com.\nYou will use Amazon API Gateway with AWS Lambda proxy integration to set the cookie for the .amazonaws.com domain.\nThe cookie is shared across the setting domain and all sibling and child domains including data.tunneling.iot.{aws-region}.amazonaws.com.\nWeb browsers might not send the cookie to the domain us-east-1.amazonaws.com as it is in the public suffix list. This list is used in browsers to limit the scope of a cookie. A manual workaround for us-east-1 Region is to set the cookie in the console of the web browser.\nSolution architecture\nThe following diagram gives an overview of the major steps involved in starting an SSH session from a web application using Secure Tunneling:\nSet a cookie named awsiot-tunnel-token with the value of the source token.\nOpen a secure WebSocket connection between your web application and the tunneling feature.\nTransfer the data using Protocol Buffers library.\nIn this blog, I describe these three steps in detail starting with how to open a tunnel. Once the tunnel is open, I walk you through how to open a secure WebSocket connection, first from a local machine, setting the source access token via HTTP header.\nThen, I explain how to use Protocol Buffers library to transfer data between a source and a destination.\nFinally, I describe the solution to set a cookie for the .amazonaws.com domain so the web application can open a secure WebSocket connection passing this cookie.\nPrerequisites\nThis post assumes you have completed the following:\nRead the AWS IoT Secure Tunneling tutorials.\nComplete the open a tunnel and start SSH session to remote device section. This section guides you on how to use secure tunneling, and configure a remote device with the local proxy.\nNode.js and npm installed on your local machine.\nWalkthrough\nStep 1: Connecting to Secure Tunneling\nThe first step is to open a tunnel and download the access tokens for the source and destination as described in open a tunnel and start SSH session to remote device.\na) Create a folder in your local machine. Navigate to this folder, and create a file named connect.js.\nb) Copy the following Node.js script in your newly created connect.js file. Replace the value of token with the access token for the source you have downloaded. Replace the value of aws_region with the AWS Region in which the tunnel is open. The access token for the source is used to open a WebSocket connection between your local machine and the tunneling service.\n// connect.js\nconst WebSocket = require(\'ws\')\nconst token = \'REPLACE WITH THE SOURCE TOKEN\'\nconst aws_region = \'REPLACE WITH THE AWS REGION IN WHICH THE TUNNEL IS OPEN\'\nconst mode = \'source\'\n\nlet url = `wss://data.tunneling.iot.${aws_region}.amazonaws.com:443/tunnel?local-proxy-mode=${mode}` \n\nconst connection = new WebSocket(url, `aws.iot.securetunneling-2.0`, {\n    headers: { \n            \'access-token\': token\n    }\n})\n\nconnection.onopen = async () => {\n    console.log(\'Source is connected to the tunneling service\')\n}\nc) Install the Node.js library ws, with the following command:\nnpm i --save ws\nd) Run the script:\nnode connect.js\nYou see Source is connected to the tunneling service in your terminal.\ne) In the AWS IoT console, select your tunnel and check that the source is connected.\nf) To connect the destination to the tunneling service, repeat this step. Replace the value of the variable mode with destination. Replace the value of token with the access token for the destination.\nStep 2: Transmitting data through the tunnel\nNow that you know how to connect the source and the destination to the tunneling feature, you can transmit data. Secure Tunneling uses protocol buffers to transfer data between the source and the destination.\nProtocol Buffers is a mechanism for serializing structured data. Protocol Buffers enables you to specify a schema for your data in a .proto file.\na) In the folder created in Step 1, create a file named schema.proto Copy the following content into the file:\n// schema.proto \n\nsyntax = ""proto3"";\n\npackage com.amazonaws.iot.securedtunneling;\n\noption java_outer_classname = ""Protobuf"";\noption optimize_for = LITE_RUNTIME;\n\nmessage Message {\n    Type    type         = 1;\n    int32   streamId     = 2;\n    bool    ignorable    = 3;\n    bytes   payload      = 4;\n    string  serviceId    = 5;\n    repeated string availableServiceIds = 6;\n    \n    enum Type {\n        UNKNOWN = 0;\n        DATA = 1;\n        STREAM_START = 2;\n        STREAM_RESET = 3;\n        SESSION_RESET = 4;\n        SERVICE_IDS = 5;\n    }\n}\nThe previous schema defines a message format for the data with six fields: type, streamId, ignorable, payload, serviceId and availableServiceIds.\nThe payload field contains a binary blob of the data to transfer. For more information, review the reference implementation guide V2WebSocketProtocolGuide.\nb) In the same folder, install the library protobufjs that you will use to load the schema and encode/decode the messages:\nnpm i --save protobufjs\nc) Create two files. Name one file source.js. Name the other file destination.js. You connect the destination to the tunneling feature and decode the incoming message in the file destination.js. You connect the source to the tunneling feature and send a message to the destination with the file source.js.\nd) Copy the following content in the destination.js file. Replace the values for token and aws_region:\n// destination.js \n\nconst WebSocket = require(\'ws\')\nconst {load} = require(\'protobufjs\')\n\nconst token = \'REPLACE WITH THE DESTINATION TOKEN\'\nconst aws_region = \'REPLACE WITH THE AWS REGION IN WHICH THE TUNNEL IS OPEN\'\n\nconst mode = \'destination\'\nconst protopath = \'./schema.proto\'\n\nlet url = `wss://data.tunneling.iot.${aws_region}.amazonaws.com:443/tunnel?local-proxy-mode=${mode}`\nlet Message\n\nconst connection = new WebSocket(url, `aws.iot.securetunneling-2.0`, {\n    headers: { \n            \'access-token\': token\n    }\n})\n\nconnection.onopen = async () => {\n    console.log(\'Destination is connected to the tunneling service\')\n    Message = await load(protopath)\n    Message = Message.root.lookupType(\'Message\')\n}\n\nconnection.onmessage = async ({data}) => {\n    try {\n        let decoded_message = Message?.decode(data)\n        if(decoded_message?.payload){\n            console.log(decoded_message.payload.toString(\'utf-8\'))\n        }\n    } catch (e) {\n        console.log(e)\n    }\n} \ne) Open the source.js file and copy the following code. Replace the values for token and aws_region.\nconst WebSocket = require(\'ws\')\nconst {load} = require(\'protobufjs\')\n\nconst token = \'REPLACE WITH THE SOURCE TOKEN\'\nconst aws_region = \'REPLACE WITH THE AWS REGION IN WHICH THE TUNNEL IS OPEN\'\n\nconst mode = \'source\'\nconst protopath = \'./schema.proto\'\n\nlet url = `wss://data.tunneling.iot.${aws_region}.amazonaws.com:443/tunnel?local-proxy-mode=${mode}`\nlet Message\n\nconst hello = \'Hello from the source\'\n\nconst connection = new WebSocket(url, `aws.iot.securetunneling-2.0`, {\n    headers: { \n            \'access-token\': token\n    }\n})\n\nconnection.onopen = async () => {\n    console.log(\'Source is connected to the tunneling service\')\n    Message = await load(protopath)\n    Message = Message.root.lookupType(\'Message\')\n\n    // start the stream \n    let tunnel_message = {\n        type: 2, // Stream Start\n        streamId: Math.floor(Math.random() * 1000), \n        ignorable: false,\n        payload: null // We don\'t send data yet as we only start the stream\n    }\n    sendData(tunnel_message)\n\n    // send the data \n    tunnel_message.type = 1 // DATA\n    tunnel_message.payload = Buffer.from(hello, \'utf-8\')\n    sendData(tunnel_message)\n}\n\nconnection.onmessage = async ({data}) => {\n    try {\n        let decoded_message = Message?.decode(data)\n        if(decoded_message?.payload){\n            console.log(decoded_message.payload.toString(\'utf-8\'))\n        }\n    } catch (e) {\n        console.log(e)\n    }\n}\n\nconst sendData = (data) => {\n    try {\n            let protoMessage = Message.verify(data)\n            let encodedMessage = Message.encode(data).finish()\n            let arrayWrapper  = new Uint8Array( 2 + encodedMessage.byteLength );\n            arrayWrapper.set( new Uint8Array( [ Math.floor(encodedMessage.byteLength / 256), encodedMessage.byteLength % 256 ] ))\n            arrayWrapper.set(encodedMessage, 2);\n            connection.send(arrayWrapper)\n        \n    } catch (e) {\n        console.log(e)\n    }\n}\nf) Open a terminal for the destination. In destination terminal, run the destination.js script:\nnode destination.js\ng) Open an additional terminal for the source. In the source terminal, run the source.js script:\nnode source.js\nYou see the message Hello from the source sent by the source (see the variable hello) received by the destination.\nIn this step, you transferred simple text between the source and the destination. If there was an SSH session, the payload of the protobuf message would contain an SSH stream.\nStep 3: Create the REST API that sets the cookie\nNow that you know how to connect and transfer data, the last step is to connect to the tunneling service from a web browser. The implementation of WebSockets inside web browsers doesn\xe2\x80\x99t support custom headers, so you must set a cookie, as described in the Secure Tunneling protocol guide.\nTo set a cookie to pass the source token for authentication when creating a new WebSocket connection, you create a REST API with Amazon API Gateway with AWS Lambda proxy integration.\nThe web application sends an HTTP POST request providing the token to the API Gateway endpoint. The Lambda function creates the cookie with the provided token. It responds to the POST API request with the Set-Cookie HTTP response header to send the cookie to the web application.\nThe endpoint of the API you create, and the endpoint to connect to the tunneling service are both subdomains of .amazonaws.com.\nStep 3.1: Create the Lambda function to set the cookie\nYou create a Node.js Lambda function using the Lambda console.\na) Open the Functions page on the Lambda console.\nb) Choose Create function.\nc) Under Basic information, do the following:\nFor Function name, enter set_cookie_lambda.\nFor Runtime, confirm that Node.js 14.x is selected.\nd) Choose Create function.\ne) Under Function code, in the inline code editor, copy/paste the following code:\n// set_cookie_lambda Lambda function\n\nexports.handler = async (event) => {\n\n    const body = JSON.parse(event.body)\n    const token = body.token\n    const origin = event.headers[\'origin\']\n\n    let d = new Date()\n    d.setTime(d.getTime() + (2*60*60*1000))\n\n    let cookie = `awsiot-tunnel-token=${token}; path=/tunnel; expires=${d}; domain=.amazonaws.com; SameSite=None; Secure; HttpOnly`\n\n    const response = {\n        headers: {\n            \'Set-Cookie\': cookie,\n            \'Access-Control-Allow-Origin\': origin,\n            \'Access-Control-Allow-Credentials\': true\n        },\n        statusCode: 200,\n        body: JSON.stringify({message: \'Success\'})\n    };\n    return response\n}\nf) Choose Deploy.\nStep 3.2: Create the Lambda function to enable CORS\nFor the API to be able to set the cookie, you must enable cross-origin resource sharing (CORS). CORS is a browser security feature that restricts cross-origin HTTP requests that are initiated from scripts running in the browser.\nFor a CORS request with credentials, you can\xe2\x80\x99t use the wildcard \xe2\x80\x9c*\xe2\x80\x9d in the value of Access-Control-Allow-Origin header. Instead, you must specify the origin.\nTo support CORS, therefore, a REST API resource must implement an OPTIONS method that can respond to the OPTIONS preflight request with at least the following response headers: Access-Control-Request-Method, Access-Control-Request-Headers, and the Origin header.\nTo do that you will create another Lambda function that will get the origin of the web application from the OPTIONS method of the API and enable CORS for this specific origin.\nRepeat the steps described in the Step 3.1 to create a Node.js Lambda function named enable_cors_lambda.\nYou create a Node.js Lambda function using the Lambda console.\na) Open the Functions page on the Lambda console.\nb) Choose Create function.\nc) Under Basic information, do the following:\nFor Function name, enter set_cookie_lambda.\nFor Runtime, confirm that Node.js 14.x is selected.\nd) Choose Create function.\ne) Under Function code, in the inline code editor, copy/paste the following code:\n// enable_cors_lambda Lambda function\nexports.handler = async (event) = {\n\n    const origin = event.headers[\'origin\']\n    const response = {\n        headers: {\n            \'Access-Control-Allow-Origin\': origin,\n            \'Access-Control-Allow-Credentials\': true,\n            \'Access-Control-Allow-Methods\': \'OPTIONS,GET, POST\',\n            \'Access-Control-Allow-Headers\': \'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token\'\n            \n        },\n        statusCode: 200,\n        body: JSON.stringify({message: \'Success\'})\n    };\n    return response;\n}\nf) Choose Deploy.\nStep 3.3: Creating the REST API to set the cookie\nNow, you can create the REST API with POST and OPTIONS methods that will invoke the Lambda functions set_cookie_lambda and enable_cors_lambda respectively.\na) In the API Gateway console, create a REST API named SetCookieApi.\nb) Create a method POST.\nLeave the Integration type set to Lambda Function.\nChoose Use Lambda Proxy integration.\nFrom the Lambda Region dropdown menu, choose the region where you created the set_cookie_lambda Lambda function.\nIn the Lambda Function field, type any character and choose set_cookie_lambda from the dropdown menu.\nChoose Save.\nChoose OK when prompted with Add Permission to Lambda Function.\nc) Create a method OPTIONS.\nLeave the Integration type set to Lambda Function.\nChoose Use Lambda Proxy integration.\nFrom the Lambda Region dropdown menu, choose the region where you created the enable_cors_lambda Lambda function.\nIn the Lambda Function field, type any character and choose enable_cors_lambda from the dropdown menu.\nChoose Save.\nChoose OK when prompted with Add Permission to Lambda Function.\nStep 3.4: Deploy the API\nChoose Deploy API from the Actions dropdown menu.\nFor Deployment stage, choose [new stage].\nFor Stage name, enter api.\nChoose Deploy.\nNote the API\xe2\x80\x99s Invoke URL.\nYou can send a POST request providing the token in the body using the Invoke URL.\nThe API sends the cookie in the response. When you open the WebSocket connection with the tunneling service, the cookie will be used to authenticate with the tunneling service.\nStep 4: Connect to the tunneling feature from a web application\nYou can now use the SetCookieApi API in your web application to connect to the tunneling feature.\nThe following code snippet of an Angular web application shows how to use the REST API to set the cookie:\nYou send an HTTP POST request to the SetCookieApi API with the token in the body.\nThe API sets the cookie in the response.\nFinally, you open a secure WebSocket connection with the tunneling feature.\nimport { Component, OnInit } from \'@angular/core\';\nimport { HttpClient } from \'@angular/common/http\'\n\n@Component({\n  selector: \'app-root\',\n  templateUrl: \'./app.component.html\',\n  styleUrls: [\'./app.component.scss\']\n})\nexport class AppComponent implements OnInit{\n  \n  token = \'REPLACE WITH THE SOURCE TOKEN\'\n  aws_region = \'REPLACE WITH THE AWS REGION IN WHICH THE TUNNEL IS OPEN\'\n  url_api_set_cookie = \'REPLACE WITH THE SetCookieApi URL\'\n  tunneling_url = `wss://data.tunneling.iot.${this.aws_region}.amazonaws.com:443/tunnel?local-proxy-mode=source`\n  constructor(private http: HttpClient){}\n\n  async ngOnInit() {\n    // SET THE COOKIE \n    await this.http.post(this.url_api_set_cookie, {token: this.token}, {withCredentials: true, }).toPromise()\n    \n    // Connect to the tunneling service\n    let socket = new WebSocket(this.tunneling_url, \'aws.iot.securetunneling-2.0\')\n\n  }\n\n}\nOnce the WebSocket connection is established, you can transfer data like SSH stream directly from your web application.\nYou can find an implementation of a web based local proxy in the aws-iot-securetunneling-web-ssh GitHub repository.\nYou can also test using an online demonstration. The demo user name and the password are both iotcore.\nCleaning up\nTo avoid incurring future charges, delete the resources created during this walkthrough.\n'"
103,Strengthening Operational Insights for Industrial Assets with AWS IoT AIML Solution (part 2),b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/12/13/3.jpg,https://aws.amazon.com/blogs/iot/strengthening-operational-insights-for-industrial-assets-with-aws-iot-aiml-solution-part-2/,"b'In this two-part blog post, we propose an AWS IoT AI/ML solution to help our industrial customers for efficiently monitoring industrial assets in a scalable manner. Part 1 of the blog shows:\nHow to create an asset simulator with AWS IoT SiteWise;\nHow to create data pipeline to integrate Amazon Lookout for Equipment with AWS IoT SiteWise.\nIn this post, you will continue building the solution started in part 1 of this series. You will need to have AWS IoT SiteWise and SiteWise Monitor configured with the industrial assets and prepared the data pipeline to send data to Amazon Lookout for Equipment. If you haven\xe2\x80\x99t completed these steps, review Part 1, Steps 1 and 2 before proceeding.\nThe following Steps 3 and 4 will guide you through how to:\nTrain Amazon Lookout for Equipment model with historical training data, and evaluate model performance;\nUse Amazon Lookout for Equipment to establish inference scheduler to provide anomaly prediction for assets;\nAugment the dashboard built in Part 1 with Amazon Lookout for Equipment service for anomaly alerts and remote monitoring.\nStep 3: Train Lookout for Equipment Model\nBefore we proceed to building our model, let\xe2\x80\x99s refresh what Amazon Lookout for Equipment is and how it works. Amazon Lookout for Equipment uses ML to detect abnormal behavior in your equipment and identify potential failures. Each piece of industrial equipment is referred to as an industrial asset, or asset. To use Lookout for Equipment to monitor your asset, you do the following:\nProvide Lookout for Equipment with your asset\xe2\x80\x99s data. The data come from sensors that measure different features of your asset. For example, you could have one sensor that measures temperature and another that measures pressure.\nStart a training job in Amazon Lookout for Equipment to train a custom ML model.\nSet up an inference scheduler to monitor the asset nearly continuously for anomalies.\nAsset failures are rare and even the same failure type might have its own unique data pattern. Nonetheless, all detectable failures are preceded by behavior or conditions that fall out of the normal behavior of the equipment. Lookout for Equipment is designed to look for those patterns by training a model that uses the sensor data to establish the baseline or normal behavior of an asset. In other words, it\xe2\x80\x99s trained to know what constitutes normal behavior and detects deviations from normal behavior as it monitors your equipment. To highlight abnormal equipment behavior, Lookout for Equipment uses labeled data in model training. Labeled data is a list of historical date ranges that corresponded to the times when your asset was behaving abnormally. Providing this labeled data is optional, but if it\xe2\x80\x99s available, it can help train your model more accurately and efficiently.\nThe following screenshot from Amazon Lookout for Equipment service shows an example of labeled data with periods of abnormal asset behavior.\nFigure 1: Format of label data used for Amazon Lookout for Equipment\nAfter you train your model, you can visualize the evaluation of the trained Lookout for Equipment model on the evaluation window, as shown in Figure 2.\nFigure 2: Summary of model training in Amazon Lookout for Equipment console\nAnd you can also select each event and Lookout for Equipment unpacks the sensor ranking and displays the top sensors contributing to the detected events. The following screenshot from the Lookout for Equipment console shows the top 15 sensors that contribute to this anomaly event. This anomaly score ranking can help the OT team to perform component checks or repairs more efficiently by starting from sensors with high anomaly scores.\nFigure 3: Analysis of top 15 sensors that contribute to anomaly behavior\nFinally, we can use the model to monitor your asset by scheduling the frequency with which Lookout for Equipment processes new sensor data through batch inference every 5 minutes. The following screenshot of Lookout for Equipment inference scheduler shows the inference history of such batch inferences at a frequency of once per 5 minutes.\nFigure 4: Inference scheduler status with Amazon Lookout for Equipment\nNow that we have a firm grasp on what Amazon Lookout for Equipment does and how it works, let\xe2\x80\x99s proceed to build our model.\nIn part 1 of this blog series, step 1 set up an AWS IoT SiteWise simulator with a CloudFormation template, and UUIDs of two pump assets are listed as outputs. Navigate to the Outputs section and copy AssetID values.\nFigure 5: Output section of the AWS CloudFormation stack from step 1\nNavigate to the SageMaker console and locate the notebook instance created by the template. Select Open JupyterLab.\nFigure 6: Amazon SageMaker notebook instance\nIn JupyterLab, navigate to l4e_notebooks folder, (1) add the for the first pump asset (FirstAssetId) in AssetID in the config.py; (2) add BUCKET (as it is shown in Figure 7) with the Amazon Simple Storage Service (Amazon S3) bucket created in Step 2 for pump asset 1.\nFigure 7: Screenshot showing S3 bucket name created within part 1 step 2 of this blog\nFigure 8: Config file used for Amazon SageMaker notebook\nNote: Amazon Lookout for Equipment will train a unique model for each industrial asset, and derive tailored insights while the asset has been operated within its own environment. In order to train a model for asset 2, you will need to update the config.py with the new S3 path and UUID for asset 2 and rerun all the notebooks. You can also train only one model at this stage. However, we will discuss how to get value from monitoring multiple similar assets later in this post.\nRun each notebook in the l4e_notebooks subdirectory in series. Although they contain detailed explanations for every step, here, we explain at a high level what is happening in each notebook.\nIn 1_data_preparation.ipynb, the notebook will perform the following tasks:(1) Downloads the provided sample dataset from the original S3 bucket; (2) Uncompresses the contents into a local directory; (3) Loads the data into the training bucket for Lookout for Equipment.\nAfter all steps in 1_data_preparation.ipynb are successfully completed, we can continue to 2_dataset_creation.ipynb. Here we will create a data_schema for our data and load the data into Lookout for Equipment by invoking the CreateDataset and StartDataIngestionJob APIs in this notebook.\nIn 3_model_training.ipynb, this notebook will train an ML model in Lookout for Equipment. First, this notebook defines the train and evaluation date ranges. Then it passes in the S3 path to the labels.csv, which contains date ranges for known historical anomalies. Finally, we start a training job by invoking the CreateModel API.\nIn 4_model_evaluation.ipynb, you can evaluate the trained model by extracting metrics associated with it with the DescribeModel API. Note that this step is optional and it doesn\xe2\x80\x99t commit any changes. It is purely for the user to analyze the training results manually.\nFinally, in 5_inference_scheduling.ipynb, the notebook launches a model into production with the call to the CreateInferenceScheduler API.\nStep 4: Build an AWS IoT SiteWise Monitor dashboard\nOnce the Lookout for Equipment inference schedule is created, the data pipeline that you set up in part 1, step 2 will integrate the Lookout for Equipment inference results with AWS IoT SiteWise. The OT team can use AWS IoT SiteWise Monitor as managed web applications to inspect and manage operational data and alarms over time. In step 1, a SiteWise Monitor portal and dashboard were set up to visualize  data from 30 sensors over time. In this step, predictions and anomaly scores from Lookout for Equipment will be visualized within the same dashboard. For detailed instructions of building each visualization, refer to the project\xe2\x80\x99s GitHub link. Note that the appearance of visualizations built by you may look different from the visualizations displayed in part 1 of this series. This is because the inference results on real-time AWS IoT SiteWise data were determined by sensor data at that particular timestamp when these screenshots were taken.\nFirst, AWS IoT SiteWise alarm functions for each AWS IoT SiteWise asset are shown in Figure 9. You can see that the Demo Pump 1 displays the asset with an alarm status (in red) while the Demo Pump 2 alarm shows a normal status (in green). For the Pump Station, the alarm status is also normal. This is because the Pump Station anomaly score (Total L4EScore metric) is a sum of all Asset L4EScore from all associated assets. Since the threshold of Pump Station Total L4EScore\xe2\x80\x94set at both pump assets being abnormal\xe2\x80\x94has not been reached, the Pump Station alarm is shown as normal. In real applications, the OT team can define a suitable threshold to manage assets with multiple hierarchies.\nFigure 9: AWS IoT SiteWise alarm for the Demo Pump Station\nSecond, Lookout for Equipment diagnostics for each sensor of Demo Pump 1 will be evaluated in detail to understand possible the reasons for an anomaly. Since 30 sensors belong to five different components as explained previously, we only show L4EScore for one sensor associated with each component for representative purposes. In the second visualization, the SensorX L4EScore for sensors 0, 6, 12, 18, and 24 are visualized with a grid widget. Sensor 6 from the impeller component shows an anomaly score90 times higher than sensor 24. This high anomaly score indicates a possible root cause of the asset\xe2\x80\x99s abnormal behavior, and the behavior of the sensors associated with the impeller needs to be examined in details as a triage action.\nFigure 10: SensorX L4E Score for different components in Demo Pump asset\nThird, anomaly scores for sensors associated with the impeller are visualized. This visualization will help the OT team to understand if the high anomaly score only corresponds to a single sensor or corresponds to every sensor associated with the impeller. If the latter is true, this may indicate a component level failure. In figure 11, all sensors show high anomaly scores (>0.1) in the past 5 minutes. Notice that the minimum anomaly score for sensors with the impeller (Sensor 7) is 46 times higher than sensors from other components. Such high anomaly score indicates impeller component failure.\nFigure 11: SensorX L4EScore for sensors within Impeller component\nFinally, a detailed sensor signal comparison between Demo Pump Asset 1 and Demo Pump Asset 2 is performed. After inspecting the sensor signals within the past one day in Figure 12, it seems that Sensor 6 from Asset 1 shows a 30% higher amplitude compared with that from Asset 2. However, Sensor 0 from Asset 1 and Asset 2 show random signal patterns, but their amplitudes do not show a significant difference during the same time period. The close correlation between the Sensor 6 signal anomaly and l4eAlarm of Demo Pump Asset 1 indicates that the possible root cause for this alarm warning is due to sensors from the impeller component.\nFigure 12: Sensor signal comparison between two pump assets\nIn summary, the processes of (1) monitoring multiple assets for alarms, and (2) diagnosing anomalies with particular sensors within a complex asset can be achieved with SiteWise Monitor. The advantage of adopting SiteWise Monitor is that the whole dashboard development does not require any web development or hosting efforts. The OT team can fully use their domain expertise to get insights quickly into their operational data, and can manage their assets with alarms when devices and equipment perform suboptimally. With the Amazon Lookout for Equipment multivariate ML model, the OT team can use component diagnostics scores from the AI service to find out root causes of underperforming assets.\n'"
104,Strengthening Operational Insights for Industrial Assets with AWS IoT AIML Solution (part 1),b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/12/13/2.jpg,https://aws.amazon.com/blogs/iot/strengthening-operational-insights-for-industrial-assets-with-aws-iot-aiml-solution-part-1/,"b'Customers that manage and maintain industrial assets strive to keep them functioning as efficiently as possible, which they can do by monitoring and analyzing the health of their assets. Plant operators measure efficiency with key performance indicators (KPIs) like overall equipment effectiveness (OEE) or mean time before failure (MTBF) and act to improve these metrics at predetermined intervals. Ideally, plant operators would only act at the time when there is a justifiable gain for a taken action, like recalibration or replacement. Meanwhile, the operational technology (OT) team will only perform maintenance during a time period with the least impact to production. Acting too soon wastes resources on lesser gains while acting too late risks unplanned downtime. Customers want a solution that automates asset monitoring, learns from past performance issues, and provides actionable insights that maintain a high standard for their KPIs.\nA condition-based monitoring solution that combines the disciplines of the Internet of Things (IoT) and machine learning (ML) can accelerate the OT team\xe2\x80\x99s ability to meet their KPI goals. The objective of a condition-based monitoring solution is to track machine telemetry data in real time and forecast abnormalities in KPIs so that maintenance may be planned only when it is needed. This kind of solution can alert OT teams about abnormal performances and provide insights about the root cause based on past performance, creating opportunities to prevent problems before they impact your operations.\nThere are two primary obstacles to overcome when engineering a condition-based monitoring solution.\nData Storage and Management: The vast amount of data collected from sensors, along with equipment and site metadata, need to be properly stored and cataloged.\nA scalable and easy-to-adopt approach to implement advanced analytics in IoT: multiple ML models need to be developed for different types of equipment, and be integrated into IoT platforms for conditional maintenance operation.\nThese obstacles can obscure insights driven from the AI solution, and can intimidate teams already responsible for maintaining hundreds of industrial assets by adding a ML component to asset management.\nIn this two-part series, we walk you through examples of how AWS IoT is helping customers solve these core challenges.\nWe address the obstacles of data storage and analysis, demonstrating how you can deploy a solution that will:\nCollect, store, organize, and monitor data from industrial equipment at scale with AWS IoT SiteWise. With AWS IoT SiteWise, multiple sensors can be structured with asset model and hierarchy levels, so data can be easily consumed for training ML models.\nDetect and diagnose equipment abnormalities with speed and precision to reduce expensive downtime with Amazon Lookout for Equipment. The OT team can use automated ML to develop multivariate ML models for complex industrial assets and achieve nearly continuous monitoring with ease.\nIntegrate inference outputs from Amazon Lookout for Equipment with AWS IoT SiteWise, so the OT team can identify issues quickly at component levels for industrial assets. The OT team can also be automatically notified of anomalies with the AWS IoT SiteWise alarm feature, to make maintenance decisions.\nSolution Overview\nAWS IoT SiteWise is a managed service that makes it simple to collect, store, organize, and monitor data from industrial equipment at scale, helping you make more informed decisions. You may use AWS IoT SiteWise to manage operations across many sites, easily calculate industrial performance indicators, and build applications that analyze industrial equipment data to avoid costly equipment failures. With consolidated data, you can gather data consistently across devices, rapidly discover issues through remote monitoring, and achieve multi-site management.\nAmazon Lookout for Equipment analyzes data from equipment sensors to train an ML model automatically for your equipment based only on your data\xe2\x80\x94no data science skills necessary. Lookout for Equipment analyzes incoming sensor data in real time and accurately identifies early warning signals that could lead to preventable dips in health metrics like OEE or MTBF. This means you can identify anomalies in equipment quickly and precisely, diagnose problems efficiently, take action to avoid costly downtime, and minimize false alarms.\nIn this solution, we demonstrate the integration of these complementary AWS managed services for nearly continuous monitoring and alerting of a simulated pump station with two assets. Each asset is a pump like the one displayed in the following photo. It is used to move a fluid by transferring the rotational energy provided by a motor to hydrodynamic energy.\nFigure 1: Centrifugal Pump, a Warman centrifugal pump in a coal preparation plant application, by Bernard S. Janse, licensed under CC BY 2.5\nCustomers can extend the steps outlined in this blog to develop a solution that can lead to optimizing their industrial assets. The result is a real-time dashboard to:\nAchieve real-time monitoring with alarm notification at scale;\nProvide detailed component-level diagnostics of an industrial asset fleet, so the OT team can perform maintenance with a clear root cause.\nThe following dashboard figure shows that pump #2 is currently in alarm and indicates which sensors are most associated with the detected anomaly.\nFigure 2: AWS IoT SiteWise Monitor dashboard developed with this solution to monitor pump assets\nMeasurements were taken around the four main components of the centrifugal pump: impeller, shaft, motor, and volute. For other sensors not positioned on one of these four components, they are organized under a general category: pump. From this reference, sensors 0-5 are within the pump level, sensors 6-11 are within the impeller component, sensors 12-17 are within the motor, sensors 18-23 are within the volute, and sensors 24-29 are within the shaft.\nThe solution scope includes:\n1. \xe2\x80\x9cSiteWiseSimulator\xe2\x80\x9d AWS CloudFormation template that contains the following core workflows:\nCreate AWS IoT SiteWise asset models for pump station and pump, and define their hierarchy relationship;\nCreate AWS IoT SiteWise alarm model to enable automatic alert notification for anomalies;\nCreate AWS IoT SiteWise assets based on asset models defined earlier, and enable MQTT notification for AWS IoT SiteWise data streaming to Amazon Simple Storage Service (Amazon S3);\nAWS Lambda function to write sensor data periodically to AWS IoT SiteWise with BatchPutAssetPropertyValue API call.\n2. Amazon Lookout for Equipment workflow with Amazon SageMaker notebooks:\nTrain Lookout for Equipment ML model;\nCreate inference scheduler to monitor multiple assets nearly continuously.\n3. \xe2\x80\x9cl4esitewise_pipeline\xe2\x80\x9d AWS CloudFormation template that contains the following data engineering pipeline to integrate Lookout for Equipment with AWS IoT SiteWise:\nStream AWS IoT SiteWise data to S3 in near-real time;\nLambda function for transforming raw telemetry data from AWS IoT SiteWise to the dataset format required by Lookout for Equipment on a predefined schedule (see l4einference-schedule.zip)\nLambda function for sending the inference results from Lookout for Equipment back into AWS IoT SiteWise. This Lambda function will also send a diagnosis from Lookout for Equipment to AWS IoT SiteWise, so the OT team can use this diagnosis to identify which sensor/component is behaving abnormally (see l4eoutput-2sitewise.zip)\n4. An AWS IoT SiteWise Monitor dashboard to visualize the Lookout for Equipment diagnosis with AWS IoT SiteWise data in real time.\nArchitecture\nFor this solution, a simulator is created to publish telemetry of the physical operations of two industrial assets\xe2\x80\x94the two centrifugal pumps. Each pump contains 30 sensor readings as measurements. Sensor measurement values of these assets are updated at a frequency of 1 Hz to AWS IoT SiteWise. To transform AWS IoT SiteWise data to the format accepted by Amazon Lookout for Equipment, the data pipeline needs to perform the following steps:\nAWS IoT SiteWise data is exported to Amazon S3 first;\nA Lambda function will be initiated at a 5-minute interval to analyze and process AWS IoT SiteWise data in S3;\nThe processed data will be saved as csv files in S3 as inference data inputs.\nLookout for Equipment first trains two models based on historical datasets from these two assets. Next, it deploys the best-fit model by setting up an inference scheduler at five-minute intervals, and produces an anomaly score on the csv files containing the AWS IoT SiteWise data. Once the inference scheduler outputs the predictions as csv files in S3, a Lambda function is initiated to update model diagnostics from Lookout for Equipment in AWS IoT SiteWise. If the prediction from Lookout for Equipment is abnormal, alarms defined within AWS IoT SiteWise will be initiated, and alarms can be visualized in a SiteWise Monitor application in real time. Further notifications to the OT team can also be set up if desired. In this architecture, Lambda functions play a pivotal role to connect the two key services together. Lambda functions can achieve high concurrency, and therefore easily scale up to meet the demand of complex industrial system with many assets.\nFigure 3: Solution Architecture for AWS IoT SiteWise integration with Amazon Lookout for Equipment\nWalkthrough\nThis post features the key solution milestones for conciseness, but readers should visit the GitHub repository for a full walkthrough and source code. This two-part post contains:\nPart 1 (this post):\nStep 1: deploy a simulator of a pump station. This step shows how to create industrial assets with AWS IoT SiteWise, and monitor data flow with a dashboard built in AWS IoT SiteWise Monitor.\nStep 2: Create data pipeline resources to (1) transform data for Lookout for Equipment as inference input and (2) fetch Lookout for Equipment inference results back to AWS IoT SiteWise.\nPart 2:\nStep 1: Train the Lookout for Equipment model with historical training data and evaluate model performance.\nStep 2: Use Lookout for Equipment to establish inference scheduler to provide anomaly prediction for assets.\nStep 3: Augment the dashboard built in Part 1 with the Lookout for Equipment service for anomaly alerts and remote monitoring.\nThe following steps will provide detailed instructions on developing this solution. To follow this blog to build the previously mentioned workflow, you don\xe2\x80\x99t need any specialized ML or IoT experience to set this up.\nPrerequisites\nFor this walkthrough, you should have the following prerequisites:\nAn AWS account. If you don\xe2\x80\x99t have an AWS account, follow the instructions to create one.\nA user role with AdministratorAccess (service access associated with this role can be constrained further when the workflow goes to production).\nA modern web browser (such as latest versions of Mozilla Firefox or Google Chrome).\nNo specialized knowledge is required to build this solution, but basic Linux and Python knowledge will help.\nStep 1: Create a pump station simulator\nIn realistic industrial settings, AWS IoT SiteWise uses AWS IoT SiteWise Edge software to automate the process of collecting industrial data by using multiple industrial protocols with pre-packaged connectors. Besides AWS IoT SiteWise Edge data ingestion, AWS IoT SiteWise supports other data ingestion methods, including using an AWS IoT SiteWise API call with BatchPutAssetPropertyValue call function. The API accepts a payload that contains timestamp-quality-value (TQV) structures, so developers can collect data from several devices and send it all in a single request. In this blog, a simulator is set up via a CloudFormation stack and uses the BatchPutAssetPropertyValue API call to send data from 30 sensors at the frequency of 1 Hz to pump assets. We recommend using the API call to publish data to avoid lengthy instruction for a device simulator, such as Kepware server.\nTo set up the simulator, log on to the AWS Management Console for CloudFormation, and use this AWS CloudFormation stack to create the following AWS resources:\nThree AWS IoT SiteWise assets: two for centrifugal pumps (child asset) and one for a pump station (parent asset);\nTwo AWS IoT SiteWise alarm models: one for the pump station and one for a centrifugal pump;\nAWS Lambda functions to create alarm models, asset models, and assets, and publish sensor data to AWS IoT SiteWise programmatically.\nFor a full list of resources created from this CloudFormation, refer to the GitHub project.\nNext, proceed to Specify stack details, provide a Stack name, and DemoDurationDays, then choose Next(Figure 4). Note that this simulator stack will be deleted automatically once the DemoDurationDays specified here is reached, and AWS IoT SiteWise resources created from this stack will be deleted. This does not include the AWS IoT SiteWise Monitor resources you will create manually later.\nFigure 4: Specify the CloudFormation stack details\nOn the next screen, called Configure stack options, choose Continue. Finally select the \xe2\x80\x9cI acknowledge that AWS CloudFormation might create IAM resources\xe2\x80\x9d agreement and choose Create. More detailed instructions on CloudFormation stack creation can be found in the AWS documentation.\nAfter deployment of the CloudFormation, check that the template has the status CREATE_COMPLETE on the AWS CloudFormation console. Select the stack and then choose the Outputs tab. Take note of both FirstAssetId and SecondAssetId, since you will use them in step 2 to set up the Lookout for Equipment integration workflow.\nFigure 5: Output section of the CloudFormation stack\nNow that you have finished deploying the SiteWiseSimulator stack, navigate to the AWS IoT SiteWise console. First select Assets, and check the assets\xe2\x80\x99 status as ACTIVE for both pump assets and the pump station asset.\nFigure 6: AWS IoT SiteWise console\nTo manage industrial asset data streams efficiently, AWS IoT SiteWise uses the concept of asset to model the physical operations of industrial assets. Using AWS IoT SiteWise asset, industrial data can be organized within a specific hierarchy level with associated parent and child models. In this blog, a pump station asset is set up as a parent asset, and it comprises of two child assets: each individual centrifugal pump. With the asset hierarchy, you can calculate statistics across multiple assets and achieve management for large-scale assets. For example, the pump station anomaly score metric (\xe2\x80\x9cTotal L4EScore\xe2\x80\x9d measurement tag) is calculated as a sum of the individual anomaly score from each child pump asset.\nTo facilitate a detailed component-level diagnosis, Amazon Lookout for Equipment provides model diagnostics for each detected abnormal behavior. These diagnostics indicate which sensors within the asset are contributing to the anomaly. This blog shows a solution to ingest the anomaly score for each sensor to AWS IoT SiteWise via a specific measurement tag for each sensor as: Sensor X L4EScore. A high L4EScore is a strong indicator of an anomaly that warrants action from the operations team. Customers can use these insights to diagnose the problem and take corrective action.\nFigure 7: Measurement definition within AWS IoT SiteWise\nWith the latest AWS IoT SiteWise alarm function, an alarm can be directly configured within an AWS IoT SiteWise asset model. The OT teams can then use such an alarm to get alerted quickly to suboptimal equipment status. To avoid false positive alarms, the metric AVG L4E Score is used to calculate the average Asset L4E Score inferred by Lookout for Equipment in the past 5 minutes. The AWS IoT SiteWise alarm l4e Alarm will evaluate the AVG L4E Score against a user-defined threshold to set the state of the alarm. Once the alarm threshold is exceeded, suitable notification methods can be defined accordingly, such as using Amazon Simple Notification Service to send emails or text messages.\nFigure 8: AWS IoT SiteWise alarm definition\nTo verify the data flow in AWS IoT SiteWise, customers can quickly set up a SiteWise Monitor dashboard to monitor real-time data ingestion. SiteWise Monitor is a feature of AWS IoT SiteWise that lets you create portals as a managed web application. To monitor the data from your assets, you will create a project and dashboards for assets within AWS IoT SiteWise. Your portal can also be shared with other users without the need for them to have an AWS account. First, you\xe2\x80\x99ll create a portal and a project with associated assets within AWS IoT SiteWise. Next, you can create a dashboard within the project you created earlier. The initial dashboard contains the real-time sensor data values from Demo Pump Asset 1 ingested in AWS IoT SiteWise. For each visual, sensor values from the same component are plotted together.\nFigure 9: AWS IoT SiteWise Monitor dashboard\nStep 2: Create Data Pipeline to Integrate Amazon Lookout for Equipment and AWS IoT SiteWise\nAmazon Lookout for Equipment requires sensor and label data in a .csv format. The inference output from Lookout for Equipment is exported as a JSON file into the Amazon S3 bucket that you specified. To integrate AWS IoT SiteWise asset data with Lookout for Equipment, a low-latency data pipeline is needed to perform two tasks:\nTransform AWS IoT SiteWise data to the specific data format used by Lookout for Equipment;\nPublish inference results back to AWS IoT SiteWise as new measurements.\nThis data pipeline is comprised of four parts:\nStream AWS IoT SiteWise data to S3 in near-real time;\nUse a Lambda function to initiate Amazon Athena at a scheduled time to reformat data in S3, and output data as .csv file for the Lookout for Equipment inference;\nAfter the Lookout for Equipment inference has finished, use the Lambda function to ingest Lookout for Equipment output data to specific measurement tags in AWS IoT SiteWise;\nSet up AWS resources for running Lookout for Equipment service (for example, a SageMaker notebook containing API calls to Lookout for Equipment).\nThis data pipeline is deployed as a CloudFormation stack in this blog. For a full list of AWS resources created from this CloudFormation, refer to the GitHub project. Since this CloudFormation resource provisioning step is similar to the procedure described in Step 1, detailed instruction can be found on GitHub.\nAfter the stack is successfully created, you can review the following data pipeline. These steps are optional and covered here for a deeper understanding of the solution.\nReview your asset property and asset metadata in Amazon S3. Navigate to the S3 console, and check the S3 bucket that was created from the stack for AWS IoT SiteWise data storage. There are two different approaches to export AWS IoT SiteWise data to S3. The first approach is to use an AWS CloudFormation template to create the required resources to stream incoming data from AWS IoT SiteWise to an S3 bucket in near-real time (one export per minute). Then, the S3 bucket saves all AWS IoT SiteWise property value update messages in the folder asset-property-updates. The S3 bucket also stores metadata for AWS IoT SiteWise assets, which include asset and property names and other information, in the folder asset-metadata. The second approach is to opt-in export measurement data to S3 from the AWS IoT SiteWise console. Once you opt in to export your data to S3, all you need to do is to provide the URL to an S3 bucket in your AWS account. However, the frequency of asset metadata export is once per 6 hours. In this blog, the first approach is used to export AWS IoT SiteWise data to reduce inference latency for Lookout for Equipment.\nFigure 10: S3 folders created to store AWS IoT SiteWise data\nRun Amazon Athena named query for both demo pump assets and review the output data format. Navigate to the Athena console, select the database from the list that looks similar to sitewise2s3_firehouse_glue_database (yours may differ based on the specified prefix), and you will find two Athena views created by the Athena named query: l4e_inference_data_pump1 and l4e_inference_data_pump2. You can select Preview from the contextual action menu icon (\xe2\x8b\xae) on the right of l4e_inference_data_pump1. The sensor data from all 30 sensors of this pump are shown in Figure 11.\nFigure 11: Outputs from Amazon Athena query\nThe output from the Athena query pivoted the asset property values, and it follows a schema that Lookout for Equipment accepts for inference. You can find more details in the AWS documentation on how to use AWS Glue and Athena to analyze AWS IoT SiteWise data.\nLambda function LocalResourcePrefix__l4einferenceschedule. The Lambda function prepares inference input data in an S3 bucket for Lookout for Equipment. This Lambda will first collect reformatted AWS IoT SiteWise data generated by Athena NamedQuery. Fill in the empty property value and output the data as a csv file with a file name defined by Lookout for Equipment inference scheduler. Since the minimum inference frequency of Lookout for Equipment is once per 5 minutes, the Lambda function will be initiated by a CloudWatch Event at the same frequency to process data. You can navigate to the Monitoring section in the AWS Lambda console to monitor the Lambda functions, to troubleshoot, or to optimize the pipeline performance. As shown in Figure 12, this Lambda function is concurrently invoked twice, one for each Demo Pump asset dataset. The multiple invocation is achieved by using the UUID of AWS IoT SiteWise assets as part of the input events of the Lambda function. Such multiple invocation patterns can be extended for monitoring hundreds of industrial assets.\nFigure 12: CloudWatch metrics for the Lambda function\nLambda function \xe2\x80\x9cLocalResourcePrefix_l4einferenceoutput\xe2\x80\x9d. This Lambda function is deployed to publish Lookout for Equipment predictions to AWS IoT SiteWise. A prediction field 0 indicates normal equipment behavior, and a prediction field 1 indicates abnormal equipment behavior. Once the JSON prediction output from Lookout for Equipment is uploaded to the S3 bucket, the Lambda function will be initialized by this S3 PutObject action. This Lambda function will update the Asset L4E Score measurement in AWS IoT SiteWise with the Lookout for Equipment prediction. When the prediction is 1, Lookout for Equipment returns an object that contains a diagnostic list. The diagnostics list has the name of the sensors and the weights of the sensors\xe2\x80\x99 contributions in indicating abnormal equipment behavior. In this blog, the diagnostics for each sensor is also ingested to AWS IoT SiteWise via the measurement tag SensorX L4EScore, where X stands for sensor number. Note that this measurement tag is only updated when the Asset L4E Score is equal to 1, otherwise this measurement tag remains as null. Also note, this Lambda function will not be invoked until the Lookout for Equipment inference service has initiated, as explained in detail in part 2 of this series.\nOther relevant resources. This data pipeline CloudFormation stack also creates other Amazon ML resources, including a SageMaker notebook instance for running SageMaker notebooks. The purpose of these SageMaker notebooks is to provide API calls to Lookout for Equipment for ML model training and inference. They also show readers a data exploration and model evaluation process to understand the business problem. Note that these notebooks are not required with Lookout for Equipment. Users can directly use this service with relevant API call as well. To use Lookout for Equipment to schedule inference, two S3 paths are created, one for Demo Pump Asset1 as l4ebucketprefix-asset1-train-inference, and one for Demo Pump Asset 2 as l4ebucketprefix-asset2-train-inference.\nSummary of Part 1\nIn Part 1 of this two-part series, you learned:\nHow to create industrial assets with AWS IoT SiteWise, and monitor data flow with a dashboard built in AWS IoT SiteWise Monitor;\nHow to create data pipeline resources to integrate Amazon Lookout for Equipment service with AWS IoT SiteWise.\nIn Part 2, you will learn how to train ML models for pump assets, and evaluate the model with the historical dataset. You will create an inference scheduler with Lookout for Equipment to monitor your device nearly continuously with this applied ML service. Finally, you will learn how to visualize ML-driven asset performance monitoring from Lookout for Equipment with AWS IoT SiteWise Monitor.\nAbout the authors\nJulia Hu is a ML&IoT Architect with Amazon Web Services. She has extensive experience in IoT architecture and Applied Data Science, and is part of both the Machine Learning and IoT Technical Field Community. She works with customers, ranging from start-ups to enterprises, to develop AWSome IoT machine learning (ML) solutions, at the Edge and in the Cloud. She enjoys leveraging latest IoT technology to scale up her ML solution, reduce latency, and accelerate industry adoption.\nDastan Aitzhanov is a Specialist Solutions Architect in Applied AI with Amazon Web Services. He specializes in architecting and building scalable cloud-based platforms with an emphasis on machine learning, internet of things, and big data-driven applications. When not working, he enjoys going camping, skiing, and spending time in the great outdoors with his family.\nMicha\xc3\xabl Hoarau is an AI/ML specialist solution architect at AWS who alternates between a data scientist and machine learning architect, depending on the moment. He is passionate about bringing the power of AI/ML to the shop floors of his industrial customers and has worked on a wide range of ML use cases, ranging from anomaly detection to predictive product quality or manufacturing optimization. When not helping customers develop the next best machine learning experiences, he enjoys observing the stars, traveling, or playing the piano.\nSebastian Salomon is a Sr IoT Data Architect with Amazon Web Services.\nHe has 7+ years of experience in IoT architecture in different vertical like IIoT, Smart Home, Smart City and Mining as well as data warehousing and big data platform. In the latest years he got focus in how to bring AI to IoT through scalable MLOps platforms. As a member of AWS Professional Services, He works with customers of different scale and industries architecting and implementing a variety of end to end IoT solutions.\n '"
105,Collecting vehicle data more efficiently with AWS IoT FleetWise,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/collecting-vehicle-data-more-efficiently-with-aws-iot-fleetwise-2/,"b'Today, we think of connected vehicles as an advanced class of vehicle with internet connectivity. However, we will soon refer to these simply as vehicles, since by 2030, over 95 percent of new vehicles sold globally will be connected to the internet, up from about 50 percent today.\xc2\xb9 Greater vehicle connectivity gives automakers opportunities to improve vehicle quality, safety, and autonomy, but it also brings challenges\xe2\x80\x94namely, how to efficiently collect and utilize the massive amounts of data generated by connected vehicles. In this post, we will walk through AWS IoT FleetWise, a new service that makes it easy and cost effective for you to collect and transform data from millions of vehicles and transfer it to the cloud in near-real time. Once the data is in the cloud, you can use it for tasks like analyzing fleet-wide vehicle health or training machine learning (ML) models that improve autonomous driving and advanced driver assistance systems (ADAS).\nChallenges with collecting vehicle data\nData variety\nEvery variation of a vehicle model generates data in a unique format, which causes a mind-boggling amount of potential unique vehicle data configurations, data structures, and schemas. For example, an automaker may have 10-15 models in its lineup, with each model having hybrid, all-wheel drive (AWD), and advanced safety options.\nAdditionally, most vehicle data is not readable by humans and is encoded in proprietary formats specific to automakers or suppliers, such as data sent over a vehicle\xe2\x80\x99s Controller Area Network Bus (CAN Bus). To make the data usable, automakers must first decode it then reconcile it across their fleets. For example, data coming from a fuel pressure sensor might be represented as Fuel_Press on model A, and Injector_Press on model B. Collecting and reconciling this data across multiple variations of vehicle models is a heavy lift and requires automakers to build, scale, and maintain custom data collections systems.\nData volume\nNot only are there increasing numbers of connected vehicles, but each vehicle also has increasing numbers of sensors generating data. Each sensor has capacity to generate richer data, especially advanced sensors like radars and cameras. For example, vehicles today now have multiple cameras, and cameras are evolving from 1 to 3 to 8 megapixels. In short, data volume is increasing at an exponential rate, which makes it more difficult to manage.\nAs vehicles continue transitioning to higher levels of autonomy, automakers need to transfer increasing volumes of data to cloud so they can use it for continuous AI/ML model training and improvement. However, cloud data transfer is cost prohibitive across a fleet of production vehicles. A single autonomous vehicle can generate up to 2 TiBs of data hourly per vehicle. As a result, automakers often resort to using autonomous test fleets with specially built on-board storage as a work-around for getting the data they need to train AI/ML models.\nGetting started with AWS IoT FleetWise\nPre-requisites\nAWS IoT FleetWise has both cloud and embedded software components. You can deploy AWS IoT FleetWise completely in the cloud before deploying on physical vehicle hardware to simulate collecting vehicle data; the only prerequisite is an AWS account and an Amazon Timestream table. To deploy on physical hardware and real-life vehicles, AWS IoT FleetWise Edge requires a POSIX-based operating system (OS). Knowledge of C/C++, POSIX APIs, and in-vehicle networking protocols such as CAN and external connectivity protocols such as MQTT are helpful when using AWS IoT FleetWise.\nModel a virtual vehicle\nAWS IoT FleetWise helps solve the data variety problem with virtual vehicle modeling. When you model a vehicle in the cloud, you standardize vehicle attributes (e.g. a two-door coupe) and sensors (e.g. fuel pressure, engine temperature) across multiple vehicle types, so a signal like fuel pressure is always represented as fuel_pressure. This modeling process allows for easy fleet-wide data analysis in the cloud.\nTo create a virtual vehicle, use the AWS IoT FleetWise Console or APIs to upload automotive standard files (such as a CANDBC), which AWS IoT FleetWise parses into a draft virtual vehicle model. You also have the choice to pick one of the pre-configured templates in AWS IoT FleetWise, such as OBD-II signals, which automatically creates a vehicle model for you based on the OBD-II standard.\nTo create an OBD standard model:\nOpen the AWS IoT FleetWise Console.\nNavigate to the Vehicle models menu item.\nClick the Add provided template button.\nSelect OBD_II, and input CAN Channel (Default is can0) and click Add.\nWhen you create an OBD model, AWS IoT FleetWise creates a decoder manifest automatically for you based on the OBD standard. The decoder manifest allows AWS IoT FleetWise to decode the proprietary signals on your vehicle. You can view decoder manifests within the vehicle model detail page:\nOnce you have a model and associated decoder manifest, you can create vehicles using the Create Vehicle API.\nSet up rules-based data collection\nAWS IoT FleetWise helps solve the data volume problem with rules-based data collection, which reduces the amount of unnecessary data transferred to the cloud. You select what data to collect, such as data from safety equipment, EV battery charge, or any other data generated by the vehicle\xe2\x80\x99s sensors. Then, you define rules and events for when to transfer that data based on parameters such as weather, location, or vehicle type. Setting up these data collection rules helps to keep costs low and gives access to more useful data.\nThe rules you define are contained within JSON documents known as schemes. There are two primary types of schemes: time-based collection and event-based collection. Time-based collection selects signals of your choosing at a given time interval as shown below:\nThe below scheme collects the Throttle Position signal every 10000MS or 10 seconds.\n{\n""compression"": ""SNAPPY"",\n""diagnosticsMode"": ""SEND_ACTIVE_DTCS"",\n""spoolingMode"": ""TO_DISK"",\n""collectionScheme"": {\n""timeBasedCollectionScheme"": {\n""periodMs"": 10000\n}\n},\n""postTriggerCollectionDuration"": 0,\n""signalsToCollect"": [\n{\n""maxSampleCount"": 1,\n""signalName"": ""Throttle__Position""\n}\n]\n}\nJSON\nAn event-based collection scheme is similar to time-based, but instead of collecting data at regular time intervals, you create a rule to trigger AWS IoT FleetWise to collect data. Below is an example event-based collection scheme, which collects two signals [Vehicle_Speed and Instant_Torque] when a specific condition is met; specifically, when the throttle position is greater than 0. AWS IoT FleetWise will collect these signals for 1000ms after the event is detected as instructed by the \xe2\x80\x9cpostTriggerCollectionDuration\xe2\x80\x9d field in this scheme.\n{\n""compression"": ""SNAPPY"",\n""diagnosticsMode"": ""SEND_ACTIVE_DTCS"",\n""spoolingMode"": ""TO_DISK"",\n""collectionScheme"":{\n""conditionBasedCollectionScheme"": {\n""conditionLanguageVersion"": 1,\n""expression"": ""$variable.`Throttle__Position` > 0"",\n""minimumTriggerIntervalMs"": 1000,\n""triggerMode"": ""RISING_EDGE""\n}\n},\n""postTriggerCollectionDuration"": 1000,\n""signalsToCollect"": [\n{\n""maxSampleCount"": 10,\n""signalName"": ""Vehicle_Speed""\n},\n{\n""maxsamplecount"": 10,\n""signalName"": ""Instant_Torque""\n}\n]\n}\nJSON\nOnce you create schemes, you deploy them to vehicles using the create and approve campaign operations within the AWS IoT FleetWise Console. Once schemes deploy to vehicles, you will see data start flowing through AWS IoT FleetWise into your Amazon Timestream database.\n'"
106,"Introducing AWS IoT ExpressLink, making it faster and easier to develop secure IoT devices",b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/introducing-aws-iot-expresslink-making-it-faster-and-easier-to-develop-secure-iot-devices/,"b'Introduction\nDeveloping and deploying secure IoT products can be challenging. It can often take months, or even years to connect a product securely to the cloud in a way that is scalable and easy to maintain for the life of the product. Today, IoT products require developers to handle a complex software stack and master a range of technologies from embedded development, to networking, cryptography and cloud architecture, all of which are rare skills to find in a single developer. An IoT project can quickly snowball into a complex endeavor with long development cycles and high failure rates. Modules that use AWS IoT ExpressLink make it faster and easier for developers of all skill levels to securely connect almost any device to the cloud and seamlessly integrate with over 200 AWS IoT services, including AWS IoT Core.\nIn this post, we will review the common challenges developers face when building IoT devices. You will learn how modules with AWS IoT ExpressLink help overcome these obstacles so you can securely connect embedded devices in weeks rather than years, lower costs, and accelerate time to market.\nComplexity hides cost and vulnerabilities\nA typical IoT application adds 50,000 (or more) lines of new embedded C code to a project. This is because many developers start by merging the connectivity code with the product feature code to run on a single microcontroller or microprocessor. The challenge is that this increase in code is difficult to manage and maintain while security vulnerabilities are concealed across hundreds of folders and files. Moreover, the resource-constraints of an embedded application can jeopardize product success. Take for example the tiny processor in a coffee machine. The increase in complexity may force you to rewrite the application from scratch or increase the project scope and budget, significantly increasing costs and delaying time to market. Additionally, the large code base requires ongoing investment to keep the connected product secure by continually analyzing and patching security vulnerabilities which is a costly exercise over the life of the product.\nUndifferentiated work\nTo create a secure IoT device, developers use complex APIs to achieve cloud connectivity:\nConnect to a Physical Layer (i.e., Wi-Fi radio)\nEstablish TCP/IP communication\nConnect to an Internet Protocol endpoint\nUpgrade to a secure socket interface (TLS) and perform mutual Authentication\nLog into an MQTT broker\nSubscribe to topics as required\nDespite the complexity of each step and amount of time and resources it takes to ensure each one is executed reliably and securely, none of these steps has a material impact on the customer experience, other than simply enabling cloud connectivity. The technical knowledge required to execute these steps is rare to find, forcing companies to either invest in creating a team of connectivity experts, or outsource the work to consulting services. As a result, resources are diverted from building innovative products and instead, spent on repetitive, undifferentiated work.\nCEO of \xc4\x93dn, Ryan Woltz, faced several of these pain points when building his smart indoor gardening devices that featured on Shark Tank. Woltz wanted his team to move quickly and focus on building brand-defining features with machine learning and artificial intelligence. Instead, he found they spent most of their time on the undifferentiated work, trying to reinvent the wheel and worrying about the security of the product. As Woltz notes, \xe2\x80\x9cDeveloping connected firmware is harder than hardware!\xe2\x80\x9d\nIntroducing AWS IoT ExpressLink modules\nAWS IoT ExpressLink powers a range of hardware modules developed and offered by AWS Partners, such as Espressif, Infineon, and u-blox. With these connectivity modules, you no longer need to be an expert in networking, cryptography, and authentication protocols to develop secure IoT devices. Now, you can shift the complex but undifferentiated work of cloud connectivity to the module and seamlessly integrate with a range of AWS IoT services in a fraction of the time and cost (see figure 1). Our family of qualified AWS partner modules allow you to choose from a range of form factors and connectivity technologies, such as Wi-Fi and Cellular, to suit your needs.\nFigure 1 \xe2\x80\x93 Modular design of connected applications with AWS IoT ExpressLink\nHow it works\nQuickly and easily connect to the cloud\nAWS IoT ExpressLink helps developers with the complex and security-critical code by packaging it into a single hardware component. With just 3 wires (TX, RX, and GND) you have everything you need to connect any embedded device to the cloud. Three more pins on the host processor provides more control and efficiency in the connection if the host processor can spare them.\nFigure 2 \xe2\x80\x93 AWS IoT ExpressLink physical interface\nWhether you are using a Wi-Fi or a cellular LTE-M module, your application can now be expressed in 10 simple lines of code (see Figure 3). Our Programmers Manual includes a dozen Attention (AT) commands to help you get started. By abstracting away the details of the communication medium and allowing you to send AWS IoT ExpressLink commands as simple as \xe2\x80\x9cconnect\xe2\x80\x9d, \xe2\x80\x9csend\xe2\x80\x9d, and \xe2\x80\x9csubscribe,\xe2\x80\x9d you can focus time and resources on the differentiating aspects of your application and the strategic value you provide.\nint main()\n{\n    print(""AT+CONNECT\\n"");\n    while(1){\n        print(""AT+SEND data {\\""A\\""=%d}"", getSensorA());\n        delays(1);\n    }\n}\nFigure 3 \xe2\x80\x93 AWS IoT ExpressLink pseudo-code example\nAs a result, your development will not be slowed down by any of the following:\nDependencies on the media layer\nExplicit dependencies on the protocols\nDependencies on the cloud security protocols\nReferences to the many (ISO/OSI) stack layers traversed by the application\nSecurity built in\nEvery module with AWS IoT ExpressLink comes pre-provisioned with security credentials set by qualified AWS Partners. They also include AWS-validated software, enabling you to directly connect to AWS IoT Core and 200+ AWS IoT services. AWS IoT ExpressLink modules implement security best practices, providing:\nA hardware root of trust, pre-provisioned with unique IDs and pre-signed certificates\nSecure secrets storage\nEncrypted communication to and from the cloud\nSecure Boot\nOver-the-Air (OTA) updates to the module\xe2\x80\x99s firmware with security patches and feature updates provided and signed by the module manufacturers\nOTA updates to the host processor, with the ability to transfer any type of file and verify its integrity and authenticity with your signature\nBuilt-in support for continuous device health monitoring\nAWS provides AWS IoT ExpressLink connectivity software and technical specifications for Partners to use in their modules. AWS also reviews results from qualification tests that Partners run before the modules are approved for listing in the AWS Partner Device Catalog. This helps to validate that security is built into the product from the outset, rather than treated as an afterthought.\nDeploy and manage at scale\nEvery module with AWS IoT ExpressLink comes pre-provisioned with a unique identifier and a certificate to simplify deployment at scale. The modules can be onboarded in a user account using a number of common methods, and make it easy to support late-binding onboarding mechanisms to increase flexibility and reduce manufacturing time and cost. Moreover, with AWS IoT Device Defender you can natively monitor your devices\xe2\x80\x99 health and easily manage your fleets at scale with AWS IoT Device Management.\nGetting started\nOrder your AWS IoT ExpressLink evaluation kits today from the following AWS partners: Espressif, Infineon and u-blox. All three offer different implementations of a Wi-Fi connectivity module. Additionally, u-blox offers a first implementation of AWS IoT ExpressLink with cellular connectivity.\n'"
107,Improving building operational performance with Cognizant 1Facility and AWS IoT TwinMaker,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/11/29/Slide3-1-1024x576.png,https://aws.amazon.com/blogs/iot/improving-building-operational-performance-with-cognizant-1facility-and-aws-iot-twinmaker/,"b'Post also written by Shardul Pradhan and Ramesh Yechangunja from Cognizant\nIntroduction\nRecent market conditions have stressed the commercial building management market due to the increased cost of construction, reduced occupancy, and increased cost of labor to monitor and maintain buildings. This is fueling the need for smarter and safer buildings. According to research from a Research And Markets article, the global smart spaces market is estimated to grow from $8.5 billion in 2019 to $19.9 billion by 2024. Building occupants expect issues to be resolved quickly and without impacting their environment. To accomplish this, building owners must be able to identify, predict, and respond to issues in a timely and cost effective manner as ongoing operating costs represent a significant portion of a buildings total cost of ownership over a buildings lifetime. Monitoring the performance of buildings is critical as it will help building owners understand the state of their building and improve decision making.\nIn this post we explore how Cognizant\xe2\x80\x99s 1Facility solution can leverage the new AWS IoT TwinMaker service to help improve the building monitoring experience by reducing the time to troubleshoot a building issue via 3D visualization and aggregating data from multiple sources in a connected building.\nFacilities operations and maintenance\nManaging a commercial building requires multiple objectives, with competing priority, to be satisfied simultaneously including:\nEnsuring health, safety, and comfort of the occupants\nReducing energy usage\nMeeting environmental and other government regulations\nLowering cost of monitoring, maintaining, and operating the building\nTo satisfy these objectives the building data must be measured and reviewed. Building data is typically collected by disparate systems and sensors and even if the data is migrated to the cloud, it will be in different storage locations and formats. Individual applications monitor each of these areas, but these applications focus on its data, its objective, and alarms related to its function. The facility manager is responsible for manually associating disparate information to determine the full understanding of the state of their building.\nA single visualization interface that federates data from multiple sources and organizes it in a meaningful way will allow building staff to effectively monitor the status of the building. Without this, staff will spend their time switching between systems without perspective on the entire building. The facility manager may miss transitory issues if they occur for a short period of time, such as when another system is being reviewed, and they are not logged to a central system. Alternatively, the underlying cause of an anomaly or alarm can be missed because relevant data is stored in multiple systems that are not linked. The context of a particular textual alarm may be lost on an inexperienced building operator. An early anomaly that is ignored may lead to a much more serious issue. The issue may be associated with the incorrect subsystem and lead to unnecessary work orders. By focusing on a single consolidated view that curates the data and uses 3D models of the building to highlight the issue will help a building operator to more quickly identify and take the appropriate mitigation steps while also monitoring key performance indicators(KPI) related to building performance and energy usage.\nCognizant\xe2\x80\x99s 1Facility solution addresses these business needs and is used by building owners and facility managers to enhance their level of awareness, intelligence, and remote management of buildings by connecting disparate storage mechanisms, sensors, and building monitoring applications into a single system.  The 1Facility solution reduces installation and operating costs by having pre-built modules to meet common facilities management use cases. AWS IoT TwinMaker enhances the capabilities of 1Facility via 3D visualization of the building helping to quickly locate building issues, even for less experienced operators, while also reducing the level of effort to build and maintain connections to the facility\xe2\x80\x99s data.\nUse case walkthrough: Remote alarm triaging\nIn this example, the facility manager focusses on a single building as opposed to the multiple buildings they manage. The application displays a 3D view of the building that an operator can virtually navigate through. A list of alarms for the entire building is shown and can be filtered to only show active alarms. Key parameters including occupancy of the building, energy utilization, as well as the environmental conditions such as ambient temperature and air quality are presented on the building level view \xe2\x80\x93 the dashboard can be customized based on specific requirements. By default, the application will present the most current data and aggregate measurements.\nWhen an alarm occurs in any floor or zone of the building the dashboard surfaces the issue via a new entry on the list of alarms and highlights the floor in the building 3D model. The entry in the alarm list provides tabulated information including the alarm name, time of the alarm, the rule that was breached, and information about the location including zone and floor. Highlighting the alarm on the 3D model provides the facility manager spatial and contextual awareness, especially if multiple alarms are triggered.\nConsider the alarm in this case is a low temperature alarm in zone A on floor 6. This could be an occupant comfort issue, a failed HVAC system, or possibly an energy management issue if a window was left open, especially because this zone contains a room that is part of the building\xe2\x80\x99s exterior. The facility manager will want to track down the root cause of this alarm so the issue can be corrected and future issues mitigated. To accomplish this they will navigate to the floor dashboard by selecting the floor name in the list of alarms or from the floor navigator drop down.\nIn this floor dashboard the particular zones or objects of interest causing the alarm will be highlighted to draw the attention of the facility manager. The alarm list shows current and historical alarm records for this floor. KPI indicators and line graphs present information about the floor in aggregate in the default view. The facility manager can explore the zone in question or other areas of interest by clicking on the anchor points in the 3D model. The data presented in the KPI indicators and line graphs will change based on the selected anchor point.\nIn our example, the facility manager explores the temperatures and other measurements in adjacent zones and observes that the temperature of all adjacent zones is normal. As the dashboard displays all the relevant data for this floor the facility manager identifies that the HVAC system is working as expected. Consider that while the facility manager is exploring the data that the alarm resolves itself, and is indicated as such in the alarm table. The temperature in zone A was only slightly low and did not show any discontinuities, so the temperature sensor is likely operating as expected. The facility manager forms a hypothesis that there is either a window open letting in cold air or possibly the air delivery system circulating hot air in zone A is malfunctioning.\nTo explore historical data the facility manager adjusts the time window using the time/date control in the top right corner. All graphs and KPI indicators will show data for the selected time period. As the facility manager plots data over the past week, they notice that the temperature in zone A has been lower than intended, but had not been low enough to trigger an alarm. The facility manager also notices that the temperature rise profile after the HVAC air delivery system is enabled is showing a delay in temperature rise the past couple days which is not reflected in the other zones, and is continuing to worsen.\nThe facility manager determines the HVAC air delivery system is malfunctioning in zone A. According to the time series data and a visual comparison against the temperature rise in other zones the HVAC air delivery system is continuing to degrade, but now reached a point where the zone temperature drops low enough to trigger an alarm. The facility manager submits a work order with a high priority to get the HVAC air delivery system inspected and serviced by the maintenance staff before the occupants\xe2\x80\x99 comfort is affected.\nThe facility manager was able to identify and triage the issue remotely before a failure or occupant complaint. Further, the maintenance staff will be prepared to inspect and service the HVAC air delivery system based on the information from the facility manager. The 3D visualization enabled the facility manager to recognize adjacent zones and examine those temperature measurements. Combining this with historical data of multiple systems and observing the trend change the facility manager accurately concluded that an HVAC air delivery system is faulty. This solution enabled the facility manager to triage the issue quickly, assign the appropriate severity maintenance ticket, and provide insight to the maintenance staff on the issue.\nTechnical implementation of 1Facility with AWS IoT TwinMaker\n1Facility is a set of connectors, tools, and processes to extract data from building systems and sensors in an effort to improve building operations, energy efficiency, and occupant safety and comfort. The solution includes design patterns to connect to in-building data sources, transmit data to the cloud, calculate KPI\xe2\x80\x99s, and identify issues in the building. A dashboard layer provides an interface to display and explore this data at the building, floor, zone, and equipment level.\n1Facility is built using a number of storage mechanisms based on the type and application or system that generated the data. Data representing a single physical object is often stored across multiple storage mediums. Therefore, the user interface or application layer must make calls to multiple data sources to pull all history for a particular physical object.\nAWS IoT TwinMaker extends the capabilities of 1Facility by providing new functionality and data access improvements. Specifically, the scene composer in AWS IoT TwinMaker is used to add 3D visualization to 1Facility. This allows the facility manager to visualize the alarm information on a 3D model of the building and more quickly recognize and resolve issues. The concept of entities and components provides a framework to link the physical building to an information model enabling unified access to data across multiple sources without the need to replicate it to a central source. In the following discussion we will walk you through how a version of 1Facility leverages AWS IoT TwinMaker to provide these enhanced capabilities.\nIn this solution example, sensor data and building systems are simulated in an AWS Lambda function. The simulated data is collected using AWS IoT SiteWise. Measurements including air quality, temperature, occupancy, and energy usage are simulated. This time series data is stored in AWS IoT SiteWise along with the building hierarchy and asset models. Threshold based alarms are configured on the asset models to detect when a measurement exceeds the specified value. AWS IoT SiteWise generates the alarm records and publishes them to AWS IoT Core via a property change notification. The alarm records ultimately reside in Amazon Timestream along with external alarm data.\n1Facility uses AWS IoT TwinMaker to access data from multiple data sources that contain the state of a physical object. Physical objects in this case include buildings, floors, zones, or equipment such as vending machines or coffee makers. In AWS IoT TwinMaker real world systems such as buildings, floors, and sensors are represented as entities. Hierarchies comprised of entities are established which correspond to the physical relationship. Components are attached to the entity to define the data that is associated with the object including measurements, alarms, and the details describing the alarm. All stored data for a physical object is made available via the entity, but remains in the original storage location.\nThe time series data stored in AWS IoT SiteWise is accessed through the built-in AWS IoT SiteWise connector which is used by default with the AWS IoT SiteWise component type. The AWS IoT SiteWise connector extracts data from AWS IoT SiteWise and exposes it via AWS IoT TwinMaker APIs such as get-property-value. This means that for AWS IoT SiteWise time series data a custom connector is not required. To reduce the configuration effort the AWS IoT SiteWise component type automatically configures the available properties by pulling in all the attributes, measurements, transforms, and metrics for the specified AWS IoT SiteWise asset.\nA custom component is defined to represent the alarm data that is stored in Amazon Timestream. The custom alarm component extends the built-in basic alarm component. Additional data fields such as alarm type, time, status, condition causing rule violation, and additional metadata are defined. A Lambda function accesses records from Amazon Timestream and returns these to AWS IoT TwinMaker in the required Unified Data Query format. The component definition specifies a particular Lambda function. This Lambda function executes when a query requests data for a property defined on the component.\nFor this solution example the visualization layer is built using Grafana hosted in an Amazon Elastic Compute Cloud (Amazon EC2) instance. Amazon Simple Storage Service (Amazon S3) stores the 3D models of the floors, zones, and assets used to build the scene. Grafana interfaces with AWS IoT TwinMaker via a plugin to access the data as opposed to interfacing with the individual data sources. This enables the application developer to focus on creating meaningful visualizations rather than determining where and how to access data.\nA differentiating feature for 1Facility enabled by AWS IoT TwinMaker is the 3D display of the building and floors to help the facility manager identify, locate, and triage issues. Using the Scene Composer feature in AWS IoT TwinMaker a scene is created for each floor and also for the overall building. As a first step, you upload the 3D models that represent the zones and other equipment. To create a scene for the floor you add one or more 3D models from the Resource library and then assemble the models to represent the floor by specifying the coordinates and rotation of each model. This is repeated for each floor as well as the building scene.\nThe facility manager uses visual indicators on the 3D model to quickly identify and gain context about issues. The icon used to represent an anchor point or color of a 3D model can be adjusted via rules and rule maps configured in the scene composer. The component property tied to the anchor point or 3D model can control the appearance of the object.\nEach dashboard representing a particular building or floor will present a 3D model and data relevant to that floor or building, and the corresponding list of alarm history. The widgets on the dashboard will pull in properties such as air quality parameters, energy utilization, and aggregated occupancy by using the Get Property Value History by Entity API in Grafana. This API will retrieve the data from where it resides whether it be AWS IoT SiteWise, Amazon S3, Timestream, or other services based on the configuration of the component and Lambda function specified to retrieve the data. In this case, selecting the entity, component, and desired properties causes the Lambda function to retrieve particular time-series properties from AWS IoT SiteWise based on the specified assetID and modelID. This enables the KPI widgets and line chart widgets to be populated when a particular anchor point is selected.\nDisplaying the list of alarms by floor or by building requires a separate component type to be created for each physical object. The AWS IoT SiteWise assetID represents the physical object that generated the data. The specific AWS IoT SiteWise assetID is defined in each component type and is the filter key in the Amazon Timestream table. The component type, representing the building or a specific floor, is included when calling the Get Property History by Component Type API to return data for a specific floor or building. To return this data, AWS IoT TwinMaker executes the same custom Lambda function, but the internal logic will only return data from Amazon Timestream to AWS IoT TwinMaker where the particular assetID is present. This data is then displayed on the list of alarms in the context of the dashboard which is being observed.\n'"
108,Introducing AWS IoT TwinMaker,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/11/30/Site-Merch_AWS-IoT-TwinMaker_Blog.png,https://aws.amazon.com/blogs/iot/introducing-aws-iot-twinmaker/,"b'The \xe2\x80\x9ctwin\xe2\x80\x9d concept is not new and actually dates back to the early days of the space program. The Apollo 13 mission in the 1960s is an early use-case example of using twins. Following the explosion of an oxygen tank in the service module, the damaged spacecraft was far beyond any situation envisioned during the design, and its state was rapidly changing. So the engineers created \xe2\x80\x9ctwins\xe2\x80\x9d on Earth that represented their best understanding of the damaged state using all the engineering information available coupled with the latest sensor readings and observations from the astronauts. These twins were instrumental for NASA engineers on Earth to understand the astronauts\xe2\x80\x99 predicament and drove operational decisions to return the astronaut crew safely back to Earth.\nIn more recent times, digital twins gained traction and have become increasingly feasible with advances and convergence of at-scale computing (in the cloud), new modeling methods, and IoT connectivity that have the potential to drive business value beyond legacy methods. To help our customers and partners realize the benefits of digital twins to drive new business outcomes we built AWS IoT TwinMaker \xe2\x80\x93 a new AWS IoT service that makes it faster and easier to create digital twins of real-world systems and use them to monitor and optimize industrial operations. In this post, we will define what a digital twin is, describe the common challenges faced when building a digital twin, walk through the key capabilities of AWS IoT TwinMaker service, and show you how to get started creating digital twins using AWS IoT TwinMaker.\nDefinition of a digital twin\nLet us first define a digital twin. One vendor\xe2\x80\x99s or customer\xe2\x80\x99s definition of digital twin may vary drastically from another. They range from a simulation of a single physical component, predictive maintenance for a piece of equipment, to a full 3D virtual walkthrough of a factory with automated operations utilizing command and control procedures. What they all have in common is that digital twins form a digital representation of something in the physical world, updated with live data, and used to drive business outcomes. Based on these common elements, a digital twin is defined as a living digital representation of an individual physical system that is dynamically updated with data to mimic the true structure, state, and behavior of the physical system, which informs decisions that drive business outcomes.\nThe key difference between a digital twin and existing modeling methods such as traditional 3D modeling (CAD), physics-based simulations, virtual worlds (3D/AR/VR), IoT dashboards of streaming sensor data, and realistic gaming environments is the information flow between the digital and physical systems. The information flow allows the digital twin to represent the current state and behavior of the physical system. Many times, we equate a higher complexity and higher fidelity virtual representation with a digital twin. Rather, it is the regular updating of the virtual system that is key to the digital twin definition. A digital twin must consume the data streams to understand the present state of the system, learn from and update itself with new observations of the system, and be able to make predictions about the current and future behavior of the system. For example, a digital twin of a cookie mixer ingests temperature and RPM IoT data to predict internal motor power temperature, a non-observable quantity during operation. The digital twin is then used to make predictions of remaining useful life (RUL) under different operational conditions and maintenance scenarios, enabling the operator to select the best dispatch schedule and maintenance plan. Output from the digital twins such as the temperature or remaining useful life is then shown to the user via a dashboard, a 3D rendering showing the temperature in-situ, or some other context relevant manner. We think of the CAD models, physics simulations, IoT dashboards, 3D renderings/immersive walkthroughs, and gaming environments as key building blocks used to build digital twins, the application that represents living virtual representation of the physical system.\nChallenges in creating digital twins\nCreating digital twins is complex and involves multiple steps. You will need to model your physical systems, which includes expressing the elements of your physical systems (e.g., equipment, processes, sites, etc.) and the relationships between these elements. Then these models need to be connected to data sources like time-series IoT data from sensors, video data from camera feeds, application data from enterprise software, to name a few. As applications that use digital twins typically pull in data from multiple data stores, developers face a heavy lift to bring in the data from these stores. Next, you need to bring in your visual assets and provide visual context to your data and insights. Providing a comprehensive visual view of the assets and the data helps end-users easily understand the data and make better decisions faster. Finally, you need an easy way to deliver these digital twins to the end-users as web applications that they can easily bring up on different hardware platforms (such as mobile, desktop, etc.). With all these steps, creating and maintaining digital twins can be daunting, and many customers struggle with how to get started. For advanced use cases, you might also want to add insights and derive predictions through analytical, machine learning (ML), or simulation tools. For these scenarios, you will need to stream the digital twin data to and from these insight tools.\nAnnouncing AWS IoT TwinMaker\nAWS IoT TwinMaker is a new AWS IoT service to help developers create digital twins of real-world systems and use them in applications that operators can use to monitor and improve operations. Key capabilities of AWS IoT TwinMaker include:\nModel builder\nAWS IoT Twin Maker provides a flexible modeling capability to represent your digital twins. The model builder allows you to create workspaces that will hold the resources, such as entity models and visual assets needed to create a digital twin. Inside the workspace, you will create entities that represent digital replicas of your equipment (e.g., a mixer or pump). You can specify custom relationships between these entities to create a digital twin graph of your real-world system. For example, you can add a relationship, seen-by, to relate a camera entity to an equipment that is visualized by that camera. Using the digital twin graph, customers can now issue geospatial queries such as finding all cameras that are pointing to an equipment to help with root cause analysis.\nComponents (Data connectors)\nFor your digital twin, you will need to bring together data from various data stores and add equipment context to the stored data. AWS IoT TwinMaker makes it simple for you to combine this data in a single service without creating another data store and without requiring you to re-enter the schema information that already exists in their data stores. In AWS IoT TwinMaker, you can associate entities with connectors (called as components in AWS IoT TwinMaker) to data stores such as AWS IoT SiteWise, to provide context to the data present in various data stores. Also, previously, you will need to write data store specific APIs to read and write data from various data stores. To reduce the heavy lift needed to connect to these data stores, IoT TwinMaker provides unified access APIs that your applications can use to access the data from various stores with the same APIs regardless of where the data is stored. AWS IoT TwinMaker provides built-in data connectors for AWS IoT SiteWise for equipment and time-series sensor data, Amazon Kinesis Video Streams for video data, and Amazon Simple Storage Service (S3) for storage of visual resources (e.g., CAD files) and data from enterprise applications. AWS IoT TwinMaker also provides a framework using AWS Lambda for you to easily create custom data connectors to other data stores (e.g., Snowflake, Siemens MindSphere).\nScene composer\nAWS IoT TwinMaker provides a console-based 3D scene composition tool to create visualizations in 3D. You can bring previously built 3D/CAD models (optimized for web and converted to glTF format) into your resource library in Amazon S3. Using AWS IoT TwinMaker\xe2\x80\x99s scene composer, you can bring these visual assets into a scene, and position the 3D assets to match your real-world systems. AWS IoT TwinMaker makes it easy for you to bind data modeled in entities with your visualization. In the scene composer, you can add visual annotations such as tags on top of the base scene, to connect a specific 3D location with data streams or user actions for that entity. For example, you can add a tag to a cookie mixer equipment that links back to its temperature data or to its user manual documentation.\nApplications\nTo create web-based digital twin applications, AWS IoT TwinMaker provides a plug-in for Grafana and Amazon Managed Grafana that you can use to create dashboards. The dashboards can embed the 3D scenes created using the scene composer as well as other widgets such as video player, hierarchy browser, time-series data charts, tables. The dashboards use AWS IoT TwinMaker\xe2\x80\x99s unified data access APIs to populate the widgets.\nGetting started with AWS IoT TwinMaker\nStep 1: Create a workspace\nTo get started, you create a workspace that will hold all the resources such as entity models and visual assets needed to create a digital twin. To create a new workspace,\nYou will need to go to IAM in AWS Management console and create a new Role and attach the following policy to it.\nRole JSON:\n{   \n    ""Version"":  ""2012-10-17"",   \n    ""Statement"":[ \n        {\n            ""Sid"":  """",\n            ""Effect"":  ""Allow"",       \n            ""Principal"": {            \n                ""Service"": [                \n                    ""iottwinmaker.amazonaws.com""             \n                ]        \n            },        \n        ""Action"":  ""sts:AssumeRole""       \n        }    \n    ]\n}\nJSON\nPolicy JSON:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Action"": [\n                ""iottwinmaker:*"",\n                ""s3:*"",\n                ""iotsitewise:*"",\n                ""kinesisvideo:*""\n            ],\n            ""Resource"": [\n                ""*""\n            ],\n            ""Effect"": ""Allow""\n        },\n        {\n            ""Action"": [\n                ""lambda:invokeFunction""\n            ],\n            ""Resource"": [\n                ""*""\n            ],\n            ""Effect"": ""Allow""\n        },\n        {\n            ""Condition"": {\n                ""StringEquals"": {\n                    ""iam:PassedToService"": ""lambda.amazonaws.com""\n                }\n            },\n            ""Action"": [\n                ""iam:PassRole""\n            ],\n            ""Resource"": [\n                ""*""\n            ],\n            ""Effect"": ""Allow""\n        }\n    ]\n}\nJSON\nCreate a workspace in AWS IoT TwinMaker console using the Role created. As part of the workspace creation, you will also provide an Amazon S3 bucket to hold your resources and any optional resource tags.\nStep 2: Create entities\nSelect a workspace to make the workspace active.\nSelect Entities in the left navigation.\nSelect Create to create a new Entity\nStep 3: Attach data sources\nOnce an entity is created, select the entity to make it active\nIn the Components tab, select Add Component to add a data connector to a data store. Provide the component name and choose from the list of available components.\nIf you need to create a custom component, navigate to the Component types item in the left side navigation and select Create component type. This will allow you to specify your own custom connector that you can author using AWS Lambda (see \xe2\x80\x9cUsing and creating component types\xe2\x80\x9d in the documentation for more details).\nStep 4: Add resources to your workspace\nTo add visual assets into your workspace, you can upload your 3D files in gLTF or glb format into your resource library. Select Resources in the left navigation and choose Add resources to add files to your resource library. Note: these resources will be saved in the Amazon S3 bucket under your account that you specified during workspace creation.\nStep 5: Compose your scene\nSelect Scenes in the left navigation and choose Create Scene to create a new scene\nAdd visual assets (gltf or glb files) from your resource library into the scene\nPosition the asset by changing the X, Y and Z values. Using the scene composer menu, you can also add lighting to the scene.\nAdd a tag to provide a data binding to an entity. Provide the entityID, componentID and property name for the tag. Place the tag on the 3D object at the desired position.\nStep 6: Create your web application using Grafana\nRun Grafana on your local desktop (using Docker) or in the cloud. Log into your Grafana instance. (See \xe2\x80\x9cAWS IoT TwinMaker Grafana integration\xe2\x80\x9d in the documentation for more details on setting up Grafana instances).\nAdd an AWS IoT TwinMaker data source. Provide your AWS IAM user credentials.\nAdd dashboards with 3D widgets, time-series charts, etc. as desired.\nPartner community to accelerate your digital twin journey\nTo help you with your digital twin journey, you can work with AWS Partners to harness AWS IoT TwinMaker capabilities and realize the potential of digital twins for your business. AWS IoT TwinMaker has software and hardware partners who provide digital twin software solutions that are either hosted on or integrated with AWS. Examples include Siemens who provide rich application services for low-code, visualization, simulation use cases. AWS IoT TwinMaker has service partners that can help you design, architect, migrate, or build new digital twin applications on AWS. Examples include Accenture who provides professional services, Cognizant who has developed software for digital representation of buildings, FuseForward who provides digital transformation solutions for critical industries such as utilities and healthcare, and TensorIoT who provides their Smart Insights platform for industrial equipment. We also have modeling, simulation, and visualization partners that provide software tools and services used to create digital twins with AWS IoT TwinMaker. Examples include advanced simulation providers such as Ansys and Maplesoft, modeling partners such as Element Analytics and Embassy of Things that help unlock data from industrial systems, dashboard and visualization providers such as Grafana Labs, and immersive 3D model generators such as Matterport. For more details, visit the AwS IoT TwinMaker partner page.\n'"
109,How to implement zero trust IoT solutions with AWS IoT,b'Thomas Kriechbaumer',2022-02-09T16:07:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-implement-zero-trust-iot-solutions-with-aws-iot-3/,"b'Introduction\nZero trust is often misunderstood. It\xe2\x80\x99s not a product but a security model and associated set of architectural principles and patterns. One of the main challenges customers face is determining how zero-trust principles can be applied to Internet of Things (IoT) and how to get started with incorporating zero trust with Amazon Web Services (AWS) IoT.\nIn this blog post, we discuss zero trust according to the NIST 800-207 architecture as a benchmark and how AWS IoT services, which support zero trust by default, can be used to create a zero-trust IoT implementation.\nWhat is zero-trust security?\nZero trust is a conceptual model and an associated set of mechanisms that provide security controls. These security controls do not depend solely on traditional network controls or network boundaries. It requires your users, devices, and systems to prove their trustworthiness, and it enforces fine-grained, identity-based rules that govern access to applications, data, and other assets.\nZero-trust principles are intended for an organization\xe2\x80\x99s infrastructure, which includes operational technology (OT), IT systems, IoT, and Industrial Internet of Things (IIoT)\xe2\x80\x94it\xe2\x80\x99s about trying to secure everything everywhere. Traditional security models rely heavily on network segmentation and give high levels of trust to devices based on their network presence. In comparison, zero trust is an integrated approach for verifying your connected devices, regardless of network location. It asserts least privilege and relies on intelligence, advanced detection, and real-time threat response.\nWith the increasing proliferation of IoT and IIoT devices, organizations are faced with protecting an expanding attack surface. Zero trust offers enhanced security than traditional network-based security because of its inherent principles, and it\xe2\x80\x99s an area of increasing government and enterprise scrutiny.\nA zero-trust model can improve an organization\xe2\x80\x99s security posture by reducing its sole reliance on perimeter-based protection. But this doesn\xe2\x80\x99t mean getting rid of perimeter security altogether. Where possible, combine identity and network capabilities to protect core assets, and apply zero-trust principles, working backward from specific use cases, with a focus on extracting business value.\nSolution overview\nAWS provides IoT services that you can use alongside other AWS identity and networking services to provide zero-trust building blocks as standard features for enterprise IoT and IIoT implementations.\nAligning AWS IoT with NIST 800-207 zero-trust principles\nAWS IoT can help you adopt a NIST 800-207\xe2\x80\x93based, zero-trust architecture (ZTA) by following the seven tenets described here:\n1. All data sources and computing services are resources.\nAt AWS, we model your data sources and computing services as resources, which is intrinsic to access management. For example, AWS IoT Core and AWS IoT Greengrass are services which contain customer resources, as are services, such as Amazon Simple Storage Service (Amazon S3) and Amazon DynamoDB, which IoT devices are designed to securely call. Each connected device must have a credential to interact with AWS IoT services. All traffic to and from AWS IoT services are sent using Transport Layer Security (TLS). AWS Cloud security mechanisms protect data as it moves between AWS IoT services and other AWS services.\n2. All communication is secured, regardless of network location.\nWith AWS IoT services, all communications are secured by default. This means that all communications among devices and cloud services are secured independently of network location by individually authenticating and authorizing AWS API calls using TLS. When a device connects to other devices or cloud services, it must establish trust by authenticating using principals such as X.509 certificates, security tokens, and custom authorizers. The AWS IoT security model supports certificate-based authentication or custom authorizers for legacy devices, authorization using IoT policies, and encryption using TLS 1.2. Along with strong identity provided by AWS IoT services, zero trust requires least-privilege access to control a device\xe2\x80\x99s operations after it connects to AWS IoT Core. This lets AWS IoT policies limit the impact in case of unauthorized access.\nAWS provides device software to allow IoT and IIoT devices to connect securely to other devices and AWS services in the cloud. AWS IoT Greengrass is an IoT open-source edge runtime and cloud service that helps build, deploy, and manage device software. AWS IoT Greengrass authenticates and encrypts device data for both local and cloud communications. Another example is FreeRTOS, an open-source, real-time operating system for microcontrollers that makes small, low-power edge devices easier to manage. FreeRTOS provides support for TLS 1.2 for secure communications and PKCS #11 for use with cryptographic elements that secure stored credentials. AWS IoT Device Client helps to connect your IoT devices securely to AWS IoT services.\n3. Access to individual enterprise resources is granted on a per-session basis, and trust is evaluated using least privileges before access is granted.\nAWS IoT services and AWS API calls grant access to resources on a per-session basis. IoT devices must authenticate with AWS IoT Core and be authorized before it can perform an action. Each time a device connects to AWS IoT Core, it presents its device certificate or custom authorizer to authenticate with AWS IoT Core. During this process, IoT policies are enforced to check if the device is authorized to access the resources it\xe2\x80\x99s requesting, and this authorization is valid only for the current session. The next time the device connects, it goes through the same steps. A similar process applies if a device tries to connect to other AWS services using AWS IoT Core credential provider.\n4. Access to resources is determined by a dynamic policy that includes the observable state of client identity, application and service, and requesting asset, all of which may include other behavioral and environmental attributes.\nA core principle behind zero trust is that no IoT device should be granted access to other devices and applications until assessed for risk and approved within the set parameters of acceptable behavior. This principle applies perfectly to IoT devices because they have limited, stable, and predictable behaviors by nature, and it\xe2\x80\x99s possible to use their behavior as a measure of device health.\nOnce identified, every IoT device should be verified against baseline behaviors before being granted access to other devices and applications in the network. A device\xe2\x80\x99s state can be detected using the AWS IoT Device Shadow service, and device anomalies can be detected using AWS IoT Device Defender.\nAWS IoT Core policies are applied to a collection of devices (also known as a thing group), in AWS IoT and are evaluated at runtime before access is granted. Membership in a group is dynamic and can be configured to change based on a device\xe2\x80\x99s behavior using AWS IoT Device Defender. AWS IoT Device Defender uses Rules Detect and ML Detect features to determine a device\xe2\x80\x99s normal behaviors and any potential deviation from the baseline. When an anomaly is detected, the device can be quarantined with limited permissions based on the static group\xe2\x80\x99s policy, or it can be disallowed from connecting to AWS IoT Core.\n5. No asset is inherently trusted. The enterprise monitors and measures the integrity and security posture of all owned and associated assets. The enterprise evaluates the security posture of the asset when evaluating a resource request. An enterprise implementing a ZTA should establish a nearly continuous diagnostics and mitigation (CDM) system to monitor, patch, and fix the state of devices and applications.\nAWS IoT Device Defender continuously audits and monitors your fleet of IoT devices. You can also use other AWS services for nearly continuous auditing and monitoring of non-IoT components and services, which can be used to evaluate the compliance and security posture of resource assets. For example, AWS IoT Device Defender can take mitigation actions, such as the following:\nPlacing a device in static thing groups with limited permissions.\nRevoking permissions.\nQuarantining a device.\nApplying patches using the AWS IoT Jobs feature for over-the-air updates to keep devices healthy and in compliance.\nRemotely connecting to a device for service or troubleshooting using the AWS IoT secure tunneling feature.\n6. All resource authentications and authorizations are dynamic and strictly enforced before access is allowed. This involves a nearly continuous cycle of obtaining access, scanning and assessing threats, adapting to threats, and reevaluating the trust of ongoing communications.\nBy default, zero trust denies access\xe2\x80\x94including any API calls\xe2\x80\x94among IoT devices. With AWS IoT, access is granted with proper authentication and authorization, which takes into account the health of your devices. Zero trust requires the ability to detect and respond to threats across IoT, IIoT, IT, and cloud networks. This can be achieved using AWS IoT Device Defender and other AWS services.\n7. The enterprise collects as much information as possible about the current state of assets, network infrastructure, and communications, which it uses to improve its security posture.\nUsing AWS IoT Device Defender, you can use IoT device data to make nearly continuous improvements to the security posture. For example, you can turn on AWS IoT Device Defender Audit features to get a security baseline for IoT devices. You can then add the Rules Detect or ML Detect features to detect anomalies found in connected devices and make improvements based on detected results.\nIn addition, with AWS IoT Device Defender custom metrics, you can define and monitor metrics that are unique to their device fleet or use case. You can also derive insights from other data collected on AWS (for example, auditing, logging, telemetry, and analytics) and use AWS IoT features such as AWS IoT Jobs to apply patches to improve security posture and AWS IoT Secure Tunneling to connect securely to devices for troubleshooting and remote service. Continuous improvements to an enterprise\xe2\x80\x99s security posture can be achieved by fine-tuning permissions.\nAWS IoT Zero Trust workshop\nTo get started, see the AWS IoT Zero Trust workshop, which can help you get experience using multiple AWS IoT services to safely and securely deploy commercial and industrial IoT devices. Working through a scenario where you deploy devices outside of your corporate perimeter, you use AWS IoT Core, AWS IoT Device Defender, AWS IoT Device Management, and Amazon Simple Notification Service (Amazon SNS) to build a resilient architecture that includes unique identity, least privilege, dynamic access control, health monitoring, and behavioral analytics to ensure the security of your devices and data.\nIf a security anomaly is detected, you can investigate and take mitigation actions, such as quarantining an anomalous device, securing connectivity to the device for remote troubleshooting, and apply a security patch to fix device vulnerabilities and keep devices healthy.\nFigure 1. Implementing zero trust using the AWS IoT workshop architecture\n'"
110,AWS IoT Greengrass now supports the Windows operating system,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-greengrass-now-supports-the-windows-operating-system/,"b'Introduction\nMicrosoft Windows is a common operating system for devices used in industrial automation. Customers using AWS IoT Greengrass have been restricted to Linux based devices until now. Today we are excited to announce native Windows support for AWS IoT Greengrass v2. This will allow customers to leverage AWS IoT Greengrass on their Windows based devices to locally collect and push data to AWS IoT and other services. In this blog, we will run through how to install and use AWS IoT Greengrass on Windows.\nTime to read 15 minutes\nTime to complete 30 minutes\nLearning level 200\nServices used AWS IoT Greengrass, AWS Identity and Access Management, Amazon S3\nCost to complete (estimated) $1\nWalkthrough\nAWS IoT Greengrass for Windows can be installed using the quick install method, an automated process that is run on the AWS IoT Greengrass device to provision the relevant device and AWS services. Alternatively, you can deploy the device pre-provisioned with the certificates required to connect to AWS IoT at a later date. In this blog, we will use the quick install method via the AWS console to set up one device. I will be using Microsoft Windows 10 Enterprise in the following example.\nWe will run through the following steps:\nNavigate to AWS IoT Greengrass getting started guide.\nInstall Java on the device.\nCreate an AWS IAM user who has permissions to provision a device.\nInstall version 2 of the AWS Command Line Interface (CLI) on the device\nCreate a local user on the Windows machine that will run AWS IoT Greengrass.\nDownload and run the AWS IoT Greengrass installer.\nChecking that AWS IoT Greengrass is installed and running.\nCreate and deploy your first AWS IoT Greengrass component.\nPrerequisites\nAn AWS account. If you don\xe2\x80\x99t have one, you can follow the steps in the Developer Guide under Set up an AWS account.\nThe use of an AWS Region. In this blog I have selected eu-west-1, Ireland. For the list of AWS IoT Greengrass v2 supported Regions, see AWS IoT Greengrass V2 endpoints and quotas in the AWS General Reference\nAn AWS Identity and Access Management (IAM) user with administrator permissions to create and edit users.\nA Windows, macOS, or Unix-like development computer with an internet connection.\nA device that meets the Requirements to install and run the AWS IoT Greengrass Core software v2.0 and has an internet connection to access the AWS cloud services.\nStep 1. Navigate to AWS IoT Greengrass getting started guide\nNavigate to the AWS IoT Core console.\nExpand Greengrass.\nChoose Getting started.\nChoose Set up one core device.\nIn the Install the Greengrass Core software section, select Windows.\nThis blog will walk you through the steps on the Windows device to install AWS IoT Greengrass.\nStep 2. Install Java on the device\nThe first step is to install Java or check that Java is installed on the device. A minimum of Java version 8 is required as AWS IoT Greengrass components, such as the nucleus, are written in Java to provide better portability between platforms.\nTo check if Java is installed:\nOpen command prompt (enter command prompt in the windows search bar).\nEnter java -version\nIf you have java installed you will see the version in the output.\nIf Java is not installed you will get a message: \xe2\x80\x98java\xe2\x80\x99 is not recognized as an internal or external command, operatable program or batch file.\nYou can download and install OpenJava or Corretto from the Corretto 11 User Guide. You may have to restart the machine after installing Java.\nStep 3. Create an AWS IAM user who has permissions to provision a device\nThe next step is to configure the AWS credentials. On the device you will need to provide the credentials of an AWS IAM user that has permissions to create and provision the AWS IoT Greengrass device. This is only needed since we are following the quick start method. In production or for a large number of devices we would automate this process.\nOpen the AWS console and navigate to the IAM Console.\nChoose Users.\nChoose Add users.\nFor name enter GGv2ProvisionUser.\nSelect the Access key as we will only use this IAM user via the CLI.\nChoose Next: Permissions.\nChoose Attach existing policies directly.\nSearch and select IAMFullAccess. This is used to create the new AWS IoT Greengrass user accounts and roles.\nSearch and select AWSIoTFullAccess. This is used to create the device.\nSearch and select AWSGreengrassFullAccess. This is used to update the AWS IoT Greengrass service.\nChoose Next: Tags.\nChoose Next: Review.\nChoose Create user.\nChoose Download .csv button to save the login credentials access key and secret access key.\nChoose Close.\nStep 4. Install version 2 of the AWS Command Line Interface (CLI) on the device\nNext, we will configure the AWS CLI with the user we created in step 2.\nInstall the AWS CLI on the device. You can follow the Getting started with the AWS CLI in the AWS Command Line Interface User Guide. Once installed you will have to reboot the machine.\nOpen command prompt (enter command prompt in the windows search bar).\nEnter aws configure into the command prompt windows and press the enter key.\nEnter the AWS Access Key ID that you generated in step 3.\nEnter the AWS Secret Access key that you generated in step 3.\nEnter the Default region name, in my case I am using Ireland so eu-west-1.\nEnter the default output format type json.\nStep 5. Create a local user on the Windows machine that will run AWS IoT Greengrass.\nNext, we will create a local user for the AWS IoT Greengrass device to use. To do this we need to install psexec.exe\nDownload PSExec from the Sysinternals downloads page and extract the zip file.\nCopy psexec.exe to C:\\Windows\\System32.\nOpen Command Prompt as Administrator. (Enter command prompt in the windows search bar and choose Run as administrator.)\nChoose Yes if prompted by the UAC pop up.\nRun the following command to create a new user. Replace <password> with a secure password.\nnet user /add ggc_user <password>\nPowerShell\nNow run the following command to store the password in the system account so that the AWS IoT Greengrass can access it. Replace <password> with the password you used in the previous step.\ncd C:\\Windows\\System32\nPowerShell\npsexec -s cmd /c cmdkey /generic:ggc_user /user:ggc_user /pass:<password>\nPowerShell\nStep 6. Download and run the AWS IoT Greengrass installer\nIn this blog, we will use the getting started guide to setup one core device within minutes.\nLogin to the AWS console and navigate to AWS IoT Core.\nExpand Greengrass from the left menu and choose Getting started.\nChoose Set up one core device.\nFor core device name and thing group you may use the default.\nUnder Step 3: Install the Greengrass Core software, select Windows.\nChoose Download.zip.\nUnzip the AWS IoT Greengrass v2 files.\nOpen Command Prompt as Administrator. (Enter command prompt in the windows search bar and choose Run as administrator.)\nNavigate to the folder where you have unzipped the files, in my case:\nD:\\Users\\paulshiner\\Desktop\\gg>\nRun the command under Run the installer. You should see an output with a message that it successfully provisioned AWS IoT resources, added Thing into Thing Group, configured Nucleus, and setup Nucleus as a system service.\nAfter the installation process completes, you can proceed to next step.\nStep 7. Checking that AWS IoT Greengrass is installed and running.\nNow we will check the device is showing in the AWS console.\nNavigate to the AWS IoT Core console.\nSelect Greengrass.\nChoose Core devices.\nThe device you created in step 6 will be listed under Greengrass core devices.\nCheck that AWS IoT Greengrass is installed and running as a system service by opening Services (enter services in the Windows search bar).\nReview the list of services for greengrass and the status is running. If not, repeat the installation steps in step 6 and check for errors. You can also review Troubleshooting AWS IoT Greengrass V2 in the Developer Guide.\nStep 8. Create and deploy your first AWS IoT Greengrass component\nIn this blog we will create a simple batch file that we can deploy to the device. This batch file will log the current OS version to a text file which we can then upload or retrieve remotely. I have chosen a batch file to show one of the simplest operations that AWS IoT Greengrass can run. You may want to run an executable or Python code to retrieve data from a 3rd party system..\nCreate a file called software.bat with the following contents:\n@ECHO OFF \n>hardware.txt (\n:: This batch file will discover the windows version we are using and store to a text file\nTITLE My System Info \nECHO ========================== \nECHO WINDOWS INFO \nECHO ============================ \nsysteminfo | findstr /c:""OS Name"" \nsysteminfo | findstr /c:""OS Version"" \nsysteminfo | findstr /c:""System Type"" \n)\nPowerShell\nWe will store this file in Amazon S3 under a folder structure that can be used to manage the versions.\nNavigate to Amazon S3 Console.\nChoose Create Bucket.\nGive your bucket a globally unique name (greengrasscomponents + a random string such as the date/time of creation).\nChoose the Region that your AWS IoT Greengrass device was installed.\nChoose Create bucket.\nWhen you return to the previous screen select the bucket name that you just created.\nChoose Create folder.\nFor Folder name, enter artifacts.\nNavigate into that folder and create another folder called com.example.software.\nNavigate into that folder and create another folder called 1.0.0 this will be used to hold our first version of the code.\nYou should now have a folder structure that resembles greengrasscomponents_<unique name>/artifacts/com.example.software/1.0.0/\nChoose Upload and select software.bat file that you created earlier into the 1.0.0 folder.\nNow select the link software.bat file in this folder.\nChoose the S3 URI to copy that link. We will need that in the recipe file.\nNow we need to make sure the AWS IoT Greengrass role has access to read the files from the Amazon S3 bucket before we can try to deploy the component.\nNavigate to the AWS IoT Core console.\nSelect Secure.\nSelect Role Aliases.\nThe role alias that was created during the AWS IoT Greengrass installer process will be listed.\nChoose the role.\nChoose Edit IAM Role\nThe link should open the IAM console for that role.\nChoose the Permissions tab. A GreengrassV2TokenExchangeRoleAccess policy is listed. You may have to expand the list.\nChoose Edit Policy\nChoose + Add additional permissions.\nChoose the service Amazon S3 by expanding the Choose a Service and searching for S3.\nNext expand the Read section under the Access level heading and select the following check boxes GetObject and GetBucketLocation.\nExpand the Resources section using the arrow.\nChoose Add ARN next to bucket. A window will open that will prompt you to enter your bucket name in my case this is greengrasscomponents_<unique name>.\nSelect Add.\nChoose Add ARN next to object. A window will open that will prompt you to enter the bucket name and object name. Enter your bucket name (in my case this is greengrasscomponents_<unique name>).\nSelect the Any box next to the Object name entry box to allow the policy to get all objects in this bucket.\nChoose Review policy.\nChoose Save Changes.\nNow we are ready to create our first component to deploy and run on our Windows AWS IoT Greengrass device.\nNavigate to the AWS IoT Core console.\nChoose Components.\nChoose Create component.\nEnter the recipe below:\nReplace <bucket_name> with the name you chose in step 8.\n{\n    ""RecipeFormatVersion"": ""2020-01-25"",\n    ""ComponentName"": ""com.example.software"",\n    ""ComponentVersion"": ""1.0.0"",\n    ""ComponentDescription"": ""My batch file"",\n    ""ComponentPublisher"": ""Me"",\n    ""ComponentConfiguration"": {\n        ""DefaultConfiguration"": {\n        }\n    },\n    ""Manifests"": [\n        {\n            ""Name"": ""windows"",\n            ""Platform"": {\n                ""os"": ""windows""\n            },\n            ""Lifecycle"": {\n                ""Run"": ""{artifacts:path}/software.bat""\n            },\n            ""Artifacts"": [\n                {\n                    ""Uri"": ""s3://<bucket_name>/artifacts/com.example.software/1.0.0/software.bat""\n                }\n            ]\n        }\n    ]\n}\nJSON\nChoose Create component.\nChoose Deploy.\nSelect your Deployment group for your Windows device.\nSelect the deploy button. You will return to the deployment screen where you can select the IoT Job which will show you the current status of the deployment. Wait until the deployment status is marked as successful before moving to the next step.\nOn your windows device navigate to the AWS IoT Greengrass work folder (C:\\greengrass\\v2\\work\\com.example.software) using windows explorer. The batch file has created a hardware.txt file that will contain the results from the script.\nThe file will contain the Windows information collected from the batch script. The contents of the document for my machine are as follows:\nAWS IoT Greengrass has an ever-growing repository of public open source components. You can see more examples in the Developer Guide, AWS-provided components. One of them is Log Manager. With Log Manager you can retrieve this log file or any files and send them securely to Amazon CloudWatch logs.\nClean Up\nWith AWS IoT Greengrass you only pay for what you use. You are charged per device connected so by disconnecting the device, you will no longer be charged. You can find the current pricing on the product page under AWS IoT Greengrass pricing.\nTo delete the device from your AWS IoT account, follow these steps:\nNavigate to the AWS IoT Core console.\nSelect Manage then select Things.\nSelect the checkbox next to your device and choose Delete.\nConfirm the name of the device in the prompt and choose Delete.\nYou will be charged for the storage of the artifacts within the Amazon S3 bucket. To delete the objects in the Amazon S3 bucket and the bucket, follow the steps in the Amazon Simple Storage Service (S3) User Guide under Deleting a bucket.\n'"
111,"Ingesting Data from S3 by Using BatchPutMessage, AWS Lambda, and Amazon Kinesis",b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/ingesting-data-from-s3-by-using-batchputmessage-aws-lambda-and-amazon-kinesis/,"b'AWS IoT Analytics is a fully managed service that you can use to query and generate insights about your IoT data. You might want to use AWS IoT Analytics on data that is not being sent to the AWS IoT Core message broker. By using the AWS IoT Analytics BatchPutMessage API, you can ingest data directly into AWS IoT Analytics from other data sources. This blog post demonstrates how to use the BatchPutMessage API to upload data stored in Amazon S3 to AWS IoT Analytics. We\xe2\x80\x99ll first walk through some simple command-line examples. Then we\xe2\x80\x99ll see how to use AWS Lambda and Amazon Kinesis to ingest data files in an S3 bucket.\nTo follow along, you\xe2\x80\x99ll need to install the AWS CLI. Note that you may need to install the AWS CLI via pip3 instead of pip to install an up-to-date client that supports iotanalytics. Also, the steps in this post were written using bash on macOS. If you use a different command-line interface, such as Windows PowerShell, you\xe2\x80\x99ll need to adjust the commands accordingly.\nAWS IoT Analytics concepts\nBefore we begin, here are some important AWS IoT Analytics concepts:\nChannels ingest data, back it up, and publish it to one or more pipelines.\nPipelines ingest data from a channel and allow you to process the data through activities before storing it in a data store.\nData stores store data. They are scalable and queryable.\nDatasets retrieve data from a datastore. They are the result of some SQL query run against the data store.\nBatchPutMessage example\nLet\xe2\x80\x99s walk through a simple example that demonstrates these concepts in action. We\xe2\x80\x99ll create a channel, pipeline, data store, and dataset. Then we\xe2\x80\x99ll send data to AWS IoT Analytics through BatchPutMessage and query for that data in our dataset.\nSet up AWS IoT Analytics\nFirst, we\xe2\x80\x99ll create the data store and channel.\naws iotanalytics create-datastore --datastore-name bpm_blog_datastore\naws iotanalytics create-channel --channel-name bpm_blog_channel\nBash\nTo create the pipeline, we\xe2\x80\x99ll specify the pipeline configuration in a JSON file and pass the file to the create-pipeline command.\nOur pipeline will be very simple because we are not processing the data in any way. We are just ingesting the data from a channel and passing it to a data store. (This is the \xe2\x80\x9cSink\xe2\x80\x9d activity.) Save this JSON to a file named pipeline_config.json.\n{\n   ""pipelineName"":""bpm_blog_pipeline"",\n   ""pipelineActivities"":[\n      {\n         ""channel"":{\n            ""name"":""Source"",\n            ""channelName"":""bpm_blog_channel"",\n            ""next"":""Sink""\n         }\n      },\n      {\n         ""datastore"":{\n            ""name"":""Sink"",\n            ""datastoreName"":""bpm_blog_datastore""\n         }\n      }\n   ]\n}\nJSON\nNow pass pipeline_config.json to create-pipeline.\naws iotanalytics create-pipeline --cli-input-json file://pipeline_config.json\nBash\nSend BatchPutMessage\nNow we\xe2\x80\x99ll use the CLI to send our BatchPutMessage request. In this example, we\xe2\x80\x99ll specify some temperature data. Save the following to a file named batchPutMessage.json. It contains the two things a BatchPutMessage request requires: the name of the channel where we are sending messages and one or more messages. A message contains the data we are uploading and an ID that identifies the message. The messageId must be unique relative to the other messages in the BatchPutMessage request. The \xe2\x80\x9cbatch\xe2\x80\x9d in BatchPutMessage is the ability to send multiple messages at a time, up to 1,000 total messages per second per account.\n{\n   ""channelName"":""bpm_blog_channel"",\n   ""messages"":[\n      {\n         ""messageId"":""1"",\n         ""payload"":""{\\""temp\\"": 10}""\n      },\n      {\n         ""messageId"":""2"",\n         ""payload"":""{\\""temp\\"": 50}""\n      }\n   ]\n}\nJSON\nSend the BatchPutMessage request.\naws iotanalytics batch-put-message --cli-input-json file://batchPutMessage.json\nBash\nIf the command is successful, the CLI will return the following response:\n{\n""batchPutMessageErrorEntries"": []\n}\nJSON\nQuery data\nWe can now query the data back from our data store. First, we\xe2\x80\x99ll create a dataset that represents the output of a \xe2\x80\x9cselect temp from bpm_blog_datastore\xe2\x80\x9d query. Save the following JSON to a file named dataset_config.json.\n{\n   ""datasetName"":""bpm_blog_dataset"",\n   ""actions"":[\n      {\n         ""actionName"":""bpm_blog_action"",\n         ""queryAction"":{\n            ""sqlQuery"":""select temp from bpm_blog_datastore""\n         }\n      }\n   ]\n}\nJSON\nNow pass the JSON file as input to the create-dataset command.\naws iotanalytics create-dataset --cli-input-json file://dataset_config.json\nBash\nCreating the dataset will not execute our query. We need to run create-dataset-content.\naws iotanalytics create-dataset-content --dataset-name bpm_blog_dataset\nBash\nFetch the query result with the get-dataset-content command. If the status is \xe2\x80\x9cCREATING,\xe2\x80\x9d the query has not finished executing. Wait a moment and try again.\naws iotanalytics get-dataset-content --dataset-name bpm_blog_dataset --version-id \'$LATEST\'\nBash\nAfter the query has been executed, the response will contain a link. Visiting that link in our browser will download the result of our query.\n{\n   ""timestamp"":1524498869.019,\n   ""status"": {\n      ""state"": ""SUCCEEDED""\n    },\n   ""entries"":[\n      {\n         ""dataURI"":""https://aws-iot-analytics-dataset-12dbc22a-96d6-466a-abff-e8239c32bfb2.s3.amazonaws.com/results/924a1629-ebb3-4b51-8ea4-715612aa6786.csv?X-Amz-Security-Token=ABCDEFG&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180423T155542Z&X-Amz-SignedHeaders=host&X-Amz-Expires=7200&X-Amz-Credential=1234457689us-east-1%2Fs3%2Faws4_request&X-Amz-Signature=XXXX""\n      }\n   ]\n}\nJSON\nIngesting data from S3 to AWS IoT Analytics using BatchPutMessage\nFor the purposes of this blog post, we have generated and uploaded some data, in .csv format, to the aws-iot-blog-assets bucket. The data is divided into 5 folders, each with 20 files. The following is a JSON representation of one datapoint in example_data_part_2.csv.\n{\n   ""deviceid"":2,\n   ""humidity"":51,\n   ""location"":""B"",\n   ""rowid"":575,\n   ""temp"":63,\n   ""timestamp"":""2018-04-18 19:04:35""\n}\nJSON\nLaunch data ingestion template\nWe\xe2\x80\x99ll ingest the data stored in the S3 bucket into AWS IoT Analytics by using two Lambda functions and a Kinesis stream. One Lambda function, \xe2\x80\x9cthe launcher\xe2\x80\x9d, will iterate through our bucket and upload each key to the stream. For each key ingested by the stream, a copy of the second Lambda function will be invoked. That second Lambda function, \xe2\x80\x9cthe worker\xe2\x80\x9d, will download the data located at that S3 key and send BatchPutMessage requests containing the data. If it encounters an error while doing so, it will be invoked again.\nDeployment packages contain the code for the Lambda functions. We use deployment packages because they allow us to upload dependencies along with the the code. The function definitions are displayed below.\nLauncher Lambda:\nimport boto3\nimport json\n\nfrom ratelimiter import RateLimiter\nfrom split import chop\n\nMAX_RECORDS_PER_REQUEST = 500\nMAX_REQUESTS_PER_SECOND = 2\n\ndef lambda_handler(event, context):\n    bucket = event[""bucket""]\n    channel_name = event[""channel_name""]\n    stream_name = event[""stream_name""]\n\n    s3_client = boto3.client(""s3"")\n    kinesis_client = boto3.client(""kinesis"")    \n    \n    total_jobs = 0\n    paginator = s3_client.get_paginator(""list_objects_v2"")\n    page_iterator = paginator.paginate(Bucket=bucket, Prefix=""IngestingDatafromS3byUsingBatchPutMessageAWSLambdaAmazonKinesis/data/"")\n    for page in page_iterator:\n        jobs = [{""key"": object[""Key""], ""channel_name"": channel_name, ""bucket"": bucket}\n            for object in page[""Contents""]]\n        for request_jobs in chop(MAX_RECORDS_PER_REQUEST, jobs):\n            records = [{""Data"": json.dumps(request_job), ""PartitionKey"": request_job[""key""]} for request_job in request_jobs]\n            put_records(kinesis_client, stream_name, records)\n        total_jobs += len(jobs)\n    return ""{} keys sent into {}"".format(total_jobs, stream_name)\n\n# 1 kinesis shard can ingest at most 1000 records per second\n# we ratelimit to ensure we do not go over that rate\n@RateLimiter(max_calls= MAX_REQUESTS_PER_SECOND, period=1)\ndef put_records(kinesis_client, stream_name, records):\n    kinesis_client.put_records(StreamName=stream_name, Records=records)\nPython\nWorker Lambda:\nimport base64\n# as of 5/11/18, the version of boto3 used by lambda does not support iotanalytics\n# so we included the newest version of boto3 in the deployment package\nimport boto3\nimport csv\nimport json\n\nfrom io import StringIO\nfrom ratelimiter import RateLimiter\nfrom split import chop\n\nMESSAGES_PER_REQUEST = 100\nMAX_REQUESTS_PER_SECOND = 10\n\ndef lambda_handler(event, context):\n    # we will only recieve 1 event because the trigger BatchSize is 1 (set via the CloudFormation template)\n    record = event[""Records""][0]\n    job_input = json.loads(base64.b64decode(record[""kinesis""][""data""]))\n    key = job_input[""key""]\n    bucket = job_input[""bucket""]\n    channel_name = job_input[""channel_name""]\n    print(""Job Input - Key: {} Bucket: {} Channel Name: {}"".format(key, bucket, channel_name))\n\n    s3_client = boto3.client(""s3"")\n    file_contents = s3_client.get_object(Bucket=bucket, Key=key)[""Body""].read().decode(""utf-8"") \n    serialized_rows = serialize_rows(file_contents)\n    messages = generate_messages(serialized_rows)\n\n    num_requests = 0\n    iot_analytics_client = boto3.client(""iotanalytics"")\n    for messages_batch in chop(MESSAGES_PER_REQUEST, messages):\n        send_batch_put_message(iot_analytics_client, channel_name, list(messages_batch))\n        num_requests += 1\n    return ""{} batchPutMessage requests sent for {}"".format(num_requests, key)\n\n# batchPutMessage can receive at most 1000 messages per second per account\n# so we ratelimit to ensure we do not send more than that\n# if you allowed for concurrent worker invocations then you would need to\n# divide this value by the max number of concurrent workers\n@RateLimiter(max_calls= MAX_REQUESTS_PER_SECOND, period=1)\ndef send_batch_put_message(iot_analytics_client, channel_name, messages_batch):\n    iot_analytics_client.batch_put_message(channelName=channel_name, messages=messages_batch)\n    \ndef serialize_rows(file_contents):\n    reader = csv.DictReader(StringIO(file_contents))\n    return (row for row in reader)\n    \ndef generate_messages(serialized_rows):\n    for messageId, row in enumerate(serialized_rows):\n        yield {""payload"": json.dumps(row), ""messageId"": str(messageId)}\nPython\nThe following Launch Stack button goes to an AWS CloudFormation template that describes the Lambda functions and Kinesis stream. It also describes IAM policies and roles that permit the Lambda functions to do the following:\nRead and list objects from S3 buckets.\nSend data into the Kinesis stream.\nBe triggered by data ingestion into the Kinesis stream.\nSend BatchPutMessage requests.\nStore logs.\nJust click Launch Stack below to launch the template. The stack will be deployed to the us-east-1 region. You do not need to specify values for the options presented. Instead, choose Next three times. Then select the I acknowledge that AWS CloudFormation might create IAM resources check box and click Create. You might have to refresh to see the new AWS CloudFormation stack.\n\nWhen the services have been completely set up, the status of the stack will change to CREATE_COMPLETE. Select the stack and then choose the Outputs tab. Note the names of the launcher Lambda function and Kinesis stream.\nInvoke the launcher Lambda function with a payload that specifies the bucket it will iterate through, the name of the Kinesis stream it will send the keys to, and the AWS IoT Analytics channel the data will be sent to.\nSave the payload to file called lambdaPayload.json.\n{\n   ""stream_name"":""EXAMPLE_KINESIS_STREAM"",\n   ""channel_name"":""bpm_blog_channel"",\n   ""bucket"":""aws-iot-blog-assets""\n}\nJSON\nInvoke the launcher Lambda function.\naws lambda invoke --function-name EXAMPLE_FUNCTION_NAME --payload file://lambdaPayload.json --region us-east-1 --cli-binary-format raw-in-base64-out lambdaOutput.txt\nBash\nYou can use the AWS Lambda console to monitor the state of the Lambda functions. Click the Launcher function and then choose the Monitoring tab. From there, you can, for example, see a graph of the number of invocations over time. You can also view links to logs for each function. You will know the data ingestion process is complete when the the worker has stopped being invoked. For the data used by this blog, the process may take about 15 minutes.\nValidating data\nTo validate the data ingested by AWS IoT Analytics, we can create datasets with queries we know the correct answer to. For example, in the this dataset, we know there were two locations where data was collected and 56,570 total records. We can create a dataset that queries for those values.\nSave the following to a file named validation_dataset_config.json.\n{\n   ""datasetName"":""bpm_blog_validation_dataset"",\n   ""actions"":[\n      {\n         ""actionName"":""bpm_blog_validation_action"",\n         ""queryAction"":{\n            ""sqlQuery"":""SELECT count(DISTINCT location), count(DISTINCT rowid) from bpm_blog_datastore""\n         }\n      }\n   ]\n}\nJSON\nExecute the following commands to verify that they report the expected result of 2 and 56570.\naws iotanalytics create-dataset --cli-input-json file://validation_dataset_config.json\naws iotanalytics create-dataset-content --dataset-name bpm_blog_validation_dataset\naws iotanalytics get-dataset-content --dataset-name bpm_blog_validation_dataset --version-id \'$LATEST\'\nBash\nWe can also query for the data at a specific row. Save the following to validation_dataset_config2.json\n{\n   ""datasetName"":""bpm_blog_validation_dataset2"",\n   ""actions"":[\n      {\n         ""actionName"":""bpm_blog_validation_action2"",\n         ""queryAction"":{\n            ""sqlQuery"":""select * from bpm_blog_datastore where rowid=\'575\'""\n         }\n      }\n   ]\n}\nJSON\nThen execute these commands.\naws iotanalytics create-dataset --cli-input-json file://validation_dataset_config2.json\naws iotanalytics create-dataset-content --dataset-name bpm_blog_validation_dataset2\naws iotanalytics get-dataset-content --dataset-name bpm_blog_validation_dataset2 --version-id \'$LATEST\'\nBash\nThe result should correspond to the row with the selected rowid from the 1/example_data_part_2.csv excerpt shown here.\nNotes about this approach and its alternatives\nThe process described in this post is not idempotent. That is, if you run either Lambda function with the same input multiple times, your data store will not be in the same end state each time. Multiple BatchPutMessage requests would be sent for each row in the .csv file. Because data stores do not impose uniqueness constraints on keys, multiple copies of the data for each key would be stored in the data store. Idempotency is relevant even if you do not intend to rerun a Lambda multiple times with the same input because it is possible for the Lambda function to fail and be invoked again.\nHowever, writing duplicate data to our data store is fine as long as we filter it out when we create our dataset. We can just specify that we want distinct results and include the rowid key as one of the selected items. As a result, each row from each .csv file would be included only once. For example, a query counting total records would look like this:\nSELECT count(DISTINCT rowid) from DATASTORE_NAME\nSQL\nYou could reduce duplicate key processing by storing the already processed keys in a database and checking the database before processing a key. That would result in less space usage for the data stores, faster dataset creation, and possibly faster runtime.\nThis approach will run one worker Lambda function at a time. You could increase the processing speed by allowing the worker Lambda functions to run concurrently. To do that you would need to increase the number of shards used by the Kinesis stream because you can only invoke one Lambda function at a time per shard. You could increase the number of shards by editing the ShardCount value defined in the AWS CloudFormation template. You would also need to increase the number of maximum allowed concurrent invocations. It is set by the ReservedConcurrentExecutions value in the AWS CloudFormation template. Lastly, you would need to divide the MAX_REQUESTS_PER_SECOND value in the worker Lambda function by the value you assigned to ReservedConcurrentExecutions.\nTo launch an altered version of the AWS CloudFormation template, you would need to download it, make your adjustments, go to the CloudFormation Console, click Create Stack, click Choose File, and specify your local copy of the template. To change one of the AWS Lambda functions, you would need to upload a Deployment package containing your desired code to a public Amazon S3 folder. You would then need to change the S3Bucket and S3Key values in the template to point to that deployment package.\nLambda functions execute for at most five minutes. If that were not enough time to iterate through all of the keys in the bucket, then this approach would not upload data for the unvisited keys. However, you could run the launcher code on a local machine. You could also invoke the launcher Lambda function multiple times concurrently on different folders in the bucket. Those invocations could be created by a third Lambda function. Alternatively, you could restart the launcher Lambda function through AWS Step Functions until it had iterated through all of the keys.\nLastly, Lambda functions have a disk capacity of 512 MB and at most 3 GB of memory, so this approach will not work for use cases that require processing large files.\nIf you cannot work within those limitations, then you should use AWS Glue, an ETL service that runs in a managed environment. You would need to edit the script it generated to have it send BatchPutMessage requests.\n'"
112,Build a proof-of-concept IoT solution in under 3 hours with the AWS IoT Device Client,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/build-a-proof-of-concept-iot-solution-in-under-3-hours-with-the-aws-iot-device-client/,"b'Introduction\nYou may be starting on your IoT journey, or have thousands of devices connected already. Maybe you just built an IoT business application, and want to deploy it to your fleet. You\xe2\x80\x99re looking for a way to build functionality to control, update, monitor, or secure your IoT devices. To guide you through this process and get you started on AWS IoT, AWS is happy to announce the \xe2\x80\x9cGet Started with AWS IoT Workshop\xe2\x80\x9d. Click here to access the Workshop.\nIn this hands-on workshop, we use the AWS IoT Device Client to provide a guided walk-through to create your proof-of-concept IoT project. In 3 hours, you will learn to:\nSecurely connect your IoT device to the internet, onboard and register it on AWS IoT Core\nRemotely control your device using AWS IoT Device Management \xe2\x80\x93 run a simple Over-The-Air (OTA) remote operation using Jobs, and set up SSH access for troubleshooting using Secure Tunneling\nSet up a daily security audit, and monitor a \xe2\x80\x98heartbeat\xe2\x80\x99 of health metrics from your device using AWS IoT Device Defender\nThe AWS IoT Device Client is written in C++, open-source, and available on GitHub. You can compile and install on Embedded-Linux based IoT devices to get started with AWS IoT Core, AWS IoT Device Management, and AWS IoT Device Defender.\nPrerequisites\nTo complete this workshop, you need:\nAn AWS account with admin privileges, or Event engine details. You can create a new AWS account here.\nA computer with the latest browser \xe2\x80\x93 like Firefox or Chrome\nBasic understanding of Linux (e.g. create directories, set file permissions) and programming (compiling code)\nWhen to use the AWS IoT Device Client\nExample Use Cases:\nThe AWS IoT Device Client is a reference implementation, and the easiest way to create an IoT proof-of-concept (PoC). It provides an easy way to connect a fleet of devices to the internet, and route IoT data to AWS. By default, it enables you to operate, manage, and control your fleets, or secure them against threats using AWS IoT services. It is open-source, so you can modify it to fit your business needs, connect your business applications to take advantage of AWS IoT features, or optimize its resource utilization when you wish to scale up from a PoC to production. Here are some example use cases the AWS IoT Device Client solves for:\n[First Connect & Provisioning] You want to provision a fleet of production devices and connect them to the internet.\nThe IoT Device Client enables your devices to automatically connect to IoT Core, exchange a bulk certificate for secure individual identities from the IoT Core Identity service, and register themselves in the IoT Core Device Registry.\nYou just built a custom business application for your IoT solution. The IoT Device Client provides a backbone of capabilities for your app.\n[Messaging] You want to exchange telemetry, state, or control messages with the app over MQTT.\nThe IoT Device Client enables your device connect over MQTT to the AWS IoT Core Device Gateway and shares that connection with your app. You can publish/subscribe to custom MQTT topics via the AWS IoT Core Message Broker by setting simple configurations on your device. You also have the option to publish data from your app directly to the AWS IoT Core Rules Engine via Basic Ingest, reducing messaging costs.\n[Control] You want to read and control the state of your device or the configuration of your app.\nThe IoT Device Client gives your app the ability to interact with AWS IoT Core Device Shadows so you can get/set the state of your device or the configuration of your app even if it is offline for prolonged periods.\n[Operate & Update] You want to update your fleet to use a new version of your app, or deploy a firmware/OS update, or simply reboot the fleet remotely.\nWith the IoT Device Client, you can directly use AWS IoT Device Management Jobs \xe2\x80\x93 it lets you deploy to targeted devices, control the speed of your deployment, and track the status of your updates, even if devices work in partially offline environments.\n[Troubleshoot or Access] You want to troubleshoot a device, retrieve logs, or access it using Secure Shell (SSH) for maintenance.\nWith the IoT Device Client your device can directly connect using the AWS IoT Device Management Secure Tunneling feature to an Admin console, providing synchronous access with admin privileges.\n[Monitor & Secure] You want to send a \xe2\x80\x98heartbeat\xe2\x80\x99 of device-side health metrics like ports open or bytes in/out to detect unusual security behaviors and guard your fleet against compromise.\nThe IoT Device Client lets your device automatically publish your metrics over MQTT to the AWS IoT Device Defender service at regular intervals.\nAWS IoT Device Client: High Level Architecture\nCompatibility:\nThe AWS IoT Device Client [GitHub] currently works on IoT devices with common microprocessors (x86_64, ARM, MIPS-32 architectures), and common Linux software environments (Debian, Ubuntu, and RHEL). We also provide a meta-aws recipe for the AWS IoT Device Client that you can build into your Yocto Linux distribution for more constrained and purpose-built devices.\n'"
113,Find runtime errors in AWS IoT Events detector models using type checking,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/find-runtime-errors-in-aws-iot-events-detector-models-using-type-checking/,"b'Customers use AWS IoT Events detector models to describe equipment states and the events that affect these states. A detector model in AWS IoT Events contains expressions written in the AWS IoT Events expression language. An expression can have one of four primitive data types: integer, string, decimal, or Boolean. By checking your expressions for correct use of data types, you can be confident that your detector model will work as you expect. In this post, we describe the consequences of using wrong data types in your AWS IoT Events detector models. We show how the troubleshooting feature of AWS IoT Events detects these type errors before executing your detector model.\nAWS IoT Events is a fully managed service that makes it easy to detect and respond to events from IoT sensors and applications by creating a detector model. To learn more about detector models, see the Getting Started with the AWS IoT Events Console guide.\nHow type checking in AWS IoT Event expressions can help you\nIn this blog we will use the example of an industrial forklift. We will monitor it using an AWS IoT Events detector model, introduce a runtime error, and then show how to troubleshoot it.\nWhen our example forklift picks up an item, it updates two attributes of an input in AWS IoT Events. One of them is weight, the weight of the item being lifted by the forklift. The second attribute is isWeightLb, which indicates whether the weight is in pounds or kilograms. Our developer uses these attributes in two ways. First, the receipt of a new value for isWeightLb is used as a heartbeat, in other words, an indicator that the forklift is active. If a value is not received at least once every five minutes, the forklift\xe2\x80\x99s status is changed to offline and a notification is sent.\nThe monitoring of the forklift for a heartbeat is modeled using a detector model in AWS IoT Events shown in the following figure. The Offline state represents that the forklift has not sent a new value for isWeightLb in the last five minutes.\nSetting up an \xe2\x80\x98Alert if too heavy\xe2\x80\x99 event\nOur developer also uses the preceding detector model to trigger a notification when the forklift lifts too heavy an item. Our developer notifies a SNS topic whenever the forklift lifts an item that is heavier than 4500 lbs. This event is detected via the Alert if too heavy event shown in the following figure.\nSetting up a \xe2\x80\x98Publish to asset property\xe2\x80\x99 event\nOur developer makes one more addition to this detector model. They have already modeled the industrial forklift with an asset model in AWS IoT SiteWise. They wish to populate the isWeightLb asset property of their forklift assets in AWS IoT SiteWise using the isWeightLb input attribute to their AWS IoT Events detectors. Upon receiving a heartbeat, they make their detector model populate an asset property in a Forklift asset in AWS IoT SiteWise via the Publish to asset property AWS IoT SiteWise action shown in the following figure.\nIntroducing a runtime error\nWe will now introduce an error that is especially common when modeling complex systems. The HeartBeat input has two attributes isWeightLb (is the weight measured in pounds or kilograms?) and weight (the weight of the item lifted by the forklift). Our developer meant to pass the input attribute isWeightLb from their AWS IoT Events detector model to their asset property in AWS IoT SiteWise. But, they pass the weight attribute from the input to AWS IoT SiteWise as if the field is a Boolean.\nEvery time this action is executed, AWS IoT Events will attempt to send the value in the weight attribute of the HeartBeat input as a Boolean value to the forklifts/forklift1/isWeightLb asset property in AWS IoT SiteWise.\nBut, for the value to be correctly ingested into AWS IoT SiteWise, the value contained in the weight attribute of the HeartBeat input must be of Boolean type. If it is not, the action will fail to send the value contained in weight to the forklifts/forklift1/isWeightLb asset property in AWS IoT SiteWise. This failure will occur not just from this detector, but all detectors that contain this AWS IoT SiteWise action. Our developer may think this is happening because their detectors have stopped receiving a heartbeat message. Instead, the detectors are receiving the heartbeat message, but are unable to handle weight as a Boolean.\nTo find the root cause of this issue, our developer will:\nEnable logging in AWS IoT Events and check the detector\xe2\x80\x99s logs in Amazon CloudWatch for incoming heartbeat messages.\nVerify that the declared data type of the forklifts/forklift1/isWeightLb asset property in AWS IoT SiteWise is Boolean.\nVerify that the isWeightLb attribute in the HeartBeat input in AWS IoT Events contains a Boolean value at runtime.\nHowever, none of these steps will reveal to our developer that their detector model mistakenly sends the weight input attribute as a Boolean value to AWS IoT SiteWise, instead of the isWeightLb input attribute.\nTo reduce such debugging pain, the troubleshooting feature of AWS IoT Events searches for inconsistencies between the expected and actual data types of input attributes in your detector model. For example, in this situation, the troubleshooting feature warns our developer that the inferred data type, integer, for $input.HeartBeat.weight does not match the expected data type, Boolean, in the AWS IoT SiteWise action.\nTroubleshooting data type errors\nThe AWS IoT Events expression language allows you to have input attributes and variables which need to have one of four primitive data types: integer, decimal, string, and Boolean. You do not declare data types for your input attributes or variables used in your detector model. The troubleshooting feature of AWS IoT Events can infer data types for them by analyzing their use within expressions in your detector model.\nFor example, consider that the Alert if too heavy event in the preceding detector model has the following condition, $input.HeartBeat.weight > 4500. This expression compares an input attribute, weight, against an integer literal, 4500. Since the input attribute weight is being compared with a value of integer type, it is meant for storing a value of integer type and therefore must be of integer type.\nAWS IoT Events infers data types for the input attributes and variables used in your detector model by leveraging the type rules of the AWS IoT Events expression language. These rules dictate the types of the operands that an operator or function in the language is allowed to operate over. For example, the type rule for the > operator in the AWS IoT Events expression language is:\nif one operand of > is of type integer, the other operand must be of type integer\nWhen analyzing your detector model, the troubleshooting feature of AWS IoT Events matches each expression against the type rule that applies to it. It infers data types for operands of operators and arguments of functions. Once a data type is inferred for an input attribute or variable, the troubleshooting feature uses this information to check your expressions in other actions for type correctness.\nExample: Catching type errors with IotSitewiseActions\nConsider the AWS IoT SiteWise action shown in the preceding figure. When you choose Run Analysis in the AWS IoT Events console shown in the following figure, the troubleshooting feature of AWS IoT Events will analyze all expressions in the detector model, including the comparison expression $input.HeartBeat.weight > 4500, to infer that $input.HeartBeat.weight must be of integer type.\nNext, AWS IoT Events will examine the expressions in the AWS IoT SiteWise action of the detector model. It will find that the expression, $input.HeartBeat.weight, is to be sent as a Boolean value to the asset property forklifts/forklift1/isWeightlb in AWS IoT SiteWise. But, since the inferred data type, integer, for the expression, $input.HeartBeat.weight, does not match the data type Boolean declared in the AWS IoT SiteWise action, AWS IoT Events will report the warning shown in the following figure.\nThe warning message states, \xe2\x80\x9cThe expression in the IotSitewiseAction field [$input.HeartBeat.weight] is defined as type Boolean and inferred as type Integer. The defined type and the inferred type must be the same.\xe2\x80\x9d This warning indicates that AWS IoT Events has inferred the expression $input.HeartBeat.weight to be of type integer. But, your AWS IoT SiteWise action assumes that the runtime value evaluated from this expression will be of Boolean type. The Location field in the warning tells us that the warning is reported in an AWS IoT SiteWise action in the Normal state\xe2\x80\x99s onEnter event list in an event named Publish to asset property.\nExample: Catching type errors with custom payload expressions\nSimilar to how your expression in your AWS IoT SiteWise action needs to have a specific declared data type, AWS IoT Events also expects your custom payload expressions to be of string type. For example, consider the action shown in the preceding figure, that showed the Alert if too heavy event, in which you use the custom payload expression ""Last weight exceeded 4500, reported: "" + $input.HeartBeat.weight.\nSince $input.HeartBeat.weight is used as an integer in the event condition $input.HeartBeat.weight > 4500 of the Alert if too heavy event, it cannot be used as part of a string payload directly. The troubleshooting feature reports this issue with the following warning:\n'"
114,How QuantumCrayon is developing the next generation of technologists in South Africa with AWS IoT EduKit,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/09/13/20210731_095555_HDR.jpg,https://aws.amazon.com/blogs/iot/how-quantumcrayon-is-developing-the-next-generation-of-technologists-in-south-africa-with-aws-iot-edukit/,"b'QuantumCrayon is a startup based in South Africa, focused on developing a community of technologists who will help guide local businesses on their digital journeys by creating, evaluating, and implementing impactful technology projects that propel the businesses into the future. They primarily work on telecommunications and disruptive 4th Industrial Revolution (4IR) technologies such as augmented reality (AR), Internet of Things (IoT), robotics, and artificial intelligence (AI).\nIntroduction to QuantumCrayon\xe2\x80\x99s educational programs\nIn addition to consulting with local businesses, they offer online courses through their EduPortal site, as well as partner with local non-profits to deliver in-person educational programs to underprivileged students that offer fun, fast, and practical dives into digital technologies. QuantumCrayon recently ran two educational programs, one with 30 high school students in Gqeberha (the tip of Africa) and another with 75 high school students in Soshanguve (about 100km north of Johannesburg). Both of these programs included a curriculum focused on IoT development.\nIntended outcomes of the program were to have students:\nGain wider exposure to various technology domains.\nExperience the thrill of developing and applying their own technology solutions to real and local problems.\nIgnite an interest in technology career paths.\nGain awareness of new career possibilities and receive career path guidance with a \xe2\x80\x98breadcrumb trail\xe2\x80\x99 to follow in furthering their formal and informal educational development.\n\xe2\x80\x9cWe have developed a technology education program of courses designed to address some of the skills development challenges in our country,\xe2\x80\x9d says Willem Boshoff, Director, QuantumCrayon Education. \xe2\x80\x9cOur objective is to inspire learners and provide them with practical Fourth Industrial Revolution (4IR) skills so that they can further their formal and informal educational development towards new career possibilities in technology. Beyond technology, we are trying to find ways to give the greatest number of people the ability to positively impact their families, organizations, and communities.\xe2\x80\x9d\nGetting hands-on with IoT\nLearning IoT is not easy. Educators and/or students must select both hardware and software frameworks to work with. When making that selection, they need to consider options that are easy enough to get started with, yet extendable enough to learn how to build something of purpose.\nTo get hands-on, the QuantumCrayon curriculum uses their own \xe2\x80\x98technology toolkit\xe2\x80\x99 of sensors and actuators, but the heart of the kit is the M5Stack Core2 for AWS IoT EduKit reference hardware. The hardware is packed with on-board features to enable a multitude of IoT applications out of the box. Learners can then broaden their capabilities to cover additional use cases with hundreds of plug-and-play expansion options.\nTo not further disrupt or delay the learning journey of pupils due to pandemic restrictions, QuantumCrayon adapted the most recent course conclusion to be run outdoors where better social distancing and ventilation could be maintained. This way, learning about coding and 4IR could continue in a time-honored tradition \xe2\x80\x93 outdoors under a shady tree!\nAs part of the hands-on learning component, students prototyped and demonstrated solutions to tackle challenges in the local minibus taxi industry. Some examples include:\nUsing sensors to measure and display seat occupancy for COVID compliance.\nUsing sensors to count passengers entering/leaving the taxi also for COVID compliance.\nUsing smartcards to enable tap-and-go electronic fare payment and improve the passenger experience.\nUsing programmable lights to display taxi destinations and improve customer experience.\nDeploying kits at a taxi stand and implementing smart cards to hail priority rides.\n\xe2\x80\x9cTo see what these young students are able to build with minimal exposure to technology and the real constraints they face is astounding,\xe2\x80\x9d said Rashed Talukder, the head of the AWS IoT EduKit program. \xe2\x80\x9cQuantumCrayon has made edge application development accessible and easy for learners who are just beginning their IoT journeys.\xe2\x80\x9d\nMaking an impact in the community\nTo date, QuantumCrayon has seen enthusiasm for the program, working with a non-profit called Mokgetha Thuto funded by the Telkom Foundation to provide IoT training to hundreds of learners. The program\xe2\x80\x99s optional project day, which was held on a public holiday just after school exams, had 83% turnout. Post-program surveys showed a nearly 50% increase in learners considering careers in technology.\nOver the next few years, based on the success of this program, they plan to expand their courses, cover more AWS services, and reach more than 3,000 students.\nSee some featured learner-created projects from this cohort, showing the breadth of solutions that novice learners felt capable and confident enough to tackle after the program.\nTo learn more about QuantumCrayon and their mission of developing a community of technologists that will drive the fourth industrial revolution, visit their website at edu.QuantumCrayon.co.za.'"
115,Building a scalable IoT system for connected air purifiers on AWS IoT: Blueair (a Unilever company),b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/09/10/Draft-AWS-Blog-2-1024x739.png,https://aws.amazon.com/blogs/iot/building-a-scalable-iot-system-for-connected-air-purifiers-on-aws-iot-blueair-a-unilever-company/,"b'Introduction\nOur homes contain everything from dust, cooking fumes, and chemicals released from paint, furniture, and cleaning agents. Add to that polluted outdoor air making its way into our homes through ventilation, and you\xe2\x80\x99ve got a cocktail of toxins floating around between your four walls. Clean air has proven positive health benefits. It can provide asthma and allergy relief, prevent sickness from bacteria and viruses, and help us sleep better which in turn boosts our immune system. Clean air even makes us smarter according to research. Blueair (a Unilever company) is a leading producer of premium air purifiers for home and professional use. They launched a new generation of connected products called HealthProtect, which proactively monitor air quality and track levels of fine particles and volatile organic compounds as well as the probability of germ growth. Blueair was already a player in the connected device space, but as it noticed that more of its customers were using connected home products, the company knew it was time to prepare for a future when all its devices, which are popular in over 60 countries, would be connected on the Internet of Things (IoT).\nTo achieve the global scalability necessary to support a growing number of connected devices around the world, Blueair rapidly developed and deployed its HealthProtect product line using an IoT system on Amazon Web Services (AWS). Building on AWS enables enhanced security and privacy for Blueair\xe2\x80\x99s customers and supports releases of new and upgraded features so that every air purifier continues to deliver value throughout its life span. \xe2\x80\x9cFreedom to breathe clean, healthy air as nature intended is our promise to consumers,\xe2\x80\x9d says Johan Alvenberg, Global IoT program lead at Blueair. \xe2\x80\x9cBy proactively monitoring the air quality and ensuring 24/7 protection against harmful pollutants, we are doing just that. For the tech savvy we have also added smart, premium usability and functions.\xe2\x80\x9d\nSolution walk-through\nBlueair built a complete end-to-end IoT platform on AWS in record time and scaled globally with ease to reach customers in more regions.\nCentralizing device management on AWS IoT Core\nWhen implementing the HealthProtect product line, Blueair opted to use AWS IoT Core as a central point for managing its growing system of connected devices. From there, it used microservices to store air-quality data and support functionalities such as voice assistance through Alexa Voice Service (AVS) Integration for AWS IoT and 1-Click filter reordering through Amazon Dash Replenishment. The company also introduced a SmartFilter feature, which calculates each filter\xe2\x80\x99s life span, tracks its life cycle, and reminds the customer to replace it when the time comes. It\xe2\x80\x99s simple for customers to automate the reordering of replacement filters either directly from Blueair or through third parties, such as Amazon Dash Replenishment, so customers always have a high level of air purification.\nTo engage with their home devices, customers use the Blueair app, which communicates using Amazon API Gateway \xe2\x80\x94a fully managed service that enables developers to create, publish, maintain, monitor, and secure APIs. Customers can ultimately engage with the device itself by way of Device Shadow, a feature of AWS IoT Core. Device shadows store the latest state of a connected device, which can be read or set at any time, even when an air purifier is turned off. This is critical for supporting the HealthProtect air purifier\xe2\x80\x99s GermShield function, which detects germ-prone environments and kills bacteria and viruses, even when the device is on standby. For security, Blueair leveraged AWS IoT Device Defender and its machine learning feature, ML Detect, to easily implement always-on, proactive security, ensuring the devices were always safe, secured, and fully functional.\nFor its computing needs, Blueair uses AWS Lambda, a serverless compute service that enables developers to run code without provisioning or managing servers. Finally, it securely stores data, including air-quality information, on Amazon DynamoDB, a serverless NoSQL database. The security features built into all AWS services enable secure communication among Blueair\xe2\x80\x99s devices, its mobile app, and AWS. Maintaining high standards for protecting customer privacy has never been simpler for Blueair.\nOnce architecture and business requirements were clear, Blueair was able to bring HealthProtect air purifiers from development to initial sales to customers\xe2\x80\x99 homes in less than one year\xe2\x80\x94an acceleration of their product development timeline. Since the turnaround time for new products was previously greater than 1 year, the company achieved a shorter timeline. Not only did Blueair speed time to market, the solution also enables continuous innovation without service disruption to its customers.\n'"
116,"Monitor and visualise building occupancy with AWS IoT Core, Amazon QuickSight and Raspberry Pi",b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/monitor-and-visualise-building-occupancy-with-aws-iot-core-amazon-quicksight-and-raspberry-pi/,"b'Occupancy monitoring in buildings is a valuable tool across different industries. From healthcare to industrial, and from entertainment to retail, customers are looking for modern and scalable IoT solutions to make practical business decisions. For example, many exhibitions in public art museums employ an open-ended approach, where there is no clear starting or finishing point to the exhibition. The layout of an exhibition needs to take into consideration the way in which the viewers find their way through the exhibition contributes to the viewers\xe2\x80\x99 engagement with the artwork. However, museums can vary the placement of the gallery based on the popularity and number of visitors. They can analyse occupancy data in near real-time and decide the particular gallery should be at the entrance of the building to gain more views or it is already popular and can be moved and grouped with other exhibitions.\nThis blog describes a simple solution that uses building occupancy data to monitor how space is being utilised. It shows how busy each sub-area of the building gets during different times of the day based on a motion sensor\xe2\x80\x99s location. We place the physical device which consists of a Raspberry Pi with Passive InfraRed (PIR) sensor at the entrance. The PIR sensor allows one to sense the motion in direct proximity, (i.e., whether a human has moved in or out of the sensors range) and will generate the data which then will be connected to cloud native services for data storage, analysis and visualisation in near real-time.\nSolution Overview\nThe diagram shows a high level architecture overview. The data is generated locally on the Raspberry Pi and published in JSON format to AWS IoT Core that easily and securely connects devices through the MQTT and HTTPS protocols. Rules Engine, a feature of AWS IoT Core, continuously processes incoming messages, enabling your devices to interact with other AWS services and streams IoT data into Amazon Kinesis Data Firehose. Kinesis Data Firehose allows you to capture and automatically load streaming data into Amazon S3. AWS Glue creates a data catalog with a table for Amazon Athena to query this data from Amazon S3 bucket. Amazon QuickSight, the cloud-powered business intelligence tool, connects to Amazon Athena to create a visualisation dashboard for further analysis.\nPrerequisites\nMinimum requirements:\nAn AWS account.\nRaspberry Pi 4 Model B with a pre-installed Operating System SD card and a power cable.\nPassive InfraRed (PIR) sensor.\nBreadboard with female to female(F2F) and male to male (M2M) jumper wires, LED light and resistor.\nDuring the process I use the headless connection type with third party software providers to access the Raspberry Pi, additionally you can access via SSH.\nStep-by-step Implementation\nNote: I use a stock Raspberry Pi 4 Model B. Figure 1 shows the Raspberry Pi mounted on a Black Case Box kit. This Box kit neatly packages the Pi and prevents damage, but is not necessary.\nFigure 1 shows a Raspberry Pi with marked colours where the same-coloured wires will be connected with the sensor and a breadboard. I use the following pinout in Raspberry Pi:\n5V power \xe2\x80\x93 marked as red\nGROUND \xe2\x80\x93 purple\nGPIO 4 (GPCLK0) \xe2\x80\x93 orange\nGPIO 17 \xe2\x80\x93 green\nFigure 1: Raspberry Pi.\nFigure 2 shows necessary components such as a breadboard, PIR sensor, a resistor, red LED light, 5 male-to-female and 1 female-to-female jumper wire cables.\nFigure 2: Necessary components.\nFigure 3 demonstrates the breadboard marked with colours where the same coloured wires belong. Let\xe2\x80\x99s look at them in more detail:\nFigure 3: Breadboard with the wires, resistor and LED light diagram\nThe blue curve indicates the resistor and the same-coloured jumper wire will be inserted into \xe2\x80\x985-\xe2\x80\x99 and \xe2\x80\x985J\xe2\x80\x99.\nThe red LED light is shown as a red line with a circle on top. If you look at the LED light, you will see that it has two different tip lengths, the short part will be inserted into \xe2\x80\x98I5\xe2\x80\x99 and the long one into \xe2\x80\x98I8\xe2\x80\x99.\nThe green square marked in \xe2\x80\x98H8\xe2\x80\x99 is used for the LED light to communicate with Raspberry Pi and LED light.\nThe white and black squared \xe2\x80\x987+\xe2\x80\x99 and \xe2\x80\x987-\xe2\x80\x99 wires are connected with the PIR sensor, in particular to the GND and VCC pinout of the sensor.\nThe red and purple squared \xe2\x80\x981+\xe2\x80\x99 and \xe2\x80\x981-\xe2\x80\x99 wires are connected with the coloured pins in Raspberry Pi, in particular to the 5V power and GROUND pinouts.\nFigure 4 shows the Passive InfraRed (PIR) sensor with VCC, GND and OUT pinouts, where black, white and orange coloured jumper wires will be connected.\nFigure 4: PIR sensor connected with the Raspberry Pi and the breadboard.\nThe white and black wires on the PIR sensor are connected with the same colour marked pins in the breadboard, as seen in Figure 3.\nThe orange wire is connected to the Raspberry Pi GPIO 4 (GPCLK0) pinout or as marked in orange colour, as seen in Figure 1.\nNow, it\xe2\x80\x99s time to connect the PIR sensor, the breadboard with the red LED light and the resistor, and Raspberry Pi with each other. If everything is connected correctly, the red LED light will turn on if any motion detected as seen in Figure 5, the code for which we will write up in later steps.\nFigure 5: Mounting everything together on Raspberry Pi.\nOnce the physical construction is complete, we are ready to look into details on how to connect and send JSON motion detection data to AWS and save it securely.\nThe rest of the blog details 5 steps for publishing IoT data to the cloud and developing near real-time dashboards. The steps are briefly summarised and then described in further details below.\nHow to connect a Raspberry Pi to AWS IoT Core\nHow to stream JSON data to Amazon Kinesis Data Firehose and save to Amazon S3\nCreate AWS Glue Data Catalog\nConfigure Amazon Athena\nVisualise object movement with Amazon QuickSight dashboard in near real-time\nStep 1. How to connect a Raspberry Pi to AWS IoT Core\nIn this section, I describe how to set up the PIR sensor that when motion is detected the red LED light turns on and we see a message \xe2\x80\x9cMotion Detected\xe2\x80\x9d on the Raspberry Pi. Next, we will need to connect our Raspberry Pi with AWS by registering it as a \xe2\x80\x9cthing\xe2\x80\x9d, creating a policy and certificates. In the end, we will see the motion messages transmitted to the cloud and saved securely for further analysis.\n1.1 Start creating a policy in AWS IoT Core and we will attach this policy to our thing in the next step.\nNavigate to the AWS IoT Core console. In the navigation pane, choose Secure, Policies, Create a policy.\nFor the Name give your policy a name.\nFor Add statements choose Advanced mode and add the policy statement with your AWS region, account number and topic name as seen below. Please check this source for more policy examples.\nSelect Create.\n{\n""Version"": ""2012-10-17"",\n ""Statement"": [   \n{\n      ""Effect"": ""Allow"",     \n   ""Action"": [        \n""iot:Publish"",  \n ""iot:Subscribe"",\n ""iot:Connect"",\n ""iot:Receive""\n   ],  \n""Resource"": ""arn:aws:iot:eu-west-1:<AWS-account-id>:topic/<topicname>""\n   }\n  ]\n}\n1.2 Create and download the AWS IoT Core device certificate\nThe Raspberry Pi requires an AWS IoT root CA (fetched by the install script), certificate, and a private key to authenticate with AWS IoT Core. Create a new certificate and attach the IoT policy deployed by the serverless application.\nNavigate to the AWS IoT Core console. In the navigation pane, choose Manage, Things, Register a Thing, Create a single thing.\nFor the Name give your thing a name.\nFor the rest leave it as default\nSelect Next and Add a certificate for your thing\nCreate a certificate with One-click certificate creation (recommended)\nOnce you followed the steps above and initiated the \xe2\x80\x98one-click certificate creation\xe2\x80\x99, you will see a message that the certificate is generated successfully, as seen below. Now, the certificates are available for download. Save these certificates securely as you will not have a second chance to download the same certificates.\nHaving created a certificate, you need to do the following:\nSelect Download \xe2\x80\x9ca certificate for this thing\xe2\x80\x9d and \xe2\x80\x9ca private key\xe2\x80\x9d. (Save these securely, as this is the only time you can download this certificate.)\nYou also need to download a root CA for AWS IoT (right click on download and select on RSA 2048 bit key Amazon Root CA1, save as a file)\nActivate the Root CA for AWS IoT.\nChoose Attach a policy (that we created on step 1.1).\n 1.3 Download certificates and securely save it to your computer.\nNow, we need to copy these certificates to Raspberry Pi, so that it understands where to connect and send the generated data. There are several options to connect with Raspberry Pi and copy over the files. I use the SFTP route and save the certificates in a safe folder in my Raspberry Pi from where I can reference in my code later.\n1.4 Install AWS IoT Python SDK in the Pi and create a motion_detected.py file to write our python code\n1. Open the terminal in the Raspberry Pi and install AWS IoT Python SDK:\npip3 install AWSIoTPythonSDK\n2. Create a motion_detected.py file in the Raspberry Pi to write our Python script that will identify whether motion has been detected by the PIR sensor.\n3. Copy and paste the python script below to motion_detected.py file:\nfrom gpiozero import LED\nfrom gpiozero import MotionSensor\nfrom datetime import datetime\n\nglobal message\nimport requests\nimport time\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\n\nmyMQTTClient = AWSIoTMQTTClient(""ClientID"")\nmyMQTTClient.configureEndpoint(""xxxxxxxxx.iot.yourregion.amazonaws.com"", 8883)\n\nmyMQTTClient.configureCredentials(""/home/pi/pi-projects/root-CA.pem"", ""/home/pi/pi-projects/LED-private.pem.key"", ""/home/pi/pi-projects/LED.pem.crt"")\n \nprint (\'Initiating Realtime Data Transfer From Raspberry Pi...\')\n\nMyvar= myMQTTClient.connect()\n\ndate = datetime.now().strftime(""%Y_%m_%d-%I:%M:%S_%p"")\nprint (f""Timestamp:{date}"")\n\nred_led = LED(17)\npir = MotionSensor (4)\nred_led.off()\n\nwhile True:\n    pir.wait_for_motion()\n    print(""Motion Detected"")\n    message= ""Motion Detected""\n    myMQTTClient.publish(""topic/pi"", ""{\\""MotionMessage\\"":\\""""+ message + ""\\"", \\""Timestamp\\"" :\\""""+ str(date)+ ""\\""}"", 0)\n    red_led.on()\n    pir.wait_for_no_motion()\n    red_led.off()\n    print (""No Motion"")\n    message= ""No Motion""\n    myMQTTClient.publish(""topic/pi"", ""{\\""MotionMessage\\"":\\""""+ message + ""\\"", \\""Timestamp\\"" :\\""""+ str(date)+ ""\\""}"", 0)\n    time.sleep(1)\nLet\xe2\x80\x99s examine the code above:\n1. We import some directories from the Python library (LED, motion sensor, date and time, MQTTClient which was installed from AWSIoTPythonSDK)\n2. We connect our Raspberry Pi to AWS IoT Core by setting up a name for MQTT client, such as \xe2\x80\x9cClientID\xe2\x80\x99\xe2\x80\x9d in my case it is myMQTTClient = AWSIoTMQTTClient(\xe2\x80\x9cClientID\xe2\x80\x9d)\n3. We create a loop to turn the LED light on/off upon movement detection.\n1.5 Copy your endpoint name from the AWS IoT Core console.\nWe need the endpoint to configure our Raspberry Pi for MQTTClient.\n1. In the AWS IoT console, navigate to IoT Core, Manage, Things, select on your created thing name, on the left side select Interact.\n2. Copy HTTPS endpoint.\n3. Once you copied the Rest API endpoint, you need to paste it into your motion_detected.py file to connect with AWS endpoint:\nmyMQTTClient.configureEndpoint(""xxxxxxxxx.iot.yourregion.amazonaws.com"", 8883)\n4. Now, configure your credentials (with the certificates that we downloaded earlier in the step 1.2) with the code below:\nNote: I renamed the downloaded certificates for the convenience as follows: root-CA.pem \xe2\x80\x93 which is the \xe2\x80\x98root-CA\xe2\x80\x99 certificate that we activated, LED-private.pem.key \xe2\x80\x93 \xe2\x80\x98a private key\xe2\x80\x99, LED.pem.crt \xe2\x80\x93 \xe2\x80\x98a certificate for this thing\xe2\x80\x99. as we mentioned in 1.3.\nmyMQTTClient.configureCredentials(""/home/pi/pi-projects/root-CA.pem"", ""/home/pi/pi-projects/LED-private.pem.key"", ""/home/pi/pi-projects/LED.pem.crt"")\n \nprint (\'Initiating Realtime Data Transfer From Raspberry Pi...\')\n5. Once we set the variable for our MQTTClient and set the endpoint, connect to that endpoint with:\nMyvar= myMQTTClient.connect()\n6. Since we want our motion to be detected with date and time frame, set the date variable in the code:\ndate = datetime.now().strftime(""%Y_%m_%d-%I:%M:%S_%p"")\nprint (f""Timestamp:{date}"")\n7. In the following steps with our code, we need to define the red led light, the motion sensor and start the motion detection with the red led light turned off.\nred_led = LED(17)\npir = MotionSensor (4)\nred_led.off()\n8. Now, its time to create a loop based on the motion detection as following:\nwhile True:\npir.wait_for_motion()\nprint(""Motion Detected"")\nmessage= ""Motion Detected""  myMQTTClient.publish(""topic/pi"", ""{\\""MotionMessage\\"":\\""""+ message + ""\\"", \\""Timestamp\\"" :\\""""+ str(date)+ ""\\""}"", 0)\nred_led.on()\npir.wait_for_no_motion()\nred_led.off()\nprint (""No Motion"")\nmessage= ""No Motion""\nmyMQTTClient.publish(""topic/pi"", ""{\\""MotionMessage\\"":\\""""+ message + ""\\"", \\""Timestamp\\"" :\\""""+ str(date)+ ""\\""}"", 0)   time.sleep(1)\nOnce you followed the steps above in the motion_detected.py document, do not forget to save it and then run the code. If everything is set up correctly, upon the movement detection within a 1\xe2\x80\x932-meter radius from the PIR sensor, you will see a message \xe2\x80\x9cMotion Detected\xe2\x80\x9d and the red LED light in your breadboard will turn on (as seen in Figure 5). Alternatively, if there\xe2\x80\x99s no motion it will show \xe2\x80\x9cNo Motion\xe2\x80\x9d and the LED light will turn off.\nStep 2. How to stream JSON data to Amazon Kinesis Data Firehose and save into Amazon S3\n2.1. Create a delivery stream with Amazon Kinesis Data Firehose.\nOnce we connected our Raspberry Pi with AWS IoT Core, we need to create an Amazon Kinesis Data Firehose Delivery Stream using the following field values:\nName Pi-to-Kinesis\nS3 Bucket <Create one>\nS3 Prefix s3://pi-to-bucket/2021/\nA successfully created delivery stream with the name Pi-to-Kinesis looks like this:\n2.2. Configure the AWS IoT rule\nAfter creating the Amazon Kinesis Data Firehose Stream with the defined storage location in Amazon S3, we need to set the rules for AWS IoT Core to take all the data from the topic, stream it to Amazon Kinesis Data Firehose, and save this data into the Amazon S3 bucket.\n1. In the AWS IoT console, navigate to AWS IoT Core, Act, Rules, Create a rule.\nCreate a new AWS IoT rule with the following field values:\nName \xe2\x80\x98RaspberryPiRule\xe2\x80\x99\nQuery Statement *\nTopic Filter \xe2\x80\x98topic/pi\xe2\x80\x99\nAdd Action Send messages to Amazon Kinesis Data Firehose\nStream name \xe2\x80\x98Pi-to-Kinesis\xe2\x80\x99\nSelect Separator \xe2\x80\x98\\n (newline)\xe2\x80\x99\n2. Let\xe2\x80\x99s test if we are getting motion messages with timestamps on AWS IoT Core.\n3. Navigate to AWS IoT Core, MQTT test client, subscribe to a topic, \xe2\x80\x9ctopic/pi\xe2\x80\x9d (the topic name that you set in your python script), Subscribe.\n4. If everything is set up correctly you will see the motion messages sent from the Pi as below:\n2.3. Check the streamed data saved in Amazon S3\n1. Navigate to Amazon S3 to see the bucket that you have created in step 2.1 while setting up an Amazon Kinesis stream. You will see the created S3 bucket, in my case its called \xe2\x80\x98pi-to-bucket\xe2\x80\x99.\n2. Select the \xe2\x80\x98pi-to-bucket\xe2\x80\x99 and check if the generated JSON data successfully saved. You will see objects in your bucket as below:\n3. Select one of those objects and choose Download or Open. If everything is set correctly you will see your data as shown in the screenshot below:\nStep 3. Create AWS Glue Data Catalog\nOur data lake is successfully created and all the data saved securely in Amazon S3 bucket. Now, it is time to use AWS Glue to create a data catalog with a table for Amazon Athena to query this data using Simple Query Language (SQL).\nPlease follow the instructions here to create a table in the AWS Glue console. You will need to create a table with column name \xe2\x80\x9cmotionmessage\xe2\x80\x9d and \xe2\x80\x9ctimestamp\xe2\x80\x9d with data type \xe2\x80\x93 string. Your table will look like this:\nStep 4. Configure Amazon Athena\nIn the previous steps, we saw that our Raspberry Pi is successfully connected with AWS IoT Core and displays the motion messages live. We also confirmed that the stored JSON data is saved in our created Amazon S3 bucket \xe2\x80\x93 \xe2\x80\x98pi-to-bucket\xe2\x80\x99. Now, we want to easily analyse the stored data with an interactive query service called Amazon Athena.\nAmazon Athena will play an instrumental role for the connection with the data visualisation tool Amazon QuickSight which we discuss in later steps.\n* Note: for more detailed information on how to create the table please follow this instruction.\n4.1. Create a simple table in Amazon Athena that will query our Amazon S3 bucket that we created earlier.\n1. Log in to the Athena Console. In the Query Editor, create a table using the following query:\nCREATE EXTERNAL TABLE IF NOT EXISTS default.new_table_pi (`MotionMessage` string,\n\n`Timestamp` string\n)\nROW FORMAT SERDE \'org.openx.data.jsonserde.JsonSerDe\'\nWITH SERDEPROPERTIES (\n\'serialization.format\' = \'1\'\n) \nLOCATION \'s3://pi-to-bucket/2021/\'\nTBLPROPERTIES (\'has_encrypted_data\'=\'false\');\n2. Once the table is created you can run the query below to see your data:\nSELECT * FROM ""default"".""new_table_pi"" limit 10;\nYou will see something like this :\nTo sum up the above steps, we created a simple table with two columns: the motion message and the timestamp, then we queried the data from the Amazon S3 bucket where our PIR sensor-generated JSON data is stored.\nStep 5. Visualise object movement with the Amazon QuickSight dashboard in near real-time\nNow, we are ready to analyse the data in the cloud-native and fully managed business intelligence tool Amazon QuickSight.\nNote: You may have to give Amazon QuickSight explicit permissions to view your Amazon Athena table.\nTo visualise data with Amazon QuickSight, follow these steps:\n1. Open the Amazon QuickSight console.\n2. Select New analysis, New dataset. \n3. Choose Athena as a new data source.\n4. Set the data source name (it is a catalog name in Amazon Athena).\n5. Select Create data source.\n6. Once the data source is created, you need to choose a database that contains a set of tables and select the specific table which you want to visualise. Choose Select:\n7. In the screenshot below you see a defined table, data source and an option to choose how you want to query your data. Select \xe2\x80\x98Directly query your data\xe2\x80\x99 and select Visualise.\n8. Design the Amazon QuickSight visualisations in the drag and drop editor. You can choose any option from visual types that are listed on the left side. I selected a vertical bar chart and a donut chart which you see in the two screenshots below.\n9. From the Fields list on the left pane you will see column names that we created earlier in Amazon Athena. Drag a \xe2\x80\x98timestamp\xe2\x80\x99 field to the X-axis and \xe2\x80\x98motionmessage\xe2\x80\x99 to the Value field wells.\nThe bar chart below shows the number of motions detected for hourly intervals over a specific period of time. For example, the highest number of motions (1.25K) in the venue was detected at 10:49 AM on April 27,2021.\nYou may want to analyse the occupancy data through a different visual format. Simply choose a \xe2\x80\x98donut chart\xe2\x80\x99 in visual types and you will see the total number of motions divided across different periods. As seen on the screenshot below, 3.816K motions in total has been detected in the building across different dates and time. In particular, 33% of total movement has been noted at 10:49 AM on April 27,2021.\n'"
117,Ten security golden rules for Industrial IoT solutions,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/ten-security-golden-rules-for-industrial-iot-solutions/,"b'Industrial digital transformation is driving changes to the Operational Technology (OT) landscape, making it more connected to the internet, IT systems and solutions. Operational Technology is the use of hardware and software to monitor and control physical assets and production operation. Industrial control systems (ICS), an element of OT, is a general term that encompasses several types of control systems and associated instrumentation used for industrial process control. As these environments continue to evolve, OT environments are leveraging more IT solutions to improve productivity and efficiency of production operations. This convergence of IT and OT systems is creating a mix of technologies that were designed to withstand hostile network environments and ones that were not, which creates risk management difficulties that need to be controlled. Industrial Internet of Things (IIoT) are systems that connect and integrates industrial control systems with enterprise systems and the internet, business processes and analytics and is a key enabler for Smart Manufacturing and Industry 4.0. It has significantly widened the array of technologies available for use in industrial environments. In this blog post, we discuss this OT/IT convergence which introduces new security risks and challenges that industrial customers must properly manage.\nTo help companies plan their industrial digital transformation safely and securely, AWS recommends a multi-layered approach to secure the ICS/OT, IIoT and cloud environments, which is captured in the following ten golden rules.\n1. Conduct a cyber-security risk assessment using a common framework (such as MITRE ATT&CK) and use it to inform system design\nBefore taking advantage of IT technologies in OT environments, conduct a cyber-security risk assessment so that the risks, gaps and vulnerabilities are fully understood and can be proactively managed. Create and maintain an up to date threat model.\nSegment industrial plant networks based on a pre-defined zoning model that includes establishment of an Industrial Demilitarized Zone (IDMZ) and control of traffic between zones, e.g. according to the Purdue Model.\nFollow the micro segmentation approach, i.e. build small islands of components within a single network that communicate only with each other and control the network traffic between segments.\nUse firewalls and unidirectional gateways to control information flow between network segments.\nUse protocol converters to convert insecure protocols to secure protocols.\nIf possible, isolate safety critical networks from business and control networks.\nIf you are unable to protect insecure assets, isolate or disconnect them from the network\nIn addition, maintain secure network foundations in the cloud.\nAWS resources\nAWS provides the following services to help you create and maintain an adequate network segmentation and secure traffic control to and in the AWS Cloud:\nAWS Virtual Private Network (VPN) solutions establish secure connections between industrial plants and AWS global network.\nAWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated network connection from your premises to AWS.\nAWS Transit Gateway connects VPCs and on-premises networks through a central hub.\nAWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs).\nAWS Virtual Private Cloud (Amazon VPC) is a service that lets you launch AWS resources in a logically isolated virtual network that you define.\n2. Maintain an asset inventory of all connected assets and up to date network architecture\nA critical aspect of a good security program is having visibility into your entire OT/IIoT system and knowing which systems don\xe2\x80\x99t support open networks and modern security controls.\nCreate and maintain an asset inventory for all OT/IIoT assets which can act as system of record and single source of truth for connected assets on the shop floor along with their major characteristics such as make and model, location and their hardware and software configuration.\nCategorize them based on their function (safety critical, control, edge, etc.), if software updates can be applied to them (patchable vs non patchable), their network design (designed for open or closed networks) so that you are aware of their criticality and their ability to support modern security controls so compensating controls can be installed to mitigate risk if needed.\nCreate and maintain an up to date network architecture showing how these assets are interconnected along with their relationships (asset hierarchies) and conduct a network security architecture review.\nConsider consolidating OT/IIoT asset information into your enterprise asset management system.\nAWS resources\nAWS provides the following assets and services to help you create and maintain a connected asset inventory:\nAWS IoT Device Management for devices connected to AWS IoT.\nAWS Systems Manager Inventory for cloud instances and on-premises computers.\n3. Provision modern IIoT devices and systems with unique identities and credentials and apply authentication and access control mechanisms\nAssign unique identities to modern IIoT devices such that when a device connects to other devices or cloud services, it must establish trust by authenticating using principals such as X.509 certificates, security tokens or other credentials.\nCreate mechanisms to facilitate the generation, distribution, rotation, and revocation of credentials.\nEstablish Root of Trust by using hardware-protected modules such as Trusted Platform Modules (TPMs) if available on the device.\nEnsure least privilege access controls for OT/IIoT devices, edge gateways and agent software accessing local and cloud resources.\nAvoid hard coding or storing credentials & secrets locally on OT/IIoT devices.\nAWS resources\nAWS provides the following assets and services to help you provision and secure modern IIoT assets:\nSecurity and Identity for AWS IoT\nAmazon Cognito is a service that provides authentication, authorization, and user management for your web and mobile apps.\nAWS Identity and Access Management (IAM) is a service that enables you to manage access to AWS services and resources securely.\nDevice authentication and authorization for AWS IoT Greengrass.\nAWS Secrets Manager is a service that can be used to securely store and manage secrets in the cloud and encrypts the secrets using AWS KMS.\nAWS Key Management Service (KMS) enables you to easily create and control the keys used for cryptographic operations in the cloud.\n4. Prioritize and implement OT and IIoT specific patch management and define appropriate update mechanisms for software and firmware updates\nAs the adoption and complexity of software increases, so does the number of defects, some of which will be exploitable vulnerabilities. While eliminating vulnerabilities, prioritize by criticality (CVSS score, for example) by patching the most critical assets first.\nHave a mechanism to push software and firmware to devices in the field to patch security vulnerabilities and improve device functionality.\nVerify the integrity of the software before starting to run it ensuring that it comes from a reliable source (signed by the vendor) and that it is obtained in a secure manner.\nEmploy authentication and access controls on deployment artifact repositories and their distribution systems.\nMaintain an inventory of the deployed software across your OT/IIoT system, including versions and patch status.\nMonitor status of deployments throughout your OT/IIoT system and investigate any failed or stalled deployments.\nMaintain notification mechanisms to immediately alert stakeholders when your infrastructure can\xe2\x80\x99t deploy security updates to your fleet.\nCreate mechanisms to identify, network isolate and/or replace legacy devices and IIoT systems that are not capable of receiving updates.\nPerform deployment of patches for the OT/IIoT devices only after testing the patches in a test environment before implementing them in production.\nAWS resources\nAWS provides the following assets and services to help you organize and maintain a continuous development and deployment pipeline:\nAmazon FreeRTOS Over-the-Air (OTA) Updates\nAWS IoT Greengrass Core Software OTA Updates\nAWS IoT jobs to define a set of remote operations that you send to and execute on one or more devices connected to AWS IoT.\nAWS Systems Manager Patch Manager automates the process of patching managed instances with both security related and other types of updates such as operating systems and applications.\n5. Secure manufacturing data at the edge and in the cloud by encrypting data at rest and create mechanisms for secure data sharing, governance and sovereignty\nIdentify and classify data collected throughout your IIoT system based on the earlier risk analysis.\nMonitor the production data at rest to identify potential unauthorized data modification.\nApply access controls using least privilege principle and monitor/audit data access.\nAccess controls should also be applied at the connectivity layer using security appliances such as firewalls or unidirectional network devices or data diodes.\nIdentify and execute on opportunities to stop collecting unused data or adjusting their granularity and retention time.\nConsider privacy and transparency expectations of your customers and corresponding legal requirements in the jurisdictions where you manufacture, distribute, and operate your IoT devices and systems.\nAWS resources\nAWS provides the following assets and services to help you secure manufacturing data at the edge and cloud:\nAWS Shared Responsibility Model for security and compliance.\nAWS Data Privacy\nAWS Compliance Programs and Offerings\nAWS Compliance Solutions Guide\nAWS KMS enables you to easily create and control the keys used for cryptographic operations in the cloud.\nData protection in AWS IoT SiteWise\nAmazon Macie to discover and protect sensitive IIoT data at scale.\n6. Whenever possible, encrypt all data in transit, including sensor/device data, administration, provisioning and deployments and when using insecure industrial protocols, convert insecure protocols into standardized and secure protocols as close to the source as possible\nProtect the confidentiality and integrity of inbound and outbound network communication channels that you use for data transfers, monitoring, administration, provisioning, and deployments by selecting modern internet native cryptographic network protocols.\nIf possible, limit the number of protocols implemented within a given environment and disable default network services that are unused.\nSelect the newer version of industrial protocols which offer security features and configure the highest level of encryption available when using ICS protocols such as CIP Security, Modbus Secure and OPC UA.\nWhen using secure industrial protocols is not an option, tighten the trust boundary using a protocol converter to translate the insecure protocol to a secure protocol as close to the data source as possible. Alternatively, segregate the plant network into smaller cell/area zones by grouping ICS devices into functional areas to limit the scope and area of insecure communications. Use unidirectional gateways and data diodes for one-way data flow and specialized firewall and inspection products that understand ICS protocols to inspect traffic entering and leaving cell/area zones and can detect anomalous behavior in the control network.\nWhen network segmentation/segregation is not an option with insecure controllers/protocols, then network isolate or disconnect those insecure systems from the network.\nHave a mechanism to identify and disable vulnerable wireless networks on the shop floor which get installed during proof of concepts, prototypes, etc. often without the necessary security approvals.\nAWS resources\nAWS provides the following assets and services to help with secure network communications:\nAWS IoT SDKs to help you securely and quickly connect devices to AWS IoT.\nFreeRTOS Libraries for networking and security in embedded applications.\nSecurity best practices for AWS IoT SiteWise\n7. Harden all connected resources and especially internet connected resources and establish secure connections to cloud services and secure remote access to on-premises resources\nInternet connected network resources such as IIoT devices and Edge Gateways need to be hardened per NIST guidelines.\nUse device certificates and temporary credentials instead of long term credentials to access AWS Cloud services and secure device credentials at rest using mechanisms such as a dedicated crypto element or secure flash.\nUse on-premises managed infrastructure solutions to simplify management and monitoring.\nEstablish a mechanism for bidirectional communication to remote devices over a secure connection.\nEstablish secure connections to cloud services and monitor these connections.\nRegularly review and identify attack surface minimization opportunities as your IIoT system evolves.\nUse physical enclosures to protect OT/IIoT assets.\nAWS resources\nAWS provides the following assets and services to help secure cloud connected network resources and securely manage on-premises computing resources:\nNIST Guide to General Server Security\nAWS IoT Greengrass hardware security\nWorking with secrets at the edge.\nAWS Systems Manager provides you with a centralized and consistent way to gather operational insights and carry out routine management tasks.\nAWS Outposts is a fully managed hybrid solution that extends the AWS Cloud to the on-premises environment, bringing the same AWS infrastructure, services, APIs, management tools, support and operating model as the AWS Cloud.\nAWS Snow Family provides highly secure portable devices to collect and process data at the edge.\nSecure Tunneling for AWS IoT Device Management to access IIoT devices behind restricted firewalls at remote sites for troubleshooting, configuration updates, and other operational tasks.\nPlant network to Amazon VPC connectivity options.\nAWS IoT Greengrass connecting to AWS IoT Core using port 443 or through a network proxy as an additional security measure.\n8. Deploy security auditing and monitoring mechanisms across OT and IIoT and centrally manage security alerts across OT/IIoT and cloud\nDeploy auditing and monitoring mechanisms to continuously collect and report activity metrics and logs from across your OT/IIoT system.\nImplement a monitoring solution in the OT and IIoT environments to create an industrial network traffic baseline and monitor anomalies and adherence to the baseline.\nPerform periodic reviews of network logs, access control privileges and asset configurations.\nCollect security logs and analyze them in real-time using dedicated tools, for example, security information and event management (SIEM) class solutions such as within a security operation center (SOC).\nContinuously check that your security controls and systems are intact by explicitly testing them.\nAWS resources\nAWS provides the following assets and services to help you monitor your security at varying levels:\nAWS IoT Device Defender to monitor and audit your fleet of IoT devices.\nMonitoring AWS IoT with CloudWatch Logs to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.\nLogging AWS IoT API Calls with AWS CloudTrail to provide a record of actions taken by a user, a role, or an AWS service in AWS IoT.\nMonitoring with AWS IoT Greengrass logs\nAWS Config to assess, audit, and evaluate the configurations of your AWS resources.\nAmazon GuardDuty to continuously monitor for malicious activity and unauthorized behavior to protect your AWS accounts and workloads.\nAWS Security Hub to automate AWS security checks and centralize security alerts.\n9. Create incident response playbooks, and build automation as your security response matures to contain events and return to a known good state\nMaintain and regularly exercise a security incident response plan to test monitoring functionality.\nCollect security logs and analyze them in real-time using automated tooling. Build playbooks of unexpected findings.\nCreate an incident response playbook with clearly understood roles and responsibilities.\nTest incident response procedures on a periodic basis.\nAs procedures become more stable, automate their execution but maintain human interaction. As the automated procedures are validated, automate what triggers their execution.\nAWS resources\nAWS provides the following assets and services to help you monitor and create incident response playbooks:\nAWS Security Incident Response Guide\nAWS Systems Manager provides a centralized and consistent way to gather operational insights and carry out routine management tasks.\n10. Create a business continuity and recovery plan including a plan for backups and cybersecurity testing\nFocus on ensuring resilience of Industry 4.0 systems by creating a business continuity plan and disaster recovery plan. Test the plans periodically and adapt them according to lessons learnt from tests and actual security incidents.\nIn business continuity and recovery plans, include third party aspects.\nDefine important parameters for your company\xe2\x80\x99s business continuity, such as a recovery time objective (RTO), recovery point objective (RPO), etc.\nUse resiliency features at the edge to support data resiliency and backup needs.\nUse cloud services for backup and business continuity.\nConduct cyber security testing across OT and IIoT periodically to test devices and OT systems, Edge Gateways, networks and communication and cloud services.\nAWS resources\nAWS provides the following assets and services to help with backup, recovery and cybersecurity testing:\nAWS Well Architected Framework, IoT Lens to design, deploy, and architect IIoT workloads aligned with architectural best practices.\nResilience in AWS IoT Greengrass to help support data resiliency and backup needs.\nBackup and Restore Use Cases with AWS\nCloudEndure Disaster Recovery for fast and reliable recovery into AWS.\nAWS Backup to centrally manage and automate backups across AWS services.\n'"
118,Getting started with MQTT retained messages for AWS IoT Core,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/09/02/getting-started-with-retained-messages-01.png,https://aws.amazon.com/blogs/iot/getting-started-mqtt-retained-messages-aws-iot-core/,"b""AWS recently announced the general availability of MQTT retained messages for AWS IoT Core. This feature allows you to store a single message per a given MQTT topic for delivery to any current and future topic subscribers. Creating a retained message simply requires setting a retained flag when publishing to let the AWS IoT Core broker know to save it. At that point the message is delivered to all current subscribers as normal, and also any new devices that subscribe to that topic in the future. Also included in this launch are new and updated APIs to help manage retained messages. Retained messages can be used in all regions where AWS IoT Core is available.\nIn this post, we provide an overview of this feature, share some use cases to keep in mind when designing your next IoT project, and provide a guide on how to get started both in the AWS IoT console and programmatically.\nOverview\nRetained messages are defined in the MQTT 3.1.1 specification, and are created by setting the retained flag to \xe2\x80\x98True\xe2\x80\x99 when publishing a message. This flag is supported by the AWS IoT Device SDKs as well as most MQTT 3.1.1 compatible clients. A retained message is delivered to any currently subscribed clients just like a normal message, and it will also be automatically sent to new clients upon subscribing to that topic. As only one retained message can be saved per topic, any future retained messages that are sent will replace an existing retained message if there is one. AWS IoT Core will store retained messages for up to three years after the last time they were updated or accessed. Publishing a new retained message with an empty payload can be used to remove the currently retained message from a particular topic. Managing these messages can be done through the new Retained Messages page within the AWS IoT console. This page can be found under the \xe2\x80\x9cManage\xe2\x80\x9d tab where you can view all of the currently retained messages in the current region as well as update them. Management can also be performed over HTTP through the use of the new ListRetainedMessages, GetRetainedMessage, and updated Publish APIs.\nUse cases for retained messages\n1. Distributing configuration settings for devices\nOne reason to use retained messages is to store configuration settings for one or more devices. This may be helpful when finishing up a bootstrapping process after a newly provisioned device first comes online, or as a discovery message for when devices connect to an IoT application and need to be informed of its capabilities. Devices or other clients could also update that retained message with the latest configuration settings as needed. When using this approach on a per-device basis where each device has its own unique configuration topic, then it is worth considering Device Shadow for AWS IoT Core. One difference would be that a retained message will be automatically delivered when subscribing versus subscribing to Device Shadow updates and deliberately requesting the current state if needed. To understand all of the key differences between the two, check out Using MQTT retained messages which includes a comparison table to help you choose the right tool for your particular use case.\nAnother reason to use a retained message is to broadcast a shared configuration to multiple devices. For example, if you have a configuration to send to a group of devices, then having the applicable devices subscribe to a shared topic would ensure that all current and future subscribers to that particular topic will have the latest version of their shared configuration. Unique device configurations could still be managed in either a Device Shadow or retained on a unique topic, while any shared or group settings could be retained within the shared topic.\nFor example, a user publishes a message to a topic that multiple devices subscribe to. Two online devices receive the message. With the retain flag set to \xe2\x80\x98True\xe2\x80\x99, the AWS IoT Core broker saves the message for future devices that subscribe to that topic. If a third device is currently offline, the message sent by the user is retained, so the offline device will automatically receive it once it connects and subscribe to that topic.\n2. Keeping track of the last known state of devices\nAnother way to use retained messages is for storing the current state of one or more devices. For example, a device could periodically publish its current state to a unique topic and set the retain flag to \xe2\x80\x98True\xe2\x80\x99 each time so that the latest state is always stored by the AWS IoT Core broker. If another client, such as a cloud service or customer-facing application needs the device state, it can just subscribe to the particular topic and automatically receive it instead of waiting for the device to publish an update. As with the first device configuration example, this particular pattern of using a unique retained message topic per device to maintain state shares similarities with Device Shadows, so please review the comparison table in Using MQTT retained messages to help choose the best option for your particular use case.\nFor maintaining the current connectivity state of a device, use the \xe2\x80\x98Will Retain\xe2\x80\x99 flag so that if a device has an ungraceful disconnect, the retained message of a particular topic is updated so that current and future subscribers can know the current connectivity state of that device. This way, if a device has an ungraceful disconnect, any other devices that subscribe to that topic before it reconnects will automatically be notified that it is currently offline.\nUsing retained messages in the AWS IoT console\nTo test out retained messages from within the AWS IoT console, we\xe2\x80\x99ll use a combination of the MQTT Test Client as well as the new Retained messages page that can be found under the Manage section. It\xe2\x80\x99s important to note that retained messages have associated AWS IoT Core policy actions that allow you to control access to this feature. Check out Example AWS IoT policies to see examples of how to authorize access to retained messages. First, we\xe2\x80\x99ll use the MQTT Test Client to publish a retained message to a test topic. Afterwards, we\xe2\x80\x99ll see how to view and update that message from the Retained Messages tab. Finally, we\xe2\x80\x99ll go back to the MQTT Test Client, subscribe to that test topic, and see the delivery of the retained message right from our browser. Let\xe2\x80\x99s get started.\nStep 1: Publish a test message with the MQTT test client\nLog in to the AWS Management Console, select Services along the top and navigate to AWS IoT Core.\nSelect Test in the left-hand navigation and then MQTT test client.\nSelect the Publish to a topic tab and enter the topic name that you\xe2\x80\x99d like to use for your test. For this example, imagine we\xe2\x80\x99re making smart home products and want to set up a topic per customer that stores account settings, which influence device settings such as opt-in usage of certain settings or premium subscription services.\nEnter \xe2\x80\x9cusers/settings/user01\xe2\x80\x9d as the topic.\nEnter {\xe2\x80\x9caccount_type\xe2\x80\x9d : \xe2\x80\x9cstandard\xe2\x80\x9d} for the message to include the customer\xe2\x80\x99s current account type.\nExpand the Additional configuration section and choose the Retain message on this topic checkbox.\nSelect Publish.\nStep 2: View the retained message within the Retained Messages page\nNow that we\xe2\x80\x99ve published a retained message, select Manage in the left-hand navigation and then Retained messages. From here, you\xe2\x80\x99ll see a list of topics that currently have retained messages.\nChoose the topic that you published a message to in Step 1. From here, you can see the retained message that is currently being saved on the topic.\nStep 3: Subscribe in MQTT test client\nNow that we\xe2\x80\x99ve confirmed our test message has been retained successfully, let\xe2\x80\x99s see it in action.\nIn the left-hand navigation, choose MQTT test client under the Test section.\nChoose the Subscribe to a topic tab.\nIn the Topic filter field, enter \xe2\x80\x9cusers/settings/user01\xe2\x80\x9d.\nSelect Subscribe. You should see the retained message pop up on your screen.\nUsing retained messages within your projects\nPublishing retained messages from within your device and application logic is supported by the AWS IoT Device SDKs as well as most MQTT clients since retained messages is a standard feature of the MQTT 3.1.1 specification. One way that retained messages for AWS IoT Core differ from the specification is that in order to receive a retained message stored on a particular topic, you\xe2\x80\x99ll need to match the topic filter exactly without the use of any wildcards (i.e. #,*).\nPublishing a retained message using the AWS IoT Device SDK\nLet\xe2\x80\x99s look at an example of how we can publish a retained message by using the AWS IoT Device SDK v2 for Python. Here is a snippet from the MQTT Pub/Sub sample that is responsible for publishing a message:\nmqtt_connection.publish(\ntopic=args.topic, \npayload=message_json,\nqos=mqtt.QoS.AT_LEAST_ONCE)\nPython\nWhile this example defaults to QoS 1, QoS 0 is also supported for retained messages. Regarding setting the retain flag, if we look at the API documentation, we see that setting it when using the publish class just requires adding the parameter retain=bool.\nSo, to publish a retained message with the AWS IoT Device SDK v2 for Python, add that parameter to the end of the snippet like this:\nmqtt_connection.publish(\ntopic=args.topic,\npayload=message_json,\nqos=mqtt.QoS.AT_LEAST_ONCE,\nretain=True)\nPython\nAs a subscriber, retained messages can be differentiated from standard messages by checking the same flag.\nTo test this, publish a new retained message to the topic \xe2\x80\x9cusers/settings/user01\xe2\x80\x9d that says \xe2\x80\x9chello from python\xe2\x80\x9d. The example can be run using the following command line:\npython3 pubsub.py --endpoint YOUR-ENDPOINT \\\n--port 8883 \\\n--cert YOUR-CERT \\\n--key YOUR-KEY \\\n--root-ca ROOT-CA \\\n--client-id YOUR-CLIENT-ID \\\n--topic users/settings/user01 \\\n--count 1 \\\n--message 'hello from python!'\nBash\nIn the AWS IoT console, verify that you now see this new message reflected in the Retained messages section.\nWhile we just looked at Python in this example, check out other AWS IoT Device SDKs which also support the retain flag out of the box.\n"""
119,Connecting with mobile BLE to AWS IoT Core using FreeRTOS and Nordic nRF52840-DK,b'Paul Shiner',2021-11-19T20:47:41+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/connecting-with-mobile-ble-to-aws-iot-core-using-freertos-and-nordic/,"b'As an IoT solution architect, customers often ask me how they can connect to AWS IoT Core (cloud) using a microcontroller unit (MCU). One solution is to use Bluetooth Low Energy (BLE) as the connection from the MCU to a mobile device; from there, the mobile device connects to the cloud. BLE works for consumer IoT device use cases such as thermostats, door locks, connected bicycles, smart watches, and many others.\nIn this blog, I demonstrate how to use a Nordic nRF52840-DK board (MCU) to connect to AWS IoT Core using BLE with an iOS mobile app. I show two ways to connect to AWS IoT Core (cloud): first by directly using BLE and passing data into AWS IoT Core using MQTT, and second by using GATT setup to pass data through to AWS IoT Core using BLE and your mobile phone.\nPre-requisites\nRead the Getting started with the Nordic nRF52840-DK Guide and How to setup BLE mobile app reference guide, as these will give you needed insights for the end-to-end demo covered in this blog. You will also use this FreeRTOS github repo, so have these resources open while you follow along.\nHave the Nordics nRF52840 development kit.\nSet up the SDK according to your mobile device\xe2\x80\x94for iOS devices you need iOS SDK for FreeRTOS here and for Android devices you need Android SDK for FreeRTOS here.\nI use the eu-central-1 region; make sure you select the region closest to you and create all the settings and services in that same region to avoid any issues later on.\nHave Xcode to set up the mobile app on iOS and to sign the mobile app. Apple requires you to have a developer account, which you can set up here.\nSolution overview\nIn our solution, we will use Nordics nRF52840-DK with FreeRTOS and will carry out the following tasks (these are commonly required tasks in embedded development to connect MCUs to the cloud using BLE and mobile applications):\nFirst, we will do the embedded-side development:\nSet up the hardware (MCU with serial port communication with the computer).\nSet up firmware (if needed to communicate with the computer).\nSet up and configure FreeRTOS on the MCU.\nSet up, configure, and deploy FreeRTOS BLE application on the MCU.\nThen, we will do the cloud side tasks:\nSet up a BLE IoT thing in AWS IoT Core.\nThen, we will do the mobile app client tasks:\nConfigure and deploy the application to our mobile phone (iOS).\nOnce we have completed following tasks, we will be able to test the complete end-to-end process of MCU connecting to AWS IoT Core using MQTT as well as Custom GATT MQTT settings from Mobile client, giving us insight on many different ways we can connect to AWS IoT.\nSolution Diagram\nTo set up your hardware\nConnect your host computer to the USB port labeled J2, located directly above the coin cell battery holder on your Nordic nRF52840 board (see the highlighted box in the following picture).\nTo set up your terminal emulator\nYou need a terminal emulator to read data between your desktop and board using serial connection. This terminal emulator will be used to read the output from the board, as well as write to the board such as firmware and FreeRTOS code. For this blog, you can use the following:\nFor Windows: TeraTerm\nFor Linux and MacOS: GNU Screen (follow configuration using settings here)\nIn your terminal emulator, run the following:\nls /dev/cu.* \nIf your device does not show up, you may need a serial port driver for the board (refer to SEGGER J-Link here to set up).\nIf the light on your board is constantly blinking, then its not connected to your laptop. When connected, a green light pulsates on LED5 (see LED5 printed on the board).\nTo set up the embedded development IDE and connect to your device\nDownload and set up SEGGER Embedded Studio and choose the Embedded Studio for ARM option. With Nordic devices, you can obtain a free license here. This also installs JLink\xe2\x80\x94if it didn\xe2\x80\x99t install, you can install from here.\nOpen SEGGER and install the Nordic CPU supported package:\nFrom the top menu, select Tools, then select Package manager.\nSearch for \xe2\x80\x9cnRF CPU Support Package\xe2\x80\x9d and then install the package.\nOnce it\xe2\x80\x99s connected, open your operating system file manager (for Mac: Finder, for Windows: File Explorer) to check that the nRF52840-DK has appeared as a removable drive named \xe2\x80\x9cJLINK\xe2\x80\x9d. It will be same for all operating systems.\nNow, configure the terminal emulator settings for this. You will need your serial port details.\nRun the following command in the command line: ls /dev/cu.*\nThe following output should be shown:\nA device looks similar to: /dev/cu.usbmodem0006833844771. The device in this example is connected.\nNext, we will configure the SEGGER terminal emulator.\nFrom the top menu, select Tools.\nSelect Terminal Emulator, then select Properties.\nUpdate the settings as follows:\nBaud Rate: 115200\nData bits: 8\nParity: None\nPort: <selected output from above>\nStop Bits: 1\nNow connect to the device:\nFrom the top menu, select Tools.\nSelect Terminal Emulator, then select Connect <device port>.\n  Once the MCU is connected, you will see the device Connect port greyed out, as shown:\nTo set up FreeRTOS with BLE and an AWS IoT thing\nOpen a command line and clone the FreeRTOS repo. Use the following command:\ngit clone https://github.com/aws/amazon-freertos.git --recurse-submodules\nTo set up a BLE IoT thing for our Nordic board\nIn this section, we will set up the IoT thing (MCU board) in AWS IoT Core (cloud side), name it nrf52840BLE, and then register without a certificate. By now, you should have already set up \xe2\x80\x9c iOS SDK for FreeRTOS Bluetooth devices.\xe2\x80\x9d For Android, follow the steps here. Now, let\xe2\x80\x99s go ahead and set up the cloud side and create your AWS IoT thing.\nCreate a thing\nOpen the AWS IoT console.\nIn the navigation pane, select Manage, then select Things.\nSelect Create things, then select Create single thing and give it a name: nrf52840BLE. (Leave the rest of the settings as default.)\nIn the Device Certificate section, select Skip creating a certificate at this time.\nNow that the thing is created, let\xe2\x80\x99s find its endpoint:\nIn the navigation pane, select Manage, then select Things.\nIn the search bar, search for nrf52840BLE, then choose nrf52840BLE.\nFrom the navigation pane, select Interact, and note the endpoint as shown in the following screenshot:\nNext, we need to create Amazon Cognito identities. To do that, we will need to create an Amazon Cognito user pool and ID pool.\nTo create an Amazon Cognito user pool: Create a user pool\nOpen the Amazon Cognito console, choose Manage user pools, then Create a user pool.\nGive pool name: nrfdemo.\nFrom navigation pane, choose App Clients, then Add an app client, and give it a name: nrfappclient.\nFrom navigation pane, choose Review defaults, choose Create pool.\nFrom the navigation pane, under General settings, note down Pool id (as shown in the following image).\nFrom the navigation pane, select App Clients and then select Show details. Make note of the App client id and the App client secret.\nTo create an Amazon Cognito identity pool: create an ID pool\nIn the Amazon Cognito console, choose Manage Identity Pools, select Create new identity pool.\nIn Identity pool name give name nrfdemoidpool.\nExpand Authentication providers, choose the Cognito tab, and then enter your user pool ID and app client ID.\nSelect Create Pool.\nExpand View Details, and make a note of the two IAM role names (see the following screenshot), Choose Allow to create the IAM roles for authenticated and unauthenticated identities to\naccess Amazon Cognito.\nSelect Edit identity pool. Make a note of the identity pool ID \xe2\x80\x93 e.g., eu-central-1:1abcde01-1a0b-1ab6-a12b-ab1abc12a123\nMake note of the IAM roles.\nTo create and attach an IAM policy to the authenticated identity \xe2\x80\x93 IAM policy to enable Amazon Cognito ID to connect to AWS Cloud\nOpen the IAM console, and from the navigation pane, choose Roles.\nFind and choose your authenticated identity\xe2\x80\x99s role,\nFind those roles in the IAM created in previous step (mine were: Cognito_nrfdemoidpoolAuth_Role and Cognito_nrfdemoidpoolUnauth_Role).\nChoose Attach policies, and then choose Add inline policy.\nChoose the JSON tab, and paste the following JSON code.\n{\n""Version"":""2012-10-17"",\n""Statement"":[\n{\n""Effect"":""Allow"",\n""Action"":[\n""iot:AttachPolicy"",\n""iot:AttachPrincipalPolicy"",\n""iot:Connect"",\n""iot:Publish"",\n""iot:Subscribe"",\n""iot:Receive"",\n""iot:GetThingShadow"",\n""iot:UpdateThingShadow"",\n""iot:DeleteThingShadow""\n],\n""Resource"":[\n""*""\n]\n}\n]\n}\nJavaScript\nGive the policy name: IAMnrfPolicy.\nSelect Create Policy.\nAt this point, we have set up an IoT thing for our MCU and connectivity credentials, which we will use to authenticate in the mobile app when MCU establishes the BLE connection. Make sure to keep your AWS IoT and Amazon Cognito information on hand. You need the endpoint URL and IDs (created in the previous steps) to authenticate your mobile application with the AWS Cloud.\nSet up your FreeRTOS environment for BLE\nTo set up a FreeRTOS BLE Mobile SDK demo application\nDownload the relevant SDK (I will use instructions for iOS.):\nFor iOS, clone the repo and set up the pod per the instructions here.\nFor Android, clone the repo and follow the instructions here.\nOnce you have cloned the repo and set up the pod using cocoapods, add the following in the Podfile which exists under [amazon-freertos-ble-ios-sdk/Example/AmazonFreeRTOSDemo/Podfile]:\npod \'AmazonFreeRTOS\', :git => \'https://github.com/aws/amazon-freertos-ble-ios-sdk.git\', :tag => \'1.2.0\'\nNote: In Xcode, if you get following files for pod showing up as red, as seen in the following screenshot, then run the following command in your workspace directory:\npod install\nThis will install all the dependencies for you.\nClose Xcode, re-open the project, and clean build.\nFinally let\xe2\x80\x99s create an IoT policy on AWS IoT for this. (If you no longer want to continue with this demo solution after you complete the steps, make sure to delete the policy later.)\nOpen the AWS IoT console.\nIn the navigation pane, select Secure.\nIn Secure, select Policies.\nChoose Create.\nGive the poolicy a name: nrfdemopolicy\nIn Action, type in iot:*\nIn Resource ARN, type in *\nSelect Allow in Effect section.\nComplete by selecting Create.\nModify iOS Mobile app using Xcode\nTo configure SWIFT code\nWe will need to modify our iOS mobile app in swift code to let it know which region and which IoT policy to use and which MQTT topic to send the data over to.\nOpen Xcode, then open the following file. We will modify constants as in the following screenshot.\namazon-freertos-ble-ios-sdk/Example/AmazonFreeRTOSDemo/AmazonFreeRTOSDemo/Amazon/AmazonConstants.swift\nOther regions such as: EUWest1, EUWest2, EUWest3, EUNorth1, EUSouth1 are also available these can be found in: AWSServiceEnum.h file select the region relevant to you. As shown, I\xe2\x80\x99m using Frankfurt region (EU-Central-1).\nModify the json file which will use the relevant AWS Cognito UserPool and IdPool we created earlier.\namazon-freertos-ble-ios-sdk/Example/AmazonFreeRTOSDemo/AmazonFreeRTOSDemo/Support/awsconfiguration.json\nNow we can proceed to build the project. (Make sure you are using your own code signing credentials and not Amazon-provided defaults, as this will fail to build).\nIn Xcode top menu, select Product.\nChoose Clean Build folder, then Build.\nOnce the build completes, select Product, and choose Run.\nThis will deploy the app your to iOS device and will code sign to run it on the device.\nSelect Create account. This will send code to the email you requested and confirm.\nBy using following these instructions you have completed the mobile app development, deployment, and its build. So, now the iOS BLE mobile app is completed, let\xe2\x80\x99s deploy the FreeRTOS BLE Demo app to MCU.\nTo deploy FreeRTOS demo BLE code to the MCU\nSwitching back to the MCU, you will need to set up instructions using details here. Earlier we already had connected to the MCU using SEGGER embedded studio\xe2\x80\x94now, let\xe2\x80\x99s deploy FreeRTOS and demo code to connect to the mobile app to send data to AWS IoT Core.\nFor FreeRTOS release, we are using release of 05/26/2021.\nTo configure the project\nIn this \xe2\x80\x9cGetting started with the Nordic nRF52840-DK\xe2\x80\x9d tutorial, when you get to the \xe2\x80\x9cConfigure your project section\xe2\x80\x9d, note down your AWS IoT endpoint and modify #define constant code in following file:\naws_clientcredential.h\nUpdate the endpoint and thing name as seen in the following screenshot:\nCheck that the BLE GATT Demo is enabled under amazon-freertos folder. To do this, go to vendors/nordic/boards/nrf52840-dk/aws_demos/config_files/iot_ble_config.h, and add #define IOT_BLE_ADD_CUSTOM_SERVICES ( 1 ) to the list of define statements.\nIncrease Bluetooth pairing timeout for the mobile app since you will be paring the device with your phone. To pair the MCU with mobile client you will be required to enter y\xe2\x80\x99 to accept the pairing. To ensure timeout doesn\xe2\x80\x99t occur, let\xe2\x80\x99s increase the timeout in the following file: iot_ble_config.h\nUpdate the following line to 60 seconds: #define IOT_BLE_NUMERIC_COMPARISON_TIMEOUT_SEC ( 60 )\nSave the file.\nTo Build and run the project FOR MCU in SEGGER\nIf this is the first time that you are running the demo on this board, you need to flash a bootloader to the board before the demo can run. Run the following: FreeRTOS Folder / projects/nordic/nrf52840-dk/ses/aws_demos/bootloader/bootloader.emProject\nWhen you get the following prompt, select O.K.\nTo build the demo BLE app for MCU\nOpen following FreeRTOS project in SEGGER Embedded Studio: FreeRTOS Folder/projects/nordic/nrf52840-dk/ses/aws_demos/aws_demos.emProject\nModify the following file (application_code/common_demos/ble/mqtt_ble/mqtt_demo_ble_transport.c) string to a different message than \xe2\x80\x9chello world.\xe2\x80\x9d I will use following test (feel free to use what you prefer): ""Hello BLE message from Nordic nRF52840-DK MCU""\nSave the project, right click and build the project (as shown in the previous screenshot).\nOnce built, select Target > Connect J-Link, and then choose Debug, Go.\nOnce the build is done, go to Target and Connect J-Link.\nWhen complete, open the FreeRTOS app on your iOS device.\nYou will see the nRF MCU will show up on the devices. Select your device and then select Pair.\nOnce you select Pair on your mobile device, enter \xe2\x80\x98y\xe2\x80\x99 on the serial terminal emulator (computer) for the MCU to be accepted with the pairing.\nFor MacOS / Linux: screen /dev/cu.usbmodem0006837380271 115200\nFor Windows (using TeraTerm): In the Terminal Press \xe2\x80\x98y\xe2\x80\x99 on the screen confirm Bluetooth pairing.\nOptional: To exit the screen app, press CTRL+A and K and press y to exit the screen app.\nTo see messages coming into AWS IoT Core\nOpen the AWS IoT console.\nIn the navigation pane, select Test.\nIn Subscribe to a topic, enter \xe2\x80\x98#\xe2\x80\x98 to capture all topics.\nChoose Subscribe.\nYou will see messages appearing in the AWS IoT console. Congratulations, you have connected your Nordics MCU using FreeRTOS BLE from MCU and using FreeRTOS iOS mobile app to act as MQTT Proxy to send data to AWS IoT Core.\nTo enable the custom BLE GATT server demo\nNow that we have completed MQTT over BLE to AWS IoT Core, let\xe2\x80\x99s do the test using Custom BLE MQTT GATT to send data to AWS IoT Core using GATT setup:\nFirst we will modify the following header file to make sure Custom BLE GATT server demo is enabled for Mobile iOS client application.\nOpen following file: FreeRTOS /vendors/nordic/boards/nrf52840-dk/aws_demos/config_files/aws_demo_config.h\nComment out \xe2\x80\x93 #define CONFIG_MQTT_BLE_TRANSPORT_DEMO_ENABLED\nAdd following #define CONFIG_BLE_GATT_SERVER_DEMO_ENABLED.\nOnce changes are done you will see the code as seen in the following screenshot:\nSave the project.\nRight-click, choose Clean, then Build.\nOnce the build is done, navigate to Debug, and choose Go.\nOn the iOS mobile app side, open the FreeRTOS app.\nSelect the MCU. When you get following option, choose Start Counter:\nFinally, to see data coming into AWS IoT Core:\nOpen the AWS IoT console.\nIn the navigation pane, select Test.\nIn Subscribe to a topic, type in \xe2\x80\x9c#\xe2\x80\x9d to capture all topics, as shown in the following screenshot.\nChoose Subscribe.\nCleaning up\nIf you followed along with this solution, complete the following steps to avoid incurring unwanted charges to your AWS account.\nAWS IoT Core\nIn the Manage section, delete the Thing (nrf52840BLE)\nIn the Secure section, remove the Policy (nrfdemopolicy)\nAmazon cognito\nDelete the User pool (nrfdemo)\nDelete the Identity pool (nrfdemoidpool)\nAWS IAM\nDelete the roles:\nCognito_nrfdemoidpoolAuth_Role\nCognito_nrfdemoidpoolUnauth_Role\nDelete IAM Policy (IAMnrfPolicy)\n'"
120,Securely ingesting large-sized payloads from IoT devices to the AWS Cloud,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/08/20/AWS-IoT-Blog_V2.jpg,https://aws.amazon.com/blogs/iot/securely-ingesting-large-sized-payloads-from-iot-devices-to-the-aws-cloud/,"b'AWS IoT Core lets you securely ingest payloads from IoT devices to the AWS Cloud at a large scale\xe2\x80\x94supporting billions of devices and trillions of messages. It also lets you process the messages and manage the devices from the cloud reliably and securely. One challenge you may have faced while designing your solution with AWS IoT Core is that there is a hard limit on maximum permissible size of MQTT payload. At the time of writing the blog, the maximum MQTT payload which AWS IoT Core can support is only 128KB (be sure to check here for the latest information). The AWS IoT service rejects publish and connect requests larger than this size. Some common IoT use cases with large-sized payload could include:\nIngesting medical images to the cloud.\nRecording and transmitting heart or lung sounds from medical devices.\nTransmitting sound file to detect car accidents in a smart city.\nTaking and transmitting images with license plate when traffic rules are violated.\nIngesting binary files generated from industrial machines to the cloud.\nIn this blog post, I explain a pattern which addresses the problem of ingesting large-sized IoT payloads in a scalable way. This is particularly applicable to constrained devices without edge capabilities, and devices which have enough memory to store one or more payloads depending on the use case before they are ingested to cloud.\nAdditionally, I explain how security is implemented by design. This is critical because of the following risks:\nIoT ecosystems can have large attack surfaces since the devices are dependent on internet-supported connectivity.\nDevice fleets can grow rapidly; hence it becomes more important that security is implemented by design in the complete development lifecycle. Retrofitting security design in a later stage adds more complexity by introducing architectural or design changes.\nSolution overview\nTo address the challenge of hard limits on MQTT payload size, you can use Amazon Simple Storage Service (Amazon S3) to store the payload using HTTPS as a secondary protocol, while still using the features of AWS IoT Core such as device shadows, registry, and rules engine for rest of the requirements. Amazon S3 is a reliable & cost-effective service to store the large objects.\nIt is best practice to keep Amazon S3 buckets private, secure, and follow the principle of least privileges. One of the recommended mechanisms for any entity to interact with a private S3 bucket is by using a pre-signed URL, which in this case is generated on request for each device by a cloud-side Lambda function. A pre-signed URL is a URL that grants temporary access to a specific S3 object without requiring AWS security credentials or permissions for a specific time period and then it expires. Using the URL, you can either READ the object or WRITE an Object. If you are new to AWS S3 pre-signed URL, please read Using pre-signed URLs and Uploading objects using pre-signed URLs.\nOnce the file is ingested, the next step is to act on the data. Unlike AWS IoT Core, there is no rule engine associated with S3 buckets. You can use Amazon S3 Event Notifications to receive notifications whenever a PUT event is triggered in your S3 bucket. Amazon S3 supports the following destinations where it can publish events:\nAWS Lambda\nAmazon Simple Notification Service (Amazon SNS)\nAmazon Simple Queue Service (Amazon SQS)\nIn this solution, I use AWS Lambda to act on the payload but based on your use case you can use other two destinations as well to publish events. For more details, please read Amazon S3 Event Notifications.\nTo push the payload to AWS, the device performs the following steps:\nTo connect with the AWS Cloud, the IoT device requests access to AWS IoT Core by authenticating itself using X.509 certificates.\nThe IoT device sends a request to a topic to generate a pre-signed URL.\nRules engine invokes a Lambda function to generate a pre-signed URL for a specific period.\nThe Lambda function publishes the pre-signed URL to a device specific topic.\nThe IoT device receives the URL and uploads the payload to an S3 bucket using HTTPS POST.\nS3 sends an event to the Lambda function to start processing when the file is uploaded.\nAnother variant of this approach is to use device shadows to communicate pre-signed URL from cloud to device as in Step 4. In IoT applications, command topics are used to control a device remotely and to acknowledge successful command executions. For best practices, please read Using the AWS IoT shadow for commands.\nNote that the solution outlined in this blog is not the only way to ingest large-sized payloads from IoT devices to the cloud. Here are a couple alternatives, which in some instances may be suitable; however, we will not be diving deep into them:\nChunking the message: In this solution, a large payload is split into smaller chunks on the device side and published using MQTT. The subscriber of the the topic owns additional responsibility to collect the chunks, reorder and reassemble the message which adds incremental steps to the solution. A challenge with this approach is that it is error prone and can increase cost since customers are charged by the number of messages transmitted between devices and AWS IoT Core.\nREST server: REST APIs provide flexibility & scalability; however, REST by design requires a connection to be made with each request. This introduces latency, and increases IO and power consumption. In addition to that, REST server requires network connectivity to serve the request. If your constrained devices are required to ingest data frequently at a low latency, or if connectivity may be intermittent, the REST server method may be unsuitable.\nI\xe2\x80\x99ll now explain how the solution explained above lets you accomplish security by design.\nAuthentication\nA strong IoT device authentication mechanism is required so that only trusted devices access the cloud. Using a strong authentication mechanism helps prevent device spoofing or hackers gaining access to the cloud.\nTypically, each device will have a unique X.509 certificate. These certificates provide AWS IoT with the ability to authenticate device connections. To enable devices access to your private Amazon S3 data, you can authenticate POST requests by generating a pre-signed URL.\nAuthorization\nAuthorization is the process of granting appropriate permissions to an authenticated device. Only an authorized device gets access to presigned URL as this URL grant access to an S3 bucket where the payload is persisted. It is important that we configure the presigned URL expiry time carefully considering device upload bandwidth and abilities. Once received, these URLS cannot be revoked or timed out.\nUsing AWS IoT Core, you can associate the required permissions (IoT policies) to each certificate associated with authorized devices to securely connect and operate with AWS. Using policy-based authorization, principle of least privileges approach is followed and every device gets access to only specific topics intended for that device. This ensures URL is not accessed by any unauthorized entities.\nEnd to end encryption\nIn the solution previously mentioned, there are two channels for communication. MQTT is used to request and receive pre-signed URL, and HTTPS is used to upload the payload on S3.\nBy default, AWS IoT data is encrypted both at rest and in transit. The message broker encrypts all communication while in-transit by using TLS version 1.2.. Data at rest is encrypted using AWS-owned keys.\nTo upload the payload on S3, HTTPS encrypts data in transit and helps prevent unauthorized users from eavesdropping on or manipulating network traffic. To encrypt S3 data at rest, you can use either Server-side Encryption (SSE) or client-side encryption. For more S3-related security best practices please read Security Best Practices for Amazon S3.\n'"
121,Build your pool water temperature monitoring solution with AWS,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/08/11/history-complete.png,https://aws.amazon.com/blogs/iot/build-your-pool-water-temperature-monitoring-solution-with-aws/,"b'I live in Toulouse, in the south of France, where the climate is classified as humid subtropical climate (Cfa in the K\xc3\xb6ppen climate classification). This is why swimming pools are so common here! My household is no exception. But as a geek, I also wanted to monitor the temperature of my swimming pool, consult real-time indicators, and view history.\nLet\xe2\x80\x99s have a deep dive (pun intended) together: in this blog post, I demonstrate how to put AWS services together to cost-effectively build a water temperature monitoring solution. By following this demo, you will learn useful tools not just for building your own water temperature monitoring solution, but other creative monitoring solutions as well.\nPrerequisites\nI had a M5StickC with an NCIR hat, and an AWS account with AWS IoT Core, Amazon Timestream and Amazon Managed Service for Grafana (Preview), which covered everything I needed to get started!\nComponents overview\nM5StickC is a mini M5Stack, powered by ESP32. It is a portable, easy-to-use, open source, IoT development board. M5stickC is one of the core devices in the M5Stack product series. It is built in a continuously growing hardware and software ecosystem. It has many compatible modules and units, as well as the open source and engineering communities that will help maximize your benefits at every step of the development process.\nNCIR hat is an M5StickC-compatible infrared sensor. This HAT module integrates MLX90614 which can be used to measure the surface temperature of a human body or other object. Since this sensor measures infrared light bouncing off of remote objects, it senses temperature without the need for physical contact.\nAWS IoT Core lets you connect IoT devices to AWS without the need to provision or manage servers. AWS IoT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they aren\xe2\x80\x99t connected.\nAmazon Timestream is a fast, scalable, and serverless time series database service for IoT and operational applications that makes it easy to store and analyze trillions of events per day up to 1,000 times faster and at as little as 1/10th the cost of relational databases.\nAmazon Managed Service for Grafana (AMG) is a fully managed service that is developed together with Grafana Labs and based on open source Grafana. Enhanced with enterprise capabilities, AMG makes it easy for you to visualize and analyze your operational data at scale. Grafana is a popular open source analytics platform that enables you to query, visualize, alert on and understand your metrics no matter where they are stored.\nHigh-level architecture\nThe following diagram shows the flow of information, starting from the M5stickC, through AWS IoT Core and then Timestream, to the end users viewing the dashboard in AMG.\nAWS IoT Core setup\nWe will start with the following steps:\nPolicy creation\nThing creation, including:\nCertificate creation\nPolicy attachment\nTo create a policy\nAn AWS IoT Core policy allows you to control access to AWS IoT Core operations that allow you to connect to the AWS IoT Core message bus as well as send and receive MQTT messages.\nOpen the AWS Management Console of your AWS account.\nNavigate to the AWS IoT Core service, then open Secure > Policies section.\nSelect Create.\nEnter the following values:\nName: TempCheckerPolicy\nStatements > Advanced\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:<region>:<account-id>:topic/TempCheckerTopic""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:<region>:<account-id>:topicfilter/TempCheckerTopic""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""*""\n    }\n  ]\n}\nJSON\nSelect Create.\nTo create a thing\nIn the AWS Management Console, open AWS IoT Core.\nIn the Manage > Things section, select Create.\nSelect Create a single thing.\nCreate a thing type with the following information:\nName: M5Stick\nDescription: An M5StickC with NCIR hat.\nSelect Create thing type.\nOn the next page, fill in the thing creation form with the following:\nName: TempChecker\nThing type: select M5Stick\nSelect Next.\nTo add a certificate for your thing and attach a policy\nIn the \xe2\x80\x9cOne-click certificate creation (recommended)\xe2\x80\x9d panel, select Create certificate.\n\nThe certificate is immediately created.\nDownload the certificate, along with public and private keys.\nSelect Attach a policy.\n\nSelect the TempCheckerPolicy policy, then select Register Thing.\nM5Stick setup\nNow that AWS IoT Core is ready to receive IoT (MQTT) messages, let\xe2\x80\x99s take care of the thing itself.\nThe M5Stick supports multiple development platforms: UIFlow, Arduino, and FreeRTOS. In this use case, I used UIFlow visual programming capabilities (using Blockly+Python) along with its AWS IoT built-in library to easily build and deploy my business logic.\nNote: You can find more information here about how to install UIFlow IDE and how to \xe2\x80\x9cburn\xe2\x80\x9d UIFlow firmware on the M5StickC.\nWe need to build and deploy a program on the M5Stick that will run continuously. It contains all the necessary instructions to take the temperature sensor data and send it to AWS IoT Core. The algorithm is simple:\nInitiate the communication with AWS IoT Core.\nInitialize the M5StickC internal clock with NTP.\nStart a loop that repeats every second with the following:\nGet the temperature from the NCIR hat.\nPublish a JSON-formatted message containing the temperature and the current timestamp.\nI added a visual indication of the temperature on the LCD screen, as well as LED signals with publishing MQTT messages.\nAs Werner Vogels, AWS CTO, says, \xe2\x80\x9ceverything fails all the time\xe2\x80\x9d, so to reduce errors, I added try-catch components to debug and recover from errors.\nIn the AWS IoT block, use the private key and certificate files you just downloaded to set the keyFile and certFile values.\nUIFlow translates the blocks into micropython.\nfrom m5stack import *\nfrom m5ui import *\nfrom uiflow import *\nfrom IoTcloud.AWS import AWS\nimport ntptime\nimport hat\nimport json\nimport time\nimport hat\n\nsetScreenColor(0x111111)\nhat_ncir5 = hat.get(hat.NCIR)\niterator = None\ntemperature = None\nlabel0 = M5TextBox(5, 72, ""1"", lcd.FONT_Default, 0xFFFFFF, rotate=0)\n\nfrom numbers import Number\n\ntry :\n  aws = AWS(things_name=\'TempChecker\', host=\'<endpoint>.iot.eu-west-1.amazonaws.com\', port=8883, keepalive=300, cert_file_path=""/flash/res/c47c10a25d-certificate.pem"", private_key_path=\'\')\n  aws.start()\n  try :\n    ntp = ntptime.client(host=\'pool.ntp.org\', timezone=2)\n    iterator = 1\n    while True:\n      temperature = hat_ncir5.temperature\n      M5Led.on()\n      try :\n        aws.publish(str(\'TempCheckerTopic\'),str((json.dumps(({\'Temperature\':temperature,\'Iterator\':iterator,\'Timestamp\':(ntp.getTimestamp())})))))\n        iterator = (iterator if isinstance(iterator, Number) else 0) + 1\n        label0.setText(str(temperature))\n        pass\n      except:\n        label0.setColor(0xff0000)\n        label0.setText(\'IoT error\')\n      M5Led.off()\n      wait(1)\n    pass\n  except:\n    label0.setColor(0xff0000)\n    label0.setText(\'NTP error\')\n  pass\nexcept:\n  label0.setColor(0xff0000)\n  label0.setText(\'AWS error\')\nPython\nAmazon Timestream setup\nNow we configure the storage for our temperature data. Amazon offers the broadest selection of purpose-built databases to support different use cases. In this case, the right tool for the right job is Timestream.\nOur use case is clearly related to time series data. Timestream is the dedicated service to manipulate this type of data using SQL, with built-in time series functions for smoothing, approximation, and interpolation. Amazon Timestream also supports advanced aggregates, window functions, and complex data types such as arrays and rows. And Amazon Timestream is serverless \xe2\x80\x93 there are no servers to manage and no capacity to provision. More information in the documentation.\nTo create a database in Timestream\nOpen Timestream in the AWS Management Console.\nSelect Create database.\nEnter the following information:\nConfiguration: Standard database\nName: TempCheckerDatabase\nEncryption: aws/timestream\nConfirm by selecting Create database.\nTo create a table\nOn the next page, we create our table.\nSelect your newly created database, open the Tables tab, and select Create table.\nSet the following values:\nTable name: Temperature\nData retention:\nMemory: 1 day\nMagnetic: 1 year\nAWS IoT Core destination setup\nOur storage is ready to receive data from AWS IoT Core.\nLet\xe2\x80\x99s configure the IoT rule that triggers when our M5StickC sends data. This will run the action to insert data into Timestream.\nOpen AWS IoT Core in the AWS Management Console.\nIn the Act > Rules section, select Create, and then enter the following:\nName: TempCheckerRule\nDescription: Rule to handle temperature messages\nRule query statement: SELECT Temperature FROM \'TempCheckerTopic\'\nIn the \xe2\x80\x9cSet one or more actions\xe2\x80\x9d panel, select Add action. Select Write a message into a Timestream table, then Configure action.\nSelect the Timestream database and table we just created. Add the following dimension:\nDimension Name: Device\nDimension Value: M5stick\nNext, we need to create an AWS IAM role to allow the service to access the database. Select Create role, and then enter the following:\nName: TempCheckerDatabaseRole\nReview your selections, and then confirm the action by selecting Add action.\nIn the \xe2\x80\x9cError action\xe2\x80\x9d panel, select Add action. Select Send message data to CloudWatch logs, select Configure action.\nSelect Create a new resource to be redirected to Cloudwatch.\nCreate a log group named TempCheckerRuleErrors.\nIn the action configuration wizard, refresh the resources list and select the newly created log group.\nWe need to create an AWS IAM role to allow the service to access Cloudwatch. Select Create role, then enter the following name:\nName: TempCheckerCloudwatchRole\nConfirm the action by selecting Add action.\nConfirm the rule creation by selecting Create rule.\nWe now have a valid rule that feeds the Timestream database with the temperature data sent by the M5StickC.\nAmazon Managed Service for Grafana setup\nNext, let\xe2\x80\x99s visualize this data.\nNote: At the time of writing, AMG is still in preview.\nOpen the AMG console, then choose Create workspace and enter the following:\nWorkspace name: TempCheckerWorkspace\nChoose Next.\n\nYou are prompted to enable AWS Single Sign-On (SSO) before you can begin managing it. If you have already performed these actions in your AWS account, you can skip this step.\n\nAMG integrates with AWS SSO so that you can easily assign users and groups from your existing user directory such as Active Directory, LDAP, or Okta within the Grafana workspace and single sign-on using your existing user ID and password. You can find more information in this blog post.\nSelect Create user.\nEnter your email address, along with your first and last name, then confirm by selecting Create user.\n\nThe AWS Organization and AWS SSO should be enabled in seconds. You will receive a few emails in parallel: one for AWS Organization setup validation, and one for for AWS SSO setup validation. Remember to check them out and complete the validation steps.\nFor permission type, use the default Service managed permissions, allowing AWS to manage IAM roles. This ensures that evolutions in AMG that require updates in IAM will be automatically propagated and service will not be interrupted. Select Next.\nBecause I built this for a personal project, I can use \xe2\x80\x9cCurrent account\xe2\x80\x9d to manage the authorizations in this AWS account. Complex organizations will want to leverage their AWS Organization Units.\nTo allow our workspace to access Timestream data source, select Amazon TimeStream, then select Next.\n\nA warning panel should appear, stating \xe2\x80\x9cyou must assign user(s) or user group(s) before they can access Grafana console.\xe2\x80\x9d To assign users, use the following steps:\nSelect Assign user.\nSelect the user you just created and confirm by selecting Assign user.\nOnce the Grafana workspace is created, the link will be provided on this page.\nTo configure a Grafana dashboard\nLog in with AWS SSO.\nOn the welcome page, navigate to Create > Dashboard.\nIn Grafana, each dashboard contains one or more panels. The panel is the basic visualization building block. With the exception of a few special purpose panels, a panel is a visual representation of data over time. This can range from temperature fluctuations to the current server status to a list of logs or alerts. There are a wide variety of style and formatting options for each panel. Panels can be moved, rearranged, and resized.\nWe start by adding a panel for the real-time temperature display. For this, a gauge will give us a quick and colorful overview.\nTo configure a temperature gauge panel\nAdd a new panel and select Amazon Timestream as data source.\nEnter the following query to retrieve the latest temperature value inserted in the database:\nSELECT measure_value::double AS temperature\nFROM ""TempCheckerDatabase"".Temperature\nORDER BY time DESC\nLIMIT 1\nSQL\nOn the right, in Panel configuration, set the panel name to \xe2\x80\x9cReal time monitoring\xe2\x80\x9d and select the Gauge visualization.\nIn the Field configuration, set the Min and Max options, as well as the relevant thresholds. I chose a progressive rainbow from blue to red as the temperature is expected to increase.\n\nSelect Save, and you will see your gauge.\nTo configure a temperature history panel\nThe second panel is a temperature history panel which will retrieve the historical data, filtered by the period selected by the user in Grafana.\nAdd a panel and select Amazon Timestream as data source.\nEnter the following statement in order to query the database with the relevant filters:\nSELECT ROUND(AVG(measure_value::double), 2) AS avg_temperature, BIN(time, $__interval_ms) AS binned_timestamp\nFROM ""TempCheckerDatabase"".Temperature\nWHERE $__timeFilter\nAND measure_value::double < 100\nAND measure_value::double > 20\nGROUP BY BIN(time, $__interval_ms)\nORDER BY BIN(time, $__interval_ms)\nSQL\nOn the right, in Panel configuration, set the Panel title to Trend and select the Graph visualization.\nSelect Apply to finalize the second panel.\nNow we have created two panels in our Grafana dashboard: one that displays current temperature on a gauge and one that shows historical temperature on a graph.\nPricing\nTo understand the cost of this project using AWS\xe2\x80\x99s pay-as-you-go services, we will use the following assumptions:\nThe M5StickC is connected permanently to send 1 message per second.\nEvery IoT message is written to the time series database, for around 40 bytes each.\n1 Grafana Editor license active, as I am the only user of my personal dashboard.\nCost breakdown\n(Note: Please check following pricing pages to ensure the current pricing)\nAWS IoT Core costs $3.42/month for the connectivity, messaging, and rules engine.\nAmazon Timestream, after 1 year of data stored, will cost $1.64/month for the storage and queries.\nAmazon Managed Service for Grafana is billed $9.00/month for every editor license.\nTotal cost\nThe total monthly cost for our complete solution is $3.42 + $1.64 + $9.00 = $14.06/month\nCleaning up\nIf you followed along with this solution, complete the following steps to avoid incurring unwanted charges to your AWS account.\nAWS IoT Core\nIn the Manage section, delete the Thing and Thing type.\nIn the Secure section, remove the Policy and Certificate.\nIn the Act section, clean up the Rule.\nAmazon Timestream\nDelete the database, this will also delete the table.\nAmazon Managed Service for Grafana\nDelete the whole workspace.\nAWS IAM\nDelete the roles created along the way.\nAmazon CloudWatch\nDelete the relevant Log groups.\n'"
122,Design IoT jobs for rapid large scale device updates with advanced device group target patterns,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/08/11/jobsatscalediagram.png,https://aws.amazon.com/blogs/iot/design-iot-jobs-for-rapid-large-scale-device-updates-with-advanced-device-group-target-patterns/,"b'Customer IoT applications require rapid over the air (OTA) updates to maintain the state of their IoT things. This becomes increasingly important as IoT fleets grow. Jobs for AWS IoT Device Management is a feature to push updates to targeted edge devices. Each job targets devices in static or dynamic AWS IoT thing groups. Static thing groups include a set of specified IoT things while dynamic thing groups contain things that match a specified query and automatically update if things are added that match this query. This blog provides design patterns to help customers achieve updates at the fastest possible rate of devices per minute (Thing Targets that Pre-exist AWS IoT Registry Entry and Target Priming), which is required for large scale rapid deployments. This blog also describes design patterns to target devices that cannot be modeled using a single thing group (e.g., cannot be described using a simple query) by creating an Include List or a Query with Exclude List.\nSolution walkthrough\nThis solution (Github repo) provides strategies to roll out jobs at the maximum account level rate even as the job target thing groups are being populated. The challenges that this solution helps customers overcome include job rollout rate limitations due to:\nAWS service limits from API calls required to populate the job targets\nAPI throttling from exceeding service limits that results in exponential back-off\nTime required to populate new AWS IoT static and dynamic thing groups\nAWS IoT things that cannot be targeted using a fleet index query\nAWS account level service limits\nThe AWS IoT Core and AWS IoT Device Management service limits that govern the maximum rate of job updates that can occur (devices/min) include:\nMaximumJobExecutionsPerMinute: The direct job rate limit\nUpdateThingShadow: Used for select advanced job target patterns described in later sections\nAddThingToThingGroup: Used for select advanced job target patterns described in later sections\nEach of these limits can be increased with a service request to increase the overall job rate.\nThing targets that pre-exist AWS IoT registry entry\nThere are scenarios where a device manufacturer or device provisioner has information about the device before it is registered in AWS IoT as a thing. For this use case, a continuous job can be created before the thing exists in the cloud. If the target is a dynamic group, the job will be queued at the time the thing is registered as long as the thing is selected by the group query. If the target is a static group, the thing will need to be manually added to the group when registered using the AddThingToThingGroup API. This manual addition process is described in more detail in the following Include List and Query with Exclude List sections.\nTarget priming\nA job queues devices that are available in the target thing group at the selected job execution rate (i.e., maximum value is MaximumJobExecutionsPerMinute). This means that the job execution rollout rate is the lesser of two rates (1) the rate at which devices are added to the thing group (not desirable), and (2) the job executions rollout configuration parameter. Target priming is the process of populating the target groups with devices at a rate that is faster than the MaximumJobExecutionsPerMinute to maximize the rollout rate of job Executions for a given job.\nFor use cases when there is time available to populate thing groups before a job, static or dynamic thing groups can be fully populated before creating the snapshot job. For example, this priming technique can be used if the things that need to be targeted are in the thing registry and are known well in advance of the time when the update needs to occur. Keep in mind that the process of adding things to a static group is rate limited by the AddThingToThingGroup API calls and the process of adding things to a dynamic group is rate limited by the time required for Fleet Indexing for AWS IoT Device Management service to populate the group.\nWhen time constraints do not allow for fully populating the target groups before creating a job, the following method should be used to populate the target group faster than the job execution rate. This method uses a dynamic group target with a query that selects a thing shadow attribute and requires updating each thing to have this shadow attribute. The process of first creating an empty dynamic thing group, and then updating the thing shadow adds the thing to the dynamic group within seconds, which is a significant rate increase compared to allowing the dynamic group to index the entire thing registry. Additionally, the UpdateThingShadow rate limit is higher than the MaximumJobExecutionsPerMinute rate. This means that the job roll out rate is determined by MaximumJobExecutionsPerMinute instead of the rate to populate the thing group and provides the maximum job rate. To use this method, you must enable fleet indexing for Thing Shadow.\nCreate dynamic group that selects thing shadow attribute and, if using a query, also include query. Sample query: shadow.reported.newVersion:1.1 && attributes.productId:widget123\nCreate continuous job that targets the dynamic group from 2a.\nUpdate the thing shadow of all things that will be targeted by the job (e.g., shadow.reported.newVersion=1.1).\nList: Perform UpdateThingShadow for all results in list.\nQuery: Use fleet index to perform query. Perform UpdateThingShadow for all results from query. Things that are added to the account after this process will be queued when the dynamic group has finished indexing all things in the account.\nUse cases\nThe Include List and Query with Exclude List design patterns in the following sections include generating and populating static thing groups from a list of things. Appropriate storage and compute resources should be allocated for processing large lists. These design patterns provide job roll out at the maximum rate (MaximumJobExecutionsPerMinute) even as the target groups are being populated. Bulk Registration can also be used to add a list of things to a thing group when time is not a constraint.\nInclude list\nThis use case applies when the target group of things are provided as a list that cannot be modeled using a query. With a list, additional considerations are required to target things that are on the list but are added to the account after job creation.\nIf all devices on the include list are in the account prior to job creation, use the methods from the Target Priming section.\nIf devices on the include list can be added to the thing registry after initial creation of the list, the following method can be used.\nUse the method in Target Priming section 2.\nStore the pre-registered include list provided by the manufacturer in a database (e.g., DynamoDB).\nTrigger lambda when new things are registered that checks if the thing is in the database and then adds thing shadow attribute to the thing if it is in the database list.\nQuery with exclude list\nThis use case applies when the target group of things are provided as a query with an additional list of things that need to be excluded such that the target cannot be modeled using the query alone. With an exclude list, additional considerations are required to avoid adding things that are on the exclude list and are added to the thing registry after job creation.\nIf all targeted devices are in the account prior to job creation.\nCreate a dynamic group that selects thing shadow attribute.\nCreate continuous job that targets the dynamic group from 1a.\nUpdate the thing shadow of all things that will be targeted by the job: Use fleet index to obtain devices from the query. Use the UpdateThingShadow API for all things obtained from the query that are not present on the exclude list.\nIf devices on the exclude list can be added to the thing registry after initial creation of the list, the following technique can be used.\nCreate a static group that will comprise of devices on the exclude list (in the future).\nCreate a dynamic group with a query that selects things with a thing shadow attribute and does not include the static group.\nSample query: shadow.reported.newVersion:2.0 && NOT thingGroupNames:excludeListA\nCreate continuous job that targets the dynamic group from 2b.\nUse the AddThingToThingGroup API to add all things on the exclude list to the static exclude thing group.\nUpdate the thing shadow of all things that will be targeted by the job: Use fleet index to obtain devices from the query. Use the UpdateThingShadow API for all things obtained from the query that are not present on the exclude list.\nStore the pre-registered exclude list provided by the manufacturer in a database (e.g., Amazon DynamoDB).\nTrigger an AWS Lambda function when new things are registered that checks if the thing is in the database and then adds the thing to the static thing group to exclude upon match.\nDesign pattern alternatives\nMultiple design patterns provided in this section include examples that use a dynamic IoT thing group with a query that selects things based on values from the thing shadow. Alternative patterns can be used such as having the dynamic group query select things based on values of thing attributes instead of thing shadow values.\nMetadata\nTime to read: 10 min\nTime to complete: 10 min\nCost to complete: < $1\nLearning level: Advanced (300)\nServices used: Amazon S3, AWS IoT Core, AWS IoT Device Management, AWS Lambda\nPrerequisites\nTo follow along, you will need an AWS account.\nDemo code walkthrough\nThis walkthrough demonstrates how to create a job that will nearly instantly start queueing AWS IoT things regardless of number of things. The target group includes things that are selected based on a fleet index query but removes a custom list of things that are provided as an exclude list. This pattern is used to demonstrate how to address scenarios when things cannot be modeled with a simple query.\nClone the Project Repo.\nComplete the project setup steps in the readme.md.\nInvoke Lambda function to seed account with IoT things.\nOpen the AWS Lambda console.\nSelect the seedThings Lambda function.\nInvoke the seedThings Lambda function with the event below to create 1,000 AWS IoT things with prefix myDemoThings.\n{\n""mode"": ""seed"",\n""demoThingPrefix"": ""myDemoThings"",\n""seedConfigNumber"": 1000\n}\nUpload sample csv file exclude list to S3.\nOpen the S3 console.\nSelect the iotJobsLists bucket.\nPress Upload to upload the sample list of things to exclude from a job that is provided in the project repo at sampleList/excludeMyDemoThings.csv.\nInvoke Lambda function to create job.\nOpen the Lambda console.\nSelect the job Lambda function.\nInvoke the job Lambda function with event below to create the job, a static group with things from the exclude list, a dynamic group that includes all things selected with the fleetIndexQuery minus the exclude list. Note: This Lambda function first enables AWS IoT registry and shadow indexing. The time to enable fleet indexing is dependent on the number of things in your account. If the enabling fleet index takes greater than 15 min, the Lambda function will timeout to avoid unnecessary compute. If the Lambda function times out, invoke the Lambda function again after fleet index is enabled. You can manually check the fleet index status by navigating to the AWS IoT settings tab.\n{\n""jobName"": ""myFirstJob"",\n""fleetIndexQuery"": ""myDemoThings*"",\n""excludeListFileName"": ""excludeMyDemoThings.csv""\n}\nCleaning up\nTo clean up your account so that you do not incur future charges:\nDelete S3 files.\nOpen the S3 console.\nSelect the iotJobsLists bucket.\nSelect all files in bucket (e.g., excludeMyDemoThings.csv).\nPress Delete to delete files.\nDelete cloud infrastructure created by AWS Amplify.\nOpen the AWS Amplify console.\nSelect the AWS Amplify App names iotjobsblog.\nChoose to delete.\nInvoke seedThings AWS Lambda function to delete IoT things.\nOpen the AWS Lambda console.\nSelect the seedThings Lambda function.\nInvoke the seedThings Lambda function with the event below to delete all things with the \xe2\x80\x9cmyDemoThings\xe2\x80\x9d prefix that were created for this walkthrough.\n{\n""mode"": ""delete"",\n""demoThingPrefix"": ""myDemoThings""\n}\nDelete IoT jobs.\na. Open the AWS IoT console.\nb. In the navigation pane, under Manage, choose Jobs.\nc. Select jobs created for this walkthrough (e.g., \xe2\x80\x9cmyFirstJob\xe2\x80\x9d).\nd. Choose to cancel job.\ne. Choose to delete job.\nDelete IoT thing groups.\na. Open the AWS IoT console.\nb. In the navigation pane, under Manage, choose Thing groups.\nc. Select thing groups created for this walkthrough (e.g., \xe2\x80\x9cmyFirstJob\xe2\x80\x9d and \xe2\x80\x9cmyFirstJob-exclude\xe2\x80\x9d).\nd. Choose to delete the AWS IoT Thing groups.\nUpdate fleet index configuration.\na. Open the AWS IoT console.\nb. In the navigation pane, choose Settings.\nc. Choose Manage Indexing.\nd. Update your fleet index configuration to the original state before completing the walkthrough and then press Update.\n'"
123,How a major manufacturer manages and monitors industrial devices and vehicles with AWS IoT,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/08/05/2021-08-05-%E4%B8%8B%E5%8D%882.27.11.jpg,https://aws.amazon.com/blogs/iot/how-a-major-manufacturer-manages-and-monitors-industrial-devices-and-vehicles-with-aws-iot/,"b'Introduction\nAt AWS, we help customers from all industries\xe2\x80\x94from home appliance producers to automakers\xe2\x80\x94effectively manage and monitor their devices at scale. In this blog, I describe a device distribution (selling and reselling) approach commonly used by business owners of IoT device management solutions called \xe2\x80\x9ctight coupling,\xe2\x80\x9d that the devices have to be customized produced and distributed to certain clients, highlight a few of its drawbacks, and introduce an alternative decoupled approach that unlocks device distribution. Then, I demonstrate how an AWS customer who manufactures industrial devices and vehicles uses the decoupled approach to more effectively manage and monitor vehicles with AWS IoT.\nWith a vehicle management and monitoring solution built on AWS, customers can quickly connect large fleets of devices, organize them into groups and control access based on group hierarchy, and quickly search for and find any device across their fleet in real time.\nTight coupling process and drawbacks\nToday, the way many device manufacturers and device management service providers distribute and resell devices is customized for each of their clients, even when device hardware and firmware are identical. This limits the device maker\xe2\x80\x99s flexibility of device distribution, increases the cost of device reselling, and subsequently can reduce their scope and ROI. Often, these challenges are caused by tight-coupling that the devices have to be customized produced and distributed to certain clients.\nIn tight-coupling process as below, we will consider a manufacturer of vehicles and devices with distributors and resellers that lease vehicles with GPS sensors and engine locks to the clients.\nFigure 1: Tight coupling process between devices and their distributors\n  First, let\xe2\x80\x99s introduce the three main roles in the tight-coupling process; each role can be users of the device management and monitoring solution outlined in this blog post.\nClients purchase or rent industrial vehicles with devices such as GPS and engine lock for their own business such as mining and construction. A client might have multiple end users like vehicle drivers and operators of vehicle fleet monitoring and management.\nDistributors and resellers place purchase orders from clients to manufacturers. They collect client-specific information, such as client name and list of sensors connected to client\xe2\x80\x99s device, and ask manufacturers to burn the information into the devices (write the information into firmware of the devices).\nManufacturers produce industrial vehicles and devices, and burn client-specific information, such as client name and sensor list, into devices. The same type of vehicle is equipped with the same type of sensor, but can carry different types of devices. For example, vehicle type A with GPS sensor and engine lock sensor installed, and client A purchases both GPS and engine lock services and client B orders only GPS service. Then the manufacturer needs to offer 2 types of devices, one type enables GPS and engine sensor for client A and another for client B enables only GPS sensor. Tight-coupling process only impacts devices, not the vehicle directly.\nWhen using the tight coupling process, a manufacturer burns client-specific information, such as different runtime models required by different clients on devices, into a device before rolling them out to market. The process is:\nThe distributor places an order to purchase vehicles with devices, and provides client-specific information, such as client name and a list of sensors connected to the client\xe2\x80\x99s device.\nThe manufacturer initializes the devices according to the client-specific information from the distributor, and supplies them to the distributor.\nThe distributor delivers ordered vehicles and devices to the client (mining). The client assigns vehicles to drivers.\nThe client returns some vehicles because the rental was contract completed or they sold them back to the distributor.\nThe distributor returns devices to the manufacturer, provides specific information for another client, and asks the manufacturer to reinitialize those returned devices.\nThe manufacturer erases returned devices and burns new client information into them, and supplies them to the distributor.\nThe distributor resells or rents those vehicles with devices for another client to the client (construction).\nA new approach to decouple devices from distributors\nThe root cause of the disadvantages of the tight-coupling pattern is static relationship between devices and device distributors, which is usually caused by storing the distributor\xe2\x80\x99s identification information or their clients\xe2\x80\x99 information on the devices. To operate a device management solution, the distributors need to authenticate and track the devices they sold or rented based on the identification information, so the linkage between the devices and the distributors is necessary. However, this linkage does not need to be static, but can be dynamically generated and removable. Dynamic tying and untying can be integrated into the device registration process in a device management platform.\nFigure 2: Decoupled process for devices and their distributors\n  The manufacturer can provide unified devices to distributors. Device distributors can decide what models can be used on the devices they distributed.\nIn this decoupled approach, there are three modeling concepts we see our customers use: device model, working condition data model, and device control model. These models can be combined and/or separated dynamically to leverage the same devices to deliver different behaviors to device users to improve the adaptability of devices to enable them to support more business scenarios.\nThe device model based on the device hardware and firmware is the model closest to a device\xe2\x80\x99s own attributes, such as device outputs and data types of those outputs. For example, output TSW (self-weight of truck carrying cement mixer) is 8000kg, output CMSW (self-weight of cement mixer) is 3000kg and output CW (weight of cement filled into the cement mixer) is 1500kg. Please note, not all outputs from devices can be understood directly by a human, many outputs from device are just a string of numbers and characters, especially in industrial manufacturing.\nThe working condition data model is a data model that users of IoT platforms or systems can directly understand. It uses predefined algorithms to transform and calculate the data from the device model, and outputs results. For example, we can get several weight values from the device model, but sometimes only the vehicle bearing ratio, i.e. (CMSW + CW)/(TSW + CMSW + CW)=0.36, has practical significance from business point of view.\nThe device control model is the model in which the device management platform issues instructions to the devices to control the operation state of the devices. Usually, it needs to interpret an instruction into a series of operations that can be directly understood and completed by the devices. For example, the device management platform issues an instruction to prohibit start-up of an industrial vehicle, the device control model will decompose the instruction into an operation to lock engine start and another operation to allow the circuit to be turned on. These two operations are commands that can be completed directly by the vehicle.\nThe selected models are pushed to devices once the devices are registered to the device management solution, and data exchanged between devices and device management solution is determined by these models. Using a decoupled approach, a manufacturer can plan their device production capacity and schedule according to total market demand. They do not have to plan device producing for each distributor. Distributors only need to pay attention to the models that the ordered devices can support, rather than spend time and money reinitializing returned devices.\nIn the next section, I outline how the device model, working condition data model, and device control model each play a role in a manufacturer\xe2\x80\x99s vehicle management solution. The solution architecture is composed of edge devices (devices installed on vehicles), and the cloud-based device management and monitoring platform used for vehicle fleet management at scale. The local computing capacity of AWS IoT Greengrass software simplifies implementation of the models introduced in this blog, and the scalability of AWS IoT Core ensures the customer does not need to care about peak payload from the edge side.\nUse case, challenges, and solution overview\nWe worked with a global manufacturer of industrial devices and vehicles to implement this decoupled solution. Their vehicle management and monitoring solution is in production in China, Europe, and India, and securely monitors and manages millions of industrial vehicles and devices.\nIn this use case, the customer first validates their devices with serial numbers. Once the device is started and connected to the internet, it sends a request containing its own serial number to AWS IoT Core. AWS IoT Core verifies the serial number of the device and generates a unique certificate for the device. The device can use this certificate to download the models (device models, working condition data model and device control model) which usually are grouped and managed per device distributor. At this point, the process of model distribution to devices completes.\nThe models usually contain description files, such as JSON files, which define data structure of the models. In addition to the data structure, the working condition data model also include logic definitions, such as algorithms. The easiest way to implement logic definition in this model is programming. AWS IoT Greengrass\xe2\x80\x99s local Lambda function hosts and completes those logics from this model. AWS IoT Core in the backend pushes the data structure and logic definition in the models to AWS IoT Greengrass software installed in the devices. AWS IoT Greengrass software saves the data structure in the device and the logic definition in local Lambda functions.\nOnce the model is activated to run, the local Lambda function of AWS IoT Greengrass will follow the data structure in device model to accept data sent by the devices, perform logics defined in working condition data model, and use device control model to breakdown operation instruction issued by device controller, such as device user or admin, to commands the devices can execute.\nEdge devices\nAWS IoT Greengrass, an IoT open source edge runtime and cloud service that helps you build, deploy, and manage device software, supports the distribution and implementation of the device model, working condition data model and device control model in a device management platform. The devices with AWS IoT Greengrass only need to carry a unified certificate including permissions to register the device in AWS IoT Core.\nIn the major manufacturer\xe2\x80\x99s solution, a black box is installed on an industrial vehicle, and many sensors are installed on the vehicle and the specific devices the vehicle carries. The data collected by the sensors are centralized on the black box, which transmits the data to a backend vehicle management platform. The platform issues instructions to the black box to control the vehicle and the devices carried by the vehicle, and the black box decomposes the instructions to commands and asks sensors on the vehicle and devices to initiate the commands.\nAWS IoT Greengrass software is installed on the black box. Because the black box (G-Box in short) communicates with the sensors through a Controller Area Network (CAN) bus, AWS IoT Greengrass Core does not need to directly communicate with the sensors. The CAN application on the G-Box sends data collected by the sensors to AWS IoT Greengrass Core, and sends commands from the vehicle management platform to sensors. AWS IoT Greengrass Core uses local Lambda functions to operate the device model, working condition data model and device control model, and interacts with AWS IoT Core through MQTT protocol.\nCloud-based device management and monitoring platform\n Figure 3: Vehicle management solution architecture on AWS\n  As shown in Figure 3, the solution implementation is:\nOnce a G-box on a vehicle is powered on and connected to the internet, the G-box uses AWS IoT Greengrass Core and the built-in unified certificate to connect to AWS IoT Core, and requests to establish an AWS IoT Greengrass group in AWS IoT Core. The vehicle management platform also verifies whether the device serial number is valid. If it is invalid, the request will be rejected. If the serial number is valid, AWS IoT Core will use the serial number as the name of the AWS IoT Greengrass group. Then the AWS IoT Greengrass group sets one-to-one pairing between AWS IoT Greengrass Core and the G-box. The Shadow in AWS IoT Greengrass Core records the state of the G-box, such as storage space utilization, health information, etc. After that, the vehicle management platform will return the certificate specific for the G-Box. The certificate is generated when the AWS IoT Greengrass group is established. From that point on, the G-box will use its specific certificate to interact with the vehicle management platform built on AWS.\n The vehicle management platform records the G-Box metadata such as serial number, box type and firmware version in Amazon Relational Database Service (RDS) MySQL. This database also manages all vehicle information such as vehicle configuration and state, G-Box, and the devices carried by the vehicles. Device distributors and clients of the distributors, device models, working condition data models, and device control models used by the clients are stored in this database as well. The major manufacturer is now also assessing Amazon Aurora and Amazon DynamoDB for certain use cases.\nThe vehicle management platform responds to the request to retrieve models from the G-Box. The platform confirms the device model, working condition data model and control model that the G-box needs to use, and includes an Amazon Simple Storage Service (S3) presigned URL in the response for the G-box to download the data structure and logic definition for these models. AWS IoT Greengrass Core downloads these models to the G-Box, and loads data structures and logics to local Lambda functions. The modeling team can be composed of manufacturers, or distributors/resellers, or both of them, and is responsible for building and updating models. When new models are ready to release, the modeling team first uploads the data structure and logic definition to Amazon S3, and then defines the application scope of the models in the Amazon RDS MySQL database. The team operating the vehicle management platform assigns the models to certain distributors, or certain clients of the distributors.\nAfter retrieving and loading the models, AWS IoT Greengrass Core on the G-box uses the device model to receive raw data from the CAN application, and, according to the working condition data model, filters and transforms the raw data into the data that can be accepted by the backend system. It then packages the data into JSON files and sends them to the topic of AWS IoT Core dedicated for the G-box. The message in the topic will trigger the AWS IoT Core Rule Engine to filter and accumulate the data. This step is usually used to remove duplicated data and supplement default values for invalid data. The Rule Engine will call an AWS Lambda function to push the data to Apache Kafka. All working condition data of all the devices on all of the vehicles in this vehicle management solution is pushed to Kafka for use by other systems and platforms. The major manufacturer is assessing Amazon Kinesis as a replacement for managed services.\nThe device control in the vehicle management solution is divided into two levels:\nThe control to the G-box and the control to the vehicle and devices in the vehicle. The state of the G-box is directly synchronized with its shadow in AWS IoT Core; the state change in the shadow will be synchronized to the G-box, and according to the changes the local Lambda functions in AWS IoT Greengrass Core on the G-Box will change its state.\nThe G-Box communicating with the sensors on devices through CAN bus voids direct communication between AWS IoT Greengrass Core and the sensors. As such, AWS IoT Greengrass Core only needs to interpret the instructions from AWS IoT Core into the commands, which can be recognized by the CAN application according to the device control model.\nThe instructions are sent by AWS IoT Core via MQTT topics. The interpretation takes place on the G-box side and is completed by AWS IoT Greengrass Core\xe2\x80\x99s local Lambda functions. The CAN application in the G-Box will command the sensors to control the vehicles and their devices, and return the operation results to vehicle management platform.\nThis vehicle management and monitoring platform provides three main interfaces for open integration: 1/ device control API, 2/ MySQL database to provide customers, models and devices information, 3/ and Kafka to hold working condition data. These interfaces can be used and integrated with a web portal, mobile app, and third-party platforms. Through these interfaces, the data can be presented to vehicle management service providers, vehicle manufacturers and distributors, vehicle owners and users.\nSummary\nBy leveraging the approach introduced in this blog, instead of returning unused devices to a manufacturer, device distributors and resellers can first confirm device behaviors required by clients, then define the most-suitable device behaviors, and finally remotely refresh those definitions if the clients request to change device behaviors. This helps increase device reusability since the device behavior models can be used by the clients with the same requirements for device behavior. By avoiding device returns and removing predefined device ownership, customers benefit by saving costs on device operations and accelerating device distribution.\nGet started with AWS IoT by going to the AWS Management Console and navigating to AWS IoT Core and AWS IoT Greengrass.\nAbout the author\nShi Yin is a Senior IoT consultant from AWS Professional Services, based in California. Shi works with many enterprise customers to leverage AWS IoT services to build IoT platforms and connect sensors and devices to those platforms.'"
124,"AWS IoT SiteWise Year One: Product enhancements, customer and partner stories",b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/08/02/monitor-wind-farm-dashboard-console.png,https://aws.amazon.com/blogs/iot/aws-iot-sitewise-year-one-product-enhancements-customer-and-partner-stories/,"b'At AWS, we build technology to help customers and partners such as Coca Cola \xc4\xb0\xc3\xa7ecek, Yara, Lyell Immunopharma, Hitachi Vantara, Embassy of Things, TensorIoT, Element Analytics, and Seeq solve real world problems like minimizing equipment downtime, maximizing product quality, and ensuring personnel safety. We launched AWS IoT SiteWise in General Availability (GA) in July 2020 as a managed service that makes it easy to collect, store, organize, and monitor data from industrial equipment at scale to help customers to make better, data-driven decisions. AWS IoT SiteWise makes it easy to access Industrial IoT (IIoT) data with asset metadata, apply AI/ML to data, and integrate it with an industrial data lake. Our partners leverage AWS IoT SiteWise to build solutions to unlock equipment data, create near real-time production monitoring applications and modernize their historian infrastructure. As AWS IoT SiteWise celebrates its first birthday, we chronicle in this post some of our major enhancements over the past year, highlight a few of our customers\xe2\x80\x99 success stories, and describe key partner solutions that have integrated with AWS IoT SiteWise.\nGenerating more value for customers\nWe constantly shape our roadmap based on the feedback of our customers and partners. First and foremost, security is paramount and we continue to make enhancements on this front. Our customers told us that they want to manage their own encryption keys for AWS IoT SiteWise storage as well as be able to establish a private connection between their Virtual Private cloud and AWS IoT SiteWise. To meet their needs, we launched customer managed encryption keys as well as AWS Private Link support for AWS IoT SiteWise data plane APIs. In addition, in H2 2020, we launched new features that addressed customer requests in the space of ease of data ingestion, added flexibility in defining metrics and transforms, visualization, and edge processing.\nExample Grafana dashboard using the AWS IoT SiteWise plugin\nFor example, our customers told us that they have existing dashboards and custom applications using open source tools like Grafana, and they wanted to add AWS IoT SiteWise data to them. So we launched the AWS IoT SiteWise Grafana plugin which enables them to bring data from AWS IoT SiteWise and visualize it in their existing Grafana dashboards in near real-time. We also added seven more chart types to provide rich data visualization. A comprehensive list of these features and additional details can be found in the following blog \xe2\x80\x93 AWS IoT SiteWise: 2020 in review.\nAWS IoT SiteWise Monitor\nIn 2021, we continue to address the most important customer requests in the space of security. For example, we started the year by adding support for accessing AWS IoT SiteWise Monitor portals through AWS Identity and Access Management (IAM) users and roles so that customers can choose between IAM and AWS Single Sign-On as their preferred enterprise identity source for SiteWise Monitor web applications. This makes creating and accessing SiteWise Monitor portals quick and easy for customers already using IAM. Customers also asked to access AWS IoT SiteWise control plane APIs through a private connection, so we extended AWS Private Link support to cover AWS IoT SiteWise control plane APIs. Additionally, their plants are distributed in multiple geographies and timezones, and they wanted be able to perform operations such as timezone conversion when defining their metrics and transforms. To support their needs, we enhanced the AWS IoT SiteWise computation engine with support for additional date and time functions. Customers told us they wanted to be able to downsample their data to improve performance of their dashboards and/or reduce their data retrieval costs. In other cases, when they use the deadbanding feature of AWS IoT SiteWise to optimize bandwidth (by ingesting data into the cloud only when the values change), they wanted to be able to fill in the missing data points so they can retrieve uniformly sampled data. To help support these use cases, we launched the AWS IoT SiteWise Interpolation API. Customers have asked us for the ability to alarm on certain conditions like when a certain measurement falls above or below certain values and they wanted to do this without configuring these alarms individually on thousands of assets. We launched AWS IoT SiteWise Alarms which enables customers to configure an alarm on an asset model and have it automatically apply to all assets from their model. Operators can manage end-to-end alarm workflows from SiteWise Monitor web applications.\nIn addition to feature requests, customers asked that AWS IoT SiteWise be made available in Asia-Pacific (APAC) regions. To meet their needs, we launched AWS IoT SiteWise in three additional AWS regions \xe2\x80\x93 Singapore, Sydney, and Beijing \xe2\x80\x93 bringing our presence to seven regions.\nAWS IoT SiteWise Edge with AWS IoT SiteWise Monitor web applications deployed locally for users like process engineers to visualize equipment data in near-real time on the plant floor.\nWe recently launched a few features in our anniversary month. Customers can now configure AWS IoT SiteWise to export their equipment data to their industrial data lake in Amazon S3. Once data is exported, customers can leverage a number of other AWS services. Our customers told us they wanted the AWS IoT SiteWise capabilities to collect, process, and monitor equipment data to run on-premises, and continue to run even when their cloud connectivity is temporarily interrupted. To meet the needs of these customers, we launched AWS IoT SiteWise Edge in Preview last year at re:Invent 2020 and just released in GA. AWS IoT SiteWise Edge brought metrics computation, data access, visualization and SiteWise Monitor applications to the customer edge.\nIn the remainder of this blog post, we look at how some of our customers are using AWS IoT SiteWise to solve their use cases. We also provide a list of partners integrating with AWS IoT SiteWise to provide domain-specific services and applications that provide customers with even more capabilities and flexibility.\nAchieving customer outcomes\nWhen AWS IoT SiteWise launched in GA, we already had several customers and partners using the service, including Bayer Crop Science, Volkswagen Group, Pentair, and Genie. In the past year, we have worked with a number of new customers on their industrial workloads with AWS IoT SiteWise. We highlight just a few of them below.\nCoca-Cola \xc4\xb0\xc3\xa7ecek (CCI), one of the key bottlers in the Coca-Cola system, produces, distributes, and sells sparkling and still beverages of The Coca-Cola Company to 10 countries across Turkey, Pakistan, central Asia, and the Middle East, serving more than 400 million consumers. As part of CCI\xe2\x80\x99s digital strategy and vision, the company used Amazon Web Services (AWS) to transform its 26 bottling plants by building a digital twin. During the project\xe2\x80\x99s first phase, CCI used AWS Professional Services to build a solution for its clean-in-place (CIP) process, a critical sanitation process in the food and beverage industry that cleans interior surfaces of production lines and equipment without disassembly. CCI needed a way to collect and process enormous amounts of industrial data as well as build digital models of clean-in-place (CIP) assets and processes. To ingest equipment data for processing, CCI used AWS IoT SiteWise. AWS IoT SiteWise ingests a large amount of industrial data from CCI plants and enables operators to monitor processes at the edge using Grafana dashboards, an open-source analytics and interactive visualization web application. CCI built the CIP digital solution in 2 months. Within 4 months of deployment, CCI identified over 30 improvement opportunities that resulted in annual savings of 20 percent on electricity and 9 percent on water per CIP system.\nLyell Immunopharma is a biotech company specializing in cell therapies such as T cell reprogramming to cure cancer patients with solid tumors. Lyell uses AWS IoT SiteWise to automate the acquisition of their data from bioreactors and other instruments. They use AWS IoT SiteWise monitor portals and Grafana dashboards to visualize this telemetry data in near real-time. These insights help Lyell troubleshoot and resolve issues, as well as make continuous improvements to their cell therapy manufacturing process.\nYara, a global leader in farming solutions, chose AWS as its preferred cloud provider to build Yara\xe2\x80\x99s next-generation Digital Production Platform (DPP). This platform will be the key enabler for Yara to digitalize its production system, consisting of 28 production sites (with a total of 122 production units that feature different production processes like NPK, ammonia, nitric acid, nitrate granulation and carbon dioxide plants) and two mines. The DPP will use AWS IoT SiteWise, AWS IoT Greengrass, AWS IoT Core, and AWS IoT Analytics, to detect, collect, and run sophisticated analytics on production data linked to productivity, reliability, environment, safety, quality and innovation. By applying AWS analytics and machine learning services, such as Amazon SageMaker to the data, Yara can predict product quality and composition, improve balancing of the site utilities, and detect when machines need repair or maintenance to keep production at optimal efficiency levels.\nDelivering business outcomes through Partners\nAWS Partners also obsess over our customers\xe2\x80\x99 feedback and have developed solutions that give customers access to more options in data ingestion, advanced analytics, and turn-key industrial IoT applications. A few example partner solutions that extend or build upon AWS IoT SiteWise are highlighted below.\nSeeq enables engineers and data scientists in process manufacturing organizations to rapidly analyze, predict, collaborate, and share insights to improve production outcomes. Seeq customers rely on Seeq for a reliable connection to their process data and tools that will accelerate analytics to drive faster, data-based decisions. With the addition of the AWS IoT SiteWise connector, Seeq customers can now access data stored in AWS IoT SiteWise, including real-time and historical process data, and contextual data from business systems, and use Seeq applications to cleanse, contextualize, and investigate it to diagnose issues and share them across their organizations.\nSeeq tools like Reference Profile and Value Search can be used to generate statistical limits using process data from AWS IoT SiteWise. These statistical limits can be monitored in near real time to ensure that production processes operate with low amounts of variability.\nTensorIoT offers SmartInsights, a shop floor-to-insights solution powering the next wave of industrial process optimization. SmartInsights leverages AWS IoT SiteWise, AWS IoT Greengrass and AWS IoT Core to help customers rapidly connect their industrial machinery and sensors to the cloud. SmartInsights is an example of a turnkey solution built on AWS IoT SiteWise for process optimization use cases. It is deployed at companies spanning a variety of industries such as metal fabricators, chemical refineries, industrial machine makers, and automotive parts manufacturers. These customers are using SmartInsights to increase situational awareness, gain actionable insight, and make more confident decisions for use cases such as operational efficiency, predictive maintenance, process optimization, and anomaly detection.\nElement Analytics allows Industrial Enterprises to enrich siloed IT/OT data with context metadata to help industrial organizations achieve cleaner, safer, healthier, and more profitable operations. Element Unify enables condition-based monitoring and improved decision-making through context-enriched plant data for real-time KPIs and metrics, with features like cross-application data modeling, no-code transformations for building data pipelines, and automated P&ID bulk text extraction. The Element Unify integration with AWS IoT SiteWise is designed to allow engineers and operators to monitor operations across facilities, quickly compute performance metrics, create applications that analyze industrial equipment data to prevent costly equipment issues, and reduce gaps in production. With Element Unify, AWS IoT SiteWise customers can centralize plant data model integration and metadata management, blending context from sources like OSIsoft PI System (now AVEVA), Asset Framework, Historians, SCADA, SAP PM or Piping and Instrumentation Diagrams (P&IDs) to address industrial use cases like condition monitoring, predictive analytics and maintenance, and overall equipment effectiveness (OEE).\nElement Unify integration with AWS IoT SiteWise enables drag and drop pipeline building with ability to incorporate multiple sources, and easily publish models to AWS IoT SiteWise and keeping them \xe2\x80\x9cevergreen.\xe2\x80\x9d\nEmbassy of Things (EOT) is helping energy companies, to discover and realize enterprise-wide cost reductions with Twin Talk, a secure and scalable ETL++ Software System designed to extract near real-time operational time series data from SCADA systems and siloed legacy historians and delivering it natively into AWS IoT SiteWise. EOT TwinTalk solutions make it easy to ingest industrial data to AWS IoT SiteWise. With data in AWS IoT SiteWise, customers can run queries, analytics, machine learning, reports, and dashboards spanning across all assets of an enterprise which is an important step towards self-optimizing industrial plants.\nTo provide more options to ingest data into the cloud, we also have partners who build sensor solutions and use AWS IoT SiteWise to collect, store and process data securely and at scale.\nRigado, deployed in more than 20,000 locations across 75 countries, connects over 6 million devices deployed over 100K sensor network systems for Enterprise IoT solutions for use cases including smart office and buildings, connected retail, and intelligent logistics. The Rigado Allegro Kit delivers a plug-and-play sensor network with sensors & devices pre-integrated with AWS IoT SiteWise, allowing solution providers to build a variety of use cases including 1/ Temperature, humidity, and air quality monitoring for refrigerators, freezers, and open areas, 2/ People counting and occupancy in restrooms, elevators, and common areas, and 3/ Employee and asset monitoring with badge and asset tag location.\nShoreline IoT is accelerating digital transformation by automating asset management and making it very affordable and infinitely scalable across all assets, especially ones that are not yet connected or are remote and unattended. The fully automated AI/ML solution is built using AWS IoT services, including AWS IoT SiteWise, and deployed at large enterprise customers for remote compressors, engines, pumps, turbines and other dynamic machines in Oil & Gas Midstream, Pulp and Paper, steel mills, chemicals and water & wastewater, food processing and Manufacturing. The solution features smart, wireless AI sensors with a 5-year battery life to replace manual inspections, and designed for non-experts to deliver 24/7 asset health monitoring through edge and cloud based predictive analytics that reduce downtime, cut maintenance costs, increase equipment efficiency, extend the life of expensive assets and reduce greenhouse gas emissions.\nUrban.io is using AWS IoT SiteWise and AWS IoT SiteWise Monitor to rapidly visualize real time data. Through a combination of wireless retrofit sensors, enterprise class IoT data aggregation and a drag and drop real time dashboard editor, Urban.io is able to deliver on the promise of acquiring customer field data from multiple points in the world and aggregating that to a \xe2\x80\x9csingle pane of glass\xe2\x80\x9d in less than 24 hours. Each device can be installed and commissioned in less than five minutes and then Urban.io\xe2\x80\x99s clients drag the data out and lay it onto dashboards themselves.\nAWS partners are building scalable industrial solutions using AWS IoT SiteWise to serve large industrial operations across many sites and countries.\nHitachi Vantara, the digital infrastructure and solutions subsidiary of Hitachi, Ltd., offers Lumada industrial solutions on the AWS cloud platform to enable customers to accelerate their Industry 4.0 journey. Hitachi offers a highly scalable and agile deployment of Lumada Manufacturing Insights solution integrated with AWS IoT SiteWise. Hitachi\xe2\x80\x99s Lumada complements AWS IoT SiteWise with sophisticated data analytics for customers in manufacturing, transportation and energy that manage industrial operations such as plant floors, power networks, train systems and mining sites.\nRackspace Technology \xe2\x80\x94 The first step industrial customers take in their digital transformation journey is to liberate data generated by their disparate factory floor assets to gain actionable insights. Rackspace Technology selected AWS IoT SiteWise for their Rackspace IIoT Smart Factory Accelerator, which provides the following right out-of-the-box: industrial protocol connectors to collect data, mechanisms to transform and enrich the data, quick data visualization through a dashboard, and simplified configuration of alarms and notifications for continuous asset monitoring. AWS IoT SiteWise\xe2\x80\x99s robust feature set allows Rackspace to accelerate their customers\xe2\x80\x99 digital transformation journey by spending more time focusing on their key Manufacturing Performance Indicators, metrics, and business outcomes.\n'"
125,Migrating connected device fleets to AWS with Custom Domains for AWS IoT Core,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/07/26/Picture-4-1024x723.png,https://aws.amazon.com/blogs/iot/migrating-devices-aws-iot-custom-domains/,"b'Introduction\nAWS launched Configurable Endpoints with Custom Domains for AWS IoT Core, a new capability that allows customers to customize the behavior of their AWS IoT Core data endpoints with custom domain names. Custom Domains enable customers to register their original custom domain names and associated server certificates to their AWS IoT Core endpoints.\nThis new capability helps AWS customers comply with their internal or external security and compliance requirements, makes it simpler to migrate IoT devices to AWS IoT, helps them implement a failover strategy for the purpose of disaster recovery, and makes it easy to architect usage scenarios with multiple AWS Regions.\nIn this blog post, we demonstrate how you can use Configurable Endpoints to simplify and expedite migration of IoT devices to AWS IoT from an existing IoT solution.\nChallenges of migrating IoT Devices\nMigrating your connected devices fleet to AWS IoT Core is a critical task of your IoT migration journey. Your devices are a central resource in your IoT value chain, as much as your users and your data, and their migration should be just as reliable and fast. Migrating devices to AWS IoT frequently involves updating the firmware and software configurations, such as which IoT endpoint and authentication method to use for connections. However, performing a mass update of a large device fleet (thousands or even millions of devices), distributed across different geographical regions, might pose some of the following challenges:\n1. Your IoT devices may not be allowed to connect to *amazonaws.com\nYour organization\xe2\x80\x99s strategic decisions for security and compliance may require you to use your own company owned domains and/or server certificates and manage your own Private Key Infrastructure (PKI) and Certification Authority. This means that your IoT application could be exposing an endpoint on your company\xe2\x80\x99 own private or public domain, such as iot.yourcompany.example.com where your devices are expected to connect. This scenario prevents you from using the standard *.amazonaws.com domains without performing a software upgrade on your devices.\nExample 1: IoT device can\xe2\x80\x99t migrate to AWS due to organisation cybersecurity policy\n2. You may want to avoid extensive over-the-air upgrades (OTA)\nThere are situations where you can\xe2\x80\x99t easily perform an extensive over the air upgrade (OTA) to reconfigure your device settings. This can be due to the long timeline for firmware development and validation, or due to the fact that a remote device upgrade may not be reliable due to limited connectivity in certain geographic areas of your fleet.\nExample 2: Migrating through over-the-air-upgrade (left) versus migrating through DNS record change (right).\nUsing a custom domain name in the device firmware helps simplify migration operations because instead of performing an OTA upgrade, you can simply update a Canonical Name (CNAME) record in the Domain Name System (DNS; single point modify). This helps you benefit from other advantages of DNS such as weighted routing to perform incremental migrations.\n3. You may have different device families to manage\nYour fleet might have different device architectures, each one requiring a different trusted endpoint and/or authorisation mechanism. Multiple configurable endpoints are required for each family to enable legacy device support.\nExample 3: Multiple device families converging to the same AWS IoT Core endpoint\nSolution overview: migrating IoT devices with custom domains for AWS IoT Core\nThe following diagram shows how you can use custom domains in AWS IoT Core for an IoT device migration.\nReference architecture of a migration using custom domains for AWS IoT Core\nThis solution leverages the following services:\nRoute 53 as Domain Name Service (DNS). In this example, we are going to set a simple routing policy to route traffic from the existing IoT Application to AWS.\nAWS Certificate Manager (ACM) as the main server certificate store. In this example we are going to use ACM for storing our server certificate issued by a private Certification Authority (CA) and our public server certificate, used to validate the ownership of our domain.\nAWS IoT Core as the target IoT endpoint of our migration. In this example, we are going to onboard an IoT device in AWS IoT Core, and set up a custom endpoint configuration with an example domain name.\nPrerequisites\nFor the walkthrough, you should have following prerequisites:\nAn AWS account.\nAWS Command Line Interface (CLI) See AWS CLI Documentation for instructions on how to install and configure AWS CLI.\nAn AWS IAM user with the credentials to create AWS resources through CLI.\nA domain name that you use to set up the custom endpoint. You can use Route 53 for the domains you registered with Route 53 or also with domains that you have registered with other DNS providers.\nA device that you want to migrate to AWS that satisfies the requirements to connect to AWS IoT Core.\nAn MQTT client to complete tests. In this walkthrough we use Eclipse Mosquitto MQTT Client.\n(Optional) A server certificate issued by your CA, and its private key to validate ownership of your domain. If you don\xe2\x80\x99t own a server certificate or a private CA, you can request one through AWS. The walkthrough covers both scenarios.\nNote on device certificates: in our walkthrough we generate new device certificates to test the behavior of the Custom Domain feature. If you already have your own device certificate you can import it to perform the test.\nImplementing the solution in your AWS account\nIn this example, we simulate a source IoT endpoint for the migration, using AWS IoT Core and Configurable Endpoints, in a different Region of the same AWS account. This post will explain the following steps for implementing this solution:\nStep 1: Configure a hosted zone in Route 53 with the registered domain name.\nStep 2: Configure the target IoT endpoint for migration in the selected AWS Region.\nIn our example we configure our endpoint in the Ireland (eu-west-1) Region. This involves \xe2\x80\x93\nRegistering a certificate chain in AWS Certificate Manager (ACM).\nConfiguring a custom domain in AWS IoT Core using your server certificate.\nCreating device certificates, and an IoT Policy in AWS IoT Core, or importing your own.\nStep 3: Set up CNAME record in Route 53 to route the traffic and perform tests with an MQTT client.\nStep 1: Configure a hosted zone in Route 53\nIn this example, we create a hosted zone in Route 53 to manage our registered domain name example.com.\nOpen the command line terminal window.\nIf you register the domain using Route 53, the hosted zone is created automatically. If the domain is registered elsewhere, run the following command to create a hosted zone in Route 53:\naws route53 create-hosted-zone --name example.com --caller-reference 2021-05-04-18:30\nAs output of the command, you receive the ID that Route 53 assigned to the hosted zone. You can also query the ID of the hosted zone using the following command:\naws route53 list-hosted-zones\nRun the following command to get Name Servers associated with the hosted zone:\naws route53 get-hosted-zone --id <Hosted_Zone_ID>\nResponse (JSON):\n...\n""DelegationSet"": {\n       ""NameServers"": [\n             ""ns-1769.awsdns-29.co.uk"",\n           ""ns-955.awsdns-55.net"",\n            ""ns-113.awsdns-14.com"",\n           ""ns-1256.awsdns-29.org""\n        ]\n}\n...\nJSON\nIf you are using a domain provider other than Route 53, configure the Name Servers of your hosted zone in the management console of your domain vendor. This allows you to use Route 53 to manage your domain.\nStep 2a: Configure the Target IoT endpoint for the migration \xe2\x80\x93 Register a certificate chain in ACM\nIf you don\xe2\x80\x99t own a server certificate for your custom IoT domain, you can request one through ACM. If you own your own server certificate, check whether your root CA certificate used to sign the certificate is included in Mozilla\xe2\x80\x98s trusted ca-bundle. If it is included, you can import the certificate chain in ACM. If it is not included, import the certificate chain in ACM and also request a public certificate through ACM.\nThe following walkthrough provides example for both scenarios:\nScenario i) You don\xe2\x80\x99t own a server certificate for your custom IoT domain\nRun the following command to issue the request:\naws acm request-certificate \xe2\x80\x93-domain-name iot.example.com \xe2\x80\x93-validation-method DNS --region <AWS_Region>\nNote down the server certificate ARN from the response:\n{\n   ""CertificateArn"": ""arn:aws:acm:eu-west-1:XXXXXXXXXXXXXXXXX:certificate/<certificate_id>""\n}\nJSON\nFollowing this, you can describe the certificate domain validation parameters to retrieve the DNS configuration parameters (in bold):\naws acm describe-certificate --certificate-arn arn:aws:acm:eu-west-1:XXXXXXXXXXXXXXXXX:certificate/<certificate_id> --region eu-west-1\nSample response:\n{\n    ""Certificate"": {\n      ""CertificateArn"": ""arn:aws:acm:eu-west-1:<account_id>:certificate/<ceritficate_id>"",\n\xe2\x80\xa6\xe2\x80\xa6\n           ""ValidationStatus"": ""PENDING_VALIDATION"",\n           ""ResourceRecord"": {\n           ""Name"": ""_XXXXXXXXXXXXXXXXXXXXX.iot.example.com."",             ""Type"": ""CNAME"",             ""Value"": ""_XXXXXXXXXXXXXXXXXXXXX.XXXXXXXXXXX.acm-validations.aws.""\n     },\n\xe2\x80\xa6\n}\nJSON\nWithin 30 minutes, the status changes to SUCCESS from PENDING_VALIDATION. Once the status changes, create a file named records.json with the following syntax, using the retrieved parameters:\n{\n    ""Comment"": ""Create ACM Validation Record"",\n    ""Changes"": [\n        {\n            ""Action"":  ""UPSERT"",\n            ""ResourceRecordSet"":\n            {\n                ""Name"": ""_XXXXXXXXXXXXXXXXXXXXX.iot.example.com."",                 ""Type"":""CNAME"",\n                ""TTL"": 300,\n                ""ResourceRecords"": [\n                    {\n                        ""Value"": ""_XXXXXXXXXXXXXXXXXXXXX.XXXXXXXXXXX.acm-validations.aws.""                     }\n                ]\n            }\n        }\n    ]\n}\nJSON\nNow run the following command to add the record to your hosted zone in Route 53:\naws route53 change-resource-record-sets --hosted-zone-id <your_hosted_zone_id> --change-batch file://records.json\nYou see the server certificates appear with validation status \xe2\x80\x9csuccess\xe2\x80\x9d in ACM on your AWS Management Console.\nYour public server certificate reporting validated status in ACM\nYou see also the previously added CNAME record appear in Route 53 on your AWS Management Console at Route 53 > Hosted Zones > <your_hosted_zone_name>\nRecord for DNS validation in your Route 53 hosted zone\nScenario ii) You own a server certificate for your custom IoT domain which is signed by a Certification Authority included in Mozilla\xe2\x80\x99s ca-bundle\nTo perform this operation, you need the following resources:\nThe PEM-encoded server certificate that is stored in a file named Certificate.pem.\nThe PEM-encoded certificate chain that is stored in a file named CertificateChain.pem.\nThe PEM-encoded, private key is stored in a file named PrivateKey.pem.\nTo configure the server certificate chain:\nOpen a command line terminal window.\nRun the following command to import your server certificate:\naws acm import-certificate \xe2\x80\x93-certificate fileb://Certificate.pem \xe2\x80\x93-certificate-chain fileb://CertificateChain.pem \xe2\x80\x93-private-key fileb://PrivateKey.pem --region <AWS_Region>\nStep 2b: Configure the target IoT endpoint for the migration \xe2\x80\x93 Configure a custom domain in AWS IoT Core using your registered server certificate\nTo perform this operation, you require the registered server certificates ARN and your domain name:\nOpen a terminal window.\nRun the following command to query your registered server certificates in ACM and note their \xe2\x80\x9cCertificateArn\xe2\x80\x9d values:\naws acm list-certificates \xe2\x80\x93region <your_AWS_Region>\nResponse:\n{\n    ""CertificateSummaryList"": [\n        {\n            ""CertificateArn"": ""arn:aws:acm:eu-west-1:XXXXXXXXXXXXXXXXX:certificate/<certificate_id>"",\n            ""DomainName"": ""iot.example.com""\n        }\n    ]\n}\nJSON\nRun the following command to register your custom domain in AWS IoT Core:\naws iot create-domain-configuration --domain-configuration-name ""TargetTestIoTPlatform"" --service-type ""DATA"" --domain-name ""iot.example.com"" --server-certificate-arns ""arn:aws:acm:eu-west-1:XXXXXXXXXXXXXXXXX:certificate/<certificate_id>""\nNow you have a custom domain configuration in AWS IoT Core in your target Region, you can see the configuration appear in your AWS Management Console under AWS IoT > Settings:\nCustom Domain Configuration in AWS IoT Core settings\nStep 2c: Configure the target IoT endpoint for the migration \xe2\x80\x93 Create device certificates, and an IoT policy in AWS IoT Core\nThe devices in your fleet require a valid identity and an IoT policy in your target IoT endpoint to connect. As the best practice, your provisioning flow should allow you to avoid sharing private key over the public internet, and it is advised that you embed a provisioning flow as part of your IoT device design.\nAWS provides a list of options for device provisioning as part of AWS IoT Core documentation and a whitepaper on \xe2\x80\x9cDevice Manufacturing and Provisioning with X.509 Certificates in AWS IoT Core\xe2\x80\x9d that explains in depth each option in respect to real customer scenarios.\nOptional step: bring your own device certificate\nYou can import your existing device certificates and CA certificate in AWS IoT Core to allow a smooth migration and avoid performing OTAs or having the device to rotate their certificate through an existing PKI. You can also register device certificates signed by a CA that is not registered in AWS IoT Core. For more information, see AWS IoT Core documentation on how to register your CA certificate and register a client certificate manually\nPlease note that the device certificates you can import should conform to the standards supported by AWS IoT Core. Please see AWS IoT Core Documentation on X.509 certificates for additional details.\nIn our example, we create a test thing, device certificate, and an IoT policy using the CLI. First, to create an identity for each of your test IoT devices:\nOpen a command line terminal window.\nRun the following command to generate a device certificate and a key pair, the files are created in local:\naws iot create-keys-and-certificate \\\n--certificate-pem-outfile ""TestThing.cert.pem"" \\\n--public-key-outfile ""TestThing.public.key"" \\\n--private-key-outfile ""TestThing.private.key"" \\\n--region <your_AWS_Region>\nResponse:\n{\n    ""certificateArn"": ""arn:aws:iot:eu-west-1:XXXXXXXXXXXXXXXXX:cert/<certificate_id>"",\n    ""certificateId"": ""<certificate_id>"",\n    ""certificatePem"": ""-----BEGIN CERTIFICATE----- [\xe2\x80\xa6] -----END CERTIFICATE-----"",\n    ""keyPair"": {\n        ""PublicKey"": ""-----BEGIN PUBLIC KEY----- [\xe2\x80\xa6] -----END PUBLIC KEY-----"",\n        ""PrivateKey"": ""-----BEGIN RSA PRIVATE KEY----- [\xe2\x80\xa6] -----END RSA PRIVATE KEY-----""\n    }\n}\nJSON\nCopy your \xe2\x80\x9ccertificateArn\xe2\x80\x9d and \xe2\x80\x9ccertificateId\xe2\x80\x9d from the output of the command.\nRun the following command to create a thing in the device registry:\naws iot create-thing \\\n--thing-name TestThing \\\n--region <your_AWS_Region>\nCreate an IoT policy using thing policy variables to enable least-privilege principle to our connecting IoT devices. As a best practice, policy variables should be used when possible. Create a TestPolicy.json file with the following content:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [{\n       ""Effect"": ""Allow"",\n       ""Action"": [\n         ""iot:Publish""\n       ],\n       ""Resource"": [\n         ""arn:aws:iot:eu-west-1:XXXXXXXXXXXXXXXXX:topic/test/device/${iot:Connection.Thing.ThingName}""\n       ]\n   },\n   {\n       ""Effect"": ""Allow"",\n       ""Action"": [\n          ""iot:Connect""\n       ],\n       ""Resource"": [\n         ""arn:aws:iot:eu-west-1:XXXXXXXXXXXXXXXXX:client/${iot:Connection.Thing.ThingName}""\n       ]\n   }\n  ]\n}\nJSON\nRun the following command to register the policy in AWS IoT Core:\naws iot create-policy \\\n--policy-name TestPolicy \\\n--policy-document file://TestPolicy.json \\\n--region <your_AWS_Region>\nAttach the policy to our device certificate, and our device certificate to our IoT thing. Run the following command to attach the IoT policy to our device certificate (you need the certificate ARN):\naws iot attach-policy \\\n--policy-name TestPolicy \\\n--target <your__device_certificate_ARN> \\\n--region <your_AWS_Region>\nFinally, run the following command to attach the device certificate to your IoT thing:\naws iot attach-thing-principal \\\n--thing-name TestThing \\\n--principal <your_device_certificate_ARN> \\\n--region <your_AWS_Region>\nYou see the registered thing, policy, and device certificate in your AWS Account through the AWS IoT Console.\nStep 4: Set up CNAME record in Route 53\nThe last step of the configuration process is to create CNAME records in your DNS to implement the routing from your domain name to the AWS IoT Core endpoint.\nAs a minimum, you need to create a CNAME record in your hosted zone, with your desired AWS IoT Core endpoint as a target. You can identify your AWS IoT Core endpoint through the following CLI command:\naws iot describe-endpoint --endpoint-type iot:Data-ATS \xe2\x80\x94region <your_AWS_Region>\nIf you use Route 53, you can use the available routing mechanisms to implement more complex scenarios, such as using Weighted Routing to perform blue/green deployments or to gradually shift traffic from one endpoint to another.\nTo create a Simple Routing policy using Route 53:\nOpen a command line terminal window.\nCreate a file named simpleRoutingRecords.json with the following content:\n{\n   ""Comment"": ""Create Simple Routing CNAME records "",\n   ""Changes"": [{\n       ""Action"": ""UPSERT"",\n       ""ResourceRecordSet"": {\n            ""Name"": ""iot.example.com."",\n            ""Type"": ""CNAME"",\n            ""TTL"": 300,\n            ""ResourceRecords"": [{\n               ""Value"": ""<prefix>-ats.iot.eu-west-1.amazonaws.com""\n            }]\n        }\n   }]\n}\nJSON\nRun the following command to add the record to your hosted zone in Route 53:\naws route53 change-resource-record-sets --hosted-zone-id <hosted_zone_id> --change-batch file://simpleRoutingRecords.json\nOnce this is complete, the new record is displayed in the hosted zone in Route 53.\nSimple routing CNAME record in Route53\nTesting the solution\nNext, we send test MQTT messages to the target platform endpoint we registered as iot.example.com using the Eclipse Mosquitto MQTT client downloaded during the prerequisites. This helps ensure the configured routing policy and migration worked as expected.\nRequirements to test the solution:\nThe PEM encoded device certificate and private key created in Step2c of our walkthrough in \xe2\x80\x9c3. Implementing the Solution in your AWS Account\xe2\x80\x9d saved as a file. In our example you should have two files: TestThing.cert.pem and TestThing.private.key.\nAn AWS IoT Core root CA certificate. In our example, we use RSA 2048 bit key: Amazon Root CA 1.\nProcedure to test your solution:\nOpen a terminal window in your target folder where your device certificate, private key, and Amazon Root CA files are located.\nOpen the AWS IoT console in your AWS account and navigate to the MQTT test client. You can find the test client at Test \xe2\x86\x92 MQTT test client.\nAWS IoT Core console MQTT test client\nIn the Topic Filter box, enter \xe2\x80\x9ctest/device/TestThing\xe2\x80\x9d, select Subscribe and leave the window open.\nIn your terminal window, run the following command:\nmosquitto_pub -h iot.example.com --cafile AmazonRootCA1.pem --cert TestThing.cert.pem --key TestThing.private.key -p 8883 -q 1 -d -t test/device/TestThing -i TestThing -m ""{\\""message\\"": \\""helloFromTestThing\\""}""\nVerify that the messages are visualized in the AWS IoT Core test client console.\nTest messages received in the AWS IoT Core console MQTT test client\nCleaning up Resources\nTo help prevent unwanted charges to your AWS account, delete the AWS resources that you used for this walkthrough. These AWS resources include the AWS IoT Core, AWS Certificate Manager, Route 53. You can use the AWS CLI, AWS Management Console, or the AWS APIs to perform the cleanup. In this section, we refer the AWS CLI approach. If you want to keep these resources, you can ignore this section.\nDisabling your DNS configuration:\nCreate a file with the following content. In our example, we name the file change-resource-record-sets.json.\n{\n  ""Comment"": ""Delete the CNAME Record Set"",\n  ""Changes"": [\n      {\n          ""Action"": ""DELETE"",\n          ""ResourceRecordSet"": {\n              ""Name"": ""iot.example.com"",\n              ""Type"": ""CNAME"",\n              ""TTL"": 300,\n              ""ResourceRecords"": [\n                  {\n                      ""Value"": ""<prefix>-ats.iot.eu-west-1.amazonaws.com""\n                  }\n              ]\n          }\n     },\n     {\n          ""Action"": ""DELETE"",\n          ""ResourceRecordSet"": {\n              ""Name"": ""_XXXXXXXXXXXXXXXXXXXXX.iot.example.com"",\n              ""Type"": ""CNAME"",\n              ""TTL"": 300,\n              ""ResourceRecords"": [\n                  {\n                      ""Value"": ""_XXXXXXXXXXXXXXXXXXXXX.XXXXXXXXXXX.acm-validations.aws.""\n                  }\n              ]\n          }\n      }\n   ]\n }\nJSON\nDelete the record using the following CLI command:\naws route53 change-resource-record-sets --hosted-zone-id <your_hosted_zone_id> --change-batch file://change-resource-record-sets.json\nDelete the hosted zones using the following CLI command:\naws route53 delete-hosted-zone --id <your_hosted_zone_id>\nCleaning up AWS IoT Core resources\nDetach the Device Certificate from the IoT policy using the following CLI command:\n aws iot detach-policy --target ""arn:aws:iot:eu-west-1:XXXXXXXXXXXXXXXXX:cert/<certificate_id>"" --policy-name ""TestPolicy""\nDelete the IoT policy using the following CLI command:\n aws iot delete-policy --policy-name TestPolicy\nDetach the Device Certificate from the test IoT thing using the following CLI command:\n aws iot detach-thing-principal --thing-name TestThing --principal arn:aws:iot:eu-west-1:XXXXXXXXXXXXXXXXX:cert/<certificate_id>\nDelete the Device Certificate from AWS IoT Core using the following CLI command:\n aws iot delete-certificate --certificate-id <certificate_id>\nDelete the IoT thing from AWS IoT Core using the following CLI command:\n aws iot delete-thing --thing-name TestThing\nDisabling your custom domain configuration\nDisable the AWS IoT Core Custom Domain Configuration Status using the following CLI command:\naws iot update-domain-configuration --domain-configuration-name ""TargetTestIoTPlatform"" --domain-configuration-status ""DISABLED""\nDelete the AWS IoT Core Custom Domain Configuration using the following CLI command:\naws iot delete-domain-configuration --domain-configuration-name ""TargetTestIoTPlatform""\nDelete all imported and requested server certificates in ACM using the following CLI command:\naws acm delete-certificate --certificate-arn arn:aws:acm:eu-west-1:XXXXXXXXXXXXXXXXX:certificate/<certificate_id>\n'"
126,Detect scene changes in remote areas with AWS IoT Events and Amazon SageMaker,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/07/14/solution_diagram-809x1024.png,https://aws.amazon.com/blogs/iot/detect-scene-changes-in-remote-areas/,"b'Organizations with large numbers of assets need to monitor their physical and operational health, in order to detect issues and act upon them. This post covers the use case of a fictitious industrial organization AcmeDrone that uses drone devices to inspect assets periodically such as infrastructure components like valves, oil/gas pipelines or power transmission lines, located in hard-to-access areas. These inspections consist of having drone devices capture scene images of the assets and validating them against a machine learning model that detects changes to the asset, such as physical damage or physical obstacles that may affect the proper asset\xe2\x80\x99s operation.\nIn this post, we provide an operational overview of the aforementioned asset inspection solution, and then describe how to set up the applicable AWS IoT services:\nAWS IoT Events to manage the asset\xe2\x80\x99s geolocation route\nAmazon SageMaker to detect scene changes\nAmazon S3 and AWS Lambda function to upload asset images and inspect them\nAmazon Simple Notification Service (SNS) to receive notifications of scene changes\nAWS IoT Core for devices\xe2\x80\x99 communication with AWS\nSolution overview\nConsider a scenario where a drone device must follow a specific route to inspect various assets within a large industrial facility. During the inspection, the drone device would stop at each location on the route, in order to capture scene images of the assets. Those images will be sent to AWS and used to detect scene changes. If significant changes are detected, the solution notifies the asset operators.\nThe drone device uses AWS IoT Core to authenticate with AWS and uses the AWS IoT Device SDK for Python.\nThis asset inspection solution involves the following sequence of data and message exchanges:\nThe drone device publishes a notification to AWS IoT Core over a MQTT topic, in order to start the inspection route.\nThe AWS IoT Core rules engine retrieves the notification from the MQTT topic.\nThe AWS IoT Core rules engine sends the notification to AWS IoT Events.\nAWS IoT Events has a detector model that monitors incoming IoT events (e.g. drone device notifications) to start the inspection route (e.g. move the device to the recording scene) by sending a request back to the AWS IoT Core MQTT topic.\nThe device reads the request from the MQTT topic.\nThe device physically moves to a recording area and captures the scene image of the asset.\nThe device uploads the scene image to an Amazon S3 bucket.\nUpon the scene image upload in the bucket, an AWS Lambda function gets executed.\nThe AWS Lambda function requests Amazon SageMaker to detect scene changes in the image uploaded by validating it against a model defined and deployed in Amazon SageMaker.\nIf scene changes were detected, the AWS Lambda function sends a notification message to an Amazon Simple Notification Service (SNS) topic.\nThe end-users subscribed to the SNS topic receive a notification message to inform them of the asset scene changes.\nPre-requisites\nTo follow along and set up the asset inspection solution, be sure to have the following:\nAn AWS account.\nA device or laptop/computer with an access to your AWS account, Python installed, and the AWS IoT Device SDK for Python.\nTo set up AWS IoT Events to manage drone device route\nIn AWS IoT Events, we create the following components to start the drone device\xe2\x80\x99s route:\nOne input representing the notification, sent by the drone device to the AWS Cloud.\nA detector model with two states (and two transitions). Upon receipt of a notification, the device state is changed to \xe2\x80\x9cArea1\xe2\x80\x9d. This state is used to trigger the drone to move to the recording area.\nThe following sections explain how the above components are implemented and how to configure AWS IoT Core to forward the device notification to AWS IoT Events.\nTo create an input in AWS IoT Events\nYou can create an input in AWS IoT Events by following the guide to create an input. In our example, we create an input with the following details:\nAn Input name set to \xe2\x80\x9cdeviceNotifInput\xe2\x80\x9d.\nAn example JSON payload/event with the content below:\n{\n  ""deviceID"": ""1"",\n  ""notifType"": ""StartRoute"",\n  ""dateTm"": ""05/26/2021  08:03:20.200""\n}\nJSON\nTo create and publish a detector model in AWS IoT Events\nIn our example, we create a detector model with the following details:\nTwo states (Stopped and Area1).\nTwo transitions (StartTransition and StopTransition) in order to transition the device from one state to another.\nUpon the reception of a notification from the device, the start transition (StartTransition) triggers the sending of a notification to the outbound AWS IoT Core\xe2\x80\x99s MQTT topic (See Steps 1 to 4 in previous section for further details) and changes the device state from Stopped to Area1.\nTo create a detector model, you can download this sample detector model file and import it into AWS IoT Events by following these steps:\nCreate an IAM role for the Detector Model. For more information, see the documentation for setting up permissions for AWS IoT Events.\nDownload the sample detector model file from the repository at this location.\nUpdate the file with the Detector Model IAM role\xe2\x80\x99s ARN (replace value \xe2\x80\x9c#detectorModelRoleArn#\xe2\x80\x9dwith a value in the following format: arn:aws:iam::account:role/service-role/detectorRoleName).\nGo to AWS Management Console and select AWS IoT Events.\nSelect Create detector model and select Import detector model.\nSelect Import, select the file from your local system and select Open. This will create your Detector Model.\nOnce the Detector Model is created, you can publish it by following the guide Create a Detector Model. In our example, the detector generation model is set to \xe2\x80\x9cCreate a detector for each key value\xe2\x80\x9d with a key set to the deviceID. The Detector evaluation model is set to \xe2\x80\x9cBatch evaluation\xe2\x80\x9d as shown in the below screenshot.\nTo configure AWS IoT Core rules\nAn AWS IoT Core rule needs to be configured to forward device data from AWS IoT Core (MQTT topic) to AWS IoT Events.\nGo to the AWS Management Console and select AWS IoT Core.\nSelect Act, then Rules, and then select the Create button.\nSet the Name for the rule and set the rule query statement to SELECT * FROM \xe2\x80\x98deviceInboundTopic\xe2\x80\x99.\nSelect \xe2\x80\x9cAdd action\xe2\x80\x9d.\nSelect Send a message to an IoT Events Input and then select Configure action as shown in the below screenshot.\nSelect the Input previously created.\nSelect Create Role and enter a role name.\nSelect Add action.\nSelect Create rule.\nTo set up Amazon SageMaker to detect scene changes\nAmazon SageMaker builds a model that evaluates if an asset (i.e. scene image of the asset) changed.\nTo create an Amazon SageMaker model, you can download this notebook and follow the steps:\nCreate an Amazon SageMaker Notebook Instance by following the steps here: Create an Amazon SageMaker Notebook Instance.\nOnce done, select your notebook instance by choosing Open JupyterLab for the JupyterLab interface.\nSelect the Upload Files icon as shown in the following screenshot:\nSelect this this notebook (previously downloaded) in your file system.\nOnce the file is uploaded, select the Create a new folder icon (as shown in the following screenshot), and set the folder name to \xe2\x80\x9cimages.\xe2\x80\x9d\nGo into the images folder and upload images from this location.\nOn the Run tab, select Run All Cells. Once done, your model endpoint should be visible in the Amazon SageMaker console.\nGo to the Amazon SageMaker console.\nSelect Inference and and select Endpoints to confirm the availability of your model endpoint.\nTo upload asset images in Amazon S3 and inspect them with AWS Lambda\nWhen a device captures a scene image, it is uploaded to an Amazon S3 bucket. Then, an AWS Lambda function gets triggered in order to evaluate the image against the Amazon SageMaker model. If changes are detected, the Lambda function publishes a notification to an Amazon Simple Notification Service (SNS) topic.\nIn order to set up this solution, follow these steps:\nAmazon Simple Notification Service setup:\nCreate a SNS topic. For more information, see the Amazon Simple Notification Service Developer Guide and, more specifically, the documentation of the CreateTopic operation in the Amazon Simple Notification Service API Reference.\nSubscribe to a SNS topic by following the guide To Subscribe an Endpoint to an Amazon SNS Topic Using the AWS Management Console.\nAWS Lambda setup:\nCreate an IAM policy with the below JSON policy document. For more information on the procedure, please refer to the steps in the IAM user guide.\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Action"": [\n""sagemaker:InvokeEndpoint""\n],\n""Resource"": [\n""arn:aws:sagemaker:region:account_number:endpoint/#endpoint_name#""\n]\n},\n{\n""Effect"": ""Allow"",\n""Action"": [\n""sns:Publish*""\n],\n""Resource"": [\n""sns_topic_arn""\n]\n}\n]\n}\nJSON\nNote: In the above policy, replace the content in bold with a valid region, account number, Amazon SageMaker endpoint name (Example: linear-learner-2021-01-01-22-39-49-363) and the SNS topic\xe2\x80\x99s ARN (format: arn:aws:sns:region:account:snsTopicName)\nCreate an IAM role for your AWS Lambda function as described in this user guide.\nWhen prompted to select permissions, choose the policy previously created.\nChoose the Amazon managed policy AmazonS3ReadOnlyAccess.\nCreate an AWS Lambda function as described in creating a Lambda function.\nFor the Runtime, choose a Python version (Example: Python 3.8).\nFor the Role, choose the IAM previously created.\nOnce the AWS Lambda function is created, do the following:\nUnder the Configuration tab, go to General Configuration, select the Edit button to set the Memory to 256 (MB) and the Timeout to 1 minute. Then select the Save button.\nUnder the Code tab, go to the Layers section and select the Add a layer button.\nSelect AWS Layers in the Layer source field, choose the AWS Lambda SciPy Layer for Python option.\nSelect a version in the Version field and select the Add button.\nCreate a directory on your computer, download the AWS Lambda source code available at this location and copy it in the directory created.\nIn this directory, open the lambda_function.py file and add a valid Amazon SageMaker Endpoint name (#SAGEMAKER_ENDPOINT_NAME#) and a valid SNS topic\xe2\x80\x99s ARN (#SNS_TOPIC_ARN#). Once done, save the file.\nRun the command: pip3 install \xe2\x80\x93upgrade -r requirements.txt -t . \xe2\x80\x94no-dependencies\nSelect all the files and folders in this directory and create a zip file.\nNote: The Pip version version must match the AWS Lambda\xe2\x80\x99s Python version (Example: Pip 3.8 for Python 3.8).\nIn the AWS Lambda console, go to the Code Source section, select the Upload From button, select the Upload button, select your zip file on your computer, and then select the Save button.\nAmazon S3 setup:\nCreate an Amazon S3 bucket as described in this user guide.\nCreate an Amazon S3 event notification in order to trigger an AWS Lambda function when a new image is uploaded in the Amazon S3 bucket. See the documentation to enable event notifications:\nIn the Event types section, select the \xe2\x80\x9cAll object create events\xe2\x80\x9d event type option (\xe2\x80\x9cs3:ObjectCreated:*\xe2\x80\x9d).\nIn the Destination section, select Lambda function as a Destination type and specify the ARN of the AWS Lambda function previously created.\nTo set up AWS IoT Core for device connection\nCreate device credentials\nYou can create device credentials by following the guides below. Once completed, you will have a certificate, private key, public key and root CA certificate.\nCreate an AWS IoT Core Policy\nCreate Device Credentials and attach IoT Core Policy to a Device Certificate.\nAttach the following policy to the device certificate.\nNote: In the following policy, replace the content in bold with a valid region and AWS account ID.\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Action"": ""iot:Connect"",\n""Resource"": ""arn:aws:iot:region:account:client/clientid""\n},\n{\n""Effect"": ""Allow"",\n""Action"": [""iot:Publish"", ""iot:Receive""],\n""Resource"": ""arn:aws:iot:region:account:topic/deviceInboundTopic""\n},\n{\n""Effect"": ""Allow"",\n""Action"": [""iot:Publish"", ""iot:Receive""],\n""Resource"": ""arn:aws:iot:region:account:topic/deviceOutboundTopic""\n},\n{\n""Effect"": ""Allow"",\n""Action"": [""iot:Subscribe""],\n""Resource"": ""arn:aws:iot:region:account:topicfilter/*""\n}\n]\n}\nJSON\nConnect to AWS IoT Core\nOnce the device credentials are created, you can now connect your IoT device to AWS IoT Core and publish the device notification by following the steps outlined.\nNote: you must install the Python SDK (visit this page) and the AWS IoT Device SDK (visit this page) to run the following code snippets.\nimport boto3\nimport json\nimport logging\nimport time\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\nlogging.basicConfig(filename=\'pythonIotDevice.log\', filemode=\'w\', format=\'%(name)s - %(levelname)s - %(message)s\',level=logging.DEBUG)\nlogger = logging.getLogger(\'pythonIotDevice\')\nlogger.info(""pythonIotDevice"")\n\n#Connection to the AWS IoT Core with Root CA certificate and unique device credentials (keys and certificate) previously retrieved\n# For certificate based connection\nmyMQTTClient = AWSIoTMQTTClient(""clientid"")\n\n# For TLS mutual authentication\nmyMQTTClient.configureEndpoint(""your.iot.endpoint"", 8883) #Provide your AWS IoT Core endpoint (Example: ""abcdef12345-ats.iot.us-east-1.amazonaws.com"")\nmyMQTTClient.configureCredentials(""/root/ca/path"", ""/private/key/path"", ""/certificate/path"") #Set paths for Root CA, for private key and private certificate\n\nmyMQTTClient.configureOfflinePublishQueueing(-1)\nmyMQTTClient.configureDrainingFrequency(2)\nmyMQTTClient.configureConnectDisconnectTimeout(10)\nmyMQTTClient.configureMQTTOperationTimeout(5)\nlogger.info(""Connecting..."")\nmyMQTTClient.connect()\n\n#Publish device notification to AWS IoT Core\ndeviceId = 1\ntimestamp = time.time();\nlogger.info(""Publishing..."")\nmyMQTTClient.publish(""deviceInboundTopic"", ""{\\""deviceID\\"":\\"""" + str(deviceId) + ""\\"",\\""notifType\\"":\\""StartRoute\\"",\\""dateTm\\"":\\""""+ str(timestamp) +""\\""}"", 0)\n\ndef handleResponse(client, userdata, message):\njsonMessage = json.loads(message.payload)\nlogger.info(\'jsonMessage=%s\', jsonMessage)\nlogger.info(""Subscribing..."")\nmyMQTTClient.subscribe(""deviceOutboundTopic"", 1, handleResponse);\n\n#Wait until reception of subscription confirmation (wait 60 seconds)\ntime.sleep(60)\nlogger.info(""Disconnecting..."")\nmyMQTTClient.disconnect()\nPython\nConnect to Amazon S3\nIn order for your device to upload images directly into Amazon S3, AWS IoT Core has a credentials provider that allows you to use the built-in X.509 certificate as the unique device identity to authenticate AWS requests. This eliminates the need to store an access key ID and a secret access key on your device.\nTo set it up, please refer to the documentation for further information on the procedure. Attach the following IAM policy to the IAM role assumed by the credentials provider.\n{\n""Version"": ""2012-10-17"",\n""Statement"": [\n{\n""Effect"": ""Allow"",\n""Action"": ""s3:PutObject"",\n""Resource"": ""arn:aws:s3:::#bucket_name#/*""\n}\n]\n}\nJSON\nNote: Replace the content in bold with the bucket name previously created.\nThe following code snippet only shows how to upload an image to Amazon S3. To run the code snippet, download one of the images from this location. Then, specify its name and path as indicated below:\nimport boto3\nimport json\nimport logging\nimport time\nimport requests\n\nlogging.basicConfig(filename=\'pythonS3IotDevice.log\', filemode=\'w\', format=\'%(name)s - %(levelname)s - %(message)s\',level=logging.DEBUG)\nlogger = logging.getLogger(\'pythonS3IotDevice\')\nlogger.info(""pythonS3IotDevice"")\n\niot_credentials_endpoint=\'https://#iot_credentials_provider_endpoint#/role-aliases/#role_alias#/credentials\' #Provide your AWS IoT Credentials endpoint (Example: ""acbcdef12345.credentials.iot.us-east-1.amazonaws.com"") and the IAM role alias previously created.\n\nresponse = requests.get(iot_credentials_endpoint, cert=(""/certificate/path"", ""/private/key/path"")) #Set paths for private certificate and private key\n\nif response:\ntmp_credentials = response.json()\naccess_key_id = tmp_credentials[\'credentials\'][\'accessKeyId\']\nsecrete_access_key = tmp_credentials[\'credentials\'][\'secretAccessKey\']\nsession_token = tmp_credentials[\'credentials\'][\'sessionToken\']\n\ns3client = boto3.client(\n\'s3\',\naws_access_key_id=access_key_id,\naws_secret_access_key=secrete_access_key,\naws_session_token=session_token,\n)\n\ns3client.upload_file(\'/jpegimage/path\', ""#bucket_name#"", \'#image_name#.jpg\') #Set path for jpeg image to upload. Then specify the bucket name (name of the bucket previously created) and the image name.\nPython\nNote: For further AWS IoT SDK (for Python) samples, please visit this page.\nClean up\nAfter you are done, if you want to ensure that no additional cost is incurred, you can remove the resources provisioned in your account. This includes the deletion of the following resources:\nDelete the AWS Lambda function with the following AWS CLI command: aws lambda delete-function \xe2\x80\x94function-name #lambda_function_name# \xe2\x80\x94region #region#\nDelete the Amazon S3 bucket as explained in this guide.\nClean up the Amazon SageMaker resources (model, endpoint and notebook) as explained in this guide.\nDelete the detector model created in AWS IoT Events with the following AWS CLI command: aws iotevents delete-detector-model \xe2\x80\x94detector-model-name #detector_model_name# \xe2\x80\x94region #region#\nNote that for the above AWS CLI commands:\nThe #lambda_function_name# is the name of the AWS Lambda\xe2\x80\x99s function previously created.\nThe #region# is the AWS region where your resources were created (Example: us-east-1).\nThe #detector_model_name# is the name of the detector model previously created in AWS IoT Events.\n'"
127,"Data ingestion using AWS Step Functions, AWS IoT Events, and AWS IoT Analytics",b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/07/16/BlogIngestData.png,https://aws.amazon.com/blogs/iot/data-ingestion-using-aws-step-functions-aws-iot-events-and-aws-iot-analytics/,"b'A key trend we observe with industrial IoT projects is that new industrial equipment come with out-of-the-box cloud connectivity and allow near real-time processing of sensor data. This makes it possible to immediately generate KPIs allowing to monitor those equipment closely and to optimize their performance. However, a lot of industrial IoT data is still stored in legacy systems (e.g. SCADA systems, messaging systems, on-premises databases) with different formats (e.g. CSV, XML, MIME). This raises multiple challenges concerning the real-time management of that sensor data, such as:\nData transformation orchestration: On-premises industrial data comes from different sources each having their own format and their own communication protocol. It is therefore necessary to find a means to orchestrate the management of all that incoming data, with a view to structure it before analysis.\nEvent driven processing: Batch jobs can introduce latencies in the data management pipeline, which motivates the need for an event-driven architecture to ingest industrial data.\nData enrichment with external sources: Data enrichment is sometimes a mandatory step in order to allow efficient analysis.\nEnhanced data analysis: Complex queries are sometimes needed to generate KPIs.\nEase of maintenance: Companies do not always have the time or the internal resources to deploy and manage complex tools.\nReal-time processing of datasets: Some metrics needs to be constantly monitored, which implies immediate processing of datasets to take actions.\nData integration with other services or applications: Finally, it will be necessary to automate the output of the analysis results to other services which need to process them in real time.\n    In this blog post we show how customers can use AWS Step Functions, AWS IoT Analytics, and AWS IoT Events as the basis of a lightweight architecture to address the aforementioned challenges in a scalable way.\nSolution overview\nIn the use case we discuss in this blog post, we assume that a company is receiving sensor data from its industrial sites through CSV files that are stored in an Amazon S3 bucket. The company has to dynamically process those files to generate key performance indicators (KPIs) every five minutes. We assume the sensor data must be enriched with additional information, such as upper and lower threshold limits, before being stored in Amazon DynamoDB. The flow of data will be constantly monitored so that alarms can be raised if there are missing data records.\nThe AWS CloudFormation template provided with this blog provisions the resources needed to simulate this use case. It includes a built-in data simulator which feeds a Step Functions workflow with CSV files containing sensor data having four fields: 1/ timestamp, 2/ production order id, 3/ asset id, 4/ value. This data is then converted to JSON objects using AWS Lambda functions, which are then forwarded to AWS IoT Analytics to enrich the data (with upper and lower limits) and retrieve it every five minutes by creating a dataset. Finally, this AWS IoT Analytics dataset is sent automatically to AWS IoT Events to be monitored and stored in DynamoDB.\nRefer to the CloudFormation template: iot-data-ingestion.json\nPrerequisites\nFor this walkthrough, you should have the following prerequisites:\nAn AWS account.\nBasic programming knowledge in Python3.8 and SQL.\nBasic knowledge of AWS CloudFormation, Amazon S3, Amazon DynamoDB, AWS Step Functions, AWS IoT Events, and AWS IoT Analytics.\nData simulation\nThe data simulator is coded in Python3.8 and runs in a Lambda function which is invoked every minute via a scheduled Amazon CloudWatch event. The data simulator stores five metrics in a CSV file in an Amazon S3 bucket, as shown in the following image. Those five metrics represent measurements from a production line.\nA production order ID is associated with each metric. This production order ID is changed every 100 invocations of the Lambda function, and for each change, upper and lower limits of the metrics are saved in DynamoDB. These limits will be used to enrich the metrics when processed by AWS IoT Analytics. For example, let\xe2\x80\x99s consider that one of the five metrics represents a revolutions per minute (RPM) measurement on a machine within a production line. Depending on the production order being fulfilled by the production line, the machine may need to be set to run at a specific RPM. Therefore, the upper and lower limits that represent the boundaries of normal operation for the machine will need to be different for each production order. The data simulator will store these upper and lower limits in DynamoDB to represent information from an external data source that will be used to enrich the data generated from the production line (the data stored in the CSV file).\nData preparation\nThe simulated data that represents the data coming from an industrial site is stored in a CSV file. This data must then be converted into a JSON format in order to be ingested by AWS IoT Analytics. Step Functions offer a flexible service to prepare data. So, instead of building a custom monolithic application, we spread the complexity of the data transformation across three Lambda functions, which are sequenced via a JSON canvas. The first Lambda function will format the CSV file into JSON, the second Lambda function will format the data field and append a timestamp, and the third Lambda function will send the data to AWS IoT Analytics. In addition, we have implemented checks to redirect invalid files to an Amazon S3 bucket if there is an error during the execution of the first two Lambda functions to be troubleshooted and reprocessed later.\n  By proceeding in the same way, formats of different file types like MIME or XML could be handled within the same data flow. Getting started with Step Functions is easy because the sequencing is done with a simple JSON file that can be created directly via the Step Functions console which has a graphical interface that clearly identifies the sequencing of each step (see screenshot below). Passing parameters from one Lambda function to another is as easy has manipulating JSON objects.\nThe data preparation architecture uses an event-driven approach, where the saving of the CSV file to Amazon S3 will generate a CloudWatch event that triggers a Step Function to process the CSV file immediately. Let\xe2\x80\x99s consider a scenario where instead we used a batch processing approach, where we have a CSV file containing production line data being stored to Amazon S3 every one minute. In this example we run a batch job every hour to process the CSV files, which will introduce a maximum data processing latency of up to 1 hour to ingest and process the data. However, with an event driven architecture, each CSV file will be processed as soon as it is saved to an Amazon S3 bucket, and eliminate any latency.\nData enrichment and analysis\nWe use AWS IoT Analytics to perform data enrichment and analysis. Four of its components are needed:\nChannels: Collect raw or unprocessed data from external sources, and feed AWS IoT Analytics pipelines.\nPipelines: Clean, filter, transform, and enrich data from AWS IoT Analytics channels.\nData Stores: Store processed data from the AWS IoT Analytics pipeline .\nDatasets: Analyze data with ad-hoc SQL queries on the AWS IoT Analytics data store.\nIn this use case, we used a single AWS IoT Analytics channel. Given the data preparation done by the Step Functions, we assume that all the incoming data are valid and ready to be analyzed. That data will flow through to an AWS IoT Analytics pipeline,which will enrich the metrics with the upper and lower limits sourced from the DynamoDB table, and then routes the data to an AWS IoT Analytics data store. As described earlier, these limits are stored in a DynamoDB table by the data simulator and then queried in AWS IoT Analytics based on the asset id and the production order id.\nWe could have decided to append production line data with the upper and lower limits before sending the record to AWS IoT Analytics, but once the upper and lower limits are stored together with the production measurement data in the AWS IoT Analytics channel, it can\xe2\x80\x99t be updated. However, appending the upper and lower limits through the AWS IoT Analytics pipeline gives the flexibility to replay the records with different limits. For example, if the upper and lower limits associated with the production line data have changed for the previous month, you then just need to reprocess the data using an AWS IoT Analytics pipeline and enrich with the latest limits. Refer to the following diagram for more information.\n\nOnce the enriched data is stored in the AWS IoT Analytics data store the data is ready to be queried. You retrieve data from a data store by creating an AWS IoT Analytics dataset. Datasets are generated using SQL expressions on the data in a data store, and in our use case, the dataset repeats the query every five minutes.\nData Processing\nTo record and monitor the incoming flow of data from AWS IoT Analytics, use AWS IoT Events, which can automatically send the dataset contents to an AWS IoT Events input. In our use case we are sending datasets every five minutes. We use the asset ID as a key by an event detector created in AWS IoT Events for each asset, which then runs custom, pre-defined conditional logic that is triggered by the incoming data and an internal timer.\n  The event detector saves the input data to a DynamoDB table and resets a five minute timer. After this time period, the event detector triggers a message as an input to a second event detector which is used to merge all the incoming messages to send a single consolidated message. Let\xe2\x80\x99s consider a scenario where we are monitoring 100 assets in a manufacturing plant, and every asset is sending an alarm. Without this second event detector identified to output a single alarm on behalf of all those assets, each asset event detector would send its own alarm message that may inundate the target mailbox. This would require additional and time consuming analysis of many email notifications, thereby further delaying any response needed to address the alarms. Because this specific event detector is be able to monitor alarms across the whole site, it can escalate the alarms accordingly.\nCleaning up\nTo avoid incurring future charges, delete the CloudFormation stack.\n'"
128,Real-time monitoring of industrial equipment using Alarms in AWS IoT SiteWise,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/real-time-monitoring-of-industrial-equipment-using-alarms-in-aws-iot-sitewise/,"b'Introduction\nThe Alarms feature in AWS IoT SiteWise allows you to set up, visualize, and manage rule-based alerts for devices, equipment, and processes. You can receive alerts via SMS or email in near-real time when equipment data breaches thresholds, allowing operations teams to take timely actions to reduce unplanned equipment downtime. AWS IoT SiteWise Alarms is powered by AWS IoT Events and is tightly integrated with it, so you can create alarms from the AWS IoT SiteWise console, AWS IoT SiteWise Monitor web applications, or using the AWS IoT SiteWise SDK. In this blog, we demonstrate the integrated Alarms experience in AWS IoT SiteWise and AWS IoT SiteWise Monitor. We create alarms in AWS IoT SiteWise and monitor them in AWS IoT SiteWise and AWS IoT SiteWise Monitor.\nNote, you can also create, monitor and manage Alarms directly in AWS IoT Events, independently of AWS IoT SiteWise. To learn more about this, please see Monitoring with alarms in the AWS IoT Events Developer Guide.\nTo create an alarm for any incoming equipment data, there are three high level steps:\nDefine an alarm rule to apply e.g. rotations per minute is greater than a certain value\nSelect the severity of this alarm e.g. an integer between 1-5 to indicate increasing importance\nConfigure notifications to send when an alarm is triggered e.g. email and SMS and/or trigger other AWS services\nTo illustrate, we use a real-life application example of Clean-In-Place (CIP) systems. CIP systems are used in manufacturing facilities that produce food & beverages, biotech and pharmaceutical products to clean equipment without disassembly (i.e. \xe2\x80\x9cin place\xe2\x80\x9d) to neutralize flavors and clear any residues from previous cycles. For efficient cleaning, plant operators need to maintain prescribed temperatures for cleaning fluids such as caustic liquid. In our example, we will monitor the temperature of caustic liquid using Alarms and raise notifications when the temperature falls below a pre-set threshold.\nCreating an asset model\nWe start with creating an asset model in AWS IoT SiteWise, that is used to create a virtual representation of a CIP system. In a real-world scenario there are likely to be multiple CIP systems being monitored, which can be grouped based on equipment type, location or other criteria. For this example, we create a CIP System asset model and a CIP Group asset model to contain multiple CIP Systems. For details on how to create asset models in AWS IoT SiteWise see Creating asset models.\n  Next we define some measurements (e.g., raw data from sensors) relevant to the CIP Systems asset model, as shown in the following image. They represent tank and temperature levels for tanks containing different types of cleaning fluids.\n  In the CIP System asset model we also created an attribute Caustic Temperature Threshold to store a temperature threshold value of 40 \xc2\xb0C. We use this attribute value later when creating the alarm to monitor a tank\xe2\x80\x99s temperature.\n  Creating assets\nHaving created the asset models, we now create the assets themselves. The CIP Group asset represents a grouping of multiple CIP systems, based on a common criteria such as location. We also create two CIP system assets CIP System 1 and CIP System 2 and add them under the asset CIP Group. While such grouping is not required for the creation of Alarms, we are doing so to organize our assets aligned with real-world scenarios.\n  The CIP system assets in AWS IoT SiteWise need to get data from actual CIP systems. This often uses OPC-UA a communication protocol for industrial automation applications. OPC-UA data is organized as aliases and these need to be mapped to each of the assets\xe2\x80\x99 measurements. For more details on this process, please see the mapping industrial data streams documentation. Once this is done, data starts streaming into the CIP system in AWS IoT SiteWise.\nDefining an Alarm\nSo far, we\xe2\x80\x99ve modeled our CIP system, instantiated virtual CIP system assets, and started streaming data directly into each asset from their OPC-UA servers. Now, we define alarms for when our CIP systems\xe2\x80\x99 operating parameters fall out of control bounds.\nAs an example, we create an alarm for when the caustic tank\xe2\x80\x99s temperature falls below a specified value. Alarms are created as part of the asset model, in this case the CIP System asset model. By creating alarms as part of the asset model, all assets created using this model will automatically be set up for this alarm with a default configuration. The alarm configuration can be updated for each individual asset, subsequently created using this asset model.\nAs we start, the asset model has no alarms defined yet.\n  We add our first alarm definition, named CausticTemperatureAlarm, to the asset model. AWS IoT SiteWise Alarms are evaluated by the AWS IoT Events service, so the default Alarm type is AWS IoT Events alarm.\nThe other alarm type, External alarm, refers to alarms that are generated in other alarm detection and management systems, outside of AWS IoT SiteWise. To consolidate your alarms you can also ingest these into AWS IoT SiteWise. We don\xe2\x80\x99t cover this type of alarm in this post, but you can read more about ingesting external alarm state here.\n  The threshold definition for the alarm specifies when to trigger the alarm, based on the value of a property meeting a specific condition. For CIP systems, it\xe2\x80\x99s important for the fluid in the caustic tank to be at a temperature higher than 40 \xc2\xb0C, so we set up the threshold for when the Caustic Tank Temperature is less than the Caustic Temperature Threshold. You\xe2\x80\x99ll recall that Caustic Temperature Threshold was created earlier and set to 40 \xc2\xb0C (see Creating Asset Models above).\n  Optionally, you can also configure email and text notifications for this alarm. Note that the AWS Single Sign-On service must be enabled and the users added in the current region for them to show up as valid destinations.\nIn addition to email and text notifications, to integrate alarm notifications with your own ticketing systems, you can also configure actions to other AWS services such as AWS Lambda, Amazon Simple Queue Service (SQS), and Amazon Simple Notification Service (SNS), to be executed when an alarm triggers. For example, you can call an AWS Lambda function to trigger and cause an update to a ticketing system, and also update an Amazon DynamoDB table. You can find details of all supported actions here.\nIn our example, we send both email and text notifications.\n  We\xe2\x80\x99ll set the Default asset state as Enabled and save the alarm by clicking Add alarm. The Enabled state ensures that all assets created from this asset model will have this alarm evaluated by default.\n  The CausticTemperatureAlarm alarm can now be seen in the Alarm definitions tab of the CIP System asset model page.\n  Alarm monitoring\nWe can now see the alarm and its status in the Asset details page. The caustic tank temperature is within normal limits, so the status is shown as Normal.\n  Next, to demonstrate an alarm being raised, we cause CausticTemperatureAlarm to trigger. We\xe2\x80\x99ll do this by varying the caustic tank temperature, using simulated input values. We do not cover this simulation method in this blog.\nWe also created a dashboard using AWS IoT SiteWise Monitor to visualize the alarms. For creating dashboards in AWS IoT SiteWise Monitor, see this guide.\nThe AWS IoT SiteWise Monitor screen below shows the simulated temperature values for CIP System 1. After remaining steady at 50 \xc2\xb0C, the temperature starts dropping and eventually breaches the 40 \xc2\xb0C temperature threshold setup earlier.\n  The Asset details page now shows an Active alarm. If notifications were set up, those would have triggered as well.\nThe Actions button shows your response options for Active alarms. You can Acknowledge the alarm indicating receipt, Snooze it for a period (after which the alarm returns to active), or Reset it. In a typical industrial process, an operator sees the alarm, and then acknowledges it to indicate the start of the problem identification and resolution process. We will mimic this workflow and Acknowledge the alarm. For more details on the alarm lifecycle, see the documentation section on Alarm states.\n  Once the alarm has been acknowledged, the alarm status changes to Acknowledged. The operational team is thus made aware that the alarm is being investigated. For more details on the other options and the alarm lifecycle, see the documentation on Alarm states.\n  '"
129,Improving Product Quality with Cognizant APEx 2.0 and AWS IoT SiteWise Edge,b'Vishal Gupta',2021-08-23T03:28:31+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/29/SWE-Launch-Fig1-v2-1024x474.png,https://aws.amazon.com/blogs/iot/improving-product-quality-with-cognizant-apex-2-0-and-aws-iot-sitewise-edge/,"b'Introduction\nConditions created by COVID-19 stressed supply chains around the world, while exponentially increasing demand for certain products such as personal protective equipment (PPE) overnight. As a result, manufacturers globally are seeking creative solutions to boost their production output. Often, the fastest way to boost output is not by adding additional capacity, but by reducing the waste in the production process. Poor product quality is one of the largest sources of such waste in manufacturing. It is also one of the hardest types of waste to tackle at scale. Many manufacturers rely on manual methods such as visual inspection to detect quality issues. This approach only works on a limited scale when the rate of production is such that quality inspectors can keep up with it. Advances in computer vision technology and edge processing infrastructure means that these manufacturers can equip their quality inspection teams with tools that can help them catch defects that would have otherwise gone undetected at scale.\nIn this post, we describe how a discrete manufacturer can detect quality issues through real-time analysis of product images using the Asset Performance Excellence (APEx 2.0) solution provided by Cognizant. This solution uses the SiteWise Edge feature of AWS IoT SiteWise to process metrics for operators on the plant floor\nMonitoring quality\nIn high volume production scenarios there are multiple stakeholders involved in managing quality. The workflow to manage product quality can become quite complex depending on the size of the production operation and the type of product. As a result, it is helpful to establish a few fundamental metrics that can give quick insight into product quality. Three common metrics quantifying quality are yield, scrap rate, and rework rate. Yield indicates the share of parts with acceptable quality within a batch. Scrap rate indicates how many parts in a batch have to be discarded due to defects. Rework rate indicates how many parts in a batch are reprocessed to remove defects. These metrics can help operators develop an initial hypothesis about the quality performance of their process before they dive deeper. For example, a process with a higher scrap rate than rework rate indicates that most defects lead to loss of product. This process may be a greater cause for concern than one which has a higher rework rate indicating that most defects are repairable. Armed with this information, operators can focus on the processes causing the greatest waste to identify the most recurring defects among the scrapped products.\nAPEx 2.0 using AWS IoT SiteWise Edge simplifies this process for operators through a managed quality monitoring experience that can run entirely on-premises. In this solution, APEx 2.0 gathers product images from cameras mounted on the production lines and utilizes computer vision to infer defects in parts produced. It also collects information about parts scrapped and reworked from external manufacturing systems. It then uses SiteWise Edge to compute the yield, scrap, and rework metrics for its custom operator application. Additionally, this application of APEx 2.0 uses machine learning models to describe the quality issues that it detects through the images. For example, it can specify if a particular defect is a crack in the part or missing pieces in a product assembly, making it easy for operators to find the most recurring defect.\nMonitoring experience\nAPEx 2.0 is a solution accelerator built to enable specific use cases and speed up the time to value for end users, while also remaining flexible for myriad applications. In this application of APEx 2.0, it is being used to provide visibility to the Overall Equipment Effectiveness (OEE) of the plant and its machines, and uses image analytics to determine part quality while running the entire application on premises.\nThis APEx 2.0 application is designed for plant managers and technicians responsible for production. A plant manager can start by selecting the production station or work cell they want to check for performance. The application displays top level metrics (such as yield, scrap rate, cycle time, and OEE) as an overview. Plant managers often rotate across shifts. Production jobs can also vary by shift. For example, beverage processing customers often use the same equipment or workstation to process different types of beverages in different shifts. The application lets them select a shift from a drop-down menu to view data for that given shift rather than all the shifts. For the selected shift, the plant manager may notice that the scrap rate is higher than expected. They can then select the metric to view a historical trend to understand when exactly during the shift the scrap rate began to rise at that particular work station.\nOnce the plant manager identifies the time, they can switch to the Inspection Details tab to get information about specific scrap or rework events that occurred during that time. The application displays each event on a timeline. The plant manager can select each event to see the image of the part to understand the type of defect. The images are annotated by the application to show areas of interest used to infer the defect. Additional information such as part number and type of defect inferred is also stated. This information can help the plant manager quickly identify the potential issues with the machine and engage the technicians on the plant floor. Additionally, they can use the part number information to physically locate and inspect the part to develop further understanding.\nAPEx 2.0 architecture using SiteWise Edge\nAPEx 2.0 unifies data from multiple industrial systems and derives insights to drive excellence across operations, resources and asset performance. The solution incorporates a library of key performance indicators (KPIs), for example, OEE, scrap ratio, and yield that follow ISO 22400 standards. The solution helps to build dashboards at the machine level, plant level, and organizational level.\nAPEx 2.0 is built using AWS IoT SiteWise. Normally, functions such as calculations, data storage, and the visualization are hosted in a cloud based environment. However, as described earlier in the post this will not meet requirements for all use cases.\nSiteWise Edge enables APEx 2.0 to run locally on the customer\xe2\x80\x99s premises while minimizing architectural and code changes. This enables advanced analytics, such as fault detection and visual inspection, without the need to send large amounts of data or sensitive data to the cloud. The production stations and work cells are defined in AWS IoT SiteWise as asset models with measures, transforms, and metrics corresponding to the relevant data and computations. The asset models are cached locally on the edge, with a sync occurring every ten minutes or on-demand via the local configuration interface.\nThis solution collects machine data from OPC-UA servers and image data from plant cameras through the AWS IoT SiteWise gateway. It uses custom functions, deployed as Docker containers and AWS Lambda functions, to process the images in the gateway and pass inference results to SiteWise Edge data processing software for metric computation. SiteWise Edge software is packaged as Greengrass components. This means partners like Cognizant can extend it using their own custom AWS IoT Greengrass components. They use the AWS IoT Greengrass stream manager to transfer data between components. This simplifies development of edge applications such as APEx 2.0. For example, to pass inference results to SiteWise Edge, the image processing function simply writes it to the AWS IoT Greengrass Stream consumed by the SiteWise Edge Data Processing pack. Image and metric data is stored locally on the gateway for offline availability. This solution runs all necessary API and front end services needed to render the application experience in containers that are also deployed using AWS IoT Greengrass.\nSiteWise Edge provides data collection and processing capabilities in the SiteWise gateway for local applications enabled by the Data Processing pack and Data Collection pack. The Data Collection pack is used to retrieve data from the OPC-UA server. Data configured in the asset models is accepted and processed by the Data Processing pack via AWS IoT Greengrass Streams. When data arrives to the Data Processing pack, transforms are performed immediately while metrics are calculated at intervals specified in the asset models. All of the incoming data and computed values are stored on the gateway, but this is configurable in the asset models based on the need to send some or all of the data to the AWS IoT SiteWise service in the cloud. SiteWise Edge supports retaining this data at the edge for up to 30 days (granted sufficient disk space is available on the gateway). Other application processes on the gateway are able to retrieve the data via API calls with those calls remaining local to the device in this particular solution. As a result, Cognizant was able to focus on developing differentiated features by integrating with foundational functionality provided by SiteWise Edge.\nFunctional overview\nFunctions to perform advanced aggregations, image classification, image annotation, and process orchestration are integrated with the SiteWise Edge functionality to provide a differentiated customer experience.\nThe ImageAnalytics function performs both image annotation and image classification. Specifically, it annotates key features of the image, such as the location and orientation of elements. The function makes a decision on the quality of the part, or a classification, and passes the result to SiteWise Edge for eventual use in the OEE calculation function. Key observations from the image are also generated and are used to identify trends in failed parts. The inferred results are then routed back to the asset model in SiteWise Edge for persistence by the Orchestrator via an AWS IoT Greengrass Stream. The quality of the part as well as the key observations are stored within the Data Processing pack on the gateway.\nThe AdvancedAggregation function post processes metrics computed by SiteWise Edge. For example, in this solution it computes cumulative shiftwise results which are the results over a given period of time and in this case from the beginning of a shift. This enables customers to view cumulative shiftwise OEE calculations in near real time rather than a single batch of post processed results at the end of the day. Specifically, the AdvancedAggregation function calls SiteWise Edge to retrieve data and combines this with shift data from a local postgreSQL database to compute the overall OEE for the shift. The result is stored in SiteWise Edge via an AWS IoT Greengrass Stream for future computations or visualization.\nUse of SiteWise Edge also helps Cognizant minimize the differences between the cloud and edge deployments of the APEx 2.0 solution, which reduces development and operating costs while ensuring a consistent customer experience. Key pieces of the architecture include asset models configured in AWS IoT SiteWise, the ImageAnalytics and AdvancedAggregation functions, the VisualizationAPI data access layer, and the user interface components are portable between the cloud and edge. The asset models configured for cloud-based deployments are automatically replicated to the edge and kept up to date by SiteWise Edge. The same measurements, transforms, and metrics expressions are supported at the edge allowing seamless re-use of existing models and the infrastructure to configure them.\nThe ImageAnalytics and AdvancedAggregation functions run in containers. These containers can be deployed and orchestrated via AWS IoT Greengrass enabling the use of the same business logic between the cloud deployment and the edge deployment. Furthermore, the user interface and data access layers are also containerized and deployed to the edge device.\nTo develop the edge solution, the configuration of the containers and functions was simply reconfigured to read data from an edge endpoint. No code changes were needed since SiteWise Edge supports the same data retrieval APIs available in the cloud. This hybrid developer experience reduces the need to maintain separate code bases for the edge and cloud solutions and simplifies testing of the many functions. It also simplifies the support requirements for the end customer who might be using both edge and cloud solutions for their factories.\n'"
130,Register Now for Alexa Live 2021 to Invent the Future of Ambient Computing—Together,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/07/12/alexa-live-blog-post.png,https://aws.amazon.com/blogs/iot/register-now-for-alexa-live-2021-to-invent-the-future-of-ambient-computing-together/,"b'Consumers are increasingly turning to AI assistants such as Amazon Alexa to control other devices in their home and automate simple, monotonous tasks. As such, AWS customers building smart consumers products are increasingly added Alexa voice to their devices, either by ensuring their devices Work With Alexa or have Alexa Built-in. For example, AWS IoT customer Vizio was able to quickly and easily add Amazon Alexa to millions of televisions already in their consumer\xe2\x80\x99s home using AWS IoT and Alexa Skills. Another customer, iDevices, brought an Alexa Built-in light switch to market in 4 months (a 78% reduction from their normal development cycle) using the Alexa Voice Service (AVS) Integration for AWS IoT Core and a FreeRTOS-enabled certified hardware development kit from AWS partner NXP. Another customer, Traeger Grills, added Amazon Alexa to their connected grills not only for voice control capabilities, but also to create a personality for their devices.\nAmazon\xe2\x80\x99s vision for Amazon Alexa is an ambient assistant that is proactive, personal, and predictable. Its mission is to make Alexa available and delightful everywhere customers want her to be, and the Alexa developer community is critical to helping us achieve this. That\xe2\x80\x99s why we are so excited for Alexa Live to return on July 21 and we can\xe2\x80\x99t wait to celebrate the latest innovations from Alexa developers and partners, together.\nThe Amazon Alexa team has been hard at work building new tools and features and are excited to share the latest advancements designed to help drive business growth, improve productivity, and deliver more delightful customer experiences. Learn more about Alexa Live, and register now to save your spot for July 21 and check out the agenda to start planning which sessions you want to attend.'"
131,Choose the right AWS video service for your use case,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/25/AWSVideoServices.png,https://aws.amazon.com/blogs/iot/choose-the-right-aws-video-service-for-your-use-case/,"b'Today, customers rely on video enabled data, audio data and time-encoded data for many use cases, including live streaming, home security, video on demand, predictive maintenance in industrial settings or doing peer video chats at work. Many organizations and consumers are embracing video enabled technology to improve their professional and personal interactions. The result is a rapid growth in the number and type of use cases including video integrated with AI/ML, interactivity and content protection.\nThis blog post will provide an overview of each AWS video service along with common use cases which will help you make an informed decision about which solution is the right one for you.\nTo meet the growing and diverse needs of different video use cases, AWS offers four video services which include Amazon Kinesis Video Streams, the AWS Elemental Media Services, Amazon Interactive Video Streaming, and Amazon Chime.\nService\nDescription\nCharacteristics\nUse Case\nKinesis Video Streams\nFully managed service\nto securely stream video\nfrom connected devices\nto AWS for analytics,\nmachine learning (ML), playback, and other\nprocessing\nMany to one \xe2\x80\xa2 Predictive Maintenance\n\xe2\x80\xa2 Smart Cities\n\xe2\x80\xa2 Smart Homes\nKinesis Video Streams WebRTC\nFully managed service to\nlive stream media or\nperform two-way audio\nor video interaction\nTwo way interactive video and audio \xe2\x80\xa2 Telehealth and virtual care\n\xe2\x80\xa2 Real time media streaming in Connected Cars and V2X\n\xe2\x80\xa2 Augment customer experience\nAWS Elemental Media Services\nBroadcast-grade live video\nprocessing services that\nincorporate many solutions\nOne to many \xe2\x80\xa2 Primary broadcast distribution\n\xe2\x80\xa2 Live OTT video streaming\nAmazon IVS\nManaged live streaming\nsolution that is quick\nand easy to set up, and\nideal for creating interactive\nvideo experiences\nOne to many \xe2\x80\xa2 Social chat with streaming content\n\xe2\x80\xa2 Votes and Polls\n\xe2\x80\xa2 E-commerce and alternative revenue\nAmazon Chime\nCommunications service\nthat lets you meet, chat,\nand place business calls\ninside and outside your\norganization, all using a single application\nOne to one or one to many \xe2\x80\xa2 Business chat\n\xe2\x80\xa2 Audio and video conference\n\xe2\x80\xa2 Online meetings\nAmazon Kinesis Video Streams\nKinesis Video Streams, together with AWS IoT, makes it easy for customers to build video enabled products and services, for solutions that can be deployed in smart cities, smart homes, industrial automation, digital twin use cases and of course a lot more.\nKinesis Video Streams provides Software Development Kits (SDKs) that you can download and install on your connected camera device to securely stream video and audio data to Kinesis Video Streams for analytics and storage. The SDKs, which are available for popular device-oriented development environments, receive data from the device\xe2\x80\x99s media source and manage the entire lifecycle of the stream as it is transmitted from the media source to the Kinesis video stream.\nNeosperience is using Kinesis Video Streams to simplify their video streaming requirements and to integrate with AI/ML.\nCommon use cases for Kinesis Video Streams\nIndustrial automation \xe2\x80\x93 predictive maintenance\nSmart cities \xe2\x80\x93 AMBER alert system                                                                                                                                                                                                                                             \nSmart home \xe2\x80\x93 pet monitor\n  Amazon Kinesis Video Streams with WebRTC\nKinesis Video Streams also supports real-time media streaming via WebRTC. WebRTC is an open-source project that incorporates the required technology for real time communication (RTC) of audio, video and data in web and native apps via APIs. WebRTC is supported on all major browsers on desktops, laptops, tablets and smart phones. Libraries supporting WebRTC make it straightforward to add WebRTC support to a mobile phone or desktop app without the need of custom plugins. Media streams are secure and encrypted with Secure Real Time Protocol (SRTP).\nWYZE is using Kinesis Video Streams with WebRTC to accelerate their live streaming capabilities.\nLive Video Streaming workflow with Amazon Kinesis Video Streams with WebRTC                                                                                                                                               \nKinesis Video Streams provides a standards-compliant WebRTC implementation as a fully managed capability. You can use Kinesis Video Streams with WebRTC to securely live stream media or perform two-way audio or video interaction between any camera IoT device and WebRTC-compliant mobile or web players. As a fully managed capability, you don\xe2\x80\x99t have to build, operate, or scale any WebRTC-related cloud infrastructure, such as signaling or media relay servers to securely stream media across applications and devices.\nUsing Kinesis Video Streams with WebRTC, you can easily build applications for live peer-to-peer media streaming, or real-time audio or video interactivity between camera IoT devices, web browsers, and mobile devices for a variety of use cases. Typical use cases include interactive video and audio between a video doorbell or baby monitor or your automobile and your mobile phone, video chat and peer-to-peer media streaming. Some advanced automotive use-cases include: a) high-definition sensor sharing \xe2\x80\x93 AV lane change, b) see-through for pass maneuvers, c) tele-operated driving, d) obstructed view assist, e) infrastructure assisted environment perception (requirements from 5G Automotive Association).\n  Comparison of Kinesis Video Streams with WebRTC and Kinesis Video Streams\nKinesis Video Streams with WebRTC is for real time communication, which is defined as sub-second latency and 2-way communication. Kinesis Video Streams with WebRTC current implementation supports 1:1 or 1:N scenarios. For 1 to N communication, each stream is unique. You cannot ingest data into the cloud for storage or processing through this capability. Kinesis Video Streams can ingest audio and video and throttles based on the number of fragments requested rather than the number of playback sessions. This gives developers the flexibility to enable up to 10x more simultaneous playback sessions for applications that use Kinesis Video Streams for live or on-demand playback. Kinesis Video Streams HTTPS streaming capability supports use cases that require streaming data into AWS ( supported by the video stream ARN) for storage and processing \xe2\x80\x93 live and on-demand playback via HLS/DASH, and real-time or batch-mode processing for machine learning. The ingestion path is supported by the\nKinesis Video Streams producer SDKs that are available in Java, C/C++, and for Android. The best case live playback latency in this case can range between 3-6 second depending on device capabilities, a limitation that stems from HLS and DASH being fragment based protocols. For adaptive bitrate streaming that would define a decode ladder to adjust to various bandwidths and screen sizes, please refer to the following blog post (https://aws.amazon.com/blogs/media/introducing-automated-abr-adaptive-bit-rate-configuration-a-better-way-to-encode-vod-content-using-aws-elemental-mediaconvert/).\nCommon use cases for Kinesis Video Streams with WebRTC\nVideo chat using Kinesis Video Streams with WebRTC                                                                                                                                                                                                         \nTelehealth and virtual care in the cloud: COVID-19 pandemic has highlighted the fundamental importance of providing non-COVID-19 related outpatient and inpatient care in clinical settings without exposing patients and health care providers to the virus.\nBecause WebRTC is a protocol that allows applications to connect to each other in a Peer-to-Peer fashion, there is no intermediary server transferring data between the two parties once the connection is established through the signaling process. Confidential information is never stored in the cloud and patient information is encrypted in transit over the internet.\nReal time media streaming in connected cars and vehicle to everything (V2X): V2X is a term that refers to high-bandwidth, low latency, and highly reliable communication between vehicle to vehicle (V2V) and vehicle to infrastructure (V2I) communications. If a vehicle is involved in an accident, the vehicle can live stream the feed on WebRTC while using location awareness so emergency services can call for help as necessary.\nThere is a new concept emerging called road side units (RSU\xe2\x80\x99s) and when vehicles approach that geographical zone as defined on a map, information is sent to them using the cellular network. RSU cameras can capture video and turn it into a regular webRTC flow that provides a high perspective of the environment such as parked vehicles or road obstacles. Because this transformation does not require transcoding, it has a low processing load and lossless conversion.\nIn the sharing economy, number anonymity creates a secure, professional barrier in the un-traditional business models at play. With webRTC, ridesharing companies can replace phone masking with the feature of VOIP calling Contextual applications to augment customer experience within websites and applications as a tool for sales enablement.\nWebRTC provides a seamless, non-invasive way to connect and collaborate. Massive files can be shared using the webRTC\xe2\x80\x99s data channel with very low latency and the benefit of full encryption between the two end points.\nAWS Elemental Media Services\nAWS Elemental Media Services provide our broadcast-grade live video processing functionality. The combination of services lets you create high-quality video streams for delivery to broadcast televisions and internet-connected multi-screen devices, like connected TVs, tablets, smart phones, and set-top boxes. For example, AWS Elemental MediaLive works by encoding your live video streams in real-time, taking a larger-sized live video source and compressing it into smaller versions for distribution to your viewers.\nDishTV are using the AWS Elemental Media Services and the AWS cloud to create \xe2\x80\x9csticky\xe2\x80\x9d customer experiences, improve engagement and reduce churn.\n\nCommon use cases for AWS Elemental Media Services\nPrimary broadcast distribution                                                                                                                                                                                                                                                       \nLive OTT video streaming optimized for low end-to-end latency\nAmazon Interactive Video Service\nAmazon IVS is a managed live streaming solution that is quick and easy to set up, and ideal for creating interactive video experiences. Send your live streams to Amazon IVS using streaming software and the service does everything you need to make low-latency live video available to any viewer around the world, letting you focus on building interactive experiences alongside the live video. You can easily customize and enhance the audience experience through the Amazon IVS player SDK and timed metadata APIs, allowing you to build a more valuable relationship with your viewers on your own websites and applications.\nViacomCBS are using Amazon IVS to serve their users in a faster and more flexible way than ever before.\nCommon use cases for Amazon IVS\nAmazon Chime\nAmazon Chime is a communications service that transforms online meetings with an application that is secure and comprehensive. Amazon Chime works across your devices so that you can stay connected and allows you to share your desktop or video during a work meeting or conference. The service has been built with the capabilities and functionality, such as flexibility to completely customize end user experience and multi party video options, required to make these types of interactions of a high quality.\nConnexity Inc leverages Amazon Chime for their video conferencing needs.\nCommon use cases for Amazon Chime\nSummary\nMore customers across all industries are using video services to drive new ways to engage and connect with each other. Now that you know the benefits and use cases for each services, you can choose the right AWS video service to enable you to deliver great quality video to your internal teams, customer organizations, and home users alike.\nUse the comparison chart at beginning of the blog to help you select the most suitable video service for your needs. Rather than investing effort on managing IoT and media streaming infrastructure, you can focus on core competencies and accelerate your time to value.\nTo learn more about the services and start building, explore the following articles, sample applications, and workshops.\nhttps://github.com/awslabs/amazon-kinesis-video-streams-webrtc-sdk-js\nhttps://github.com/awslabs/amazon-kinesis-video-streams-webrtc-sdk-c\nhttps://github.com/awslabs/amazon-kinesis-video-streams-producer-sdk-cpp\nhttps://github.com/awslabs/amazon-kinesis-video-streams-producer-sdk-java\nhttps://video-streaming-and-analysis.workshop.aws/en/\nhttps://ivs-streaming.workshop.aws/en/\nhttps://aws.amazon.com/blogs/media/part1-how-to-set-up-a-resilient-end-to-end-live-workflow/'"
132,Implementing Local Client Devices with AWS IoT Greengrass,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/24/MQTT-Device-Architecture-1024x481.png,https://aws.amazon.com/blogs/iot/implementing-local-client-devices-with-aws-iot-greengrass/,"b'AWS IoT Greengrass is an open source edge runtime and cloud service that helps you build, deploy, and manage device software at the edge. AWS IoT Greengrass Version 2.2.0 now includes support for local clients and devices (client devices) to locally connect to an AWS IoT Greengrass Core using MQTT. Client devices can securely send and receive messages using the Message Queuing Telemetry Transport protocol (MQTT), either to AWS IoT Core in the cloud, or communicate with other components via the Interprocess communication feature (IPC).\nThese new capabilities simplify the security, connectivity, and delivery of messages using AWS IoT Greengrass. This provides a seamless transition between things using AWS IoT Core for communication and the local AWS IoT Greengrass Core by using the same X.509 client certificate, MQTT connection, and MQTT topic namespace for interacting with messages.\nIn this blog post I describe use cases for client devices using a local AWS IoT Greengrass Core for connectivity, messaging, and interaction with IPC-enabled components. I step through the process for configuring and deploying the AWS IoT Greengrass components for MQTT, and how client devices are authorized to connect and communicate on set topics. I then demonstrate local MQTT messaging, messaging to AWS IoT Core, and IPC interoperability from a client device perspective.\nThe audiences for this blog post are architects or developers creating edge compute solutions who are familiar with setting up and operating AWS IoT Greengrass Version 2. If you are new to AWS IoT Greengrass or currently using AWS IoT Greengrass Version 1.x, please read What is AWS IoT Greengrass (Version 2) and step through the Getting started tutorial to familiarize yourself with the terminology and operation of AWS IoT Greengrass Version 2.\nOverview\nTo illustrate the client device and local MQTT broker capabilities, I will use the following architecture to demonstrate client device interaction:\nIn this architecture, there are two client devices, thing1 and thing2, both configured and authorized to connect to the local MQTT broker. I will refer to them as things when describing resources in AWS IoT Core, and when connecting and interacting with AWS IoT Greengrass, will refer to them as client devices. Once connected to AWS IoT Greengrass, the client devices can publish and subscribe to MQTT topics for different local use-cases such as communication with other devices, local shadows, and to AWS IoT Core topics and shadows in the cloud.\nTo demonstrate the different usage patterns, I show the component configuration for client devices thing1 and thing2 communicating through the local MQTT broker, how the client devices can publish and subscribe to topics mirrored in the cloud, and how they can also interact with other components via the IPC.\nFor demonstration purposes, overly permissive policies are used. For production deployments, please refer to the Service role permissions for core devices and the Minimal AWS IoT policy for AWS IoT Greengrass V2 core devices documentation pages for limiting permissions needed by AWS IoT Greengrass.\nDeploy the client devices components\nThere are three client device components that make up the local MQTT environment for client devices to connect and communicate. By using these components, the client devices thing1 and thing2 will communicate locally with AWS IoT Greengrass and not require an MQTT connection to AWS IoT Core in the cloud. I will add all three of the components to a new or revised deployment and describe the use and configuration details for each.\nThe first component is the Moquette MQTT broker component ( aws.greengrass.clientdevices.mqtt.Moquette), which is the local MQTT broker that will be used by the client devices for native MQTT communication, and used by the MQTT bridge component for translation to and from the IPC publish and subscribe capability. This component is based on a fork of the open source Moquette Project MQTT compliant broker. The default configuration values will have Moquette bind to all network interfaces and only use the default MQTT secure SSL communication listening on port 8883. These value can be changed by the merge update process.\nThe next component is the MQTT bridge component ( aws.greengrass.clientdevices.mqtt.Bridge), which relays MQTT messages between client devices, local AWS IoT Greengrass publish/subscribe, and AWS IoT Core. You use this component to route messages between the Moquette MQTT broker component (LocalMqtt) and either AWS IoT Core (IotCore) or the IPC (Pubsub). I will use the following merge update to allow the local client devices to access an AWS IoT Core topic, and to allow messages published on AWS IoT Core to be received locally by the same client devices :\n{\n  ""mqttTopicMapping"": {\n    ""ClientDevicesToCloud"": {\n      ""topic"": ""from_local/hello/world"",\n      ""source"": ""LocalMqtt"",\n      ""target"": ""IotCore""\n    },\n    ""CloudToClientDevices"": {\n      ""topic"": ""from_cloud/hello/world"",\n      ""source"": ""IotCore"",\n      ""target"": ""LocalMqtt""\n    }\n  }\n}\nJSON\nIn this merge update JSON document for the MQTT bridge component, I set up one mapping that listens for messages on the from_local/hello/world topic from the local MQTT broker and then publishes that message to to the same topic on AWS IoT Core in the cloud. The second mapping is the reverse where the MQTT bridge is subscribed to the from_cloud/hello/world topic on AWS IoT Core. When a message is received on that topic, the MQTT bridge component will publish it to the same topic on the local MQTT broker.\nWhen configuring for your own use, make sure to not configure any source and target mappings that use the same topic, otherwise this will cause an infinite message loop. For example, if the topic hello/world was used in the configuration above for both mappings, a message published on hello/world to the local MQTT broker would be published on AWS IoT Core. This would then be seen as a message being received on AWS IoT Core, and then re-published back to the Moquette MQTT broker in an infinite loop. If there is request-response pattern using MQTT, use one topic for the publishing requests such as cmd/my_topic/request, and a separate response topic such as cmd/my_topic/response to subscribe for the responses. This pattern is described in the IoT Atlas.\nWith the MQTT bridge component merge configuration applied, the final component to be deployed is the Client device auth component (aws.greengrass.clientdevices.Auth), which authenticates client devices and authorizes client device actions. The component performs this by matching AWS IoT Core thing names to client devices, and then applying a policy that informs the MQTT broker as to what MQTT operations and topics client devices can act upon. The merge update below will reference thing1 and thing2, and then authorize them to communicate locally on a topic, and also to access the from_local/hello/world and from_cloud/hello/world topics:\n{\n  ""deviceGroups"": {\n    ""formatVersion"": ""2021-03-05"",\n    ""definitions"": {\n      ""MyDeviceGroup"": {\n        ""selectionRule"": ""thingName: thing1 OR thingName: thing2"",\n        ""policyName"": ""MyBlogPostPolicy""\n      }\n    },\n    ""policies"": {\n      ""MyBlogPostPolicy"": {\n        ""AllowConnect"": {\n          ""statementDescription"": ""Allow connections with matching clientId"",\n          ""operations"": [""mqtt:connect""],\n          ""resources"": [""mqtt:clientId:thing1"", ""mqtt:clientId:thing2""]\n        },\n        ""AllowLocalPublish"": {\n          ""statementDescription"": ""Allow client devices to publish on LOCAL test/topic"",\n          ""operations"": [""mqtt:publish""],\n          ""resources"": [""mqtt:topic:test/topic""]\n        },\n        ""AllowLocalSubscribe"": {\n          ""statementDescription"": ""Allow client devices to subscribe to LOCAL test/topic/response"",\n          ""operations"": [""mqtt:subscribe""],\n          ""resources"": [""mqtt:topicfilter:test/topic/response""]\n        },\n        ""AllowSubscribeToCloud"": {\n          ""statementDescription"": ""Allow client devices to subscribe to the AWS Cloud originated topic"",\n          ""operations"": [""mqtt:subscribe""],\n          ""resources"": [""mqtt:topicfilter:from_cloud/hello/world""]\n        },\n        ""AllowPublishToCloud"": {\n          ""statementDescription"": ""Allow client devices to publish on a local topic that will be sent to the AWS Cloud"",\n          ""operations"": [""mqtt:publish""],\n          ""resources"": [""mqtt:topic:from_local/hello/world""]\n        }\n      }\n    }\n  }\n}\nJSON\nVerify connectivity, local, and cloud messaging\nWhen the Client device auth component is deployed, it will perform a variety of operations to configure the Moquette MQTT broker component. First, it will create a list of thing names in AWS IoT Core that match the selectionRule, which is this case would be to include thing1 and thing2. Next, with the list of things to include as client devices, the Client device auth component will then transfer the attached thing certificates to the AWS IoT Greengrass Core and configure the Moquette MQTT broker component to use them for mutual TLS authentication. Finally, the Client device auth policy or policies are applied to the Moquette MQTT broker component. This enforces what client devices are able to connect to the local AWS IoT Greengrass Core Moquette MQTT broker (via the mqtt:connect operation) and what MQTT topics each thing can subscribe to or publish messages.\nWith all three components added and configured to a deployment, the AWS IoT Greengrass Core will download the newly added components and configure. You can verify the status of the deployment by looking in the $GG_ROOT/logs/greengrass.log file and monitor for client device connections, subscriptions, and publish operations, as seen in this output from the log file:\n[INFO] (nioEventLoopGroup-3-8) com.aws.greengrass.device.DeviceAuthClient: Creating new session. {}\n[INFO] (nioEventLoopGroup-3-8) io.moquette.broker.metrics.MQTTMessageLogger: C->B CONNECT <null>. {}\n[INFO] (nioEventLoopGroup-3-8) com.aws.greengrass.mqttbroker.ClientDeviceAuthorizer: Retrieved client session. {clientId=thing1, sessionId=81843a7e-b7d7-4e23-b94a-7492d2039dd6}\n[INFO] (nioEventLoopGroup-3-8) com.aws.greengrass.mqttbroker.ClientDeviceAuthorizer: Successfully authenticated client device. {clientId=thing1, sessionId=81843a7e-b7d7-4e23-b94a-7492d2039dd6}\n[INFO] (nioEventLoopGroup-3-8) io.moquette.broker.metrics.MQTTMessageLogger: C->B SUBSCRIBE <thing1> to topics [MqttTopicSubscription[topicFilter=test/topic/response, option=SubscriptionOption[qos=AT_LEAST_ONCE, noLocal=false, retainAsPublished=false, retainHandling=SEND_AT_SUBSCRIBE]]]. {}\n[INFO] (nioEventLoopGroup-3-8) io.moquette.broker.metrics.MQTTMessageLogger: C<-B SUBACK <thing1> packetID <36810>, grantedQoses [1]. {}\n[INFO] (nioEventLoopGroup-3-8) io.moquette.broker.metrics.MQTTMessageLogger: C->B SUBSCRIBE <thing1> to topics [MqttTopicSubscription[topicFilter=from_cloud/hello/world, option=SubscriptionOption[qos=AT_LEAST_ONCE, noLocal=false, retainAsPublished=false, retainHandling=SEND_AT_SUBSCRIBE]]]. {}\n[INFO] (nioEventLoopGroup-3-8) io.moquette.broker.metrics.MQTTMessageLogger: C<-B SUBACK <thing1> packetID <36811>, grantedQoses [1]. {}\nXML\nAs seen from the log file, thing1 connects to the Moquette MQTT broker and subscribes to the local response topic test/topic/response and also to the topic from_cloud/hello/world that receive messages from AWS IoT Core. Besides client device entries, all MQTT operations will be logged such as publishes, connections, and disconnections.\nTo perform the testing, I created the Node-RED flow below with an MQTT configuration for thing1 that simultaneously publishes a message on both the local test/topic and from_local/hello/world topics. Each box represents an operation taking place, with the flow from left to right. The nodes in white are comments to describe the two different sections.\nIt is important understand the MQTT configuration when connecting and validating a connection to the Moquette MQTT broker from a client device. The X.509 server certificate used by the Moquette MQTT broker has special attributes that client devices use to validate the endpoint to connect, and also the signing certificate authority. While this capability is included in the AWS IoT Device SDKs, it does require additional understanding when using other MQTT clients such as Node-RED. Please refer to the Interact with local IoT devices section of the AWS IoT Greengrass documentation for more details.\nWithin the same Node-RED flow I also have the Subscribe to local responses\xe2\x80\xa6 section, where thing1 is subscribed to the test/topic/response (local) and from_cloud/hello/world (AWS cloud) topics. The top flow demonstrates how messages are published, and the bottom flow receives and processes messages from the subscribed topics.\nWith thing1 connected, clicking on the publish hello world message node sends a sample message to the two topics on the Moquette MQTT broker. The message to test/topic will be processed by the Moquette MQTT broker component and delivered to a local component (not shown, it is the operation shown by the arrow from the processed by component node). This local component will then publish a response to the test/topic/response topic to which thing1 is also subscribed. The Received message text in the debug window verifies the message was received and processed by the local component back to thing1.\nIn parallel, the second message to the from_local/hello/world topic is forwarded to AWS IoT Core by the MQTT bridge component. To confirm messages being sent and received to AWS IoT Core, I navigate in the AWS console to AWS IoT Core \xe2\x86\x92 Test \xe2\x86\x92 MQTT test client and subscribe to the from_local/hello/world topic, and click on the publish hello world message node again. In the AWS console, from the Subscriptions for the topic, I then see the message that was published to the Moquette MQTT broker and processed by the MQTT bridge component has been delivered to AWS IoT Core:\nTo test the reverse message flow from AWS IoT Core to the local AWS IoT Greengrass MQTT broker, I enter from_cloud/hello/world in the Topic name field, I then create a response in the Message payload text box, and finally select the Publish button to send the message. I see it arrive in the Debug messages pane within Node-RED configuration for thing1 subscribed to the same topic on the Moquette MQTT broker on the AWS IoT Greengrass Core.\nWith the verified output from both local-to-local, mapped local-to-cloud, and cloud-to-local, you now have the ability configure, authenticate, and authorize client devices with the provided Moquette MQTT broker.\nBridging IPC and local MQTT topics\nThe MQTT bridge component can also create mappings between the IPC and the Moquette MQTT broker for bidirectional communication. If you require IPC component communication directly to only an AWS IoT Core topic, instead of using the MQTT bridge component, use the AWS IoT Core MQTT messaging IPC service instead.\nFor instance, in the above example where I discuss the processed by component node, this is a local component that subscribes to test/topic via the IPC instead of MQTT. When it receives a message it then copies the content and publishes it on the test/topic/response topic along with a count of the times has been invoked since startup. To accomplish this client device interaction with the local component, I update the MQTT bridge component configuration to map the topics to and from the Pubsub mapping which is used by custom components. Here is the updated MQTT bridge component merge update with the addition of LocalMqtt to Pubsub for topic/test,and Pubsub to LocalMqtt for topic/test/response:\n{\n  ""mqttTopicMapping"": {\n    ""ClientDevicesToCloud"": {\n      ""topic"": ""from_local/hello/world"",\n      ""source"": ""LocalMqtt"",\n      ""target"": ""IotCore""\n    },\n    ""CloudToClientDevices"": {\n      ""topic"": ""from_cloud/hello/world"",\n      ""source"": ""IotCore"",\n      ""target"": ""LocalMqtt""\n    },\n    ""DevicesToIpc"": {\n      ""topic"": ""test/topic"",\n      ""source"": ""LocalMqtt"",\n      ""target"": ""Pubsub""\n    },\n    ""IpcToDevices"": {\n      ""topic"": ""test/topic/response"",\n      ""source"": ""Pubsub"",\n      ""target"": ""LocalMqtt""\n    }\n  }\n}\nJSON\nWith this configuration deployed to the AWS IoT Greengrass Core, a client device can use MQTT to send and receive messages, and the local component can use the IPC functionality to act on messages without requiring an MQTT connection.\nClient device best practices\nThe client device capabilities provided by the new Moquette MQTT broker, MQTT bridge, and Client device auth components allows for secure and flexible communication between an MQTT device (client device) and local MQTT broker, AWS IoT Core topics, and with custom components via IPC. Here are some best practices when implementing client devices.\nClient devices require access public AWS IoT Greengrass endpoints\nIn order for a client device to connect to the AWS IoT Greengrass Core, it will need to know the local IP address, hostname, and the certificate authority that signed the server certificate used by the MQTT broker. To accomplish this, the client device will need to make an authenticated call to the public endpoint which will return the needed information.\nThis discovery process uses the client device\xe2\x80\x99s X.509 certificate and private key to authenticate when making an API call. While this can be performed through a regular RESTful call and processing the results, the AWS IoT Device SDKs, Mobile SDKs, and AWS IoT Device Client have the AWS IoT Greengrass Core discovery functionality built in. Using these SDKs for client device provide not only general MQTT capabilities but also the full discovery process. If you are using your own MQTT libraries, please refer to the Interact with local IoT devices documentation for full details.\nUse the IPC for component communication where possible\nWhile client devices with X.509 certificates can use MQTT for their communication, AWS IoT Greengrass components should use the IPC method for all of their publish and subscribe operations. The IPC supports the same fine-grained security controls on a per-component basis and doesn\xe2\x80\x99t require the overhead of an MQTT protocol stack. Finally, the IPC support interoperability with both the local Moquette MQTT broker via the MQTT bridge component and publish/subscribe IPC service, and to the AWS IoT Core via the AWS IoT Core MQTT messaging IPC service.\nThe only time you would use the client device pattern is if your components are written in a programming language where an AWS IoT device SDK exists. In that case you can have a component act as a client device, but you will have to manage the creation of a thing and certificate in AWS IoT Core.\nModel and test all topic interactions between the Moquette MQTT broker, IPC, and AWS IoT Core\nWhen creating client devices interaction between the Moquette MQTT broker and other services, it is recommended to map out the message flows. By mapping publish to subscribe operations, you can visualize and refine interactions. This can also help to ensure that message loops between the Moquette MQTT broker and AWS IoT Core do not take place.\nOnce you have mapped the interactions, a series of test cases for all potential interactions can help verify the Client devices auth component permissions are properly setup.\nSummary\nIn this blog post I described the new client device functionality of AWS IoT Greengrass and demonstrated some example patterns of usage. The examples show how client devices can communication locally with each other or via AWS IoT Greengrass Core using the Moquette MQTT broker component. I also showed how local messages between the Moquette MQTT broker, AWS IoT Core, and components using the IPC can be routed and acted upon.\nWith this overview, you should now be able to incorporate your existing AWS IoT things into new or existing AWS IoT Greengrass Version 2 deployments. For more details on how to interact with client devices and the components used, please refer to the documentation pages here:\nInteract with local IoT devices\nMoquette MQTT broker component\nMQTT bridge component\nClient device auth component\nTo become familiar with other AWS IoT Greengrass features and capabilities, here are some additional links to documentation and workshops:\nWhat\xe2\x80\x99s new \xe2\x80\x93 Summary page of release notes describing new features and changes\nAWS-provided components \xe2\x80\x93 All public components available for inclusion into an AWS IoT Greengrass deployment\nPerforming machine learning inference \xe2\x80\x93 A popular use-case for using AWS IoT Greengrass ML inference and how it works\nAWS IoT Greengrass v2 workshop \xe2\x80\x93 Self-paced workshop that goes through setup and main features of AWS IoT Greengrass Version 2'"
133,Secondary sensing and actuation for factories using AWS IoT and CloudRail Gateways,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/secondary-sensing-and-actuation-for-factories-using-aws-iot-and-cloudrail-gateways/,"b'Post also contributed by Felix Kollmar, Co-Founder and CEO of CloudRail.\nIntroduction\nSmart Manufacturing applications such as condition monitoring, predictive analytics, and predictive quality require real-time, granular, rich, and easily accessible process data. Manufacturing uses a hierarchical structure of systems, commonly referred to as the ISA-95 automation pyramid. The two lower layers of the pyramid are the Programmable Logic Controllers (PLC), and the real-time automation network, both on the factory floor. PLCs control industrial equipment using software, sensors and actuators connected via input-output interfaces. Data collected from equipment by PLCs enables applications in the upper layers of the pyramid develop smart manufacturing solutions.\nGreenfield environments are sites with new automation equipment that provide out-of-box secure connectivity outside the Operations Technology (OT) network. This connectivity allows Information Technology (IT) software applications on-premises and in the cloud to access rich, granular data sets from manufacturing equipment. Facilities that have decades old legacy equipment which may not have process data available, or unlocking data from them involves significant effort to bridge OT and IT networks, are called brownfield environments. In this blog, we discuss overlay solutions using sensors and actuators that make it possible to implement smart manufacturing applications in brownfield environments.\nChallenges in brownfield scenarios\nBrownfield facilities encounter the following challenges:\nThere are facilities where mechanisms have been built in the past to extract process data from PLCs into local Data Historians or local Andon type applications on the factory floor. For these scenarios, we recommend using the  Industrial Machine Connectivity on AWS Quick Start solution, and third party software such like Ignition from Inductive Automation and KepServerEx from PTC as an intermediary for translation from the myriad of proprietary industrial automation protocols to the OPC UA (IEC 62541) or MQTT protocols. OPC UA is being widely adopted as a standard in the manufacturing domain.\nThere are facilities where extraction of data from PLCs may be impractical for a variety of reasons. Existing PLCs might be operating in a legacy environment where the risk of re-programming the PLC to unlock data from the field network outweighs the benefit of data extraction. Or, a PLC in operation might not support the required communication interfaces. Often facilities have PLCs from several vendors, further complicating data access.\nSimilar challenges exist for configuration and control of PLCs. A challenge with brownfield environments is that OT personnel is often concerned about making networking changes to legacy environments from a security perspective, and a secondary sensing mechanism can overcome that.\nIn this blog, we propose sensing and actuation solutions for customers with brownfield facilities, by using secondary sensing. Secondary sensing is a non-invasive way to add edge gateways and sensors to an existing production site to enable more data collection which can be used to improve operational efficiencies and productivity without impacting production downtime.\nSolution overview\nWe recommend two secondary sensing and actuation solutions:\nIn order to avoid re-programming and impacting the real-time operations controlled by a PLC, deploy an edge gateway running AWS IoT Greengrass and the AWS IoT SiteWise connector in the facility to directly tap into an existing real-time network of sensors. This will provide the mechanism for the edge gateway to extract data from the industrial automation system and exchange data with the AWS Cloud by creating additional data sources.\nDeploy a new set of sensors and actuators connected to an edge gateway running AWS IoT Greengrass and the AWS IoT SiteWise connector on the factory floor using a completely separate field network. As in the previous scenario, the edge gateway will exchange data with the AWS Cloud by creating an additional secondary communication channel.\nThe two approaches discussed above can be implemented together or separately. Both solutions use key AWS IoT services such as AWS IoT Greengrass, AWS IoT SiteWise, and AWS IoT Core.\nBuilding blocks for accelerating Industry 4.0\nBy ingesting process data at the edge and leveraging a large set of services in the AWS Cloud, applications can be developed to provide sophisticated insights for various operational and business stakeholders.\nEdge Ingestion: This block provides an interface for ingestion of sensor readings, PLC tag data and Historian data, as well as for command and control with the edge gateway running AWS IoT Greengrass.\nEdge Processing: This provides a variety of capability such as conversion from various industrial protocols to a standard. Various types of data processing can include dead-banding (filtering out irrelevant fluctuations in tag readings), downsampling (reducing the frequency of collection of data that does not change rapidly). Other capabilities at the edge include data buffering (to avoid loss when cloud connectivity is unreliable), local data storage, local ML Inferencing (object detection and image classification). This block also ensures secure communication with the OT network on one hand, and the cloud on the other.\nCloud Ingestion: AWS Cloud ingestion endpoints can be AWS IoT Core for sensor data, AWS IoT SiteWise (for PLC/Historian data points, Amazon Kinesis (for streaming data and video), Amazon S3 (for any generic data upload). These data ingestion endpoints in the AWS cloud facilitate the creation of a Data Lake. Data in the data lake can be cleansing, contextualized, transformed and enriched using AWS analytics services (AWS Glue, Amazon Athena, Amazon EMR, etc) to create datasets that can be visualized using tools such as Amazon QuickSight.\nCloud Processing: Here, data is accessed from the Data Lake to perform analytics, generate and train AI/ML models, run inferencing & data visualization using AWS services such as AWS Glue, Amazon Athena, Amazon Redshift, Amazon SageMaker, Amazon QuickSight. ML models trained in the cloud can also be deployed to AWS IoT Greengrass running on the edge gateway for local inferencing. Additional custom applications can be developed for various user personas.\nSelecting an AWS IoT-qualified edge gateway\nAWS provides many qualified third party hardware options for customers to choose from to implement a secondary sensing solution on their factory floor. The choices can be found in the AWS Partner Device Catalog. It is important that you pick a gateway device that is qualified for AWS IoT Greengrass for AWS connectivity, and provides the physical interfaces required for communication with the sensors and actuators. They can be analog serial based protocols such as RS232/RS422/RS485 for Modbus RTU/ASCII variants, CAN Bus, USB, or digital protocols such as EthernetIP or Modbus TCP.\nIn the remainder of this blog, we will dive deep into a solution that we have assembled and tested using a AWS IoT Greengrass-qualified edge gateway device from CloudRail.\nThe CloudRail edge gateway connects with both AWS IoT Core and AWS IoT SiteWise services in the cloud and optionally runs AWS IoT Greengrass for data preprocessing. Within a factory environment, CloudRail has developed a secondary sensor and actuator architecture primarily around the IO-Link field protocol, and cloud connectivity using an Ethernet interface. The box is DIN rail mountable and provides Ingress Protection (IP 20) suitable for a factory environment.\nIO-Link (see FAQs) is a PLC standard (IEC 61131-9:2013 Programmable controllers \xe2\x80\x93 Part 9: Single-drop digital communication interface for small sensors and actuators (SDCI)) for a serial communication protocol that allows three types of data to be exchanged \xe2\x80\x93 process data, service data, and events.\nIO-Link uses point-to-point connectivity between a IO-Link Master device and sensors rather than a message bus topology. Multiple IO Masters can be connected to the CloudRail gateway box via an Ethernet connection. This allows a single gateway to support sensors and actuators across longer runs within a factory floor. Hundreds of IO-Link based sensors and actuators are supported by vendors such as IFM, Turck, Sick, Pepperl+Fuchs, or Balluff . The CloudRail solution also supports Digital I/O (0-24V) sensors as well as Analog (4-20mA) sensors using an Analog to IO-Link Adapter. A design guide can be found at IO-Link Design Guide.\nSensing solution architecture using an AWS IoT-qualified edge gateway from CloudRail\nThe four scenarios depicted in the diagram allow customers the flexibility to choose the best data ingest mechanism based on their use case.\nProxying sensor data to AWS IoT Core with local processing using AWS Lambda on AWS IoT Greengrass: Data from sensors enters the CloudRail gateway through an IO-Link Master device. Protocol conversion from IO-Link to MQTT is performed by custom logic at ingress to the edge gateway and the payload is transmitted to the AWS IoT Greengrass MQTT Broker in order to invoke a Lambda function. The Lambda function performs user defined custom logic and forwards the resulting data to IoT Core through a secure internet connection on the gateway.\nProxying sensor data to AWS IoT Core without local processing: Data from sensors enters the CloudRail gateway through a IO-Link Master. Protocol conversion from IO-Link to MQTT is performed by custom logic at ingress and the payload is transmitted to AWS IoT Core through a secure internet connection on the gateway.\nProxying sensor data to AWS IoT SiteWise without local processing: Data from sensors enters the CloudRail gateway through a IO-Link Master. Protocol conversion from IO-Link to AWS IoT SiteWise format is performed by custom logic at ingress and the payload is transmitted to AWS IoT SiteWise using the BatchPutAPI through a secure internet connection on the gateway.\nProxying OPC UA tag data to AWS IoT SiteWise without local processing: The CloudRail box has implemented an OPC UA client that can connect to an OPC UA Server to ingest PLC Tag Data from PLCs that support translation from a multitude to automation protocols to OPC UA. By connecting securely with the OPC UA Server, PLC tag data can be ingested into the CloudRail gateway, and transmitted to AWS IoT SiteWise using the BatchPutAPI through a secure internet connection on the gateway.\nActuation solution architecture using an AWS IoT-qualified edge gateway from CloudRail\nThe three actuator scenarios depicted in the diagram are as follows:\nConfiguration and command from an end application from AWS IoT Core via AWS IoT Greengrass: Configuration and command messages issued from the end application enters the CloudRail gateway through a secure MQTT connection between AWS IoT Core and AWS IoT Greengrass Core. A subscription can be configured on AWS IoT Greengrass Core such that the MQTT message landing on a topic can invoke a Lambda function. The Lambda function could implement some conditional logic and message forwarding to the IO-Link protocol converter. Protocol conversion from MQTT to IO-Link is performed here and the payload is transmitted to the actuator via the IO-Link Master.\nConfiguration and command from an end application from AWS IoT Core to IO-Link without local AWS IoT Greengrass processing: Configuration and command messages issued from the end application enters the CloudRail gateway through a secure MQTT connection between IoT Core and a MQTT Broker coexisting with the IO-Link protocol converter. Protocol conversion from MQTT to IO-Link is performed here along with any conditional logic before the payload is transmitted to the actuator via the IO-Link Master.\nConfiguration and command from an end application from AWS IoT Core to OPC-UA server without local AWS IoT Greengrass processing: Configuration and command messages issued from the end application enters the CloudRail gateway through a secure MQTT connection between IoT Core and a MQTT Broker coexisting with OPC UA Client. Protocol conversion from MQTT to OPC UA is performed here along with any conditional logic before the payload is transmitted to the OPC UA Server. The OPC UA Server then performs the configuration update or command on the target PLC.\nSetting up the CloudRail solution with AWS IoT\nCloudRail works with over 12,000 compatible industrial sensors supporting the IO-Link standard. These include digital sensors as well as analog ones that can be connected using an IO-Link adaptor. Sensors are connected to IO-modules, which talk to the CloudRail gateway via Ethernet. While the CloudRail gateway needs to be enclosed in an IP20-rated cabinet, the IO-modules are IP67-rated and can be mounted directly on the machine. One CloudRail gateway can be simultaneously connected with hundreds of IO-modules at the same time.\nExample Scenario:\nIn the following example, we have a RFID reader, an IO-Link Hub, a CloudRail gateway, and all the necessary connectors cables. You can find these components in the AWS Partner Device Catalog. We connect the RFID reader to AWS using CloudRail, and receive RFID tag data as a stream of MQTT messages in AWS IoT Core.\nWe first connect the RFID Reader as the sensor to the gateway via the IO-Link hub as shown in the diagram below. Upon power up, the CloudRail gateway automatically detects all connected IO-modules and sensors.\nWe then log in to the CloudRail management portal at https://devices.cloudrail.com/login and create an account if it has not already been created before. The RFID reader will appear in the list of discovered devices.\nNext, we select AWS IoT Core and name the sensor. CloudRail supports multiple AWS IoT services. We can choose between a direct connection to AWS IoT Core or AWS IoT SiteWise, or can connect the sensor to a local AWS IoT Greengrass instance running on the CloudRail gateway.\nCloudRail will automatically add and configures sensors as new devices in the AWS IoT Core through an API, retrieve the necessary certificates and configures the local MQTT client. All this happens automatically in the background. We are provided an auto-generated MQTT topic as well as the data schema documentation.\nAt this point the sensor is connected to AWS IoT Core and starts sending data to AWS IoT Core in an automatically generated JSON format. This allows the developers to immediately start building applications using the sensor data as is without needing to do any data transformation.\n'"
134,"“AWS is how”: LG Electronics makes life good with smarter, happier homes",b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/24/LG3_AWSishow_June2021-1.jpeg,https://aws.amazon.com/blogs/iot/aws-is-how-lg-electronics-makes-life-good-with-smarter-happier-homes/,"b'The dream of creating a smart home, where all appliances and electronics could be controlled from a central computer hub, began to take shape in 1965, when a Westinghouse engineer, Jim Sutherland, developed the first home computer, the ECHO IV. Sutherland integrated the ECHO IV into his home\xe2\x80\x99s electronic systems, and he and his family used it to control their clocks, stereo, thermostat, TV, and typewriter. After living with the ECHO IV, Southerland\xe2\x80\x99s wife, Ruth, speculated on the future of home computers, saying, \xe2\x80\x9cWouldn\xe2\x80\x99t it be wonderful if they could provide more time for parents to spend with their children, making every home a happier one?\xe2\x80\x9d\nWe\xe2\x80\x99ve come a long way from using a home computer to set our clocks and thermostats. It\xe2\x80\x99s now common practice for us to turn off home appliances from our mobile phones and use Amazon Alexa to play music in our houses while we\xe2\x80\x99re making dinner. But even these tasks, as remarkable as they would have been to Jim and Ruth Sutherland, are just the tip of the smart home iceberg.\nLG Electronics shares Ruth Sutherland\xe2\x80\x99s vision of the smart home as a happier home. With the widest assortment of internet-enabled appliances and one app to control them all, LG not only helps simplify our daily lives\xe2\x80\x94it gives us easy-to-use tools for being more efficient, proactive, and environmentally responsible.\nThe LG ThinQ platform, which runs on AWS, allows you to control LG ThinQ smart appliances with your voice and cell phone. For LG customers, \xe2\x80\x9ccontrol\xe2\x80\x9d means more than simply \xe2\x80\x9cturning on and turning off.\xe2\x80\x9d Using AI, LG ThinQ can learn your preferences to make relevant recommendations and offer tips based on your habits and the status of your devices. For example, ThinQ learns when you tend to get ice from your refrigerator and makes sure that ice is always available at that time of day.\nYou can also use the ThinQ app to put your smart LG refrigerator in vacation mode\xe2\x80\x94from anywhere you are\xe2\x80\x94to save energy while you\xe2\x80\x99re away from home. When you\xe2\x80\x99re running errands, you can check the app to see how much time is left on your wash cycle and confirm that you can make one more stop before heading home to put your sheets into the dryer. On movie night, as you relax on your sofa, you can use a single voice command to tell ThinQ to adjust your lighting and television, creating the best possible viewing experience. (ThinQ works with Amazon Alexa for voice control, and LG Smart TVs have Alexa built right in.)\nAnother valuable ThinQ feature is Proactive Customer Care, which helps keep LG appliances performing at their best. ThinQ uses a data lake, built on AWS, to analyze big data and anticipate appliance issues before they arise. Based on usage data gathered from your LG appliances, ThinQ automatically sends you contextual alerts and helpful reports. A notification from your clothes washer, for example, could tell you that you\xe2\x80\x99ve added too much detergent and need to reduce the amount and run a Tub Clean cycle before your next load. And a message from your refrigerator could indicate that it\xe2\x80\x99s time to change the water filter and also provide a filter finder to help you shop.\nOver 30% of consumers who\xe2\x80\x99ve received Proactive Customer Care alerts have been able to fix appliance problems on their own, eliminating the need for a service call. Plus, the alert feature helps keep your appliances in \xe2\x80\x9ctip top shape,\xe2\x80\x9d improving efficiency and durability while saving energy.\nHow does AWS help LG make homes smarter and more connected? A key word is: \xe2\x80\x9cscalability.\xe2\x80\x9d AWS provides the flexible, global infrastructure that enables ThinQ to support a growing number of customers, devices, and appliances around the world. For storing, managing, and analyzing the data that brings intelligence to ThinQ, LG relies on AWS secure, resizable, cost-efficient services. These include Amazon Elastic Compute Cloud (Amazon EC2) with the fastest processors in the cloud; Amazon Relational Database Service (Amazon RDS), which is easy to set up, operate, and scale; and Amazon Simple Storage Solution (Amazon S3), offering industry-leading scalability, data availability, and performance.\nPowering smart homes and creating personalized experiences depends on collecting and exchanging appliance data, and LG gets help from AWS in this area as well. The company employs AWS IoT services, which are easy to use and bring together data management and rich analytics. AWS IoT services integrate with other AWS services, allowing LG to build complete solutions. Plus, AWS IoT services scale to billions of devices and trillions of messages, helping ensure that LG can keep innovating to bring more intelligence\xe2\x80\x94and more happiness\xe2\x80\x94to more homes around the world.\nYou can see how LG makes homes smarter and happier in the new \xe2\x80\x9cAWS is how\xe2\x80\x9d ad campaign.\nLearn more about how AWS helps customers build smart products and services in the cloud. And check out the list of LG products that were honored with 2021 CES\xc2\xae Innovation Awards and the LG press event at CES 2020.'"
135,"AWS is How: Carrier improves occupant health with Abound, a healthy building solution",b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/18/Abound-1.jpg,https://aws.amazon.com/blogs/iot/aws-is-how-carrier-abound-healthy-building-solution/,"b'Earlier this year, Carrier Global Corporation, a leading global provider of healthy, safe, and sustainable building and cold chain solutions, launched Abound by Carrier. This launch is part of Carrier\xe2\x80\x99s growing investment in digital solutions designed to give people confidence in the health and safety of their indoor environments. Abound is a cloud-native, open technology platform that aggregates data from different systems and sensors and provides building owners, operators, and occupants transparency into contextually relevant insights about air quality, thermal comfort, and other performance data. In this blog post, learn how Carrier built on AWS, combining AWS IoT and analytics services, to quickly deliver an innovative healthy building solution and value to customers.\nThe Abound platform connects directly to existing building systems and sensors with no need for upgrades, retrofitting, or replacements. What\xe2\x80\x99s more, unlike other building management platforms, Abound is designed to easily work with all systems, regardless of manufacturer, to unlock and unite siloed data to provide more powerful, actionable insights. The platform can be installed and scaled quickly, and showcases data on a single pane of glass and via remote readings.\nThe Abound platform works by connecting building systems and sensors to AWS IoT Core, which streams data into the Carrier IoT Action Engine. This uses AWS IoT rule actions, Amazon Kinesis, and AWS Lambda functions to process data into the appropriate Abound platform service (e.g., command, alarm, asset snapshot, asset history). From there, end users such as building owners, operators, and occupants can access the insights they need through a smart, simple interface. Or, via Abound\xe2\x80\x99s application programming interface (API), users can also access insights through responsive display generators for in-building digital displays, mobile applications, or existing digital experiences. With access to insights, like indoor air quality, they can enjoy peace of mind or take action to improve it.\n\xe2\x80\x9cThe launch of Abound underscores Carrier\xe2\x80\x99s leadership in digital innovation and ability to move quickly to exceed our customers\xe2\x80\x99 needs. The platform came together in a fraction of a year and I couldn\xe2\x80\x99t be prouder of the team,\xe2\x80\x9d said Bobby George, Carrier\xe2\x80\x99s Senior Vice President & Chief Digital Officer. \xe2\x80\x9cAbound\xe2\x80\x99s platform architecture was designed around open standards and modern cloud native technologies and users can quickly adapt it to a wide range of integration, connectivity, and scaling needs. The platform is comprehensive and delivers value to our customers through the complete integration of software, hardware, and digital analytics.\xe2\x80\x9d\nThe Abound digital platform will also enable building operators to benchmark building performance related to air quality, ventilation, and humidity against thresholds identified for certain air features within the WELL Building Standard (WELL) from the International WELL Building Institute, a global authority on healthy buildings. Building owners will have the ability to display real-time information and messaging about a building\xe2\x80\x99s health through the Abound API, which can be used to create digital wallboards and support mobile experiences.\nAbound is currently being piloted across the U.S. with customers in the commercial building, K-12 education, entertainment, and sports industries, including at Truist Park, home to the Atlanta Braves. It is also operating at Carrier\xe2\x80\x99s world headquarters and building technology showcase, the Center for Intelligent Buildings, in Palm Beach Gardens, Florida.\nAbound is the latest solution from Carrier that is built using AWS services. In February 2020, Carrier selected AWS as its preferred cloud provider to drive digital transformation. Then, in October 2020, Carrier announced the co-development of Carrier\xe2\x80\x99s new Lynx digital platform\xe2\x80\x94a suite of tools that provide Carrier customers around the world enhanced visibility, increased connectivity, and actionable intelligence across their cold chain operations to improve outcomes for temperature-sensitive cargo, including food, medicine, and vaccines. The Lynx platform, too, uses AWS IoT, analytics, and machines learning services to extend Carrier\xe2\x80\x99s existing digital offerings for managing the temperature-controlled transport and storage of perishables. Lynx was recently recognized among Fast Company\xe2\x80\x99s 2021 World Changing Ideas.\nLearn more about Abound by Carrier and Carrier\xe2\x80\x99s Lynx digital platform.'"
136,How to access and display files from Amazon S3 on IoT devices with AWS IoT EduKit,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/06/04/iot-edukit-png-highlight.jpg,https://aws.amazon.com/blogs/iot/how-to-access-and-display-files-from-amazon-s3-on-iot-devices-with-aws-iot-edukit/,"b'AWS IoT EduKit is designed to help students, experienced engineers, and professionals get hands-on experience with IoT and AWS technologies by building end-to-end IoT applications. The AWS IoT EduKit reference hardware is sold by our manufacturing partner M5Stack. Self-paced guides are available online. The code and tutorial content are open to the community to contribute via their respective GitHub repositories. In this blog post, I walk you through how to access files from Amazon S3 and display them on IoT devices. You\xe2\x80\x99ll learn how to download and display PNG images on a M5Stack Core 2 for AWS IoT EduKit. I use the AWS IoT EduKit tutorial, \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d as my starting point.\nAt the time of writing, there are five easy-to-follow tutorials and sample code that makes it simple to get started with AWS IoT EduKit. The first tutorial walks you through the process of setting up your environment and uploading a connected home application to the device that can be controlled remotely via an app on a mobile phone. The second tutorial takes you through the process of creating a \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d. You can build a smart thermostat that controls a fictitious Heating, Ventilation and Air Conditioning (HVAC) system by going through the third tutorial. The fourth tutorial uses AWS AI/ML services to build a smart thermostat that derives predictions from raw data for a room occupancy use case. And finally, the fifth tutorial includes the steps to create your own Amazon Alexa voice assistant that controls the onboard hardware.\nDemo Overview\nIn this demo, I first walk you through the basic structure of the Blinky project using the \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d tutorial. Then, I extend the project by adding the code that displays PNG formatted images on the device. The device listens for incoming messages that contain a URL pointing to an image hosted in Amazon S3. Then, it downloads the image, stores it in RAM, decodes it into raw RGB (red, green, and blue) data to finally display in on the screen.\nHere is a brief description of how I extend the project:\nThe iot_subscribe_callback_handler is triggered every time a new MQTT message is received. This function calls the function iot_subscribe_callback_handler_pngdemo which stores the content of the message in RAM and a pointer in the queue xQueueMsgPtrs.\nA separate process monitors the queue xQueueMsgPtrs and triggers the processJSON function. This function\xe2\x80\x99s job is to read the message, download the image and decode it. The image bitmap is stored in RAM and a pointer to the image is stored in xQueuePngPtrs.\nFinally, a process that monitors this queue displays the image.\nFigure 1 \xe2\x80\x93 Messages and downloaded files are stored in RAM. Queues and tasks used to process data.\nPrerequisites\nThe M5Stack Core2 for AWS IoT EduKit reference hardware\nCompleted the \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d guide\nBasic familiarity with the C programming language and FreeRTOS\nA link to a 320\xc3\x97240 pixel PNG image hosted in Amazon S3\nThe Cloud Connected Blinky \xe2\x80\x93 How does it work?\nThe program starts by first setting up all the necessary hardware components like LEDs, touchscreen interface, and the LCD screen. Then, it starts the Wi-Fi components, connects to a Wi-Fi network and starts two tasks in parallel: blink_task and aws_iot_task.\nThe aws_iot_task waits until the Wi-Fi is ready to connect to AWS IoT Core and subscribes to a topic named after a hardware-based unique identifier using the Message Queuing Telemetry Transport (MQTT) protocol. The task sends 2 messages that contain the text \xe2\x80\x9chello from SDK\xe2\x80\x9d every 3 seconds to AWS IoT Core. The task also downloads incoming messages as they become available.\nThe blink_task starts in a suspended state but is configured to blink the LEDs every 200 milliseconds when it is set to resume. The function iot_subscribe_callback_handler is triggered whenever a message is received. It is programmed to print the contents of the message it received in the local terminal window and to resume blink_task if it is suspended and vice versa.\nNow, I walk through the following procedures required to access files from Amazon S3 and display them on IoT devices.\nYou\xe2\x80\x99ll learn how to:\nAdd support to decode PNG images\nStore the contents of incoming message in a queue\nRetrieve messages from a queue and process them\nBuild, flash, and test the device\nStep 1 \xe2\x80\x93 Add support to decode PNG Images\nThe \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d example code comes with the Light and Versatile Graphics Library (LVGL) which is a library that makes it easier to create a graphical user interface on embedded devices. The library has PNG support but the functionality is not included in the default package.\nTo add PNG support to your project:\nOpen the \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d using the PlatformIO development platform.\nClone the repository as a subdirectory of the components directory.\ncd components && git clone https://github.com/lvgl/lv_lib_png.git\nBash\nThe project uses CMake to make it easy to build your project. Create a new CMakeLists.txt under components/lv_lib_png. This tells the CMake system to add the source and include files under this directory to the project should it be required. It also specifies that the component depends on the core2forAWS component.\n# File: components/lv_lib_png/CMakeLists.txt\n\nset( COMPONENT_SRCDIRS . )\nset( COMPONENT_ADD_INCLUDEDIRS . )\nset( COMPONENT_REQUIRES ""core2forAWS"" )\nregister_component()\nUpdate the existing CMakeLists.txt file available in the main directory by adding the lv_lib_png component to the COMPONENT_REQUIRES list.\n# File: main/CMakeLists.txt\n\nset(COMPONENT_REQUIRES ""nvs_flash"" \n        ""esp-aws-iot"" \n        ""esp-cryptoauthlib"" \n        ""core2forAWS"" \n        ""lv_lib_png""\n        )\nCreate a new file called pngdemo.c , save it in the main folder and add the following code:\n// File: main/pngdemo.c\n#include ""lvgl/lvgl.h""\n#include ""lodepng.h""\nC\nThe AWS IoT EduKit reference hardware comes with a 320\xc3\x97240 LCD configured to use 16-bit color depth (BGR565). Images converted from PNG to raw bitmaps by LVGL use 24 bits by default (RGB888). A function that converts images to 16-bit color depth and swaps the blue and red color information is required to display images converted by LVGL.\nCreate a function called convert_color_depth in pngdemo.c.\n// File: main/pngdemo.c\n\nvoid convert_color_depth(uint8_t * img, uint32_t px_cnt)\n{\n    lv_color32_t * img_argb = (lv_color32_t*)img;\n    lv_color_t c;\n    uint32_t i;\n\n    for(i = 0; i < px_cnt; i++) {\n        c = LV_COLOR_MAKE(\n    img_argb[i].ch.blue, \n    img_argb[i].ch.green, \n    img_argb[i].ch.red);\n        img[i*2 + 1] = c.full >> 8;\n        img[i*2 + 0] = c.full & 0xFF;\n    }\n\n}\nC\nYou have completed step 1. The device can now handle PNG images and convert them to a format compatible with the LCD screen.\nStep 2 \xe2\x80\x93 Store the contents of incoming message in a queue\nThe \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d program configures the aws_iot_task to receive messages coming from AWS IoT Core and prints the contents of the message in the local terminal window. You can use a queue to send fixed or variable sized messages between tasks. The content of variable sized messages is not stored in the queue. Instead, a queue holds fixed size structures that contain pointers.\nI modify aws_iot_task so that it will store the data of an incoming message in the queue xQueueMsgPtrs. The data will be accessed later by the task check_messages created in Step 3. Since the message size is not known, space for the message payload is going to be dynamically allocated in RAM and a pointer to it is going to be stored in a queue.\nTo store the contents of incoming messages in a queue:\nCreate a new file called pngdemo.h, save inside the main/includes folder and add the following code. This file contains some definitions that determine the size of the queues and the maximum amount of memory that can be used per incoming message and downloaded file.\n// File: main/includes/pngdemo.h\n\n#pragma once\n\n// Max number of messages to store\n#define MSG_QUEUE_DEPTH 128\n// Max number of images to store in the buffer \n#define PNG_QUEUE_DEPTH 1\n// Max size of the incoming message containing an URL\n#define MAX_URL_BUFF_SIZE 1024\n// Theoretical maximum size of an incoming PNG. \n// It includes the PNG file data, signature, chunks and CRC checksum.\n#define MAX_PNG_BUFF_SIZE (320*240*4)+8+4+4+4\n\n// Function prototypes\n\nvoid convert_color_depth(uint8_t * img, uint32_t px_cnt);\n\nvoid processJSON(char * json);\n\nvoid iot_subscribe_callback_handler_pngdemo(char * payload, int len);\n\nvoid check_messages(void * param);\nC\nOpen main.c and include the header file pngdemo.h.\nCreate a queue handler in the global declaration section of the main.c file; this is at the top of the program and outside of any function.\n// File: main/main.c\n\n#include ""pngdemo.h""\nQueueHandle_t xQueueMsgPtrs;\nC\nCreate a queue inside the app_main function which is implemented in the main.c file. Name this queue xQueueMsgPtrs. The depth of the queue will be defined by a macro that will be defined later and the size of each item will be the size of a pointer.\n// File: main/main.c\n\nxQueueMsgPtrs = xQueueCreate(PNG_QUEUE_DEPTH,sizeof(char *));  \nC\nRemember that aws_iot_task is designed to call the function iot_subscribe_callback_handler every time a new message comes in. This function needs to be modified to pass the parameters to a new function which is designed to store the message in RAM and store the pointer in a queue. The new function needs to be able create a buffer to store the incoming message and to send the pointer to the queue using xQueueSend.\nUpdate pngdemo.c by adding the headers described below and link xQueueMsgPtrs.\n// File: main/pngdemo.c\n\n#include <string.h>\n#include ""freertos/FreeRTOS.h""\n#include ""freertos/queue.h""\n#include ""freertos/task.h""\n#include ""esp_log.h""\n#include ""pngdemo.h""\n\nstatic const char *TAG = ""PNGDEMO"";\n\n// Link to the queue that stores pointers of the incoming messages\nextern QueueHandle_t xQueueMsgPtrs;   \nC\nCreate the function iot_subscribe_callback_handler_pngdemo in pngdemo.c.\n// File: main/pngdemo.c\n\nvoid iot_subscribe_callback_handler_pngdemo(char * payload, int len)\n{\n    // Create buffer to store the incoming message\n    char * myItem = heap_caps_malloc(len, MALLOC_CAP_SPIRAM);\n\n    // Copy the incoming data into the buffer\n    strncpy(myItem,payload,len);\n\n    // Send the pointer to the incoming message to the xQueue.\n    xQueueSend(xQueueMsgPtrs,&myItem,portMAX_DELAY);\n}\nC\nOpen main.c and modify the function iot_subscribe_callback_handler to pass the payload to iot_subscribe_callback_handler_pngdemo if the MQTT topic name has \xe2\x80\x9c/png\xe2\x80\x9d.\n// File: main/main.c\n\nvoid iot_subscribe_callback_handler(AWS_IoT_Client *pClient, \n                                   char *topicName, uint16_t topicNameLen,     \n                                   IoT_Publish_Message_Params *params, \n                                   void *pData) \n{\n   ...\n\n    if (strstr(topicName, ""/png"") != NULL) \n    {\n      iot_subscribe_callback_handler_pngdemo(\n          (char *)params->payload,\n          (int)params->payloadLen\n      );\n    }\n\n   ...\n\n}\nC\nExtend the existing CMakeLists.txt to include the new source file we created in step 1, procedure step 5 so that it will compile and link it to the executable that gets flashed into the microcontroller.\nOpen the CMakeLists.txt  file and modify set(COMPONENT_SRCS) by adding the source file pngdemo.c to the list.\n# File: main/CMakeLists.txt\n\nset(COMPONENT_SRCS \n    ""main.c""  \n    ""blinky.c""\n    ""ui.c""\n    ""pngdemo.c""\n    )\nYou have completed step 2. Incoming messages are now being stored in memory as they come in and there is a queue that contains a pointer to each message.\nStep 3 \xe2\x80\x93 Retrieve messages from a queue and process them \nA new task check_messages is created to access the data in the queue. The task\xe2\x80\x99s job is to monitor the queue xQueueMsgPtrs and process the data using a new function called processJSON. The new function processJSON parses a message and retrieves the contents of the key img_url. Then, it downloads the image and stores it temporarily in RAM. The code is designed to process messages that use the JSON format and images are retrieved via HTTP. The cJSON library is used to decode the messages and the esp_http_client library is used to download files. Incoming images are converted from PNG to raw format. Then, the color depth is converted from 24 to 16 bits storing the resulting data in RAM for later use. Finally, a pointer to the 16-bit image buffer is sent to a queue called xQueuePngPtrs.\nTo retrieve messages from a queue and process them:\nOpen pngdemo.c and add the freertos/semphr.h header, making sure it is added after freertos/FreeRTOS.h.\nAdd the esp_http_client.h and cJSON.h headers.\nLink the file to the xQueuePngPtrs and xGuiSemaphore\n// File: main/pngdemo.c\n\n#include ""freertos/semphr.h""\n#include ""esp_http_client.h""\n#include ""cJSON.h""\n\n// Queue to store the pointers to the PNG buffers\nextern QueueHandle_t xQueuePngPtrs;    \n// Handler to the semaphore that makes the guiTask yield\nextern SemaphoreHandle_t xGuiSemaphore; \nC\nOpen pngdemo.c and create a new function called processJSON.\n// File: main/pngdemo.c\n\n void processJSON(char * json) \n {\n \n }\nC\nThe function converts the raw message to a cJSON object using cJSON_Parse. Then it stores the contents of the key img_url inside a new buffer called url_buffer.\n// File: main/pngdemo.c\n\nvoid processJSON(char * json)\n{    \n    ...\n    \n    // Parse the JSON object    \n    cJSON * root   = cJSON_Parse(json);\n\n    // Find out how big is the string is\n    int len = strlen(cJSON_GetObjectItem(root,""img_url"")->valuestring);\n    \n    // Allocate memory, align it to use the SPIRAM\n    char * url_buffer = heap_caps_malloc(MAX_URL_BUFF_SIZE, MALLOC_CAP_SPIRAM);\n\n    // Copy the contents of the parsed string to the allocated memory\n    memcpy(url_buffer, cJSON_GetObjectItem(root,""img_url"")->valuestring, len+1);\n\n    // Make sure the last byte is zero (NULL character)\n    url_buffer[len+1] = 0;\n\n    // Don\'t need the parsed object anymore, free memory\n    cJSON_Delete(root);\n   \n    ...\n \n }\nC\nAllocate a large enough buffer to hold the image and use esp_http_client to download it.\n// File: main/pngdemo.c\n\nvoid processJSON(char * json) \n{\n    ...\n    \n    // Allocate a large buffer, align it to use the SPIRAM\n    unsigned char * buffer = heap_caps_malloc(MAX_PNG_BUFF_SIZE, MALLOC_CAP_SPIRAM);\n    if (buffer == NULL) {\n        ESP_LOGE(TAG, ""Cannot malloc http receive buffer"");\n        return;\n    }\n    \n    esp_err_t err;\n    int content_length;\n    int read_len;\n    \n    // Intialize the HTTP client\n    esp_http_client_config_t config = {.url = url_buffer};\n    esp_http_client_handle_t http_client = esp_http_client_init(&config);\n\n    // Establish a connection with the HTTPs server and send headers\n    if ((err = esp_http_client_open(http_client, 0)) != ESP_OK) {\n        ESP_LOGE(TAG, ""Failed to open HTTP connection: %s"", esp_err_to_name(err));\n        free(buffer);\n        return;\n    }\n\n    // Immediately start retrieving headers from the stream\n    content_length =  esp_http_client_fetch_headers(http_client);\n\n    // Retrieve data from the stream and store it in the SPI ram\n    read_len = esp_http_client_read(http_client, (char *) buffer, content_length);\n\n    // Validate that we actually read something\n    if (read_len <= 0) {\n           ESP_LOGE(TAG, ""Error read data"");\n    }\n\n    ESP_LOGI(TAG, ""HTTP Stream reader Status = %d, content_length = %d"",\n      esp_http_client_get_status_code(http_client),\n      esp_http_client_get_content_length(http_client));\n    \n    // Tear down the http session\n    esp_http_client_cleanup(http_client);\n    \n    ...\n    \n}\nC\nNow that the image is stored in RAM, decode it from PNG to raw bitmap and converting it to 16-bit color depth.\n// File: main/pngdemo.c\n\nvoid processJSON(char * json) \n{\n    \n    ...\n    \n    // Pointer that will point to the decoded PNG data\n    unsigned char * png_decoded = 0;\n\n    uint32_t error;\n    uint32_t png_width;\n    uint32_t png_height;\n\n    // Use LodePNG to convert the PNG image to 32-bit RGBA and store it \n    // in the new buffer.\n    error = lodepng_decode32(&png_decoded, \n       &png_width, \n       &png_height, \n       buffer, \n       read_len);\n    if(error) {\n       ESP_LOGE(TAG, ""error %u: %s\\n"", error, lodepng_error_text(error));\n       return;\n    }\n   \n   // Clean up\n   free(url_buffer);\n   free(buffer);\n\n   // Convert the 32-bit RGBA image to 16-bit and swap blue and red data.\n   convert_color_depth(png_decoded,  png_width * png_height);\n   \n   ...\n   \n}\nC\nThe image is ready. Send its pointer to the xQueuePngPtrs queue.\n// File: main/pngdemo.c\n\nvoid processJSON(char * json) \n{\n   \n   ...\n   \n   // All done, send the pointer that points to the PNG data to the queue.\n   xQueueSend(xQueuePngPtrs,&png_decoded,portMAX_DELAY);\n   \n   ...\n   \n}   \nC\nCreate a queue handler in the global declaration section of main.c\n// File: main/main.c\n\nQueueHandle_t  xQueuePngPtrs; \nC\nCreate a new queue, and add it inside the app_main function.\n// File: main/main.c\n \nxQueuePngPtrs = xQueueCreate(PNG_QUEUE_DEPTH,sizeof(char *));\nC\nOpen pngdemo.c and create a new function called check_messages. This function continuously checks if messages available in the queues xQueuePngPtrs and xQueuePngPtrs. The function processes available messages as they arrive by calling xQueueReceive and passing a pointer to another function.\n// File: main/pngdemo.c\n \nvoid check_messages(void *param)\n{\n    char * pngPtr;\n    char * msgPtr;\n\n    while(1)\n    {\n        // Yield for 500ms to let other tasks do work\n        vTaskDelay(500 / portTICK_RATE_MS); \n\n        if(xQueuePngPtrs != 0)\n        {\n            if (xQueueReceive(xQueuePngPtrs,&pngPtr,(TickType_t)10))\n            {\n                ESP_LOGI(TAG, ""Got a PNG pointer, free heap: %d\\n"",\n                              \n                esp_get_free_heap_size());\n\n                // Make sure the gui Task will yield\n                xSemaphoreTake(xGuiSemaphore, portMAX_DELAY);\n\n                // Object that will contain the LVGL image \n                // in RAW BGR565 format\n                lv_obj_t * image_background;\n\n                // Clean the screen\n                lv_obj_clean(lv_scr_act());\n\n                // Create a new object using the active screen and no parent\n                image_background = lv_img_create(lv_scr_act(), NULL);\n\n                lv_img_dsc_t img = {\n                  .header.always_zero = 0,\n                  .header.w = 320,\n                  .header.h = 240,\n                  .data_size = 320 * 240 * 2,\n                  .header.cf = LV_IMG_CF_TRUE_COLOR,\n                  .data = (unsigned char *)pngPtr\n                };\n\n                // Force LVGL to invalidate the cache\n                lv_img_cache_invalidate_src(&img);\n\n                // Tell LVGL to load the data that the pointer points to\n                lv_img_set_src(image_background, &img);\n\n                // Free the PNG data\n                free(pngPtr);\n\n                // Let the guiTask continue so that the screen gets refreshed\n                xSemaphoreGive(xGuiSemaphore);\n            }\n        }\n        if(xQueueMsgPtrs != 0)\n        {\n            if (xQueueReceive(xQueueMsgPtrs,&msgPtr,(TickType_t)10))\n            { \n                // Send the pointer that  points to the string to process it\n                processJSON(msgPtr);\n\n                // Free the URL data\n                free(msgPtr);\n            }\n        }\n    }\n}\nC\nUpdate CMakeLists.txt by adding the esp_http_client and json components to the COMPONENT_REQUIRES list.\n# File: main/CMakeLists.txt\n\nset(COMPONENT_REQUIRES\n    ""nvs_flash"" \n    ""esp-aws-iot"" \n    ""esp-cryptoauthlib"" \n    ""core2forAWS"" \n    ""lv_lib_png""\n    ""esp_http_client"" \n    ""json""\n)\nC\nCreate a new task called check_messages in main.c. Make sure the task is created after the queue created in step 3, procedure step 9 . This is important because the task monitors the queue contents as soon as it starts.\n// File: main/main.c\n\nxTaskCreatePinnedToCore(&check_messages,""check_messages"", 4096, NULL, 4, NULL, 1); \nC\nThe code is now ready!  Your device will listen for messages and shows an image on the display.\nStep 4 \xe2\x80\x93 Build, flash, and test the device\nYou are now ready to build (compile) and upload the firmware to the microcontroller. The process is the same as with the other tutorial for building, flashing, and monitoring the serial output:\nRun the following command from the terminal window:\npio run --environment core2foraws --target upload --target monitor\nBash\nSend a message to <<CLIENT_ID>>/png using the AWS IoT MQTT test client. This is almost identical to how you send the command to blink an LED in the \xe2\x80\x9cCloud Connected Blinky\xe2\x80\x9d tutorial.\nHere is a sample of the message payload the device is designed to receive:\n{\n    ""img_url"" : ""https://edukit.workshop.aws/en/AWS_IoT_EduKIt_Logo-320px_240px.png""\n}\nJSON\nFigure 2 \xe2\x80\x93 Sending a message using the AWS IoT MQTT test client\nAlternatively, use this script to test your code:\n# file docs/test.py\n\nimport boto3\nimport json\n\nENDPOINT = \'https://<<IOT_ENDPOINT>>\xe2\x80\x99\n\nclient = boto3.client(\'iot-data\', endpoint_url=ENDPOINT)\n\ndata = { \'img_url\' : \'<<URL_TO_PNG_FILE>>\' }\n    \nr = client.publish(\n    topic=\' <<CLIENT_ID>>/png\',\n    qos=0,\n    payload = json.dumps(data)\n)\nPython\n  Clean Up\nNo additional resources have been created in your AWS account. However, the following command can be used to clear the contents the AWS IoT EduKit reference hardware flash memory:\npio run --environment core2foraws --target erase\nBash\n'"
137,Build an AWS IoT Well-Architected environment with the IoT Lens,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/05/18/aws-iot-well-architected-lens.png,https://aws.amazon.com/blogs/iot/build-an-aws-iot-well-architected-environment-with-the-iot-lens/,"b'There are an estimated 31 billion IoT devices in 2020, and this is expected to increase to 75 billion by 2025 according to Security Today. You may be starting on your IoT journey or have hundreds of thousands of devices connected and want to improve your architecture and reduce your cost. To guide you through this process, AWS is happy to announce the IoT Lens for the AWS Well-Architected Framework. AWS Well-Architected helps cloud architects build secure, high-performing, resilient, and efficient infrastructure for their applications and workloads. This post provides an introduction of the purpose of the IoT Lens, topics covered, common scenarios, and AWS services included.\nThe new IoT Lens offers comprehensive guidance to make sure your IoT devices and cloud framework are designed in accordance with AWS best practices. The goal is to give you a consistent way to design and evaluate IoT devices and associated cloud architectures, based on the following five pillars:\nOperational Excellence\nSecurity\nReliability\nPerformance Efficiency\nCost Optimization\nThe IoT Lens can help you assess the IoT device software and workloads you have deployed in AWS by identifying potential risks and offering suggestions for improvements.\nUsing the IoT Lens to address common requirements\nThe IoT Lens addresses the following on the device end:\nSecuring devices and credentials\nAccessing IoT devices\nProvisioning IoT devices\nUpgrading configuration, credentials and firmware on IoT devices\nThe IoT Lens covers the data flow from/to the devices:\nEncrypting data from / to devices\nControlling the frequency of message flow from cloud to the device\nOptimizing the data ingestion from the device\nThe IoT Lens also addresses architecting the cloud to:\nAnalyzing and monitoring device metrics to improve device performance\nDesigning reliable and cost optimized storage of device data in the cloud\nScaling your IoT workloads as the number of devices increase\nIn addition to the above, the IoT Lens addresses Disaster Recovery for your IoT workloads, which is crucial to ensure that your devices are always connected to the cloud.\nThe IoT Lens can be used to start your IoT journey whether you are looking for telemetry data from your devices or Command and Control of your devices. You can use the IoT Lens to improve your architecture by incorporating features such as device management, security, configuration, over-the-air (OTA) Updates, and redundancy in device connections to the cloud. If you already have an IoT workload, the IoT Lens can be used to scale your workload and operate it efficiently.\n'"
138,Get Started with Fleet Hub for AWS IoT Device Management,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/05/24/figure-1-general-solution-architecture.png,https://aws.amazon.com/blogs/iot/get-started-with-fleet-hub-for-aws-iot-device-management/,"b'There are billions of devices in homes, factories, oil wells, hospitals, cars, and thousands of other places\xe2\x80\x93which means there are billions of devices to monitor and manage. AWS IoT helps customers in all industries effectively manage their device fleets, and can reliably scale to billions of devices and trillions of messages. Companies often rely on many different stakeholders, from developers to admin staff, to manage and monitor their IoT device fleets. To do so, these organizations build, deploy and administer their own custom platforms for non-technical users to interact with. While this helps manage fleet behavior and take corrective action, like troubleshooting an offline device or deploying an update before a device becomes non-compliant, these homegrown solutions require dedicated and often increasing levels of maintenance over time. This is especially true as an organization scales and adds more products to their connected device portfolio, which can result in engineering resources and time being pulled away from other higher impact priorities or innovation opportunities.\nFleet Hub for AWS IoT Device Management Overview\nFleet Hub for AWS IoT Device Management is a fully managed web application that allows non-technical stakeholders to easily view and interact with your device fleets. Getting started is also quick, as web applications created through Fleet Hub can be deployed in minutes, without any code, and integrate with existing enterprise protocols to meet security requirements. Once deployed, you can monitor fleet and device health, be alerted to unusual behavior through rule-based alarms, and use built-in integrations with other AWS IoT Device Management features and AWS IoT services to further troubleshoot an identified issue or take corrective actions.\nNon-AWS account users can now access Fleet Hub for AWS IoT Device Management to monitor device fleets in near-real time, set alarms to notify technicians about unusual behaviors, and take corrective actions in response to alarms\xe2\x80\x94all via a single sign-on portal that is controlled by the AWS account holder.\nIn this blog, we will walk through how to set up and deploy a Fleet Hub web application. In this example, Fleet Hub will manage battery operated trackers used to monitor the health and safety of the elderly. We will show how the AWS account administrator can set up a single sign-on portal, add users, and use device attributes to configure alert types for filters.\nAssisted living use case for Fleet Hub\nIoT connected device fleets come in all shapes and sizes and can be used for a variety of applications; this blog specifically uses the example of an assisted living monitoring use case. As health outcomes globally improve, people are living longer. As they do, elderly populations are seeking enriched, healthy, and independent lives. IoT applications like assisted living monitoring make this possible by placing various types of sensors around the home of the elder person, allowing them personal freedom whilst providing remote monitoring to ensure their safety. In this specific example, we will be using GPS trackers with mobile communication connectivity, which must be battery powered to allow freedom of movement. Maintaining battery levels, including proactive notifications (such as a charging notification when battery state is low), is imperative. For a care assistant (like in an assisted living home), utilizing battery-powered monitoring devices also mitigates the need to know the type of electronics required to power devices (e.g. the entire fleet has the same power requirements).\nPrerequisites\nIn order to start using Fleet Hub you first need the following artifacts operating in your AWS account:\nIf you do not have an AWS account, you will need to create and activate an AWS account first and set up both AWS IoT Core and AWS IoT Device Management. For getting started instructions, please view the AWS IoT Core getting started guide and the guide for how to manage devices with AWS IoT.\nTurn on AWS IoT Core fleet indexing, which is required for use with Fleet Hub https://docs.aws.amazon.com/iot/latest/developerguide/iot-indexing.html\nDevices that are able to deploy shadows using the AWS IoT Device SDK or in custom code that can read subscribed topic data. This is because fleet index needs to be able to pull metrics from assets on devices that will change in order to evaluate them. Discover qualified hardware that works with AWS services to help build and deliver successful IoT solutions in the AWS Partner Device Catalog.\nSolution Overview: How managing devices with Fleet Hub works\nThe following diagram, Figure 1, shows an architecture of an array of devices connecting through AWS IoT Core via MQTT. Fleet Hub monitors these devices for specific attributes that are designated as important. To do this, Fleet Indexing is turned on for the AWS account so that thing aggregates can be created.\nThe AWS administrator can then create web applications for non-technical staff that allow them access to the device group, which the staff can use to monitor devices and create their own alarms (like for issues in the home or assisted living facility). These web applications can be made granular so that specific account holders, such as care assistants, can access only their approved devices to manage and control. With Fleet Hub, the users (such as the care assistant or approved family members) can create their own alarms and choose to be alerted by Email or text message via Amazon Simple Notification Service (SNS).\nFigure 1: General architecture\nIn this blog, we will walk through the procedures to set up and deploy Fleet Hub so it can be used for a similar workload.\nTo do this, we need to create a web application and aggregate fleet metrics. This can be accomplished through the following procedures:\nStep 1: Turn on Fleet Indexing\nStep 2: Find specific device attributes to monitor\nStep 3: Set custom fields\nStep 4: Set up Fleet Hub user portal\nStep 5: Turn on single sign-on\nStep 6: Set up alarms\nTurn on Fleet Indexing\nWhen it comes to monitoring a large number of devices, it can be hard to analyze specific trends and issues. For instance, if there is device failure, it can be difficult to determine whether that is due to the battery, firmware, movement out of range, or something more sinister.\nWith Fleet Hub, the administrator of the AWS account can turn on Fleet Indexing to monitor their devices, aggregate connection metrics, run queries to drill down and filter, list device details, and set up alarms.\nFleet Indexing creates an index of the messages coming in from your things and also indexes on connectivity, errors, and any shadow attributes that you\xe2\x80\x99ve set up. To understand how to get measurable metrics into Fleet Hub, we first need to turn on Fleet Indexing in the AWS account. If you already have this turned on, then you can proceed to the next section. Fleet indexing is required to use Fleet Hub.\nTo turn on Fleet Indexing:\nOpen the AWS IoT console, and navigate to Settings\nSelect Enable Fleet Indexing\nFigure 2: Turning on fleet indexing\nSelect the specific device shadow attributes to monitor\nThe next step is to select specific attributes you plan to monitor. In this example, we are using AWS IoT Core shadow attributes from the GPS tracking device. If you have already coded shadow attributes for your device, you can open your thing in the AWS IoT Core console and select Shadows to see your device shadows. If you have not already added shadow attributes, you can add shadow and service attributes using the instructions in this doc. Note, after creating device shadows you will need to do a device firmware update. Use your shadows to view the attributes you want to monitor through Fleet Hub (such as battery state, firmware version, etc.).\nThe below demonstrates what a shadow state should look like for battery state in Fleet Hub as an example.\nWhere \xe2\x80\x9cbatt_state\xe2\x80\x9d represents 12% battery\nMovement =  1 (moving) 0 (not moving)\n Firmware =  (current state of the device in software\nFor the battery, what we are looking for is if state goes below XX% (in this example, 12) we can create a report / send alerts. Looking at the shadow example, the device is reporting its current state out 100. 12 represents 12% of battery.\n\xe2\x80\x9creported\xe2\x80\x9d: {\n\xe2\x80\x9cbatt_state\xe2\x80\x9d: \xe2\x80\x9c12\xe2\x80\x9d,\n\xe2\x80\x9cmovement\xe2\x80\x9d: 1,\n\xe2\x80\x9cfirmware\xe2\x80\x9d: \xe2\x80\x9c2.23r2\xe2\x80\x9d\n}\n}\nFigure 3: Shadow of the GPS tracker\nYour device may have numerous shadow attributes that can be used from location in lat/long, movement in G/Nm or orientation of the device. Once you have selected these attributes, you can use them to set custom fields.\nSet custom fields\nTo set these attributes as custom fields:\nOpen the AWS IoT console\nNavigate to Settings, and then to Set custom fields\nSelect Set custom fields and add the attributes you want to monitor (as shown in Figure 4)\n4.     Select Add custom field\nConfirm your field name\nSelect your field type\n[Optional] Click Add another (and repeat above) to add as many fields as you need\nFigure 4: Adding custom fields into Fleet Indexing\nUsing device shadow updates in this way is really useful because you can set these attributes once for a device class/software version and then all of your devices with these attributes will report this state since Fleet Indexing validates updates from a shadow state. Knowing these states is powerful and adds another dimension to the data from devices. You can also validate updates with thing attributes for things that don\xe2\x80\x99t have a shadow state by defining a set of attributes for a device and then updating these attributes using update-thing as part of the CLI. See the AWS Documentation for more details.\nSet up the Fleet Hub user portal\nFleet Hub allows the AWS account administrator to set up all the resources, such as things and certificates, needed to create one or more web applications that provide transparency into the specific devices that non-technical users need to monitor and report on. In the use case of monitoring the elderly, key workers must periodically and remotely check in on their patients to ensure activity levels are in an acceptable (and expected) range. Additionally, this situation requires definition of movement parameters to ensure the trackers are functioning properly\xe2\x80\x94which will be captured as the battery status from the AWS IoT Device Shadow service outlined in the second step.\nFrom an AWS administration perspective, setting up Fleet Hub is easy to do\xe2\x80\x93after the device shadows are selected, you can set up Fleet Hub user portal in less than 5 minutes.\nTo create the Fleet Hub user portal:\nNavigate to the AWS IoT Core console\nSelect Fleet Hub in the menu option\nSelect Get Started\nSelect Create Application. In this screen, you can define indexing and users of the portal (see Figure 5)\nFigure 5: Enabling a Fleet Hub portal from the console\nEnable single sign-on for Fleet Hub\nSetting up AWS Single Sign-On (SSO) provides access to specific users that are external to the AWS account, such as a care assistant. In the SSO portal, you can also define the indexing parameters which are important for users to be able to view and search with Fleet Hub.\nTo set up single sign-on for Fleet Hub:\nVisit the AWS SSO Getting Started page to learn how to set up single sign-on for your account, or navigate to the Fleet Hub Application settings in the Fleet Hub console and Select set up\nFrom the Fleet Hub Application settings page, validate that the custom search fields you added in the previous step are correct. If so, choose next\nAdd the federate user role. If you don\xe2\x80\x99t have one, click create new service role\nAdd the name of your Fleet Hub instance and any details for it, such as ownership or project information\nFigure 6: Setting up Fleet Hub\nThe next step is to add users to the account so they can log in. You will need to go through the steps of adding the users along with their email address. To do this:\nOpen the SSO service and select Users on the left\nSelect Add user\nNavigate back to Fleet Hub in the AWS IoT console\nChoose your users, and select Add\nOnce complete, the Fleet Hub environment is created in SSO (takes a few minutes to build). The SSO service will send the selected users an email invitation to join the Fleet Hub application. Upon following the email instructions, they will be able to log in and use the Fleet Hub service via SSO.  Figure 7 shows the Fleet Hub dashboard where users can see the devices and their attributes.\nFigure 7: Fleet Hub Dashboard\nSet up alarms\nWith Fleet Hub, you can set up alarms to notify technicians about unusual behavior. Once all the devices are available in the Fleet Hub dashboard, users can then create alarms. Fleet Hub allows a standard user to create alarms that can be used to track a single device or a fleet. In our case, this means tracking an individual person (who is perhaps, living independently) or group of people (who reside in an assisted living facility). In our example, we set an alarm that is initiated when battery level has gone below a certain threshold (as shown in Figure 8) to notify users (such as an elderly person living alone or a nurse) using an SNS action.\nFigure 8: Alarm display screen with metrics.\nTo set up the alarms:\nFrom the Fleet Hub dashboard, select Create alarm\nThe drop-down list will include your custom attributes alongside the standard ones\nSelect an aggregation type\nThere are a few options depending on what attributes you want to monitor, such as maximum/minimum counts, sum, average. These can help you understand if devices are missing or when devices dip below a certain threshold.\nChoose a monitor period (such as every 5 minutes)\nSelect next to go to the alarm trigger state (such as greater than/equal to/lower than)\nFor example, for your battery state, you could say is greater than 90% battery or is equal/lower than 10% battery)\nSelect the trigger point, whether that be greater than or less than the value in the percentile\n[Optional] Select next and fill out the email address or email list for who you want the alarm to go to and name the alarm state\nOnce you\xe2\x80\x99ve completed these steps, your alarms are visible in the Fleet Hub alarms screen in the dashboard (as shown in Figure 8) as well as via email.\nClean Up\nTo avoid incurring future charges, delete all resources that you have created.\nThe SSO portal Fleet Hub application can be deleted by first navigating to Fleet Hub in the AWS IoT console and then selecting applications. Select your application and choose delete.\nFleet indexing can be turned off by navigating to the AWS IoT Core console, selecting Settings, then navigating to Manage fleet Indexing and then Thing indexing and group indexing.\nSummary\nWith Fleet Hub for AWS IoT Device Management, you can quickly and easily build no-code, standalone web applications to monitor the health of your device fleets, such as for our use case of a fleet of battery-operated trackers used to monitor the elderly. Once Fleet Hub is set up, it can be used to manage common fleet-wide tasks such as restarting devices, updating firmware, rotating expired certificates, and investigating and remediating operational and security issues. This helps make it easier and faster for customers to manage their connected device fleets, freeing up valuable time and ensuring they can provide a reliable, secure, and high-quality end user experience.\nResources\nThis feature is now generally available in Fleet Hub is now generally available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), and Europe (London). Note, you will be able to access devices in any AWS Region by enabling Fleet Indexing for that Region. To learn how you can easily deploy a Fleet Hub application to monitor and interact with your device fleets, read the Fleet Hub documentation. To learn more, visit the AWS IoT Device Management website.\nAbout the author\nAndrew Delamare is a Senior Specialist Solution Architect for AWS IoT, based in London. Andrew works with many companies in different sectors, looking to leverage data from their physical assets to gain better insights in their operations and make it measurable.'"
139,Part 2/2: Building Reliable IoT Device Software Using AWS IoT Core Device Advisor,b'Andra Christie',2021-07-12T19:56:59+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/05/18/Figure-1-ConditionMonitoringArchitecture-1024x207.png,https://aws.amazon.com/blogs/iot/part-2-2-building-reliable-iot-device-software-using-aws-iot-core-device-advisor/,"b'This post was co-written by David Walters, Sr Partner Solutions Architect, AWS IoT, and Pavan Kumar Bhat, Sr. Technical Product Manager, AWS IoT Device Ecosystem.\nIntroduction\nThis is the second blog in a two-part series. In the first blog, I explained the importance of testing IoT devices and how AWS IoT Core Device Advisor works. In this blog, I share my experience using Device Advisor to debug a software application on an IoT device with a real-world industrial condition monitoring example.\nSolution Overview\nFirst, let\xe2\x80\x99s examine an IoT solution built with AWS Partner solutions and AWS services to monitor and visualize the state of three water pumps controlled by Programmable Logic Controllers (PLC). PLCs are ruggedized computers used to control industrial assets.\nFigure 1: Solution architecture for water pump condition monitoring.\nThe solution highlighted in this blog post covers the following AWS Partner solutions and AWS services:\nEveryware Software Framework (ESF) is a flexible application framework that runs on IoT gateways and integrates field protocol libraries. ESF has been qualified for AWS IoT Core by Eurotech, and devices running ESF are listed in the AWS Partner Device Catalog.\nAWS IoT Core lets you connect IoT devices to the AWS Cloud without the need to provision or manage servers. AWS IoT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS services and to other devices reliably and securely.\nAmazon Timestream is a fast, scalable, and serverless time series database service for IoT and operational applications that makes it easy to store and analyze trillions of events per day.\nAmazon Managed Service for Grafana (AMG) is a fully managed and secure data visualization service that enables customers to instantly query, correlate, and visualize operational metrics, IoT data, and traces for their applications from multiple data sources.\nEach PLC is generating data about the state of the water pumps and communicating over Modbus TCP, a standard communication protocol used by PLCs, to an IoT gateway. Everyware Software Framework is running on the gateway device. An ESF Wires application is configured to collect data over the Modbus TCP protocol and the data is published to AWS IoT Core using the AWS IoT Core Connector for ESF.\nOnce the data arrives on AWS IoT Core, an IoT Rule is triggered for each message and moves data into Amazon Timestream. Finally, the data is visualized in Amazon Managed Service for Grafana for operators to see the real-time status of the water pumps. If the IoT device is not reliable while deployed in the field, critical condition monitoring data may not be seen by an operator, leading to pump downtime and possible flooding.\nTo see the condition and operating status of the water pumps, I open up the Amazon Managed Service for Grafana dashboard.\nFigure 2: Amazon Managed Grafana dashboard with no data available.\nUsing Device Advisor to Debug the Device Software\nAs we see in the screen above, no data is currently appearing on the Grafana dashboard. This can indicate that data is not arriving on AWS IoT Core due to connectivity or reliability issues. AWS IoT Core Device Advisor can help debug such issues. To start debugging, I create a test suite from the AWS IoT Device Advisor console specific for my solution with the following prebuilt test cases:\nSecurity_Device_Policies \xe2\x80\x93 The AWS IoT Policy associated with the device should not allow the device to perform more actions than needed for the application. This test ensures that best practices are followed and that the device does not include wildcard policy statements.\nTLS_Connect \xe2\x80\x93 The TLS Connect Test Case ensures that the device and software meets all of the required TLS 1.2 requirements and implements certificate-based mutual authentication. If the device cannot establish TLS mutual authentication with AWS IoT Core, the device will not be able to connect.\nMQTT_Connect \xe2\x80\x93 Once the TLS connection has been established, the device must use the MQTT 3.1.1 application protocol with AWS IoT Core. Any errors on the device\xe2\x80\x99s implementation of the MQTT client protocol can cause the device connection to fail. This test checks that the device can authenticate, establish a connection the MQTT broker, and send a valid MQTT CONNECT packet.\nMQTT_Publish \xe2\x80\x93 This test case ensures that the device correctly implements an MQTT Publish packet, and publishes on the correct topics for your IoT application. I configured three test cases to check that the device publishes to \xe2\x80\x98ws/zone1/pump1/dt\xe2\x80\x99, \xe2\x80\x98ws/zone1/pump2/dt\xe2\x80\x99 and \xe2\x80\x98ws/zone1/pump3/dt\xe2\x80\x99 to ensure the IoT Rule is triggered on \xe2\x80\x98ws/#\xe2\x80\x99.\nShadow_Publish_Reported_State \xe2\x80\x93 This test case ensures that the device implements the Device Shadow protocol. The device should publish each water pump\xe2\x80\x99s reported motor state to a Classic Shadow when it first connects to AWS IoT Core.\nFigure 3: Test suite creation from the AWS IoT Core Device Advisor console.\nOnce the test suite is set up, I configure Everyware Software Framework to connect to the Device Advisor endpoint.\nFigure 4: The MQTT broker endpoint is changed to point to the Device Advisor endpoint under the \xe2\x80\x98Broker-url\xe2\x80\x99 configuration parameter in ESF.\nI start the Device Advisor test suite from the AWS IoT Core Management Console and select PumpGateway-001 as the test device. When each test case moves from Pending to In Progress, I connect ESF to the Device Advisor endpoint.\nOnce the Test Suite has completed, results are displayed in the Device Advisor console.\nFigure 5: AWS IoT Core Device Advisor console displays the test run results indicating multiple test failures.\nAccording to the Device Advisor test report, the Policy Test failed due to a policy that contains a wildcard (\xe2\x80\x98*\xe2\x80\x99). The policy should be changed to ensure that the device is only allowed to connect with its Client ID, publish on specified topics, and update its Device Shadow. I replaced the device\xe2\x80\x99s policy with a more restrictive policy, and attached it to the device certificate. For more information on IoT Policy best practices, see the documentation.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Connect""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:<region>:<accountID>:client/PumpGateway-001""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Publish""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:<region>:<accountID>:topic/ws/zone1/pump1/data"",\n        ""arn:aws:iot:<region>:<accountID>:topic/ws/zone1/pump2/data"",\n        ""arn:aws:iot:<region>:<accountID>:topic/ws/zone1/pump3/data"",\n        ""arn:aws:iot:<region>:<accountID>:topic/$aws/things/PumpGateway-001/shadow/update""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:UpdateThingShadow""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:<region>:<accountID>:thing/PumpGateway-001""\n      ]\n    }\n  ]\n}\nThe TLS_Connect test passed because ESF has successfully implemented TLS 1.2 using the AWS IoT Device Java SDK v2.\nThe MQTT_Connect failed, and subsequent tests also failed because they are dependent on the device connecting to Device Advisor using the MQTT protocol.\nThe System Message for the MQTT_Connect, \xe2\x80\x98Test case time out\xe2\x80\x99, indicates that the timeout was reached before the device sent an MQTT CONNECT packet. To investigate with more detailed information, I click on the \xe2\x80\x98Test case log\xe2\x80\x99 link to open Amazon CloudWatch Logs.\nFigure 6: Amazon CloudWatch Logs displaying the TLS handshake\nThe CloudWatch log shows that a successful TLS handshake occurred, but the device did not send a CONNECT packet to the Device Advisor endpoint. The device is able to establish a connection to the Device Advisor endpoint, and before the device sends the MQTT CONNECT packet, the server closes the connection with the device.\nNext, I check the registered certificate on AWS IoT Core to ensure that it is valid and active.\nFigure 7: The certificate on AWS IoT has been revoked.\nThe certificate has been revoked, which causes the MQTT connection to fail. Certificates can be revoked by administrators or from automated mitigation actions configured in AWS IoT Device Defender. A certificate may be revoked to prevent devices utilizing that certificate from connecting to AWS IoT Core due to a security threat or misbehavior. In order to ensure my device remains secure and can connect to AWS IoT Core, I generate a new certificate and rotate the certificate in ESF.\nOnce the certificate has been rotated, I re-run the Device Advisor tests and view the results in the AWS IoT Core Device Advisor console.\nFigure 8: Device Advisor test report shows test case failures.\nThe MQTT Connect test is successful now. The CloudWatch Log for this test case shows 2 events after the TLS handshake, indicating the device under test (DUT) sent a CONNECT packet, and Device Advisor responded with a CONNACK:\nFigure 9: CONNECT and CONNACK messages exchanged with the device and Device Advisor\nThere are 2 other test case failures related to the configuration of my ESF application.\nMQTT Publish Test Pump 2 test case failed and Device Advisor reported \xe2\x80\x98Test case time out. Did not receive MQTT PUBLISH message with topic: ws/zone1/pump2/data.\xe2\x80\x99 To debug this issue, I review the CloudWatch Logs for the test case.\nFigure 10: Amazon CloudWatch Logs showing published messages to AWS IoT Core Device Advisor.\nPUBLISH events are recorded that indicate that the device has published to the incorrect topic.\nI changed the topic from \xe2\x80\x98enmonitor/zone1/pump2/data\xe2\x80\x99 to the correct topic \xe2\x80\x98ws/zone1/pump2/data\xe2\x80\x99 in the \xe2\x80\x98Topic Id\xe2\x80\x99 field of the ESF Publisher component for Pump 2.\nFigure 11: Pump 2 Publisher component in Everyware Software Framework.\nThe Device Shadow test failed with the following error message: \xe2\x80\x98Shadow document reported by device does not match expected reported state. Test case received the following shadow document from the device: {\xe2\x80\x9cstate\xe2\x80\x9d:{\xe2\x80\x9creported\xe2\x80\x9d:{\xe2\x80\x9cMOTOR_RUNNING\xe2\x80\x9d:true}},\xe2\x80\x9dthingName\xe2\x80\x9d:\xe2\x80\x9dPumpGateway-001\xe2\x80\xb3}\xe2\x80\x99\nThe expected reported state is defined in the Test Suite creation script:\n""REPORTED_STATE"": {\n                    ""PUMP1_MOTOR_RUNNING"": True\n                }\nIn my application I chose to use a single Classic Shadow for all water pumps to reduce MQTT messaging costs related to updating multiple small Named Shadow documents for each water pump. The context must be kept for each reported motor state by including the pump name in the reported parameter. To change the name of the value, I edit the JavaScript Filter ESF Wire component that is used to extract the motor state and transform the message before publishing to AWS IoT Core Device Shadow service.\nFigure 12: AWS IoT Device Shadow implementation as a JavaScript Filter in Everyware Software Framework\nAfter reconfiguring my ESF application, I run the Device Advisor test suite one more time to ensure all failed test cases are now passing.\nFigure 13: All test cases are now passing in AWS IoT Core Device Advisor\nNow that all the Test Suite Test Cases in AWS IoT Core Device Advisor are passing, I change the endpoint in ESF to the AWS IoT Core ATS endpoint and connect the device. Data is now arriving in the Grafana dashboard and the application is running as expected.\nFigure 14: Data is now arriving on the Grafana dashboard.\nAbout Eurotech\nEurotech is among the first AWS Partner Network partners to use Device Advisor to qualify their IoT devices for the AWS IoT Core Qualification Program. Using Device Advisor, Eurotech is able to test their software framework, Everyware Software Framework, to ensure their customers build reliable IoT device software. Everyware Software Framework passed all test cases in the Qualification Test Suite and is qualified for AWS IoT Core. Devices running ESF, such as the BoltGATE 20-31, are listed in the AWS Partner Device Catalog.\n'"
140,Part 1/2: Building Reliable IoT Device Software Using AWS IoT Core Device Advisor,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/05/17/advisor-how-it-works.png,https://aws.amazon.com/blogs/iot/part-1-2-building-reliable-iot-device-software-using-aws-iot-core-device-advisor/,"b'This post was co-written by David Walters, Sr Partner Solutions Architect, AWS IoT, and Pavan Kumar Bhat, Sr. Technical Product Manager, AWS IoT Device Ecosystem.\nIntroduction\nInternet of Things (IoT) devices that fail to connect to the internet reliably or are vulnerable to security threats can be catastrophic to IoT device makers. An unreliable IoT device can lead to customer dissatisfaction and loss of customer trust.\nIoT device makers building reliable, secure, and scalable IoT devices and applications need comprehensive tools\xe2\x80\x94such as cloud and device testing infrastructure\xe2\x80\x94for testing IoT device software. Once customers deploy IoT devices in production, it becomes increasingly difficult to discover and fix problems such as connectivity or reliability issues. These issues have the potential to negatively impact the customer experience. Fixing the issues may lead to device down time because it will require physical access to the device or unplanned over-the-air updates. These issues can be compounded when you scale from hundreds of devices to millions of devices globally.\nAWS IoT Core lets you connect IoT devices to the AWS Cloud without the need to provision or manage servers. AWS IoT Core can support billions of devices and trillions of messages, and provides customers with a fully managed and secure device gateway and message broker. With AWS IoT Core Device Advisor, now generally available, you can test your IoT device\xe2\x80\x99s connection to AWS IoT Core to ensure the device\xe2\x80\x99s software follows the best practices for connectivity, scalability, and security. Device Advisor provides pre-built Message Queuing Telemetry Transport (MQTT), Transport Layer Security (TLS), and security tests that are built based on real-life customer use cases and common errors found during the development of an IoT device.\nIn this two-part blog series, I will explain how AWS IoT Core Device Advisor provides a managed testing framework for IoT devices that can keep your devices secure and reliable. In this first blog, I showcase how Device Advisor works. In the second blog, I examine a real-world use case to demonstrate how Device Advisor can be used during development to debug an industrial condition monitoring IoT software application.\nAWS IoT Core Device Advisor Use Cases and Benefits\nDevice Advisor test suites can be created and run from the AWS IoT Core console, AWS CLI, or AWS SDKs. Test engineers utilizing the AWS SDKs or AWS CLI can build AWS IoT Core Device Advisor test suites into a Continuous Integration/Continuous Deployment (CI/CD) pipeline to ensure each new version of the device\xe2\x80\x99s software is robust and reliable before triggering an over-the-air (OTA) update or releasing a new product.\nUsing Device Advisor to spot common errors before deploying your IoT application can help accelerate your time-to-market and increase your customer\xe2\x80\x99s confidence in your solution. Additionally, because AWS IoT Core Device Advisor is a fully managed service, using Device Advisor frees up your engineering team\xe2\x80\x99s time to focus on core business logic and differentiation rather than building and maintaining their own testing capabilities.\nHardware partners that participate in the AWS Device Qualification Program can qualify their device for AWS IoT Core by running the AWS IoT Core Device Advisor qualification test suite with their device. After passing all tests in the qualification suite, partners can download the signed test report and upload it to a Device Catalog submission. The AWS Partner Device Catalog provides a list of devices that are qualified by partners for AWS IoT Core, FreeRTOS, AWS IoT Greengrass, and Amazon Kinesis Video Streams. Qualified devices have already passed core MQTT and TLS connectivity tests in the qualification test suite. This provides you with peace of mind and time to focus on building your IoT applications rather than ensuring your hardware works with AWS services\nHow it Works\nIoT devices connect to AWS IoT Core Device Advisor via TLS1.2 using X.509 certificates and mutual authentication. Device Advisor operates on a separate endpoint than AWS IoT Core, and your production devices remain unaffected while the devices you are testing are connected to Device Advisor.\nFigure 1: AWS IoT Core Device Advisor system diagram\nFirst, you configure custom test suites to suit your specific use case and testing requirements. Each test case is run sequentially, and Device Advisor manages the test setup for each test case. You are responsible for connecting your device to the Device Advisor endpoint and triggering the appropriate device-side behavior for each test case.\nDevice Advisor can test your device\xe2\x80\x99s TLS implementation and AWS IoT policy for security vulnerabilities. Device Advisor evaluates your device\xe2\x80\x99s connectivity to AWS IoT Core by testing the device\xe2\x80\x99s MQTT protocol implementation. Scalability tests like MQTT Exponential Backoff ensure your device does not cause disruptive behavior such as edge network congestion (latency due to bandwidth constraints) in the event of a disconnection event. For a full list of test cases, and their configuration parameters, please see Device Advisor test cases.\nThe pre-built tests are designed to simulate failure scenarios, and Device Advisor validates that your IoT device responds appropriately to this behavior. There are several TLS test cases that evaluate the security of the device\xe2\x80\x99s TLS implementation. For example, in the \xe2\x80\x98Not Signed By Recognized CA\xe2\x80\x99 test case, Device Advisor presents an invalid server certificate and tests that the device appropriately closes the TLS connection when it receives the invalid certificate.\nAfter running a test suite, Device Advisor provides a detailed test report that shows passing and failing tests. Each test case is accompanied with detailed Amazon CloudWatch Logs that show the TLS and MQTT packets exchanged with the device under test. The CloudWatch Logs can be used to debug and fix any issues and test failures.\nSetting Up AWS IoT Core Device Advisor\nLet\xe2\x80\x99s take a look at the detailed workflow to set up an AWS IoT Core Device Advisor Test Suite from the AWS Management Console. Before starting, create and activate an AWS account if you do not already have one.\nSet up the necessary AWS IoT resources for your device. You will need to create an AWS IoT Thing, register a Device Certificate, and attach an AWS IoT Policy. To complete this step, follow the instructions in Create AWS IoT resources from the AWS IoT Core Developer Guide.\n Configure your device to connect to AWS IoT Core Device Advisor by setting the endpoint on your device to connect to Device Advisor\xe2\x80\x99s unique endpoint. Your Device Advisor endpoint will differ from the AWS IoT Core endpoint, but utilizes the same server certificate and device certificate that you setup when connecting to AWS IoT Core.To view your Device Advisor endpoint from the AWS Management Console, navigate to the AWS IoT Core service console, choose Test and then Device Advisor. Choose Start walkthrough and the Device Advisor endpoint will be displayed under Getting started with Device Advisor. \n Configure an IAM Role for your device and copy the Role ARN. The IAM Role will grant your device privileges to perform actions during Device Advisor testing.\nCreate an AWS IoT Core Device Advisor Test Suite on the Device Advisor console by navigating to the AWS IoT Core service console, choose Test, Device Advisor, and then Test Suites. On the Test Suites page, choose Create test suite and then Create a new test suite. You can also choose pre-configured test suites, such as the AWS IoT Core Qualification test suite, to qualify your device for listing in the AWS Partner Device Catalog.\nConfigure your test suite. Choose \xe2\x80\x98Test suite properties\xe2\x80\x99. Enter a test suite name and enter the Device Role ARN created in step 3 and click on \xe2\x80\x98Update properties\xe2\x80\x99.\nDrag and drop the test cases that you wish to run onto the test group. Detailed instructions to set up your test suite and configure test cases is available in the Device Advisor documentation.\nChoose the test suite name from the Device Advisor console. \nTo run the test suite, choose Actions, and then choose Run test suite. On the next page, choose your AWS IoT Thing that you created in step 1, and then choose Run test.\nAWS IoT Core Device Advisor will manage all of the test setup and update the status within the console accordingly. When each test moves from Pending to In Progress, connect your device to the AWS IoT Core Device Advisor test endpoint obtained in Step 2. Some test cases may require the device to perform actions such as publish and subscribe to topics. Your device should perform those steps immediately after connecting to the Device Advisor endpoint.\nExamine the test results. If any test resulted in the status of Failed, the full test case log is available in Amazon CloudWatch for closer inspection and debugging. Device Advisor provides links to each test case\xe2\x80\x99s full log. If you selected and passed the AWS IoT Core Device Qualification test suite, you can download the signed test report to upload with your device listing in the AWS Partner Device Catalog. If you did not pass the AWS IoT Core Device Qualification test suite, fix any failed tests and run the test suite again.\n'"
141,Yara and AWS to Digitalize Crop Nutrition Production System,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/05/18/AWS_Yara_Isometric_Squid_Hires-1.jpg,https://aws.amazon.com/blogs/iot/yara-aws-digitize-crop-nutrition-production-system/,"b'Amazon Web Services (AWS) will assist world-leading crop nutrition company Yara in building a Digital Production Platform (DPP) to further improve safety, reliability, product quality and plant efficiency.\nThe Yara Digital Production Platform aims to reduce Yara\xe2\x80\x99s environmental footprint, supporting the company to deliver on its mission to responsibly feed the world and protect the planet.\nToday, Amazon Web Services is announcing a strategic engagement with Yara, a global leader in farming solutions, to build Yara\xe2\x80\x99s next-generation Digital Production Platform (DPP). This platform will be the key enabler for Yara to digitalize its production system, consisting of 28 production sites (with a total of 122 production units that feature different production processes like NPK, ammonia, nitric acid, nitrate granulation and carbon dioxide plants) and two mines. AWS is Yara\xe2\x80\x99s preferred cloud provider for the DPP, which aims to make production more efficient, reliable, sustainable, and safe. The DPP will serve as the digital core to securely capture and analyze new and existing data to gain insights.\nCombined with applications built on top of the DPP, Yara aims to accelerate operational excellence by optimizing throughput in a safe and sustainable way, reducing energy consumption, minimizing plant downtime, and improving safety and quality control across Yara\xe2\x80\x99s production sites, spanning locations in Europe, Asia Pacific, South America and North America. To achieve this, Yara will combine data gathered from production and business systems into a global data lake built on Amazon Simple Storage Service (Amazon S3). The platform will use the full breadth and depth of AWS technologies, including internet of things (IoT), compute, storage, analytics, and machine learning, to optimize utilization of assets such as compressors and pumps, and also process safety, asset reliability, and production volumes. It will also make use of new technologies such as drones and robotics, which will help employees avoid hazardous situations like when entering confined spaces or working at heights.\nThe DPP will use AWS IoT SiteWise, AWS IoT Greengrass, AWS IoT Core, and AWS IoT Analytics, to detect, collect, and run sophisticated analytics on production data linked to productivity, reliability, environment, safety, quality and innovation. By applying AWS analytics and machine learning services, such as Amazon SageMaker (AWS\xe2\x80\x99s service that enables data scientists and developers to build, train, and deploy machine learning models quickly) to the data, Yara can predict product quality and composition, improve balancing of the site utilities, and detect when machines need repair or maintenance to keep production at optimal efficiency levels.\nSelect image to view full size\nThe new DPP will also support the creation of a Yara Digital Production ecosystem where partners such as suppliers, distributors, manufacturers, and startups will be able to connect, integrate, and collaborate on new business models.\n\xe2\x80\x9cYara\xe2\x80\x99s vision is simple yet extremely powerful. Through our worldwide operations we seek to contribute to a collaborative society, a world without hunger, and a planet respected. The digitalization of our production system contributes to all these goals,\xe2\x80\x9d said Marcus Furuholmen, VP Digital Production in Yara. \xe2\x80\x9cThe new Yara DPP will help us substantially improve efficiencies, foster collaboration with partners on new business models, and most importantly, increase the quality of our fertilizer products, which will lead to more mouths fed globally in a sustainable way.\xe2\x80\x9d\n\xe2\x80\x9cWe are proud to help Yara with its important mission to responsibly feed the world and protect the planet for years to come. The transformation of their production system is yet another example of how AWS helps and supports customers\xe2\x80\x99 unique innovation endeavors,\xe2\x80\x9d said Bill Vass, VP of Technology, AWS, Inc. \xe2\x80\x9cThe Yara and AWS collaboration will have a profound impact on Yara\xe2\x80\x99s global production system. With AWS as its preferred DPP cloud provider, Yara gains access to the broadest and deepest set of cloud functionality, the highest performance and security, and the largest community of partners and customers of any other infrastructure provider.\xe2\x80\x9d\nAbout Yara\nYara grows knowledge to responsibly feed the world and protect the planet. Supporting our vision of a world without hunger and a planet respected, we pursue a strategy of sustainable value growth, promoting climate-friendly crop nutrition and zero-emission energy solutions. Yara\xe2\x80\x99s ambition is focused on growing a climate positive food future that creates value for our customers, shareholders and society at large and delivers a more sustainable food value chain.\nTo achieve our ambition, we have taken the lead in developing digital farming tools for precision farming, and work closely with partners throughout the food value chain to improve the efficiency and sustainability of food production. Through our focus on clean ammonia production, we aim to enable the hydrogen economy, driving a green transition of shipping, fertilizer production and other energy intensive industries.\nFounded in 1905 to solve the emerging famine in Europe, Yara has established a unique position as the industry\xe2\x80\x99s only global crop nutrition company. We operate an integrated business model with around 17,000 employees and operations in over 60 countries, with a proven track record of strong returns. In 2020, Yara reported revenues of USD 11.6 billion.\nPhoto Credit: Yara/Dag Frode Heiland'"
142,How to troubleshoot an AWS IoT Events detector model,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/04/27/HVAC-detector-model-analysis-warning-from-AWS-IoT-Events-console-1-1024x190.png,https://aws.amazon.com/blogs/iot/troubleshoot-aws-iot-events-detector-model/,"b'AWS IoT Events recently launched a new troubleshooting feature that automatically analyzes your detector model for potential syntax errors, structural issues, and runtime errors without needing to publish the detector model first. In this post, you will learn how to use this new feature with your AWS IoT Events detector model.\nAWS IoT Events is a fully managed service that makes it easy to detect and respond to events from IoT sensors and applications. The detector model in AWS IoT Events lets you monitor your equipment or device fleets for failures or changes in operation and trigger actions when such events occur. To learn more about detector models, see the Getting Started with the AWS IoT Events Console guide.\nPrior to the launch of this new feature, to check if a detector model works as expected, customers would first send sample data to the detector model. Next, they would execute the DescribeDetector API to check if the detector state changed as expected. In the case where the detector\xe2\x80\x99s state did not have the expected change, they would then identify the root cause, publish an updated version of the detector model, and then send the sample data again to the detector model. They would keep repeating this debugging cycle until their detector model achieved their desired functionality (or they ran out of time). Such debugging can be time consuming, especially for a complex detector model.\nHere is an example of how debugging can be time consuming. Our detector model continuously monitors the temperature of a room and turns on the heating or cooling mode for the HVAC system as needed to maintain temperature between 68-72 degrees Fahrenheit. The detector computes and stores the average temperature in a variable named averageTemperature.\nAfter sending sample data to this example detector model, we observe that the average temperature is not recomputed. Checking the logs in Amazon CloudWatch for the detector model reveals no information as to why the average temperature is not recomputed. We check the following condition of the detector model that needs to be satisfied in order to recompute the average temperature.\n($variable.resetMe == true) && ($input.temperatureInput.sensorData.temperature < 80 && $input.temperatureInput.sensorData.temperature > 60)\nWe have set the variable resetMe to ""true"", a value of String data type, when the detector enters the start state. After several attempts, we realize that the value, ""true"" (note the quotation marks) can never equal true, a Boolean value. This causes the condition ($variable.resetMe == true) to always evaluate to false.\nThis new troubleshooting feature of AWS IoT Events catches this mismatch of data types much earlier by flagging a warning for the resetMe variable. Without the feature, debugging a much bigger detector model with 20 states and 50 variables, as an example, can be a time-consuming exercise. This new feature performs seven different analyses on your detector model for potential syntax errors (e.g. bad expressions or payloads), structural issues (e.g. missing states or input triggers) and runtime errors (e.g. data type mismatch, missing data, potential to hit service limits, etc.) before publishing the model.\nTo get started with troubleshooting your detector model\nThis step-by-step walkthrough consists of the following sections to debug the previous example detector model:\nPrerequisites\nCreating an input\nCreating a detector model\nTroubleshooting issues with the detector model\nPrerequisites\nFor this use case, make sure that you have an AWS account in the same AWS Region where AWS IoT Events is available. This use case uses the US East (N. Virginia) Region. However, you can choose another AWS Region where AWS IoT Events is available.\nTo create an input for the detector model\nCreate an input named temperatureInput by following the steps:\nSave the following JSON in a file on your computer.\n{\n  ""sensorId"": 1,\n  ""areaId"": 1,\n  ""sensorData"" : {\n    ""temperature"": 70\n  }\n}\nNavigate to the AWS IoT Events console, then choose Inputs, Create input.\nFor Input name, enter \xe2\x80\x9ctemperatureInput\xe2\x80\x9d.\nChoose Upload a JSON file.\nIn the dialog box, choose the JSON file that you created in step 1.\nChoose Create to create the input.\nOnce the input is created successfully, you will be redirected to the AWS IoT Events inputs console page with the following message.\nTo create a detector model\nCreate a draft detector model named areaDetectorModel by following these steps:\nDownload the JSON file.\nNavigate to the AWS IoT Events console, then choose Detector models.\nChoose Create detector model to navigate to Create your detector model console page.\nChoose Import detector model from the left pane and then choose Import to select the JSON file for the detector model that you downloaded in step 1.\nOnce the detector model is created successfully, you will be redirected to the canvas:\nTo troubleshoot issues with the detector model\nTroubleshoot the detector model by following these steps:\nChoose Run analysis.\nWait until the analysis completes and results are displayed in the Detector model analysis panel. Choose Warning to see the details for the incompatible data types:\nTo fix this warning, choose Start state in the imported detector model.\nIn the State pane, choose prepare event under onEnter.\nOn the Add OnEnter event page, expand the first Set variable action.\nChange the Assign value of resetMe variable from the String value of \xe2\x80\x9ctrue\xe2\x80\x9d to the Boolean value of true.\nScroll down the list of all the actions and choose Save.\nChoose Rerun analysis.\nWait until the analysis completes and results are displayed in the Detector model analysis panel with no errors and no warnings.\nYou can also scroll down the list in the Detector model analysis panel to validate that the resetMe variable now has the Boolean data type as shown:\nNow your detector model is ready to be published!\n'"
143,Using AWS IoT Greengrass Version 2 with Amazon SageMaker Neo and NVIDIA DeepStream Applications,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/03/26/architecture-integration-between-aws-iot-greengrass-v2-and-nvidia-jetson-modules.png,https://aws.amazon.com/blogs/iot/using-aws-iot-greengrass-version-2-with-amazon-sagemaker-neo-and-nvidia-deepstream-applications/,"b""AWS IoT Greengrass Version 2 was released for general availability during re:Invent 2020. AWS IoT Greengrass is an Internet of Things (IoT) open source edge runtime and cloud service that helps you build, deploy, and manage device software. Customers use AWS IoT Greengrass for their IoT applications on millions of devices in homes, factories, vehicles, and businesses. AWS IoT Greengrass V2 now offers an open source edge runtime, improved modularity, new local development tools, and improved fleet deployment features. This new version provides a component framework that manages dependencies, and allows you to reduce the size of deployments since you only need to deploy the flexible components required for your application. A component is defined with a YAML or JSON formatted recipe. Additionally, applications no longer have to be AWS Lambda based; you can now package a command-line application directly in your recipe in whatever language you choose. Of course, AWS IoT Greengrass V2 provides components that enable to run Lambda applications as well. You can access the AWS IoT Greengrass V2 open source project here on GitHub and learn more about what\xe2\x80\x99s new in AWS IoT Greengrass Version 2 in the AWS IoT Greengrass Developer Guide.\nThis post will walk you through the following two use cases of the integration between AWS IoT Greengrass V2 and NVIDIA Jetson modules:\nHow to deploy and use GPU accelerated Image Classification on NVIDIA Jetson modules (Nano, TX2, Xavier NX and AGX Xavier supported) with Amazon SageMaker Neo and\nHow to deploy a Video Analytics Pipeline with NVIDIA DeepStream on Jetson modules.\nThe two use case walkthrough sections are not dependent on each other. If you want to only deploy the NVIDIA DeepStream application sample, you can skip Section 1 and go directly to Section 2.\nPre-requisites\nNVIDIA Jetson module (Nano, TX2, Xavier NX or AGX Xavier)\nNVIDIA Jetpack 4.4\nGit\nopencv-python (if you are using a sd image this is included otherwise install with NVIDIA SDK Manager)\nNumPy (install this ahead of time as it can take some time to install)\nAWS IoT Greengrass V2\nAWS account with administrator access \xe2\x80\x93 If you don\xe2\x80\x99t have one, see Set Up an AWS Account\nAWS Command Line Interface (CLI) with AWS IoT Greengrass V2 support \n[For part 2] NVIDIA DeepStream SDK installed on Jetson module\nSection 0: AWS IoT Greengrass Version 2 Installation\nThis post is not an introduction to AWS IoT Greengrass V2. For detailed steps for installing and running AWS IoT Greengrass V2 on edge devices, refer to the getting started section of the developer guide.\nIf you just want to install AWS IoT Greengrass Version 2 on Jetson modules and get started quickly, then you can take the installation script we prepared in GitHub and run this bash script on your Jetson module. Once it successfully installs, you can move on to the next sections.\nSection 1: Image classification with Amazon SageMaker Neo compiled models\nIn this section, we are going to walk you through how to run an Amazon SageMaker Neo-compiled and optimized image classification neural network model. This is common in use cases such as animal image classification.\nThis example will take a pre-made JPEG image of a dog converted to a NPY file, perform inference (classification) on it, and send the results as a message to AWS IoT Core via MQTT.\nFigure 1: Picture of a dog\nIn the context of AWS IoT Greengrass V2, this section will deploy three AWS IoT Greengrass components on your Jetson module:\nvariant.Jetson.DLR \xe2\x80\x93 installs the appropriate Amazon SageMaker Neo DLR on your device. Learn more about AWS IoT Greengrass V2 DLR Installer in the Developer Guide.\nvariant.Jetson.ImageClassification.ModelStore \xe2\x80\x93 installs ResNet18 image classification models optimized for Jetson modules\naws.greengrass.JetsonDLRImageClassification \xe2\x80\x93 Contains the Python example that does image classification and sends a message to AWS IoT Core using the MQTT protocol.\nPLEASE NOTE: This example deployment will install some Python packages outside of a virtual environment. To be specific, python-opencv is specially installed as part of Jetpack 4.4. so the installation the Debian package may run for an extended period of time. NumPy can also take a long time to install.\nCheckout components for deployment\nIn this section we will clone the sample repository from GitHub and prepare the components for deployment. You will get Git installed to proceed.\nTo prepare the samples for deployment:\n1. From your Jetson module, check out the GitHub repository with the following command:\ngit clone https://github.com/aws-samples/aws-iot-greengrass-v2-deploy-nvidia-deepstream.git\n2. In the GitHub repository, copy the recipes in the jetson_inference/recipes into your local GreengrassCore (i.e., ~/GreengrassCore/recipes). See the directory trees below that show the source paths in GitHub vs what it should look like in your GreengrassCore home directory after you copy them.\nDirectory structure for deployment\n  3. Copy the directory contents of jetson_inference/artifacts to your GreengrassCore/artifacts directory so that the folder structure looks like the following.\nGitHub Source\n4. Next, we will upload the component versions to the AWS IoT Greengrass V2 cloud service. Run the following commands on your Jetson device in your GreengrassCore home directory (~/GreengrassCore) you copied the recipes and artifacts into:\naws greengrassv2 create-component-version --inline-recipe fileb://recipes/aws.greengrass.JetsonDLRImageClassification-1.0.0.json\naws greengrassv2 create-component-version --inline-recipe fileb://recipes/variant.Jetson.DLR-1.0.0.json\naws greengrassv2 create-component-version --inline-recipe fileb://recipes/variant.Jetson.ImageClassification.ModelStore-1.0.0.json\nDeploy the sample components provided to Jetson module through AWS IoT Greengrass V2\nBefore starting this section, verify that you have successfully installed AWS IoT Greengrass V2 on your Jetson device. Uploading components to the AWS IoT Greengrass V2 service will allow you to install the examples to your AWS IoT Greengrass Core software installation on your Jetson device. Verify you have a valid installation of AWS IoT Greengrass Core software v2 \xe2\x80\x93 refer to the Pre-requisites section for help.\nTo deploy the components to your Jetson module:\nNavigate to the AWS IoT Core Console (https://console.aws.amazon.com/iot/home).\nChoose Greengrass.Components to deploy\nChoose Components \xe2\x80\x93 You should see the three components you created via the AWS CLI.\nChoose any one of the three components you created.\nChoose Deploy.\nChoose Create new deployment.\nChoose Next.\nFor Name give the deployment a name.\nFor Target type, choose Thing Group and enter the name of your device core, which can be found at the following link to the AWS IoT Greengrass Core page within the AWS Management Console:   https://console.aws.amazon.com/iot/home?region=us-east-1#/greengrass/v2/cores).\nChoose Next.\nOn the Select Components screen, make sure to select all three of the components you created and choose Next.\nOn the Configure Components screen, choose Next.\nOn the Configure advanced settings screen, choose Next.\nOn the Review screen choose Deploy.\nVerify Inference Results\nIf you have successfully deployed the three components, inference should start immediately.\nThis will show inference data coming from your Jetson device resulting from a successful deployment. If you do not see any data, please go through and verify successful completion of each procedure outlined in the \xe2\x80\x9cDeploy the Components to your account\xe2\x80\x9d section, or consult the AWS IoT Greengrass V2 Troubleshooting Guide.\nTo view results with the MQTT Test Client:\nOn the AWS Management Console, choose AWS IoT Core\nChoose Test\nChoose MQTT Test ClientEnter topic to filter messages\nEnter demo/topic for Subscription Topic \nChoose Subscribe to topicInference/classification messages\nSection 2: Deploy NVIDIA DeepStream Application with AWS IoT Greengrass V2\nNVIDIA\xe2\x80\x99s Jetson product family enables customers to extend server-class compute to devices operating at the edge. NVIDIA has developed a streaming analytics toolkit called DeepStream to leverage TensorRT and CUDA to optimize AI performance at the edge. The DeepStream SDK provides an end-to-end video processing and ML inferencing analytics solution for transforming pixels and sensor data into actionable insights.\nIn this section, we will present how AWS can help deploy DeepStream apps and new ML models run by DeepStream apps on NVIDIA Jetson modules at scale with AWS IoT Greengrass V2.\nFor this demonstration, we will use the sample model and sample DeepStream application developed by NVIDIA in their DeepStream SDK as an example. You are also welcome to use your customized models and DeepStream apps.\nBefore starting the deployment process, first verify your DeepStream installation on your Jetson module:\n1. Enter this command on your terminal to start the reference application\n$ deepstream-app -c <path_to_config_file>\n** <path_to_config_file> is the pathname of one of the reference application\xe2\x80\x99s configuration files\n2. Verify DeepStream application runs successfully on your terminal\nNote, if you are using a Jetson Nano , we recommend using /opt/nvidia/deepstream/<your deepstream version>/samples/configs/deepstream-app/source8_1080p_dec_infer-resnet_tracker_tiled_display_fp16_nano.txt as your configuration file.\nIf the sample app starts without reporting error, then proceed to the deployment section in this article.  If you have trouble running this sample app, please refer to DeepStream documentation troubleshooting section for more details.\nTo deploy the NVIDIA DeepStream Application with AWS IoT Greengrass V2:\nStep 0: Create a DeepStream application package\nBefore completing the steps in this section, first determine if you\xe2\x80\x99d like to use a sample DeepStream application package or use your own customized deployment package. We have created a sample DeepStream application package that consists of three components:\nML model (directly sourced from DeepStream SDK provided by NVIDIA:  https://developer.nvidia.com/deepstream-download)\nModified version of sample DeepStream application configuration file.\nModified version of sample DeepStream primary GIE configuration file.\nYou can use this as an example to follow along the deployment steps, or you can use your own customized version of DeepStream configuration files and your own trained ML models.\nStep 1: Prepare local environment\n1. If you have not yet cloned the GitHub repository, run the following command to clone it locally\ngit clone https://github.com/aws-samples/aws-iot-greengrass-v2-deploy-nvidia-deepstream.git\n2. Export the path to the GitHub repository locally as an environment variable by running:\ncd aws-iot-greengrass-v2-deploy-nvidia-deepstreamexport DEMO_PATH=${PWD}\nStep 2: Upload your package into an Amazon S3 bucket\nCreate an S3 bucket by running the following command. (if you already have an S3 bucket, skip this step and use your existing bucket in Step XX):\naws s3 create-bucket \xe2\x80\x93bucket [YOUR_S3_BUCKET_NAME]\nEnter into nvidia_deepstream_integration folder in your GitHub repository by running:\ncd $DEMO_PATH/nvidia_deepstream_integration\nUpload our prepared sample deployment package in our S3 bucket:\naws s3 cp jetson_deployment.zip  s3:// [YOUR_S3_BUCKET_NAME]/jetson_deployment.zip\nStep 3: Create an AWS IoT Greengrass V2 component\nRename greengrass_component.json file by adding a postfix  that AWS IoT Greengrass V2 uses as version number. For example:\nmv greengrass_component.json greengrass_component-1.0.0.json\nOpen greengrass_component.json file with your text editor, and replace the placeholder [YOUR_S3_BUCKET_NAME] with the actual bucket name that you used in Step 2.\nUpload an AWS IoT Greengrass V2 component to the AWS IoT Greengrass cloud service.\naws greengrassv2 create-component-version --inline-recipe fileb://greengrass_component-1.0.0.json\nYou will see the following message returned by AWS CLI:\n{\n\xe2\x80\x9carn\xe2\x80\x9d: \xe2\x80\x9carn:aws:greengrass:us-west-2:XXXXXXXXXXXX:components:deepstream-deployment:versions:1.0.0\xe2\x80\x9d,\n\xe2\x80\x9ccomponentName\xe2\x80\x9d: \xe2\x80\x9cdeepstream-deployment\xe2\x80\x9d,\n\xe2\x80\x9ccomponentVersion\xe2\x80\x9d: \xe2\x80\x9c1.0.0\xe2\x80\x9d,\n\xe2\x80\x9ccreationTimestamp\xe2\x80\x9d: \xe2\x80\x9c2021-03-19T14:13:30.126000-07:00\xe2\x80\x9d,\n\xe2\x80\x9cstatus\xe2\x80\x9d: {\n\xe2\x80\x9ccomponentState\xe2\x80\x9d: \xe2\x80\x9cREQUESTED\xe2\x80\x9d,\n\xe2\x80\x9cmessage\xe2\x80\x9d: \xe2\x80\x9cNONE\xe2\x80\x9d,\n\xe2\x80\x9cerrors\xe2\x80\x9d: {}\n}\n}\n** Note: the default AWS IoT Greengrass V2 role does not have S3 access. So please manually add S3 access to your AWS IoT Greengrass V2 role if you have not already done so by running the following AWS CLI command or doing it manually in the AWS Management Console.\naws iam attach-role-policy --role-name [Your_Greengrass_V2_role_name] --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\nIf you encounter Invalid choice: 'greengrassv2', this indicates that you need to download and update your AWS CLI service to the latest version.\nStep 4: Deploy the AWS IoT Greengrass V2 component\nNavigate to the following page on AWS IoT console and click on \xe2\x80\x9cDeploy\xe2\x80\x9d.\nAWS Management Console, AWS IoT Greengrass V2 Components Deployment\nVerify that the component ran successfully either from your AWS IoT Greengrass Core software v2 runtime log located at /greengrass/v2/logs.\nIn that folder, there\xe2\x80\x99s greengrass.log (for the nucleus) and <componentName>.log for each component.\nYou can also verify by observing if you are receiving inferencing results on your configured DeepStream pipeline sink.\nSection 3: Additional Resources\nLocal deployment of AWS IoT Greengrass V2 components\nYou can also deploy locally without an internet connection as outlined in the AWS IoT Greengrass V2 Getting Started Guide (Create your first component section).\nChange camera source\nYou can replace the image inference with a camera interface. Because most Jetson modules do not come with cameras, your method for interfacing with the camera may vary for your type of camera. Please refer to inference.py for more details.\nDeepStream IoT Test Applications (test 4 or test 5 in DeepStream application)\nDeepStream applications have a function called Gst-nvmsgbroker. This plugin can send payload messages to AWS IoT Core** using MQTT protocol. It accepts any buffer with NvDsPayload metadata attached and uses the nvds_msgapi_* interface to send the messages to the server. If you need to use AWS IoT Core or AWS IoT Greengrass as a MsgBroker sink for your DeepStream application, you need the shared library from this GitHub: AWS IoT Core Integration with NVIDIA DeepStream.\nNVIDIA DeepStream integration with AWS IoT Greengrass V1 (legacy)\nTo review the integration between DeepStream and AWS IoT Greengrass V1, please refer to the following GitHub repository. https://github.com/aws-samples/aws-iot-greengrass-deploy-nvidia-deepstream-on-edge\nSummary: Start building!\nIn this post we\xe2\x80\x99ve shown two ways to use AWS IoT Greengrass V2 on NVIDIA Jetson devices: classify images using SageMaker Neo and deploy a DeepStream video analytics pipeline for video data. To help you evaluate, test, and develop with this new release of AWS IoT Greengrass, the first 1,000 devices in your account will not incur any AWS IoT Greengrass charges until December 31, 2021. You will still incur charges for other AWS services you use with your applications running on AWS IoT Greengrass such as AWS IoT Core. We can\xe2\x80\x99t wait to see what you build!\nReferences\nChihuahua picture is part of the Stanford ImageNet resource collection located at http://vision.stanford.edu/aditya86/ImageNetDogs.\nNVIDIA DeepStream Developer Guide: https://developer.nvidia.com/deepstream-getting-started\nAWS IoT Greengrass V2 Developer Guide: https://docs.aws.amazon.com/greengrass/index.html\nAbout The Authors\nRyan Vanderwerf is a Partner Solutions Architect focusing on IoT partnerships\n          Yuxin Yang is an IoT Consultant in AWS Professional Services\n """
144,AWS IoT Device Defender Announces ML Detect GA,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/03/09/AWS-IoT-Device-Defender-Alarms-1024x551.png,https://aws.amazon.com/blogs/iot/ml-detect-for-device-defender/,"b'Today, AWS announced the general availability of AWS IoT Device Defender Machine Learning Detect and Mitigation (ML Detect), a new feature that automatically detects IoT device-level operational and security anomalies based on learnings from past device data. Customers can already use AWS IoT Device Defender\xe2\x80\x99s Rules Detect feature to manually set static alarms. ML Detect makes this easier by automatically setting your fleet\xe2\x80\x99s expected behavior so that you don\xe2\x80\x99t need an in-depth understanding of how your devices behave across a range of metrics to get started like messages sent, disconnect frequency, and bytes in/out. Also, ML Detect automatically updates the expected behavior based on new data trends caused by seasonality and other changing factors.\nThis post presents an overview of the feature, highlights how some of our customers are benefitting from device-level monitoring and operational reliability provided by the feature, and walks you through steps to get started.\nOverview of AWS IoT Device Defender ML Detect\nML Detect uses machine learning to set thresholds for the expected behavior of your IoT device. The feature makes it easier to use AWS IoT Device Defender Detect, as you no longer need a comprehensive understanding of how your device should behave (such as disconnect frequency, number of messages sent, etc.) before configuring the feature. When an anomaly is identified, you can respond by choosing a built-in mitigation action, like quarantining a device.\nAWS IoT Device Defender ML Detect includes the following capabilities:\nSupports six cloud-side metrics and seven device-side metrics for near-real-time continuous monitoring and applies machine-learning algorithms to inference if there is an anomaly in metric datapoints.\nSupports confidence level HIGH/MEDIUM/LOW in ML alarm notifications.\nDuring the initial ML training period, the feature will aggregate a minimum of 25,000 datapoints per metric for 14 days across your devices, and at the initial model creation, will begin identifying device behavior anomalies.\nAfter the initial model is created,  the feature retrains the model each day with a minimum of 25,000 datapoints per metric to refresh the expected device behaviors based on the latest trailing 14 days\nSupports built-in mitigation actions so you can address device issues.\nUses the same alarm mechanism as AWS IoT Device Defender Rules Detect, which includes Amazon SNS notification integration.\nCustomers already benefiting from ML Detect\nBy using AWS IoT Device Defender ML Detect, our customers are providing more automated monitoring, troubleshooting and support to their end customers. The feature helps them meet their customer service commitments and improves the overall reliability of their system.\nERA Home Security: meeting customer service commitments with automated device monitoring and mitigation\nERA Home Security is a UK-based home security hardware and solution company that has been in business since 1838. They recently migrated their home-grown IoT infrastructure onto AWS IoT and started using AWS IoT Device Defender ML Detect to monitor their device fleet for connectivity issues and anomalous behaviors, such as tamper events. Since implementing AWS IoT Device Defender ML Detect in September 2020, ERA Home Security was able to improve their customer experience by meeting over 99.9% of their customer service commitments. If devices went offline, the ERA team was notified immediately and able to resolve issues quickly based on the alarm details. \xe2\x80\x9cThe results are very promising and I can see us scaling up our usage of ML Detect in our production environment. Giving our highly technical staff the freedom to innovate on our customers\xe2\x80\x99 behalf and leave the heavy lifting of devices mitigation automation to Device Defender ML Detect,\xe2\x80\x9d Jey Jeyasingam, Chief Technology Officer of ERA Home Security shared with AWS.\nJane: proactive device monitoring for better protection and care of customers\nJane is a smart living technology company based in Belgium that provides seniors, as well as senior living communities, in-home health monitoring solutions. These solutions connect seniors with their care providers via dashboards and alerts for proactive and reactive wellness updates. As Jane worked to bring their solutions to senior living communities, their monitoring devices experienced poor connectivity in local 3G networks. They frequently received reports of disconnect issues, almost exclusively from customers. Since deploying AWS IoT Device Defender ML Detect, Jane has been able to see which device is dropping connection unexpectedly and provide more proactive support and troubleshooting for their customers. These improvements are critical as Jane expands their business in the B2B market. \xe2\x80\x9cThrough AWS IoT Device Defender ML Detect, we can proactively monitor and protect our customers that contributes to the reliability of our system. This way our care-givers and seniors can sleep soundly,\xe2\x80\x9d Evert Van Cauwenberg, Chief Technology Officer of Jane commented to AWS.\nGetting started with ML Detect in the AWS IoT Console\nYou can use the AWS IoT Console or the AWS CLI to create a ML-based Security Profile, which will give you the option to monitor standard metrics on your entire device fleet or selected device groups. The following steps detail how to get started with ML Detect in the AWS IoT Console:\nStep 1 Enable ML Detect on your device group(s)\nTo start using ML Detect, you first create a Security Profile that uses machine learning to learn expected device behaviors by automatically creating models based on historical device metric data. The Security Profile can be assigned to a group of devices or all the devices in your fleet.\n1. Set basic configurations\nOpen the AWS IoT Core. In the navigation pane, choose Detect, Security Profiles, Create Security Profile, Create ML anomaly Detect profile.\nFrom the Target drop down, select device group(s) or all of your fleet devices for monitoring.\nFor Security Profile name, enter a value.\nFor Description (optional), enter a value that describes your security profile.\nFor Select metric behaviors in Security Profile, clear any device metrics selected that you don\xe2\x80\x99t want to monitor\n(Optional) Set up SNS notification so you can receive alarm notifications via email, text or any incident response system you send alarm notifications to.\nFor Topic, you have the option to create a new SNS topic or using existing one from drop down.\nFor Role, select predefined role. If you don\xe2\x80\x99t have any predefined roles, you can go to IAM to set up Role (see IAM role further instructions.)\nNote: Cloud-side metrics will be collected from device connection and messaging logs from AWS IoT without requiring device-side implementation. Device-side metrics will require device-side implementation (e.g. AWS IoT  Device Client or AWS IoT Device Defender sample agent integration with your device firmware).\n2. Edit metric behaviors\nClick \xe2\x80\x98Next\xe2\x80\x99 to go to \xe2\x80\x9cEdit metric behaviors\xe2\x80\x9d. This action allows you to customize the default metric behavior settings provided in previous step.\n3. Review configuration\nAfter editing metric behaviors, click \xe2\x80\x98Next\xe2\x80\x99 and reach \xe2\x80\x9cReview configuration\xe2\x80\x9d. Confirm the configuration of the metric behaviors in your ML Security Profile or return to the previous steps to make any edits.\nOnce you click Create ML Security Profile, your ML model(s) will start building.\nStep 2: Behaviors and ML training\nNow that we have the models created, let\xe2\x80\x99s check in on their status.\nIn the AWS IoT Console, go to Defend > Device > Security Profiles and select your Profile, select Behaviors and ML training tab. You will be presented with status of the ML model training. You can see behavior names at the top, such as Messages_sent_ML_behavior, ML as Threshold type and \xe2\x80\x98Pending build\xe2\x80\x99 as Model status.\nBuilding State\nOnce the model status becomes \xe2\x80\x98Active\xe2\x80\x99, it will start inferencing anomalies in your device data and update itself based on new data patterns across your devices.\nActive state\n  Step 3: Review your ML Detect alarms\nAfter the initial ML models are built (it usually takes 14 days with sufficient training data), they are ready for data evaluations, and thereafter, you can view Detect alarms inferred by the models on an ongoing basis.\n1. Stay in AWS IoT console, let\xe2\x80\x99s go to Defend > Detect > Alarms and review. You will be presented with two tabs: one showing Active alarms and one tabbed as History.\nAs displayed in the example Alarms tab below, we can see thing (device) \xe2\x80\x98ddml1,\xe2\x80\x99 which is attached to the ML_Detect_profile Security Profile, has made connection attempts and incurred failed authorizations.\n2. Click over to the History tab, you can see all the alarm events that occurred over the past 24 hours (you can select additional options from dropdown to display up to 30 days).\nThe green line represents alarms cleared and red indicates devices still in alarm. Hovering over the lines and dots, you can see the date, time, and status of the alarms during this timestamp, an example shown below.\n3. Scroll down the same page, you can also view additional details about these past alarms and their state.\nHere you can see thing name (device) \xe2\x80\x98ddml12\xe2\x80\x99 received too many messages and subsequently cleared them. This action then cleared the alarm state for \xe2\x80\x98ddml12\xe2\x80\x99.\n4. Dive deeper by clicking on the thing name. Here, we select \xe2\x80\x98ddml12\xe2\x80\x99 and see the graph in the Defender metrics section (see below).\nIt shows a spike in messages received, which triggered an alarm. However, the alarm cleared thereafter.\nStep 4: Fine-tune your ML Detect alarms\nOnce your models are in Active state, you can update your Security Profile ML behavior settings to try out different configurations. Three confidence levels are available : High, Medium and Low.\nHigh confidence means low sensitivity in anomalous behavior evaluation and lower number of alarms.\nMedium is medium sensitivity for anomalous behavior and medium number of alarms.\nLow confidence means high sensitivity and higher number of alarms.\n1. To adjust your notifications, stay in AWS IoT console, go to Defend > Detect > Security Profiles and select the profile radio button of the security profile you want to modify and review. Then click Actions > Edit.\n2. On the Set basic configurations page, you can select and de-select more options for metrics as well as attach your device to other devices or groups of devices.\n3. Click Next to go to the edit metric behaviors screen.\nFor example, we alter Authorization failure datapoints required to trigger alarm from the default of 1 to 3 and modify the confidence to Low. With these parameters, we will see a device is allowed to attempt authorization 3 times before it raises an alarm and will also set the notification confidence level to Low.\nSimilarly, you can alter other settings as you see fit for your devices, their alarms, datapoints required to clear alarm, and suppressed notifications.\n4. Once complete, click Update ML Security Profile \xe2\x80\x93 these new settings will be saved. You can access these changes by clicking on the profile and viewing the updates in the Behaviors and ML training.\nStep 5: Mitigate identified device issues\n1. Create a quarantine thing group\nBefore we set up quarantine mitigation actions, let\xe2\x80\x99s create a quarantine group where we will move the device in alarm. You can also use any existing group if you have one.\nGo to Manage > Thing groups > create Thing Group and give your group a suitable name. We will name ours \xe2\x80\x98Quarantine_group.\xe2\x80\x99 Then, click Create thing group button at the bottom of the page. Under Thing group, Security, apply the following policy to the thing group.\n{""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {""Effect"": ""Deny"",\n      ""Action"": ""iot:*"",\n      ""Resource"": ""*"",\n    }\n  ]\n}\nJSON\n  2. Create a mitigation action\nOnce we have the group created, we can set up a mitigation action that moves devices in alarm into \xe2\x80\x98Quarantine_group.\xe2\x80\x99\nGo to Defend > Mitigation Actions > Click Create\nLet\xe2\x80\x99s create the following setup:\nAction name: Give the Action a name, such as Quarantine_action.\nAction type: We will select \xe2\x80\x98Add things to thing group (Audit or Detect mitigation).\xe2\x80\x99\nAction execution role: choose Create Role or select an existing role if you have created one earlier.\nParameters: select Thing groups. We used Quarantine_group, which we created earlier.\nOnce all the sections are completed, save this action.\n3. Mitigate Detect alarms\nLet\xe2\x80\x99s go to Defender > Detect > Alarms\nUnder the \xe2\x80\x98Active\xe2\x80\x99 tab, we can see multiple devices are in the alarm state and are filling the Published alarms page with too many notifications. Let\xe2\x80\x99s select a device and apply a mitigation action.\nSelect the device which you want to move to quarantine and click \xe2\x80\x98Start Mitigation Actions.\xe2\x80\x99\nOnce you click the \xe2\x80\x98Start Mitigations Actions\xe2\x80\x99 button, you will be presented with pre-created mitigation actions. Let\xe2\x80\x99s use the one we created earlier.\nNow that the device is isolated in \xe2\x80\x98Quaratine_group\xe2\x80\x99, we can further investigate the root cause of the issue. Once the investigation is completed, we can move the device out of quarantine or take further actions.\nIn addition, you can set up everything we\xe2\x80\x99ve walked through above using the AWS CLI if you want to automate the AWS IoT Device Defender ML Detect workflows in your DevOps pipeline. For more instructions on how to do so, please refer to the Detect commands documentation\xc2\xad or sample code on Github.\n'"
145,Connecting home appliances with a smart home solution built on AWS in the AWS China Region,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/03/11/aws-iot-device-management-for-fleet-management.png,https://aws.amazon.com/blogs/iot/connecting-home-appliances-with-a-smart-home-solution-built-on-aws-in-the-aws-china-region/,"b'This blog post introduces how the manufacturers of home appliances can use AWS Services to build and maintain their smart home solutions. These solutions are both the platforms that power their connected products as well as the applications consumers use to control those products. This blog post illustrates a real use case from a customer that manufactures home appliances in China and sells them throughout the world. We will walk through a reference architecture that outlines their end-to-end solution and describe how the customer uses AWS IoT together with other AWS Services for their core use cases. You\xe2\x80\x99ll learn how the customer built a secure way for smart home appliances to share information with the families that use them, and how the customer securely manages their fleet of home appliances at scale within the AWS China Region. This blog post includes Python code snippets so you can implement a similar solution, where a device sends data to a smart home IoT platform and securely shares multimedia files from the device to customer-facing mobile or web applications.\nHome appliances are becoming smarter as their users interact with them\nWith the continuous development of IoT and AI, smart home device growth has accelerated. The trend towards smarter devices and the smart home as a whole is primarily for two objectives:\nIntelligent and personalized interaction between home appliances and end users\nEase of interoperability between two or more intelligent home appliances\nAWS IoT makes it easy for you to build scalable IoT applications that collect, process, analyze, and act on data generated by connected home devices without having to manage any infrastructure. AWS IoT also integrates with other AWS Services, so you can easily build complete smart home solutions and focus your efforts on delivering new experiences and adding even more value to your consumers.\nThis blog post focuses on two key services within the AWS IoT service portfolio \xe2\x80\x93 AWS IoT Core and AWS IoT Greengrass. In addition to AWS IoT Core and Greengrass, AWS has broad and deep IoT services, from the edge to the cloud, and provides a powerful and comprehensive ecosystem of technology and solutions that help customers build, manage, and continually improve their IoT devices and platforms. For more information about AWS IoT, refer to https://aws.amazon.com/iot/.\nAWS IoT Core\nAWS IoT Core is a fully managed service that lets you connect IoT devices to the AWS Cloud and to other IoT devices without the need to provision or manage servers. For more information about AWS IoT Core, refer to the AWS IoT Technical Documentation: https://docs.aws.amazon.com/iot/latest/developerguide/what-is-aws-iot.html\nAWS IoT Greengrass\nAWS IoT Greengrass seamlessly extends AWS Services to physical devices to enable them to operate locally on the data they generate while still using the AWS Cloud for management, analysis, and persistent storage. For more information about AWS IoT Greengrass, refer to the AWS IoT Greengrass Technical Documentation: https://docs.aws.amazon.com/Greengrass\nIn the next section, we will describe a number of other AWS Services that this customer used to build their IoT infrastructure for their smart home use case.\nSmart Home platform powered by AWS IoT services\nIn this section, we\xe2\x80\x99ll discuss the real customer use-case and illustrate how AWS IoT services play a main role in their smart home solution.\nSolution Background\nFirst, let\xe2\x80\x99s understand the background of what challenges the customer sought to overcome, and the technical architecture of their smart home solution. This customer is a world-class manufacturer and seller of home appliances. They wanted to build a new IoT infrastructure so that they could easily connect those appliances to the cloud, manage them at scale, and make their products more intelligent. To achieve these goals, they built a solution using a number of AWS Services, such as:\nAWS IoT Core: easily and securely connect devices to the cloud, and reliably scale to billions of devices and trillions of messages\nAWS IoT Device Management: register, organize, monitor, and remotely manage connected devices at scale\nAWS IoT Greengrass: bring local compute, messaging, data management, sync, and ML inference capabilities to edge devices\nAmazon Cognito: offer simple and secure user sign-up, sign-in, and access control\nAmazon API Gateway: create, maintain, and secure APIs at any scale\nAWS Lambda: run code without thinking about servers or clusters. Only pay for what you use\nAmazon S3: object storage built to store and retrieve any amount of data from anywhere\nAmazon Relational Database Service (RDS): set up, operate, and scale a relational database in the cloud with just a few clicks\nSolution Architecture\nThe technical architecture of the customer\xe2\x80\x99s solution is composed of edge devices (such as refrigerators), a mobile app for remote management, and the cloud-based smart home IoT platform used for home appliance fleet management at scale. AWS IoT Greengrass was deployed on the refrigerators which act as a gateway between other smart home devices, such as a microwave oven, and the smart home IoT platform. Authentication of users in the mobile app is handled through an integration of the customer\xe2\x80\x99s existing SSO solution with an Amazon Cognito Identify Pool. The smart home IoT platform is built with AWS IoT Core and AWS Lambda to provide customer device registration, easy device fleet management at scale, and the interconnection of end users and the home appliances connected to this platform.\nFigure 1: IoT platform architecture built using AWS Services in the AWS China Region\nAs shown in Figure 1, the solution implementation is:\nStep 1: Refrigerators connect to the internet and send messages to AWS IoT Core through MQTT protocol. Microwave ovens connect to AWS Greengrass deployed on the refrigerators and then connect to AWS IoT Core via the internet and MQTT protocol.\nStep 2: AWS IoT Core uses a rule engine to extract necessary data from the messages and pass the data to AWS Lambda function\nStep 3: AWS Lambda functions generate and then return an Amazon S3 presigned URL to store multimedia such as images, audio files, and videos\nStep 4: AWS Lambda functions write data into Amazon RDS MySQL\nStep 5: Mobile apps request identity token from the Amazon Cognito account previously integrated with the customer\xe2\x80\x99s AWS Directory Service, and then send requests to AWS ALB\nStep 6: Application-layer firewall deployed on Amazon EC2 instances protect APIs supported by Amazon API Gateway\nStep 7: Amazon API Gateway receive requests from Mobile apps and trigger AWS Lambda function to fulfill the requests.\nTaking Action and Driving insights at the Edge\nThis solution uses an Android tablet on a refrigerator door to provide an end user interface and several cameras installed on the inside of the refrigerator door. The Android interface supports interactions such as typing, verbal commands, and visual via the in-door cameras. These cameras leverage an image recognition solution from a 3rd party to detect what food is being added and removed from the refrigerator. That data is updated in an Amazon RDS MySQL database. Then, the customer surfaced the data to the end users via the Android Tablet or on their mobile phone app so that the end users can gain real-time insights about what food is available in their fridge.\nFigure 2: Tablet interface and in-door cameras in refrigerator\nSolutions for Use Cases\nLet\xe2\x80\x99s walk through the core use cases for this solution. The use cases are\nEnd users register their refrigerators using the mobile app, which adds the device to the customer\xe2\x80\x99s smart home platform.\nEnd users sign in to the mobile app to interact with the smart home platform.\nEnd users search existing ingredients and add new ones in the fridge using their tablet and/or mobile app.\nCustomer securely manages the fleet of refrigerators registered on the smart home platform.\nSolution for Use Case 1: Users Register the refrigerator\nFirst, we will outline the process of how the refrigerators are registered to the smart home IoT platform. Each refrigerator has a preset certificate generated and placed in the tablet by the manufacturer to access to AWS IoT Core for the smart home IoT platform. The preset certificates are only granted the permissions needed to create a Thing in AWS IoT Core, which results in a new device added to the customer\xe2\x80\x99s smart home IoT platform, as well as to download certificates to the refrigerator, which means security to the customer. The refrigerator uses these preset certificates to connect to AWS IoT Core and create a thing for itself, and save the client ID and download certificates to its local storage. These new certificates are not activated until the refrigerator is paired to a mobile app user. The end user uses the mobile app to scan the barcode located on the refrigerator. The barcode contains the refrigerator\xe2\x80\x99s device information such as a unique serial number and hardware types. Once the mobile app scans the barcode, the information is sent to the smart home IoT platform and verified. Once the verification succeeds the refrigerator is recorded in the database of the customer\xe2\x80\x99s device management service and the certificates of the thing for the refrigerator is activated in AWS IoT Core. Then the refrigerator completes the registration process in the smart home IoT platform. This process is highlighted in the figure below.\nFigure 3: End users register their refrigerators to the smart home platform\nSolution for Use Case 2: End users sign in to the smart home platform\nEnd users need to register and log in to the smart home IoT platform in order to control the refrigerators remotely. After they register the device as described in the first use case solution, end users can use the Android tablet to perform operations from the front of the refrigerator, such as sending a voice message, without needing to log in to the smart home IoT platform. From the perspective of user management, this solution treats the end users who control the same refrigerator as a family group. For example, the husband can use his iPhone as an end user to log into the IoT platform\xe2\x80\x99s iOS app to control the refrigerator, and the wife uses her Android phone app as another end user to log into the IoT platform and control the same refrigerator. More importantly, the Android tablet on the refrigerator is also treated as an end user who can control the refrigerator but does not need to log into the IoT platform. Instead, the tablet uses certificates as its identity to communicate with the smart home IoT platform. These authentication approaches help the smart home IoT platform fulfill different authentication requirements to keep the refrigerator and the data it generates secure, while also optimizing the end user experience.\nFigure 5: End users sign into the smart home platform\nSolution for Use Case 3: End users add and search ingredients from the tablet and mobile app\nWhen a user closes the refrigerator door, an AWS Lambda function of \xe2\x80\x9cadd ingredients\xe2\x80\x9d is triggered and is invoked by a REST API managed with the Amazon API Gateway service. The 3rd party image recognition solution detects if new ingredients were added to or removed from the fridge, and if any were added or removed they are inserted into/deleted from a database using Amazon RDS for MySQL. Then another Lambda function \xe2\x80\x98ingredients search\xe2\x80\x99 will retrieve all ingredients currently in the refrigerator and send them back to the tablet installed on the refrigerator and the user\xe2\x80\x99s mobile app connected to the smart home IoT platform. Both the tablet and mobile app can check for ingredients in the refrigerator in real time by video data streamed from the in-door cameras, so a user can browse what food is available in the fridge without opening the door, saving energy and preserving food quality, or when they are on-the-go from anywhere, such as at the grocery store.\nFigure 6: End users add and search ingredients from tablet and mobile app\nSolution for Use Case 4: Secure fleet management\nThe customer\xe2\x80\x99s smart home IoT platform leverages AWS IoT Device Management to organize and manage their fleet of refrigerators and store device records in a database. The thing shadows in AWS IoT Core sync with the state of the refrigerators, and AWS IoT Device Management indexes attributes, such as \xe2\x80\x9cRunningMode\xe2\x80\x9d and \xe2\x80\x9cDoorOpened\xe2\x80\x9d, in thing shadows. Then the smart home IoT platform can filter out the refrigerators with specific attribute values and take action based on those attributes. For example, they can organize a things group of refrigerators with the \xe2\x80\x9cDoorOpened\xe2\x80\x9d state and trigger an alarm to both the Android tablet and the user\xe2\x80\x99s mobile app if the refrigerator has the \xe2\x80\x9cDoorOpened\xe2\x80\x9d state for more than 10 mins.\nFigure 4: leverage AWS IoT Device Management to manage refrigerators\nFigure 4: leverage AWS IoT Device Management to manage refrigerators\nAmazon S3 presigned URL is provided by the Amazon S3 service to temporarily share objects, such as multimedia like audio and visual files, owned by a user to other users without access credential to the objects. This allows users to upload or download objects, such as recipe cards or voice messages, to Amazon S3 buckets without permitting the users to have the right to read and write objects in the buckets. This is very important because the smart home IoT platform needs to support the scenario where end users do not provide access credentials to the smart home platform when sending multimedia information through the tablet on the refrigerators. To learn more about sharing an object with a resigned URL using Amazon S3, please refer to the technical documentation found here: https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/examples-s3-presign.html.\nSummary\nWith a smart home IoT solution built on AWS IoT, you can provide your users with the real time status of home appliances, such as refrigerators and microwave ovens, and enable them to control these home appliances and execute operations from anywhere. You can make it easy for your users to securely share the status of their device with other family members, and to communicate with them using multimedia information such as images and videos. This makes it easier and more convenient for end users to plan out ingredients, compile recipes, and maintain a healthy diet all while enjoying more time spent with their families. We look forward to seeing how you use this example to start building the future of the smart home with AWS IoT! To learn more about AWS IoT solutions for the connected, smart home, refer to our solutions page: https://aws.amazon.com/iot/solutions/connected-home/ or contact us directly here: https://pages.awscloud.com/connectedhomecontact.html.\nAbout the author\nShi Yin is an IoT consultant from AWS Professional Services, based in California. Shi worked with many big enterprises to leverage AWS IoT Services to build IoT platforms and connect sensors and devices to the platforms.'"
146,Your Guide to AWS IoT at Embedded World 2021,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/02/26/Screen-Shot-2021-02-25-at-4.01.56-PM-copy-1024x454.png,https://aws.amazon.com/blogs/iot/your-guide-to-aws-iot-at-embedded-world-2021/,"b'Embedded World 2021 is almost here! Embedded World is the place for all things embedded-system technologies and distributed intelligence. This year\xe2\x80\x99s exhibition and conference will be entirely digital, running the week of March 1-5, 2021. In this blog post, we share sessions you won\xe2\x80\x99t want to miss from AWS experts and our AWS Partners as we dive deep to showcase how device software, edge computing, and emerging technologies will shape IoT solutions we rely on every day.\nHow might you spend your days at Embedded World this year? Attend AWS IoT conference sessions to learn more about how we are bringing cloud connectivity and intelligence to the IoT edge. Stop by the AWS IoT booth in the virtual exhibition center to view daily live technology solution demos with our AWS Partners, chat live with AWS IoT experts, and explore AWS IoT edge solutions and services. Use our conference guide to quickly reference our sessions and demos. Finally, make sure to enter to win $25 in AWS promotional credits on our external event page.\nSESSIONS\nA cornerstone of Embedded World is knowledge sharing. We are honored to have been selected to present on the following topics, for which each will also have an associated paper (available to Embedded World attendees) to dive deeper into each subject.\nUsing future-proofed microcontroller designs with FreeRTOS (ID: 10452)\nMarch 1 | 11:00-11:30 (CET) | 2:00-2:30 (PT) | Richard Barry, Senior Principal Engineer, Amazon Web Services\nToday, we\xe2\x80\x99re seeing an amazing dynamic between the edge and the cloud, and where customers are putting their workloads. Many applications rely on the physical world around us where microcontrollers continue to prove to have a dominant place. Customers are looking for composability and robust RTOS support. Discover how to overcome challenges in development acceleration while ensuring firmware integrity and longevity, how that ties into Long Term Support releases, and what that means for an open source project in development for more than 15 years.\nBuild your own Embedded Linux CI/CD pipeline using the cloud (ID: 10449)\nMarch 1 | 13:30-18:00 (CET) | 4:30-9:00 (PT) | Richard Elberger, Principal Technologist, Amazon Web Services\nLearn how to build a CI/CD pipeline using the AWS Cloud by creating your own Bitbake Metadata Layer and build upon a series of triggers that run on top of Cloud infrastructure to drive the build and stage processes for the Embedded Linux image, SDK, and Package Streams. Then, learn how to integrate your build process with continuous tests for CI and image staging for continuous development. You will understand how to create the pipeline for your own products and be able to reuse the artifacts you created during the workshop.\nTinyML for AI at the very, very edge (ID: 10454)\nMarch 2 | 13:30-14:00 (CET) | 4:30-5:00 (PT) | Rajeev Muralidhar, Principal Specialist Solutions Architect, Amazon Web Services and Prasad Vyawahare, Software Development Engineer, Amazon Web Services\nAdvances in ultra-low power hardware architectures, semiconductor process technologies, and AI algorithms have enabled TinyML \xe2\x80\x93 a new class of ML on tiny microcontrollers. TinyML has enabled use cases such as predictive maintenance, anomaly detection, and ultra-low power audio or video recognition on devices in the sub-10mW power envelope. We will look at the TinyML framework, its architecture, and how we can build low power audio deep neural networks (DNNs) and video convolutional neural networks (CNNs) using TensorFlow Lite on FreeRTOS-based microcontrollers. We will then discuss challenges and opportunities crucial for this technology to be scalable and deployable in real-world scenarios.\nFormally verifying the FreeRTOS IPC mechanism (ID: 10446)\nMarch 2 | 14:00-14:30 (CET) | 5:00-5:30 (PT) | Nathan Chong, Principal Applied Scientist, Amazon Web Services\nThe FreeRTOS kernel is a real-time operating system for microcontrollers and small microprocessors. The kernel provides interprocess communication (IPC) to enable applications to be flexibly split over multiple communicating tasks. The main IPC mechanism in FreeRTOS is a concurrent queue: a FIFO data structure that tasks can use to send and receive messages. As a fundamental building block for larger applications, the correctness of the queue is vital. Join this session to learn about formal verification of the memory safety, thread safety, and functional correctness of the queue using deductive verification.\nCloud-driven CI/CD for Embedded Linux (ID: 10447)\nMarch 2 | 14:00-14:30 (CET) | 5:00-5:30 (PT) | Richard Elberger, Principal Technologist, Amazon Web Services\nBuilding a Linux distribution requires significant compute and storage. Delivering solutions with Embedded Linux requires even more savvy given requirements to provide firmware updates to improve security, resiliency, and application capability. By creating a Continuous Integration (CI) and Continuous Delivery (CD) pipeline for Embedded Linux-based IoT solutions, you improve quality, consistency, and time to market. Learn the core components and events for Embedded Linux CI/CD that transitions to post-release events, such as over-the-air firmware updates, mechanisms for Embedded Linux flavored Continuous Integration and Continuous Delivery, and the mechanics for securely providing automated firmware updates.\nDEMOS\nThree on-demand demos are available today on our external event page, and five will be hosted live in our booth within the virtual exhibition center. View the schedule for live demos and add the ones you don\xe2\x80\x99t want to miss to your calendar here.\nDaily live demos:\nIIoT anomaly detection with AWS, Klika Tech, and STMicroelectronics\nMarch 1 | 17:20-17:50 (CET) | 8:20-8:50 (PT) | Featuring AWS Partners Klika Tech and STMicroelectronics\nKlika Tech and AWS will demonstrate a development kit built on AWS that provides a rapid, scalable solution for deploying machine learning in IIoT ecosystems to drive manufacturing efficiency. The demo features a step-by-step illustration of the unique model for decision making in the automated response to anomaly vibrations use case.\nLoRaWAN\xc2\xae Smart Building Reference Kit\nMarch 2 | 17:20-17:50 (CET) | 8:20-8:50 (PT) | Featuring AWS Partners TensorIoT and Semtech\nWith the Smart Building Reference Kit (SBK), you can quickly discover how to use LoRaWAN\xc2\xae networks and sensors to explore cloud-based smart building applications. Join the demo to explore employee safety and well-being, sustainability, operating efficiency, or your own smart building needs.\nKeeping manufacturing moving with vision-driven conveyor belt systems\nMarch 3 | 17:20-17:50 (CET) | 8:20-8:50 (PT) | Featuring AWS Partner ADLINK\nThis demo will show how to detect defects and drive action in real time on a production line using a machine vision AI system integrating AWS IoT SiteWise and AWS IoT Greengrass V2 with ADLINK Edge\xe2\x84\xa2.\nHow to build a voice-enabled smart home product with RISC-V\nMarch 3 | 18:15-18:45 (CET) | 9:15-9:45 (PT) | Featuring AWS Partner Espressif\nThis demo will cover building a voice-enabled application with an arbitrary wake word. Enable Bluetooth LE (BLE) long range devices in the smart home with ESP32-C3, Espressif\xe2\x80\x99s low-cost silicon based on RISC-V ISA.\nAdaptive healthcare AI and analytics inference at the edge with Xilinx SoCs through Amazon SageMaker\nMarch 4 | 17:20-17:50 (CET) | 8:20-8:50 (PT) | Featuring AWS Partner Xilinx\nTrain in the cloud, deploy and infer at the edge, and maintain a connected distributed AI Analytics infrastructure. Learn how to leverage Amazon SageMaker, TVM, the Xilinx PYNQ platform, and the Xilinx Deep Learning Processing Unit (DPU) to scale your AI deployment in Healthcare and beyond.\nOn-demand demos:\nAWS IoT Greengrass V2 on RISC-V architecture\nOn-demand | Featuring AWS Partner SiFive\nThis demo will show AWS IoT Greengrass V2 using Aicas JVM on the HiFive Unmatched RISC-V. You now have a choice to run AWS IoT Greengrass on edge gateways running RISC-V architecture. See how RISC-V allows you to build highly customized processors and microcontrollers.\nCondition-based and predictive motor maintenance\nOn-demand | Featuring Amazon Monitron\nThis demo highlights a powerful use case for Amazon Monitron hardware leveraging predictive motor maintenance. You will get to see how Amazon Monitron addresses the condition-based maintenance and predictive maintenance use cases, and how other methods such as run to failure and planned maintenance can also be incorporated into the overall maintenance methodologies.\nAWS predictive quality industrial demo\nOn-demand | Featuring AWS and AWS Partners\nIndustrial IoT offers new levels of predictability for industrial enterprises. Predictive quality is used to spot and remediate quality issues quickly. Generated insights can be used to optimize outputs based on environmental factors and supply chain inputs. The goal is to identify everything impacting final product quality by creating a prediction model that can be used to define concrete improvement steps.\nCheck out more content and conference tips on our AWS IoT at Embedded World 2021 page.'"
147,AWS IoT SiteWise: 2020 in review,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2021/01/14/SWM-Marketing-Hero2-1024x557.png,https://aws.amazon.com/blogs/iot/aws-iot-sitewise-2020-in-review/,"b'In this post, we summarize the new features and enhancements AWS IoT SiteWise launched in 2020 to improve customer experience to optimize industrial operations, and improve productivity and availability of industrial equipment.\nThis post is summarized into the following sections:\nEnhanced security\nMore options for data ingestion and edge processing\nGreater asset modeling flexibility\nOut of the box alarms on equipment data\nEnhanced data visualization for better insights\nAWS IoT SiteWise plugin for Grafana\nAWS CloudFormation support\nNew region availability\nLearning resources\nWhat\xe2\x80\x99s next\nEnhanced security\nSecurity is the first priority at AWS and a shared responsibility between AWS and our customers. With many industrial customers moving to AWS Cloud for their Industry 4.0 digital transformation journey, security remains at the top of our minds and this past year was no different for AWS IoT SiteWise. With AWS IoT SiteWise, all of your data is encrypted by default using a service-managed encryption key. You can now encrypt this data using your own encryption key that is configured in AWS Key Management Service (KMS) as shown below in the AWS Management Console. To learn more, refer to Encryption at rest and Key management.\nAdditionally, AWS IoT SiteWise now supports Amazon Virtual Private Cloud (VPC) endpoints via AWS PrivateLink for the data plane application programming interfaces (APIs) \xe2\x80\x93 PUT and GET APIs. This enables you to securely send and receive data from within your VPC, without crossing the public Internet and without using public IP addresses. You can do so by creating a VPC endpoint as shown below for the AWS IoT SiteWise service to establish a private connection between your VPC and AWS IoT SiteWise. To learn more, refer to AWS IoT SiteWise and interface VPC endpoints.\nMore options for data ingestion and edge processing\nFor most industrial customers, in the event of network latency and/or intermittent connectivity, in addition to sending the data to the cloud, it is a must have to continue collecting and processing equipment data locally (on-premises) to keep the production lines running without disruption. In addition, customers want to explore optimizing network bandwidth usage by sending only processed data to the cloud, for example, applying deadbands to only send significant changes in measurements or applying filters to only send measurements that exceed a threshold.\nAt re:Invent 2020, we launched SiteWise Edge (Preview), a new feature of AWS IoT SiteWise that brings the same capabilities of AWS IoT SiteWise in the cloud to the customer\xe2\x80\x99s premises. The SiteWise Edge software runs on AWS IoT Greengrass that is installed on local hardware such as third-party industrial gateways and computers, AWS Outposts, or AWS Snow Family compute devices. With SiteWise Edge, you can now organize and process your equipment data locally in the AWS IoT SiteWise gateway using the same asset models defined in the cloud. You can then read the equipment data from the local gateway using the same APIs that you use with AWS IoT SiteWise in the cloud. For example, you can compute and monitor metrics such as overall equipment effectiveness (OEE) locally for use in production line monitoring on the factory floor using SiteWise Monitor dashboards served locally from the AWS IoT SiteWise gateway. By processing data on-premises, you can reduce latency for local applications and ensure business continuity even if Internet connectivity is disrupted. For example, a local alarm application that relies on the data collected by SiteWise Edge can continue to detect and respond to changes in the equipment status. With SiteWise Edge, in addition to sending equipment data to a centralized industrial data lake in the cloud for cross-site operational view and advanced analytics (such as machine learning), you can choose to send changes or processed data to the cloud for selective measurements to optimize the network bandwidth usage. To learn more, refer to Process data locally with AWS IoT SiteWise.\nIn an industrial site, connectivity between an on-premises edge gateway and the cloud can experience intermittent interruptions due to either planned or unplanned events. As a result, we added a store and forward capability in our edge gateway to avoid data loss. You can now ingest late data that is up to 7 days old (extended from 15 minutes) to AWS IoT SiteWise in the cloud when recovering from a connectivity issue. AWS IoT SiteWise recalculates the related transforms and metrics automatically on arrival of the late data. To get the most out of this feature, upgrade the AWS IoT SiteWise connector to version 8 or later. Refer to late data ingestion to learn more.\nIn addition to the existing OPC-UA and MQTT protocol support, AWS IoT SiteWise now supports data ingestion from two additional industrial protocols (Modbus TCP and EtherNet/IP) that are commonly used by our customers connecting industrial equipment such as electrical power monitoring systems, meters, generators, uninterruptible power supply (UPS), and transfer switches. Before adding a Modbus TCP or EtherNet/IP data source, remember to deploy the Modbus-TCP Protocol Adapter connector or Ethernet IP Protocol Adapter connector on your edge gateway. You can add a Modbus TCP or EtherNet/IP data source to your AWS IoT SiteWise Gateway as shown below in the AWS Management Console. Refer to Configure a Modbus TCP source and Configure an EtherNet/IP source to review all the supported configurations.\nFor the OPC-UA data sources, AWS IoT SiteWise added the following two capabilities to further optimize the network bandwidth usage for sending data to the cloud:\nDeadbanding: You can now define deadbands for the OPC-UA source property groups (a property group is a set of measurements) to filter out and discard certain data at the edge before transmitting to the cloud. A deadband specifies a band of tolerable fluctuations in the incoming data values from your OPC-UA source. This is to minimize the number of data points to be sent and stored in the cloud, optimize available network bandwidth, and reduce cost. To choose how much data is sent to the cloud and how much is discarded, you can specify two types of deadbands (Percentage and Absolute) for the OPC-UA source property group. To learn more on how the two deadband types work, refer to Filter OPC-UA data ingestion with deadband ranges.\nConfigurable scan mode: You can now configure OPC-UA scan mode to control the way you collect data from the OPC-UA server by choosing either Subscription or Polling mode. In subscription mode, the OPC-UA server transmits data only when it changes. This mode is helpful in ingesting data from sources that have a high rate of change. In polling mode, the connector polls the OPC-UA server at a specified frequency to read data points even if the values do not change. This is helpful in ensuring a constant rate of ingestion from sources that may have a low rate of change. To learn more on how this works, refer to Control data collection frequency with Scan mode.\nAdditionally, you can now select a custom AWS IoT Greengrass stream manager stream as the destination for the data coming from all three supported industrial protocols (OPC-UA, Modbus TCP, and EtherNet/IP). By default, all data would go to the AWS IoT SiteWise cloud service. By routing data to a custom stream, you can now author long-running AWS Lambda functions that can perform local data transformations or filtering, at the edge. For example, you can connect to a local on-premises ERP system to enrich the telemetry data streams before sending to the cloud. You can also setup an export for AWS IoT Greengrass on the custom stream to send data to AWS IoT Analytics, Amazon Kinesis Data Streams, and Amazon S3. To use this feature, upgrade the AWS IoT SiteWise connector to version 9 or later. For more details, refer to Choosing a destination for your source server data.\nGreater asset modeling flexibility\nWith formula expressions in AWS IoT SiteWise, you can define the mathematical functions to transform and aggregate your raw industrial data to gain insights about your operations. AWS IoT SiteWise has expanded its formula expression capability of metrics and transforms to include conditional logic and string manipulations, allowing users greater flexibility in defining real time monitoring of IoT assets.\nWith Conditional functions support, you can now define conditional logic to detect malfunction of your expensive equipment, or flag deviations from typical equipment behavior. For example, to take an action when a sensor has breached a temperature threshold of 300 degrees Fahrenheit, you can simply define a transform in AWS IoT SiteWise with the conditional expression if(gt(temperature, 300), temperature, none) which returns the \xe2\x80\x9ctemperature\xe2\x80\x9d value when temperature is greater than or equal to \xe2\x80\x9c300\xe2\x80\x9d, otherwise returns \xe2\x80\x9cnone\xe2\x80\x9d (no value).\nWith String functions support, you can now define conditional computations using string functions (concatenation, comparisons, case conversion, slicing, string length, and search) on user-defined transforms and metrics of incoming telemetry data and visualize the output on a SiteWise Monitor dashboard. For example, you want to convert the equipment status from strings to boolean values for downstream application consumption. To achieve this, you can simply define a transform in AWS IoT SiteWise with the conditional expression if(equals(equipment_status,""Maintenance""),0,1) which returns \xe2\x80\x9c0\xe2\x80\x9d when the equipment status is \xe2\x80\x9cMaintenance\xe2\x80\x9d, otherwise returns \xe2\x80\x9c1\xe2\x80\x9d. For a list of string functions supported, refer to Using strings in formulas.\nAlso, AWS IoT SiteWise now supports the Boolean datatype for properties, pseudo constants such as NONE, and computations with standalone attributes. In AWS IoT SiteWise, Booleans convert to their number equivalents, i.e., \xe2\x80\x9ctrue\xe2\x80\x9d is converted to \xe2\x80\x9c1\xe2\x80\x9d and false is converted to \xe2\x80\x9c0\xe2\x80\x9d. For example, you have an equipment property named \xe2\x80\x9cIdle\xe2\x80\x9d that can have a value of \xe2\x80\x9c0\xe2\x80\x9d or \xe2\x80\x9c1\xe2\x80\x9d where \xe2\x80\x9c1\xe2\x80\x9d indicates the idle state and \xe2\x80\x9c0\xe2\x80\x9d indicates the running state of the equipment. You can calculate the total equipment idle time for a given time interval with this expression: IdleTime = statetime(Idle). To learn more, refer to Using formula expressions.\nOut of the box alarms on equipment data\nFor Industrial IoT applications, data monitoring alone is not enough. You may also want to get alerted on anomalies or malfunctioning of your costly equipment. With alerting, you can prevent downtime and reduce operational expenditure associated with downtime or capital expenditures associated with repairing or replacing the equipment.\nTo help with this, AWS IoT SiteWise launched Alarms, a feature (currently in preview) using AWS IoT Events under the cover in a seamless way, that allows you to create alarms on your equipment data. You can also setup, visualize, and manage rule-based alarms for devices, equipment, and processes in AWS IoT Events itself for any device data going directly to the service. You can configure these alarms so that you receive alerts via SMS or email in near-real time when equipment data breaches thresholds, allowing operations teams to take timely actions to reduce unplanned downtime.\nTo integrate the alarm notifications with your own ticketing systems, you can also configure actions to other AWS services such as AWS Lambda, Amazon Simple Queue Service (SQS), and Amazon Simple Notification Service (SNS). Once you create the alarm, you can use existing AWS IoT SiteWise APIs to query the current or historical alarm state over specific time intervals. With AWS IoT SiteWise Monitor, operations teams can visualize equipment alarms, analyze alarm data against live and historical data trends, determine corrective actions to take (like scheduling equipment repair), and manage the end-to-end alarm workflow (like acknowledging an alarm with comments about actions taken). To learn more, refer to Monitoring data with alarms.\nIn the Cookie Factory example shown below, an alarm rule is configured to trigger a severity 3 alarm (e.g., severity 1, 2 and 3 corresponding to high, medium and low severity) when Mixer 1 exceeds 200 rotations per minute, and send an SMS when the alarm is triggered for necessary corrective actions to take by an operations team. Once the alarm is defined, it can be dragged and dropped just like any other asset property in the SiteWise Monitor dashboard to easily visualize the status of the alarms. When the alarm for Mixer 1 is triggered, an SMS notification is received on the configured mobile device. In addition, operations team is interested to visualize the historical status for the Zone 2 equipment using status timelines chart, and how the abnormal mixer behavior and asset downtime impacting the overall OEE.\nEnhanced data visualization for better insights\nAWS IoT SiteWise Monitor, a fully managed out of the box web application of AWS IoT SiteWise, now supports Status charts, Table charts, and Scatter charts. With these new chart types, you can now choose the chart type that makes the most sense for your data you want to visualize in your AWS IoT SiteWise Monitor dashboards. For example, if you have a temperature indicator of your sensors that can be high, medium, or low, you could display each state in a different color using a status grid for current status or a status timeline for historical status.\nAdditionally, AWS IoT SiteWise Monitor now supports Trend lines, a linear regression line that best approximates the relationship between measured data and time. With trend lines, you can now intuitively identify gradual shifts and changes in your live and historical data simply by adding trend lines to any of your line, scatter, and bar charts. For example, a wind farm operator may observe a gradual decline in the power output trend line from a wind turbine while observing there is a flat and steady wind speed trend line. The operator may correlate this insight to a power conversion efficiency issue with the wind turbine and call on field technicians to inspect and troubleshoot it.\nThe following video shows how you can easily build dashboards and browse your data and metrics from AWS IoT SiteWise for a wind farm using AWS IoT SiteWise Monitor.\nAWS IoT SiteWise plugin for Grafana\nIn 2020, AWS and Grafana Labs launched the AWS IoT SiteWise plugin for Grafana. Grafana is a data visualization platform that some of our customers already use to visualize and monitor time-series data in operational dashboards. Users of Grafana 7.3.0 and higher can use this plugin to visualize AWS IoT SiteWise asset data in Grafana dashboards. This also lets you easily combine data from multiple sources (for example AWS IoT SiteWise, Amazon S3, or Amazon CloudWatch) when needed and monitor them all using a single Grafana dashboard. You have two options to use for the plugin: Local Grafana servers that you manage or AWS Managed Service for Grafana. To learn more about the setup, refer to Integrating with Grafana.\nThe following video shows a sample Grafana dashboard which is monitoring key operational metrics for a wind farm data from AWS IoT SiteWise:\nAWS CloudFormation support\nAWS IoT SiteWise now supports AWS CloudFormation so you can create and manage AWS IoT SiteWise resources by authoring CloudFormation templates for Asset Models, Assets, Gateway resources, and AWS IoT SiteWise Monitor resources such as portals, projects, and dashboards. You can reuse these templates across accounts and regions to ensure consistency. To learn more, refer to AWS IoT SiteWise resource type reference in the CloudFormation user guide.\nNew region availability\nIn July 2020, AWS IoT SiteWise was made generally available in US East (N. Virginia), Europe (Frankfurt), US West (Oregon), and Europe (Ireland). AWS IoT SiteWise is now available in two additional AWS Regions \xe2\x80\x93 Asia Pacific (Sydney) and Asia Pacific (Singapore). We continue to expand to new regions, for the most current list of regions where AWS IoT SiteWise is available, visit the AWS Region table.\nLearning resources\nAWS IoT SiteWise is a fully managed AWS service that provides an end-to-end solution to collect, organize, analyze, and monitor data from industrial equipment at scale to help you make better, data-driven decisions. With AWS IoT SiteWise, you can monitor operations across facilities with centralized data, continuously compute common industrial performance metrics, and create applications that analyze industrial equipment data to optimize operations, prevent costly equipment issues, and reduce gaps in production. To get started, refer to Getting started with AWS IoT SiteWise.\nTo learn more, refer to the following:\nHow Genie\xc2\xae (a Terex\xc2\xae brand) improved paint quality using AWS IoT SiteWise \xe2\x80\x93 In this post, we discuss how Genie used an AWS IoT SiteWise based solution to ingest, organize, and analyze critical process parameters from the paint system. This solution identified inconsistent and improper pretreatment parameters in near real-time and enabled Genie to apply necessary corrective actions to improve the downstream paint quality of Genie lifts.\nCollecting, organizing, monitoring, and analyzing industrial data at scale using AWS IoT SiteWise \xe2\x80\x93 In this post, you will walk through a solution using AWS IoT SiteWise.\nWhat\xe2\x80\x99s next\nWe are looking forward to 2021 to enable you with data-driven insights to optimize your industrial operations, and improve productivity and availability of your industrial equipment. Stay tuned to the What\xe2\x80\x99s New with AWS channel for AWS IoT SiteWise to learn further updates. Contact us if you want to implement AWS IoT SiteWise in your environment and need assistance.'"
148,Introducing AWS IoT Core for LoRaWAN,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/12/15/IoT-Core-For-LoRaWAN-Architecture-1-1024x542.jpg,https://aws.amazon.com/blogs/iot/introducing-aws-iot-core-for-lorawan/,"b'Many IoT devices rely on Low-Power Wide-Area Networks (LPWAN) to connect their fleets. Wi-Fi, Bluetooth, or wired Ethernet serve an important role in providing connectivity, but these connections have limited range. Cellular connectivity may require expensive monthly service fees which can consume high power and limits the battery life of small, low-bandwidth sensors or devices. It is common for many enterprises to develop IoT applications using devices that transmit data over long range (1-3 miles urban coverage or up to 10 miles with line of sight) or through the walls and floors of buildings. These applications may be used for real-time asset tracking at airports, remote temperature monitoring in buildings, or predictive maintenance of industrial equipment. Such applications also require devices to be optimized for low-power consumption, so that batteries can last several years without replacement, making the implementation cost-effective. Low-power, wide-area networks like LoRaWAN address many of these challenges and give customers a way to connect their devices over a long distance while consuming small amounts of power which is why we built AWS IoT Core for LoRaWAN. In this post, you will learn about the feature benefits, the Partner community, real-world customer use cases, and how to get started using AWS IoT Core for LoRaWAN in your own IoT solution.\nAnnouncing AWS IoT Core for LoRaWAN\nAWS IoT Core for LoRaWAN is a fully-managed feature that allows you to connect and manage wireless devices that use LoRaWAN connectivity with the AWS Cloud. Using AWS IoT Core for LoRaWAN, enterprises can setup a private LoRaWAN network by connecting their LoRaWAN devices and gateways to the AWS Cloud \xe2\x80\x93 without developing or operating a Network Server (NS) for LoRaWAN themselves. This eliminates the undifferentiated work and operational burden of managing an NS, and enables you to easily and quickly connect and secure LoRaWAN device fleets at scale. Combined with the long range and deep in-building coverage provided by LoRaWAN, AWS IoT Core for LoRaWAN enables enterprises to accelerate IoT application development by acting on the data generated from connected LoRaWAN devices using AWS services.\n\xe2\x80\x9cThe rapid acceleration of growth in both private and public LoRaWAN networks has been key in the expansion of LoRaWAN deployments worldwide. AWS\xe2\x80\x99 launch of AWS IoT Core for LoRaWAN offers an innovative solution to accelerate private network deployments by offering a simple, reliable, cloud-based method that allows customers to easily and cost-effectively deploy private LoRaWAN networks. It is always exciting to see new products and business models entering the market that strengthen the community for LoRaWAN. I congratulate AWS on this achievement,\xe2\x80\x9d said Donna Moore, CEO and Chairwoman of the LoRa Alliance.\nOne of the key challenges for enterprises interested in using LoRaWAN is operating an NS as part of a privately managed network. An NS is required to manage LoRaWAN device and gateway connections. LoRaWAN gateways serve as a bridge between the LoRa devices and the NS in the cloud. Today, enterprise network engineers have two options; either operate an in-house NS, or use a commercially managed NS service. When operating in-house, engineers invest in custom development work starting with an open-source or licensed NS software and combining it with multiple AWS services, which is time-consuming and distracts from core business goals. It also incurs the operational overhead of managing the associated infrastructure and providing technical assistance to internal teams building applications. Alternatively, when using commercially managed NS services, customers find the accompanying up front license or subscription-based bundle pricing costly to operate. Lastly, network engineers also need to make it easy for developers in their company to deliver business applications and solutions with the data collected from connected devices.\nAWS IoT Core for LoRaWAN enables network engineers to connect LoRaWAN devices and gateways to the cloud with a few simple steps in the AWS IoT console, thus speeding up the network setup time. With AWS IoT Core for LoRaWAN, you can ingest data and immediately act on that data to perform common actions such as converting data formats, sending data into Amazon DynamoDB, or invoking any number of other AWS services required to drive business outcomes.\nUsing AWS IoT Core for LoRaWAN, engineers can connect off-the-shelf LoRaWAN devices without the need to modify embedded software for a plug-and-play experience. To further reduce onboarding friction, AWS IoT Core for LoRaWAN includes support for the open-source LoRaWAN gateway-to-NS communication protocol called LoRa Basics\xe2\x84\xa2 Station from Semtech. Support for LoRa Basics Station means engineers can avoid rewriting or testing custom gateway software to securely connect LoRaWAN gateways to AWS IoT Core. Additionally, AWS\xe2\x80\x99 gateway qualification program for LoRaWAN enables engineers to source gateways from AWS Partners that are pre-configured with LoRa Basics Station and are ready to connect with AWS IoT Core.\nOnce LoRaWAN devices and gateways are connected, developers can take advantage of all of the features of AWS IoT. A common example might be to use the AWS IoT Core Rules Engine to write simple SQL queries to transform and act on the device data, like converting data from proprietary binary to JSON format, raising alerts, or routing it to other AWS services, like Amazon S3. From the AWS IoT console, engineers can also query metrics for connected devices and gateways to troubleshoot connectivity issues. With pay-as-you-go pricing and no monthly commitments, enterprises can connect and scale their LoRaWAN device fleets reliably, and build applications with AWS services quickly and efficiently.\n\xe2\x80\x9cSemtech\xe2\x80\x99s LoRa is a proven IoT solution that supports a long range, low power wide area network (LPWAN) platform and meets AWS IoT Core\xe2\x80\x99s goal of enabling rapid, simple, cost-effective creation of private LoRaWAN networks. We are pleased to have collaborated with AWS on the use of LoRa as the next generation, Enterprise technology for modern Cloud-based IoT networks,\xe2\x80\x9d said Alistair Fulton, Vice President and General Manager in Semtech\xe2\x80\x99s Wireless Sensing Products Group.\nPartner community of gateways and System Integrators\nTo get you started quickly with AWS IoT Core for LoRaWAN, we have worked with leading gateway manufacturers and System Integrators (SI) that offer qualified hardware and consulting services.\nWe collaborated with leading gateway manufacturers including Browan, Kerlink, Laird Connectivity, MultiTech, and TEKTELIC to qualify their hardware for AWS IoT Core for LoRaWAN. The AWS IoT Device Qualification Program (DQP) is designed to help you find hardware that is compatible with a variety of AWS services. For AWS IoT Core for LoRaWAN, the DQP involves partners integrating LoRa Basics Station into their gateway hardware, which goes through rigorous testing by both AWS and the partner to ensure a robust and secure implementation for customers. Once qualified, the gateway is listed into the AWS Partner Device Catalog where you can filter, browse, and find the most appropriate hardware for their particular use case. A subset of these partners are also offering AWS IoT Core for LoRaWAN Developer Starter Kits which includes a gateway, a sensor, and a getting started guide. The guide includes step-by-step instructions for how to use the AWS IoT Console and partner gateway console to connect the LoRaWAN device and gateway, and build a simple application using AWS services such as using the Amazon Simple Notification Service (SNS) to send an SMS notification or Amazon Quicksight to visualize data from LoRaWAN devices in a dashboard.\nTo enable you to build a product based on AWS IoT Core for LoRaWAN, we worked with three leading System Integrators: Klika-Tech, TensorIoT, and Leverege. All three SIs were part of the beta program for AWS IoT Core for LoRaWAN and are very familiar with how the feature works, how to connect gateways, how to ingest data from sensors, and how to build an application using AWS IoT. These SIs offer design and integration engineering services to help you quickly build end-to-end applications on AWS that utilize AWS IoT Core for LoRaWAN.\nFinally, we also collaborated with TensorIoT and Semtech to create two LoRaWAN Solution Starter Kits. Targeted at customers who want to quickly deploy sensors and build a proof of concept (PoC) using AWS IoT Core for LoRaWAN, Solution Starter kits provide a cloud-hosted dashboard using AWS IoT Core under the hood. The Smart Building Kit which contains a variety of sensors from Browan Communications including temperature, humidity, leak detection, desk and room occupancy, and people counting. The kit includes the required LoRaWAN gateways and a Wi-Fi hotspot. The Asset Tracking Kit includes an outdoor-rated LoRaWAN gateway together with six industrial trackers, also from Browan. The kit enables you connect trackers and track the assets on a map provided in a cloud dashboard. These kits are available for immediate purchase on Mouser, Digi-Key, and Amazon.com.\n\xe2\x80\x9cWith AWS IoT Core, we have simplified how IoT devices connect and interact with cloud applications with support for MQTT, HTTP and WebSockets protocols,\xe2\x80\x9d said Dirk Didascalou, Vice President, IoT, Amazon Web Services. \xe2\x80\x9cBut customers have told us they are looking for wireless connectivity choices that meet the low-power, long-range application needs when setting up connectivity for applications such as asset tracking, industrial equipment maintenance, and building automation. That\xe2\x80\x99s why we built support for AWS IoT Core for LoRaWAN enabling customers to connect, scale, and manage LoRaWAN device fleets directly to AWS. We\xe2\x80\x99re excited to bring the benefits of simplified LoRaWAN connectivity and IoT application development to enterprises of all sizes.\xe2\x80\x9d\nAWS IoT Core for LoRaWAN food safety customer use cases\nMost restaurants use notebooks and clipboards for compliance checks. Compliance Mate is changing that. Compliance Mate offers a solution to address a critical need for proactive food safety at restaurants. Too many hospitality brands operate without a comprehensive temperature monitoring and Hazard Analysis Critical Control Point (HACCP) compliance system. As a result, they\xe2\x80\x99re putting guests at risk every day. They\xe2\x80\x99re also forfeiting a major opportunity to keep staff accountable, reduce food waste, and maintain brand integrity.\nThrough a combination of wireless temperature sensors, mobile technologies, and easy-to-use tools built for the modern kitchen, Compliance Mate gives their customers total control over food safety and compliance at their stores. With real-time access to temperature data, customers can quickly identify operational deficiencies and prevent food safety mishaps before they occur. They can also make evidence-based decisions about kitchen processes and staff training.\nCompliance Mate is using AWS IoT Core for LoRaWAN to connect temperature sensors in restaurant refrigeration and freezer units\xe2\x80\x94these cold climate sensors being devices that leverage a low-power, long-range wide area network. The LoRaWAN devices can penetrate the thick walls of refrigeration units and can last for years without replacement thanks to their low power consumption which reduces their operating costs. Using AWS IoT Core for LoRaWAN allows them to more easily meet their end customer goal of ensuring customer food safety while reducing the risk of food perishing.\n\xe2\x80\x9cWe built a turn-key monitoring solution which includes providing LoRa hardware and a cloud application to serve large chains like Chick-fil-A, Shake Shack, and Five Guys. We already have a LoRaWAN implementation in production for which we had to build a custom network backend. AWS IoT Core for LoRaWAN provides us a great incentive to get out of managing that infrastructure and focus on improving the experience of our customers,\xe2\x80\x9d says Adam Parrott, CTO, Compliance Mate.\nGetting started\nTo get started with AWS IoT Core for LoRaWAN, you can find and select a Developer Starter Kit from the AWS Partner Device Catalog that includes both a gateway and a sensor. Follow instructions provided in the Getting Started Guide that comes with the kit will walk you through creating certificates and keys unique to your gateways and how to provision those credentials onto your specific gateway. Once that\xe2\x80\x99s completed, you input device credentials (identifiers and security keys provided by the device vendor) on the AWS IoT console and follow guided defaults for specifying device configuration to provision devices. Devices can then join the network and you can see up-link packets coming into the AWS IoT Rules Engine. Then you will provision the sensor and finally use the data from the sensor to take some action such as sending the data to Amazon DynamoDB.\nAWS IoT Core for LoRaWAN is available immediately in two Regions: US East (Northern Virginia) and EU (Ireland).\nTo learn more, visit AWS IoT Core for LoRaWAN.\nLoRaWAN is a mark used under license from the LoRa Alliance.\nAbout the authors\nAdrian Valenzuela is a Senior IoT Go-To-Market Specialist at Amazon Web Services and is based in Dallas, Texas. Adrian is responsible for business development for the AWS IoT Connectivity & Control services and is maniacally focused on working with customers to develop innovative technology regardless of size, industry, or location. Adrian has nearly two decades of experience work in tech \xe2\x80\x93 from ultra-low power microcontrollers, microprocessors, and now cloud solutions for embedded devices.\n    Karthik Ranjan joined Amazon in October of 2018. Based in Seattle, Karthik is responsible for driving the LoRaWAN ecosystem strategy for AWS IoT. Prior to this Karthik spent 8 years at Arm where he lead the healthcare segment team focused on the creation of health IoT gateways and drove industry standardization around onboarding data from health IoT endpoints. Karthik was named in the list of the Top 100 influencers leaders in Health Tech by Hotwire. Before that Karthik led Arm\xe2\x80\x99s global carrier relationship team. Karthik has more than 20 years\xe2\x80\x99 experience working in the consumer electronics industry with companies such as Intel, Microsoft, and Amino. Throughout his career, he has been instrumental in driving standardization efforts around emerging broadband technologies including DLNA, g.lite & DOCSIS, and major IPTV deployments.'"
149,Introducing AWS IoT SiteWise Edge,b'David Walters',2021-05-18T19:43:28+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/12/15/Site-Merch_Full-Build_SiteWise-Edge_Blog.png,https://aws.amazon.com/blogs/iot/introducing-aws-iot-sitewise-edge/,"b'Note: SiteWise Edge is now generally available. Please see this blog post to get started with SiteWise Edge.\nFrom assembling automobiles to producing pharmaceuticals, successful industrial operations are fruits of continuous efforts to minimize equipment downtime, maximize product quality, and ensure personnel safety. Industrial IoT promises capabilities that can help manufacturers unlock insights quickly from a growing volume of sensor data from their equipment. Armed with these insights, operators can respond to equipment issues, product quality issues, and safety hazards as soon as they occur. In this post we will walk through AWS IoT SiteWise Edge, a new feature that enables customers to collect and process equipment data on-premises for low latency applications that must continue to work even if connection to the cloud is unavailable. With AWS IoT SiteWise Edge, developers can skip building time-series data acquisition and edge processing infrastructure to focus on building local applications that offer insights and support quick decision making on the factory floor.\nA lap around AWS IoT SiteWise Edge features\nAWS IoT SiteWise Edge brings features of AWS IoT SiteWise in the cloud to the customer\xe2\x80\x99s premises. Specifically, you can now use asset models defined in the cloud service to process data in the SiteWise gateway locally, and visualize equipment data using local SiteWise Monitor dashboards served from the SiteWise gateway. You can also read data directly from the gateway using the same GET APIs that you use to read data from AWS IoT SiteWise in the cloud. AWS IoT SiteWise Edge software can be installed on 3rd party Linux industrial computers, AWS Snow Family devices, and AWS Outposts. AWS IoT SiteWise Edge provides infrastructure for key functions of an IoT edge application bearing in mind the application lifecycle from development to support:\nData collection from disparate sources\nIndustrial IoT applications, ranging from monitoring dashboards to anomaly detection, utilize data from multiple disparate equipment and sensors. Typically this data is already logged in a historian database (a local time-series database). AWS IoT SiteWise Edge includes collectors that can securely read multiple time-series data streams from equipment and historian databases using OPC-UA, EtherNet/IP, and Modbus protocols. AWS IoT SiteWise Edge normalizes these data streams to a common format before storing them in an internal local time-series database for additional processing or routing them to AWS IoT SiteWise.\nData organization and contextualization\nTime-series data collected from historians and equipment needs to be labelled with contextual information to be understood by developers and be used in applications. For example, a temperature data stream may be represented by a non-descriptive alphanumeric ID such as \xe2\x80\x9cX012232.\xe2\x80\x9d AWS IoT SiteWise allows you to create asset models for each type of equipment that describe its data streams or \xe2\x80\x9cmeasurements.\xe2\x80\x9d For example, you can describe an Evaporator asset that has Temperature, State, and Pressure as measurements. You can then map non-descriptive data stream IDs to each of these descriptive labels. You can create asset models for each type of equipment and then organize them in a hierarchy to represent production lines or entire factories. You can use APIs to query data streams using descriptive labels consistently across your applications. With AWS IoT SiteWise Edge you can configure the same asset models to be available locally so you can query labelled data directly from the gateway. Additionally, AWS IoT SiteWise Edge automatically syncs any changes made to asset models with all your gateways ensuring your applications are always using the current definition of assets.\nData transformation and metrics processing\nOften data streams have to be processed further into metrics that indicate the health and performance of industrial operations. You can specify formulas in asset models to compute metrics over fixed time intervals from labelled data streams (e.g. Average Temperature over 1 min). Asset models also support transformation of time-series data points for use in the metric calculations. For example, you can configure a model to transform temperature values in Fahrenheit to Celsius or equipment state values into binary true or false values based on a criteria and then compute an average temperature metric reported in Celsius. AWS IoT SiteWise Edge automatically computes transforms and metrics defined in asset models configured for the edge. If the gateway collects a data stream that has an associated asset model, it processes the data stream according to the formulas available in the asset model, stores the result locally, and also forwards the result to the cloud for additional processing and longer term storage. Local applications can read processed data using the same GET APIs available in the cloud directly from the gateway. You can use this feature to filter data to only values of interest, aggregate values over time, such as computing averages, or total time spent in a given state to compute sophisticated metrics such as Overall Equipment Effectiveness (OEE).\nData visualization\nBesides reading data into custom applications through GET APIs, you can also use AWS IoT SiteWise Monitor to create monitoring dashboards without writing any code (or SQL queries) and access them locally. You can load the dashboards in a web browser running on a computer that can reach the gateway over the local factory network. AWS IoT SiteWise Edge serves the dashboard directly from the gateway and automatically syncs any changes made to the dashboards in the cloud to all your gateways.\nGateway management\nSupporting on-premises gateways across multiple sites can be challenging. AWS IoT SiteWise helps you remotely configure and centrally manage gateways through the AWS Management Console. AWS IoT SiteWise regularly collects metrics on gateway health and connectivity with industrial data sources in Amazon CloudWatch and shows them on the gateway section of the console. Now, AWS IoT SiteWise Edge provides the \xe2\x80\x9cOpsHub for AWS IoT SiteWise\xe2\x80\x9d application for monitoring and troubleshooting gateways entirely locally. The OpsHub for AWS IoT SiteWise application can be installed on any Windows PC. The application connect directly to your gateway over the local network. The application gives you access to device health metrics (e.g. memory, CPU, cloud connectivity), status of edge software (e.g. uptime of dashboard applications), and recent data collected from equipment. You can use the application to debug disruptions in the flow of your data and restart software on the gateway to fix issues.\nGetting started\nPre-requisites\nAt a minimum, AWS IoT SiteWise Edge requires an industrial computer running Linux with a x86 64 bit quad-core processor, 16GB RAM, and 256GB in disk space. In preview, we recommend you use dedicated hardware for use with AWS IoT SiteWise Edge. In preview, AWS IoT SiteWise Edge software runs on AWS IoT Greengrass v1 (v1.10.2 recommended) installed on Ubuntu Server 18.04+ LTS OS for x86. You also have to install Java8, Python 3.7, and Docker software packages. Additionally, ensure that ports 443, 8443, and 8883 are externally accessible on your device.\nTo install AWS IoT Greengrass, please follow Quick Start: Greengrass device setup.\nCreate an AWS IoT SiteWise gateway\nOnce you have installed the pre-requisite software on your device, you can setup the gateway from the AWS IoT SiteWise Console. AWS IoT SiteWise Edge bundles capabilities in \xe2\x80\x9cpacks\xe2\x80\x9d that are installed on the gateway. The Data Processing pack enables computation of metrics and transforms using asset models and visualizing them with AWS IoT SiteWise Monitor dashboards at the edge. It also enables REST APIs on the gateway that you can use to query data for your local applications. The Data Collection pack supports collecting data from common industrial data sources and transferring it to the AWS Cloud. You can collect data from OPC-UA servers, Modbus servers, and over EtherNet/IP. You can transfer the collected data to Amazon S3, AWS IoT SiteWise, AWS IoT Core, Amazon Timestream, and Amazon Kinesis.\nTo setup a new gateway:\nOpen the AWS IoT SiteWise console.\nNavigate to the Gateways section from the Edge menu item and Add a new gateway.\nSelect the AWS IoT Greengrass group associated with your gateway device. The console will install AWS IoT SiteWise software as AWS IoT Greengrass Connectors in this group.\nEnable the Data Processing pack option and click Create Gateway. The Data Collection pack is required and installed by default when you create the gateway.\nOnce the gateway is created, you configure its data sources from the gateway detail page. You can configure OPC-UA, Modbus, and EtherNet/IP data sources. Please see AWS IoT SiteWise data source configuration documentation to learn more.\nUpdate AWS IoT Greengrass service roles\nAWS IoT SiteWise Edge deploys software in Docker containers on AWS IoT Greengrass core. The container images are hosted on Amazon Elastic Container Registry (ECR) and deployed by the service to the gateway device. To enable your device to access those images, you need to grant AWS IoT SiteWise permissions to Greengrass core running on the device.\nTo grant permissions to the role:\nNavigate to the IAM console and search for the Greengrass_ServiceRole (or any alternative role you may have associated with the Greengrass group you are using for your gateway). The Greengrass_ServiceRole role is typically created automatically when you create a group in the AWS IoT Greengrass console.\nAttach an inline policy to this role.\nPolicy definition (JSON):\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""VisualEditor0"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""ecr:GetDownloadUrlForLayer"",\n                ""ecr:BatchGetImage""\n            ],\n            ""Resource"": ""*""\n        },\n        {\n            ""Sid"": ""VisualEditor1"",\n            ""Effect"": ""Allow"",\n            ""Action"": ""ecr:GetAuthorizationToken"",\n            ""Resource"": ""*""\n        },\n        {\n            ""Sid"": ""VisualEditor2"",\n            ""Effect"": ""Allow"",\n            ""Action"": ""iotsitewise:*"",\n            ""Resource"": ""*""\n        }\n    ]\n}\nJSON\nDeploy AWS IoT Greengrass Connectors\nOnce you have configured your sources, navigate to the AWS IoT Greengrass v1 (classic) console to deploy the connectors to your device.\nTo do this:\nNavigate to Groups in the AWS IoT Greengrass v1 (classic) console\nSelect the group you picked for use with your gateway in the previous step, and navigate to the Connectors page .\nYou should see two connectors with \xe2\x80\x9cSiteWise\xe2\x80\x9d in the title in your group. Choose Actions and then choose Deploy. AWS IoT Greengrass will start the deployment.\nThe deployment can take up to 5 minutes to complete. When completed, the deployment status will change to \xe2\x80\x9csucceeded.\xe2\x80\x9d\nConfigure Asset Models\nOnce the Data Processing pack is enabled and all connectors are successfully deployed to the gateway, it can begin processing data using asset models.\nTo configure an asset model for the edge:\nNavigate to the Build section in the console and find the asset model you wish to configure.\nOpen the Configure for Edge setting on the top left side of the console. You can select from one of three options presented:\nNo Edge configuration (default) \xe2\x80\x93 This options sends all data points to the cloud. Metrics and transforms are computed in the cloud. Select this option for properties you want to use in remote applications e.g. cross-site monitoring dashboards and analytics.\nCompute all properties at the edge \xe2\x80\x93 This options configures all transforms and metrics to compute in the gateway and only send the final results to AWS IoT SiteWise. Depending on the specifics of the asset model, you may want to understand how much compute resources your metrics and transforms may require. Select this option if you want to all data for the asset to be available for querying locally to minimize latency and ensure the data is available regardless of cloud connectivity.\nCustom configuration \xe2\x80\x93 You can choose which asset model properties you want to compute at the edge. This option allows you to incrementally move compute to the edge. For example, you could initially only choose the properties required by local applications to be computed at the edge. This option is also handy for filtering data streams. You can define filters on measurements as transforms computed at the edge and keep those measurements at the edge. For this configuration, the gateway will only send the filtered values for those measurements to the cloud.\nIn preview, you can process up to 150 transactions per second on a quad-core 16GB device. A transaction can be a measurement data point collected, a transform computed, or a metrics computed. For example, you can process data for 10 assets with 5 measurements (1 data point per second), 5 transforms, and 5 metrics (10 x [5+5+5]). An AWS IoT SiteWise gateway fetches all  instances of the asset model from the service and processes data for measurements it is able to collect. All you need to do is configure the asset models themselves and keep the above load guidance in mind.\nSet up gateway credentials\nBefore you can access data or dashboards from the gateway, you need to create Sigv4 credentials on the gateway. Setting these credentials is mandatory and ensures any unauthorized clients on the network cannot gain access to the gateway. The credentials are created with a user defined 12 character password, which is also used by the OpsHub for AWS IoT SiteWise application and local SiteWise Monitor dashboards to securely retrieve data from the gateway.\nTo create the gateway credentials:\nssh into your SiteWise gateway\nExecute sudo /sitewise_edge/credentials/create-credentials.sh\nThe terminal will display the message below to prompt you to enter your desired password. Choose a 12 character password.\ngateway-host % ./create-credentials.sh \n\nPassword has following minimum requirements:\n1. Must be at least 12 characters long.\n2. Contain mixture of both uppercase and lowercase letters.\n3. Contain a mixture of letters and numbers.\n4. Include of at least one special character, e.g., ! @ # ? ].\n5. Characters < or > are prohibited as both can cause problems in Web browsers.\n\nEnter Password: \nConfirm Password: \nEnter a date (yyyy-mm-dd) [leave empty for never]: 2022-12-31\n\n--------------------------------------------------------------------------------\nSecurity Reminder:\n\nSecurity is a shared responsibility between AWS and you. When you use\nAWS IoT SiteWise Edge, you are also responsible for securing your devices, local\nnetwork connection, and private keys. Encrypt and secure your gateway, so your\nindustrial data is secure as it moves through the gateway. If your gateway has\na hardware security module, you can configure AWS IoT Greengrass to secure your\ngateway. For more information, see Hardware security integration in the\nAWS IoT Greengrass Developer Guide. Otherwise, consult the documentation for\nyour operating system to learn how to encrypt and secure your file system.\n--------------------------------------------------------------------------------\n\n\nYour API access credentials expiring on (2022-12-31) are:\nexport AWS_ACCESS_KEY_ID=""EDGE3DZTKQUF5IAIWUVS""\nexport AWS_SECRET_ACCESS_KEY=""e6174a0fbd3d2a42072e0beb61de42280fc6656722533e0a0a16bf4f7e57c968""\nexport AWS_REGION=""Edge""\nBash\nFinally, acquire the gateway certificate. You will need this certificate to call APIs and use the OpsHub for AWS IoT SiteWise application. To acquire the certificate follow these steps:\nSSH into the gateway.\nCopy the certificate file (servercert.pem) from /sitewise_edge/certificates/servercert.pem to the client machine Note: you have to be root and sudo cp /sitewise_edge/certificates/servercert.pem\nscp the file to your local machine.\nMonitor your gateway\nOnce your gateway is in operation you can monitor it locally and the AWS IoT SiteWise console. You can use the OpsHub for AWS IoT SiteWise application locally to check the state and performance of your gateway in real-time. This data can help you debug gateways and also understand if you need to upgrade the device hardware to support your workload well.\nThe application provides the following data and options to help with debugging and management:\nList of software components running on the gateway\nUptime status of software services (e.g. are the dashboard services running or down?)\nDevice performance metrics (e.g. disk usage, CPU usage, memory usage)\nCloud connectivity status\nLatest data points collected and computed for asset properties (to confirm that data is processing as expected)\nOption to restart the gateway software. Restarting or power cycling the gateway restarts all software services and fetches the latest asset model definitions from the cloud service\nTo use the OpsHub for AWS IoT SiteWise application download and install it from here. To sign in, follow these steps:\nEnter password created during gateway setup.\nSelect the certificate obtained from the gateway.\nEnter the IP address of the gateway on your local factory network. Make sure both port 8443 and 443 are open and externally accessible on the gateway.\nConsuming data in local applications\nOnce you have setup your gateway and configured asset models for edge, you can access data directly from the gateway using GET APIs in the AWS IoT SiteWise SDK. You can also use the OpsHub for AWS IoT SiteWise application to browse a list of AWS IoT SiteWise Monitor portals available on the gateway and launch them in a web browser.\nQuerying data from the gateway\nYou can use AWS IoT SiteWise to get data from the gateway. You can use the AWS CLI or Postman app to test the APIs to confirm the gateway is processing data as expected. A generic http client like Postman would require a service name and region to work. Use service name as \xe2\x80\x9ciotsitewise\xe2\x80\x9d and region as \xe2\x80\x9cEdge.\xe2\x80\x9d\nTo get data from the gateway, you will need to configure your AWS IoT SiteWise SDK:\nConfigure the SDK to use the access-key-id and secret-access-key provided during the gateway setup step above. Here is an example on how to do this in node.js.\nRegister your gateway certificate with your SDK. Here is an example to do this in node.js.\nIf the gateway is processing the data, the results of an GetAssetProperty() call should include computed values for transforms and metrics. You can also see the latest value computed using the Asset Models service in OpsHub for AWS IoT SiteWise application.\nAccessing AWS IoT SiteWise Monitor portals\nYou can see a list of AWS IoT SiteWise Monitor portals in the OpsHub for AWS IoT SiteWise application. Once connected, navigate to SiteWise Monitor Portals item in the services menu to see a list of portals available on the gateway. You can launch the SiteWise Monitor portal in your web browser. You can bookmark this link or share it with your colleagues. The dashboards can be accessed through these links from a web browser on any machine on the same network as the gateway.\nNote: you may have to accept self signed certificates from both https 443 and 8443 ports to be able to access the dashboards in your web browser.\n'"
150,Unlock the value of embedded security IP to build secure IoT products at scale,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/12/10/EmSPARK-Arch_LO_Update_10292020-1024x629.png,https://aws.amazon.com/blogs/iot/unlock-the-value-of-embedded-security-ip-to-build-secure-iot-products-at-scale/,"b'Introduction\nIoT product development crosses several domains of expertise from embedded design to communication protocols and cloud computing. Because of this complexity \xe2\x80\x9cend-to-end\xe2\x80\x9d or \xe2\x80\x9cedge-to-cloud\xe2\x80\x9d IoT security is becoming a challenging concept in the industry. Edge in many cases refers to the device as a single element in the edge-to-cloud chain. But the device must not be regarded as a whole when security requirements are defined. Trust must first be established within the processing unit and propagated through several layers of the software stack before the device becomes a trusted end node. Securing the processor requires to properly integrate multiple layers of security and use security features implemented in hardware. Embedded security expertise and experience is required to accomplish such tasks. It is very easy to put a lot of effort on implementing security for an IoT product and in the same time missing to cover key use cases. A simpler way to narrowing down on defining the end-to-end security is to start with identifying the minimum set of business requirements.\nBrand image, how a company\xe2\x80\x99s customers perceive and value it, is one of the most valuable assets of any corporation. Two of the most important characteristics of an IoT device that can promote a positive brand image are: resiliency and privacy. For resiliency, this might mean adding features that increase the device\xe2\x80\x99s ability to self-recover from malfunctions or cyber-attacks. For privacy, this means protecting user information and data but also the intellectual property (IP), the product invested in the product. This means that preventing exploitation through vectors such as product\\device cloning and over production becomes important. Another business driver is the overall cost of ownership for the product. Are there security related features that can drive the cost down? We include here not just operational cost but also liabilities.\nIn this blog, we dive deeper into solutions that support these business requirements. We will also discuss a demo we have created in collaboration with our partners Sequitur Labs and Arrow to demonstrate a commercially available approach to solving a number of several security use cases for IoT.\nSecurity in depth \xe2\x80\x93 a methodical approach for securing connected products\nIoT security must start with securing the device, so that data, data collection, and information processing can be trusted. Security must be applied in layers and facilitate trust propagation from the silicon hardware root of trust (HWRoT) to the public/private cloud or the application provider back-end. Furthermore, the connected paradigm provides the opportunity to delegate access control and security monitoring in the cloud, outside of the device. Narrowing down further, device security must be rooted by enabling fundamental capabilities of the processor or system on chip and consider all three stages of the device lifecycle: inception (manufacturing, first boot), operation, and decommissioning.\nIn a nutshell we should consider the following layers for securing any IoT product:\nSet a hardware root of trust \xe2\x80\x93 secure programming and provisioning (firmware, key material, fuses)\nImplement hardware enforced isolation \xe2\x80\x93 system partitioning secure / non-secure\nDesign secure boot \xe2\x80\x93 authenticated boot chain all the way to an authenticated kernel\nBuild for resiliency \xe2\x80\x93 fail-safe to an alternative firmware image and restore from off-board location\nEnable Trusted Execution \xe2\x80\x93 establish a logical secure enclave\nAbstract hardware security \xe2\x80\x93 streamline application development\nEnable security monitoring \xe2\x80\x93 cloud based, actionable security monitoring for a fleets of devices\nThese capabilities provide a foundation sufficient to fulfill the most common security requirements of any IoT product.\nEmbedded security features needed to build the security layers described above are available today from many silicon providers. However, software is needed to turn these into a usable framework for application developers to easily implement higher layer security use cases without the need for advanced silicon expertise.\nSuch software products must be architected to be easily ported to diverse silicon designs. Secondly, the software solution must work with the established IoT manufacturing process. \xe2\x80\x9cTurning on\xe2\x80\x9d embedded security features triggers changes to existing manufacturing flows to accommodate hardware testing before final firmware image can be programmed, burning fuses in the silicon in a specific order and overall handling sensitive cryptographic key material. The fragmentation, complexity, and expertise required are the reasons why embedded security is a challenge to implement at scale in IoT today.\nA closer look \xe2\x80\x93 commercially available secure platform with Arrow Shield96\nAWS partnered with Sequitur Labs and Arrow to provide a commercial solution that follows the approach described in the previous paragraph. This solution follows the NIST SP 800-193 for Platform Firmware Resilience Guidelines and goes beyond to create a secure platform fitted for embedded and IoT products. In the same time it is abstracting the complexity of understanding and utilizing embedded security IP such as hardware crypto, random number generators, fuse controllers, tampers, hardware integrity checkers, TrustZone, on-the-fly memory encryption.\nFor this blog, we created a demo using the Arrow Shield 96 Trusted Platform (Fig 1) single board computer running Sequitur Labs custom firmware image based on the EmSPARK Security Suite. The Arrow Shield96 board is based on the Microchip SAMD27, a Cortex A5 entry level MPU that embeds a set of security IP capable to fulfill the most stringent security requirements.\nFig.1 Arrow Shield 96 Trusted Platform\nLet\xe2\x80\x99s dive deeper into the technical implementation first then into the demo scenarios that fulfill some of customers\xe2\x80\x99 business needs.\nSecurity inception and propagation of trust\nSecure boot and firmware provisioning\nIntroducing secure boot requires initial programming of the CPU, essentially burning keys in the processor\xe2\x80\x99s fuses, setting up the boot configuration, establishing the Hardware Root of Trust, and ensuring the processor only boots authenticated, trusted firmware. Secure boot implementation is tightly correlated to the processor programming and the device firmware provisioning. The following section provides details how secure boot and firmware provisioning can be done properly to establish a trusted security foundation for any application.\nFirmware provisioning\nEmSPARK Security Suite methodology for provisioning and programming the Shield96 board minimizes complexity and the need for embedded security expertise. It provides a tool and software building blocks that guide the device makers to create an encrypted manufacturing firmware image first. The manufacturing firmware image packages the final components: encrypted blobs of the final device firmware, a provisioning application, and customer specific key material such as private key and X.509 certificate for cloud connectivity, certificate authorities to authenticate firmware components and application updates.\nThe actual firmware provisioning and CPU programming is performed automatically during the very first boot of the device flashed with the manufacturing image. With the CPU running in secure mode the provisioning application burns the necessary CPU fuses and generates keys using the embedded TRNG (true random number generator) to uniquely encrypt the software components that together form the final firmware. Such components are the Trusted Execution Environment (CoreTEE), Linux kernel, customer applications, Trusted Applications, and key material (such as key material needed to authenticate with AWS IoT Core).\nThe output \xe2\x80\x93 establishing a trusted foundation\nThe result is firmware encrypted uniquely with a key derived from the HWRoT for each device in a process that does not leave room for device secrets mismanagement or human error. Device diversification achieved this way drastically reduces the cost of manufacturing by eliminating the need for HSMs and secure facilities while providing protection from class break attacks (break one break all).\nAnother task the provisioning process performs during the very first boot is creating and securely storing a unique device certificate from a preloaded CSR (Certificate Signing Request) template and a key pair generated using the HW TRNG then signed with a customer provided private key only usable securely during the device first boot. The device certificate serves as the immutable device identity for cloud authentication.\nSecure boot\nThe secure boot implemented creates the system partitioning in secure and non-secure domains making sure all peripherals are set to the desired domain. Arm TrustZone and Microchip security IP are at the core of the implementation. CoreTEE, the operating system for the secure domain runs in on-the-fly AES encrypted DDR memory. This protects a critical software component (the TEE) from memory probing attacks. Secure boot has been designed so at the end of the boot process, before handing over control of the processor from the secure domain to the non-secure domain (Linux) to close access to the fuse controller, secure JTAG, and other peripherals that can be leveraged to breach the security.\nBuilding for resilience\nSecure boot implements two features that boost device resilience \xe2\x80\x93 a fail-over boot from a secondary image (B) when primary boot (A) fails, and the ability to restore a known good image (A) from an off-board location. The solution includes a hardware watchdog and a boot-loop counter (as set by the device maker) that Linux resets to maximum after each successful boot. If Linux fails to boot repeatedly and the counter reaches zero the B partition is set for the next boot. After such failure once the failover boot B is loaded, the device connects to an off-board location (in our demo that is a repository on AWS) retrieves the latest firmware image and re-installs it as the primary one (A). These two features help to reduce operational cost by allowing devices in the field to self-heal. In addition, AWS IoT Device Defender checks device behaviors for ongoing analysis and triggers alerts when behaviors deviate from expected ranges.\nIn our demo when the alternative firmware image (B) is loaded, an event is triggered in the AWS IoT Device Defender agent. The AWS IoT Device Defender agent running as a TA in the secure domain sends these events to the AWS IoT Device Defender Detect service for evaluation. For this demo we are using the AWS Device Defender Custom Metrics feature which gives the flexibility to package and send to AWS Device Defender any device metrics. The TA, running in the secure domain, also signs AWS IoT Device Defender messages to facilitate integrity validation for each reported event.\nAnother key component of the EmSPARK Suite is the secure update process. Since secure boot is the only process that can decrypt firmware components during device start it is also involved in performing the firmware update. The firmware update feature is facilitated in Linux as an API call that requires a manifest and the signed and/or encrypted new firmware image. The API call performs image signature verification and sets the flag for the boot to update and restarts the board. During next boot the secure boot process decrypts the new image using a pre-provisioned key and re-encrypts it with the board-specific key. The manifest indicates which components need to be updated \xe2\x80\x93 Linux Kernel, TEE, TAs and/or bootloader.\nEnabling easy development through security abstraction\nArrow Shield through the EmSPARK Suite product preloads a number of TAs (Trusted Applications) with the Shield96 firmware. The figure below is a view of the dual domain implementation and the software components provided with the Shield96 Trusted product in our demo.\nFig 2. Software architecture enabling TrustZone\\TEE with EmSPARK Suite\nThese TAs expose a set of secure functions to Linux via a C SDK (called the CoreLocker APIs). The Arrow board and Sequitur\xe2\x80\x99s security suite preloads the following TAs for our demo:\nCryptographic engine \xe2\x80\x93 providing symmetric, asymmetric crypto operations and key generation integrating silicon-specific hardware crypto\nKey-store and a CA-store managed (add, delete) via signed commands\nSecure firmware update\nSecure storage for files and stream data\nTLS and MQTT stacks\nAWS IoT Device Defender secure agent\nIn addition, a tamper detection and remediation TA has been added for our demo purposes (as detailed in \xe2\x80\x9cThe demo\xe2\x80\x9d section below). These TAs provide a preloaded framework for implementing a comprehensive set of security use cases assuring that security operations are executed in isolation from the application OS in an authenticated and resilient environment. Such use cases include confidentiality, authentication and authorization, access control, attestation, privacy, integrity protection, device health monitoring, secure communication with the cloud or other devices, secure lifecycle management.\nAll TA functions are made available to application development through a set of C APIs via an SDK. Developers do not need to understand the complexity of creating TAs or using HW security provided by the chipset.\nTranslating TAs to security use cases\nThrough a securely managed CA-store (Certificate Authority) the device can authenticate payloads against a set of CAs optionally loaded at manufacturing or later in the device lifecycle. Having the ability to update securely the CAs the device or product owner can transfer the ownership of certain functions such as firmware update or application update to other entities. For example, the customer owns the applications but the firmware update and security management may be delegated to a third party Managed Service Provider while maintaining privacy requirements.\nThe cryptographic engine is core to anything related to security and implement a set of symmetric and asymmetric cryptographic functions and key generation allowing applications in non-secure domain to execute crypto in isolation. HW crypto is used when implemented by the chipset.\nThe Microchip SAMA5D2 implements in hardware the ability to monitor in real time regions of memory. In the Shield96 firmware this feature \xe2\x80\x93 ICM, Integrity Check Monitoring \xe2\x80\x93 is used to monitor the integrity of the Linux kernel. Any modification of the Linux kernel triggers an interrupt in the secure domain. The hardware isolation implemented through TrustZone prevents Linux to even \xe2\x80\x9cbe aware\xe2\x80\x9d of such interrupts. The interrupt triggers a remediation function implemented in a TA and together with the Device Defender Secure Agent TA that does three operations:\nrecords the tampering event and restarts Linux from the verified, authenticated encrypted image provided through secure boot\nafter restart packages the tampering event into a JSON format, signs it for integrity assurance and stores it\npublishes the JSON package to the AWS IoT Device Defender monitoring service\nComplementing the edge-to-cloud security strategy with AWS IoT Device Defender\nAWS IoT Device Defender audits device cloud configuration based on security best practices and monitors anomalies and threats on devices based on expected cloud- and device-side behaviors on an ongoing basis. In this demo and for complementing the defense mechanisms implemented at the device level, AWS IoT Device Defender performs its monitoring capability and enables customers to receive alerts when it evaluates that anomalous or threat events occurred on an end-node. This demo required integrating AWS IoT Device Defender agents on both the non-secure and secure domains of the Shield96 board. The security domain is providing the secure crypto signature (using securely a private key) to device health reports and also isolates the detection and reporting processes from being intercepted by malicious applications. AWS IoT Device Defender agent collects monitored behaviors in the forms of metrics from both domains; then from the secure domain, AWS IoT Device Defender agent sends the metrics to the AWS Cloud for evaluation.\nThe Demo\nFor a full demo tutorial, please watch this video .\nFig. 3 Edge-to-cloud IoT security demo at Arrow Embedded to Go 2020\nThe demo covers the following scenarios:\nOut of the box experience\nFirmware personalization \xe2\x80\x93 secure firmware rotation to provide a logistical separation between manufacturing and production firmware\nDevice registration to AWS IoT Core\nDevice decommissioning (de-registration) from AWS IoT Core\nSecure firmware update\nResilience demonstration \xe2\x80\x93 tamper event simulation and remediation\nEvent reporting to AWS IoT Device Defender\nDemonstrating resilience and tamper violation reporting with AWS IoT Device Defender\nThe boot logic for the demo includes a safety check for tamper events. In this case, we connected a button to an environmental tamper pin. The tamper violation generated by the button press is detected in the next boot sequence so the initial boot code switches to the secondary boot stack, and proceeds to boot the \xe2\x80\x9cfail-safe\xe2\x80\x9d boot image. Once booted the system will publish the tamper event to AWS IoT Device Defender for logging and analysis. In the demo, the primary and secondary images are identical, so each tamper event simply switches to the other. This allows the demo scenario to be repeated with each tamper event switching the system from A to B or B to A firmware images.\nStreamlining personalized firmware to commercial boards\nThe commercial solution introduced by Arrow with the Shiled96 board includes a cloud based secure firmware rotation from the manufacturing generic firmware using AWS thus streamlining device personalization and providing a production ready device to a multitude of customers.\nOut of manufacturing, the Shield96 Trusted board comes preloaded with a minimum and generic version of Linux. The out of the box experience to get to a personalized and up to date firmware is as simple as inserting an SD card and connecting the board to the Internet. The device boots securely, partitions the SD card then using Just-in-Time Registration of Device Certificates on AWS IoT (JITR) registers the device to AWS IoT Core and provisions it to Sequitur\xe2\x80\x99s AWS IoT Core endpoint and to the Sandbox application. Next, the device automatically downloads the most recent generic or customer-specific file system, installs it and restarts. Thus the Sandbox provides lifecycle device management and firmware updates.\nThe 2-stage firmware deployment starting with a generic preloaded firmware at Arrow Programming Center followed by a cloud based final firmware rotation gives customers valuable features. For instance, an Original Equipment Manufacturer (OEM)\\Original Device Manufacturer (ODM) may need to produce devices with firmware variations for deployment in different geographical regions or customized for different customers. Alternatively, the OEM\\ODM may want to optimize logistics, manufacture in volume while the firmware is still in development, and load the final firmware in a distribution facility before shipping to customers. It also eliminates the opportunity for IP theft in manufacturing since the final firmware is never present at the manufacturer.\n'"
151,Announcing AWS IoT Device SDK for Embedded-C 202011.00,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/announcing-aws-iot-device-sdk-for-embedded-c-202011-00/,"b'Introduction\nAWS IoT Device SDK for Embedded-C (C-SDK) 202011.00 is now generally available. C-SDK is a collection of open source libraries written in C under the MIT license that makes it faster to securely connect embedded IoT devices to AWS IoT Core. This release improves several underlying libraries including coreMQTT, AWS IoT Device Shadow, and AWS IoT Jobs. It also adds new libraries including coreHTTP, and AWS IoT Device Defender needed for embedded and IoT applications.\nRefactored and optimized IoT connectivity, security, and AWS-specific libraries\nThis release includes refactored coreMQTT, coreHTTP, coreJSON, AWS IoT Device Shadow, AWS IoT Device Defender, and AWS IoT Jobs libraries for optimized memory usage and modularity, making them easier for use in resource-constrained devices. These libraries have gone through code quality checks (e.g. MISRA-C compliance, Coverity static analysis), and validation of memory safety with the C Bounded Model Checker (CBMC) automated reasoning tool. For more information on the libraries, you can read the README file.\nYou can find a summary of each library in the following list.\ncoreMQTT: The MQTT library provides a lightweight publish/subscribe (or PubSub) messaging protocol that runs on top of TCP/IP. This library is often used in Machine to Machine (M2M) and IoT use cases. The coreMQTT library implements a subset of the MQTT 3.1.1 protocol standard. It provides a menu of composable functions so that you can choose a combination that fits your needs. It has no dependencies on any additional libraries other than the standard C library. Finally, it includes an optional user-implemented platform time function.\ncoreHTTP: The HTTPS Client library provides a lightweight HTTP client request and response messaging protocol that runs on top of TCP/IP. This library is often used in web applications. The coreHTTP library is compliant with HTTP 1.1 standard, and is designed for embedded platforms. It has no dependencies on any additional libraries other than the standard C library and http-parser.\ncoreJSON: JSON (JavaScript Object Notation) is a lightweight data-interchange format. This format is easy for humans to read and write and for machines to parse and generate. The coreJSON library is a JSON parser that adheres to the ECMA-404 JSON standard. It is suitable for low memory footprint embedded devices.\nAWS IoT Device Shadow: This library is a client library for interacting with the AWS IoT Device Shadow service. It has no dependencies on any additional libraries other than the standard C library, and therefore, can be used with any MQTT client library.\nAWS IoT Device Defender: This library is a client library for interacting with the AWS IoT Device Defender service. This library has no dependencies on any additional libraries other than the standard C library, and therefore, can be used with any MQTT client library.\nAWS IoT Jobs: This library is a client library for interacting with the AWS IoT Jobs service. This library has no dependencies on any additional libraries other than the standard C library, and therefore, can be used with any MQTT client library.\nC-SDK date-based versioning\nLike our previous C-SDK release (C-SDK 202009.00), this release continues to follow date-based versioning in place of semantic versioning. This date-based versioning follows the format YYYYMM.NN:\nY represents the year (e.g. 2020).\nM represents the month (e.g. Oct).\nN represents the release order within the designated month (00 being the first release in Oct).\nFor example, a second release in November 2020 would be 202011.01.\nEach C-SDK library retains its semantic versioning, in which the version number itself (X.Y.Z) shows if the release is a major, minor, or point release. Semantic versioning on an individual library can help you assess the scope and impact of a new release on your application.\nHow this release affects you\nThe libraries in this release contain modified APIs that may affect your existing applications (Documentation and API References). To allow your build scripts to use the updated libraries, you may need to update any existing applications based on previous versions of C-SDK. You can find detailed information about migrating your application to the new release in the C-SDK Migration Guide.\n'"
152,Creating Object Recognition with Espressif ESP32,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/23/esp32-cam-diagram.png,https://aws.amazon.com/blogs/iot/creating-object-recognition-with-espressif-esp32/,"b'By using low-cost embedded devices like the Espressif ESP32 family, and the breadth of AWS services, you can create an advanced object recognition system.\nESP32 microcontroller is a highly integrated solution for Wi-Fi and Bluetooth IoT applications, with around 20 external components. In this example, we use AI Thinker ESP32-CAM variant that comes with an OV2640 camera module. This module is a low voltage CMOS image sensor providing full functionality of a single-chip UXGA (1632\xc3\x971232) camera and image processor in a small footprint package.\nAs a development platform, we will be using PlatformIO. It is a cross-platform, cross-architecture, multi-framework, professional tool for embedded systems engineers and for software developers who write applications for embedded products. We will be using it to program our ESP32-CAM microcontroller.\nThis following diagram demonstrates a connection between an ESP32-CAM and AWS IoT Core. It allows publishing and subscribing to MQTT topics. This means that the device can send any arbitrary information to AWS IoT Core while also being able to receive commands back.\n    Solution overview\nThis post will walk you through building a complete object recognition solution, starting with deploying a serverless project on AWS that handles the communication between the cloud and ESP32-CAM device and then setup of AWS IoT Device SDK for Embedded C inside PlatformIO project.\nThe list of services that we will be using is as follows:\nAWS IoT Core\nAmazon Rekognition\nAmazon S3\nAWS Lambda\nRequired equipment:\nAI Thinker ESP32-CAM\nUSB \xe2\x80\x93 TTL Serial Adapter\nBreadboard\n3x LEDs\n3x 330 Ohm resistors\nJumper Wires\n1x button\nHigh-level overview of the steps involved in this demo:\nCreate an AWS IoT device and export the certificates\nCreate an S3 bucket\nCreate two Lambda functions\nCreate two AWS IoT Core rules\nInstall and configure the Visual Studio Code with PlatformIO extension\nInstall Espressif 32 platform inside PlatformIO\nAssemble all the components on the breadboard\nDownload the project source code, build and flash it to ESP32-CAM device\nPress the button and point the camera towards any subject\nObserve the LEDs (Red: animal, Green: person, Yellow: everything else)\nCheck the serial port and Amazon CloudWatch for logs\nThis solution relies on the MQTT protocol to communicate with the cloud. The dataflow starts at the ESP32 embedded device that sends an MQTT message once the button is pressed. An IoT rule forwards this message to a Lambda function that generates an S3 signed URL and sends it back. Once the device receives the URL, it takes the framebuffer data from the camera module and does an HTTPS request to S3 to POST the image. On successful upload, ESP32 sends another MQTT message to a Lambda function and provides the name of the uploaded file. This Lambda function then calls Amazon Rekognition API, identifies the scene on the image and sends the results back to the embedded device that then decides which LED to turn on.\nCreating an AWS IoT device\nTo communicate with the ESP32 device, it must connect to AWS IoT Core with device credentials. You must also specify the MQTT topics it has permissions to publish and subscribe on.\nIn the AWS IoT console, choose Manage, Things and click Create.\nName the new thing myesp32-cam-example. Leave the remaining fields set to their defaults. Choose Next.\nChoose Create certificate. Only the thing cert, private key, and Amazon Root CA 1 downloads are necessary for the ESP32 to connect. Download and save them somewhere secure, as they are used when programming the ESP32 device.\nClick on Activate and then click on Attach a policy.\nClick on Register Thing without attaching any policies at this step.\nIn the AWS IoT console side menu, choose Secure, Policies, Create a policy.\nName the policy Esp32Policy. Choose the Advanced tab.\nPaste in the following policy template swapping out REGION and ACCOUNT_ID.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:client/myesp32-cam-example""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topicfilter/esp32/sub/data""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topicfilter/esp32/sub/url""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Receive"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topic/esp32/sub/url""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Receive"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topic/esp32/sub/data""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topic/esp32/pub/data""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:REGION:ACCOUNT_ID:topic/esp32/pub/url""\n    }\n  ]\n}\nJSON\nCreating an S3 bucket\nTo store the images from ESP32-CAM we need to create an S3 bucket. Create a bucket called \xe2\x80\x9cesp32-rekognition-YOU_ACCOUNT_ID\xe2\x80\x9d. Please use your account ID as a suffix to the bucket name. S3 bucket names are unique and this technique simplifies the process of choosing a non-taken name. Next, we make sure that your bucket is private.\nIn the permissions, set the bucket policy to the following. Modify account ID and username placeholders respectively:\n{\n    ""Version"": ""2012-10-17"",\n    ""Id"": ""Policy1547200240036"",\n    ""Statement"": [\n        {\n            ""Sid"": ""Stmt1547200205482"",\n            ""Effect"": ""Allow"",\n            ""Principal"": {\n                ""AWS"": ""arn:aws:iam::YOUR_ACCOUNT_ID:user/YOUR_USERNAME""\n            },\n            ""Action"": [\n                ""s3:GetObject"",\n                ""s3:PutObject""\n            ],\n            ""Resource"": ""arn:aws:s3:::esp32-rekognition-YOUR_ACCOUNT_ID/*""\n        }\n    ]\n}\nJSON\nAlso, paste the following CORS configuration to allow cross account requests:\n<?xml version=""1.0"" encoding=""UTF-8""?>\n<CORSConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/"">\n<CORSRule>\n    <AllowedOrigin>*</AllowedOrigin>\n    <AllowedMethod>GET</AllowedMethod>\n    <AllowedMethod>POST</AllowedMethod>\n    <AllowedMethod>PUT</AllowedMethod>\n    <AllowedMethod>DELETE</AllowedMethod>\n    <AllowedHeader>*</AllowedHeader>\n</CORSRule>\n</CORSConfiguration>\nXML\nCreating Lambda functions\nLambda functions are responsible for generating S3 Signed URLs as well as interacting with Amazon Rekognition API.\nFirst, we create the Lambda function responsible for getting S3 Signed URLs. Name it \xe2\x80\x98esp32-request-url\xe2\x80\x99, choose the \xe2\x80\x98Python 3.8\xe2\x80\x99 runtime, and add the following code, swapping out your REGION and account ID:\nimport boto3\nfrom botocore.client import Config\nimport json\nimport uuid\n\ndef lambda_handler(event, context):\n    bucket_name = \'esp32-rekognition_YOUR_ACCOUNT_ID\'\n    file_name = str(uuid.uuid4()) + \'.jpg\'\n\n    mqtt = boto3.client(\'iot-data\', region_name=\'REGION\')\n    s3 = boto3.client(\'s3\')\n\n    url = s3.generate_presigned_url(\'put_object\', Params={\'Bucket\':bucket_name, \'Key\':file_name}, ExpiresIn=600, HttpMethod=\'PUT\')\n    # command = ""curl --request PUT --upload-file {} \'{}\'"".format(file_name, url)\n    # print(command) # for local testing purpose\n    # print(file_name + \'/\' + url[8:]) # for local testing purposes\n\n    response = mqtt.publish(\n            topic=\'esp32/sub/url\',\n            qos=0,\n            payload=file_name + \'/\' + url[8:]\n        )\n       \nPython\nNow we modify your new Lambda functions execution role, adding the following permissions, so that it can generate S3 Signed URLs, and publish them to the MQTT topic:\n  ...{\n            ""Sid"": ""VisualEditor3"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""iot:Publish""\n            ],\n            ""Resource"": ""*""\n        },\n        {\n            ""Sid"": ""VisualEditor2"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:*""\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::esp32-rekognition-YOUR_ACCOUNT_ID"",\n                ""arn:aws:s3:::esp32-rekognition-YOUR_ACCOUNT_ID/*""\n            ]\n        }...\nJSON\n  Now create the second Lambda function. Name it \xe2\x80\x9cesp32-request-rekognition\xe2\x80\x9d and follow the same structure as the first, with Python 3.8 runtime. Paste the following code:\nimport boto3\nimport json\n\ndef detect_labels(bucket, key, max_labels=10, min_confidence=90, region=""REGION""):\n        rekognition = boto3.client(""rekognition"", region)\n        response = rekognition.detect_labels(\n               Image={\n                       ""S3Object"": {\n                               ""Bucket"": bucket,\n                               ""Name"": key,\n                       }\n               },\n               MaxLabels=max_labels,\n               MinConfidence=min_confidence,\n        )\n        return response[\'Labels\']\n\ndef lambda_handler(event, context):\n    results = \'\'\n    mqtt = boto3.client(\'iot-data\', region_name=\'REGION\')\n\n    bucket_name = \'esp32-rekognition_YOUR_ACCOUNT_ID\'\n    file_name = str(event[\'payload\'])\n\n    for label in detect_labels(bucket_name, file_name):\n        if (float(label[\'Confidence\']) > 90):\n                results += (label[\'Name\'] + \';\')\n\n\n    response = mqtt.publish(\n            topic=\'esp32/sub/data\',\n            qos=0,\n            payload=results\n        )\n \nPython\n  Again, we need to modify function\xe2\x80\x99s execution role, adding the following permissions, so that it can invoke Rekgonition detection service and publish the results to the MQTT topic:\n...{\n            ""Sid"": ""VisualEditor0"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""rekognition:DetectLabels"",\n                ""iot:Publish""\n            ],\n            ""Resource"": ""*""\n        },\n        {\n            ""Sid"": ""VisualEditor1"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:GetObject"",\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::esp32-rekognition-YOUR_ACCOUNT_ID"",\n                ""arn:aws:s3:::esp32-rekognition-YOUR_ACCOUNT_ID/*""\n            ]\n        }...\nJSON\nThese permissions allow Lambda function to talk to Amazon Rekognition API and publish the results to another MQTT topic.\nCreating IoT Core rules\nTo allow AWS IoT Core to Invoke our Lambda functions when MQTT messages arrive, we need to create two AWS IoT Core rules.\nThe first rule will forward the request esp32-request-url Lambda function. For that, you need to specify the following query statement:\nSELECT * FROM \'esp32/pub/url\'\nSQL\nSelect \xe2\x80\x9cSend a message to a Lambda function\xe2\x80\x9d as an Action and point it to \xe2\x80\x9cesp32-request-url\xe2\x80\x9d Lambda function. Optionally you can add error action and forward the results to CloudWatch logs.\nThe second rule will forward the request to the esp32-request-rekognition Lambda function. For that you need to specify the following query statement:\nSELECT * FROM \'esp32/pub/data\nSQL\nSelect \xe2\x80\x9cSend a message to a Lambda function\xe2\x80\x9d as an Action and point it to \xe2\x80\x9cesp32-request-rekognition\xe2\x80\x9d Lambda function. Also, here you can add an error action and forward the results to CloudWatch logs.\nTesting the cloud solution.\nBefore we move on to the embedded device, let us test this solution.\nFirst, let\xe2\x80\x99s test if our Lambda function returns signed URLs for our ESP32-Cam to use as an upload location. Open AWS IoT core and go to \xe2\x80\x9cTest\xe2\x80\x9d section.\nSubscribe to esp32/sub/url MQTT topic\nPublish the following json to esp32/pub/url MQTT topic:\n{""payload"":""virtual-esp32-device""}\nJSON\nIf you check on the topic that you subscribed to, you should receive a response with the filename/signed URL.\nYou can test this signed URL with tools like Postman. Paste the URL, select the PUT method, and set the body to \xe2\x80\x98binary\xe2\x80\x99, which allows you to select the file you want to upload. Once you submit the request, check your S3 bucket, a new file should be there.\nSecond, let\xe2\x80\x99s upload an image called test.jpg to the S3 bucket that you created earlier. Then open AWS IoT core and go to \xe2\x80\x9cTest\xe2\x80\x9d section again.\nSubscribe to esp32/sub/data MQTT topic\nPublish the following JSON to esp32/pub/data MQTT topic:\n{""payload"":""test.jpg""}\nJSON\nCheck the response in the esp32/sub/data topic. You should see keywords associated to what Amazon Rekognition service identified on your test image.\nSetting up ESP32-CAM\nBefore we start, make sure you have the right components at hand.\nUse the following diagram to assemble this solution:\nDownload the source of this demo project.\nThis project has the following structure:\ncomponents:\nesp32-camera/\naws-iot-device-sdk-embedded-C/\ninclude\nmain project include files\nsrc\ncerts/\nmain project source files\nCMakeLists.txt\nKconfig.projbuild\nplatformio.ini\nsdkconfig\nCMakeLists.txt\nExtract it into your working directory, open src/certs and substitute private.pem.key and certificate.pem.crt with the certificates that you downloaded during IoT device creation (maintaining the same filenames).\nOpen PlatformIO IDE (part of Visual Studio Code), make sure Espressif 32 framework is installed. Then inside PlatformIO terminal run the following command:\nplatformio run -t menuconfig\nBash\nSelect Example Configuration option and configure your WiFi details as well as IoT client ID (myesp32-cam-example).\nAlso, make sure to select \xe2\x80\x9cSupport for external, SPI-connected RAM\xe2\x80\x9d under Component config \xe2\x86\x92 ESP32-specific option.\nOpen sdkconfig file in the root folder and modify CONFIG_AWS_IOT_MQTT_HOST variable to the one that is under IoT Core \xe2\x80\x93 Manage \xe2\x80\x93 Things \xe2\x80\x93 myesp32-cam-example \xe2\x80\x93 Interact (HTTPS).\nAfter completion of these steps, you are ready to build and flash to your device.\nAfter a successful build and flash process, you can point the camera at a subject, press the button and wait for an LED to light up based on the results from Amazon Rekognition.\nNow let us test it on a real subject knowing the following:\nRed LED: animal\nGreen LED: person\nYellow LED: everything else\nAs you can see, my cat was correctly identified as an animal.\nTo debug any issues, connect a serial monitor to the serial port associated with your device. In addition, you can see logs associated to this solution inside CloudWatch Logs in the AWS Management Console.\nClean up\nTo avoid incurring future charges, delete the IoT Things together with both Lambda functions.\n'"
153,How Genie® (a Terex® brand) improved paint quality using AWS IoT SiteWise,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/27/Screen-Shot-2020-09-26-at-10.19.30-PM-1024x508.png,https://aws.amazon.com/blogs/iot/how-genie-a-terex-brand-improved-paint-quality-using-aws-iot-sitewise/,"b'Post by David McClellan, P.E., Engineering Manager and Jason Crozier, Cloud Architect at Terex.\nGenie\xc2\xae, a Terex\xc2\xae Brand, is a global manufacturer of lifting and material handling products and services delivering lifecycle solutions that maximize customer return on investment.\nIn this post, we discuss how Genie used an AWS IoT SiteWise based solution to ingest, organize, and analyze critical process parameters from the paint system. This solution identified inconsistent and improper pretreatment parameters in near real-time and enabled Genie to apply necessary corrective actions to improve the downstream paint quality of Genie lifts.\nAWS IoT SiteWise is a managed service to collect, organize, and analyze data from sensors, equipment, machines, programmable logic controllers (PLC) on the plant floor at scale.\nAbout the Use Case\nGenie had a high priority need to collect data from the paint pretreatment process in near real-time. This was due to increased paint-related defects as reported by Genie Customers. The data revealed that the paint pretreatment process was one key contributor to the paint-related defects.\nBefore using AWS, Genie used manual methods to collect shop floor data stored on hand written logs or electronic spreadsheets. Process instrumentation was in place but the readable outputs from this instrumentation were not being used. Genie was moving toward a traditional database-based solution to house the process instrumentation data and developing in-house websites to visualize the data.\nThe following principles were critical for the solution:\nData must be stored for up to 10-years for historical trend analysis\nGenie team members must be able to dive deep into the historical data for specific dates of manufacturing\nData must be visualized in near real-time on a dashboard, so machine operators and Engineering can react quickly to irregular trends or out of bound conditions for the key process parameters and key performance indicators (KPI)\nPaint operators must be able to manually enter collected data from the shop floor such as results from a chemical testing process (titration)\nThe solution must be able to generate alerts and send notifications in near real-time for out of bound operating conditions to take necessary corrective actions\nSolution must be scalable and repeatable for rapid deployment globally at scale\nAfter collaborating with AWS Professional Services for the pilot solution, we also quickly realized the potential of unlimited analytics opportunities for data-driven insights. We could do this by connecting related enterprise data from systems such as Enterprise Resource Planning (ERP) and Manufacturing Execution System (MES), with the operational data from manufacturing.\nSolution Walkthrough\nGenie and AWS Professional Services deployed an end-to-end production ready solution in eight weeks for the manufacturing operations, delivering real business outcomes. The following are core functions delivered by the solution:\nSecurely connect the plant floor to AWS\nIngest paint pre-treatment process data to AWS in near real-time\nIngest manually collected data (such as titration results) from the shop floor to AWS\nCreate virtual assets of the sensors and key processes from the shop floor in the AWS Cloud\nVisualize KPIs for the assets in near real-time to identify inconsistent and improper paint pretreatment\nMonitor operating conditions in near real-time, create alerts, and send notifications for corrective actions\nEnable Business Intelligence (BI) reporting for trend analysis and dive deep on historical data of up to 10-years\nThe following diagram illustrates the end-to-end solution deployed along with the AWS services used:\nThis solution is foundational for Genie\xe2\x80\x99s digital innovation journey. The following diagram illustrates how the solution can be extended to other enterprise data (ERP, MES, secondary sensors, other IoT devices) to perform advanced analytics such as Machine Learning and Data Warehousing on product, enterprise, and manufacturing data for optimizing operations.\nThis solution walkthrough consists of the following considerations:\nPlant to AWS connectivity\nSecurity first\nIngesting data into AWS\nCreating asset-hierarchy in the cloud\nStoring data in the cloud\nCreating alerts and send notifications for out of bound conditions\nVisualizing KPIs in near real-time and performing historical analysis\nRepeatable for rapid deployment at scale globally\nPlant to AWS connectivity\nThe management of the edge gateway remotely was a key requirement for the AWS IoT Greengrass service and KEPServerEX software running on the gateway. Not all industrial edge gateways provide a remote access controller, thereby requiring manual in-person intervention for a power recycle. To satisfy the requirement, an on-premise server was chosen with the following specifications:\nForm Factor 1U\nShort Chassis depth to place into a network Rack\nRugged server with dust filters for survival in the manufacturing shop floor\nRemote access controller allowing remote management regardless of the OS state\nAbility to deploy AWS IoT Greengrass for multiple manufacturing sites via existing setup with a golden image\nSetup for automatic failover\nFor high availability (HA), the on-premise server was joined to the existing remote access controller that enabled faster failover using regularly taken backups, reducing downtime. The backup can be restored when needed to the existing on-premises servers and retain the same IP address avoiding configuration updates for AWS IoT Greengrass. The automatic failover can be configured on the existing setup.\nWhile the entire process instrumentation connectivity from the shop floor to KEPServerEX was established in a few hours, live data streaming into AWS IoT SiteWise in the cloud happened within a week.\nSecurity first\nSecurity is job zero at Genie. A secure network topology and authentication system were implemented. AWS IoT Greengrass uses X.509 certificates, AWS IoT policies, and IAM policies and roles to secure the applications that run on the edge gateway locally. Refer to Security in AWS IoT Greengrass to learn more on how security on AWS is a shared responsibility.\nIngesting data into AWS\nPaint pretreatment process data from all the stages are ingested into AWS IoT SiteWise over the OPC-UA protocol. This uses the AWS IoT SiteWise Connector software running on the edge gateway, which is also running AWS IoT Greengrass.\nIn addition to the paint pretreatment process data, paint operators are able to enter manually collected data from process and instrumentation checks. This includes results from the chemical testing process (titration) that were also ingested into AWS IoT SiteWise using its BatchPutAssetPropertyValue API in an event-driven way.\nCreating asset-hierarchy in the cloud\nUsing AWS IoT SiteWise asset modeling capability, Genie\xe2\x80\x99s goal was to set up the following conceptual asset hierarchy at the enterprise level. This enabled a cross-site view of the key operational KPIs and contextualized the telemetry data for downstream applications.\n    The following asset hierarchy is set up in AWS IoT SiteWise for the pilot plant:\nStoring data in the cloud\nThe modeled data from paint pretreatment process is stored in a scalable and managed time-optimized data store of AWS IoT SiteWise (often referred to as a \xe2\x80\x9chot\xe2\x80\x9d operational data store). As the data becomes warm or cold, AWS IoT SiteWise is configured to send the data to Amazon S3 (data lake) to build the 10-years of history for downstream analytics.\nOnce the data is in the data lake, options are:\nAnalyze the data using familiar SQL with Amazon Athena\nPerform Machine Learning on the data using Amazon SageMaker\nPerform data integration, enrichments, and data transformations between operational and enterprise data (eg. MES, ERP) available in the data lake using Amazon EMR, AWS Glue etc.\nBuild a data warehousing solution using Amazon Redshift\nBuild Business Intelligence (BI) reports for historical trending and analysis and enable self-service using Amazon QuickSight\nCreating alerts and send notifications for out of bound conditions\nAn alerting solution is built for monitoring critical paint pretreatment process parameters and KPIs to take necessary corrective actions in near real-time.\nRules are set to examine the streaming values and compare against high and low bounds. Each bound has a warning zone and a critical limit. If a value enters a warning zone and stays in the warning zone for a designated quantity of data points, then an email alert is issued to the Paint Support Team for necessary corrective action.\nVisualizing KPIs in near real-time and performing historical analysis\nCriteria for data visualization was driven by end user persona needs. The AWS IoT SiteWise Monitor feature is chosen for near real-time operating conditions monitoring for the critical paint pretreatment process parameters and KPIs. Amazon QuickSight is chosen for BI reporting for historical trending and self-service data analysis. These are fully managed AWS services with no infrastructure to manage.\nUsing AWS IoT SiteWise Monitor, we can explore our library of shop floor assets, and create and share cross-site operational KPI dashboards with Plant Operators. This can be used for near real-time monitoring and visualization of KPIs such as performance, quality, and availability parameters of the overall equipment efficiency (OEE) KPI.\nUsing the near real-time runtime charts of SiteWise Monitor, the results enable the Genie Operations Team to understand current operating conditions of the paint system. The line graph option is used for most of real-time data visualization needs. This enables the Genie Operations Team to immediately see abnormal conditions and escalate as needed to resolve issues quickly. Engineering can then drill down into the data points to see what other operating conditions are affected.\nAmazon QuickSight is used by the Engineering and Quality team members in a much longer historical timeframe with a variety of capabilities to create management reports and further inspect the data.\nIn addition to the paint pretreatment process data, a one-time historical dataset from Excel was imported into the same data lake in Amazon S3.  Then Amazon Athena is used to access the historical data in Amazon QuickSight for visualizing historical trending. Following is a sample Amazon QuickSight report visualizing historical trending of the pump pressure against its upper and lower operating condition thresholds:\nOnce the paint pretreatment process data is available in the data lake, the Support and Manufacturing Engineering teams can use Amazon Athena to query the data from the data lake into QuickSight as well as for further on-demand data mining using familiar SQL. Following is a sample dashboard for Stage 1 monitoring of a critical process parameter (pH), which was shared with the team members to view on-demand.\nAmazon QuickSight also provides an out of the box Machine Learning (ML) Insights capability with zero coding. Genie is currently exploring this feature to discover hidden trends and outliers, identify key business drivers, and perform powerful what-if analysis and forecasting. This can be achieved with no technical expertise or ML experience.\nRepeatable for rapid deployment at scale globally\nOne of the key principles of the solution was repeatability to deploy in other paint systems globally with minimal changes. Some of the paint systems are similar to the pilot paint system, while the remaining will require some modification to the asset models. The automation is done using the AWS Developer Tools suite following AWS best practices. A step-by-step deployment runbook includes the deployment steps for the pilot plant. Within two weeks of the pilot delivered by the AWS team, the Genie team deployed the automated solution successfully in a new plant paint system. This included hardware setup and new asset model configuration changes.\nKey learnings\nThere were several key learnings from this pilot to highlight. The tight collaboration between Genie IT, OT, and multiple AWS teams helped to move the pilot quickly.\nThe key factors that contributed to this speed were the following:\nMotivated and nimble one-team mindset of Terex IT, OT, and AWS\nCollaboration tools established early\nHigh availability of key stakeholders\nAWS IoT SiteWise continued to evolve quickly to meet Genie needs and provided a set of niche features such as asset modeling and SiteWise Monitor that avoided building and maintaining a custom web application for near real-time dashboards\nAccess to a low-code / no-code application for the manual data entry could compress the timeline further\nThrough immersion day labs, training, and practical experience from AWS, the Genie team learned how product, enterprise, and manufacturing data can be connected to deliver new data-driven insights which are either not seen before or have been extremely difficult to get to. From near real-time visualization using SiteWise Monitor to analytics of Amazon QuickSight, Genie team is able to derive the operational insights from the data.\nAWS\xe2\x80\x99 customer obsession and working backwards principles delivered tangible results quickly, and established solid procedures for scaling. Knowing that Genie OT team was resource limited, the AWS team deployed a fully automated production ready solution that can be deployed across all the paint systems globally.\n'"
154,AWS IoT Named “Best Consumer IoT Solution” at 2020 IoT World Awards,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/08/13/IoT-GTMs-Global-Campaign-Consumer-IoT-Award-LinkedIn.jpg-1024x535.jpg,https://aws.amazon.com/blogs/iot/aws-iot-wins-best-consumer-iot-solution-at-2020-iot-world-awards/,"b'At AWS, we build technology to help customers and partners like Bose, Vizio, LG, British Gas Centrica Connected Home, Ayla, NXP, and more solve real world problems and unlock possibilities to create better business outcomes and new consumer experiences. Yesterday, IoT World named AWS IoT the \xe2\x80\x9cBest Consumer IoT Solution\xe2\x80\x9d for 2020. We are grateful to the IoT World team and panel of judges for this honor, and commend our ecosystem peers who were shortlisted. This award is an opportunity for us reflect on the journey we\xe2\x80\x99ve forged with our customers and global ecosystem of world class partners who use AWS IoT services to build consumer application for use cases such as home automation, security and monitoring, home networking, energy management, and more.\nThese organizations rely on our technology to help accelerate time to market, innovate for better customer experience, reduce connection costs, manage IoT devices at scale, and deliver results to their top and bottom line. But the truth is, we also rely on them to ensure we are providing the market with the right solutions for building and managing great consumer IoT applications. Our ecosystem of partners help integrate our services with IoT hardware customers need to produce smart and secure products, build ready-made solutions, and extend their expertise to help customers achieve their desired outcomes faster. Our customers and partners inspire us by their ingenuity and constant desire to break the boundaries of what is possible today. Understanding their problems and desired outcomes helps us better shape the technology we provide them, and inspires our teams to always strive for more from the solutions we deliver.\nSince launching AWS IoT in 2015, we recognize that most, if not all, of our major product milestones are the direct result of learning from the pain points our customers and partners are facing and turning those learnings into solutions that help them securely build and manage IoT devices at scale. This blog post will chronicle several of our key solution milestones and highlight a few of the customers and partners who continue to help us define what it means to be the industry\xe2\x80\x99s best solution for consumer IoT use cases.\n2015-2016: AWS IoT is born\nBefore we announced the general availability of AWS IoT in December 2015, pioneer customers were already building IoT applications using other AWS and Amazon Services. Coupling their feedback with our experiences with Amazon Robotics, drones (Amazon Prime Air), the Amazon Echo and Alexa Voice Service, the Dash Service, and multiple generations of Kindles and FireOS devices, gave us a well-informed perspective on current pain points that added complexity and development time to IoT applications.  We designed AWS IoT Core, a managed cloud service that lets connected devices easily and securely interact with cloud applications and other devices at scale, with all of these learnings in mind.\nOne of these early customers was iRobot. In September of 2015, as the popularity of the Roomba climbed and the number of connected customers and services quickly multiplied, iRobot recognized it needed an IoT solution that could quickly scale for more direct control. They selected AWS IoT as a core component for their next generation platform. \xe2\x80\x9cThe AWS serverless architecture and the ease of use of the AWS services inside it free up developer time to produce business value,\xe2\x80\x9d said Ben Kehoe, Cloud Robotics Research Scientist, iRobot. Today, iRobot uses AWS IoT services to provision and manage their global connected device fleet (they surpassed 30 million robots sold milestone in 2019!), delivers new innovations in smart home robotics such as the Terra\xc2\xae t7 Robot Mower, and continues to handle holiday traffic spikes of up to 20X their norm with ease.\nAnother pioneer was Rachio, creator of the Rachio Smart Sprinkler Controller, a WiFi-based irrigation controller that allows consumers to optimize irrigation schedules. The controller consults local weather forecasts and automatically adjusts watering time and volume to account for specific irrigation setups, plants, and soil types in up to 16 different irrigation zones. This allows users to conserve water while not under-watering lawns and landscaping. \xe2\x80\x9cFor companies wanting to get into the IoT space, tools like AWS IoT enable a faster time to market and eliminate the need to spend months and months and hundreds of thousands of dollars building a solution yourself,\xe2\x80\x9d says Franz Garsombke, CTO and Co-Founder of Rachio.\nLearn about Zimplistic\xe2\x80\x99s solution in this episode of \xe2\x80\x9cNow Go Build\xe2\x80\x9d with Werner Vogels, Amazon CTO and VP.\nZimplistic \xe2\x80\x94 the makers of Rotimatic, a smart, fully automated flatbread-making robot \xe2\x80\x94use IoT and Machine Learning technology to replicate a bread making process that\xe2\x80\x99s been handed down from parents to their children over generations. Using AWS IoT, Zimplistic can monitor the performance of the machines, making changes to its software if errors occur. Crucially, Zimplistic can also gather data on customer usage and feed that information into design updates. The connectivity also enables Zimplistic to roll out new software quickly and easily to all machines at the same time. This means Rotimatic owners get the convenience of a smart device that repairs itself if an error occurs and is being constantly improved.\n2017: Powerful intelligence at the edge, easier device management, and a better way to manage video data generated from connected cameras.\nIn June 2017, we introduced AWS IoT Greengrass to help customers seamlessly extend AWS to edge devices so they can act locally on the data they generate, while still using the cloud for management, analytics, and durable storage. This functionality is particularly useful for customers managing security cameras, routers, and in-home health monitoring devices, for example.\nThis ability to act locally, even when not connected to the Cloud, was critical for Electronic Caregiver, as this enabled them to directly support a patient\xe2\x80\x99s safety and wellbeing in the home. Electronic Caregiver provides patients with wearable gadgets (such as a wrist pendant), 24/7 vitals monitoring devices (such as a contact-free thermometer and a glucose meter), and in-home healthcare solutions that are connected to the cloud but must operate seamlessly day and night at the edge. If a patient\xe2\x80\x99s health reading is atypical, Electronic Caregiver springs into action delivering 24/7 Emergency response if needed to get the patient back on track. From a technical perspective, AWS IoT Greengrass Machine Learning Inference pushes a machine learning model built in Amazon SageMaker directly to the edge device in the user\xe2\x80\x99s home. The patient is asked specific questions to help assess the cause of the anomaly, and then they receive from their device a prediction of the likely reason(s) for this result as well as recommended solutions. These questions and solutions are voiced to the patient with Amazon Lex and Amazon Polly, as well as shared with the patient\xe2\x80\x99s selected stakeholders (such as family members and doctors) so everyone on the individual\xe2\x80\x99s care team is immediately aware.  Today, Electronic Caregiver delivers critical patient information around the world that helps save lives using AWS IoT together with dozens of other AWS services.\nWhile edge use cases were growing in importance, our customers had also seen growth in device fleets, with millions or even tens of millions of devices deployed at hundreds or thousands of locations. At this scale, treating each device individually was impossible. We introduced AWS IoT Device Management to help customers securely onboard, organize, monitor, and remotely manage their IoT devices at scale throughout their lifecycle.\nLearn more about Klika Tech and Stonehenge NYC\xe2\x80\x99s smart apartment solution on their This is My Architecture episode.\nKlika-Tech, an AWS Systems Integration Partner focusing on IoT, Big Data, and Data Visualization solutions, began using AWS IoT Device Management in a number of solutions tailored for consumer IoT use cases. In one such solution, Klika Tech and Stonehenge NYC came together to demonstrate what\xe2\x80\x99s possible in smart apartment technology. Klika Tech built a proof of concept using Alexa, Salesforce, and AWS IoT services including AWS IoT Core, AWS IoT Analytics, and AWS IoT Device Management. As part of the proof of concept, AWS IoT monitored the air conditioning in the apartment, and users could control temperatures using Alexa. Klika Tech created a system for tenants to report service issues via Alexa, which are automatically entered into Salesforce, where they could be monitored and addressed by management.\nWatch Comcast share their connected home security camera solution at AWS New York Summit 2019.\nIn 2017, AWS also introduced Amazon Kinesis Video Streams (KVS), a service that makes it easy to securely stream video from connected devices such as security cameras or baby monitors to AWS for machine learning, analytics, and processing. AWS IoT, together with KVS, simplify device management and video streaming for millions of smart home cameras. Comcast migrated to AWS IoT and KVS as well as other AWS services, such as Amazon SageMaker, to power their Xfinity Home security cameras and focus on secure storage of video data from customers worldwide. By using fully-managed services, Comcast was able to develop a solution that was at least 25% less costly than their previous solution and reduced operational burden. This helps them focus their engineering resources on building better customer experiences such as Alexa Voice integration and developing rich playback applications.\nFinally, we officially brought FreeRTOS into the AWS IoT portfolio. FreeRTOS is an MIT licensed open source, real-time operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage. FreeRTOS helps consumer products companies like appliances, wearable technology, or smart lighting manufacturers standardize microcontroller-based device development, delivery, and maintenance across a wide variety of products and models. Customers like Traeger, PetSafe, Hatch, and more use the FreeRTOS kernel to run low-power devices as well as software libraries that make it easy to securely connect to the cloud or other edge devices, so they can collect data from them for IoT applications and take action.\n\nBelkin, a global electronics brand that specializes in connectivity devices, is no stranger to innovation. They launched the original Wemo smart plug in 2012. As their device count grew and Belkin prepared to introduce the next generation, the company needed a solution that would allow them to focus on their product innovations\xe2\x80\x94not on managing their IoT infrastructure\xe2\x80\x94and found one in AWS IoT. By updating its IoT infrastructure with AWS IoT Core and FreeRTOS, Belkin was now prepared to handle a surge in new devices at less cost, while reducing product latency. As the next generation of AWS IoT Core and FreeRTOS\xe2\x80\x93enabled devices reaches more people, such as the newly announced Wemo Mini that works with Alexa, Belkin expects the time and money it saves will lead to more robust data analysis and machine learning, providing opportunities to further improve Wemo devices.\n2018: IoT security and robotics\nTo help customers secure their fleet of devices, we introduced AWS IoT Device Defender, a service that lets you continuously monitor security metrics for deviations from what you have defined as appropriate behavior for each device. If something doesn\xe2\x80\x99t look right, AWS IoT Device Defender sends out an alert so you can take action to remediate the issue. \xe2\x80\x9cAWS IoT Device Defender provides device behavior monitoring that is a must-have for any IoT company that is building a secure infrastructure,\xe2\x80\x9d says Franz Garsombke, CTO, Rachio. AWS IoT Device Defender was recognized as the \xe2\x80\x9cBest IoT Security Solution\xe2\x80\x9d at the 2019 IoT World Awards.\nAt re:Invent 2018 we introduced AWS RoboMaker, a service that leverages AWS IoT Greengrass and helps developers build, test, and deploy robotics applications in the cloud. AWS IoT veteran iRobot uses AWS RoboMaker to quickly discover problems across different product lines, accelerate the pace of their software builds and tests, and to ultimately manufacture higher quality consumer products. \xe2\x80\x9cWe were already an AWS customer, using AWS IoT services to monitor our robot fleet,\xe2\x80\x9d Chris Kruger, Director of Software Engineering at iRobot says. \xe2\x80\x9cWe trust AWS to deliver reliability, flexibility, and scalability.\xe2\x80\x9d\n2019: Alexa Voice and two-way video streaming\nIn September 2019, Amazon announced the general availability of Alexa Connect Kit (ACK), a new way for device makers to connect devices to Alexa without worrying about managing cloud services, writing an Alexa skill, or developing complex networking and security firmware. ACK is built on AWS IoT, and meets the cloud reliability requirements for the Works with Alexa (WWA) certification program. Leading device makers and consumer products companies, including Procter & Gamble and Hamilton Beach, use ACK to develop smart devices.\nFollowing up on the launch of ACK, we released the Alexa Voice Service (AVS) Integration for AWS IoT Core on AWS IoT Day in November 2019. AVS Integration for AWS IoT Core helps customers quickly and cost-effectively go to market with Alexa Built-in capabilities on new categories of products such as light switches, thermostats, and small appliances. AVS Integration for AWS IoT Core lowers the Alexa Built-in cost up to 50 percent by offloading compute and memory intensive workloads to the cloud and lowers the hardware requirements from 100MB to 1MB of RAM and from ARM Cortex \xe2\x80\x98A\xe2\x80\x99 class microprocessors to ARM Cortex \xe2\x80\x98M\xe2\x80\x99 class microcontrollers. This enables customers to bring Alexa directly to any connected device so users can talk directly to their surroundings rather than to an Alexa Family of Devices. The AVS Integration for AWS IoT Core was highlighted by Gartner in their 2020 Vendor Report as a key example of how Amazon is expanding the breadth and depth of its cloud infrastructure offerings. In this report, Gartner rated Amazon as Strong due to its consistent delivery of capabilities and customer value.\niDevices was among the esteemed winners of the first-annual Connected Design Awards for their Instinct Alexa Built-in light switch.\nBy using the AVS Integration for AWS IoT Core, iDevices was able to accelerate time-to-market from their typical 12-14-month development cycle to 4 months and optimized their infrastructure costs for their Instinct light switch with Alexa Built-in. \xe2\x80\x9cIf you think about the innovation in the gangbox, the light switches, and outlets, there really hasn\xe2\x80\x99t been anything,\xe2\x80\x9d says iDevices CTO, Shawn Monteith. \xe2\x80\x9cNow you can control it with voice, and what we\xe2\x80\x99re really trying to do is just extend that technology and bring some innovation to it.\xe2\x80\x9d\nFinally, at re:Invent 2019 Amazon Kinesis Video Streams added support for real-time two-way media streaming with WebRTC for use cases like home security and monitoring, camera-enabled doorbells, baby and pet monitoring, smart appliances, and more. Wyze uses AWS IoT to connect and manage their consumer devices and Amazon KVS to ingest, store, and process camera video. Now, Wyze has expanded their product offerings to include devices such as light bulbs, smart plugs, locks, contact and motion sensors, and more, delivering innovative experiences at attractive price points across a variety of consumer use cases.\nWhat will 2020 and beyond bring?\nIn 2020, we have seen companies continue to rely on AWS IoT services to help them cost-effectively deliver innovative consumer IoT products and experiences at scale.\n\xe2\x80\x9cWe have great customers. They challenge us every day to peek around corners and invent the tools they need to build connected ecosystems. Our customers are solving real world problems every day and we love being a part of that process!\xe2\x80\x9d says Michael MacKenzie, GM of AWS IoT Connectivity and Control Services.\nWatch Traeger\xe2\x80\x99s Customer Story on Twitch, and be sure to watch until the end for a surprise appearance by Werner Vogels, Amazon CTO and VP!\nOne such customer is Traeger Grills. Traeger allows users to command their grill from the couch or on-the-go with a WiFi controller that connects a smartphone to the grill via the Traeger App. They saw rapid commercial success and quickly realized they needed a new IoT platform to support their growth\xe2\x80\x94and saw AWS as a way to better integrate different parts of their business. Earlier this year, Traeger worked with a member of the Amazon Partner Network (APN), OST, to migrate hundreds of thousands of grills to AWS IoT Core, FreeRTOS, and OST\xe2\x80\x99s proprietary IP, The IoT Foundation, with no disruptions to the end user\xe2\x80\x99s service. By the end of 2020, Traeger expects that number to quadruple\xe2\x80\x94and with the AWS platform, this growth in capacity is available on demand, allowing Traeger to scale as needed. Traeger Grills also work with Alexa, so users can ask Alexa to set the food probe temperature, check pellet levels during cooking, or to shut down the grill after they are done. Because it\xe2\x80\x99s on AWS\xe2\x80\x99 single, well-integrated platform, Traeger can now bring value, like voice-enable actions, to the market faster.\nWe always welcome feedback about what to build next \xe2\x80\x93 get in touch with our team to let us know what you\xe2\x80\x99d like to see us build, or to learn how to get started with AWS IoT Solutions for the connected home and consumer devices. If you\xe2\x80\x99d like to stay up to date on the latest AWS IoT news, subscribe to our monthly newsletter here.'"
155,"Announcing new IoT partner solutions spanning automotive, healthcare, manufacturing, and connected home industry use cases",b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/27/solution-use-cases.jpg,https://aws.amazon.com/blogs/iot/announcing-new-iot-solutions/,"b'There are billions of devices in homes, factories, oil wells, hospitals, cars, and thousands of other places. Companies are discovering that these \xe2\x80\x9cthings\xe2\x80\x9d not previously connected to the Internet can provide intelligence into new areas of their business. The result? All aspects of an enterprise can be data-driven, which leads to insights that they can use to improve the customer experience, increase operational efficiency, and fuel innovation. Companies can understand their business operations better and make accurate decisions about their products, processes, and customer satisfaction faster than they could before.\nBuilding Solutions with AWS and APN Partners\nWith the proliferation of devices, you increasingly need solutions to connect them, and collect, store, and analyze device data. Comprehensive IoT solutions are typically more complex than the average IT project\xe2\x80\x94 they include devices, local data collection and analysis, and cloud services to collect, store, and analyze device data. AWS has broad and deep IoT services, spanning the edge to the cloud, to help you securely build IoT applications for virtually any use case across a wide range of devices. We also make it easy to select hardware that works with our services to help build and deliver successful IoT solutions with over 500 qualified partner devices in the AWS Partner Device Catalog. You can also take advantage of solutions leveraging undifferentiated heavy lifting already done by AWS and APN IoT Partners, including AWS IoT Competency Partners who have delivered demonstrated success in providing specialized edge-to-cloud IoT solutions. This helps you streamline your IoT projects, reduce the risk of your efforts, focus on your core competencies, and accelerate your time to value.\nDiscover AWS and IoT Partner Solutions\nTo make it easy for you to discover the right solution and qualified devices for your business requirements, we created the AWS IoT Solution Repository. On the AWS IoT Solution Repository, you can find solutions built by AWS Experts and the APN Partner community, IoT Solutions on the AWS Marketplace, and the AWS Partner Device Catalog, all in a single place. You can search and filter solutions by industry, solution type, use case, and AWS services used to help you quickly find the right solution for you.\n29 New IoT APN Solutions Now Available\nAPN partner solutions address a broad range of use-cases from from device connectivity to track and trace sensors, from connected factory to workplace safety monitoring, and from smart consumer products to user engagement. Built on AWS IoT, these 29 new APN partner solutions address a broad range of use-cases from device connectivity to track and trace sensors, from connected factory to workplace safety monitoring.\nActility ThingPark Location Low-Power Asset Tracking Solution \xe2\x80\x93 An asset tracking solution with battery-powered LoRaWAN low-power trackers with a modular location engine from Abeeway. Switchable location technology enables outdoor and indoor service continuity, and reporting behavior of trackers can be fully customized to match a wide range of asset tracking use-case requirements.\nActility ThingPark Enterprise Solution \xe2\x80\x93 A LoRaWAN private networking solution efficiently connects an organization\xe2\x80\x99s most valuable assets. It provides a scalable multi-gateway LoRaWAN connectivity infrastructure as well as dashboards for key operational insight and alarm management.\nAyla Connected Home HVAC Solution \xe2\x80\x93 A platform-based solution for HVAC manufacturers helps bring new cloud connected equipment to market faster. The solution provides a platform with set of pre-built services, dashboard and mobile applications, including integration with Amazon Dash Replenishment Service (DRS) and voice enablement.\nAyla High Value Asset Tracking Solution \xe2\x80\x93 A track and trace solution for manufacturers, utilities, aerospace, and automotive companies to track high value assets such as tools, equipment, parts, and supplies using RFID, Bluetooth LE, and cellular connectivity to optimize equipment utilization and minimize loss.\nAyla Supply Chain Asset Tracking Solution \xe2\x80\x93 This track and trace solution enables manufacturers, quick service restaurants, and transportation companies to secure and control a fleet of supply chain tracker devices, with the foundational services needed to connect, secure, and manage a holistic supply chain tracking solution.\nBosch Phantom Connected Machines Solution \xe2\x80\x93 A solution for retail, commercial, and residential verticals to measure energy consumption at a store, area, and appliance level to deliver valuable energy consumption insights as well as drive savings and sustainability goals across facilities.\nCognizant Connected Buildings Solution \xe2\x80\x93 A smart building solution brings together disparate building systems, assets, and sensors to provide facility managers and engineers with a transparent enterprise-wide real estate view with real time insights and intelligence for efficient, effective daily operations.\nConnected Factory Solution \xe2\x80\x93 This purpose-built offering from AWS and Partners unlocks data from manufacturing equipment, such as PLCs and Historians, to optimize operations, increase productivity, and improve availability.\nCradlepoint NetCloud Edge Connector for AWS IoT Greengrass \xe2\x80\x93 A NetCloud IoT edge-to-cloud service solution providing device management and orchestration services for Cradlepoint\xe2\x80\x99s purpose-built LTE and 5G wireless edge routers with AWS IoT Greengrass integration for local processing and action on edge-generated data.\nCrowley Carbon Energy Management Solution \xe2\x80\x93 Manufacturers have data stored in disparate systems across the factory. This solution seamlessly integrates into your production systems to quickly provide meaningful results based on real-time predictive energy and process analytics, and ROI-driven savings measurement and verification.\nDeloitte Smart Factory Fabric Solution \xe2\x80\x93 A pre-configured suite of cloud-based IoT applications for the smart factory delivers operational insights to improve performance and reduce costs by increasing visibility, improving production, improving quality, and reducing unplanned downtime.\nDomo IoT Asset Tracking \xe2\x80\x93 This joint solution from Verizon and Domo monitors asset location and conditions in real-time to deliver key insights and drive more informed business decisions resulting in improved operational efficiencies, cost control, and issue identification and resolution.\nEseye AnyNet Global Cellular IoT Connectivity Solution \xe2\x80\x93 Seamless data provisioning, simplified management, and ubiquitous IoT cellular connectivity solution, covering over 700 mobile network operators globally to simplify and automate the secure global deployment of IoT to deliver an average of 99.8% connectivity.\nEXOR Asset Condition Monitoring Solution \xe2\x80\x93 This solution includes the EXOR eXware 707T gateway with vibration sensors mounted on motors for time-series analysis on collected machine performance datasets to detect anomalies, so equipment service can be performed to address downtime issues proactively.\nFalkonry Clue Industrial ML Solution \xe2\x80\x93 This solution for predictive production operations identifies and addresses operational inefficiencies, such as unplanned downtime, unnecessary maintenance cycles, and quality variations, resulting in increased availability, performance, and quality.\nHarting and SiC Equipment Monitoring Solution \xe2\x80\x93 Machine operators need access to reliable usage and availability data of their industrial systems, including OEE data. This solution enables local data processing and cloud-based management for flexibility, robustness, and convenience for brownfield retrofit and other IIoT projects.\nModjoul Contact Tracing for Worker Safety \xe2\x80\x93 This contact tracing solution helps businesses reduce the spread of illness at the workplace. It delivers control and transparency through features such as symptom questionnaires, efficient QR code based entry management, employee census, wearable integration, and worker privacy.\nPega Digital Prescriptive Maintenance Solution \xe2\x80\x93 This solution uses Pega Intelligent Automation and AWS IoT to address the challenges of automating aftermarket services such as warranty, maintenance, or parts return to make business transformation possible across the entire value chain of an industrial enterprise.\nPi Labs and Pixada Vehicle and Asset Tracking Solution \xe2\x80\x93 This solution provides logistics and insurance companies with an easy-to-integrate aftermarket IoT vehicle tracking product to collect, store, and transmit reliable data from onboard sensor devices. This includes additional services for analysis and monitoring of driving data with integration into existing systems.\nPressac and Keytree Desk Monitoring Solution \xe2\x80\x93 Building managers can monitor desk occupancy with ultra-low power, wireless technology. The desk occupancy sensor accurately detects real-time presence and continually monitors desk occupancy, so you can track utilization and implement smart desk and room booking.\nPressac Equipment Energy Monitoring Solution \xe2\x80\x93 This solution helps organizations monitor energy usage at a granular level to reduce energy consumption and increase cost savings. Pressac sensors and gateways monitor building consumption and provide actionable data for more efficient energy use.\nTensorIoT Rubix Solution \xe2\x80\x93 This solution delivers a streamlined management system for IoT devices, as well as a single pane of glass for operational metrics and alerting. Users can easily enable device provisioning and OTA updates with scalable custom alerting, dashboards, and telemetry visualization.\nTensorIoT SafetyVisor Solution \xe2\x80\x93 This computer vision and IoT solution monitors your work environment to predict health protocol violations, so you can fix anomalies before they become a problem to help keep employees and customers safe.\nTensorIoT SmartInsights Solution \xe2\x80\x93 This industrial IoT and ML solution helps customers rapidly connect their industrial machinery and sensors to the cloud, where that data can be used to improve response time to issues and drive operational efficiency, as well as unlock long-term insights.\nThe Things Industries \xe2\x80\x93  The Things Enterprise Stack (TTES) is a scalable LoRaWAN Server that enables connectivity, management, and monitoring of large, remote gateways and device fleets. Its API-first platform reduces development effort and integrates seamlessly with existing systems.\nToradex with NXP \xe2\x80\x93 This solution helps accelerate the development of AI-enabled computer vision products. The kit provides industrial-grade edge compute and camera hardware, including an end-to-end reference implementation to demonstrate object detection and classification, leveraging AWS IoT Greengrass and Amazon SageMaker Neo.\nVertex Digital Twin Solution \xe2\x80\x93 This cloud-based, digital twin solution helps by bringing aligned 3D data to the shop floor and to connected touchscreen and mobile devices, powering sequenced work instructions, and visual reporting tools to improve product development collaboration.\nWipro Condition Based Monitoring Solution \xe2\x80\x93 This condition-based monitoring solution provides 24/7 asset visibility to ensure optimal asset utilization, better operational insights, and increase overall efficiency, providing real time insights on different assets types through a single interface.\nWipro Track and Trace Solution \xe2\x80\x93 This asset track and trace solution addresses the challenges faced by different industries to track different types of assets and monitor real time location to increase asset visibility, reduce theft/misplacements, and increase operational efficiency.\nReady to get started?\nThese solutions showcased here are just the first of many solutions our partners are developing using AWS Services to tackle the complexity of IoT for common industry use cases. These solutions help customers accelerate time to value with a trusted advisor with deep industry and use case expertise to guide you on your IoT journey.\nThere are several ways to get started with these solutions. Visit the AWS IoT Solution Repository to find a solution that meets your business needs, discover hardware or devices by accessing the AWS Partner Device Catalog, or purchase solutions directly from the AWS Marketplace. And, if you are ready to get started building your own IoT solution, visit our AWS IoT website to learn more about how to get started with AWS IoT services for industrial, consumer, and commercial use cases.\nNot seeing a solution or architecture that fits your needs? We\xe2\x80\x99re constantly on the look out for what to build next, and we have a professional services team that can help you with custom solutions in the meantime. Contact Professional Services and drop us a comment about what type of solution you are looking for!'"
156,Volkswagen opens the Industrial Cloud community,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/23/VWAG_Industrialcloud_Partner_EN_2000-1024x576.png,https://aws.amazon.com/blogs/iot/volkswagen-opens-the-industrial-cloud-community/,"b'Interview with Nihar Patel and Sarah Cooper\nTogether with Amazon Web Services (AWS) and integration partner Siemens, Volkswagen is opening up the Industrial Cloud to other companies from the engineering and technology sectors. In an interview, leading managers Nihar Patel (Executive Vice President New Business Development at Volkswagen AG.) and Sarah Cooper (General Manager of IoT Solutions at Amazon Web Services, Inc.) explain the advantages of new partnerships and give an outlook on the further expansion of the cloud.\n  Volkswagen and AWS have been working on the Industrial Cloud for a good year now. How would you describe the mission from today\xe2\x80\x99s perspective?\nPatel: We want to bring together data from all the Volkswagen Group facilities and make it usable on a real time basis. This will create the basis for even more efficient processes and increased productivity. We have already completed the first part of the journey \xe2\x80\x93 by the end of this year, 18 locations will be connected via the cloud. But that is only part of the task. In the future, we want to integrate other companies, such as suppliers, into the cloud. We are now taking an important step with eleven international partners who provide their own software applications.\nWhat is the benefit?\nPatel: The data that we integrate with the Industrial Cloud creates more efficiency through intelligent algorithms and software applications. For example, one of the eleven pioneering partners has developed an algorithm that uses artificial intelligence to optimize the use of driverless transport systems. Another company has an application that can be used to simulate the maintenance intervals of machines. The examples show: As the number of partners grows, so does the range of solutions our plants can draw on. The Industrial Cloud is not a closed club. We are open to cooperation \xe2\x80\x93 with our suppliers and any other company that wants to contribute solutions and/or consumer them.\nCooper: At AWS, we have extensive experience with building technology solutions that create value for both solution providers and users. Our insight is: Additional partners always bring in additional data, which in turn enables new solutions. This creates a positive dynamic that leads to further improvements.\nHow might such improvements look?\nCooper: A good example is software for optimizing plant efficiency. But this is only one option \xe2\x80\x93 analyzing data offers almost unlimited opportunities to expand the range of industrial applications at a rapid pace.\nPatel: Another example is energy management \xe2\x80\x93 a major issue in every factory. Together with partners, we want to work out solutions to reduce energy consumption \xe2\x80\x93 not just in one plant, but at many locations. This is good for the environment and good for Volkswagen. The more plants we bring into the cloud, the greater the economies of scale.\n\xe2\x80\x9cAs the number of partners grows, so does the range of solutions our plants can draw on.\xe2\x80\x9c\nNihar Patel\nExecutive Vice President New Business Development at Volkswagen AG.\nWhat do the partner companies gain from this?\nPatel: The companies have the opportunity to use their applications in partnership with one of the largest automobile production networks. They gain access to data with which they could further improve their products and processes and be even more successful in the market. The partner companies can also achieve high economies of scale because their solution is not only used in one plant, but potentially at more than 100 locations of the Volkswagen Group.\nCooper: In our experience, many industrial companies face very similar challenges. For system suppliers, this means: If their solution proves to be a standard in the Industrial Cloud, then the interest of other customers will also grow.\nIs it not risky to give other companies deep insights into production data?\nCooper: Data security and confidentiality are always our top priorities. Nevertheless, it can be useful to share information in order to get more efficient solutions. The key concept is selectivity: with whom does VW share that data and for what purpose?\nPatel: It\xe2\x80\x99s a give-and-take. If we expect companies to develop solutions for us, then we should also share the necessary information. There is great potential for better processes. In a data cloud, 1 plus 1 is not 2, but significantly more.\n\xe2\x80\x9cTogether we solve challenges that none of us could tackle alone.\xe2\x80\x9d\nSarah Cooper\nGeneral Manager of IoT Solutions at Amazon Web Services, Inc.\nLet us return to the cooperation between Volkswagen and AWS. Do you see a benefit beyond cloud development?\nPatel: At AWS, there is a strong culture of putting the customer at the center of everything. The needs are recorded in a narrative to develop the appropriate solution. This is a method that we increasingly adopt in our collaboration. We orient ourselves to the needs of our plants, and in the future to the needs of the supply chain.\nCooper: We learn from each other every day. It\xe2\x80\x99s not that each company only does its part of the job \xe2\x80\x93 the Industrial Cloud is created as a joint development project. Volkswagen contributes in-depth knowledge of industrial processes and excellent production. We at AWS are experts in digital processes. Together we solve challenges that none of us could tackle alone.\nWhat are the next steps?\nPatel: We take an evolutionary approach. On the one hand, we will integrate more and more solutions and Volkswagen locations into the cloud. On the other hand, we want to bring additional partner companies on board with incremental / new solutions. Volkswagen locations can then obtain software applications directly from the cloud to optimize their production. The Industrial Cloud will become the App Store for our plants.\nCan the project ever be completed or is the Industrial Cloud growing and growing?\nCooper: Modern software is never finished. I think the Industrial Cloud will lead to many applications and solutions that we are not yet thinking about. It is important that we get the right partners on board now. The more the companies contribute to solving the existing challenges, the more dynamic the collaboration will become. Together we can create a platform for VW from which many partners can benefit \xe2\x80\x93 companies from the automotive industry and perhaps even beyond.\nPatel: In the long term, we are striving for an open marketplace for industrial applications. On such a platform, all participants would be able to exchange, purchase and use their applications among themselves \xe2\x80\x93 regardless of any ties to Volkswagen. It would be a place that is basically available to all companies \xe2\x80\x93 from suppliers and technology partners to other automobile manufacturers.\nTo learn more about AWS IoT for Industrial, visit: https://aws.amazon.com/iot/solutions/industrial-iot\nTo read about Volkswagen\xe2\x80\x99s announcement on the launch of the Industrial Cloud community, visit: https://www.volkswagen-newsroom.com/en/press-releases/volkswagen-brings-additional-partners-to-industrial-cloud-6258\nFor more information on the Industrial Cloud, visit: https://www.industrialcloudhub.com\n     '"
157,Connected Factory Solution based on AWS IoT for Industry 4.0 success,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/cf-v1-image-1024x576.png,https://aws.amazon.com/blogs/iot/connected-factory-offering-based-on-aws-iot-for-industry-4-0-success/,"b'Manufacturing industries only realize 20 to 30 percent of the value of their data. By consistently leveraging the value of their data, manufacturing companies could reduce product development costs by up to 50 percent and operating costs by up to 25 percent, while increasing their gross margins by one third[1]. Industrial IoT (IIoT) is a data lever \xe2\x80\x93 it brings machines, field assets at the edge, cloud computing, analytics, and people together to improve the performance and productivity of industrial processes. With IIoT, industrial companies can digitize processes, transform business models, and improve performance and productivity, while decreasing waste. Currently, companies across a wide range of industries are working on IoT projects that connect billions of devices and deliver value across a variety of use cases including predictive quality and maintenance analytics, asset condition monitoring, and process optimization.\nFor example, Volkswagen Group is partnering with AWS to improve the productivity of their plants and save billions of euros when data from all 124 Volkswagen Group plants can be evaluated in a standardized way \xe2\x80\x93 \xe2\x80\x9cThe Industrial Cloud will be a key lever for improving the productivity of plants by 30 percent\xe2\x80\x9d according to Head of Volkswagen Group Production Gerd Walker.[2]\nIntroducing the AWS IoT Connected Factory Solution\nThe AWS IoT Connected Factory Solution makes it easy for customers to modernize their operations. With two versions of the solution, AWS can address the needs of manufacturing customers no matter their size or level of maturity along their Industry 4.0 transformation journey. The solution includes an industrial machine connectivity (IMC) kit, a kit to help customers easily get data from their assets into the AWS Cloud, IIoT Consulting and deployment expertise from AWS Professional Services, global and regional system integrators, and partner solutions based on AWS IoT for Industry 4.0 use cases.\nUnlock data to modernize manufacturing\nWe see that a vast majority of industrial customers are seeking a solution that can free up operational data at scale with near real-time visibility. This data visibility, through dashboards and deeper analytics like ML/AI, helps customers understand the reasons for production micro-stoppages, improve throughput without compromising quality, and understand trends that lead to sub-optimal quality parts being manufactured. Additionally, customers are looking for data visibility at enterprise, plant, line, machine, process, and product level which is not possible today with data being locked within these plants.\nManufacturing Challenges\nThe biggest manufacturing challenges are visibility into operational technology (OT) data from machines, such as Programmable Logic Controllers (PLCs) and Supervisory Control and Data Acquisition (SCADA) systems, for performing Root Cause Analysis (RCA) when a line or machine goes down, improving throughput without compromising quality, and understanding details of micro-stoppages of machinery in real time. Even advanced implementations like a Factory Information Systems (FIS) cannot provide visibility at a component level (e.g. a motor in a machine). The vast majority of industrial customers cannot do any analysis in real time even at the line or machine level, let alone at the component level.\nIT Challenges\nA manufacturing plant floor has a disparate set of PLCs and multiple device protocols (300+) which make it extremely challenging to talk to these plant floor \xe2\x80\x9cThings\xe2\x80\x9d and access data which can be leveraged for diagnostics and predictive analytics. Additionally, most customers and partners spend an inordinate amount of time building connectivity to these plant floor systems by linking their IT applications to OT systems which is highly unscalable due to multiple integration points without an IT framework driven approach. Additionally, they have to build technology components to scale solutions from multi-plant rollout, security, and multiple other viewpoints. A key blocker for Industry 4.0 initiatives is this device connectivity and integration challenge limiting scalability.\nThe Connected Factory Solution\nThe Connected Factory Solution helps customers get production solutions and proof of value (PoV) deployments running at their plants as quickly as possible. First, with this solution customers do not have to invest significantly in data collection that is considered undifferentiated heavy lifting. Second, customers are able to collect, organize, and store their industrial data in AWS in an operational data store for hot data, data that is accessed frequently, and an industrial date lake for warm/cold data, data that is infrequently accessed, as well as define virtual assets and asset hierarchies to provide structure and context to the data. Third, with this streamlined data collection process, customers are able to recognize immediate business value through visualization of their operational metrics from all sources of data. Fourth, they receive a deployment kit to be able to roll out the solution across all their factory lines and plants. Lastly, with this data organized in AWS, customers can accelerate their Industry 4.0 journey and achieve business outcomes like predictive maintenance, predictive quality, and remote asset management.\n  The Connected Factory Solution is available in two versions. Customers can select the Mobilize for Production Offering from AWS Professional Services or the Proof of Value Offering from the AWS GSI/SI Partner Network. The architecture for both versions is shown below.\nConnected Factory Option 1: Mobilize for Production Offering from AWS Professional Services\nBelow is the Connected Factory Solution Architecture for Real-Time Data that is delivered during the Mobilize for Production Offering from AWS Professional Services.\nConnected Factory Option 2: Proof of Value Offering from the AWS GSI/SI Partner Network\nThe IMC kit is designed to enable customers and partners to get data from their assets into the AWS Cloud in a simple, structured process so they can rapidly realize the business value that is derived from that data. Customers can convert existing asset hierarchy definitions (i.e. factory, lines, machines, tags, etc.) defined in partner edge applications like Inductive Automation\xe2\x80\x99s Ignition Server or PTC\xe2\x80\x99s KEPServerEX to the equivalent asset hierarchy within AWS IoT SiteWise. With asset hierarchies defined within AWS IoT SiteWise, customer data can be ingested continuously into the AWS Cloud and all the pertinent metadata is readily accessible for applications to help customers uncover business value, such as developing more efficient maintenance schedules from asset condition monitoring dashboards. Below is the reference architecture for the IMC kit, with Partner Connectivity Applications from Ignition and Kepware shown as 2 options for industrial protocol translation at the edge.\nWith multiple ingestion patterns from the edge to the cloud, customers and partners may choose the IMC Kit path that suits the needs of their specific use case. The first ingestion path is via the AWS IoT SiteWise Connector running in an AWS IoT Greengrass core (via OPC-UA) to AWS IoT SiteWise in the cloud. The second ingestion path is sending data directly from edge applications (i.e. Ignition Server) to AWS IoT Core via MQTT. The third ingestion path is sending data from the edge application (i.e. Ignition Server or KEPServerEX) to AWS IoT Greengrass where it can then be processed and filtered by customer-defined AWS Lambda functions, used for local machine learning model inference or consumed by a containerized Docker application. Raw and processed data can then be transmitted to the AWS Cloud through a number of different paths including AWS IoT Core, Amazon Kinesis Data Streams, or AWS IoT Analytics. No matter the data ingestion path from edge to cloud, the IMC kit supports the mapping of the edge application asset tag hierarchy into AWS IoT SiteWise so that the asset meta data is always available in the cloud for applications to use.\nConfiguration and deployment process\nThe IMC kit will include the hardware and software required to connect a customer\xe2\x80\x99s equipment to the cloud and visualize their data. The kit is designed to enable partners to see real business value from the IIoT solution and deploy a complete production solution that addresses all of their critical use cases. One example of a proof of value deployment a partner could deliver would be to help enable a customer to visualize near real-time operational metrics and perform Root Cause Analysis (RCA) of their assets when a line goes down. The kit software will be packaged into CloudFormation Templates that simplify the deployment process. There are two deployment modes: virtual (for evaluation and training) and physical (for real deployments). The CloudFormation Templates will provision the cloud resources and generate the scripts required to bootstrap physical edge devices. All documentation required to deploy this kit will be included with the CloudFormation Templates. The CloudFormation Stacks that will launch resources in AWS IoT SiteWise, AWS IoT Greengrass, AWS IoT Core, AWS Lambda, Amazon DynamoDB, AWS CloudFormation, Amazon EC2, Amazon S3, and Amazon QuickSight. Below is a map of how the IMC kit components relate to ISA 95 levels and what capabilities are enabled at each level.\nExtending the IMC Kit with Partner Solution Integrations\nThe IMC kit has been designed to enable partners to integrate with their own products and solutions. For example, an independent software vendor (ISV) that markets an industrial protocol adapter software application may want to integrate with the IMC kit to simplify the process of building IIoT solutions on top of AWS IoT services. The source code for the IMC kit is public so partners and customers can have access to the entire code repository and documentation. SI and GSI partners are trained to integrate their solution portfolio with the IMC kit, so that the industrial machine connectivity component of their architecture is simplified.\nIIoT Consulting and Deployment Expertise with the AWS Partner Ecosystem\nMore and more enterprise companies are modernizing their manufacturing operations with AWS. While every company is different, and some will feel comfortable to tackle these challenges on their own, most of the companies we work with are looking for help. Some companies lack deep knowledge with the AWS platform to design the right architecture, don\xe2\x80\x99t have enough resources to implement it, lack the technological breadth to integrate with all their enterprise systems, need help to create engaging user interfaces and experience, or are not staffed to operate their solution globally around the clock.\nThe Connected Factory Solution brings an ecosystem of partners across hardware, edge software, IIoT consulting, deployment, and industrial solutions that can help customers build and implement applications. Partners are important in this transformation \xe2\x80\x93 AWS continues to build an ecosystem of complimentary capabilities to accelerate business outcomes for customers. The ecosystem of partners shown in the image below has the expertise to deliver an end-to-end solution for customers to reduce the complexity of IIoT. These partners leverage the IMC kit so they can focus on differentiation instead of the infrastructure needed for their IIoT solutions. This minimizes risk, reduces development costs, and drives unique value differentiation.\nSummary\nThe Connected Factory Solution accelerates our customers\xe2\x80\x99 journey to optimize operations, reduce the infrastructure heavy lifting, and unlock the value trapped in their data. With this solution, customers get a consistent AWS IoT experience and are able to unlock data to modernize their manufacturing operations and accelerate Industry 4.0 success.\nYou can start using the Connected Factory Solution right away using the source code in the Github repository, or contact the AWS IoT team to learn more about this solution and how you can use it to transform your manufacturing operations.\n[1] https://www.mckinsey.com/business-functions/operations/our-insights/manufacturing-analytics-unleashes-productivity-and-profitability\n[2] https://media.vw.com/releases/1303'"
158,How to integrate NVIDIA DeepStream on Jetson Modules with AWS IoT Core and AWS IoT Greengrass,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/05/07/nvidia-1.png,https://aws.amazon.com/blogs/iot/how-to-integrate-nvidia-deepstream-on-jetson-modules-with-aws-iot-core-and-aws-iot-greengrass/,"b'AWS continually evolves our edge computing offerings to provide customers with the technology they need to extend AWS services to edge devices, such as consumer products or manufacturing equipment, and enable them to act intelligently. This helps customers avoid unnecessary cost and latency, and empower customers with the ability to manage edge devices securely and efficiently.\nYou can use AWS IoT Greengrass to extend a wide range of AWS cloud technologies to your edge devices so they can act locally on the data they generate, while still using the cloud for real-time data analytics, data storage and visualization, and training and fine-tuning machine learning models. In addition to providing technology solutions from the edge to the cloud, AWS works with a variety of device providers across the globe to provide customers with the right hardware to choose from for their particular use case.\nNVIDIA DeepStream SDK is an accelerated framework to build managed intelligent video analytics apps and services. The NVIDIA Jetson product family enables customers to extend server-class compute performance to devices operating at the edge. By using DeepStream in combination with TensorRT and CUDA on the Jetson platform , customers can build and deploy high throughput, low latency solutions.\nIn this post, we will demonstrate how you can integrate NVIDIA DeepStream on Jetson Modules with AWS IoT Services, so that you can start building innovative solutions with the AWS technologies and infrastructures to best meet your unique business requirements.\nSolution Overview\nThe objective of this post is to provide an overview on how to enable NVIDIA DeepStream Applications to publish MQTT messages to AWS IoT Core and AWS IoT Greengrass. The following diagram presents the architecture of the solution demonstrated in this post.\nThe following sections will walk through the following procedures to install and set up the DeepStream SDK\xe2\x80\x99s message broker API to publish MQTT messages to AWS IoT Core. (If you want to use your Jetson module as an AWS IoT Greengrass Aware Device, you can further refer to the last section \xe2\x80\x9cCompatible with AWS IoT Greengrass\xe2\x80\x9d for more details.)\nProcedure 1: Download AWS DeepStream adaptor\n[Optional] Procedure 2: Manually build the shared library\nProcedure 3: Provision DeepStream App with AWS IoT credentials\nProcedure 4: Transfer certificates to Jetson modules\nProcedure 5: Run Deepstream App\nAfter the solution walkthrough, we explain how to process IoT messages with AWS IoT Rules, and how to connect the AWS DeepStream adaptor to AWS IoT Greengrass.\nPre-requisites\nAWS account admin console access\nA Jetson module with DeepStream SDK installed and internet access\nGstreamer installation as described in the NVIDIA documentation.\nFor the convenience of this solution walkthrough, we demonstrate how to create an environment variable of the path where your DeepStream SDK is installed. Please replace <DeepStream SDK PATH> to the path of your DeepStream SDK on your Jetson module:\n$ export DEEPSTREAM_SDK_PATH=<DeepStream SDK PATH>\nTo verify your DeepStream installation, on your Jetson module, navigate to the ${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps/deepstream-app directory on the development kit, and enter this command on your terminal to run the reference application:\n$ deepstream-app -c <path_to_config_file>\nWhere <path_to_config_file> is the pathname of one of the reference application\xe2\x80\x99s configuration files, we recommend using ${DEEPSTREAM_SDK_PATH}/samples/configs/deepstream-app/source4_1080p_dec_infer-resnet_tracker_sgie_tiled_display_int8.txt\nIf the sample app has run successfully, then you can proceed to the deployment section in this article.  If you have trouble running this sample app, please refer to the DeepStream SDK Development Guide for more details on how to troubleshoot this step.\nSolution Deployment\nProcedure 1: Download AWS DeepStream adaptor\nTo download the AWS DeepStream adaptor\nIn your Jetson module, navigate to Downloads folder\nDownload or clone the AWS-managed GitHub repo.\nCopy the aws_protocol_adaptor sub-folder to ${DEEPSTREAM_SDK_PATH}/sources/libs.\n$ cd ~/Downloads\n$ git clone git@github.com:awslabs/aws-iot-core-integration-with-nvidia-deepstream.git\n$ cd aws-iot-core-integration-with-nvidia-deepstream\n$ cp -r aws_protocol_adaptor ${DEEPSTREAM_SDK_PATH}/sources/libs\n[Optional] Procedure 2: Manually build the shared library\nThe shared library (.so file) is pre-compiled and committed in the GitHub repo you cloned in Step 1 in the aws_protocol_adaptor/device_client directory. If you want to build and customize your shared library, you can follow procedure 2 to re-compile this shared library file with customized features such as optimized buffer size for incoming or outgoing MQTT messages, or TLS connection timeout values.\nTo manually build the shared library\nFirst create an empty directory for the AWS IoT device SDK library within the aws_protocol_adaptor library we cloned in procedure 1.\nNext, clone the AWS IoT device SDK in Embedded-C version 3 into this empty directory we created.\n$ mkdir ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/aws-iot-sdk\n$ cd {DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/aws-iot-sdk\n$ git clone https://github.com/aws/aws-iot-device-sdk-embedded-C.git .\nThis AWS IoT device SDK has an external dependency on Mbed TLS, so navigate to aws-iot-sdk/external_libs/. And clone the existing Mbed TLS repo in this folder:\n$ cd ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/aws-iot-sdk/external_libs/mbedTLS\n$ git clone https://github.com/ARMmbed/mbedtls.git\nNavigate to device_client folder, and compile the shared library:\n$ cd ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client\n$ make clean\n$ make\nIf you inspect this current folder, you should see the libnvds_aws_proto.so file just updated.\nProcedure 3: Provision DeepStream App with AWS IoT Core credentials\nTo provision DeepStream App with AWS IoT Core credentials\nNavigate to AWS web console, and select AWS IoT Core service.\nOn the left-side menu, choose Secure \xe2\x86\x92 Policies.\nOn the right upper corner, select Create.\nA window will appear to help you create a policy.\nWARNING: For this demonstration, we are going to explain how to create a policy to allow a thing to access every resource with any action in AWS IoT Core. In production, as a best practice, you should specify the resource and allowed actions to ensure you\xe2\x80\x99re granting least privilege permissions).\nFill in the required fields, and select Create.\nOn the left-side of the AWS IoT console choose Manage->Things. On the right upper corner, select Create to start the process of creating a thing on AWS IoT.\nSelect \xe2\x80\x9cCreate a single thing\xe2\x80\x9d in the next dialog box.\nIn the proceeding window, put ds_app as name, for the purposes of this demo. Leave the rest unchanged and select Next.\nSelect Create certificate.\nIn the page that appears, download all of the links for the certificates we just generated for this thing.\nFor root certificate, a link redirects you to a root certificate download page. You should download Amazon Root CA1, which can also be accessed here.\nSelect the Activate button on this page to activate the set of certificates that you just downloaded.\nFinally, select Attach Policy, and choose the policy named ds_app_policy you just created.\nProcedure 4: Transfer certificates to a Jetson module\nTo transfer certificates to a Jetson module\nNavigate to the path of your downloaded certs.\nYou should see four files in the following naming format.\nXXX-certificate.pem.crt\nXXX-private.pem.key\nXXX-public.pem.key\nAmazonRootCA1.pem\nYou can rename them as follows.\ncertificatePem.cert.pem\nprivateKey.private.key\npublicKey.public.key\nroot.ca.pem\nNow, make a cert folder on your Jetson module, and transfer these downloaded certificates and keys to your Jetson module. In this case, we are on the same network as our Jetson module, so we can use scp command to transfer the certificates:\n$ scp certificatePem.cert.pem privateKey.private.key publicKey.public.key root.ca.pem <YOUR_JETSON_IP>:${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/certs/\nAlternatively, you can upload them to a secure storage in the cloud to be downloaded by your Jetson module.\nNote: Once you have successfully transferred these certificates onto your Jetson module. We are going to put these certificates in the following directory for this demonstration, but you can use custom directories as long as you specify them in your cfg_aws.txt file:\n$ mkdir ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/certs\n$ mv <4 CERTS FILES> ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/certs\nOn your Jetson module, navigate to\n$ cd ${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/ \nEdit cfg_aws.txt :\nReplace <YOUR IOT HOST ADDRESS> with your AWS IoT Endpoint URL, which is located in the AWS IoT console \xe2\x86\x92 Settings, in the box labeled Endpoint.\nReplace <DEEPSTREAM SDK PATH> to the absolute path of your DeepStream SDK PATH.\nWARNING: Using relative path rather than absolute path would cause certificate parsing failure error. If this happens, you can come back to this file and edit certificate paths and restart your DeepStream application.\nReplace the values of both ThingName and ClientID with ds_app (to match the name of the thing we created above).\nProcedure 5: Run DeepStream App\nFinally, we are going to use the test apps developed by NVIDIA to verify our adaptor setup. We are going to run tests with both test4 and test5 in the NVIDIA DeepStream SDK sample app folder (${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps). The deepstream-test4 can be used to demonstrate adding custom objects as NVDS_EVENT_MSG_META user metadata with buffers for generating a custom payload to be published to AWS IoT Core. The deepstream-test5 can demonstrate how to use \xe2\x80\x9cnvmsgconv\xe2\x80\x9d and \xe2\x80\x9cnvmsgbroker\xe2\x80\x9d plugins in the pipeline, create NVDS_META_EVENT_MSG type of meta, and upload to AWS IoT Core. Both apps can help verify the installation and functionalities of this message broker.\nTo use Test App 4\nFirst, navigate to test4 in your DeepStream SDK at ${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps/deepstream-test4 on your Jetson module, and build DeepStream app test 4 using \xe2\x80\x9cmake\xe2\x80\x9d command.\n$ cd ${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps/deepstream-test4\n$ make\nThen, use the following command to run test4\n$ ./deepstream-test4-app -i ../../../../samples/streams/sample_720p.h264 -p ../../../libs/aws_protocol_adaptor/device_client/libnvds_aws_proto.so --conn-str=hello -c ../../../libs/aws_protocol_adaptor/device_client/cfg_aws.txt -t test --no-display\nNow navigate to the AWS IoT console, and on the menu bar on the left, select test\nInput test (or # to receive messages on all topics) in the subscription topic box, and select Subscribe to topic. You should see MQTT messages start to show up on the console after the app successfully runs:\nTo use Test App 5\nFirst, navigate to test5 in your DeepStream SDK at ${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps/deepstream-test5 on your Jetson module, and build DeepStream app test 5 using \xe2\x80\x9cmake\xe2\x80\x9d command.\n$cd ${DEEPSTREAM_SDK_PATH}/sources/apps/sample_apps/deepstream-test5\n$ make\nIn order to run deepstream-test5, open your configuration file in an editor you prefer:\n$cp configs/test5_config_file_src_infer.txt configs/test5_config_file_src_infer_aws.txt\n$ vim configs/test5_config_file_src_infer_aws.txt\nThen, modify msg-broker-proto-lib under your message broker sink (sink1), to point to:\n${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/libnvds_aws_proto.so\nAnd also modify msg-broker-config under the same sink to point to:\n${DEEPSTREAM_SDK_PATH}/sources/libs/aws_protocol_adaptor/device_client/cfg_aws.txt\nNext, modify the topic to a topic name that you choose, and modify the first sink to a fake sink.\nThen, you can use the following command to run test5:\n$ ./deepstream-test5-app -c configs/test5_config_file_src_infer_aws.txt \nNow, navigate to AWS IoT console, and on the menu bar on the left, select Test\nInput test (or # to receive messages on all topics) in the subscription topic box\nChoose Subscribe to topic. You should see MQTT messages start to show up on this console after the app successfully runs:\nThis concludes the procedure for installing and setting up the DeepStream SDK\xe2\x80\x99s message broker API to publish MQTT messages to AWS IoT Core or AWS IoT Greengrass. Next, we will explain how you can process IoT messages with AWS IoT Rules, and how to connect the AWS DeepStream adaptor to AWS IoT Greengrass.\nProcessing IoT messages with AWS IoT Rule\nOnce you see messages coming into AWS IoT Core, there are a lot of options to further process them or store them on the AWS Cloud. One simple example would be to use AWS IoT Rules to push these messages to a customized AWS Lambda function, which parses the messages and puts them in Amazon DynamoDB. You may find the following documents helpful in setting up this IoT rule to storage pipeline:\nCreating a Rule with an AWS Lambda Action \nReading and Writing A Single Item in DynamoDB \nImplementing a Serverless AWS IoT Backend with AWS Lambda and Amazon DynamoDB\nThe following documents may further assist you to build a production-ready AWS Data Pipeline:\nAWS IoT Analytics Console Quick Start Guide\nIntegrating IoT data with your data lake with new AWS IoT Analytics features\nReal-Time IoT Device Monitoring with Kinesis Data Analytics\nWriting to Kinesis Data Firehose Using AWS IoT\nCompatible with AWS IoT Greengrass\nThis AWS DeepStream adaptor also supports connections to AWS IoT Greengrass. You can modify <YOUR IOT HOST ADDRESS> in cfg_aws.txt to your Greengrass Endpoint/IP address.\nThere are several options to find out the Greengrass Endpoint/IP address. If you know the IP address of your Greengrass device or run \xe2\x80\x9cifconfig\xe2\x80\x9d on your Greengrass device to find it out, you can directly put that as <YOUR IOT HOST ADDRESS>. AWS IoT Greengrass also provides a Discovery API, which enables devices to retrieve the information required to connect to the AWS IoT Greengrass core that is in the same Greengrass group as the device.\nFor further information on enabling your device to connect to AWS IoT Greengrass, please follow module 4 in AWS IoT Greengrass developer guide.\n'"
159,How to Bridge Mosquitto MQTT Broker to AWS IoT,b'Adrian Buzescu',2020-12-11T05:06:06+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/05/04/Schema-How-to-bridge-Mosquitto-to-AWS-IoT-Core-1024x381.png,https://aws.amazon.com/blogs/iot/how-to-bridge-mosquitto-mqtt-broker-to-aws-iot/,"b'UPDATE: The original blog post written on August 18th 2016 has been updated to this current version with the help of the author Michael Garcia (Principal Solutions Architect at AWS) and Anish Yadav (Cloud Support Associate at AWS).\nWhether it is in the context of industrial IoT or in connected homes, gateways are present in most architectural discussions. Today, we will show you how to implement the Mosquitto broker \xe2\x80\x98Bridge\xe2\x80\x99 capability to setup bi-directional exchange of data with AWS IoT Core through MQTT messages. This will enable your devices to communicate locally with the Mosquitto broker and with AWS IoT Core to benefit from the power of the AWS Cloud.\nWhy Bridge your MQTT Broker to AWS IoT\nIf you have legacy IoT deployments, you might already have devices connected to an MQTT broker such as Mosquitto. In that scenario, your MQTT broker can be very close to where your sensors are deployed (local MQTT broker) or in a remote location like the Cloud.\nIf you plan to migrate to AWS IoT Core or wish to test it in order to benefit from the scalability, agility, security and high availability of the AWS Cloud, bridging your legacy MQTT broker to AWS IoT core could represent an easy transient solution that you can deploy quickly. In this article, we will implement a bridge using the Mosquitto broker such as illustrated in the diagram below.\n  How to Install Mosquitto MQTT Broker\nTypically, you should install this on what you view as your local gateway which is the device that will be the link between your local devices and other local devices or to the AWS Cloud. Mosquitto supports a wide range of platforms including many distributions of Linux. Therefore, you can run it on devices as well as on a full-fledged server/virtual machine. You can go to Mosquitto download page for instructions.\nFor the sake of convenience and reproducibility, in this blog we will install the Mosquitto broker on an Amazon EC2 Linux instance which is the equivalent to having a local gateway running a Linux distribution.\nIf you are not planning on using an Amazon EC2 Instance you can skip to the section \xe2\x80\x9cHow to configure the bridge to AWS IoT Core\xe2\x80\x9d\nLaunching and Configuring the EC2 Instance\nBefore launching an Amazon EC2 Ubuntu instance to host the Mosquitto broker, we are going to create an IAM Role so we\xe2\x80\x99ll be able to use the CLI from the Amazon EC2 instance to generate AWS IoT credentials for the bridge.\nGo to the AWS Web Console and access the IAM service (Fig. 1)\n  Click on Roles. Then, click on Create role (Fig. 2)\n  Select EC2 and click on Next: Permissions (Fig. 3)\n  Filter with the value AWSIoTConfigAccess (Fig. 4). Then select the policy AWSIoTConfigAccess and click on Next: Tags. Skip the next screen by clicking on Next: Review.\n  Enter AWS_IoT_Config_Access as the Role name and enter a Role description. Review the role and click on Create role (Fig. 5)\n  Now that the Role has been created you can go to Amazon EC2. Choose a region, in this article I am using N. Virginia (us-east-1). Then click on Launch Instance and use the filter with the value \xe2\x80\x9cubuntu\xe2\x80\x9d. Select the Ubuntu Server 18.04 LTS x86 (Fig. 6)\n  Select the t2.micro instance type (Fig. 7).\n  Click on Next: Configure Instance Details. In the IAM Role dropdown, select AWS_IoT_Config_Access (Fig. 8).\nMake sure you use the default VPC and that the Auto-assign Public IP is Enable to get a public IP automatically. If you wish to use another VPC, make sure the subnet you choose will enable you to remotely connect to your Amazon EC2 instance. Then, click on Next: Add Storage.\n  Leave everything as is and click on Next: Tag Instance. You may assign a tag to your instance. Click on Next: Configure Security Groups. Create a new security group as described in the screenshot (Fig. 9).\n  Review and launch the EC2 instance. Make sure to select an existing Key Pair or to create a new one in order to connect to the Amazon EC2 instance later on. Once the Amazon EC2 instance is running, click on \xe2\x80\x9cConnect\xe2\x80\x9d and follow instructions to establish a connection through a terminal. Once logged into the Amazon EC2 instance type the following commands:\n#Update the list of repositories with one containing the latest version of #Mosquitto and update the package lists\nsudo apt-add-repository ppa:mosquitto-dev/mosquitto-ppa\nsudo apt-get update\n\n#Install the Mosquitto broker, Mosquitto clients and the aws cli\nsudo apt-get install mosquitto\nsudo apt-get install mosquitto-clients\nsudo apt install awscli\nBash\nHow to Configure the Bridge to AWS IoT Core\nNow that we have installed the Mosquitto broker onto our Amazon EC2 instance (or local gateway), we will need to configure the bridge so that the Mosquitto broker can create a bi-directional connection to AWS IoT Core. We will first use the AWS CLI to create the necessary resources on AWS IoT side.\nEnter the following commands in your terminal:\n#Configure the AWS CLI with your AWS region, leave access/private keys blank\naws configure\n\n#Create an IAM policy for the bridge\naws iot create-policy --policy-name bridgeMQTT --policy-document \'{""Version"": ""2012-10-17"",""Statement"": [{""Effect"": ""Allow"",""Action"": ""iot:*"",""Resource"": ""*""}]}\'\n\n#Place yourself in Mosquitto directory and download the Amazon Root CA #certificate\ncd /etc/mosquitto/certs/\nsudo wget https://www.amazontrust.com/repository/AmazonRootCA1.pem -O rootCA.pem\n\n#Create certificates and keys. Make a note of the certificate ARN as it will be #needed to configure the IoT Policy.\nsudo aws iot create-keys-and-certificate --set-as-active --certificate-pem-outfile cert.crt --private-key-outfile private.key --public-key-outfile public.key --region us-east-1\n\n#Copy the ARN of the certificate returned by the command line in the form of #arn:aws:iot:us-east-1:0123456789:cert/xyzxyz and replace it in the following #command line in order to attach the IoT policy to your certificate\naws iot attach-principal-policy --policy-name bridgeMQTT --principal <certificate ARN>\n\n#Add read permissions to the private key and the public certificate\nsudo chmod 644 private.key\nsudo chmod 644 cert.crt\nBash\nWe now have a client certificate for our bridge, this certificate is associated with an IoT policy. This IoT policy will give permissions to the bridge to connect to AWS IoT Core and publish/subscribe to any topic (this policy must be further restricted to match your usage appropriately). The last step is to create the configuration file with our specific configuration for the Mosquitto Broker bridge.\n#Retrieve the value of the AWS IoT Core ATS endpoint for your AWS Region using #the cli and make a note of it.\naws iot describe-endpoint --endpoint-type iot:Data-ATS\n\n#Create the configuration file\nsudo nano /etc/mosquitto/conf.d/bridge.conf\nBash\nFirst, edit the following by replacing the value of the \xe2\x80\x98address\xe2\x80\x99 with the value of your AWS IoT Core ATS endpoint. Second, copy the content and paste it in the nano editor. Finally, save the file on the Amazon EC2 instance by using the following key combinations \xe2\x80\x98ctrl + o\xe2\x80\x99, \xe2\x80\x98enter\xe2\x80\x99, then \xe2\x80\x98ctrl + x\xe2\x80\x99.\n# ============================================================\n# Bridge to AWS IOT\n# ============================================================\n\nconnection awsiot\n\n#<Paste your AWS IoT Core ATS endpoint retrieved from the AWS CLI in the form of xxxxxxxxxxxxxxx-ats.iot.<region>.amazonaws.com:8883\n\naddress xxxxxxxxxxxxxxx-ats.iot.<region>.amazonaws.com:8883\n\n# Specifying which topics are bridged and in what fashion\ntopic awsiot_to_localgateway in 1\ntopic localgateway_to_awsiot out 1\ntopic both_directions both 1\n\n# Setting protocol version explicitly\nbridge_protocol_version mqttv311\nbridge_insecure false\n\n# Bridge connection name and MQTT client Id, enabling the connection automatically when the broker starts.\ncleansession true\nclientid bridgeawsiot\nstart_type automatic\nnotifications false\nlog_type all\n\n# ============================================================\n# Certificate based SSL/TLS support\n# ============================================================\n\n#Path to the rootCA\nbridge_cafile /etc/mosquitto/certs/rootCA.pem\n\n# Path to the PEM encoded client certificate\nbridge_certfile /etc/mosquitto/certs/cert.crt\n\n# Path to the PEM encoded client private key\nbridge_keyfile /etc/mosquitto/certs/private.key\n\n#END of bridge.conf\nNow we can restart the Mosquitto broker to load this new configuration:\n#Restart the Mosquitto Mosquitto broker\nsudo service mosquitto restart\nBash\nMaking Sure Everything is Working\nThe Mosquitto broker has now restarted and has already connected to AWS IoT Core in the background. In our configuration we have bridged 3 topics:\nawsiot_to_localgateway: any message received by AWS IoT Core from this topic will be forwarded to the local gateway.\nlocalgateway_to_awsiot: any message received by the local gateway will be forwarded to AWS IoT Core.\nboth_directions: any message received on this topic by one MQTT broker will be forwarded to the other MQTT broker.\nWe will check that the topic localgateway_to_awsiot is functioning properly, meaning that messages will be forwarded from the local Mosquitto broker to AWS IoT Core.\nGo to the Test section of the AWS IoT Console.\nEnter localgateway_to_awsiot as the Subscription topic and click on Subscribe to topic (Fig. 10)\n  Now that we are listening for incoming messages on the AWS IoT Core side, we will publish an MQTT message from a local client inside the Amazon EC2 instance to the Mosquitto broker inside the Amazon EC2 instance to test if the bridge is running properly. If everything runs properly, the message will be emitted from the local client to the Amazon EC2 instance Mosquitto broker and forwarded to AWS IoT Core.\n#Publish a local message to the Mosquitto broker running on the Amazon EC2 #instance from the terminal\nmosquitto_pub -h localhost -p 1883 -q 1 -d -t localgateway_to_awsiot  -i localClientID -m ""{\\""message\\"": \\""helloFromLocalGateway\\""}""\nBash\nYou should now get this message on your screen, delivered to AWS IoT Core thanks to the configured bridge running on your Amazon EC2 instance (Fig. 11).\nAs an exercice, you can use the following commands to test the other configured bridged topics to test sending messages both ways!\n# Publish a message locally on the topic both_directions and receive the message on AWS IoT Core\nmosquitto_pub -h localhost -p 1883 -q 1 -d -t both_directions -i yourClientID -m ""{\\""message\\"": \\""helloFromLocalGateway\\""}""\n\n# Subscribe to the both_directions topic to receive message sent by AWS IoT #Core on that topic\nmosquitto_sub -h localhost -p 1883 -t both_directions\nBash\nIf you are done testing with an Amazon EC2 Instance you can replicate this setup with the device you are planning to use as a gateway which is hosting the Mosquitto broker!\nNext Steps\nNow that your bridge between your local Mosquitto broker and AWS IoT Core is up and running you might want to fine tune some parameters of the bridge connection. Please consult the Bridge section of the official Mosquitto documentation if you need additional details.\nAlso, bear in mind the limitations of this approach if you are considering production use. The bridge connection is using only one connection to exchange messages to AWS IoT Core which is subject to the AWS IoT Core Broker limits. Furthermore, the Mosquitto broker represents a single point of failure in this architecture. Due to those shortcomings in terms of scalability and high availability, we recommend you reach out to the AWS team in order to evaluate other solutions if your use case requires it. Alternatively, you could connect your devices directly to AWS IoT Core using FreeRTOS, our IoT Device SDKs, or use AWS IoT Greengrass.\nDon\xe2\x80\x99t forget you can use Machine Learning, Data lakes and Analytics and other AWS IoT Services to create your IoT application. To learn more do not hesitate to read our IoT blog, to browse our library of patterns, or to register for free online training.'"
160,How to automate onboarding of IoT devices to AWS IoT Core at scale with Fleet Provisioning,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/04/30/fleet-provisioning-1.jpg,https://aws.amazon.com/blogs/iot/how-to-automate-onboarding-of-iot-devices-to-aws-iot-core-at-scale-with-fleet-provisioning/,"b'Customers use AWS IoT to analyze the data generated by their IoT devices to quickly gain meaningful insights about their business. This helps them solve a variety of problems, such as identifying required improvements to their manufacturing processes, predicting device failures, or quickly diagnosing and troubleshooting device issues for their customers.  However, before IoT devices can connect to the cloud and do useful work, devices need to be provisioned. IoT device provisioning refers to the process of configuring devices with unique identities (e.g. X.509 certificate and a private key), registering these identities with the AWS IoT endpoint, and associating required permissions (e.g. an IoT Policy) so that devices can securely connect and operate with AWS IoT and other cloud-based applications.\nToday, customers use AWS IoT Core features like Just-In-Time-Registration (JITR) and Just-In-Time-Provisioning (JITP) to automate and scale the process of registering device identities with the AWS Cloud and associating the required AWS IoT permissions. But, customers are still responsible for securely generating and flashing unique identities onto devices. For many customers, particularly for original equipment manufacturers (OEMs) manufacturing large numbers of devices, this process remains manual and time-consuming.\nNow, with AWS IoT Core Fleet Provisioning, customers can securely automate the end-to-end device onboarding process.  More importantly, key attributes can now be sent from the device and validated in an AWS Lambda function for additional integrity. Fleet Provisioning securely delivers a unique digital identity to each device, validates the device payload via a Lambda function, registers the identity in a customers\xe2\x80\x99 AWS account, and sets up the devices with all required permissions and registry metadata (e.g. Things, Thing Groups). All of this happens automatically upon the devices\xe2\x80\x99 first connection to AWS IoT Core, or whenever a device needs to receive new credentials or updated configuration, saving valuable time and engineering resources for customers.\nThere are 2 primary provisioning methods available with Fleet Provisioning:\nProvisioning by Claim, often referred to as a bootstrap certificate approach.\nProvisioning by a trusted user (e.g. a Mobile/Web App user): this process is very similar to the provisioning by claim process.\nIn this blog, we demonstrate how to use the Provisioning by Claim approach in detail and explain when you should use this approach. At the end of this post, we will describe the differences when using the Provisioning by a Trusted User approach. So, let\xe2\x80\x99s get started.\nWhen to use the Provisioning by Claim workflow\nProvisioning by Claim is designed to target scenarios wherein devices would be manufactured with a shared bootstrap certificate on them. These bootstrap certificates have limited IoT permissions that only allow the devices to do the following: 1/establish first connection with AWS IoT Core, 2/ prove their identity, and 3/ request a fully functional identity with the necessary IoT permissions that devices can use for subsequent communication with AWS IoT Core. This shared bootstrap certificate could be placed on devices at the factory or at a staging facility while flashing the initial software onto devices. If the device already has its own private key on board, it can send a certificate signing request (CSR) along with the bootstrap certificate to be signed by AWS IoT Core.\nIn addition to validating the bootstrap certificate presented by devices, Fleet Provisioning also provides Lambda-based provisioning hooks that enable appropriate validation for pertinent device attributes. Examples of device attributes could include a serial number, MAC ID, device location, etc. The Lambda functions should be leveraged in the provisioning transaction to automate the approval or denial of a particular device\xe2\x80\x99s provision status based on the custom attributes sent during this process.\nSolution Overview: Provisioning by Claim (with Bootstrap Cert)\nThe Provisioning by Claim workflow is showcased in the previous image (Fig. 1). When the device is powered on and has network access, the following takes place:\nThe device connects to AWS IoT Core over a secure TLS 1.2 connection, using a bootstrapped certificate. If the device has a CSR, then that would be presented along with bootstrap certificate.\nThe certificate has a highly restrictive policy associated, providing access only to IoT topics associated with the Fleet Provisioning process.\nThe Fleet Provisioning service responds with the official certificate/private key payload along with a \xe2\x80\x9cproof of ownership\xe2\x80\x9d token to securely separate the transaction. This token is used in a subsequent call to activate the certificate. If a CSR was presented, then the certificate would be generated from that CSR.\nThe device makes an MQTT request to AWS IoT Core, presenting the ownership token, name of the Fleet Provisioning template created by the account owner, and (optionally) device attributes for provisioning validation. We recommend that customers take advantage of the Lambda-based provisioning hooks to enable additional validation, such as validating the device\xe2\x80\x99s serial number or MAC ID, against a pre-approved list.\nThe Fleet Provisioning template is acted upon, and the provisioning transaction takes place and returns a result. Commonly: Validate device attributes in Lambda, activate certificate, attach production policy, and create Thing/groups (optional).\nBased on the sum of the provisioning transaction, a result is returned on the status of the new certificate. If successful, the bootstrap cert is deprecated/rotated for the \xe2\x80\x9cproduction\xe2\x80\x9d certificate. If the transaction is denied, an \xe2\x80\x9caccess denied\xe2\x80\x9d error will be returned to the device.\nSolution Walkthrough: Setting up the \xe2\x80\x9cProvisioning by Claim\xe2\x80\x9d workflow\nIn the next section, we\xe2\x80\x99ll walk through the steps necessary to set up the provisioning by claim workflow described in the previous section. The instructions take place in the AWS Management Console. There are 3 main procedures for setting up the workflow:\nProcedure-1: Create the Provisioning Template\nProcedure-2: Define your provisioning claim (aka bootstrap certificate)\nProcedure-3: Configure the Device Side Client Software\nOnce this workflow is set up, device onboarding happens automatically whenever devices are powered-on and provided network access.\nProcedure 1 \xe2\x80\x93 Create a Provisioning Template\nA provisioning template details the instructions that must be carried out when a device is to be provisioned. Provisioning templates can include things like which policy to associate with a particular certificate, what to name a Thing in the device registry, whether or not to activate the associated cert, and more. Visit the Fleet Provisioning Templates documentation to learn more.\nTo create your provisioning template\nOpen the AWS Management Console\nIn the navigation pane, under AWS IoT Core, select Onboard, and then select Fleet Provisioning Templates.\nNote: The first visit may include an introduction, where you\xe2\x80\x99ll navigate to Onboard Many devices/Create Templates.\n Select Create.\nProvide a name for your template (the template name will be referenced when calling from the device side).\nProvide/Create a provisioning role.\nNote: This role gives permission to AWS IoT Core to create/update resources in your AWS IoT account on your behalf.\n[Highly Recommended] select a Lambda function to hook-in to your provisioning transaction.\nAs mentioned in the introduction, you can define a Lambda function to process parameter payload from your device. You can take that payload and analyze it against white lists, internal subscription databases, or any other internal resources to approve or deny a provisioning request which is critical to maintaining proper security best practices.\nThe attributes sent from the device in the \xe2\x80\x9cprovisioning-templates\xe2\x80\x9d call can be pulled from the event [\xe2\x80\x9cparameters\xe2\x80\x9d] tag in Lambda.\nAt a minimum, your Lambda must return a Boolean \xe2\x80\x9callowProvisioning\xe2\x80\x9d (True/False) to return the provisioning pipeline.\nThe following is an example of a basic provisioning hook Lambda function:\nimport json\nprovision_response = {\'allowProvisioning\': False}\ndef isWhitelisted(serial_number):\n    #check serial against database of approved serials\n    ...\n    \ndef lambda_handler(event, context):\n    \n    # DISPLAY ALL ATTRIBUTES SENT FROM DEVICE\n    print(""Received event: "" + json.dumps(event, indent=2))\n    \n    # Assume Device has sent a device_serial attribute\n    device_serial = event[""parameters""][""SerialNumber""]\n    \n    # Check serial against an isWhitelisted() function\n    if isWhitelisted(device_serial):\n        provision_response[""allowProvisioning""] = True\n        \n    return provision_response\nNow, let\xe2\x80\x99s finalize the template creation with \xe2\x80\x9coptional\xe2\x80\x9d settings.\nSelect the desired check boxes if you want your provisioned devices to be placed in the AWS IoT Registry and/or included with additional key/value attributes.\nSelect Next\nNext, we select the policy that will be associated with devices that are fully provisioned. Policies manage the access your devices will have to the AWS IoT Core endpoint for things like connecting, subscribing and receiving on specified topics. Visit the AWS IoT Policy documentation for more information on how to create a policy.\nTo define the AWS IoT Policy\nCreate or select an existing IoT Policy to be associated to devices after they\xe2\x80\x99ve been qualified to be fully provisioned.\nFor example, the following policy grants devices permission to connect to AWS IoT Core with a client ID that matches the thing name and to subscribe to and receive messages on the my/topic topic:\n{""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {""Effect"": ""Allow"",\n            ""Action"": [\n                ""iot:Connect""\n            ],\n            ""Resource"": [""arn:aws:iot:REGION:123456789012:client/${iot:Connection.Thing.ThingName}""]\n        },\n        {""Effect"": ""Allow"",\n            ""Action"": [\n                ""iot:Subscribe""\n            ],\n            ""Resource"": [\n                ""arn:aws:iot:REGION:123456789012:topicfilter/my/topic""\n            ]\n        },\n        {""Effect"": ""Allow"",\n            ""Action"": [\n                ""iot:Receive""\n            ],\n            ""Resource"": [\n                ""arn:aws:iot:REGION:123456789012:topic/my/topic""\n            ]\n        }\n    ]\n}\nSelect Next\nNow you have the opportunity to define additional management structures for \xe2\x80\x9cthings\xe2\x80\x9d created in the registry by the template.\nTo define settings for the AWS IoT Thing Registry\nSet a prefix for all things created in the registry.\nOptional, but recommended: Apply a thing type for this template.\nOptional: Select a group to place all things provisioned through the template.\nOptional: Add any additional attributes you may want included in the registry.\nSelect Next\nIf you selected the option to send configuration information to devise that are provisioned,\nAdd attributes and default values (optional).\nSelect Create template\nProcedure 2 \xe2\x80\x93 Define your provisioning claim (aka bootstrap certificate)\nIn this section, we will nominate/create the certificate which is used as the common bootstrap certificate.\nTo define your provisioning claim\nSelect a certificate formerly created by AWS IoT Core or use a certificate signed by your own certificate authority (CA).\nIf you have not yet created a certificate, Shift+click on \xe2\x80\x9cGenerate a certificate\xe2\x80\x9d to walk through the following certificate creation workflow.\nSelect Create to start the wizard, and then select Create certificate to generate the certs.\nDownload the cert payload including the public and private keys, as well as the root CA.\nMake sure to Activate the certificate.\nSelect Done (No need to Attach a policy).\nClose the newly opened window, and refresh the page listing available certificates.\nWith the desired certificate selected, choose Attach policy to attach a restrictive policy to the certificate. As explained earlier, this restrictive policy will only allow devices possessing bootstrap certificates to establish first connection with AWS IoT Core, prove their identity, and request a fully functional identity with necessary IoT permissions.\nChoose Enable template and then select Close.\nProcedure 3 \xe2\x80\x93 Configure the Device Side Client Software\nThe final procedure will walk you through how to configure the device-side and client-side software. First, if you generated a bootstrap certificate in Procedure 2, ensure the certificate, root.ca and private key have been downloaded from the AWS IoT Console and stored on the device in a secure location.\nOnce you have ensured the bootstrap credentials are stored securely on board, the device must make an initial connection to AWS IoT Core. It must also define a callback to capture responses from the provisioning service.\nThe following example demonstrates how to connect your device to AWS IoT Core. While other AWS IoT SDK\xe2\x80\x99s are supported, the sample below is shown with the AWS IoT Python SDK. A complete Python reference client can be found here: aws-iot-fleet-provisioning.\n// Don\'t forget to define a callback method to capture return data.\n// Note: In this example, on_message_callback must also be defined\n// as a method in the class near the top.\nself.primary_MQTTClient.onMessage = self.on_message_callback\ndef on_message_callback(self, message):\n    # inspect message.payload\n// Example standard python IoT Core connect configuration.\nself.primary_MQTTClient.configureEndpoint(self.iot_endpoint, 8883)\nself.primary_MQTTClient.configureCredentials(""{}/{}"".format(self.secure_cert_path,\n       self.root_cert), ""{}/{}"".format(self.secure_cert_path, self.secure_key),\n       ""{}/{}"".format(self.secure_cert_path, self.claim_cert))\n self.primary_MQTTClient.configureOfflinePublishQueueing(-1)  \n self.primary_MQTTClient.configureDrainingFrequency(2)  \n self.primary_MQTTClient.configureConnectDisconnectTimeout(10)  \n self.primary_MQTTClient.configureMQTTOperationTimeout(3)      \n self.logger.info(\'##### CONNECTING WITH PROVISIONING CLAIM CERT #####\')\n        \n self.primary_MQTTClient.connect()\nOnce your device is successfully connected to AWS IoT Core, your application must publish to a reserved AWS IoT provisioning topic responsible for generating the credential payload.\nTo make the initial publish to obtain cert payload\n# Make a publish call to topic to get official certs\nself.primary_MQTTClient.publish(""$aws/certificates/create/json"", ""{}"", 0)\nThe response will return the certificate, private key, and an ownership token and invoke the callback function. The certificate and key should be securely persisted from this response. The additional ownership token should be published to the second provisioning topic, along with the name of the intended provisioning template, and (optionally) any desired device parameters as illustrated in the following code example:\n//Pack up the token, and any relevant device attributes.\nregister_template = {""certificateOwnershipToken"": token,\n    ""parameters"": {""serialNumber"": serial, ""customAttribute"": someAttribute}}\n#Publish payload to second provisioning topic and include desired template name.\nself.primary_MQTTClient.publish(\n     ""$aws/provisioning-templates/{TEMPLATE_NAME}/provision/json"", json.dumps(register_template), 0)\nThe service responds based on the result of the actions defined in the provisioning template.\nSome devices are capable of generating a key pair using secure hardware-based solutions. In those cases, they must generate a certificate out of the key pair to connect with AWS IoT Core. This can be accomplished by generating a CSR and submitting that CSR to be signed by AWS IoT Core.  The initial publish to AWS IoT Core to obtain certificates would be modified as shown in the snippet below:\nself.primary_MQTTClient.publish(""$aws/certificates/create-from-csr/json"", \n      ""{ ""certificateSigningRequest"": ""CSR_TEXT_HERE""}"", 0)\nVisit the AWS IoT API Reference documentation for more detail on how to create certificates from CSR.\nThis concludes the procedures required to set up the \xe2\x80\x9cProvisioning by Claim\xe2\x80\x9d workflow. Next, we will explain the differences when setting up AWS IoT Core Fleet Provisioning using the \xe2\x80\x9cTrusted User\xe2\x80\x9d method.\nSetting up Fleet Provisioning via a \xe2\x80\x9cTrusted User\xe2\x80\x9d\nNotably, there is an additional feature of fleet management that enables a \xe2\x80\x9ctrusted user\xe2\x80\x9d to provision on behalf of a device. This is a common use case when provisioning a device via a mobile app user, for example, for consumer Wi-Fi devices that are shipped with a companion mobile app for the end user to configure the device using Wi-Fi. The flow is very similar to provisioning with a bootstrap certificate except that a user performs an initial call to AWS IoT Core from a trusted intermediary (like a mobile app) to obtain a bootstrap certificate. This certificate is then passed to the mobile device which then follows the same flow outlined in procedures 1-3 for bootstrapped devices. For more information, visit the AWS IoT Fleet Provisioning with a Trusted User documentation.\n'"
161,Connecting disparate industrial systems to AWS using Ignition Edge,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/connecting-disparate-industrial-systems-to-aws-using-ignition-edge.png,https://aws.amazon.com/blogs/iot/connecting-disparate-industrial-systems-to-aws-using-ignition-edge/,"b'Enabling operational data connectivity to AWS IoT Greengrass seamlessly extends AWS to the edge to provide tools to act locally on the OT data, while still using the cloud for management, analytics, and durable storage. With AWS IoT Greengrass and the Cirrus Link MQTT Transmission module on the Ignition platform from Inductive Automation, industrial data from PLCs, RTUs and sensors can utilize AWS Lambda functions, execute predictions based on machine learning models, keep device data in sync, and communicate with other devices. Here is the solution architecture.\nConfiguring Inductive Automation\xe2\x80\x99s Ignition platform to communicate with Amazon Web Service\xe2\x80\x99s AWS IoT Greengrass and AWS IoT Core is easy using Cirrus Link\xe2\x80\x99s MQTT Transmission module. This tutorial will show how this can be done step by step.\nPrerequisites\no Establish an AWS account\nSet up page: https://aws.amazon.com/\nInstructions to create an account are here: https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/\no Download and Install Ignition Edge onto a laptop, development machine, or embedded gateway (Windows, Linux, macOS supported)\nDownload page: https://inductiveautomation.com/downloads/ignition/\nInstallation instructions are here: https://docs.inductiveautomation.com/display/DOC80/Installing+and+Upgrading+Ignition\no Download and install the MQTT Transmission module from Cirrus Link into the Ignition platform installed in the step above. In case there are no compatible modules available for the selected Ignition version, adjust your selection for more results.\nDownload page: https://inductiveautomation.com/downloads/third-party-modules/\nInstallation instructions are here: https://docs.inductiveautomation.com/display/DOC80/Installing+and+Upgrading+Ignition\no Install AWS IoT Greengrass on a platform of your choice by following the following two tutorials from AWS. Make sure the platform you choose here is on a network accessible by the Ignition platform you installed above. Also make sure this platform has access to the Internet to be able to get to AWS IoT.\nhttps://docs.aws.amazon.com/greengrass/latest/developerguide/module1.html\nhttps://docs.aws.amazon.com/greengrass/latest/developerguide/module2.html\no   Note that you can download Ignition Edge & AWS IoT Greengrass on the same gateway device thus eliminating the need to have multiple gateways in your factory.\nProcedure\nWith an AWS account already established, log into the AWS console and browse to the AWS IoT Greengrass landing page and then click \xe2\x80\x98Groups\xe2\x80\x99 on the left-side navigation pane.  You should see the group \xe2\x80\x98MyFirstGroup\xe2\x80\x99 that was created in the AWS prerequisites above. If you do not see MyFirstGroup in the Greengrass Groups, revisit the prerequisite that covers AWS IoT Greengrass installation and setup above.\nClick on MyFirstGroup and then Cores on the left.  You should see the following.\nSelect the MyFirstGroup_Core and then select Connectivity.  You should see something similar to what is shown below.  Note the IP address for later use in the MQTT Transmission configuration.  If you do not see any endpoint configuration redeploy your group from the AWS IoT Greengrass console. This tutorial shows how that can be done: https://docs.aws.amazon.com/greengrass/latest/developerguide/configs-core.html\nNow we need to create the \xe2\x80\x98device\xe2\x80\x99 that represents the Ignition system in the AWS IoT Greengrass configuration.  To do so, browse to your group and then select \xe2\x80\x98Devices\xe2\x80\x99 on the left as shown below.\nNow click \xe2\x80\x98Add your first Device\xe2\x80\x99.  This will show the following.\nSimply click the \xe2\x80\x98Create New Device\xe2\x80\x99 button. This will allow you to create a name for your device.  We will use the name \xe2\x80\x98MyIgnition\xe2\x80\x99 and click \xe2\x80\x98Next\xe2\x80\x99 as shown below.\nNow click the \xe2\x80\x98Use Defaults\xe2\x80\x99 for the security setup in the lower right corner as shown below.\n  Finally, you will be given the certificate and keys associated with the newly created device.  Make sure to download them here as they will not be available again after this point.  These will be used in the configuration for MQTT Transmission.  Once downloaded, click the \xe2\x80\x98Finish\xe2\x80\x99 button\nWhen complete, you should see your device in the Devices section of the Greengrass Group as shown below.\nNow we will create a subscription to allow messages to be sent between AWS IoT Greengrass and AWS IoT Core.  Begin by browsing to your Greengrass group and then \xe2\x80\x98Subscriptions\xe2\x80\x99 as shown below.\nClick \xe2\x80\x98Add your first Subscription\xe2\x80\x99.  We will create two subscriptions.  The first will source data from \xe2\x80\x98IoT Cloud\xe2\x80\x99 and send it to the target \xe2\x80\x98MyIgnition\xe2\x80\x99.  This is shown below.\nSet the topic filter to \xe2\x80\x98#\xe2\x80\x99 as shown below.\nNow create a second subscription with a source of \xe2\x80\x98MyIgnition\xe2\x80\x99, a target of \xe2\x80\x98IoT Cloud\xe2\x80\x99, and a filter of \xe2\x80\x98#\xe2\x80\x99.  This will allow messages to flow from AWS IoT Greengrass up to \xe2\x80\x98IoT Cloud\xe2\x80\x99.  When complete, your subscription table should look as follows.\nAfter the Greengrass Subscriptions have been made, make sure to re-deploy the Greengrass Group so the changes get updated on the remote AWS IoT Greengrass device.\nThe Ignition/MQTT Transmission configuration will require use of the AWS IoT Greengrass group certificate.  To acquire this, you will need to use the AWS command line interface tools.  These can be acquired here: https://aws.amazon.com/cli/.  Once downloaded and installed to a development system, use the following commands to fetch the group certificate. Note your Greengrass group ID can be found in the AWS IoT Greengrass web console under \xe2\x80\x98Settings\xe2\x80\x99.\nhttps://docs.aws.amazon.com/cli/latest/reference/greengrass/get-group-certificate-authority.html\naws greengrass list-group-certificate-authorities --group-id [group_id]\n\nget-group-certificate-authority\n\n--certificate-authority-id <value>\n\n--group-id <value>\n\n[--cli-input-json <value>]\n\n[--generate-cli-skeleton <value>]\nBash\nAfter running the above two commands you should have a file called group.ca.pem.  Make sure it looks similar to the one shown below.\n-----BEGIN CERTIFICATE-----\n\nMIIEFTCCAv2gAwIBAgIVAN2y5YnDmRasuE4IU+anNUWaC4eiMA0GCSqGSIb3DQEB\n\nCwUAMIGoMQswCQYDVQQGEwJVUzEYMBYGA1UECgwPQW1hem9uLmNvbSBJbmMuMRww\n\nGgYDVQQLDBNBbWF6b24gV2ViIFNlcnZpY2VzMRMwEQYDVQQIDApXYXNoaW5ndG9u\n\nMRAwDgYDVQQHDAdTZWF0dGxlMTowOAYDVQQDDDE3NTgwODIyNjU1MzY6ZjFlZGI5\n\nOWYtNjcxYS00MDdjLWFhZjMtMTBkODM2ZWIyNDkxMCAXDTE5MDcwODIwMjg0OVoY\n\nDzIwOTkwNzA4MjAyODQ4WjCBqDELMAkGA1UEBhMCVVMxGDAWBgNVBAoMD0FtYXpv\n\nbi5jb20gSW5jLjEcMBoGA1UECwwTQW1hem9uIFdlYiBTZXJ2aWNlczETMBEGA1UE\n\nCAwKV2FzaGluZ3RvbjEQMA4GA1UEBwwHU2VhdHRsZTE6MDgGA1UEAwwxNzU4MDgy\n\nMjY1NTM2OmYxZWRiOTlmLTY3MWEtNDA3Yy1hYWYzLTEwZDgzNmViMjQ5MTCCASIw\n\nDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAIeSsSSasd0BDp5IKUsPsSPBJk9t\n\nUNI7BXn3R4A9lO2/XCAVX3pcdN4YMsa1wcDeu+XnlFqGE72+H/rxS93yc94RciQp\n\nYLkZo2FRVZrdVTdW2QJGuugq8wzGXG2nsqNEOa1gCqukxTDX+MtinUQL1+yw/haY\n\nCR6DhpHfEuPAGW35cmJ1XInznOw4MgpGD5uS333E0x9zzkc4KSW2n+5CJW0CH8gz\n\nvdwXNDB0lBRdh0uetM4wRuK2zcl+95bwbQlbR8rorAXS3x/AEGES2cwZ+xb0+N4D\n\nAF5/IUVhLztAVdoBZlpsuMB80nTTHbsbCSkhAqD6MQOfID3lQHEkqEXgQKkCAwEA\n\nAaMyMDAwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUj4v4REh+ak5nLsuQ1UaF\n\nrn1bj7YwDQYJKoZIhvcNAQELBQADggEBAD9LW7tuDcqtWVcdQ0caqxNPubO6pBKE\n\nwQndSAbvi4xA1Shg/VMoMcucAszTGiQZSeYPnmT4Q2lpw486xi+1LaAHACbz8RFN\n\nC22vmerTqvA8qbL1N3i4atOA00E27ik67V2fHTVpZD+LU94fkeZZTLGJ071vxJwX\n\nIOSvwNGfDpvxxqkSr/kVKt8MTUYalIlE3GYagfwcDNox+UMIZCJqizDp4njgi46N\n\njqi+lSzvt5eYQCrIKTtAR/TTdbsAvbMrCwlRLUMc6+0AjnKOztYaB1kfMSk1aJhG\n\nHRHybJpbZfOFdSTADYySe6ATD47ctlnihbjY5LRc0QBmEevhHie133o=\n\n-----END CERTIFICATE-----\nBash\nNow we have all of the components required to connect MQTT Transmission in Ignition to Greengrass.  Begin by browsing to the Ignition gateway web UI and logging in.  Click the \xe2\x80\x98Config\xe2\x80\x99 tab on the left.  Now scroll down and click \xe2\x80\x98Settings\xe2\x80\x99 under the MQTT Transmission heading near the bottom of the left navigation pane.  Then select \xe2\x80\x98Servers\xe2\x80\x99 tab. This is shown below.\nNow click the \xe2\x80\x98edit\xe2\x80\x99 button to the right of the \xe2\x80\x98Chariot SCADA\xe2\x80\x99.  Change the following:\n\xc2\xb7       Name: My Greengrass\n\xc2\xb7       URL: ssl://[your_greengrass_ip_noted_earlier]:8883\n\xc2\xb7       Username: set to blank\n\xc2\xb7       Password: set to blank\n\xc2\xb7       Certificate Files: Upload your device [UUID].cert.pem, [UUID].private.key, and group.ca.pem\n\xc2\xb7       Client ID: MyIgnition\n\xc2\xb7       Data Format Type: Sparkplug_B_v1_0_JSON\n\xc2\xb7       Leave everything else default.\nWhen finished, you should have something similar to what is below.\nNow click \xe2\x80\x98Save Changes\xe2\x80\x99.  After doing so, you should see the following.\nNow in the AWS IoT Console browse to the \xe2\x80\x98Test\xe2\x80\x99 option on the left navigation pane as shown below.\nIn the \xe2\x80\x98Subscription topic\xe2\x80\x99 field enter \xe2\x80\x98#\xe2\x80\x99 as shown above and then click the \xe2\x80\x98Subscribe to topic\xe2\x80\x99 button.  This will open the following window.\nFinally, we need to create some tags so we can push data to Greengrass.  Do so by opening Ignition Designer.  Once open, create a tag tree exactly as shown below under the default tag provider.\nOnce the tag tree has been created, click the \xe2\x80\x98Transmission Control/Refresh\xe2\x80\x99 Boolean tag.  Now browse back to the \xe2\x80\x98Test\xe2\x80\x99 menu option in the AWS IoT Console.  You should see both a NBIRTH and DBIRTH message have arrived as shown below.\nNow go back to Ignition Designer and change the value of Tag1 to something else.  Shortly after the change is made, a DDATA message will appear in the AWS IoT Console as shown below.\nAt this point, basic connectivity has been established and additional tags can be added to the tag tree.  These can be OPC tags, derived tags, or other types of supported Ignition tags.  Keep in mind any time you add tags to the tag tree under the device level folder you must click the \xe2\x80\x98Transmission Control/Refresh\xe2\x80\x99 tag again.\nYou can easily add other devices to Ignition Edge like industrial automation systems and use Ignition Edge to do protocol conversion from Ethernet IP, Modbus TCP, etc. to OPC UA & MQTT. Under OPC-UA SERVER, click Create new Device and you will see this:\n  In the example below, we have an Allen-Bradley MicroLogix PLC and two tag simulators, Simulators Generic Simulator & Simulators Dairy Demo Simulator.\nNow tags from these devices can be seen in Ignition Designer under Tag Browser and AWS IoT.\nWrapping up\nIn this blog, we looked at how to connect and configure Ignition Edge with AWS IoT Greengrass & AWS IoT Core. We are now able to process the IoT messages from disparate industrial devices in the AWS environment.\nSummary\nBy following the steps in this post, you can collect industrial data from programmable logic controllers (PLCs), SCADA systems, plant historians, and other manufacturing systems and in a few hours get data flowing into AWS securely, efficiently, and cost-effectively. After the industrial data is ingested into AWS, it can be used for a variety of smart manufacturing use cases, including building ML models for predictive maintenance. Try it yourself. Get started today with connecting industrial assets and applications from the plant floor to AWS.\nAbout the author and additional resources\nRyan Dsouza is a Senior Solution Architect for Industrial IoT at Amazon Web Services (AWS). Based in New York City, Ryan helps customers architect, develop and operate scalable and highly innovative solutions using the depth and breadth of AWS platform capabilities to deliver measurable business outcomes. Ryan is an instrumentation engineer with over 25 years experience in digital platforms, smart products, smart manufacturing, energy management, building and industrial automation and IT/OT systems across a diverse range of industries. Prior to AWS, Ryan worked in Accenture, SIEMENS, General Electric and AECOM, serving customers with their smart factory solutions and digital transformation initiatives.\nAdditional resources to learn more:\n\xc2\xb7       Industrial Internet of  Things: https://aws.amazon.com/iot/solutions/industrial-iot/\n\xc2\xb7       AWS IoT: https://aws.amazon.com/iot/?nc2=h_iot_\n\xc2\xb7       AWS IoT Analytics User Guide:  https://docs.aws.amazon.com/iotanalytics/latest/userguide/welcome.html\n\xc2\xb7       Amazon SageMaker Getting  Started Developer Guide: https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html\n\xc2\xb7       ML model building: https://aws.amazon.com/blogs/machine-learning/predict-march-madness-using-amazon-sagemaker/\n\xc2\xb7       Using AWS IoT for Predictive  Maintenance: https://aws.amazon.com/fr/blogs/iot/using-aws-iot-for-predictive-maintenance/\n                             '"
162,Monitor IoT device geolocation with AWS IoT Events,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/ArduinoBlogIOT-2-6-2-12-5-Copy-of-Copy-of-Page-1-e1587253710248.png,https://aws.amazon.com/blogs/iot/monitor-iot-device-geolocation-with-aws-iot-events/,"b'Organizations with large numbers of IoT devices need efficient solutions to track events occurring across multiple devices, in order to identify operational issues and act upon them. This post covers the use case of a fictitious organization AcmeTracker that offers services to track the geolocation of a wide suite of assets (such as vehicles), by using IoT devices to monitor and notify support teams when an asset is outside of its expected geolocation boundaries. The organization AcmeTracker uses AWS IoT services to manage the devices and its data. Each device gets unique device credentials (certificates and private keys) by using the Fleet Provisioning feature in AWS IoT Core, and each device geolocation is monitored by AWS IoT Events.\nIn this post, we provide an operational overview of the aforementioned asset monitoring solution, and then describe how to setup the applicable AWS IoT services:\nSetup AWS IoT Events to monitor GPS coordinates\nSetup unique device credentials with Fleet Provisioning in AWS IoT Core\nSolution overview\nConsider a scenario where a fleet of vehicles must follow a specific itinerary. The geolocation input is used to monitor each vehicle and notify the vehicle operators if the vehicle is not following the expected itinerary. The organization AcmeTracker provides IoT devices manufactured with embedded provisioning claim credentials (certificates and keys).\nThe devices use the provisioning claim credentials to authenticate with AWS IoT using the AWS IoT Device SDK for Python. Programming languages other than Python are supported by the AWS IoT Device SDK, and for the full list of programming languages supported by the AWS IoT Device SDK, visit this page.\nThis asset monitoring solution involves the following sequence of data and message exchanges:\nThe device requests the creation of unique device credentials (create certificate and keys) to the AWS IoT Core service via a MQTT topic.\nThe device requests to register itself (activate unique device credentials) in the AWS IoT Core service via a MQTT topic, based on a provisioning template defined in the AWS IoT Core service.\nThe device retrieves GPS coordinates from a satellite.\nThe device publishes its GPS coordinates to the AWS IoT Core service over a MQTT topic.\nThe AWS IoT Core rules engine retrieves the GPS coordinates from the MQTT topic.\nThe AWS IoT Core rules engine sends the GPS coordinates to the AWS IoT Events service.\nThe AWS IoT Events service has a detector model that monitors incoming IoT events (GPS coordinates) to detect if a device is in its expected boundaries.\nIf a device state changes (either in boundary or out of boundary), the detector model sends a message to an Amazon Simple Notification Service (SNS) topic.\nThe end-users subscribed to the SNS topic receive a notification message to inform them of the device\xe2\x80\x99s state change.\nNote: Step 1 and Step 2 are only applicable for new devices for which unique device credentials are not yet generated and activated. Devices that have unique device credentials start the flow from Step 3.\nIn order to monitor and respond to changing GPS coordinates of the IoT device (covered in steps 6-9 above), AWS IoT Events must be configured accordingly. This is reviewed in the section below named Setup AWS IoT Events to monitor GPS coordinates.\nFor the IoT devices to connect to AWS IoT Core (covered in steps 1, 2, 4 and 5 above), the Fleet Provisioning feature must be enabled. This is reviewed in the section below named Setup unique device credentials with Fleet Provisioning in AWS IoT Core.\nNote: This solution implementation requires the selection of an AWS Region where Amazon Simple Notification Service (SNS), AWS IoT Core, and AWS IoT Events services are available. Visit the AWS Region table here for a full list of AWS Regions where these AWS services are available.\nSetup AWS IoT Events to monitor GPS coordinates\nIn AWS IoT Events, the organization AcmeTracker creates the below components to implement the asset monitoring solution:\nOne input representing the data, sent by the IoT device to the AWS Cloud, which includes the geolocation details (latitude and longitude)\nA detector model with 2 states (and 2 transitions) to detect if the device is in boundary or out of boundary. The detector model uses the input data to detect the state associated to a device.\nThe following subsections explains how the above components are implemented and how to configure AWS IoT Core to forward the device geolocation data to AWS IoT Events.\nCreate Input in AWS IoT Events\nYou can create an input in AWS IoT Events by following the guide to create an input. In our example, the organization AcmeTracker creates an input with the following details:\nAn Input name set to \xe2\x80\x9cgpsInput\xe2\x80\x9d\nAn example JSON payload/event with the content below\n{\n  ""gpsDeviceID"": ""1"",\n  ""gpsLat"": 10.1,\n  ""gpsLng"": 10.1,\n  ""gpsDatTm"": ""03/02/2020  08:03:20.200""\n}\nJSON\nCreate and publish Detector Model in AWS IoT Events\nIn our example, the organization AcmeTracker creates a detector model with the following details:\nTwo states (InBoundary and OutOfBoundary)\nTwo transitions (InBoundaryTransition and OutOfBoundaryTransition) in order to move the device from 1 state to another\nThe detector model design is illustrated below:\nTo create a detector model, you can download this sample detector model file and import it into AWS IoT Events by following the steps below:\nCreate a SNS topic. For more information, see the Amazon Simple Notification Service Developer Guide and, more specifically, the documentation of the CreateTopic operation in the Amazon Simple Notification Service API Reference.\nSubscribe to a SNS topic by following the guide To Subscribe an Endpoint to an Amazon SNS Topic Using the AWS Management Console.\nCreate an IAM role for the Detector Model. For more information, see the documentation for setting up permissions for AWS IoT Events.\nDownload the sample detector model file from the repository at this location.\nUpdate the file with the SNS topic\xe2\x80\x99s ARN (replace value \xe2\x80\x9c#snsTopicArn#\xe2\x80\x9d with a value in the following format: arn:aws:sns:region:account:snsTopicName)\nUpdate the file with the Detector Model IAM role\xe2\x80\x99s ARN (replace value \xe2\x80\x9c#detectorModelRoleArn#\xe2\x80\x9dwith a value in the following format: arn:aws:iam::account:role/service-role/detectorRoleName)\nGo to the AWS console and select the AWS IoT Events service\nClick on Create detector model and click on Import detector model\nClick on Import, select the file from your local system and click on Open\nOnce done, the Detector Model is created\nOnce the Detector Model is created, you can publish it by following the guide Create a Detector Model. As the organization AcmeTracker needs to track the states of multiple devices, the detector generation model is set to \xe2\x80\x9cCreate a detector for each key value\xe2\x80\x9d with a key set to the gpsDeviceID. The Detector evaluation model is set to \xe2\x80\x9cBatch evaluation\xe2\x80\x9d.\nBoundary State Configuration in Detector Model\nIn our example, the organization AcmeTracker sets up the detector model\xe2\x80\x99s states to notify a SNS topic after evaluating the input received. If the input received shows that the device is in bounds or out of bounds, a notification is sent to a SNS topic to inform the end user of the current device state (respectively \xe2\x80\x9cInBoundary\xe2\x80\x9d or \xe2\x80\x9cOutOfBoundary\xe2\x80\x9d).\nThe points below outline the configuration of the 2 states:\nBoth states include an OnEnter event and an OnInput event sending a notification to a SNS topic based on an event condition\nExample of event condition for the \xe2\x80\x9cInBoundary\xe2\x80\x9d state:\n$input.gpsInput.gpsLat>=10.1 && $input.gpsInput.gpsLat<=10.2 && $input.gpsInput.gpsLng>=10.1 && $input.gpsInput.gpsLng<=10.2\nExample of event condition for the \xe2\x80\x9cOutOfBoundary\xe2\x80\x9d state:\n$input.gpsInput.gpsLat<10.1 || $input.gpsInput.gpsLat>10.2 || $input.gpsInput.gpsLng<10.1 || $input.gpsInput.gpsLng>10.2\nNote: The above coordinates (latitude and longitude) are only illustrative.\nBoundary Transition Configuration in Detector Model\nIn our example, the organization AcmeTracker sets up transitions in the detector model in order to change the state of the device after evaluating the device\xe2\x80\x99s input against a condition (Event trigger logic).\nThe below points outline the configuration of each transition:\nBoth transitions include an event trigger logic which is used as a condition to move from one state to the other\nExample of Event trigger logic for \xe2\x80\x9cInBoundaryTransition\xe2\x80\x9d transition:\n$input.gpsInput.gpsLat>=10.1 && $input.gpsInput.gpsLat<=10.2 && $input.gpsInput.gpsLng>=10.1 && $input.gpsInput.gpsLng<=10.2\nExample of Event trigger logic for \xe2\x80\x9cOutOfBoundaryTransition\xe2\x80\x9d transition:\n$input.gpsInput.gpsLat<10.1 || $input.gpsInput.gpsLat>10.2 || $input.gpsInput.gpsLng<10.1 || $input.gpsInput.gpsLng>10.2\nNote: The above coordinates (latitude and longitude) are only illustrative.\nConfigure AWS IoT Core rules\nAn AWS IoT Core rule needs to be configured to forward device geolocation data from AWS IoT Core (MQTT topic) to AWS IoT Events.\nGo to the AWS console and select the AWS IoT Core service\nClick on Act, Rules and then click Create a Rule\nSet the Name for the rule and Set the Rule query statement to SELECT * FROM \xe2\x80\x98gpsTopic\xe2\x80\x99\nClick on \xe2\x80\x9cAdd action\xe2\x80\x9d, Send a message to an IoT Events Input and Configure action\nSelect the Input previously created\nClick on Create Role and enter a role name\nClick on Add action\nClick on Create rule\nSetup unique device credentials with Fleet Provisioning in AWS IoT Core\nThe organization AcmeTracker uses the Fleet Provisioning feature in AWS IoT Core to enable a fleet of IoT devices sharing the same business function to be managed with the same policies and the same AWS IoT Core rules. In our example and as outlined in the solution overview, the organization AcmeTracker provides IoT devices manufactured with embedded provisioning claim credentials (certificates and keys). The devices use the provisioning claim credentials to authenticate with AWS IoT Core using the AWS IoT Device SDK for Python. By using Fleet Provisioning, the IoT devices can exchange these credentials with unique device credentials for regular operations. This section explains how to create provisioning claim credentials, create a provisioning template and connect to AWS IoT Core.\nCreate provisioning claim credentials\nYou can create provisioning claim credentials by following the guides below. Once completed, you will have a certificate, private key, public key and root CA certificate.\nCreate and Activate a Device Certificate\nCreate an AWS IoT Core Policy\nAttach an AWS IoT Core Policy to a Device Certificate. Attach the following policy to the device certificate:\nNote: In the policy below, replace the region and account variables (region:account) with a valid region and account number (Example: us-east-1:123456789).\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:region:account:client/clientid""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [""iot:Publish"",""iot:Receive""],\n      ""Resource"": [\n        ""arn:aws:iot:region:account:topic/$aws/certificates/create/*"",\n        ""arn:aws:iot:region:account:topic/$aws/provisioning-templates/iotDeviceTemplateName/provision/*""\n      ]\n    },    \n   {\n      ""Effect"": ""Allow"",\n      ""Action"": [""iot:Subscribe""],\n      ""Resource"": [\n        ""arn:aws:iot:region:account:topicfilter/$aws/certificates/create/*"",\n        ""arn:aws:iot:region:account:topicfilter/$aws/provisioning-templates/iotDeviceTemplateName/provision/*""\n      ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n         ""iot:CreateProvisioningClaim""\n      ],\n      ""Resource"": [\n         ""arn:aws:iot:region:account:provisioningtemplate/iotDeviceTemplateName""\n      ]\n    }\n  ]\n}\nJSON\nCreate a provisioning template in AWS IoT Core\nYou can create a provisioning template in AWS IoT Core by following the steps below:\nGo the AWS console and select AWS IoT Core service\nClick on Onboard, Fleet Provisioning templates and then Create\nClick on Get Started\nChoose a template name (in our example: iotDeviceTemplateName)\nIn the Provisioning role, click on Create a Role\nThen click on Next, click on Advanced mode and copy paste an AWS IoT policy with the following details:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:region:account:client/clientid""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [""iot:Publish"",""iot:Receive""],\n      ""Resource"": ""arn:aws:iot:region:account:topic/gpsTopic""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [""iot:Subscribe""],\n      ""Resource"": ""arn:aws:iot:region:account:topicfilter/*""\n    }\n  ]\n}\nJSON\nClick on Create template\nClick on Enable template (you do not need to select any certificate in the \xe2\x80\x9cUse provisioning claim\xe2\x80\x9d section)\nConnect to AWS IoT Core\nOnce the provisioning template is enabled, you can now connect your IoT device to AWS IoT Core and publish the GPS coordinates by following the steps outlined below.\nNote that you must install the Python SDK (visit this page) and the AWS IoT Device SDK (visit this page) to run the below snippets.\nStep 1: Create Keys and Certificate by using the below code snippet:\nimport boto3\nimport json\nimport logging\nimport time\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\n\nlogging.basicConfig(filename=\'pythonIotDeviceCreate.log\', filemode=\'w\', format=\'%(name)s - %(levelname)s - %(message)s\',level=logging.DEBUG)\nlogger = logging.getLogger(\'pythonIotDevice\')\nlogger.info(""pythonIotDevice"")\n\nglobal certificateOwnershipToken\nglobal certificatePem\nglobal privateKey\ncertificateOwnershipToken = \'\'\ncertificatePem = \'\'\nprivateKey = \'\'\n\n#Connection to the AWS IoT Core with Root CA certificate and provisioning claim credentials (private key and certificates)\n\n# For certificate based connection\nmyMQTTClient = AWSIoTMQTTClient(""clientid"")\n# For TLS mutual authentication\nmyMQTTClient.configureEndpoint(""your.iot.endpoint"", 8883) #Provide your AWS IoT Core endpoint (Example: ""abcdef12345-ats.iot.us-east-1.amazonaws.com"")\nmyMQTTClient.configureCredentials(""/root/ca/path"", ""/private/key/path"", ""/certificate/path"") #Set path for Root CA and provisioning claim credentials\nmyMQTTClient.configureOfflinePublishQueueing(-1)\nmyMQTTClient.configureDrainingFrequency(2)\nmyMQTTClient.configureConnectDisconnectTimeout(10)\nmyMQTTClient.configureMQTTOperationTimeout(5)\n \nlogger.info(""Connecting..."")\nmyMQTTClient.connect()\n\n#Create keys and certificate by publishing a request in a MQTT topic\n \nlogger.info(""Publishing..."")\nmyMQTTClient.publish(""$aws/certificates/create/json"", ""{}"", 0)\n\n#Subscribe to a separate MQTT topic to retrieve the unique device credentials and certificate ownership token\n\ndef certCallback(client, userdata, message):\njsonMessage = json.loads(message.payload)\ncertificateOwnershipToken = jsonMessage[\'certificateOwnershipToken\']\ncertificatePem = jsonMessage[\'certificatePem\']\nprivateKey = jsonMessage [\'privateKey\']\nlogger.info(\'certificateOwnershipToken=%s, certificatePem=%s, privateKey=%s\', certificateOwnershipToken, certificatePem, privateKey)\n\nlogger.info(""Subscribing..."")\nmyMQTTClient.subscribe(""$aws/certificates/create/json/accepted"", 1,  certCallback);\n\n#Wait until reception of subscription confirmation (sleep time set to 60 seconds)\ntime.sleep(60)\n\nlogger.info(""Disconnecting..."")\nmyMQTTClient.disconnect()\nPython\nStep 2: Open the log file generated (pythonIotDeviceCreate.log). Then retrieve the certificate ownership token and unique device credentials (private key and certificate) as they will be necessary for the next steps. Finally,  save the private key and certificate in separate files.\nStep 3: Register device by using the below code snippet:\n#Register the device (link the unique device credentials with the provisioning template) by publishing a request in a MQTT topic with the certificate ownership token\n\nimport boto3\nimport json\nimport logging\nimport time\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\n\nlogging.basicConfig(filename=\'pythonIotDeviceRegister.log\', filemode=\'w\', format=\'%(name)s - %(levelname)s - %(message)s\',level=logging.DEBUG)\nlogger = logging.getLogger(\'pythonIotDevice\')\nlogger.info(""pythonIotDevice"")\n\n#Connection to the AWS IoT Core with Root CA certificate and provisioning claim credentials (private key and certificates)\n \n# For certificate based connection\nmyMQTTClient = AWSIoTMQTTClient(""clientid"")\n# For TLS mutual authentication\nmyMQTTClient.configureEndpoint(""your.iot.endpoint"", 8883) \n#Provide your AWS IoT Core endpoint (Example: ""abcdef12345-ats.iot.us-east-1.amazonaws.com"") myMQTTClient.configureCredentials(""/root/ca/path"", ""/private/key/path"", ""/certificate/path"") \n#Set path for Root CA and provisioning claim credentials (do not use the private key and certificate retrieved from the logs in Step 1 since those credentials are not yet activated) myMQTTClient.configureOfflinePublishQueueing(-1)\nmyMQTTClient.configureDrainingFrequency(2)\nmyMQTTClient.configureConnectDisconnectTimeout(10)\nmyMQTTClient.configureMQTTOperationTimeout(5)\n\nlogger.info(""Connecting..."")\nmyMQTTClient.connect()\n\njsonInput = {\n    ""certificateOwnershipToken"": ""#certificateOwnershipToken#"", #Provide the Certificate Ownership Token previously retrieved from the logs in Step 1\n    ""parameters"": {\n        ""SerialNumber"": ""Provide-A-Device-Serial-Number"" #Provide a Serial Number (Example: 012)\n    }\n}\n \nlogger.info(""Publishing..."")\nmyMQTTClient.publish(""$aws/provisioning-templates/iotDeviceTemplateName/provision/json"", json.dumps(jsonInput), 0)\n\n#Subscribe to a separate MQTT topic to retrieve the confirmation\n\ndef templateCallback(client,  userdata, message):\n    logger.info(""Confirmation received: "")\n    logger.info(message.payload)\n    logger.info(""from topic: "")\n    logger.info(message.topic)\n\nmyMQTTClient.subscribe(""$aws/provisioning-templates/iotDeviceTemplateName/provision/json/accepted"", 1, templateCallback);\n\n#Wait until reception of subscription confirmation (sleep time set to 60 seconds)\ntime.sleep(60)\n\nlogger.info(""Disconnecting..."")\nmyMQTTClient.disconnect()\nPython\nStep 4: Publish GPS coordinates by using the below code snippet.\nimport boto3\nimport json\nimport logging\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\n\nlogging.basicConfig(filename=\'pythonIotDevicePublish.log\', filemode=\'w\', format=\'%(name)s - %(levelname)s - %(message)s\',level=logging.DEBUG)\nlogger = logging.getLogger(\'pythonIotDevice\')\nlogger.info(""pythonIotDevice"")\n\n#Connection to the AWS IoT Core with Root CA certificate and unique device credentials (keys and certificate) previously retrieved\n\n# For certificate based connection\nmyMQTTClient = AWSIoTMQTTClient(""clientid"")\n# For TLS mutual authentication\nmyMQTTClient.configureEndpoint(""your.iot.endpoint"", 8883) #Provide your AWS IoT Core endpoint (Example: ""abcdef12345-ats.iot.us-east-1.amazonaws.com"")\nmyMQTTClient.configureCredentials(""/root/ca/path"", ""/private/key/path"", ""/certificate/path"") #Set path for Root CA and unique device credentials (use the private key and certificate retrieved from the logs in Step 1)\nmyMQTTClient.configureOfflinePublishQueueing(-1)\nmyMQTTClient.configureDrainingFrequency(2)\nmyMQTTClient.configureConnectDisconnectTimeout(10)\nmyMQTTClient.configureMQTTOperationTimeout(5)\n \nlogger.info(""Connecting..."")\nmyMQTTClient.connect()\n\n#Publish gps coordinates to AWS IoT Core\n\nmyMQTTClient.publish(""gpsTopic"", ""{\\""gpsDeviceID\\"":\\""1\\"",\\""gpsLat\\"":10.1,\\""gpsLng\\"":10.1,\\""gpsDatTm\\"":\\""03/02/2020  08:03:20.200\\""}"", 0)\nPython\nStep 5: Verify that you received a notification, reflecting the device state (InBoundary), from the SNS topic you\xe2\x80\x99ve previously subscribed to. You can also confirm that the device is in boundary in AWS IoT Events: Go to AWS IoT Events, click on your Detector model name and confirm the device\xe2\x80\x99s current state is as illustrated below:\nStep 6: Publish GPS coordinates by replacing the gps coordinates in the publish call of the previous code snippet with the below values:\nmyMQTTClient.publish(""gpsTopic"", ""{\\""gpsDeviceID\\"":\\""1\\"",\\""gpsLat\\"":10.0,\\""gpsLng\\"":10.0,\\""gpsDatTm\\"":\\""03/02/2020  08:03:20.200\\""}"", 0)\nPython\nStep 7: Verify that you received a notification, reflecting the device state (OutOfBoundary), from the SNS topic you\xe2\x80\x99ve previously subscribed to. You can also confirm that the device is out of boundary in AWS IoT Events: Go to AWS IoT Events, click on your Detector model name and confirm the device\xe2\x80\x99s current state is as illustrated below:\nNote: For further AWS IoT SDK (for Python) samples, please visit this page.\n'"
163,Industrial IoT – From Condition Based Monitoring to Predictive Quality to digitize your factory with AWS IoT Services,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/product-page-diagram-AWS-IoT-Industrial-Marketing.0429142a3dbac2d3d5defa051ff9d5bff5b05f50-1-1024x677.png,https://aws.amazon.com/blogs/iot/industrial-iot-from-condition-based-monitoring-to-predictive-quality-to-digitize-your-factory-with-aws-iot-services/,"b'Industrial IoT (IIoT) bridges the gap between industrial equipment and automation networks (usually called OT, Operations Technology) and Information Technology (IT). In IT, use of new technologies such as machine learning, cloud, mobile, and edge computing are becoming commonplace. IIoT brings machines, cloud computing, analytics, and people together to improve performance, productivity, and efficiency of industrial processes enabling customers to turn to IIoT applications for predictive quality and maintenance and to remotely monitor their operations from anywhere.\nBut realizing the value of IIoT is challenging and usually there are three elements that, from our experience, are holding manufacturers back:\nData is collected too infrequently\nData is difficult to access\nUnable to overcome data silos and link data together\nThis blog will explore how industrial companies can use Predictive Quality to determine actions such as adjusting machine settings, using different sources of raw materials, or doing additional worker training that will improve the quality of the factory output.\nBy leveraging AWS IoT services, industrial companies across different industries such as mining, energy and utilities, manufacturing, precision agriculture, and oil and gas can reason on top of operational data and improve performance, productivity, and efficiency.\nCurrent situation and challenges of the Industry\nWhether you are in manufacturing, utilities, mining, oil and gas, or any other industrial market segment, you have legacy equipment that has been working reasonably well for the last 10, 20 or even 30 years. Many industrial companies have made significant investments in operational technologies such as Industrial PCs (IPCs), Programmable Logic Controllers (PLCs) or large Distributed Control Systems (DCS) with real-time distributed control networks (fieldbuses) connecting them, and Supervisory Control and Data Acquisition (SCADA) systems. Operational technologies were designed and deployed to last a couple of decades, are deeply entrenched, and are very difficult to replace.\nThe following picture shows the ISA-95 Industrial Edge Architecture and how the above-mentioned elements are related to each other.\nFigure 1 \xe2\x80\x93 The automation pyramid according to the ISA 95 model (source: researchgate.net)\nIf we want to benefit from new technologies like IoT, machine learning, and computer vision, we have to adapt existing equipment and systems, which were not designed for IoT applications.\nFirst challenge for any IIoT application is to connect legacy equipment, so we are able to collect data from different devices (sensors, actuators, electrical motors) from different manufacturers. In many situations we have to adapt to different industry protocols or even retrofitting, by adding new technology to older systems so they are able to measure, allow remote control, and connect.\nThe second and most important challenge comes together with the connectivity, is security. We have to keep the device and its data secure. The failure of an equipment or system in a production environment can result in costly downtime and impact to the business. We have to ensure that industrial connected devices are able to operate at top performance without cloud connectivity. Data collection processes must not interfere with the operation of the device and ensure that any remote control or update operation is done in a secure way from only allowed operators.\nOnce we have the data secured comes the third challenge, to get insights. Data can be locked in different \xe2\x80\x9cfloors\xe2\x80\x9d of the factory (different levels of the ISA-95 architecture). In order to get insights from all the raw data, it is key to link the data together, no matter if the data is coming from different devices, manufacturers, historians, fieldbuses, systems, or databases.\nHow it works\nAWS IoT helps industrial companies overcome challenges to attain business goals.\nFirst, AWS IoT lets you easily connect, manage, and update devices of any type from small microcontrollers, to more powerful gateway devices. You can integrate your existing legacy equipment on the manufacturing floor such as Programmable Logic Controllers (PLC) and Supervisory Control and Data Acquisition (SCADA) systems by deploying simple sensors to monitor processes and track key performance indicators without overhauling or replacing existing hardware.\nSecond, AWS IoT provides built-in device authentication and authorization to keep your IoT data and devices protected. You can also continuously audit security policies associated with your devices, monitor your device fleet for abnormal behavior, and receive alerts if something doesn\xe2\x80\x99t look right. You can even take corrective actions, such as powering off devices or pushing a security fix.\nThird, AWS IoT enables connected devices to operate with intermittent Internet connectivity to mitigate risks of unexpected downtime. You can run machine learning models or software code and store data locally until Internet connection is available.\nAWS IoT provides \xe2\x80\x9cplug and play\xe2\x80\x9d capabilities so you can scale your IoT applications to thousands or millions of devices. With AWS IoT, you can organize device inventory, monitor your fleet of devices, and remotely manage devices across many locations including updating device software over-the-air (OTA).\nIn the next picture you can see how the different AWS IoT Services can work together to make IIoT a reality for your business.\nFigure 2 \xe2\x80\x93 AWS IoT Industrial Reference Architecture.\n  Once devices are securely onboarded, AWS IoT offers an easy way to run analytics on IoT data. AWS IoT collects, processes, and analyzes IoT data quickly and easily so you can gain operational insights. AWS IoT integrates with Amazon SageMaker so you can build machine learning models for your Industrial IoT Data. These machine learning models can run in the cloud and can be deployed locally on devices. With Amazon QuickSight, you can visualize and explore data and share insights across teams.\nIn the following section, you will find a detailed explanation how the different AWS IoT Services provide value to support the most important industrial use cases:\nAsset Condition Monitoring\nPredictive Maintenance\nPredictive Quality\n  Top Industrial Use cases and architecture walkthrough\nAsset Condition Monitoring\nAsset condition monitoring captures the state of your machines and equipment so you can understand how the asset is performing in the field or on the factory floor. Typically, data such as temperature, vibration, and error codes indicate if equipment usage is optimal but it\xe2\x80\x99s hard to capture manually since technicians need to physically inspect machines. With AWS IoT, you can capture all IoT data and monitor performance. With increased visibility, you can maximize asset utilization and fully exploit your investment.\nWe suggest the following reference architecture for doing Asset Condition Monitoring (aka Condition Based Monitoring) in industrial environments.\nFigure 3 \xe2\x80\x93 AWS IoT Industrial Reference Architecture for Asset Condition Monitoring\nLet\xe2\x80\x99s review the role of each AWS IoT Services to provide you a holistic Asset Condition Monitoring use case inside your industry:\nAWS IoT Greengrass brings local compute, messaging, data caching, sync, and ML inference capabilities to edge devices. In this specific use case, AWS IoT Greengrass provides you:\nWith AWS IoT Greengrass Connectors and long-running lambda functions to integrate with any existing industrial protocols and devices. Besides that, with AWS IoT Greengrass you have also access to the local resources of the gateway where it is running, enabling AWS IoT Greengrass to receive sensor data and manage device via GPIO, serial ports or any other interface. AWS IoT Greengrass can connect with higher-level systems like SCADA or even MES to enrich the information coming from the industrial devices and also to feed data back from the shop floor to the MES bus. In the following picture you can see how AWS IoT Greengrass can communicate with existing legacy devices.                                                                                                                         \n     Figure 4 \xe2\x80\x93 AWS IoT Greengrass doing Protocol Translation to connect to existing factory machines.\nYou can also operate offline. AWS IoT Greengrass lets connected devices operate even with intermittent connectivity to the cloud. Once the device reconnects, AWS IoT Greengrass synchronizes the data on the device with AWS IoT Core, providing seamless functionality regardless of connectivity.\nHelps you reduce the cost of running IoT applications. You can get rich insights at a lower cost by programming your device to filter data locally (and even doing machine learning inference at the edge) and only transmit the data you need for your applications to the cloud. This reduces the amount of raw data transmitted to the cloud, minimizing cost and increasing the quality of the data you send to the cloud. You could even have the ETL paradigm (Extract-Transform-Load) at the edge, where you extract the data from the factory machines doing protocol conversion, you transform the data into the right format and then load (i.e. send) the data into AWS IoT Core.\n    Figure 5 \xe2\x80\x93 AWS IoT Greengrass doing local processing of IoT data.\nAWS IoT Core is a managed cloud service that lets connected devices easily and securely interact with cloud applications and other devices. AWS IoT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. In this specific use case,\nAWS IoT Core can filter, transform, and act upon device data on the fly, based on business rules you define. You can use the IoT Rules to be able to detect in real-time malfunctioning in equipment and redirect this information to the right service. In this case, if errors are detected, we send those errors to the AWS SNS messaging service to send either a SMS or an Email to the factory manager to take actions. Besides that, all the information is sent to AWS IoT Analytics for further processing and analyzing of the data.\nAWS IoT Analytics is a fully-managed service that makes it easy to run and operationalize sophisticated analytics on massive volumes of IoT data without having to worry about the cost and complexity typically required to build an IoT analytics platform. In this specific use case,\nAWS IoT Analytics can enrich the IoT data received from the industrial equipment with information located in other sources, can fill the gaps if data is missing, can eliminate false readings and can perform mathematical operations in case sensors are not right calibrated.\nAWS IoT Analytics can prepare the data to be visualized directly with Amazon QuickSight and to be analyzed with machine learning using Amazon SageMaker.\nWith the basis of this architecture we have the right pieces to address the following use case, predictive maintenance.\nPredictive Maintenance\nPredictive maintenance analytics captures the state of industrial equipment so you can identify potential breakdowns before they impact production. With AWS IoT, you can continuously monitor and infer equipment status, health, and performance to detect issues in real-time. When organizations use predictive maintenance analytics, equipment lasts longer, worker safety increases, and the supply chain is optimized.\nFor predictive maintenance we suggest the following reference architecture:\nFigure 6 \xe2\x80\x93 AWS IoT Industrial Reference Architecture for Predictive Maintenance\nIf you compare this architecture with the previous one for Asset Condition Monitoring you will see a couple of extra functionalities that enable you to anticipate equipment failure:\nAmazon SageMaker is a fully-managed service that covers the entire machine learning workflow to label and prepare your data, choose an algorithm, train the model, tune and optimize it for deployment, make predictions, and act. In this specific architecture,\nAmazon SageMaker can directly apply already existing or any custom-built algorithm on top of the clean data processed by AWS IoT Analytics. You can do statistical classification through a method called logistic regression. You can also use Long-Short-Term Memory (LSTM), which is a powerful neural network technique for predicting the output or state of a process that varies over time. The pre-built notebook templates also support the K-means clustering algorithm for device segmentation, which clusters your devices into cohorts of like devices. These templates are typically used to profile device health and device state such as HVAC units in a factory or wear and tear of blades on a wind turbine.\nAWS IoT Greengrass makes it easy to perform machine learning inference locally on devices, using models that are created, trained, and optimized in the cloud. AWS IoT Greengrass gives you the flexibility to use machine learning models in Amazon SageMaker or to bring your own pre-trained model stored in Amazon S3. In this architecture,\nOnce the predictive model is trained in AWS Cloud, the model can be deployed in AWS IoT Greengrass and perform machine learning inference locally. In such way, you can run immediate corrective actions on the edge, locally, if the predicted model anticipates malfunctioning behavior, then your factory will run always on the safe side.\nNow, let\xe2\x80\x99s enhance the predictive maintenance reference architecture to reach predictive quality, which is the goal of any smart factory.\nPredictive Quality\nPredictive quality analytics extract actionable insights from industrial data sources such as manufacturing equipment, environmental conditions, and human observations. The goal of predictive quality analytics is to determine actions such as adjusting machine settings or using different sources of raw materials that will improve the quality of the factory output. Using AWS IoT, industrial manufacturers can build predictive quality models which help them build better products. Higher quality products increase customer satisfaction and reduce product recalls.\nThe recommended reference architecture for predictive quality, not only monitors the state of the industrial equipment (asset condition monitoring) and predicts failures (predictive maintenance), but also monitors the quality of the manufactured product during all the steps of the production line, by adding computer vision and machine learning as you can see in the following picture:\nFigure 7 \xe2\x80\x93 AWS IoT Industrial Reference Architecture for Predictive Quality\nIn this new architecture we add the following elements:\nComputer Vision to capture via images and/or videos the product in each of the phases. In this architecture,\nThanks to AWS IoT Greengrass you can connect to any simple camera, perform the required protocol translation, and transform that camera in a smart camera by running machine learning inference at edge.\nInitially, enough images and/or videos have been uploaded to the cloud and stored in S3, to be able to train a vision machine learning model appropriate to your product. This model will do the detection of faulty products automatically.\nOnce the machine learning model is trained, we can deploy this model in AWS IoT Greengrass, and run machine learning inference locally, so even if you lose connectivity to internet, you will be still able to do the inference and asses the quality locally.\n'"
164,Scaling authorization policies with AWS IoT Core,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/scaling-authorization-policies-with-aws-iot-core-1024x571.png,https://aws.amazon.com/blogs/iot/scaling-authorization-policies-with-aws-iot-core/,"b'Introduction\nSolutions architects, developers, and system designers building IoT solutions need ways to properly secure data and functions that operate on data across the entire solution landscape. In this post, we describe a few design options for scaling authorization policies focused on multi-user and multi-device use cases with AWS IoT Core. We cover several scenarios, including varying levels of device-to-user cardinality and scale. This information is helpful for making security design and architecture decisions for solutions built on AWS IoT services.\nSecurity coverage is needed at each tier, including IoT devices, network paths, end-user devices, databases, backend systems, and other components that interact with the data. A common term in IT security when approaching a security architecture is \xe2\x80\x9cAAA\xe2\x80\x9d or \xe2\x80\x9ctriple-A,\xe2\x80\x9d which represents the terms authentication, authorization, and accounting (or sometimes, auditing). AAA is a way to organize and view security requirements and map solution architecture onto those requirements. This way solution stakeholders, end users, and compliance professionals understand how a solution is designed to cover these important requirements.\nThe essential form of IoT solutions implies a distributed systems architecture as an inherent design element. With distributed systems architecture comes the need for complementary distributed security solutions. Many customers are using federation approaches for handling identity (authentication) requirements for distributed systems in the cloud and for hybrid architectures integrating cloud and on-premises enterprise systems. These federation approaches can be integrated into securing data and functions for IoT as well. To learn more about AWS identity federation options, view this identity federation in AWS page.\nWith a solid solution for identity in place, we can focus on dealing with the requirements of authorization, the second \xe2\x80\x9cA.\xe2\x80\x9d We are going to focus on options for common authorization use cases IoT solution builders face. Customers have indicated that the most common user-to-device configurations are 1:1 and 1:many, so this post covers some examples for those cases.\nSimple use case: 1 user to 1 device (1:1)\nStarting with the 1 user to 1 device (1:1) use case makes sense because it is the most simple to understand and configure using out-of-the-box AWS IoT Core features. Additionally, the description of the use case as 1:1 leads directly to the scenarios relevant to its selection and application.\nScenarios where the 1:1 use case is appropriate include prototype development and personal devices. Many prototyping activities map well onto the 1:1 configuration to support rapid changes and configuration simplicity associated with prototype development. Another scenario is for an end user with a personal device. The end user, using potentially multiple end-user interfaces, such as web and mobile, wants to interact with a single personal device.\nThe qualifier personal is used to help clarify the intention of the device as one designed to be used by a single individual, like a toothbrush. If you want to share your toothbrush with others, skip to a later use case covering many users to many devices (m:n).\nOn the technical front, identity for the 1:1 use case can be realized in AWS IoT Core using the Amazon Cognito identity service. AWS IoT Core enables applications and administrators to attach individual users represented as Amazon\nCognito principal to AWS IoT policies. This association enables the Amazon Cognito principal to communicate directly with the AWS IoT Core endpoints using HTTPS or MQTT over WebSockets. Through AWS IoT Core policies, this configuration allows the Amazon Cognito principal to be authorized for all the same actions and resources as an IoT device. This enables communication with any MQTT topic namespace, including special topics with $aws prefixes for device shadow and jobs interactions.\nDetailed steps for setting up Amazon Cognito and AWS IoT Core devices for a 1:1 use-case scenario can be found in this blog post titled Configuring Cognito User Pools to Communicate with AWS IoT Core.\nUse-case extension: 1 user to many devices (1:m)\nNow we\xe2\x80\x99ll extend the use-case scope to include more than one device for a single end-user principal. For this use case, let\xe2\x80\x99s say the end user (we\xe2\x80\x99ll call her Cheryl) has multiple IoT devices. Cheryl\xe2\x80\x99s devices share a brand name and are marketed for their ability to be managed from a single application. We, as the builders of the application and device software, must consider the functional requirements along with the AAA requirements of the solution of this expanded scope.\nNow multiple devices require interaction from the end user\xe2\x80\x99s application. This seems simple enough. We can create an AWS IoT Core policy for each device and attach it to the Amazon Cognito principal associated with Cheryl. We can use the same identity federation options, enabling Cheryl to log in using Amazon Cognito user pools or other identity providers such as Google, Facebook, Login with Amazon, and others.\nHowever, there\xe2\x80\x99s an \xe2\x80\x9cand\xe2\x80\x9d in this solution. The \xe2\x80\x9cand\xe2\x80\x9d is important in this use case and exceptionally important in the next one. Let\xe2\x80\x99s dive a bit deeper.\nAnytime you design for a seemingly unbounded quantity of entities (for example, users, principals, devices, instances, etc.) there are generally some boundaries that you should check for. Many times, the boundaries are large and far away and an understanding of the growth dynamics of your solution are important to confirm and monitor. However, you don\xe2\x80\x99t generally have to design using those boundaries as near-term constraints. In this particular situation, there are a couple of boundaries that we should evaluate.\nFirst, since we are expanding the number of devices that Cheryl can have, and thereby adding additional policies, we should check to see if there are any boundaries that we may encounter. We decided to solve this requirement by creating a new policy per device and attaching it to the Amazon Cognito identity principal for Cheryl. Let\xe2\x80\x99s consult the AWS IoT Service Quotas documentation to see if there are any boundaries that we should consider.\nWhat you find are these relevant limits:\nMaximum number of policies that can be attached to a certificate\nor Amazon Cognito identity \xe2\x80\x93 10\nMaximum policy document size \xe2\x80\x93 2048 characters (excluding white space)\nThis means that Cheryl is limited to a maximum of 10 devices. Depending on the types of devices, this might be satisfactory. For a scenario where Cheryl may be using a smartphone or web application to manage a thermostat, water heater, lighting controller, and perhaps an appliance or two, we seem to be at just half of our limit of 10. Should our use case expand to perhaps each lightbulb in the house, each sprinkler head in the yard, and every power receptacle in the wall, then we could easily exceed our limit of 10 devices per user.\nWe have several options. Let\xe2\x80\x99s examine an early alternative candidate using a different approach.\nAggregating permissions for multiple devices into fewer policy documents\nDevice policy documents protect the basic functions of interacting with AWS IoT Core in flexible ways. Fundamentally, the primary interface to AWS IoT Core is MQTT topics. Protecting devices essentially means protecting the topics from unwanted communication. AWS IoT Core topics are denied by default. Permission to even connect to the device gateway endpoint must be explicitly granted. Nothing prevents the accumulation of permissions to actions and resources associated with multiple device topics into a single policy. The only constraint is that the total policy document size, excluding white space (non-printable characters) must be less than 2048 characters.\nWhat this means for our design is that we can add device permissions to a single policy until that policy begins to approach the maximum size. Then we can create a new policy and begin adding additional permissions.\nConsider the following approach:\nInitial state: Cheryl\xe2\x80\x99s Amazon Cognito Identity exists and has one policy attached.\nDesired Operation: Add the ability to interact with the shadow topics of an IoT kitchen light for Cheryl with the thing name of \xe2\x80\x98cheryl-kitchen-light-01\xe2\x80\x99.\nTo start, we must build the JSON required to add the permissions for Cheryl\xe2\x80\x99s kitchen light device. Below are the resource strings must add the shadow topics to a policy that already permits connect, publish, subscribe, and receive:\nFor publish and receive actions (85 characters):\narn:aws:iot:us-east-1:123456789012:topic/$aws/things/cheryl-kitchen-light-01/shadow/*\nFor subscribe action (91 characters):\narn:aws:iot:us-east-1:123456789012:topicfilter/$aws/things/cheryl-kitchen-light-01/shadow/*\nThen, we must add 176 characters to an IoT policy.\nTo do this, we perform the following actions with our application code:\nRead the policies attached to Cheryl\xe2\x80\x99s Amazon Cognito principal with ListPrincipalPolicies.\nFor each policy do the following:\nGet the policy document with GetPolicy. (Mind the Service Quotas on this one, there is currently a 10 transaction per second (TPS) limit on certain control plane calls such as GetPolicy.)\n1. Strip the white space from the policy document and check the size.\n2. If the policy has capacity (current size + 176 is less than 2048)\nAdd the resources to the policy.\n3. If the policy has no capacity\nGo to the next policy.\nIf we can\xe2\x80\x99t find a policy with capacity, then we can create a new policy if we are under the limit of 10. If 10 policies are attached and they are all close to the maximum size, then we throw an error or we could do something a bit more clever.\nScaling with intelligent thing names\nThe naming of objects has a long history in computing. Much like variables in a computer program, object naming can have a significant effect on the comprehensibility and usability of a system. The scheme associated with object naming can also lend itself to some creative uses and enable rather elegant configurations.\nIn AWS IoT Core, there are several types of entities. There are policies, certificates, and things to start with. There are also thing types, attributes, and thing groups, which enable richer device management use cases. For this scaling use case, we are going to use a naming and a wildcard feature found in IoT policies.\nFirst, let us consider a familiar naming abstraction, the prefix. If you are familiar with Amazon Simple Storage Service (S3), you may know how the namespace works in that service. The namespace is flat with a concept of naming prefixes and delimiters that enable this flat namespace to take on hierarchical features. We are going to use this same concept of a prefix to add hierarchical management of the thing namespace to enable grouping of things.\nJust to be clear, we are not using the AWS IoT Device Management feature called \xe2\x80\x9dthing groups\xe2\x80\x9d in this scenario. While the thing groups feature does serve many useful purposes for device organization and management, it is not purposed for our aims in this particular use case.\nLet\xe2\x80\x99s get back to Cheryl and her family and smart home full of connected devices.\nLet\xe2\x80\x99s start when Cheryl purchases her first smart devices: a smart home hub, a couple of smart bulbs, a connected garage door opener, and how about a smart bird feeder?\nCheryl starts her setup by registering her smart hub on the associated website. She creates an account and adds the device to her account. Let\xe2\x80\x99s say that the application generates a unique prefix for Cheryl\xe2\x80\x99s account at this time. We call this prefix \xe2\x80\x9dxyz123\xe2\x80\x9d.\nWhen Cheryl\xe2\x80\x99s first device is registered under her account, the thing name in AWS IoT Core is created with the prefix xyz123. So, the IoT thing name for Cheryl\xe2\x80\x99s smart hub might be xyz123-home-hub-00. Next, Cheryl adds her other devices to her account with thing names like these:\nSmart garage door opener: xyz123-garage-door-00\nSmart bird feeder: xyz123-bird-feeder-00\nCheryl proceeds to add all of her devices to her account for a total of 12 devices. This is in excess of the 10-policy limit. We are not able to attach 12 policies to Cheryl\xe2\x80\x99s Amazon Cognito principal. Additionally, Cheryl is now going to grant access to her devices to the rest of her family of four additional people.\nUsing our prefix naming scheme, we can create a policy like the one below. This grants access permissions to any principal to which the policy is attached to access special topics like for the device shadow:\n{\n    ""Version"" : ""2012-10-17"",\n    ""Statement"": [\n            {\n                ""Effect"" : ""Allow"",\n                ""Action"" : [\n                    ""iot:Publish"",\n                    ""iot:Receive""\n                ],\n                ""Resource"": ""arn:aws:iot:us-east-1:1234567890:topic/$aws/things/xyz123*/shadow/*""\n            },\n            {\n                ""Effect"" : ""Allow"",\n                ""Action"" : [\n                    ""iot:Subscribe""\n                ],\n                ""Resource"" : ""arn:aws:iot:us-east-1:1234567890:topicfilter/$aws/things/xyz123*/shadow/*""\n            }\n        ]\n}\n  This policy can be created once, given a name like xyz123-policy-00, and be attached to Cheryl\xe2\x80\x99s Amazon Cognito principal as well as each of the Amazon Cognito principals associated with each of her family members. This policy provides authorization to shadow service topics for any IoT thing with a name that starts with the prefix xyz123.\nNow, instead of needing to do clever policy management by size and count, we can provide a named collection of things grouped by end users using naming prefixes. This solution is simple and works well within all of the service limits associated with policy sizes and attachments.\n'"
165,Integrate open source InfluxDB and Grafana with AWS IoT to visualize time series data,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/05/28/GrafanaBlogArchitectureFeatured.png,https://aws.amazon.com/blogs/iot/influxdb-and-grafana-with-aws-iot-to-visualize-time-series-data/,"b'Across numerous types of implementations, a large portion of IoT applications collect large volumes of telemetry data. From industrial use cases to healthcare, and from consumer goods to logistics, IoT telemetry data points are highly time-dependent. In most IoT solutions, when the data is collected and reported matters for several reasons. For instance, in attribution analyses for anomaly detection or predictive maintenance scenarios, the sequence of events that have caused or are about to cause failures needs to be accurately stored, precisely documented, and understood.\nTime-variant systems are important not only at an individual IoT device level but also at IoT application levels. For instance, on a factory floor the speed of movement of a conveyor belt in conjunction with its power drive and weight of the parts it carries at any given moment may provide better indicators of belt failure than when only data elements captured from the belt drive alone are considered. Additionally, the sequence of events/data preceding any particular failure can be predominantly understood as time and data flow charts.\nIn time-variant IoT applications it is imperative that the time drift between devices and/or between sensors and gateway software (such as AWS Greengrass) be explainable and managed. An effective way to manage the time drift across IoT applications elements is to attach a timestamp at the ingestion of each telemetry data payload into the AWS IoT Core. A key element to recall is that AWS IoT Core does not guarantee the order of data ingested and, for this reason, even if you add a timestamp at ingestion, it is best practice for IoT devices/sensors to have a uniformly incremental sequence number for each payload (or a timestamp, if possible).\nThis blog details how to develop a time-variant IoT solution using basic AWS IoT components and a time series optimized InfluxDB instance to store telemetry data. It also sets up a time series visualizations tool called Grafana. Both InfluxDB and Grafana are open-source.\nAn AWS IoT device simulator generates high frequency time series data. Data is ingested by the AWS IoT Core and a Lambda function is triggered by the rule engine to insert the data into a time series specialized database. In our case, we use an EC2 instance where we installed AWS CLI and InfluxDB. On the same EC2 instance we\xe2\x80\x99ve installed AWS CLI and InfluxDB we installed Grafana and developed time series visualizations and dashboards. Another use case can be triggered when we use the InfluxDB data to create time series data sets (as CSV) and store them in S3 to train and deploy an anomaly detection ML model using Amazon SageMaker.\nThe architecture diagram above consists of simulated edge IoT devices that publish JSON data to AWS IoT Core. An AWS Lambda function gets triggered and inserts IoT data into an InfluxDB database instance which is used to develop dashboards with Grafana. An additional option is represented to trigger Lambda Step Functions to aggregate the data at particular time intervals (such as average at 5 minute intervals) and to insert the aggregated data into InfluxDB. The InfluxDB data can also be exported as CSV files into Amazon S3 buckets and be the data source to perform anomaly detection or other ML modeling with Amazon SageMaker.\nThis blog details 4 steps to publish IoT data to a time series database and develop real time dashboards.\nSet up the AWS IoT Device Simulator;\nSet up InfluxDB and Grafana on your own Amazon EC2 instances;\nSet up AWS IoT Core resources and AWS Lambda function needed to populate the time series database;\nDevelop Grafana dashboard(s) with real-time visualizations to track IoT data.\nStep 1. Set up the AWS IoT Device Simulator\nThe first step is to deploy the AWS IoT Device Simulator on the target AWS account. The AWS CloudFormation template deployment guide can be found at this link. It may take up to 15 minutes for all resources required to be provisioned. After we deploy the AWS IoT Device Simulator we create a new device type called PressureDevice. The pressure device shows up as a device type in the AWS IoT Device Simulator.\nWe add a few message attributes: pressure, viscosity, sensordatetime, deviceid, and clientid for this device type as well as the data frequency.\nThe configuration settings for each attribute are listed below. Please note that each device and attribute receives an internal ID separate from any other IDs we create.\n{\n  ""name"": ""pressure"",\n  ""_id_"": ""wzCHpAvdm"",\n  ""min"": 500,\n  ""type"": ""int"",\n  ""max"": 1500\n}\n\n{\n  ""name"": ""viscosity"",\n  ""_id_"": ""NJJXwHTdW"",\n  ""min"": 25,\n  ""type"": ""int"",\n  ""max"": 100\n}\n\n{\n  ""name"": ""sensordatetime"",\n  ""_id_"": ""QyKD1oCtd"",\n  ""tsformat"": ""default"",\n  ""type"": ""timestamp""\n}\n\n{\n  ""name"": ""deviceid"",\n  ""_id_"": ""W4uk2jVHX"",\n  ""static"": ""false"",\n  ""type"": ""shortid""\n}\n\n{\n  ""name"": ""clientid"",\n  ""_id_"": ""nXHjO4oTL"",\n  ""static"": true,\n  ""type"": ""uuid""\n}\nJSON\n  On the Widgets of the simulator browser section create 20 new instances of pressuresensor devices, which will actually start to publish data to AWS IoT Core (on the specified MQTT topic, pressure/data) as soon as they are started.\n  Let\xe2\x80\x99s navigate to the AWS console and go to AWS IoT Core and test to inspect the data we are receiving from our simulated devices, by going to the Test menu, then subscribing to the same topic we have specified (pressure/data).\nWe can see how the data arrives from the device simulator to the AWS IoT Core.\nStep 2. Set up InfluxDB and Grafana on an EC2\nThe next step is to set up an Amazon EC2 instance in a private subnet of your VPC. For a step-by-step tutorial, please see this link. You may also elect to install InfluxDB and Grafana on a stand-alone Amazon EC2 instance, i.e. not part of a VPC. When you set up your VPC or Amazon EC2 instance, add port 3000 to your security group for inbound access. For our blog purposes, select a t2.micro instance type and a Ubuntu distribution. SSH into the Amazon EC2 instance created and install InfluxDB and Grafana.\nTo install InfluxDB run the following commands.\nwget https://dl.influxdata.com/influxdb/releases/influxdb_1.7.7_amd64.deb\n \nsudo dpkg -i influxdb_1.7.7_amd64.deb\nBash\nAfter the installation completes, start the InfluxDB engine.\nsudo service influxdb start\nBash\nYou can validate the InfluxDB engine is running correctly by interacting with InfluxDB CLI.\ninflux\nBash\nTo exit the InfluxDB CLI, just type quit.\nquit\nBash\nThe following steps installs Grafana on the same EC2 instance. In production environments you may need to install it on a separate EC2 instance on the same subnet.\nwget https://dl.grafana.com/oss/release/grafana_6.2.5_amd64.deb \nsudo apt-get update\nsudo apt-get install libfontconfig1\nsudo apt --fix-broken install\n\nsudo dpkg -i grafana_6.2.5_amd64.deb\nBash\nOnce both InfluxDB and Grafana are setup let\xe2\x80\x99s create a database and table. Create a new database and a new user using following syntax, and use the quit command to exit the database instance.\ninflux\n\ncreate database awsblog\n \ncreate user awsblog with password \'YourPassword\'\n\nquit \nBash\nTo complete our custom installs, let\xe2\x80\x99s add Telegraf (this is a plugin-driven server agent for collecting and reporting metrics).\nNote: you may have to add into the repository influxData repository, to add these further instructions can be found here.\nsudo apt install telegraf -y\nBash\nLet\xe2\x80\x99s start it and enable it.\nsudo systemctl start telegraf\n \nsudo systemctl enable telegraf\nBash\nValidate that Telegraf its running:\nsudo systemctl status telegraf\nBash\nLet\xe2\x80\x99s edit and save the basic configuration in the file /etc/telegraf/telegraf.conf. Look for the following section in the file, and add after the [[outputs.influxdb]]\nNote: you may have to use sudo to save the file, this depends on you OS and user setup. With nano, CTRL-O saves the file to disk and CTRL+X exits the nano editor.\nsudo nano /etc/telegraf/telegraf.conf\n\n###############################################################################\n# OUTPUT PLUGINS #\n###############################################################################\n# Configuration for sending metrics to InfluxDB\n[[outputs.influxdb]]\n\ndatabase = ""awsblog""\nusername = ""awsblog""\npassword = ""YourPassword""\nBash\nThe final step for our Amazon EC2 instance is to setup Grafana (the graphics engine) to use the InfluxDB as a datasource. To do so, access the Grafana UI via the following URI.\nhttp://<EC2-PublicDNS>:3000/\nChange the default username and password from admin/admin and setup the data source. Ensure that the URL that points to the InfluxDB instance has the port number of the database instance (at the end of the URL make sure you have :8086).\nWe are now ready to test a few record inserts into our InfluxDB using the EC2 console.\ninflux\n\nuse awsblog\n \nINSERT pressure,sensor=client001sensor01 value=1001,viscosity=34\nINSERT pressure,sensor=client002sensor01 value=2101,viscosity=37\nINSERT pressure,sensor=client003sensor01 value=0901,viscosity=38\nINSERT pressure,sensor=client004sensor01 value=1201,viscosity=39\nINSERT pressure,sensor=client005sensor01 value=1101,viscosity=60\n\nquit\nBash\nThe next few steps will enable the solution to get the sensor data from our AWS IoT rule and insert the data into the InfluxDB using a Lambda function.\nStep 3. Set up a Lambda function and AWS IoT core resources\nSetting up a Lambda function\nLet\xe2\x80\x99s create a new Lambda function in Node.js 10.x, and paste the code below. We call it blogLambda2InfluxDB.\nCode for index.js\nconst Influx = require(\'influx\');\n\n//This code writes data from IoT core rule via Lambda into InfluxDB \n\nexports.handler = async (event,context,callback) => {\n\n    var pressureInputValue = JSON.parse(event.pressure);\n    var viscosityInputValue = JSON.parse(event.viscosity);\n    //Create clientID\n    var clientid = JSON.stringify(event.clientid);\n    var deviceid = JSON.stringify(event.deviceid);\n    var sensorInputName = deviceid+clientid; \n\n    //var sensordatetime = JSON.stringify(event.sensordatetime);\n    \n    var result = writeToInfluxDB (pressureInputValue, viscosityInputValue,sensorInputName);\n    \n    callback(null, result);\n\n  };\n\nfunction writeToInfluxDB(pressureVar, viscosityVar,sensorVar)\n{\n    console.log(""Executing Iflux insert"");\n\n    const client = new Influx.InfluxDB({\n        database: process.env.INFLUXDB,\n        username: process.env.INFLUXDBUSRNAME,\n        password: process.env.INFLUXDBPWD,\n        port: process.env.INFLUXDBPORT,\n        hosts: [{ host: process.env.INFLUXDBHOST }],\n        schema: [{\n            measurement: \'pressure\',\n    \n            fields: {\n                pressureValue: Influx.FieldType.FLOAT, \n                viscosity: Influx.FieldType.FLOAT,\n            },\n    \n            tags: [\'sensorID\']\n        }]\n    });\n    \n    client.writePoints([{\n        measurement: \'pressure\', fields: { pressureValue: pressureVar, viscosity: viscosityVar, },\n        tags: { sensorID: sensorVar}\n    }]) \n    console.log(""Finished executing"");\n}    \nJavaScript\nYour Lambda console should look similar to the image below.\nThen, let\xe2\x80\x99s add a few environment variables as below (substitute the relevant values with your own).\nAnd now Please notice how the Lambda function uses the environment variables we set up to perform the InfluxDB inserts. Select the execution role, VPC, subnets, and security group belonging to the same values as on your Amazon EC2 instance (InfluxDB server).\nLet\xe2\x80\x99s create and execution role for Lambda by following the step guideline found here (look under heading Execution Role and User Permissions)\nFor testing purposes you can set up your local environment to have access to influx utilities.\nCreate lambda on your laptop (where AWS CLI is installed) or EC2 with the following commands.\nnpm init\nnpm install \xe2\x80\x94save influx\nBash\nUse directions from this link and paste the AWS Lambda function code (see above Step 3 section Code for index.js) into the index.js file and zip it up and upload it into your AWS Lambda console.\nSET UP AWS IoT Core resources\nNavigate to the AWS IoT console and then to the Act menu. Let\xe2\x80\x99s create a new rule called awsblog IoT Rule with an action to invoke a AWS Lambda function, to match the statement below.\nSELECT pressure AS pressure, viscosity as viscosity, sensordatetime as sensordatetime, deviceid as deviceid, clientid as clientid FROM \'pressure/data\'\nBash\nThen select our AWS Lambda function: blogLambda2InfluxDB which we created above.\nStep 4. Develop real-time Grafana dashboards\nAfter the time series data from our simulated devices starts to stream into the InfluxDB instance we can start developing visualizations using Grafana. To access the Grafana web interface, log on to your Amazon EC2 instance that hosts Grafana, and navigate to http://ec2-xxx-xxx-xxx-xxx.compute-1.amazonaws.com:3000/login, where the xxx-xxx-xxx-xxx is the elastic IP address of your Amazon EC2 instance. You need to recall the Grafana username and password you created during Step 2 above.\nThen click on the plus sign to create a dashboard, called Pressure and Viscosity.\nThen add a new panel with the setting below. Rename it as Timeseries and Moving Average (by selecting the appropriate metrics space and aggregations). Your screen should look as below..\nYou can add more visualization panels to create a dashboard like the one shown below, but yours may look different based on the panels and visualization types you decide to add.\n'"
166,How to perform secondary processor over-the-air updates with FreeRTOS,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/02/19/GeneralArchitecturev2-1024x665.png,https://aws.amazon.com/blogs/iot/how-to-perform-secondary-processor-over-the-air-updates-with-freertos/,"b'Many embedded architectures include a connectivity processor connected to one or more secondary processors that perform business logic. The ability to perform secondary processor over-the-air (OTA) updates is just as critical as updating the connectivity processor. This is because it allows for low-cost patching of bugs and security vulnerabilities as well as delivering new features to the device.\n  FreeRTOS is an open source, real-time operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage. AWS IoT Device Management makes it easy to securely register, organize, monitor, and remotely manage IoT devices at scale. AWS IoT Device Management provides an OTA Update Manager service to securely create and manage updates across a fleet of devices. The service works with the FreeRTOS OTA agent library by digitally signing the firmware, converting the file into an MQTT stream using the streaming API, and delivering the firmware to the device using AWS IoT jobs. The OTA agent library allows the reuse of an MQTT connection over TLS to reduce memory consumption on the connectivity processor.\nIn this post, we show you how to use the fileId parameter to deliver updates to the secondary processor. This post is not specific to any hardware and can be adapted to any system that runs FreeRTOS 201908.00 or later. For additional details on how to set up OTA using FreeRTOS and AWS IoT Device Management, refer to the FreeRTOS OTA tutorial.\nReference architecture overview\nThe following architecture diagram describes the flow of the secondary processor update from AWS IoT through a connectivity processor. The device runs FreeRTOS on the connectivity processor and has a serial interface such as SPI connected to the secondary processor. An authorized operator securely uploads the firmware to an Amazon S3 bucket and initiates the OTA update. The firmware file is signed using a digital certificate and a stream is created. An AWS IoT job is then created to send the firmware update to the device. The device\xe2\x80\x99s connectivity processor identifies that the firmware update is one destined for the secondary processor and sends the update over the serial interface.\n  Make firmware changes\nFreeRTOS includes code that demonstrates how to perform OTA updates. You can find out details about how the demo works in the OTA updates demo application documentation. You can also download changes to the OTA demo from this code link and follow along after applying the patch.\nOTA for a processor is typically handled by a Microcontroller Unit (MCU) vendor using guidelines listed in the OTA porting guide. The MCU vendor implements functions in the Platform Abstraction Layer (PAL) to perform the update. The patch prevents you from disrupting the firmware updates to the connectivity processor and overriding the behavior for secondary processor updates. The patch file previously provided lets you accomplish the following:\nProvide function overrides to the PAL layer. If the firmware is intended for the connectivity processor, the vendor-supplied PAL functions are called. Otherwise, the function allows you to send the update to the secondary processor using the overrides. These functions have been left empty so that hardware-specific transfers can be performed as needed by your platform.\nOverride the PAL layer to call the function overrides using the internal OTA agent initialization function:\nOTA_AgentInit_internal(xConnection.xMqttConnection, (const uint8_t *)(clientcredentialIOT_THING_NAME), &amp;otaCallbacks, (TickType_t)~0);\nC\nHere are some items that you might need to adjust in the patch for your application:\nInitialize communication with the secondary processor before initializing the OTA agent.\nCheck the file ID in the code to identify which processor is being updated. This file ID must match the ID sent in the script described in the next section. When an OTA update is created from the console, the file ID sent down is 0. Do not use 0 for any secondary processor updates.\nEnsure that each of the callbacks return the appropriate error. For example, in the prvPAL_CreateFileForRx_customer callback, you might want to put the secondary processor into a known state to start receiving updates. If the state change fails, the callback should return an error.\nEnsure that you return back eOTA_PAL_ImageState_Valid as the current platform image state on startup and eOTA_PAL_ImageState_PendingCommit when the platform state is set to eOTA_ImageState_Testing by the OTA agent state machine.\nEnsure that the secondary processor is updated by checking the version number in the self-test routine. There is no explicit check done by the OTA state machine to ensure that the secondary processor updated.\nTo ensure that you are running the demo correctly, be sure to make the following changes:\nConfigure your AWS environment by setting up storage and code-signing certificate. You can follow Steps 1 and 2 in Perform OTA Updates on Espressif ESP32 using FreeRTOS Bluetooth Low Energy.\nLocate the aws_demo_config.h for your platform. For example, for ESP32, this file is located in vendors/espressif/boards/esp32/aws_demos/config_files/\nDefine CONFIG_OTA_UPDATE_DEMO_ENABLED and comment out any other demo defines.\nModify demos/include/aws_clientcredential.h:\nAdjust the endpoint url in clientcredentialMQTT_BROKER_ENDPOINT[]\nAdjust the thing name in clientcredentialIOT_THING_NAME\nModify demos/include/aws_clientcredential_keys.h:\nAdd the device certificate to the keyCLIENT_CERTIFICATE_PEM define.\nAdd the device private key to the keyCLIENT_PRIVATE_KEY_PEM define.\nModify demos/include/aws_ota_codesigner_certificate.h:\nAdjust signingcredentialSIGNING_CERTIFICATE_PEM with the certificate that will be used to sign the firmware binary file. If you need more details on how to create the certificate, follow instructions in the first step.\nOnce the firmware is programmed, the OTA agent should continue to function normally for the connectivity processor. At the same time, it should also allow you to provide the OTA update to your secondary processor. You should see the following prints on the debug console of the connectivity processor:\n12 309 [iot_thread] OTA demo version 0.9.2\n13 309 [iot_thread] Creating MQTT Client...\n----\n21 823 [iot_thread] Connected to broker.\n22 824 [iot_thread] [OTA_AgentInit_internal] OTA Task is Ready.\n23 825 [OTA Agent Task] [prvOTAAgentTask] Called handler. Current State [Ready] Event [Start] New state [RequestingJob]\n----\n56 924 [iot_thread] State: Ready  Received: 1   Queued: 0   Processed: 0   Dropped: 0\n57 1024 [iot_thread] State: WaitingForJob  Received: 1   Queued: 0   Processed: 0   Dropped: 0\n58 1124 [iot_thread] State: WaitingForJob  Received: 1   Queued: 0   Processed: 0   Dropped: 0\nC\nAt this point, your device is ready to receive an OTA update.\nSet up the OTA update script\nOnce you have set up the firmware to allow for secondary processor updates, you must set up the cloud to transmit these updates to the device. The following steps walk you through how to initiate the OTA update to your secondary processor:\nInstall prerequisites:\npip3 install boto3\npip3 install pathlib\nBash\nGet the OTA script from this code link.\nRun the script with a fileId greater than 0 and by providing the file location for the secondary processor binary.\nHelp can be obtained by issuing:\npython3 start_ota_stream.py \xe2\x80\x94h\nusage: start_ota_stream.py [-h] [--fileId FILEID] \xe2\x80\x94profile PROFILE\n[--region REGION] [\xe2\x80\x94account ACCOUNT]\n[--devicetype DEVICETYPE] --name NAME \xe2\x80\x94role ROLE\n--s3bucket S3BUCKET \xe2\x80\x94otasigningprofile\nOTASIGNINGPROFILE \xe2\x80\x94signingcertificateid\nSIGNINGCERTIFICATEID [\xe2\x80\x94codelocation CODELOCATION]\n[\xe2\x80\x94filelocation FILELOCATION]\n\nScript to start OTA update\n\noptional arguments:\n-h, --help show this help message and exit\n--fileId FILEID ID of file being streamed to the device\n--profile PROFILE Profile name created using aws configure\n--region REGION Region\n--account ACCOUNT Account ID\n--devicetype DEVICETYPE\nthing|group\n--name NAME Name of thing/group\n--role ROLE Role for OTA updates\n--s3bucket S3BUCKET S3 bucket to store firmware updates\n--otasigningprofile OTASIGNINGPROFILE\nSigning profile to be created or used\n--signingcertificateid SIGNINGCERTIFICATEID\ncertificate id (not arn) to be used\n--codelocation CODELOCATION\nbase FreeRTOS folder location (can be relative) when\nfileId is 0\n--filelocation FILELOCATION\nOTA update file location when fileId is greater than 0\nBash\nExample execution:\npython3 start_ota_stream.py --profile otausercf --name mythingname --role ota_role --s3bucket ota-update-bucket --otasigningprofile signingprofile --signingcertificateid <certid> --fileId 1 --filelocation update.bin\n\nCertificate ARN: arn:aws:acm:us-east-1:123456789012:certificate/cert-uuid\nUsing App Location: update.bin\nBuild File Name: update.bin\nSearching for profile signingprofile\nFound Profile signingprofile in account\nWaiting for signing job to completeOTA Update Status: {\'ResponseMetadata\': {\'RequestId\': \'2c910ef5-1df5-4df6-8fe9-ddc3c46c68d2\', \'HTTPStatusCode\': 200, \'HTTPHeaders\': {\'date\': \'Tue, 07 Jan 2020 19:53:48 GMT\', \'content-type\': \'application/json\', \'content-length\': \'184\', \'\nconnection\': \'keep-alive\', \'x-amzn-requestid\': \'2c910ef5-1df5-4df6-8fe9-ddc3c46c68d2\', \'access-control-allow-origin\': \'*\', \'x-amz-apigw-id\': \'F8g4CFECoAMFz5g=\', \'x-amzn-trace-id\': \'Root=1-5e14e1cc-1fb61a4d9261e6b0602290c9\'}, \'RetryAttem\npts\': 0}, \'otaUpdateId\': \'device-8673-0-0-0\', \'otaUpdateArn\': \'arn:aws:iot:us-east-1:123456789012:otaupdate/device-8673-0-0-0\', \'otaUpdateStatus\': \'CREATE_PENDING\'}\nBash\nYou should see the update start in the console. Here are some prints you see in the debug console of the device:\n75 2767 [OTA Agent Task] [prvParseJobDoc] Size of OTA_FileContext_t [64]\n76 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ jobId: AFR_OTA-device-58124-0-0-0 ]\n77 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ protocols: [""MQTT""] ]\n78 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ streamname: device-8673-0-0-0 ]\n79 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ filepath: update.bin ]\n80 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ filesize: 10446 ]\n81 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ fileid: 1 ]\n82 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ certfile: /cert.pem ]\n83 2767 [OTA Agent Task] [prvParseJSONbyModel] Extracted parameter [ sig-sha256-ecdsa: MEUCIQDNRumLRyXqUM3Z2wa71/LV4ufv... ]\n84 2767 [OTA Agent Task] [prvParseJobDoc] Job was accepted. Attempting to start transfer.\n85 2767 [OTA Agent Task] [prvPAL_GetPlatformImageState_customer] OTA Demo for secondary processor.\n86 2767 [OTA Agent Task] [prvPAL_CreateFileForRx_customer] OTA Demo for secondary processor.\n----\n96 2781 [OTA Agent Task] [prvRequestFileBlock_Mqtt] OK: $aws/things/mythingname/streams/device-8673-0-0-0/get/cbor\n97 2781 [OTA Agent Task] [prvOTAAgentTask] Called handler. Current State [RequestingFileBlock] Event [RequestFileBlock] New state [WaitingForFileBlock]\n98 2805 [OTA Agent Task] [prvIngestDataBlock] Received file block 0, size 4096\n99 2805 [OTA Agent Task] [prvPAL_WriteBlock_customer] OTA Demo for secondary processor.\n----\n108 2816 [OTA Agent Task] [prvIngestDataBlock] Received final expected block of file.\n109 2816 [OTA Agent Task] [prvStopRequestTimer] Stopping request timer.\n110 2816 [OTA Agent Task] [prvPAL_CloseFile_customer] Received prvPAL_CloseFile_customer inside OTA Demo for secondary processor.\n111 2816 [OTA Agent Task] [prvIngestDataBlock] File receive complete and signature is valid.\n----\n124 2833 [iot_thread] State: WaitingForJob  Received: 5   Queued: 0   Processed: 0   Dropped: 0\n125 2833 [OTA Agent Task] [prvPAL_ActivateNewImage_customer] OTA Demo for secondary processor.\nBash\nOnce the OTA update is complete, the device restarts as needed by the OTA update process and tries to connect with the updated firmware. If the connection succeeds, the updated firmware is marked as active, and you should see the updated version in the console:\n58 866 [OTA Task] [prvUpdateJobStatus] Msg: {""status"":""SUCCEEDED"",""statusDetails"":{""reason"":""accepted v0.9.2""}}\nBash\n'"
167,Improving the management and security of your AWS IoT resources with tagging,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/imageBlog2-1024x496.png,https://aws.amazon.com/blogs/iot/improving-the-management-and-security-of-your-aws-iot-resources-with-tagging/,"b'Solution providers operating environments such as smart building, utilities, manufacturing systems, and connected products offer business-to-business services often based on IoT platforms deployed in multitenant deployments. Securely managing those resources by use case, types, locations and by tenants can sometime be hard.\nCreating hierarchical grouping of things is a common pattern, but it does not address multitenancy well. For instance, the same tenant might rent offices in several cities and share some buildings with other tenants, and this cannot be captured by creating hierarchical groups. On the other hand, the same resources might be used over time by different tenants (such as a connected vehicle, a rented office space, or connected device).\nIn this post, we walk through how to use AWS tags on multitenant IoT deployments to improve management and security of AWS IoT resources in such environments. We first discuss why tagging resources is important, and then we dig into AWS IoT tagging capabilities. We then go through the steps of setting up tags and using tags for a fictional multitenant smart building environment.\n  Why is tagging resources important?\nTags are labels in the form of a key-value pair that can be attached to your AWS resources. They provide additional information and context about that specific resource. Tags can identify who owns the resource, the environment where it is used, and any other technical or business attributes based on your requirements.\nAn effective tagging policy allows you to track all of your AWS resources from different services. Manage them according to your requirements, by building your own set of resources grouped by tags.\nTagging can serve various purposes. The most common use of tags is to control cost allocation. AWS Cost Explorer uses tags allocated to resources to break down AWS cost by tags, and you can create detailed billing reports accordingly. Tags also allow grouping cost from various services (AWS IoT Core, Amazon EC2 instances, Amazon S3 buckets, AWS Lambda functions, and others) consumed in a particular context (for example, consumed for one project or by one tenant of a shared IoT service).\nDifferent tags can flag all resources of a given tenant, business unit, cost center, customer, project, application, or any dimension, allowing granular and consolidated approach to cost allocation.\nAnother direct benefit of tags is to allow filtering resources on the AWS Management Console based on tags or portions of tags. This allows you to see all resources related to a project, organization, or any grouping relevant to the operation of your environment. It creates a custom console for you. This is based on the resource groups that can be set either through the console or through the resource group API.  AWS IoT Analytics, AWS IoT Core, AWS IoT Device Defender, and AWS IoT Device Management support resource groups.\nTags can also serve your security policies by allowing access control based on tags. IAM policies can be configured to define resource policies based on tags. Using tags with IAM policies allows controlling access to a group of resources based on their tag values.\nTags can be used to identify which resources are involved in some automated activities, for example, development resources that should be stopped after business hours. Tags can also identify device groups that can be involved in specific AWS IoT Device Defender audits.\nTo serve those different purposes, you can create your own tagging strategy based on AWS tagging strategies best practices.\n  IoT-specific tagging capabilities\nFirst, given the potentially huge number of connected things, IoT things cannot be directly tagged. Instead, groups of things can be tagged. So, apply your tagging strategy to groups of things.\nThings can be grouped in different ways. The AWS IoT Core device registry allows creation of hierarchical thing groups\xe2\x80\x94a thing can belong to several groups. In a later example, things are grouped by location (each floor of the building forming a group of devices). You can apply a tag to such a group.\nYou can also define dynamic groups, where group membership is defined by query rules on device connectivity status, shadow values, or registry parameters, making the group dynamic.  You might, for instance, create a group for sensors that display a temperature higher than 25\xc2\xb0C, and another one for all device currently connected and ready to receive downstream data and commands. Applying tags to such dynamic groups allows you to quickly identify the devices related to those dynamic groups and take appropriate actions.\nBilling groups are groups of things created for billing purposes that collect billable information for the things.\nYou can tag each billing group that you create to identify which tenant, business unit within a tenant, product, or project things are being used for. This is part of the AWS cost allocation report with your usage and costs aggregated by your tags.\nA thing can only belong to a single billing group, and billing groups cannot be organized in hierarchies. For more details on billing groups capabilities, see billing groups capabilities.\nYou can also tag other AWS IoT Core resources:\nThing type\xe2\x80\x94several thing types can be tagged to match either a specific group of similar things types.\nTopic rules can be tagged to match a specific application using this rule.\nJobs, scheduled audits, and security profiles can also be tagged to facilitate automation.\nApplying tags to a multitenant AWS IoT deployment\nIn this example, you learn how to apply tags to thing types, hierarchical thing groups, and billing groups by going through an example of a multitenant smart building IoT setup.\nA fictitious company, ExampleCorp, offers office spaces for rent to various businesses and provides energy-efficient and wellness office services. Those services rely on smart devices such as smart lights, presence sensors, temperature sensors, and air quality sensors. To manage its building parks, ExampleCorp is using AWS IoT services. ExampleCorp must manage things according to their types and creates several thing types.\nDefining and tagging thing types\nFirst, define thing types to clearly identify the various types of things that ExampleCorp is using. In the AWS IoT Core console, choose Manage,  Types.\nWhen creating thing types on the console, you can directly apply tags. Alternately, tags can also be set by going through the tagging API. Allocating a tag to this thing type allows quick listing and applying of actions to a set of similar things, both from CLI or API.\nWhen you choose LightBulbs thing type, you get details on this thing type and on the tag applied to this type.\nWhen thing types have been properly tagged, you can easily list all the thing types tagged with a specific tag. The following is an example of retrieving all thing types produced by the manufacturer AnyCompany1 , who is providing both TemperatureSensor and LightBulb-versionA thing types to ExampleCorp\n[]  aws resourcegroupstaggingapi get-resources --tag-filters Key=""Manufacturer"",Values=""AnyCompany1"" | awk -F\\/  \'/ResourceARN/ {print $2}\' | awk -F \\"" \'{print $1}\')\n\nTemperatureSensor LightBulb-versionA\nBash\nFrom this point, all things of this thing type can be listed and used for either accounting, or as entry to an AWS IoT job command.\nGrouping things logically and tagging groups\nAfter having properly created and tagged thing types, ExampleCorp has onboarded a few devices in the AWS IoT Core console.\nIn addition, to facilitate service delivery and management, ExampleCorp decides to organize things grouping by use case and by floor.\nTo create groups, in the AWS IoT Core console, choose Manage, groups.\nThe following diagram shows a hierarchical group for light bulbs, split in sub groups representing the various locations when smart lightbulbs are deployed. Select the \xe2\x80\x9cGroups\xe2\x80\x9d Tab under the LightBulbs group to list all subgroups:\n  You can navigate this hierarchy by clicking on group names (Building1FirstFloor, Building1SecondFloor Building2) and you can add subgroups with the \xe2\x80\x9cadd a group\xe2\x80\x9d command.\nThing groups have a hierarchical structure that fits well with organizing things according to their location (building, floor) and use case. However, ExampleCorp wants to quickly identify the set of devices that their customers use.\nWhile it is possible to list all things within a group, allocating tags to various thing groups allows quick listing and applying of actions to a group of things, both from CLI or API. In this example, a tag representing the customer who uses the things is allocated to the thing groups.\nIn the following screenshot, AnyCompany2  company is renting the first and third floors of Building 2, and an appropriate tag (customerName = AnyCompany2) has been set up for those thing groups. The following IOT Console screenshot shows the tags applied to the things group representing the first floor of Building 2. Select the \xe2\x80\x9cTag\xe2\x80\x9d Tab under the LightBulbs group to display the tags associated to this group:\n\nWhen ExampleCorp wants to list which things are being used by a particular customer, they can run a CLI command. The following code example lists all things from the thing group being used by a particular customer. In this example, list all things from thing group with the tag CustomerName = \xe2\x80\x9cAnyCompany2\xe2\x80\x9d.\n#Get the list of all resource groups tagged for the customer\n# First, retrieve the thing group tagged for this customer\n[]  aws resourcegroupstaggingapi get-resources --tag-filters Key=""customerName"",Values=""AnyCompany2"" | awk -F\\/  \'/ResourceARN/ {print $2}\' | awk -F \\"" \'{print $1}\')\nThirdFloor\nfirstFloor\n\n#Use those group names to retrieve the list of things within these groups\n\n[]  aws iot  list-things-in-thing-group   --thing-group-name ThirdFloor\n{\n    ""things"": [\n        ""lightBulbs90"",\n        ""lightBulbs93"",\n        ""lightBulbs99"",\n        ""lightBulbs92"",\n        ""lightBulbs94"",\n        ""lightBulbs97"",\n        ""lightBulbs98"",\n        ""lightBulbs96"",\n        ""lightBulbs91"",\n        ""lightBulbs95""\n    ]\n}\naws iot  list-things-in-thing-group   --thing-group-name firstFloor\n{\n    ""things"": [\n        ""lightBulbs53"",\n        ""lightBulbs51"",\n        ""lightBulbs57"",\n        ""lightBulbs52"",\n        ""lightBulbs58"",\n        ""lightBulbs55"",\n        ""lightBulbs54"",\n        ""lightBulbs56"",\n        ""lightBulbs59"",\n        ""lightBulbs50""\n    ]\n}\nBash\nCreating relevant billing groups\nBilling groups are the basic unit for charging in AWS IoT.  You can assign billing groups to things, individually, whether they are part of a group or not.\nIn our example, Example Corp decides to create one billing group for each building floor for all things within this floor.\nThe following commands create a billing group for the things in the First Floor of the Building 2, and automatically adds a tag to this group to spot its location.\naws iot create-billing-group  --billing-group-name Building2FirstFloorLightBulbs --tags Key=""Location"",Value=""Building2-FirstFloor""\n{\n    ""billingGroupArn"": ""arn:aws:iot:us-east-1:453102091241:billinggroup/Building2FirstFloorLightBulbs"",\n    ""billingGroupId"": ""af885c88-15b2-4f3d-8809-287e07c56338"",\n    ""billingGroupName"": ""Building2FirstFloorLightBulbs\n}\nBash\nIt is a best practice, when possible, to allocate things to billing group at thing creation time. When this is not possible, you must add things individually to the billing group.\n  In our example, ExampleCorp allocates things to the billing groups created for each area. The following CLI commands shows how to add things individually to an existing billing group.\n#add one thing to billing group\n[]   aws iot add-thing-to-billing-group --billing-group-name Building2FirstFloorLightBulbs --thing-name lightBulbs53\nBash\nWhen building areas are rented to a customer, billing groups can be tagged with the customer\xe2\x80\x99s name.\nFor example, if AnyCompany2 rents the First floor of building 2, this billing group may be tagged with a specific Tag CustomerName=AnyCompany2.\nNow, the previously created billing group is now tagged to the appropriate customer name (AnyCompany2).\n[]   aws resourcegroupstaggingapi tag-resources --resource-arn-list arn:aws:iot:us-east-1:453102091241:billinggroup/Building2FirstFloorLightBulbs --tags  ""customerName""=""AnyCompany2""\n{\n    ""FailedResourcesMap"": {}\n}\nBash\nThe previous command successfully added the tag in the billing group. To display billing groups in the AWS IoT Core console, choose Manage, Billing Groups, and select the billing group to display:\n  This same tag can be used for non-IoT resources to be part of cost allocation tags. When activated, cost allocation tags can be used as a dimension of grouping and filtering in Cost Explorer, as well as for refining AWS budget criteria.\nUsing tags with an IAM policy example\nAnother common use of tags is to have a fine-grained configurable set of IAM policies.\nThe following policy can be attached to any user related to a specific tenant (for instance, AnyCompany2 in this example) to allow them to send updates to device shadows. This is achieved by checking that both principal (the user) and resources (The Billing Group) have the same customerName tag (AnyCompany2).\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": ""iot:UpdateBillingGroup"",\n            ""Resource"": ""*"",\n            ""Condition"": {\n                ""StringEquals"": {\n                    ""aws:ResourceTag/customerName"": ""${aws:PrincipalTag/customerName}""\n                }\n            }\n        }\n    ]\n}\nJSON\nTo see a list of AWS IoT condition keys, see Condition Keys for AWS IoT in the IAM User Guide. To learn with which actions and resources you can use a condition key, see Actions Defined by AWS IoT.\nThe tagging is essential to tenant security. Policies can prevent unauthorized users from acting on tags, and to restrict which tag keys and values can be set to a resource or passed to an AWS command. For more information, see this tutorial on using tags for attribute-based Access control.\n'"
168,Implement a Connected Building with Amazon Alexa and AWS IoT,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/01/07/aws-iot-command-control-connected-device-alexa-architecture-1024x512.png,https://aws.amazon.com/blogs/iot/implement-a-connected-building-with-alexa-and-aws-iot/,"b'This post covers the use case of an organization creating voice-enabled features for its customers. The example use case is building a smart hotel environment that allows hotel guests and employees to use voice commands to control devices within hotel rooms. Throughout this post, we focus on the integration between Amazon Alexa, Amazon API Gateway, AWS Lambda, and AWS IoT Core.\nThe following are potential use cases for which a smart hotel might choose to build:\nHotel staff voice commands\n\xe2\x80\x9cAlexa, tell smart hotel skill to reset room 211.\xe2\x80\x9d\nThis triggers the smart TV, lights, vacuum, and shades to begin a new customer workflow.\n\xe2\x80\x9cAlexa, tell smart hotel skill to reset rooms 100 through 110.\xe2\x80\x9d\nThis triggers multiple rooms to begin a new customer workflow.\nCustomer voice commands\n\xe2\x80\x9cAlexa, tell smart hotel skill to set room temperature to 72 degrees.\xe2\x80\x9d\nThis sends a command to an AWS IoT Core enabled thermostat to change the temperature.\n\xe2\x80\x9cAlexa, tell smart hotel skill to order breakfast from room service.\xe2\x80\x9d\nThis notifies the hotel staff that the customer in a specified room wants a meal.\nWhy Amazon Alexa?\nAlexa is Amazon\xe2\x80\x99s cloud-based voice service available on over 100 million devices from Amazon and third-party device manufacturers. With Alexa, you can build natural voice experiences that offer customers a more intuitive way to interact with the devices they use every day. Using the Alexa Skills Kit, developers can build their own voice skill to be used on devices enabled by Alexa globally.\nWhy AWS IoT?\nBillions of devices are in homes, factories, oil wells, hospitals, cars, and thousands of other places. With the proliferation of devices, you increasingly need solutions to connect them and collect, store, and analyze device data. AWS IoT provides broad and deep functionality, spanning the edge to the cloud, so you can build IoT solutions for virtually any use case across a wide range of devices.\nCombining Amazon Alexa with AWS IoT\nWhen creating a smart building environment, utilizing both Amazon Alexa and AWS IoT enables builders to create an end-to-end voice-controlled building experience. Unlike traditional architectures, Amazon Alexa and AWS IoT allow for cost-optimized serverless workloads. This means that you don\xe2\x80\x99t have to provision long-running servers. Instead, your functions run only when users invoke Alexa with voice commands.\nPrerequisites\nAlexa Skills Kit account\nAmazon Web Services account\nAlexa device (Amazon Echo, Alexa mobile application, third-party hardware with Alexa, and others)\nArchitecture\nThis post walks you through the details of building this architecture on AWS.\nView the full architecture diagram on the Connected Home solution page.\nDeploy architecture in AWS account\nDownload the HotelBackEnd Lambda function zip file.\nUpload it to an S3 bucket in the same region you\xe2\x80\x99re working in. Note the name of your S3 bucket.\nDownload and deploy this AWS CloudFormation template.\nClick \xe2\x80\x9cRaw\xe2\x80\x9d button and copy/paste into text editor. Save as IoTBlog.yaml.\nDuring CloudFormation deployment, enter the S3 bucket name and file name (not including .zip) as parameters.\nAlexa skill creation\nThis post doesn\xe2\x80\x99t focus on the development of an Alexa skill. However, we cover some basics. For a more detailed introduction to developing Alexa skills, see the following resources:\nAlexa Skills Kit\nResources for Alexa Smart Home Developers\nFirst, navigate to the Alexa Console. Create an invocation name that your hotel customers and staff will use to invoke the skill. I\xe2\x80\x99ve set the invocation name of my skill to smart hotel. The invocation name should be two or more words and follow the Alexa Skills Kit guidelines.\nNext, we add our first intent. An intent represents an action that fulfills a user\xe2\x80\x99s spoken request. Intents are specified in a JSON structure called the intent schema. Each intent is mapped to several utterances. The sample utterances specify the words and phrases users can say to invoke your intents.\nWe create an intent called SetTemperature with many utterances that a user can say to map to this intent. Intents can optionally have arguments called slots. Slots allow for variables to be sent within the intent.\nWe set the slot by double clicking temp and selecting Add to create new slot. Scroll down and set the slot type to AMAZON.NUMBER. Verify all of the temp slots are highlighted as seen below. The intent is then passed to the backend for processing, which we cover shortly. See the following example:\n User: Alexa, ask Smart Hotel to set my temperature to 72 degrees.\nInvocation Name: Smart Hotel\nIntent: SetTemperature\nSlot: 72\nThe second intent is for the use case where a hotel employee wants to reset all the smart devices in a room to prepare for a new customer. Follow the same steps as before for the ResetRoom intent creation.\nIntent: ResetRoom\nSlot: roomNumber\nWe stop the Alexa Skill building here, but keep in mind that the skill would typically have many intents (SetLights, SetShades, StartVacuum, OrderRoomService, and more) with each intent holding a robust set of utterances. When done, choose Save, and then choose Build Model.\nNow that you have built your Alexa skill, you must link it with a Lambda function in order to pass the intent schema to be processed. In our case, we will be using Lambda and API Gateway to authenticate the user and send the command to IoT Core, which will handle the interaction with the hardware. To link the skill with Lambda, go to your AWS account and navigate to the SmartHotelBackend Lambda function. \nCopy the ARN of the Lambda function.\nPaste it in the Endpoint tab of the Alexa Developer Console. Make note of Your Skill ID. Choose Save Endpoints.\nChoose the Build tab, and then choose Build Model.\n\nNow copy the Skill ID and paste it into the Add trigger menu within your Lambda function.\n\nNavigate to Amazon API Gateway, and copy your API Invoke URL from Stages > smart-hotel-api.\n\nPaste the API Invoke URL into the environment variable section of your SmartHotelBackend Lambda function with api as the key.\nLambda and API Gateway\nThe Alexa Event Handler Lambda function receives the JSON payload from the Alexa skill and sends it to API Gateway for authentication and routing to the relevant Lambda function. Then, API Gateway authorizes the request using a Lambda authorizer. This function verifies the access token from the request and optionally checks it against an internal Amazon DynamoDB database. For example, the authorizer might look up the hotel customer\xe2\x80\x99s credentials to determine whether the user is authorized to receive the requested content.\nAfter the request has been authorized, API Gateway sends the request on to the specified API URI, which invokes the Lambda function associated with that specified logic. For this example, we send the request on to the Lambda function that triggers AWS IoT Core functionality.\nLambda authorizer template\nimport json\n\n#Format return policy that API Gateway expects\ndef generatePolicy(principalId, effect, resource):\n  return {\n    \'principalId\': principalId,\n    \'policyDocument\': {\n      \'Version\': \'2012-10-17\',\n      \'Statement\': [{\n        \'Action\': \'execute-api:Invoke\',\n        \'Effect\': effect,\n        \'Resource\': resource\n      }]\n    }\n  };\ndef customLogicFunction(token):\n    #Run your custom authorization here\n    #i.e. Check your DynamoDB table for token associated with user\n    #Return true or false\n\ndef lambda_handler(event, context):\n    \n    #if(customLogicFunction(event[\'authorizationToken\']) == true)\n        return generatePolicy(\'user\', \'Allow\', event[\'methodArn\'])\n    \n    #else\n      #return generatePolicy(\'user\', \'Deny\', event[\'methodArn\'])\nPython\nThis is the Lambda authorizer that does your custom authorization logic. Notice the format of response API Gateway is expecting. API Gateway passes the source token to this Lambda authorizer function in the event.authorizationToken attribute. The Lambda authorizer function reads the token and acts as follows:\nIf the token value is Allow, the authorizer function returns a 200 OK HTTP response and an IAM policy that looks like the following, and the method request succeeds:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Action"": ""execute-api:Invoke"",\n      ""Effect"": ""Allow"",\n      ""Resource"": ""arn:aws:execute-api:us-east-1:xxxxxxxxxxxx:m88ssxznb7/ESTestInvoke-stage/GET/""\n    }\n  ]\n}\nJSON\nFinally, be sure to set the Lambda function trigger to API Gateway, associate a role based on least privilege, and set the timeout time to 10 seconds.\nAPI Gateway\nThe CloudFormation template creates two URIs for our API. One is for authorized hotel staff to reset the room (\xe2\x80\x9cAlexa, tell smart hotel skill to reset room 211\xe2\x80\x9d), which will use the authorizer function. The second is for hotel guests to set the temperature (\xe2\x80\x9cAlexa, tell smart hotel skill to set room temperature to 72 degrees\xe2\x80\x9d), which will not need authorization. Each URI will have a method with a Lambda function that is called.\nThe first lambda function is for the room reset logic. We called this \xe2\x80\x9csmart-hotel-reset-room\xe2\x80\x9d. This function sends messages to the IoT Core topic associated with the specific room. Each device within the room is subscribed to it. Examples of this are turning off the TV, resetting room temperature, turning lights off, and closing the blinds.\nNotice the method request requires authorization using our custom authorizer function. This is to ensure only authorized hotel employees can reset the room.\n\nHere is the code that backs the /set-room resource:\nimport json\nimport boto3\nimport datetime\ntimestamp = datetime.datetime.utcnow().strftime(\'%Y-%m-%dT%H:%M:%S.%f\')\nclient = boto3.client(\'iot-data\')\n\n\ndef lambda_handler(event, context):\n    roomId = event[\'multiValueQueryStringParameters\'][\'room\'][0]\n    # TODO implement\n    temp = 72\n    response = client.publish(\n        topic = \'resetRoom\',\n        qos = 0,\n        payload = json.dumps({""roomid"": roomId, ""timestamp"": timestamp, ""shades"": ""up"", ""theater"": ""stopped"", ""thermostat"": temp})\n    )\n    return {\n        ""statusCode"": 200,\n    }\nPython\nThe second Lambda function is for customers to set the temperature. We called it \xe2\x80\x9csmart-hotel-set-temp\xe2\x80\x9d, and the code simply writes to the temperature topic for the specific room. The thermostat is subscribed to this topic. The roomId and temperature are passed in from the API gateway request. Note that we are not utilizing Device Shadow here. Part 2 of this post series will cover the hardware side of this solution and will utilize Device Shadow for devices with sporadic internet connection.\nimport json\nimport boto3\nimport datetime\ntimestamp = datetime.datetime.utcnow().strftime(\'%Y-%m-%dT%H:%M:%S.%f\')\nclient = boto3.client(\'iot-data\')\n\n\ndef lambda_handler(event, context):\n    temp = event[\'multiValueQueryStringParameters\'][\'temp\'][0]\n    print(event)\n    roomId = 101\n    response = client.publish(\n        topic = \'setTemp\',\n        qos = 0,\n        payload = json.dumps({""roomid"": roomId,""timestamp"": timestamp, ""thermostat"": temp })\n    )\n    return {\n        ""statusCode"": 200,\n    } \nPython\nWe do not authorize calls to this URI because the customers do not need an account to change their temperature.\nAlexa skill event handler\nThis function is named Alexa Event Handler in the architecture diagram above. This function is called whenever a user invokes the Smart Hotel Alexa Skill. It routes the command to the appropriate API method (either /set-temp or /set-room). As your skill becomes more complex, you add more resources or methods to your API to accommodate additional functionality.\nCreating an event handler for an Alexa skill can be the subject of a post in itself. However, we supply the following sample code that routes to either method based on specific intents. We created a SetTemp and ResetRoom intent in Alexa Skills Kit.\n\'use strict\';\nconst Alexa = require(\'alexa-sdk\');\nconst req = require(\'request\');\nconst APP_ID = undefined;\n\nconst SKILL_NAME = \'SmartHotel\';\nconst GET_FACT_MESSAGE = """";\nconst HELP_MESSAGE = \'Please repeat.\';\nconst HELP_REPROMPT = \'What can I help you with?\';\nconst STOP_MESSAGE = \'Goodbye!\';\n\n\nvar AWS = require(\'aws-sdk\');\nconst apiLink = process.env.api;\n\nconst handlers = {\n    \'LaunchRequest\': function () {\n        this.emit(\'SetTemperature\');\n    },\n    \'SetTemperature\': function () {\n        var temp = this.event.request.intent.slots.temp.value;\n        var url = apiLink + \'/set-temp?temp=\' + temp\n        req.post(url, function(err, res, body) {\n            if(err){\n                console.log(\'error\', err);\n            } else{\n                console.log(\'success\', body);\n            }\n        });\n        const speechOutput = \'Sounds good! I\\\'ve set your temperature to \' + temp;\n        this.response.cardRenderer(SKILL_NAME, speechOutput);\n        this.response.speak(speechOutput);\n        this.emit(\':responseReady\');\n    },\n    \'ResetRoom\': function () {\n        var room = this.event.request.intent.slots.roomNumber.value;\n        var postBody = {url: apiLink + \'/set-room?room=\' + room, \n                        headers: {Authorization: this.event.context.System.apiAccessToken}}\n        req.post(postBody, function(err, res, body) {\n            if(err){\n                console.log(\'error\', err);\n            } else{\n                console.log(\'success\', body);\n            }\n        });\n        const speechOutput = \'Okay! Resetting room \' + room + \' now.\';\n        this.response.cardRenderer(SKILL_NAME, speechOutput);\n        this.response.speak(speechOutput);\n        this.emit(\':responseReady\');\n    },\n    \'AMAZON.HelpIntent\': function () {\n        const speechOutput = HELP_MESSAGE;\n        const reprompt = HELP_REPROMPT;\n\n        this.response.speak(speechOutput).listen(reprompt);\n        this.emit(\':responseReady\');\n    },\n    \'AMAZON.CancelIntent\': function () {\n        this.response.speak(STOP_MESSAGE);\n        this.emit(\':responseReady\');\n    },\n    \'AMAZON.StopIntent\': function () {\n        this.response.speak(STOP_MESSAGE);\n        this.emit(\':responseReady\');\n    },\n};\n\nexports.handler = function (event, context, callback) {\n    const alexa = Alexa.handler(event, context, callback);\n    alexa.appId = APP_ID;\n    alexa.registerHandlers(handlers);\n    alexa.execute();\n};\nPython\nTesting\nNow that we\xe2\x80\x99ve set up our Alexa to AWS IoT architecture, let us see the topics where the messages are going. Go to AWS IoT Core, and choose the Test tab. Subscribe to the setTemp topic.\nIn a new tab, go to Alexa Skills Kit and choose the Test tab. Either speak through the microphone or type in the box to interact with your skill.\n\nNavigate back to the AWS IoT Core test console to see the message.\nYou can do the same for resetRoom topic.\nThis shows you the topic\xe2\x80\x99s incoming messages and simulates what the hardware device will subscribe to. When the device receives the setTemp message, it will grab the temperature value and change the temperature value of the device. The resetRoom topic will be subscribed to by multiple devices within the hotel room such as the shades, the thermostat, and the television or smart plug.\n'"
169,Asset Maintenance with AWS IoT services – Predict and respond to potential failures before they impact your business,b'Raleigh Murch',2020-04-30T21:16:32+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/image-4-1024x330-1.png,https://aws.amazon.com/blogs/iot/asset-maintenance-with-aws-iot-services-predict-and-respond-to-potential-failures-before-they-impact-your-business/,"b'AWS IoT customers manage a large number of industrial assets which send sensor data to the cloud. The smooth operation of these assets is critical to the productivity of their plants, since any equipment breakdown can lead to unexpected downtime and require expensive recovery maintenance. The ability to predict such failures and respond to them in a timely manner can help industrial users improve operational efficiency and total uptime. In this post, we describe how AWS IoT users can use AWS IoT Events to deploy an integrated asset maintenance solution using sensor data in combination with machine learning based predictive models to respond to potential failures.\nAWS IoT Events for asset maintenance\nAWS IoT Events is a fully managed service which makes it easy to detect and respond to events from IoT sensors or applications. Once an event has been detected, AWS IoT Events allows you to trigger actions to other AWS services. For example, you can use AWS IoT Events to combine multiple sources of telemetry data, inferences, and external data to determine whether an asset requires maintenance. Then, you can automatically trigger a notification through Amazon Simple Notification Service (SNS) to inform an operator on the plant floor about the required actions.\nOverview of asset maintenance strategies\nAn effective maintenance program allows industrial companies to reduce the likelihood of equipment failure. To achieve this, a typical solution requires multiple approaches to monitor assets. Each of these approaches can be defined by the number and variety of parameters analyzed, and has a \xe2\x80\x9cmaintenance maturity level\xe2\x80\x9d. Here are 3 common maturity levels that our customers consider:\nSchedule-based maintenance refers to the maintenance performed at periodic intervals, typically defined by the original equipment manufacturer (OEM). E.g. A pump has exceeded 100 hours of operation.\nCondition-based maintenance refers to the maintenance performed when predefined metric thresholds are breached. These thresholds can be defined by the operator or by the OEM. E.g. Pumping temperature of the fluid exceeds 200 deg C.\nPredictive (AI-based) maintenance refers to the maintenance activities that are triggered when there is a high likelihood of failure. The likelihood of failure can be determined using a machine learning algorithm on data coming from the sensors and other 3rd party systems, such as ERP or weather data. E.g. The probability of failure of the pump in the next 24 hours exceeds 50%.\nThe maintenance maturity level for an asset is based on 3 factors \xe2\x80\x93 data availability, accuracy of failure models, and cost of developing and maintaining an asset maintenance solution. A predictive maintenance solution, which requires continuous data gathering and intelligent insights, is ideal for critical assets where timely actions have a significant business impact.\nSolution\nLet us walk through how you can build a unified asset maintenance solution using AWS IoT services for all the maintenance maturity levels described above.\nConsider a scenario where a motor is pumping coolant fluid for a critical process. The motor and pump housing can have several sensors to capture metrics such as temperature and pressure at various points, and flow rate. These inputs can be used to predict failure and take action if you can model the likelihood of failure based on the behavior observed before each failure. The solution here is designed to send a push notification to the operator when the pump requires maintenance. This could be:\na scheduled maintenance required when the pump has been running for a fixed number of hours\nan unscheduled maintenance triggered by an abnormally high temperature for a defined period of time\nan unscheduled maintenance triggered when the pump has a high likelihood of failure, determined by the ML model\nThere are 4 steps in building a cloud based solution for this pump.\nCollect and ingest data into AWS cloud\nBuild a predictive machine learning model using historical data (cold path data flow)\nPredict failure with real time sensor data (hot path data flow)\nIdentify state of asset and take action\nReference architecture for Predictive Maintenance using AWS IoT services\nStep 1: Collect and ingest data into AWS cloud\nData is collected from industrial equipment (in this example, coolant pumps) through sensors. Sensor data can be transmitted from equipment and ingested into your AWS cloud in a number of ways. Some common choices include: (1) Direct ingest to AWS IoT Core, (2) Ingest to AWS IoT Core via AWS IoT Greengrass core running on a qualified gateway device, (3) Ingest via AWS IoT SiteWise Gateway. For this solution, we assume that the data has been ingested via AWS IoT Core.\nNote: For more information on ingesting data via AWS IoT Greengrass, read our blog post on Asset Condition Monitoring.\nStep 2: Build a machine learning model\nAfter you ingest data, you can send aggregated historical data into a separate pipeline to build and tune your machine learning model using Amazon SageMaker. We assume you have already set up Amazon SageMaker to tune your model and will not cover it here outside of showing where it sits in the reference architecture (cold path data flow). The output of this step is a machine learning model which predicts whether the coolant pump will fail in the next 24 hours for a given set of sensor readings.\nNote: To learn more about how to build and deploy a machine learning model, the Predictive Maintenance using Machine Learning solution on the AWS solutions page demonstrates how to use SageMaker with an example dataset.\nStep 3: Predict failure in real time\nTo predict failure on real time data, you need to call the machine learning model that you have built in Step 2. To do this:\na. Through the AWS Lambda console, create an AWS Lambda function which can call the SageMaker endpoint for each message received from the motor (for more details on the Lambda function, refer to the AWS Machine Learning blog post: Call an Amazon SageMaker model endpoint using Amazon API Gateway and AWS Lambda)\nb. Create two AWS IoT Events inputs (each input is a stream of data), which we will use later to define an event detector model. Input 1 (InputRawSensorData) will be used for the raw sensor data, whereas Input 2 (InputMLInference) will be used to handle machine learning inferences.\nCreating an input in AWS IoT Events\nc. Create a rule in AWS IoT Core to trigger 2 actions (to AWS Lambda and AWS IoT Events) when it receives real time messages from the motor. The first action triggers a Lambda function to compute the machine learning inference and pass the inference to AWS IoT Events for predictive maintenance. The second action sends the raw sensor data directly to AWS IoT Events for schedule and condition based maintenance.\nYou can do this from the AWS IoT Core console by clicking on Act in the left navigation. Then click on Create a rule.\nGo to AWS IoT and click on Create a rule (under Act > Rules in the left navigation)\nClick on Add action to configure the rule actions in AWS IoT Core to send raw sensor data to the AWS IoT Events detector model\nd. Go back to the Lambda function that you have created earlier, and use the BatchPutMessage function to send messages to the AWS IoT Events detector model for machine learning inferences (with the inputName defined in AWS IoT Events). The detector model uses this input along with the sensor data (input in c) to determine the state of the coolant pump.\n""messages"": [ \n    { \n        ""inputName"": ""InputMLInference"", \n        ""messageId"": ""string"", \n        ""payload"": json.dumps({\'motorID\': motorID, \'prediction\' : value}, indent = 4)\n    }\n ]\nJSON\nNow you\xe2\x80\x99re ready to ingest a test message from the coolant pump and run your machine learning model against it to compute the likelihood for pump failure!\nStep 4: Identify state of the asset and take action\nNow, you can use the two inputs generated from Step 3 in AWS IoT Events to determine the state of your coolant pump. AWS IoT Events provides a drag and drop interface to create a detector model. The detector model defines the states to be monitored, conditions to be evaluated and actions to be triggered for each event.\nCreate a detector model using the drag and drop canvas on the AWS IoT Events console\nYou can create \xe2\x80\x9cTransition events\xe2\x80\x9d to define how your asset moves from one state to another. For example, when the sensors detect that the speed of the pump is greater than 10 rpm (input from sensor TT01), the pump automatically moves from \xe2\x80\x9cmotor_off\xe2\x80\x9d to \xe2\x80\x9cmotor_on\xe2\x80\x9d. Just drag the cursor from one state to another to create a transition, and define the logic on the right pane.\nDefine a transition event in the AWS IoT Events canvas with simple conditional expressions\nWhen the detector model evaluates a new message from the coolant pump, event actions allow you to specify actions that should be taken in each state. Within each state, you can define event actions when the pump enters the state (OnEnter), receives an input and remains in the same state (OnInput), and when it exists the state (OnExit). In this example, AWS IoT Events sends a message to Amazon Simple Notification Service (SNS) when it enters a maintenance state such as \xe2\x80\x9cscheduled_service\xe2\x80\x9d. Users who need to be notified about the state change can subscribe to this SNS topic.\nDefine an action to notify an SNS topic when an event is detected\nThe screenshot below is a sample detector model for the pump maintenance use case. You can download the detector model as a json object and import it to your own AWS account using the import detector model option in the console. For scheduled maintenance, we have defined a variable to track the total runtime of the pump. When the runtime exceeds 100 hours, the state of the pump automatically changes to \xe2\x80\x9cscheduled_service\xe2\x80\x9d, and sends a push notification to a technician or a ticketing system via Amazon Simple Notification Service (SNS). For rule-based thresholds, you can use simple expressions using sensor inputs to trigger a state transition. In this example, we change the state of the pump to \xe2\x80\x9chigh_temperature\xe2\x80\x9d when the temperature threshold is breached continuously for 5 minutes or 3 continuous readings (alarm on-delay). You can also define a third maintenance state, \xe2\x80\x9clikely_failure_24hrs\xe2\x80\x9d when the probability of failure in the next 24 hours exceeds your decision threshold for prediction. When the operator completes the service, you can send another input to the detector model to change the state.\nTesting your detector model in AWS IoT Events\nOnce you have created all inputs and published your detector model, you can send sample messages through the AWS IoT Events console to test the detector model and trigger state transitions and actions. Click on Send data and select Send sample data. Then, choose the input name and enter the attributes you want to send. The first two messages will move the pump to the \xe2\x80\x9cmotor_off\xe2\x80\x9d state. Now you can send sensor data and see the state of the coolant pump change!\nHere is the preview of a sample message from the pump indicating that the speed is 80 rpm and temperature is 65 degrees Celsius.\nOpen the detector model in the AWS IoT Events console and click on Send data to send sample data\nThe current state of all detectors is displayed in the console. You can test sending another inference input (prediction = 1) to see the state of the pump change to \xe2\x80\x9clikely_failure_24hrs\xe2\x80\x9d.\nPrediction inputs can change the current state of the detector to \xe2\x80\x9clikely_failure_24hrs\xe2\x80\x9d\nAWS IoT Events is ideal for industrial use cases since it allows you to scale instantly when you want to expand this solution to other similar assets. By simply specifying a different key value in the input message, you can create any number of detector instances (or detectors) to detect the state every asset which follows the same transition path.\nResources\nCollecting and ingesting data with AWS IoT Core and AWS IoT Analytics\nhttps://aws.amazon.com/blogs/iot/using-aws-iot-services-for-asset-condition-monitoring/\nBuilding and training machine learning models with AWS IoT Core, AWS IoT Analytics and Amazon SageMaker\nhttps://aws.amazon.com/solutions/predictive-maintenance-using-machine-learning/\nDetect and respond to events at scale using AWS IoT Events\nhttps://aws.amazon.com/blogs/aws/new-aws-iot-events-detect-and-respond-to-events-at-scale/\nAWS CloudFormation Template for predictive maintenance solution\nhttps://github.com/aws-samples/aws-iot-events-accelerators/tree/master/integratingmachinelearning'"
170,"Collecting, organizing, monitoring, and analyzing industrial data at scale using AWS IoT SiteWise (Part 3)",b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/image-28-1024x713.png,https://aws.amazon.com/blogs/iot/collecting-organizing-monitoring-and-analyzing-industrial-data-at-scale-using-aws-iot-sitewise-part-3/,"b'Post by Asim Kumar Sasmal, Senior Data Architect in the IoT Global Specialty Practice of AWS Professional Services and Saras Kaul, Senior Product Manager of AWS IoT SiteWise.\n  [Before reading this post, read Part 1 and Part 2 in the series.]\nIn Part 1 of this series, you learned how to model and ingest data from industrial sites in a secure, cost-effective, and reliable manner using AWS IoT SiteWise (in preview).\nIn Part 2, you learned how to monitor key measurements and metrics of your assets in near-real time using SiteWise Monitor, a new capability of AWS IoT SiteWise.\nIn Part 3 (this post), you learn how to:\nSubscribe to the AWS IoT SiteWise modeled data via AWS IoT Core rules engine\nEnable conditions monitoring and send notifications or alerts using AWS IoT Events in near-real time\nEnable Business Intelligence (BI) reporting on historical data using Amazon QuickSight\nAbout AWS IoT Events\nAWS IoT Events is a fully managed service that makes it easy to detect and respond to events from IoT sensors and applications. It lets you monitor your equipment or device fleets for failures or changes in operation. It can also trigger actions when such events occur. For more information, see Getting Started with the AWS IoT Events Console.\nAbout Amazon QuickSight\nAmazon QuickSight is a fast business analytics service that you can use to:\nBuild visualizations\nPerform ad hoc analysis\nGet business insights quickly from your data in a self-serve fashion\nAs a fully managed and hosted service, there is no client-server to manage. With Amazon QuickSight, you can easily create and publish interactive dashboards that include built-in ML Insights. Access the dashboards from any device and embed them into your custom applications, portals, and websites. With pay-per-session pricing, Amazon QuickSight lets you give everyone access to the data they need, while only paying for what you use.\nSolution Overview\nAWS IoT SiteWise can publish asset data to AWS IoT via MQTT publish-subscribe message broker, so that you can interact with your asset data using other AWS services. With AWS IoT Core rules engine, you can conditionally route your data to other services. For this post, you ingest AWS IoT SiteWise modeled data into an AWS IoT Analytics Channel to transform the JSON messages slightly (mainly to flatten them) for querying from the AWS IoT Analytics Datastore. You then setup two AWS IoT Analytics Datasets \xe2\x80\x93 one dataset is to feed into an AWS IoT Events detector model for conditions monitoring of key aggregated metrics of your equipments and the other dataset is for BI reporting using Amazon QuickSight.\nThe following diagram illustrates the high-level end-to-end solution described in this multi-part post and shows the AWS services involved.\nWalkthrough\nThere are six sections in this walkthrough:\nSetting up an AWS IoT Analytics Channel, Pipeline, and Data Store\nSetting up an AWS IoT Core rule to ingest SiteWise modeled data into AWS IoT Analytics\nSetting up an AWS IoT Events detector model for conditions monitoring\nSetting up an AWS IoT Analytics dataset content delivery to the AWS IoT Events detector model\nSetting up an AWS IoT Analytics dataset to visualize in Amazon QuickSight\nVisualizing the AWS IoT Analytics dataset in Amazon QuickSight\nPrerequisites\nUse the prerequisites from Part 1.\nYou have an Amazon SNS topic named iote_send_email_sns_topic to receive email notification. Make a note of the SNS topic ARN, which you will use later.\nYou have an IAM role named iote_equip_temp_role with trust relationships for iotevents.amazonaws.com, iotanalytics.amazonaws.com, and iot.amazonaws.com. The role also has an IAM policy with the following permission on the SNS topic:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": ""sns:Publish"",\n            ""Resource"": ""arn:aws:sns:us-west-2:<AWS-Account-ID>:iote_send_email_sns_topic""\n        }\n    ]\n}\nJSON\nSetting up an AWS IoT Analytics Channel, Pipeline, and Datastore\nFollowing are the steps to setup an AWS IoT Analytics Channel, Pipeline, and Data Store:\nCreate an IAM policy named sitewise_blogpost_iota with the following permissions on the AWS IoT Analytics and attach that to the existing IAM role iote_equip_temp_role:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Action"": ""iotanalytics:BatchPutMessage"",\n            ""Resource"": ""*"",\n            ""Effect"": ""Allow""\n        }\n    ]\n}\nJSON\nCreate an AWS Lambda function named sitewise_blogpost_transform_function with the following Python 3.7 code:\nimport json\nimport logging\nimport sys\nimport time\n\n# Configure logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nstreamHandler = logging.StreamHandler(stream=sys.stdout)\nformatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\nstreamHandler.setFormatter(formatter)\nlogger.addHandler(streamHandler)\n\ndef lambda_handler(event, context):\n    logger.info(""event: {}"".format(event))\n    print(json.dumps(event, indent=2))\n    transformed = []\n    \n    for e in event:\n        logger.info(""e: {}"".format(json.dumps(e, indent=2)))\n        swtype=e[\'type\']\n        asset_id = e[\'payload\'][\'assetId\']\n        property_id = e[\'payload\'][\'propertyId\']\n        logger.info(""type: {} asset_id: {} property_id: {}"".format(swtype, asset_id, property_id))\n        row = {""type"": swtype, ""asset_id"": asset_id, ""property_id"": property_id}\n        for v in e[\'payload\'][\'values\']:\n            logger.info(""v: {}"".format(v))\n                \n            time_in_seconds = int(time.time())\n            if \'timestamp\' in v and \'timeInSeconds\' in v[\'timestamp\']:\n                logger.debug(""timeInSeconds in payload"")\n                time_in_seconds = v[\'timestamp\'][\'timeInSeconds\']\n                \n            value = """"\n            if \'doubleValue\' in v[\'value\']:\n                logger.debug(""doubleValue in payload"")\n                value = v[\'value\'][\'doubleValue\']\n                valuetype= ""double"" \n            if \'integerValue\' in v[\'value\']:\n                logger.debug(""integerValue in payload"")\n                value = v[\'value\'][\'integerValue\']\n                valuetype= ""integer"" \n            if \'booleanValue\' in v[\'value\']:\n                logger.debug(""booleanValue in payload"")\n                value = v[\'value\'][\'booleanValue\']\n                valuetype= ""boolean"" \n            if \'stringValue\' in v[\'value\']:\n                logger.debug(""stringValue in payload"")\n                value = v[\'value\'][\'stringValue\']\n                valuetype= ""string"" \n                \n            quality = """"\n            if \'quality\' in v:\n                logger.debug(""quality in payload"")\n                quality = v[\'quality\']\n                \n            row[\'timestamp\'] = time_in_seconds\n            row[\'quality\'] = quality\n            row[\'value\'] = value\n            row[\'valuetype\'] = valuetype\n            logger.debug(""row: {}"".format(row))\n            transformed.append(row)\n                \n    logger.info(""transformed: {}\\n"".format(json.dumps(transformed, indent=2)))\n\n    return transformed\nPython\nMake sure that you grant permission for AWS IoT Analytics service to execute the Lambda function above using the following AWS CLI command:\naws lambda add-permission --function-name \'sitewise_blogpost_transform_function\' --region \'us-west-2\' --statement-id 1234 --principal iotanalytics.amazonaws.com --action lambda:InvokeFunction --profile default\nCode\nCreate an AWS IoT Analytics Channel named sitewise_blogpost_channel with Service-managed Amazon S3 bucket as the storage type (default). You can also choose your own Amazon S3 buckets as the storage type.\naws iotanalytics create-channel --cli-input-json file://mychannel.json --region \'us-west-2\' --profile default\nCode\nThe file mychannel.json contains the following code:\n{\n    ""channelName"": ""sitewise_blogpost_channel""\n}\nJSON\nSample run output:\n{\n    ""channelArn"": ""arn:aws:iotanalytics:us-west-2:<AWS-Account-ID>:channel/sitewise_blogpost_channel"", \n    ""channelName"": ""sitewise_blogpost_channel"", \n    ""retentionPeriod"": {\n        ""unlimited"": true\n    }\n}\nCode\nCreate an AWS IoT Analytics Data Store named sitewise_blogpost_datastore with Service-managed Amazon S3 bucket as the storage type (default). You can also choose your own Amazon S3 buckets as the storage type.\naws iotanalytics create-datastore --cli-input-json file://mydatastore.json --region \'us-west-2\' --profile default\nCode\nThe file mydatastore.json contains the following code:\n{\n    ""datastoreName"": ""sitewise_blogpost_datastore""\n}\nJSON\nSample run output:\n{\n    ""datastoreName"": ""sitewise_blogpost_datastore"", \n    ""datastoreArn"": ""arn:aws:iotanalytics:us-west-2:<AWS-Account-ID>:datastore/sitewise_blogpost_datastore"", \n    ""retentionPeriod"": {\n        ""unlimited"": true\n    }\n}\nCode\nCreate an AWS IoT Analytics Pipeline named sitewise_blogpost_pipeline with the pipeline source as sitewise_blogpost_channel and the pipeline output as sitewise_blogpost_datastore.\naws iotanalytics create-pipeline --cli-input-json file://mypipeline.json --region \'us-west-2\' --profile default\nCode\nThe file mypipeline.json contains the following code:\n{\n    ""pipelineName"": ""sitewise_blogpost_pipeline"",\n    ""pipelineActivities"": [\n        {\n            ""channel"": {\n                ""name"": ""mychannelactivity"",\n                ""channelName"": ""sitewise_blogpost_channel"",\n                ""next"": ""mylambdaactivity""\n            }\n        },\n        {""lambda"": {\n                ""name"": ""mylambdaactivity"",\n                ""lambdaName"": ""sitewise_blogpost_transform_function"",\n                ""batchSize"": 10,\n                ""next"": ""mydatastoreactivity""\n            }\n        },\n        {\n            ""datastore"": {\n                ""name"": ""mydatastoreactivity"",\n                ""datastoreName"": ""sitewise_blogpost_datastore""\n            }\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""pipelineArn"": ""arn:aws:iotanalytics:us-west-2:<AWS-Account-ID>:pipeline/sitewise_blogpost_pipeline"", \n    ""pipelineName"": ""sitewise_blogpost_pipeline""\n}\nCode\nNote that the batch size is set to 10 for the Lambda invocation, which can be increased up to 1000 based on your SLA latency requirements and velocity of your streaming data.\nSetting up an AWS IoT Core rule to ingest SiteWise modeled data into AWS IoT Analytics\nCreate an AWS IoT Analytics rule that sends messages to the Channel that you created earlier.\nReplace the IAM role ARN with iote_equip_temp_role ARN.\naws iot create-topic-rule --rule-name sitewise_blogpost_rule_for_iota --topic-rule-payload file://rule.json --region \'us-west-2\' --profile default\nCode\nThe file rule.json contains the following code:\n{\n     ""sql"": ""SELECT * FROM \'$aws/sitewise/asset-models/+/assets/+/properties/+\'"",\n     ""ruleDisabled"": false,\n     ""awsIotSqlVersion"": ""2016-03-23"",\n     ""actions"": [\n         {\n             ""iotAnalytics"": {\n                 ""channelName"": ""sitewise_blogpost_channel"",\n                 ""roleArn"": ""arn:aws:iam::<AWS-ACCOUNT-ID>:role/iote_equip_temp_role""\n             }\n         }\n     ]\n }\nJSON\nAfter the rule is created, navigate to AWS IoT Analytics and create a test dataset by selecting a sample of 10 records from the sitewise_blogpost_datastore as below to make sure you are getting the data processed all the way through and available for querying using AWS IoT Analytics Dataset SQL query.\nSetting up an AWS IoT Events detector model for condition monitoring\nNow, to monitor the average equipment temperature during the last five minutes for the Unit 2 PLC of all three wind turbines, create an AWS IoT Events detector model named iote_equip_temp_detector_model.\nThe detector model has two states named Good and Critical. There may be a situation where the average equipment temperature climbs above a threshold of 70\xc2\xbaF (a manufacturer\xe2\x80\x99s specification) three times in a row. In that case, the detector model instance for the corresponding Wind Turbine\xe2\x80\x99s Unit 2 PLC switches its state from Good to Critical.\nSimilarly, the detector model instance switches its state from Critical to Good when the average equipment temperature drops below 70\xc2\xbaF three times in a row. Each state transition sends an email notification via Amazon SNS to your operations team to perform the necessary actions.\nUse the following steps to create the detector model.\nCreate an AWS IoT Events input named iote_equip_temp:\naws iotevents create-input --cli-input-json file://iote_equip_temp_input.json --region \'us-west-2\' --profile default\nCode\nThe file iote_equip_temp_input.json contains the following code:\n{\n    ""inputName"": ""iote_equip_temp"",\n    ""inputDescription"": ""IoT Events Equipment Temperature Monitoring"",\n    ""inputDefinition"": {\n        ""attributes"": [\n            {\n                ""jsonPath"": ""name""\n            },\n            {\n                ""jsonPath"": ""avg_value""\n            }\n        ]\n    }\n}\nJSON\nSample run output:\n{\n    ""inputConfiguration"": {\n        ""status"": ""ACTIVE"", \n        ""inputArn"": ""arn:aws:iotevents:us-west-2:<AWS-ACCOUNT-ID>:input/iote_equip_temp"", \n        ""lastUpdateTime"": 1574882105.027, \n        ""creationTime"": 1574882105.027, \n        ""inputName"": ""iote_equip_temp"", \n        ""inputDescription"": ""IoT Events Equipment Temperature Monitoring""\n    }\n}\nCode\nCreate an AWS IoT Events detector model named iote_equip_temp_detector_model:\naws iotevents create-detector-model --cli-input-json file://iote_equip_temp_detector_model.json --region \'us-west-2\' --profile default\nCode\nThe file iote_equip_temp_detector_model.json contains the following code (remember to replace the IAM role ARN for iote_equip_temp_role and SNS topic ARN for iote_send_email_sns_topic).\n{\n    ""detectorModelName"": ""iote_equip_temp_detector_model"",\n    ""detectorModelDescription"": ""AWS IoT Events Equipment Temperature Monitoring Detector Model"",\n    ""detectorModelDefinition"": {\n        ""states"": [\n            {\n                ""stateName"": ""Critical"",\n                ""onInput"": {\n                    ""events"": [\n                        {\n                            ""eventName"": ""DecrementcriticalCounter"",\n                            ""condition"": ""convert(Decimal,$input.iote_equip_temp.avg_value) <= 70"",\n                            ""actions"": [\n                                {\n                                    ""setVariable"": {\n                                        ""variableName"": ""criticalCounter"",\n                                        ""value"": ""$variable.criticalCounter - 1""\n                                    }\n                                }\n                            ]\n                        }\n                    ],\n                    ""transitionEvents"": [\n                        {\n                            ""eventName"": ""to_Good"",\n                            ""condition"": ""$variable.criticalCounter <= 1"",\n                            ""actions"": [\n                                {\n                                    ""sns"": {\n                                        ""targetArn"": ""arn:aws:sns:us-west-2:<AWS-ACCOUNT-ID>:iote_send_email_sns_topic""\n                                    }\n                                }\n                            ],\n                            ""nextState"": ""Good""\n                        }\n                    ]\n                },\n                ""onEnter"": {\n                    ""events"": []\n                },\n                ""onExit"": {\n                    ""events"": []\n                }\n            },\n            {\n                ""stateName"": ""Good"",\n                ""onInput"": {\n                    ""events"": [\n                        {\n                            ""eventName"": ""IncrementcriticalCounter"",\n                            ""condition"": ""convert(Decimal,$input.iote_equip_temp.avg_value)  > 70"",\n                            ""actions"": [\n                                {\n                                    ""setVariable"": {\n                                        ""variableName"": ""criticalCounter"",\n                                        ""value"": ""$variable.criticalCounter + 1""\n                                    }\n                                }\n                            ]\n                        },\n                        {\n                            ""eventName"": ""ResetcriticalCounter"",\n                            ""condition"": ""convert(Decimal,$input.iote_equip_temp.avg_value) <= 70"",\n                            ""actions"": [\n                                {\n                                    ""setVariable"": {\n                                        ""variableName"": ""criticalCounter"",\n                                        ""value"": ""0""\n                                    }\n                                }\n                            ]\n                        }\n                    ],\n                    ""transitionEvents"": [\n                        {\n                            ""eventName"": ""to_Critical"",\n                            ""condition"": ""$variable.criticalCounter >= 2"",\n                            ""actions"": [\n                                {\n                                    ""sns"": {\n                                        ""targetArn"": ""arn:aws:sns:us-west-2:<AWS-ACCOUNT-ID>:iote_send_email_sns_topic""\n                                    }\n                                }\n                            ],\n                            ""nextState"": ""Critical""\n                        }\n                    ]\n                },\n                ""onEnter"": {\n                    ""events"": [\n                        {\n                            ""eventName"": ""Initialization"",\n                            ""condition"": ""true"",\n                            ""actions"": [\n                                {\n                                    ""setVariable"": {\n                                        ""variableName"": ""criticalCounter"",\n                                        ""value"": ""0""\n                                    }\n                                }\n                            ]\n                        }\n                    ]\n                },\n                ""onExit"": {\n                    ""events"": []\n                }\n            }\n        ],\n        ""initialStateName"": ""Good""\n    },\n    ""roleArn"": ""arn:aws:iam::<AWS-ACCOUNT-ID>:role/iote_equip_temp_role"",\n    ""key"": ""name""\n}\nJSON\nSample run output:\n{\n    ""detectorModelConfiguration"": {\n        ""status"": ""ACTIVATING"", \n        ""detectorModelDescription"": ""AWS IoT Events Equipment Temperature Monitoring Detector Model"", \n        ""lastUpdateTime"": 1574882287.039, \n        ""roleArn"": ""arn:aws:iam::<AWS-ACCOUNT-ID>:role/iote_equip_temp_role"", \n        ""creationTime"": 1574882287.039, \n        ""detectorModelArn"": ""arn:aws:iotevents:us-west-2:<AWS-ACCOUNT-ID>:detectorModel/iote_equip_temp_detector_model"", \n        ""key"": ""name"", \n        ""detectorModelName"": ""iote_equip_temp_detector_model"", \n        ""detectorModelVersion"": ""1""\n    }\n}\nCode\nIn case you wonder about the condition \xe2\x80\x9c$variable.criticalCounter >= 2\xe2\x80\x9d for transition event \xe2\x80\x9cto_Critical\xe2\x80\x9d that should have been \xe2\x80\x9c>=3\xe2\x80\x9d, it is due to a current limitation in AWS IoT Events.\nIn the AWS IoT Events console, choose Detector models and select iote_equip_temp_detector_model. Choose Edit and verify the detector model that you just created in the AWS CLI.\nCreate a new IAM policy or modify the existing policy of your IAM role iote_equip_temp_role with the following permissions on the AWS IoT Events input (iote_equip_temp) that you created earlier:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": ""iotevents:BatchPutMessage"",\n            ""Resource"": [\n                ""arn:aws:iotevents:us-west-2:<AWS-ACCOUNT-ID>:input/iote_equip_temp""\n            ]\n        }\n    ]\n}\nJSON\nRemember to replace the IAM role ARN of your AWS IoT Events input iote_equip_temp noted earlier.\nSetting up an AWS IoT Analytics dataset content delivery to the AWS IoT Events detector model\nNow that you have created your AWS IoT Events detector model, create an AWS IoT Analytics Dataset named iote_equip_temp_dataset. The content delivery target is the AWS IoT Events detector model input \xe2\x80\x93 iote_equip_temp.\nRemember to replace the IAM role ARN as well as the assed_id and property_id for your environment. To get the asset_id and property_id, you can use list-asset to list all your assets and then describe-asset. You can also get the human readable name of the asset property from describe-asset API.\naws iotanalytics create-dataset --cli-input-json file://mydataset.json --region \'us-west-2\' --profile default\nCode\nThe file mydataset.json contains the following code:\n{\n    ""datasetName"": ""iote_equip_temp_dataset"",\n    ""actions"": [\n        {\n            ""actionName"": ""myaction"",\n            ""queryAction"": {\n                ""sqlQuery"": ""SELECT Replace(Replace(asset_property_name, \'/\', \'-\'), \' \') name, avg_value FROM   (SELECT CASE WHEN asset_id = \'4be96ade-55ec-40fd-b2ed-277bdcb83a4e\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 1/Unit 2 PLC/Equipment Temperature\' WHEN asset_id = \'6390c711-86ea-4d58-a97a-3b52f43388aa\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 2/Unit 2 PLC/Equipment Temperature\' WHEN asset_id = \'a5642995-b599-4449-a0db-ea5de7e074af\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 3/Unit 2 PLC/Equipment Temperature\' ELSE \'unknown\' END                        asset_property_name, Avg(Cast(value AS DOUBLE)) AS avg_value FROM   sitewise_blogpost_datastore WHERE  From_unixtime(timestamp) > current_timestamp - interval \'5\' minute AND asset_id IN ( \'4be96ade-55ec-40fd-b2ed-277bdcb83a4e\', \'6390c711-86ea-4d58-a97a-3b52f43388aa\', \'a5642995-b599-4449-a0db-ea5de7e074af\' ) AND property_id IN ( \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\') GROUP  BY 1)temp""\n            }\n        }\n    ],\n    ""contentDeliveryRules"": [\n        {\n            ""destination"": {\n                ""iotEventsDestinationConfiguration"": {\n                    ""inputName"": ""iote_equip_temp"",\n                    ""roleArn"": ""arn:aws:iam::<AWS-ACCOUNT-ID>:role/iote_equip_temp_role""\n                }\n            }\n        }\n    ],\n    ""triggers"": [\n        {\n            ""schedule"": {\n                ""expression"": ""cron(0/5 * * * ? *)""\n            }\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""datasetName"": ""iote_equip_temp_dataset"", \n    ""datasetArn"": ""arn:aws:iotanalytics:us-west-2:<AWS-ACCOUNT-ID>:dataset/iote_equip_temp_dataset""\n}\nCode\nAfter the dataset is created, either wait five minutes for the dataset to run as scheduled or run it manually from AWS CLI as follows:\naws iotanalytics create-dataset-content --dataset-name ""iote_equip_temp_dataset"" --region \'us-west-2\' --profile default\nCode\nSample run output:\n{\n    ""versionId"": ""f2ade0be-092f-4686-a4aa-8ecbc967cb5c""\n}\nCode\nWait for the content to be created by running the following command. The state should show as SUCCEEDED for your dataset content to be available on Amazon S3.\naws iotanalytics get-dataset-content --dataset-name ""iote_equip_temp_dataset"" --region \'us-west-2\' --profile default\nCode\nSample run output:\n{\n    ""status"": {\n        ""state"": ""SUCCEEDED""\n    }, \n    ""timestamp"": 1574642608.767, \n    ""entries"": [\n        {\n            ""dataURI"": ""https://aws-iot-analytics-dataset-cb3a5eef-4a9f-423c-8fd7-beb9ee6210d5xxxxxxxxxxxxx""\n        }\n    ]\n}\nCode\nYour AWS IoT Analytics Dataset results are sent to the AWS IoT Events detector model.\nIn the AWS IoT Events console, choose Detector models, iote_equip_temp_detector_model to see the three detector model instances \xe2\x80\x93 one for each Unit 2 PLC of all three Wind Turbines.\nAfter the AWS IoT Analytics dataset ran a few times as scheduled, all three Unit 2 PLC from the three Wind Turbines transitioned from a Good to a Critical state as shown below:\nYou should have received a similar email as below indicating the Critical status for Unit 2 PLC.\nSetting up an AWS IoT Analytics Dataset to visualize in Amazon QuickSight\nOne of your requirements for an end-to-end use case is to visualize the lowest-grain Equipment Temperature readings for all three Wind Turbines for the last hour in Amazon QuickSight.\nCreate an AWS IoT Analytics Dataset named quicksight_equip_temp_dataset producing the lowest-grain equipment temperature readings for the last hour for all three Wind Turbines as follows.\nRemember to replace the asset_id and property_id for your environment. To get the asset_id and property_id, you can use list-asset to list all your assets and then describe-asset. You can also get the human readable name of the asset property from describe-asset API.\naws iotanalytics create-dataset --cli-input-json file://mydataset2.json --region \'us-west-2\' --profile default\nCode\nThe file mydataset2.json contains the following code:\n{\n    ""datasetName"": ""quicksight_equip_temp_dataset"",\n    ""actions"": [\n        {\n            ""actionName"": ""myaction"",\n            ""queryAction"": {\n                ""sqlQuery"": ""SELECT timestamp, equip_temp, Replace(Replace(asset_property_name, \'/\', \'-\'), \' \') name FROM   (SELECT CASE WHEN asset_id = \'4be96ade-55ec-40fd-b2ed-277bdcb83a4e\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 1/Unit 2 PLC/Equipment Temperature\' WHEN asset_id = \'6390c711-86ea-4d58-a97a-3b52f43388aa\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 2/Unit 2 PLC/Equipment Temperature\' WHEN asset_id = \'a5642995-b599-4449-a0db-ea5de7e074af\' and property_id = \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\' THEN \'/Wind Turbine 3/Unit 2 PLC/Equipment Temperature\' ELSE \'unknown\' END                        asset_property_name, From_unixtime(timestamp) AS timestamp, Cast(value AS DOUBLE)    AS equip_temp FROM   sitewise_blogpost_datastore WHERE  From_unixtime(timestamp) > current_timestamp - interval \'1\' hour AND asset_id IN ( \'4be96ade-55ec-40fd-b2ed-277bdcb83a4e\', \'6390c711-86ea-4d58-a97a-3b52f43388aa\', \'a5642995-b599-4449-a0db-ea5de7e074af\' ) AND property_id IN ( \'912e4cc3-7ceb-4b1f-951e-ffacc618f7dc\'))temp""\n            }\n        }\n    ],\n    ""triggers"": [\n        {\n            ""schedule"": {\n                ""expression"": ""cron(0 * * * ? *)""\n            }\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""datasetName"": ""quicksight_equip_temp_dataset"", \n    ""datasetArn"": ""arn:aws:iotanalytics:us-west-2:<AWS-ACCOUNT-ID>:dataset/quicksight_equip_temp_dataset""\n}\nCode\nAs explained earlier, after the AWS IoT Analytics dataset is created, either wait for the dataset to run as scheduled (which in this case is one hour) or run it manually from the AWS CLI.\nVisualizing the AWS IoT Analytics Dataset in Amazon QuickSight\nAWS IoT Analytics provides direct integration with Amazon QuickSight. To visualize the AWS IoT Analytics dataset quicksight_equip_temp_dataset, see Visualizing AWS IoT Analytics Data with QuickSight.\nAfter you create an Amazon QuickSight Dataset for your AWS IoT Analytics Dataset (quicksight_equip_temp_dataset), you can create a sample analysis.\nSummary\nIn Part 3 of this multi-part series, you subscribed to the AWS IoT SiteWise modeled data via AWS IoT Core rules engine, enabled condition monitoring and send notifications or alerts using AWS IoT Events in near-real time, and finally, enabled Business Intelligence (BI) reporting on historical data using Amazon QuickSight.\nThis multi-part series described a secure, cost-effective, and reliable field-to-cloud solution. You learned how to:\nIngest all your data from hundreds of industrial sites that have tens of thousands of PLCs and sensors\nVisualize key measurements and metrics for the devices, processes, and equipment in near-real time\nEnable condition monitoring and send notifications and alerts in near-real time to take actions when needed\nEnable Business Intelligence (BI) reporting on historical data for reporting\nHopefully, you have found this post informative and the proposed solution walkthrough helpful. As always, AWS welcomes feedback. Please submit comments or questions below.'"
171,"Collecting, organizing, monitoring, and analyzing industrial data at scale using AWS IoT SiteWise (Part 2)",b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/image-26-1024x505.png,https://aws.amazon.com/blogs/iot/collecting-organizing-monitoring-and-analyzing-industrial-data-at-scale-using-aws-iot-sitewise-part-2/,"b'Post by Asim Kumar Sasmal, Senior Data Architect in the IoT Global Specialty Practice of AWS Professional Services and Sourav Chakraborty, Senior Product Manager of AWS IoT SiteWise.\n  [Before reading this post, read Part 1 in the series.]\nIn Part 1 of this series, you learned how to model and ingest data from industrial sites in a secure, cost-effective, and reliable manner using AWS IoT SiteWise (in preview).\nIn Part 2 (this post), you learn how to:\nMonitor key measurements and metrics of your assets and take necessary actions when required in near-real time using SiteWise Monitor, a new capability of AWS IoT SiteWise.\nIn Part 3, you learn how to:\nSubscribe to the AWS IoT SiteWise modeled data via AWS IoT Core rules engine\nEnable condition monitoring and send notifications or alerts using AWS IoT Events in near-real time\nEnable Business Intelligence (BI) reporting on historical data using Amazon QuickSight\nAbout SiteWise Monitor\nSiteWise Monitor is a new feature of AWS IoT SiteWise that provides managed web applications that you can use to view, monitor, and share operational data from your processes and equipment at scale. Access to the web portal is controlled through your enterprise identity by using AWS Single Sign-On (SSO). That means your domain experts, such as Process Engineers, can sign in to a SiteWise Monitor web application from a desktop or mobile browser without needing access to your AWS account. SiteWise Monitor helps users interactively view live and historical process and equipment data.\nSolution Architecture\nThe following diagram illustrates the high-level end-to-end solution described in this multi-part post along with the AWS services used in the solution.\nWalkthrough\nThere are two sections in this walk-through:\nSetting up the Monitor Portal in AWS IoT SiteWise\nMonitoring key measurements and metrics in near-real time\nPrerequisites\nUse the prerequisites from Part 1.\nSetting up the Monitor Portal in AWS IoT SiteWise\nIn Part 1 of this multi-part series, you have modeled your industrial assets and started the data ingestion into AWS IoT SiteWise from the OPC-UA server (KEPServerEX). You can now setup a web application, called a portal, with SiteWise Monitor to visualize the key measurements and metrics in near-real time.\nSiteWise Monitor provides three personas/roles within your organization \xe2\x80\x93 Portal administrator, Project owner, and Project viewer. An IT administrator in your organization creates portals and assigns Portal administrators and Portal users. Once a portal is created, a Portal administrator creates a Project with a collection of assets and dashboards, and assigns an owner to each project. A Project owner is an author who creates the visualization dashboards to represent your operational data and when ready, shares with the Project viewers.\nTo set up a portal to view your AWS IoT SiteWise data, perform the four steps below :\nEnable AWS SSO. This is an optional step if you already have AWS SSO setup, otherwise SiteWise Monitor will set it up and allow the IT administrator to create the first native user \xe2\x80\x93 all from within the AWS IoT SiteWise console.\nConfigure and create a Portal with a name of your choice. For this post, akstest-sitewise-monitor is the portal name\nAdd Portal administrators\nAdd users and send an invitation email to Portal administrators\nFor more information, see Getting Started.\nFollowing the above steps, you setup the portal and see the list of portals in the AWS IoT SiteWise Console as shown below:\nMonitoring key measurements and metrics in near-real time\nOnce you setup your portal and are logged in as a Portal administrator, follow the steps below to create sample dashboards of your Wind Turbine data:\nIn the navigation pane of AWS IoT SiteWise Console, choose Monitor, then Portals and then click on the URL link to get to the Portal and visualize your assets. \nExpand the left pane of the Portal and click on Projects to choose either an existing project or create a new project. For this walk-through, click on Create project to create a new project named Monitor Wind Farm. \nScroll down to Project assets section of the portal and click on Go to asset library to add your Wind Turbine asset hierarchy named Wind Farm to the Monitor Wind Farm project.\nClick on Add asset to project, select your existing Monitor Wind Farm project, and click on Add asset to project.\nClick on Create dashboard and then click on Add assets to dashboard and Edit to author your dashboard.Provide a name to your dashboard as Wind Turbine 1 \xe2\x80\x93 PLC Unit 1 (East) and then expand the asset hierarchy on the right side to drag and drop Max Generated Power, Generated Power, Average Wind Speed, and Wind Speed for Wind Turbine 1 \xe2\x80\x93 PLC Unit 1 you wish to monitor. Choose the appropriate chart type from the options based on your requirement. Click on Done once done to finish your dashboard creation and visualize.\nNavigate to Projects, Wind Farm and share the project to your Project owners and Project viewers as required.\nSummary\nIn Part 2 of this two-part series, you learned how to monitor key measurements and metrics of your assets and take necessary actions when required in near-real time using SiteWise Monitor, a new capability of AWS IoT SiteWise.\nIn Part 3, you will learn how to:\nSubscribe to the AWS IoT SiteWise modeled data via AWS IoT Core rules engine\nEnable condition monitoring and send notifications or alerts using AWS IoT Events in near-real time\nEnable Business Intelligence (BI) reporting on historical data using Amazon QuickSight\nHopefully, you have found this post informative and the solution helpful. As always, AWS welcomes feedback. Please submit comments or questions below.'"
172,"Collecting, organizing, monitoring, and analyzing industrial data at scale using AWS IoT SiteWise (Part 1)",b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/image-1-1-1024x713.png,https://aws.amazon.com/blogs/iot/collecting-organizing-monitoring-and-analyzing-industrial-data-at-scale-using-aws-iot-sitewise-part-1/,"b'Post by Saras Kaul, Senior Product Manager of IoT SiteWise, Asim Kumar Sasmal, Senior Data Architect, and Mark Gilbert, Senior Consultant in the IoT Global Specialty Practice of AWS Professional Services.\n  Industrial customers have been looking for a secure, cost-effective, and reliable field-to-cloud solution that does the following:\nIngests all their data from hundreds of industrial sites that have tens of thousands of PLCs and sensors\nVisualizes key measurements and metrics for the devices, processes, and equipment in near-real time\nEnables condition monitoring and send notifications and alerts in near-real time to take actions when needed\nEnables Business Intelligence (BI) on historical data for reporting\nIn this multi-part post, we will walk you through examples of how AWS IoT is helping customers solve these core challenges.\nIn Part 1 (this post), you learn how to:\nCreate virtual representations of your industrial assets using AWS IoT SiteWise\nCollect and ingest data locked away in your industrial sites to AWS IoT SiteWise\nFor this post, we will use a KEPServerEX simulator driver from Kepware as the OPC-UA server for AWS IoT SiteWise to subscribe to the data. However, you can use any OPC-UA server of your choice.\nIn Part 2, you learn how to:\nMonitor key operating parameters and performance metrics for your assets using SiteWise Monitor, a new capability of AWS IoT SiteWise, and take necessary actions when needed in near-real time\nIn Part 3, you learn how to:\nStream modeled equipment data in real-time from AWS IoT SiteWise to be consumed by custom applications via AWS IoT Core rules engine\nEnable condition monitoring and send notifications or alerts using AWS IoT Events in near-real time\nEnable Business Intelligence (BI) reporting on historical data using Amazon QuickSight\nAbout AWS IoT SiteWise\nAWS IoT SiteWise is a fully managed AWS IoT service that you can use to collect, organize, and analyze data from industrial equipment at scale. AWS IoT SiteWise enables you to collect data on the plant floor from sensors, equipment, or a local on-premises gateway and upload to AWS cloud using a gateway software (AWS IoT SiteWise Connector). AWS IoT SiteWise Connector runs on common industrial gateway devices running AWS IoT Greengrass, and reads data directly from servers and historians over the OPC-UA protocol. You can then structure and organize data using a rich asset-modeling framework to create virtual representations of equipment and processes. The data ingested and modeled in AWS IoT SiteWise is stored in a scalable and time-optimized internal data store. Once data is stored in AWS IoT SiteWise, you can stream live data in near real-time and query historical data to build downstream IoT applications. With the recently announced SiteWise Monitor capability of AWS IoT SiteWise, you can explore your library of assets, and create and share operational dashboards with plant operators for real-time monitoring and visualization of equipment health and output. To learn more about what\xe2\x80\x99s new with AWS IoT SiteWise, visit to What\xe2\x80\x99s new.\nSolution Architecture\nThe following diagram illustrates the high-level end-to-end solution described in this multi-part post along with the AWS services used in the solution.\nWalkthrough\nThere are five sections in this step-by-step walk-through:\nPrerequisites\nSetting up KEPServerEX with sample data\nSetting up AWS IoT Greengrass and deploying AWS IoT SiteWise gateway software\nModeling your assets in AWS IoT SiteWise\nSetting up AWS IoT SiteWise gateway for data ingestion\nPrerequisites\nThis example uses the US West (Oregon) Region. However, you can choose another AWS Region of your choice where AWS IoT SiteWise (in preview), AWS IoT Analytics, and AWS IoT Events services are available. Visit the AWS Region table for a full list of AWS Regions where AWS services are available.\nYou have an AWS account in the same AWS Region.\nYou have the AdministratorAccess policy granted to your AWS account (for production, we recommend restricting access as needed).\nYou have AWS CLI installed and configured to use with your AWS account.\nThis example uses simulated Wind Turbine data using KEPServerEX from Kepware (a third-party software) as the OPC-UA server and its simulator driver. If you have any questions regarding KEPServerEX, please contact Kepware for support.\nSetting up KEPServerEX with sample data\nLaunch an Amazon EC2 Windows instance (t2.medium, Windows Server 2019 for this post) by following the instructions in Getting Started with Amazon EC2 Windows Instances.\nDownload and install the free demo for KEPServerEX from Kepware on the EC2 instance.\nMake sure that the EC2 instance\xe2\x80\x99s security group inbound rule allows traffic for the port number that you plan to use with the OPC-UA endpoint. This post uses the default port number 49320.\nFor the message security policy, choose Basic128Rsa15 \xe2\x80\x93 Sign and encrypt.\nRight click on Project and navigate to Properties, Property Editor. Choose Allow anonymous login option as Yes for OPC UA (if default is No) from the Property Editor as shown below and click on Apply:\nAfter KEPServerEX is set up, log in to the Windows machine to set up the three wind turbines (Wind Turbine 1, Wind Turbine 2, Wind Turbine 3) using the KEPServerEX simulator driver.\nAs shown in the following screenshot, each wind turbine has two PLC units:\nUnit 1 has three tags: Power, Rotor Speed, and Wind Speed\nUnit 2 has two tags: Equipment Temperature and Outside Temperature\nAfter the tags are created, monitor the simulated values by launching the OPC Quick Client (shown in the screenshot above) to validate the data simulation. The following screenshot shows the OPC Quick Client display when Wind Turbine 1.Unit 1 PLC is selected.\nThe following screenshot shows the OPC Quick Client display when Wind Turbine 1.Unit 2 PLC is selected.\nSetting up AWS IoT Greengrass and deploying AWS IoT SiteWise gateway software\nNow that KEPServerEX is set up to simulate the required sample data for this walkthrough, set up AWS IoT Greengrass on your device gateway.\nFor this post, you use an Amazon EC2 Linux instance instead of a real industrial gateway device. AWS IoT SiteWise supports x86_64 and ARMv7l CPU architecture-based device gateways.\nUse the following steps to set up AWS IoT Greengrass on the EC2 Linux instance.\nCreate an IAM role named SiteWiseDemo with required permissions using the steps in Create an IAM Policy and Role. Make a note of the IAM role ARN, which you will use later.\nLaunch an EC2 Linux instance (t2.medium), using the steps in Getting Started with AWS IoT Greengrass \xe2\x80\x93 Module 1 \xe2\x80\x93 Setting Up an Amazon EC2 Instance.\nAfter the EC2 instance is launched and is in running status, connect to the EC2 instance by using SSH\nMake sure that your EC2 Linux instance has the pre-requisites as noted, specifically the following:\nx86 64-bit architecture\nOpenJDK 8 (not an earlier or later version). Execute sudo yum install java-1.8.0 to install the required version (if needed).\nTo allow AWS IoT Greengrass to use Java, you need to create a java8 symbolic link to the Java executable (if not already setup by the Java 8 installation earlier). Execute sudo ln -s /usr/bin/java /usr/bin/java8 to create the symbolic link (if needed). Execute java8 -version to validate the symbolic link pointing to 1.8.x version.\nCreate a /var/sitewise data directory and give the ggc_user permissions for that directory using the commands below. AWS IoT SiteWise uses this directory to store system data.\nsudo mkdir /var/sitewise\nsudo chown ggc_user /var/sitewise\nsudo chmod 700 /var/sitewise\nBash\nThe /var/sitewise is the default directory which you can customize (for example, replace /var/sitewise with /var/custom/path/). Doing so requires extra steps after the AWS IoT SiteWise gateway is created. For more information, see step 5 in Configure the AWS IoT SiteWise Connector.\nAfter EC2 instance configuration is complete, follow the instructions in Module 2: Installing the AWS IoT Greengrass Core Software to install AWS IoT Greengrass software (version 1.9.4 or later) on the EC2 instance and also create an AWS IoT Greengrass group named sitewise_gg. Only execute the instructions up to Module 2 from the AWS IoT Greengrass Getting Started guide.\nTo attach the IAM role SiteWiseDemo to the AWS IoT Greengrass group sitewise_gg you just created, follow the steps in Attach an IAM Role to an AWS IoT Greengrass Group.\nAWS IoT SiteWise gateway is a software which is available as an AWS IoT Greengrass Connector. A Unix shell script below deploys the AWS IoT SiteWise Connector (replace the GG_GROUP_ID, GG_GROUP_NAME, REGION, and PROFILE parameters from your environment). If you have the AWS CLI available and configured for your environment, execute the shell script from your laptop or from the EC2 instance.\n#!/bin/bash\n\nexport GG_GROUP_ID=""xxxx""\nexport GG_GROUP_NAME=""xxxx""\nexport REGION=""xxxx""\nexport PROFILE=""xxxx""\n\nCOMMAND=""aws --region $REGION greengrass --profile $PROFILE""\nGG_LIST_GROUPS_RESULT=`$COMMAND list-groups | jq "".Groups[] | select(.Name == \\""$GG_GROUP_NAME\\"")""`\nGG_GROUP_VERSION=`echo $GG_LIST_GROUPS_RESULT | jq -r \'.LatestVersion\'`\n\nfunction add_connector {\n     GET_GROUP_VERSION_RESULT=`$COMMAND get-group-version --group-id $GG_GROUP_ID --group-version-id $GG_GROUP_VERSION`\n \n     CREATE_CONNECTOR_DEFINITION_RESULT=`$COMMAND create-connector-definition --name $GG_GROUP_NAME --initial-version ""{ \\\n         \\""Connectors\\"": [ \\\n             { \\\n                 \\""Id\\"": \\""MySiteWiseConnector\\"", \\\n                 \\""ConnectorArn\\"": \\""arn:aws:greengrass:$REGION::/connectors/IoTSiteWise/versions/5\\"", \\\n                 \\""Parameters\\"": { \\\n                 } \\\n             } \\\n         ] \\\n     }""`\n \n     CONNECTOR_DEFINITION_ARN=`echo $CREATE_CONNECTOR_DEFINITION_RESULT | jq -r "".LatestVersionArn""`\n \n     CORE_DEFINITION_ARN=`echo $GET_GROUP_VERSION_RESULT | jq -r "".Definition.CoreDefinitionVersionArn""`\n     CREATE_GROUP_VERSION_RESULT=`$COMMAND create-group-version --group-id $GG_GROUP_ID --core-definition-version-arn $CORE_DEFINITION_ARN --connector-definition-version-arn $CONNECTOR_DEFINITION_ARN`\n \n     GG_GROUP_VERSION_ID=`echo $CREATE_GROUP_VERSION_RESULT | jq -r \'.Version\'`\n     $COMMAND create-deployment --deployment-type ""NewDeployment"" --group-id $GG_GROUP_ID --group-version-id $GG_GROUP_VERSION_ID\n \n }\n add_connector\nBash\nSample run output:\nEdit the Security Group for the Windows EC2 instance for KEPServerEX to allow traffic from the Security Group for the Greengrass EC2 instance for port number 49320, which you plan to use with the OPC-UA end-point.\nModeling your assets in AWS IoT SiteWise\nYou now have your KEPServerEX simulating OPC-UA data and have configured AWS IoT Greengrass with the AWS IoT SiteWise gateway software running on your edge gateway.\nNext, you will model your assets using asset modeling in AWS IoT SiteWise before you ingest your data. Asset models drive standardization for your industrial data. An asset model contains a name, description, asset properties, and asset hierarchy definitions.\nEarlier, you set up three wind turbines in KEPServerEX. Assume that one of the three wind turbines is in the East location and the remaining two are in the West location in the state of Illinois. You want to create the below asset hierarchy for the Wind Farm. Assume that Unit 1 PLC and Unit 2 PLCs are same model type across all the three Wind Turbines. You need to create four models for the asset hierarchy below \xe2\x80\x93 one for Unit 1 PLC, one for Unit 2 PLC, one for Wind Turbine, and finally, one for Wind Farm.\nFollow the steps below to create the models:\nExecute the following AWS CLI command to create the model for Unit 1 PLC:\naws iotsitewise create-asset-model --cli-input-json file://Unit_1_PLC_model_template.json --profile default\nCode\nThe file Unit_1_PLC_model_template.json contains the following code:\n{\n    ""assetModelHierarchies"": [], \n    ""assetModelDescription"": ""Unit 1 PLC Model Template"", \n    ""assetModelName"": ""Unit 1 PLC Model"", \n    ""assetModelProperties"": [\n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""measurement"": {}\n            }, \n            ""unit"": ""m/s"", \n            ""name"": ""Wind Speed""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""measurement"": {}\n            }, \n            ""unit"": ""rev/s"", \n            ""name"": ""Rotor Speed""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Serial BT12345""\n                }\n            }, \n            ""name"": ""Model""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""measurement"": {}\n            }, \n            ""unit"": ""kW"", \n            ""name"": ""Generated Power""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""metric"": {\n                    ""variables"": [\n                        {\n                            ""name"": ""var_generatedpower"",\n                            ""value"": {\n                                ""propertyId"": ""Generated Power""\n                            } \n                        }\n                    ], \n                    ""expression"": ""max(var_generatedpower)"", \n                    ""window"": {\n                        ""tumbling"": {\n                            ""interval"": ""5m""\n                        }\n                    }\n                }\n            }, \n            ""name"": ""Max Generated Power""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""metric"": {\n                    ""variables"": [\n                        {\n                            ""name"": ""var_windspeed"", \n                            ""value"": {\n                                ""propertyId"": ""Wind Speed""\n                            }\n                        }\n                    ], \n                    ""expression"": ""avg(var_windspeed)"", \n                    ""window"": {\n                        ""tumbling"": {\n                            ""interval"": ""5m""\n                        }\n                    }\n                }\n            }, \n            ""name"": ""Average Wind Speed""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Unit 1 PLC""\n                }\n            }, \n            ""name"": ""Name""\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""assetModelArn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/b82337f0-c24d-45ed-8ac4-bbfb370bb27e"", \n    ""assetModelId"": ""b82337f0-c24d-45ed-8ac4-bbfb370bb27e"", \n    ""assetModelStatus"": {\n        ""state"": ""CREATING""\n    }\n}\nCode\nMake a note of the assetModelId to use shortly.\nExecute the following AWS CLI command to create the model for Unit 2 PLC:\naws iotsitewise create-asset-model --cli-input-json file://Unit_2_PLC_model_template.json --profile default\nCode\nThe file Unit_2_PLC_model_template.json contains the following code:\n{\n    ""assetModelHierarchies"": [], \n    ""assetModelDescription"": ""Unit 2 PLC Model Template"", \n    ""assetModelName"": ""Unit 2 PLC Model"", \n    ""assetModelProperties"": [\n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""metric"": {\n                    ""variables"": [\n                        {\n                            ""name"": ""var_outsidetemperature"", \n                            ""value"": {\n                                ""propertyId"": ""Outside Temperature""\n                            }\n                        }\n                    ], \n                    ""expression"": ""avg(var_outsidetemperature)"", \n                    ""window"": {\n                        ""tumbling"": {\n                            ""interval"": ""15m""\n                        }\n                    }\n                }\n            }, \n            ""name"": ""Avg Outside Temperature""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""measurement"": {}\n            }, \n            ""unit"": ""Fahrenheit"", \n            ""name"": ""Outside Temperature""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Serial BT54321""\n                }\n            }, \n            ""name"": ""Model""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""measurement"": {}\n            }, \n            ""unit"": ""Fahrenheit"", \n            ""name"": ""Equipment Temperature""\n        }, \n        {\n            ""dataType"": ""DOUBLE"", \n            ""type"": {\n                ""metric"": {\n                    ""variables"": [\n                        {\n                            ""name"": ""var_equipmenttemperature"", \n                            ""value"": {\n                                ""propertyId"": ""Equipment Temperature""\n                            }\n                        }\n                    ], \n                    ""expression"": ""avg(var_equipmenttemperature)"", \n                    ""window"": {\n                        ""tumbling"": {\n                            ""interval"": ""15m""\n                        }\n                    }\n                }\n            }, \n            ""name"": ""Avg Equipment Temperature""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Unit 2 PLC""\n                }\n            }, \n            ""name"": ""Name""\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""assetModelArn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/4ae586a6-f41e-4f7c-bb03-968349a0e1f5"", \n    ""assetModelId"": ""4ae586a6-f41e-4f7c-bb03-968349a0e1f5"", \n    ""assetModelStatus"": {\n        ""state"": ""CREATING""\n    }\n}\nCode\nMake a note of the assetModelId to use shortly.\nExecute the following AWS CLI command to create the model for Wind Turbine:\naws iotsitewise create-asset-model --cli-input-json file://wind_turbine_model_template.json --profile default\nCode\nThe file wind_turbine_model_template.json contains the following code (remember to replace the two childAssetModelId with the model ids you noted above for Unit 1 PLC and Unit 2 PLC models):\n{\n    ""assetModelDescription"": ""Wind Turbine Model Template"", \n    ""assetModelName"": ""Wind Turbine Model"",\n    ""assetModelHierarchies"": [\n        {\n            ""childAssetModelId"": ""<Replace with assetModelId noted above for Unit 1 PLC>"", \n            ""name"": ""Unit 1 PLC Model""\n        }, \n        {\n            ""childAssetModelId"": ""<Replace with assetModelId noted above for Unit 2 PLC>"", \n            ""name"": ""Unit 2 PLC Model""\n        }\n    ], \n    ""assetModelProperties"": [\n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Wind Turbine""\n                }\n            }, \n            ""name"": ""Name""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""East""\n                }\n            }, \n            ""name"": ""Location""\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""assetModelArn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/97b68f68-2fba-46ff-a199-6fc90bbb11e4"", \n    ""assetModelId"": ""97b68f68-2fba-46ff-a199-6fc90bbb11e4"", \n    ""assetModelStatus"": {\n        ""state"": ""CREATING""\n    }\n}\nCode\nMake a note of the assetModelId to use shortly.\nExecute the following AWS CLI command to create the model for Wind Farm:\naws iotsitewise create-asset-model --cli-input-json file://wind_farm_model_template.json --profile default\nCode\nThe file wind_farm_model_template.json contains the following code (remember to replace the childAssetModelId with the model id you noted above for the Wind Turbine Model above):\n{\n    ""assetModelDescription"": ""Wind Farm Model Template"", \n    ""assetModelName"": ""Wind Farm Model"",\n    ""assetModelHierarchies"": [\n        {\n            ""childAssetModelId"": ""<Replace with assetModelId noted above for Wind Turbine>"", \n            ""name"": ""Wind Turbine Model""\n        }\n    ], \n    ""assetModelProperties"": [\n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Wind Farm""\n                }\n            }, \n            ""name"": ""Name""\n        }, \n        {\n            ""dataType"": ""STRING"", \n            ""type"": {\n                ""attribute"": {\n                    ""defaultValue"": ""Illinois""\n                }\n            }, \n            ""name"": ""Location""\n        }\n    ]\n}\nJSON\nSample run output:\n{\n    ""assetModelArn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/fd30d3bf-e58a-4ec6-90a7-f882d35b7823"", \n    ""assetModelId"": ""fd30d3bf-e58a-4ec6-90a7-f882d35b7823"", \n    ""assetModelStatus"": {\n        ""state"": ""CREATING""\n    }\n}\nCode\nExecute the following AWS CLI command to get the list of all the model IDs you created above for creating the assets next.\naws iotsitewise list-asset-models --profile default\nCode\nSample run output:\n{\n    ""assetModelSummaries"": [\n        {\n            ""status"": {\n                ""state"": ""ACTIVE""\n            }, \n            ""description"": ""Unit 2 PLC Model Template"", \n            ""lastUpdateDate"": 1574824993.0, \n            ""creationDate"": 1574824993.0, \n            ""id"": ""4ae586a6-f41e-4f7c-bb03-968349a0e1f5"", \n            ""arn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/4ae586a6-f41e-4f7c-bb03-968349a0e1f5"", \n            ""name"": ""Unit 2 PLC Model""\n        }, \n        {\n            ""status"": {\n                ""state"": ""ACTIVE""\n            }, \n            ""description"": ""Wind Turbine Model Template"", \n            ""lastUpdateDate"": 1574825291.0, \n            ""creationDate"": 1574825289.0, \n            ""id"": ""97b68f68-2fba-46ff-a199-6fc90bbb11e4"", \n            ""arn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/97b68f68-2fba-46ff-a199-6fc90bbb11e4"", \n            ""name"": ""Wind Turbine Model""\n        }, \n        {\n            ""status"": {\n                ""state"": ""ACTIVE""\n            }, \n            ""description"": ""Unit 1 PLC Model Template"", \n            ""lastUpdateDate"": 1574824802.0, \n            ""creationDate"": 1574824801.0, \n            ""id"": ""b82337f0-c24d-45ed-8ac4-bbfb370bb27e"", \n            ""arn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/b82337f0-c24d-45ed-8ac4-bbfb370bb27e"", \n            ""name"": ""Unit 1 PLC Model""\n        }, \n        {\n            ""status"": {\n                ""state"": ""ACTIVE""\n            }, \n            ""description"": ""Wind Farm Model Template"", \n            ""lastUpdateDate"": 1574826696.0, \n            ""creationDate"": 1574826675.0, \n            ""id"": ""fd30d3bf-e58a-4ec6-90a7-f882d35b7823"", \n            ""arn"": ""arn:aws:iotsitewise:us-west-2:<AWS-Account-ID>:asset-model/fd30d3bf-e58a-4ec6-90a7-f882d35b7823"", \n            ""name"": ""Wind Farm Model""\n        }\n    ]\n}\nCode\nMake a note of the 4 asset model ids you will be using for asset creation in the next step.\nExecute the following AWS CLI commands to create the assets below (remember to replace the asset-model-id with the corresponding model ids you noted in the previous step):\nWind Turbine 1 \xe2\x80\x93 PLC Unit 1 (For Wind Turbine 1 PLC Unit 1)\nWind Turbine 1 \xe2\x80\x93 PLC Unit 2 (For Wind Turbine 1 PLC Unit 2)\nWind Turbine 2 \xe2\x80\x93 PLC Unit 1 (For Wind Turbine 2 PLC Unit 1)\nWind Turbine 2 \xe2\x80\x93 PLC Unit 2 (For Wind Turbine 2 PLC Unit 2)\nWind Turbine 3 \xe2\x80\x93 PLC Unit 1 (For Wind Turbine 3 PLC Unit 1)\nWind Turbine 3 \xe2\x80\x93 PLC Unit 2 (For Wind Turbine 3 PLC Unit 2)\naws iotsitewise create-asset --asset-name ""Wind Turbine 1 - PLC Unit 1"" --asset-model-id ""b82337f0-c24d-45ed-8ac4-bbfb370bb27e"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 1 - PLC Unit 2"" --asset-model-id ""4ae586a6-f41e-4f7c-bb03-968349a0e1f5"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 2 - PLC Unit 1"" --asset-model-id ""b82337f0-c24d-45ed-8ac4-bbfb370bb27e"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 2 - PLC Unit 2"" --asset-model-id ""4ae586a6-f41e-4f7c-bb03-968349a0e1f5"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 3 - PLC Unit 1"" --asset-model-id ""b82337f0-c24d-45ed-8ac4-bbfb370bb27e"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 3 - PLC Unit 2"" --asset-model-id ""4ae586a6-f41e-4f7c-bb03-968349a0e1f5"" --profile default\nCode\nNavigate to AWS IoT SiteWise, Assets, Wind Turbine 1 \xe2\x80\x93 PLC Unit 1 asset and click on Edit to update the following:\nUnder Measurements:\nUpdate property alias for Generated Power with the OPC-UA tag name \xe2\x80\x93 /Wind Turbine 1/Unit 1 PLC/Power and Notification Status with ENABLED (default is DISABLED)\nUpdate property alias for Rotor Speed with the OPC-UA tag name \xe2\x80\x93 /Wind Turbine 1/Unit 1 PLC/Rotor Speed and Notification Status with ENABLED (default is DISABLED)\nUpdate property alias for Wind Speed with the OPC-UA tag name \xe2\x80\x93 /Wind Turbine 1/Unit 1 PLC/Wind Speed and Notification Status with ENABLED (default is DISABLED) \nUnder Metric, update Notification Status with ENABLED (default is DISABLED) for both Max Generated Power and Average Wind Speed. \nClick on Save asset to save the changes. In this step, you mapped the Measurements to their appropriate OPC-UA tags. Also, by enabling Notification Status, modeled data from AWS IoT SiteWise will now be published to the topic names as shown in the screenshot above. You can subscribe to those topics from AWS IoT Core rules engine to build your own IoT applications downstream (outside AWS IoT SiteWise).\nRepeat step 7-1, 7-2, and 7-3 above for the remaining five assets below to update with their corresponding OPC-UA tags for the Measurements from KEPServerEX and enable the Notification Status for both Measurements and Metrics:\nWind Turbine 1 \xe2\x80\x93 PLC Unit 2\nWind Turbine 2 \xe2\x80\x93 PLC Unit 1\nWind Turbine 2 \xe2\x80\x93 PLC Unit 2\nWind Turbine 3 \xe2\x80\x93 PLC Unit 1\nWind Turbine 3 \xe2\x80\x93 PLC Unit 2\nExecute the following AWS CLI commands to create the assets below (remember to replace the asset-model-id from your own environment):\nWind Turbine 1\nWind Turbine 2\nWind Turbine 3\nWind Farm\naws iotsitewise create-asset --asset-name ""Wind Turbine 1"" --asset-model-id ""97b68f68-2fba-46ff-a199-6fc90bbb11e4"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 2"" --asset-model-id ""97b68f68-2fba-46ff-a199-6fc90bbb11e4"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Turbine 3"" --asset-model-id ""97b68f68-2fba-46ff-a199-6fc90bbb11e4"" --profile default\naws iotsitewise create-asset --asset-name ""Wind Farm"" --asset-model-id ""fd30d3bf-e58a-4ec6-90a7-f882d35b7823"" --profile default\nCode\nNavigate to AWS IoT SiteWise, Assets, Wind Turbine 1 asset and click on Edit. Under Assets associated to this asset, add the following two hierarchy nodes as shown in below screenshot and also update Location to East and Name to Wind Turbine 1, and click on Save asset. \nRepeat step 10 above for the remaining assets below to associate the necessary asset hierarchy nodes:\nWind Turbine 2 (Associate to Wind Turbine 2 \xe2\x80\x93 PLC Unit 1 and Wind Turbine 2 \xe2\x80\x93 PLC Unit 2)\nWind Turbine 3 (Associate to Wind Turbine 3 \xe2\x80\x93 PLC Unit 1 and Wind Turbine 3 \xe2\x80\x93 PLC Unit 2)\nWind Farm (Associate to Wind Turbine 1, Wind Turbine 2, and Wind Turbine 3)\nNavigate to AWS IoT SiteWise, Assets to verify that the asset hierarchy looks the one you wanted to build. \nIngesting data using AWS IoT SiteWise gateway\nNow that you have the asset model created, set up your AWS IoT SiteWise gateway in the cloud to start the data ingestion into AWS IoT SiteWise.\nNavigate to AWS IoT SiteWise, Ingest, Gateways and click on Add gateway to create a new SiteWise Gateway named Wind Turbine SiteWise Gateway with Greengrass group ID as sitewise_gg. Click on Add gateway once done. \nOnce the SiteWise Gateway is created successfully, you will see below: \nYou are now ready to add a source (KEPServerEX for this post) for the AWS IoT SiteWise Gateway you just created. Click on Manage, View Details, New source to add your source OPC-UA server details. Click on Save to save the details. Note that you can add multiple sources to the same gateway.Note that the message security policy is set to Basic128Rsa15 \xe2\x80\x93 Sign and encrypt (this is the same message security policy you chose earlier for KEPServerEX). The message security policy determines the algorithm used for the encryption and signing of OPC-UA messages exchanged with the gateway device.\nAlso, authentication is set to none and anonymous to match with the Allow anonymous login option you have chosen earlier from KEPServerEX under Property Editor, General, OPC UA.\nAfter creating the gateway and associating with the source (OPC-UA server), log in to the KEPServerEX Windows machine. To trust the certificate from OPC UA Configuration Manager (which allows the data to flow from KEPServerEX to AWS), choose Trust as shown in the screenshot below. \nTo verify that the OPC-UA data is streaming from KEPServerEX to AWS IoT SiteWise, execute the below AWS CLI command a couple of times for any of the asset properties to see that the value is changing from time to time. For this post, you choose asset as Wind Turbine 1 \xe2\x80\x93 PLC Unit 1 and Generated Power as the property. Remember to replace with the corresponding asset-id and property-id from list-assets and describe-assetoutput in your environment.\naws iotsitewise get-asset-property-value --asset-id ""84841a92-232d-4a43-ab0a-fe7536a537ed"" --property-id ""a2085ae5-c553-446e-825a-ba9e84dabaf1"" --profile default\nCode\nSample output for Run 1:\n{\n    ""propertyValue"": {\n        ""timestamp"": {\n            ""timeInSeconds"": 1574876940, \n            ""offsetInNanos"": 524000000\n        }, \n        ""quality"": ""GOOD"", \n        ""value"": {\n            ""doubleValue"": 3.702181100845337\n        }\n    }\n}\nCode\nSample output for Run 2:\n{\n    ""propertyValue"": {\n        ""timestamp"": {\n            ""timeInSeconds"": 1574876972, \n            ""offsetInNanos"": 25000000\n        }, \n        ""quality"": ""GOOD"", \n        ""value"": {\n            ""doubleValue"": 4.034252643585205\n        }\n    }\n}\nCode\nSummary\nIn Part 1 of this multi-part post, you learned how to model your industrial assets and ingest data from industrial sites in a secure, cost-effective, and reliable manner using AWS IoT SiteWise. You used KEPServerEX from Kepware as the OPC-UA server for AWS IoT SiteWise to subscribe to the data.\nIn Part 2, you learn how to:\nMonitor key operating parameters and performance metrics for your assets using SiteWise Monitor, a new capability of AWS IoT SiteWise, and take necessary actions when needed in near-real time\nIn Part 3, you learn how to:\nStream modeled equipment data in real-time from AWS IoT SiteWise to be consumed by custom applications via AWS IoT Core rules engine\nEnable condition monitoring and send notifications or alerts using AWS IoT Events in near-real time\nEnable Business Intelligence (BI) reporting on historical data using Amazon QuickSight\nWe hope you found this post informative and the walk-through helpful. As always, AWS welcomes feedback. Please submit your comments or questions below.'"
173,Training the Amazon SageMaker object detection model and running it on AWS IoT Greengrass – Part 2 of 3: Training a custom object detection model,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/batch-inference-1024x410-1.png,https://aws.amazon.com/blogs/iot/sagemaker-object-detection-greengrass-part-2-of-3/,"b'Post by Angela Wang and Tanner McRae, Engineers on the AWS Solutions Architecture R&D and Innovation team\nThis post is the second in a series on how to build and deploy a custom object detection model to the edge using Amazon SageMaker and AWS IoT Greengrass. In part 1 of this series, we walked through the training data preparation process: capturing video, extracting and selecting frames, and using Amazon SageMaker Ground Truth to label the images.\nIn this post, you prepare the output from the SageMaker Ground Truth labeling job for model training, submit a custom object detection training job, and finally, convert the output model artifact for making inference locally.\nHere\xe2\x80\x99s a reminder of the architecture you are building as a whole:\nFollowing the steps in your AWS account\nIf you would like to try out each step yourself, you can run through the Jupyter notebooks in the GitHub project repository.\nCompleting part 1 of the series is not a prerequisite for following along in your account. If you have created your own Ground Truth job, you can use your own labeled data. If not, use the example labeled data that we provided (under the CDLA Permissive license). If you choose to use example data, make sure that you use the US East (Northern Virginia) Region.\nProcess SageMaker Ground Truth labeling job outputs for training\nThe output of the SageMaker Ground Truth bounding box labeling job is in a format called augmented manifest file. This format is accepted as input to an Amazon SageMaker built-in object detection training algorithm.\nThere are a few advantages of using the augmented manifest format compared to other input formats supported by Amazon SageMaker:\nUnlike the traditional approach of providing paths to the input images separately from its labels, the augmented manifest file already combines both into one entry for each input image. This reduces complexity in algorithm code for matching each image with labels. For a more detailed explanation, see Easily train models using datasets labeled by Amazon SageMaker Ground Truth.\nWhen splitting your dataset for train, validation, and test, it\xe2\x80\x99s not necessary to rearrange and re-upload image files to different Amazon S3 prefixes for train and validation. After you upload your image files to S3, you never have to move it again. You can just place pointers to these images in your augmented manifest file for training and validation. See more on the train and validation data split in this post later.\nWhen using an augmented manifest file, the training input images are loaded on to the training instance in Pipe mode. The input data is streamed directly to the training algorithm while it is running (as opposed to File mode, where all input files must be downloaded to disk before the training starts). This results in faster training performance and less disk resource utilization. For more information about the benefits of Pipe mode, see Accelerate model training using faster Pipe mode on Amazon SageMaker.\nNo format conversion is required if you are using Ground Truth to generate the data labels.\nIn this example project, even though the augmented manifest file format is supported as training input for Amazon SageMaker, you may still need a small amount of processing work:\nJoin together outputs from multiple labeling jobs: To be able to iterate on SageMaker Ground Truth jobs, you created several smaller labeling jobs for the dataset instead of a single large job containing the full dataset.\nFilter out labels that did not meet the quality bar: Look through the labeled bounding boxes in the Ground Truth console and manually mark down any images that were not well labeled.\nInject the correct class labels:  In part 1, you already prepended the name (class) of the object to the file names of the frames extracted from the video. You then added it as additional metadata in the SageMaker Ground Truth labeling manifest. Because of this, in the labeling job, you didn\xe2\x80\x99t ask the labeler to pick the right class when it drew bounding boxes. This approach saved effort for the worker. However, it also means that the annotations in the Ground Truth output always have the same class_id of 0, because you only specified one class of objects when you submitted the labeling job. Here\xe2\x80\x99s an example output from the completed labeling job:\n{\n ""source-ref"": ""s3://aws-greengrass-blog/frames/yellow_box_1/yellow_box_1_000022.jpg"", \n ""color"": ""yellow"", \n ""object"": ""box"",\n ""bb"":{\n   ""annotations"":[{""class_id"":0,""width"":499,""top"":134,""height"":726,""left"":0}],\n   ""image_size"":[{""width"":1280,""depth"":3,""height"":1080}]\n },\n ""bb-metadata"":{\n   ""class-map"":{""0"":""storage box""},\n   ...\n }\n}\nJSON\nThe code in this Jupyter notebook uses the additional metadata (color and object key pairs in the output JSON) to inject the correct class labels in the bounding box annotation. For example, the blue box with class ID 0, yellow box with class ID 1. It updates the class-map field in the manifest. The resulting entry looks something like this:\n{\n ""source-ref"": ""s3://aws-greengrass-blog/frames/yellow_box_1/yellow_box_1_000022.jpg"",\n ""color"": ""yellow"", \n ""object"": ""box"",\n ""bb"":{\n   ""annotations"":[{""class_id"":1,""width"":499,""top"":134,""height"":726,""left"":0}],\n   ""image_size"":[{""width"":1280,""depth"":3,""height"":1080}]\n },\n ""bb-metadata"":{\n   ""class-map"": {""0"":""blue box"", ""1"":""yellow box""},\n   ...\n }\n}\nJSON\n4. Split the data into train and validation sets\nAmazon SageMaker requires two datasets during training: a train and a validation dataset. The training set consists of the images and annotations used to actually train the model. The validation set is not used for training but to validate that the model can generalize (it can accurately make predictions on previously unseen data). It\xe2\x80\x99s also used to compare accuracy between different trained models during hyperparameter tuning.\nWhy split the data this way? The process of model training is essentially reducing loss (how far off the model\xe2\x80\x99s prediction is compared to the training dataset) in each training iteration. However, minimizing the loss runs the risk of making the model too tailored to the particularities of the training data (overfitting). For an illustration of this, use the following scatter plot of 2D points as an example training dataset:\nA model represented by the red line in the preceding plot does a passable job describing the underlying pattern of the data points with a relatively small loss. For a counterexample, see the following model represented in the blue line:\nThe function represented in blue technically has a smaller loss than the red model but does a worse job describing the pattern of the dataset. It would almost certainly perform worse on previously unseen data. Using a validation dataset is therefore necessary to evaluate the performance of the model against a dataset not used during training.\nData processing code and walkthrough\nReview the code and follow the data processing steps by running this Jupyter notebook on the project GitHub repo in an Amazon SageMaker notebook instance.\nOther considerations before starting your Amazon SageMaker training job\nThere are two other issues to consider before starting the training job: transfer learning and data augmentation\nTransfer learning\nFor deep learning\xe2\x80\x93based computer vision algorithms to perform well, you must have a massive amount of training data. The popular dataset COCO, for example, has more than 200 k labeled images. When you have only a few hundred to a thousand labeled images, the best way to achieve accurate results is through transfer learning. The built-in Amazon SageMaker object detection algorithm makes it trivial to do transfer learning. It initializes the weights of the neural network using parameters from a pretrained model. For more information about enabling it, see the following code section.\nData augmentation\nTo achieve higher accuracy, it\xe2\x80\x99s also common to use data augmentation in addition to transfer learning. It\xe2\x80\x99s the fastest and cheapest way to multiply the amount of training data you have, by generating new data based on your existing training data. For a detailed introduction to various data augmentation techniques, see Data Augmentation | How to use Deep Learning when you have Limited Data.\nFor this example, we wrote a simple script that performs some rudimentary augmentation: flipping the image and bounding box labels by x-axis and y-axis, and rotating 90 degrees clockwise and counterclockwise:\nYou now have five times more training data after running a simple script. We found that even simple data augmentation like this can make a significant difference in the accuracy. The validation metric used in this project, mAP (mean average precision), saw a 21.5% increase after adding the augmented data to the training dataset. All other hyperparameters remained the same.\nThis approach of augmenting the data before training is referred to as offline augmentation. Some deep learning frameworks, such as Gluon, also support online augmentation, which applies augmentation as the data is fed to train the model. To take advantage of that, you can build a custom Docker container with your training code and use the bring-your-own-algorithm functionality of Amazon SageMaker.\nSubmit a training job using the built-in object detection algorithm\nNow you are ready to start training jobs. Using the Amazon SageMaker boto3 SDK, you can define train and validation inputs using the following code. The values of the attribute_names parameter must match those in your augmented manifest file:\nThe JSON attribute name for the S3 URI of the input image\nThe JSON attribute name for the bounding box annotations\ns3_train_data= ""s3://{}/{}/training-manifest/train.manifest"".format(bucket, prefix)\ns3_validation_data = ""s3://{}/{}/training-manifest/validation.manifest"".format(bucket, prefix)\n\ntrain_input = {\n    ""ChannelName"": ""train"",\n    ""DataSource"": {\n        ""S3DataSource"": {\n            ""S3DataType"": ""AugmentedManifestFile"",  \n            ""S3Uri"": s3_train_data,\n            ""S3DataDistributionType"": ""FullyReplicated"",\n            # This must correspond to the JSON field names in your augmented manifest.\n            ""AttributeNames"": [\'source-ref\', \'bb\']\n        }\n    },\n    ""ContentType"": ""application/x-recordio"",\n    ""RecordWrapperType"": ""RecordIO"",\n    ""CompressionType"": ""None""\n}\n\nvalidation_input = {\n    ""ChannelName"": ""validation"",\n    ""DataSource"": {\n        ""S3DataSource"": {\n            ""S3DataType"": ""AugmentedManifestFile"",  \n            ""S3Uri"": s3_validation_data,\n            ""S3DataDistributionType"": ""FullyReplicated"",\n            #  This must correspond to the JSON field names in your augmented manifest.\n            ""AttributeNames"": [\'source-ref\', \'bb\']\n        }\n    },\n    ""ContentType"": ""application/x-recordio"",\n    ""RecordWrapperType"": ""RecordIO"",\n    ""CompressionType"": ""None""\n}\n\ns3_output_location = \'s3://{}/{}/output\'.format(bucket, prefix)\nPython\nNext, set the hyperparameters. You can find documentation for all the supported hyperparameters in the Amazon SageMaker documentation. There are a few things worth highlighting:\nbase_network \xe2\x80\x93 This is the base feature extractor network as part of the SSD model. Currently the Amazon SageMaker built-in object detection algorithm supports either ResNet-50 or VGG-16. We chose ResNet because it\xe2\x80\x99s more lightweight and thus faster, given that you run the inference at the edge on AWS IoT Greengrass. To train the model with a base network even more lightweight, such as MobileNet and ShuffleNet, you can define a custom algorithm using frameworks such as Gluon, Keras, PyTorch, etc.\nuse_pretrained_model \xe2\x80\x93 This enables/disables transfer learning by initializing the weights of the neural network using parameters from a pre-trained model.\nnum_classes \xe2\x80\x93 This is the number of classes of objects you are trying to predict. In this example, you only have two classes: \xe2\x80\x9cblue storage box\xe2\x80\x9d or \xe2\x80\x9cyellow storage box.\xe2\x80\x9d During transfer learning, the original output neural net layer is replaced by a new output layer with number of nodes equal to num_classes.\nuse_pretrained_mode \xe2\x80\x93 This is the height and width of the image being passed into the model. Conveniently, Amazon SageMaker reshapes the image on the fly during training, so you don\xe2\x80\x99t have to resize the images beforehand.\nmini_batch_size \xe2\x80\x93 This is the number of inputs used for each round of forward and backward pass. Larger batch sizes usually allow the algorithm to converge faster. However, it\xe2\x80\x99s more computationally resource intensive to run each batch. Along with the learning_rate, these are two hyperparameters that you should consider tuning to achieve higher accuracy.\nlearning_rate \xe2\x80\x93 This defines the initial learning rate. Configure it along with lr_scheduler_factor and lr_scheduler_step to gradually reduce the learning rate as your training progresses. Because you are using transfer learning with pretrained parameters, keep the initial learning rate relatively small. Otherwise, the weights get updated in increments that are too large and you obtain unusable results.\nhyperparams = { \n            ""base_network"": \'resnet-50\',\n            ""use_pretrained_model"": ""1"",\n            ""num_classes"": ""2"",   \n            ""mini_batch_size"": ""30"",\n            ""epochs"": ""30"",\n            ""learning_rate"": ""0.001"",\n            ""lr_scheduler_step"": ""10,20"",\n            ""lr_scheduler_factor"": ""0.25"",\n            ""optimizer"": ""sgd"",\n            ""momentum"": ""0.9"",\n            ""weight_decay"": ""0.0005"",\n            ""overlap_threshold"": ""0.5"",\n            ""nms_threshold"": ""0.45"",\n            ""image_shape"": ""512"",\n            ""label_width"": ""150"",\n            ""num_training_samples"": str(num_training_samples)\n }\nPython\nNext, for training parameters, specify the following:\nThe container image for the built-in object detection algorithm\nThe compute resource type and size (we recommend picking a GPU instance in the P3 or P2 instance family)\nThe input mode\xe2\x80\x94because you are using the AugmentedManifestFile input file type, you must specify Pipe mode (see Augmented Manifest File)\nYou can find documentation about the other parameters here.\ntraining_image = sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, \'object-detection\', repo_version=\'latest\')\n\ntraining_params = \\\n    {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": training_image,\n            ""TrainingInputMode"": ""Pipe""\n        },\n        ""RoleArn"": role,\n        ""OutputDataConfig"": {\n            ""S3OutputPath"": s3_output_path\n        },\n        ""ResourceConfig"": {\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.p3.8xlarge"",\n            ""VolumeSizeInGB"": 200\n        },\n        ""TrainingJobName"": model_job_name,\n        ""HyperParameters"": hyperparams,\n        ""StoppingCondition"": {\n            ""MaxRuntimeInSeconds"": 86400\n        },\n        ""InputDataConfig"": [\n            train_input,\n            validation_input\n        ]\n    }                                     \nPython\nFinally, kick off the training job with the preceding configurations:\nclient = boto3.client(service_name=\'sagemaker\')\nclient.create_training_job(**training_params)\nPython\nAmazon SageMaker training Jupyter notebook code and walkthrough\nReview the full code and follow the training job submission by running this Jupyter notebook on the project GitHub repo in an Amazon SageMaker notebook instance.\nModel training tip: Evaluate progress by visualizing trend of validation metric update.\nDuring training, the built-in object detection algorithm reports accuracy metrics on the validation dataset after each training epoch. Find links to the training log and Amazon CloudWatch metrics graph from the Amazon SageMaker console. For example, the mAP (mean average precision) for the training job with the preceding configuration follows:\nVisualizing the trend of the mAP validation metric helps you evaluate your hyperparameter choices. For example, if the mAP keeps rising without plateauing, maybe you should train for more epochs. If it shows a significant drop, maybe you should reduce your learning rate.\nTo improve your hyperparameter choices and achieve better results, look into using the automatic hyperparameter tuning feature of Amazon SageMaker. See the Automatic Model Tuning documentation.\nRun local inference using the trained model on an Amazon SageMaker notebook instance\nTo validate the trained model further and make predictions using the trained model, there are three options:\nDeploy it to an endpoint using Amazon SageMaker Hosting Services to get one inference at a time in real time\nUse Amazon SageMaker Batch Transform to apply a one-off batch inference job on an entire dataset\nDownload the model artifacts to an Amazon SageMaker notebook instance and test running inference locally\nBecause the goal is to eventually run this prediction at the edge, we went with the third option: download the model to an Amazon SageMaker notebook instance and do interference locally. To verify that the model makes inferences as expected, test local inference on an Amazon SageMaker notebook instance before trying it on your edge device. Make sure that the instance has all the MXNet and CUDA dependencies properly configured.\nThe trained model parameters, along with its network definition, is stored in a tar.gz file in the output path for the training job. Download and unzip it:\nMODEL_ARTIFACT = sagemaker_client.describe_training_job(TrainingJobName=JOB_ID)[\'ModelArtifacts\'][\'S3ModelArtifacts\']\n!aws s3 cp $MODEL_ARTIFACT .\n!tar -xvzf model.tar.gz\nPython\nUpon unzipping the model, you should find three files in your directory:\nmodel_algo_1-symbol.json   <-- neural network definition \nhyperparams.json           <-- hyper parameters  \nmodel_algo_1-0000.params   <-- trained weights for the neural network\nConvert the trained model artifact to a deployable model artifact\nThe model output produced by the built-in object detection model leaves the loss layer in place and does not include an NMS (non-max suppression) layer. To make it ready for inference on the machine, remove the loss layer and add the NMS layer. Use a script from this GitHub repo.\ngit clone https://github.com/zhreshold/mxnet-ssd.git\nBash\nYou must run the deploy.py script to convert a trained model to a deployable model. An example follows:\npython /home/ec2-user/SageMaker/mxnet-ssd/deploy.py --network resnet50 --num-class 2 --nms .45 --data-shape 512 --prefix model_algo_1\nBash\nWhen running this script, make sure that command line options you pass in match exactly the hyperparameters of your training job. If you\xe2\x80\x99re unsure, refer the hyperparams.json file in your unpacked model artifacts to confirm. To run this script successfully, you must use Python2.\nWith the model artifacts properly converted, you can now load the updated model artifacts into MXNet:\nparam_path=\'model_algo_1\'\nsym, arg_params, aux_params = mx.model.load_checkpoint(param_path, 0)\nmod = mx.mod.Module(symbol=sym, label_names=[], context=ctx)\nmod.bind(for_training=False, data_shapes=input_shapes)\nmod.set_params(arg_params, aux_params)\nPython\nAnd then, make some inferences with the test images.\nThe local inference Jupyter notebook also includes code that lets you do inference in batch with all images in a folder and generate a PDF that visualizes the inference output for each frame.\nLastly, remember to save the copy of the deployable model artifact in S3.\naws s3 cp deploy_model_algo_1-0000.params s3://my-bucket/deployable-model/\naws s3 cp deploy_model_algo_1-symbol.json s3://my-bucket/deployable-model/\nBash\nLocal inference Jupyter notebook code and walkthrough\nReview the code and follow the preceding local inference steps by running this Jupyter notebook on the project GitHub repo in an Amazon SageMaker notebook instance.\n'"
174,Training the Amazon SageMaker object detection model and running it on AWS IoT Greengrass – Part 1 of 3: Preparing training data,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/07/09/instructions-1024x643.png,https://aws.amazon.com/blogs/iot/sagemaker-object-detection-greengrass-part-1-of-3/,"b'Post by Angela Wang and Tanner McRae, Engineers on the AWS Solutions Architecture R&D and Innovation team\nRunning computer vision algorithms at the edge unlocks many industry use cases that has low or limited internet connectivity. Combining services from AWS in the Machine Learning (ML) and Internet of Things (IoT) space, training a custom computer vision model and running it at the edge has become easier than ever.  The blog post Using and Retraining Image Classification Models with AWS IoT Greengrass shows an example of running image classification models on AWS IoT Greengrass. In computer vision, image classification tells you what type of objects are in the image. Object detection, in addition to defining objects, also tells you where the objects are by producing bounding boxes that mark the location of each object being detected.\nIn industries such as manufacturing and supply chain, the capability of object detection to locate objects makes it applicable to a wider range of use cases compared to image classification alone. For example:\nTrack and count inventory\nIdentify barcodes or QR codes printed on top of boxes\nLocate product defects for quality control or predictive maintenance\nWhen running object detection models for use cases such as inventory tracking, it is common to have limited connectivity to the internet. Yet in order to count and track inventory accurately, it\xe2\x80\x99s often necessary to process multiple frames per second per camera. This can be a lot of data to send over the internet if you run the ML inference in the cloud. Therefore, running the object detection model at the edge can often be a low-latency and reliable solution. Using the ML inference feature of AWS IoT Greengrass can simplify managing and deploying ML inference to the edge.\nThese use cases also tend to require training a specialized object detection model using custom data. This enables the model to recognize specific products in backgrounds that are unique to the customer\xe2\x80\x99s business. Amazon SageMaker is built to accelerate the process by providing a built-in workflow for data labeling and a built-in object detection algorithm.\nEven though tools like Amazon SageMaker and AWS IoT Greengrass do an excellent job in their own domains, there is still work to be done for an end-to-end solution:\nHow do you take a source video feed and turn it into labeled training data?\nHow do you make sure that you have the right collection of data before you pay people to label them?\nHow do you convert the output of the Amazon SageMaker object detection algorithm model artifact into a format that you can deploy using AWS IoT Greengrass for inference?\nIn this multipart post series, we share the processes, scripts, and best practices that we used to address these questions while working on similar object detection projects with customers. The example of tracking two types of boxes going in and out of a room with an overhead camera is a simplified version of tracking objects on a factory floor.\nPrerequisites\nYou are welcome to read the best practices described in this post. However, if you would like to try out each step yourself, make sure that you have the following in place:\nAn AWS account\nAn Amazon S3 bucket\nA running Amazon SageMaker notebook instance\nThis GitHub repository cloned to the Amazon SageMaker notebook instance\nIf you collect your own data, a web camera connected to your laptop and objects on which to train the custom model\nNote: Make sure that when creating the IAM role for the Jupyter notebook, the IAM role can access the greengrass-object-detection-blog bucket and the S3 bucket that you created for this project.\nArchitecture\nIn the next few posts, we walk through each part of the following architecture, as shown in the diagram:\n  This post takes a closer look at the data gathering for training your own object detection model using a web camera.\nGather video footage\nTo construct an environment similar to an inventory tracking use case on a factory floor, we installed a web camera on the ceiling of an office. Then we connected it to the computer through USB.\nAfter the setup was complete, we took videos of ourselves carrying these boxes around under the webcam using this 00_get_video.py script. The script uses the OpenCV library, an open source BSD-licensed library of programming functions built for real-time computer vision. The library is cross-platform and contains a wealth of algorithms and video and image-processing functionalities. For this use case, we used OpenCV to capture videos from a web camera and to extract frames from the videos.\nTo use this script to gather your own footage, run the script on your laptop after installing Python dependencies. (Press q to stop the recording.)\npip install -r data-prep/requirements.txt\npython data-prep/00_get_video.py -n <name-of-video> -c <camera-id>\nBash\nAfter you record the videos, upload them to an S3 bucket using the aws s3 sync tool.\nTry to gather footage on as many different scenarios that can happen in production as possible so that your model is trained on varying environments and still performs well if anything changes. For example, try different lighting, room configuration, inventory movement patterns, and so on.\nYou can review the video gathering Python script here.\nInstructions on following these steps in your AWS account\nYou can perform each of the following steps by running through this Juypter notebook on your Amazon SageMaker notebook instance (with the exception of creating the Amazon SageMaker Ground Truth labeling job). You can use either the video that you collected yourself or using example video files provided by us (released under the CDLA Permissive license).\nExtracting and uploading frames\nNow that you have collected some videos, you must extract individual frames from them so they can be labeled and used for training. You can run the 01_video_to_frame_utils.py script for each of the videos you collected on an Amazon SageMaker notebook instance:\npython data-prep/01_video_to_frame_utils.py --video_s3_bucket $VIDEO_S3_BUCKET --video_s3_key $VIDEO_S3_KEY --working_directory $WORKDING_DIR --visualize_video True --visualize_sample_rate 1 -o $OUTPUT_S3_BUCKET\nBash\nAfter you extract the frames,  use s3 sync to upload them to S3:\naws s3 sync $WORKDING_DIR/$folder_name s3://$OUTPUT_S3_BUCKET/frames/\nBash\nFrame extraction tips\nTip 1: Prefix extracted frames with class annotation\nDuring data labeling using SageMaker Ground Truth for object detection, the worker typically need to select the class the object belongs to in addition to drawing the bounding box. However, if you recorded videos for each product you want to detect separately, you could include the name of the item in the name of the video file. Then during frame extraction, you can carry that name over to the image file names, which gives you a free class annotation. See the following diagram for an example.\nTip 2: Review the contents of your extracted frames for image quality, personally identifiable information (PII), confidential data, and background-only images\nBefore you begin labeling your training data, make sure to review the contents of your extracted frames for image quality, PII, confidential data, or background-only images. Consider retaking the video, or apply additional filtering steps for empty frames or frames with PII. The frame extraction script (01_video_to_frame_utils.py) automatically generates a thumbnail like the following for you:\nBuild a labeling manifest file for Amazon SageMaker Ground Truth\nTo train an ML model, you need large, high-quality, labeled datasets. Labeling for thousands of images can become tedious and time consuming. Thankfully, Amazon SageMaker Ground Truth makes it easy to crowdsource this task. The Ground Truth service offers easy access to public and private human labelers for annotating datasets. It provides built-in workflows and interfaces for common labeling tasks, including drawing bounding boxes for object detection.\nWhen creating a labeling job in Amazon SageMaker Ground Truth, you create a manifest file pointing to the locations of the input images stored in S3 that require annotation. Each line corresponds to a single image and is an independent JSON document.\nUse the 02_generate_gt_manifest.py script to generate this manifest by specifying the S3 location of the frames you have extracted in the previous step:\npython data-prep/02_generate_gt_manifest.py -b $S3_BUCKET -k $S3_KEY_PREFIX -d $WORKING_DIR -r $SAMPLING_RATE\nBash\nAfter reviewing the content of the generated manifest JSON file, upload it to an S3 bucket of your choosing. Use this location in the next step when creating the Ground Truth job. You can also choose to join together manifest files generated from multiple videos before uploading it to S3.\nSageMaker Ground Truth manifest generation tips\nTip 1: Append additional metadata to your SageMaker Ground Truth labeling manifest file\nA cool feature of SageMaker Ground Truth is the ability to attach additional metadata associated with each input. This metadata is preserved as part of the labeled output of the Ground Truth as passthrough information. For example, you can append the \xe2\x80\x9ccolor\xe2\x80\x9d and \xe2\x80\x9cobject\xe2\x80\x9d values to each image in the manifest that was previously stored in the image\xe2\x80\x99s file name.\n{""source-ref"": ""s3://my-bucket/frames/blue_box_1/blue_box_1_000023.jpg"", ""color"": ""blue"", ""object"": ""box""}\n{""source-ref"": ""s3://my-bucket/frames/blue_box_1/blue_box_1_000025.jpg"", ""color"": ""blue"", ""object"": ""box""}\n{""source-ref"": ""s3://my-bucket/frames/yellow_box_1/yellow_box_1_000019.jpg"", ""color"": ""yellow"", ""object"": ""box""}\n{""source-ref"": ""s3://my-bucket/frames/yellow_box_1/yellow_box_1_000020.jpg"", ""color"": ""yellow"", ""object"": ""box""}\nJSON\nAfter the image has been annotated by SageMaker Ground Truth workers, here\xe2\x80\x99s what the output line looks like in the output manifest file:\n{\n ""source-ref"":""s3://my-bucket/frames/blue_box_1/blue_box_1_000023.jpg"",\n ""color"": ""blue"", \n ""object"": ""box"",\n ""bb"":{\n   ""annotations"":[{""class_id"":0,""width"":499,""top"":134,""height"":726,""left"":0}],\n   ""image_size"":[{""width"":1280,""depth"":3,""height"":1080}]\n },\n ""bb-metadata"":{\n   ""job-name"":""labeling-job/demo"",\n   ""class-map"":{""0"":""storage box""},\n   ""human-annotated"":""yes"",\n   ""objects"":[\n     {""confidence"":0.09}\n   ],\n   ""creation-date"":""2019-05-03T22:33:23.351336"",\n   ""type"":""groundtruth/object-detection""\n }\n}\nJSON\nAs you can see, the bounding box annotations labeled by SageMaker  Ground Truth workers is added, but the additional metadata (the color and object key-value pairs) isn\xe2\x80\x99t touched at all. In this example, this additional metadata helps generate class labels used in training.\nThis can also be useful in cases of labeling jobs chaining. For example, you might run a classification job first to classify what\xe2\x80\x99s in an image. You could take that output and pass it into a new bounding box job. That effectively chains the two jobs together into a single output that you can use to train an object detection model with.\nTo see example code of appending this metadata, find the following line in the manifest generation script and uncomment the following line:\n# to see appending additional metadata in action, uncomment the following line if you are using the example data\nobj = append_additional_metadata(obj, s3_object.key)\nPython\nTip 2: Decide what at interval to sample your frames\nAlso consider a frame sampling rate when generating your labeling job manifest. Why should you sample your frames? Say that you have about 10 hours of footage taken at 30 FPS (frames per second). That\xe2\x80\x99s a total of 10 x 60 x 60 x 30 = 1,080,000 images. It\xe2\x80\x99s not only expensive and time consuming to label every frame, but you might also find that consecutive frames are nearly identical, especially if your video has a high frame rate.\nFor example, here\xe2\x80\x99s an example of 16 consecutive frames from our 5 FPS footage:\nAnd here\xe2\x80\x99s 16 frames that were sampled 1 out of every 10 frames from our footage:\nThe the manifest generation script has a command line option so you can specify the sampling frequency when generating the labeling manifest.\nBefore submitting a labeling job to SageMaker Ground Truth, review the content of the manifest you generated by using the 03_visualize_gt_labeling_manifest.py script:\npython data-prep/03_visualize_gt_labeling_manifest.py -b $S3_BUCKET -k $S3_KEY_MANFIST\nBash\nCreate a data labeling job in Amazon SageMaker Ground Truth\nYou can now move on to creating labeling jobs in Amazon SageMaker Ground Truth. In this post, we don\xe2\x80\x99t cover each step in creating a labeling job in Ground Truth. It\xe2\x80\x99s already covered in detail by this great post, Amazon SageMaker Ground Truth \xe2\x80\x93 Build Highly Accurate Datasets and Reduce Labeling Costs by up to 70%.\nSageMaker Ground Truth job submission tip:  Follow an iterative process in writing concise and clear instructions\nWe followed the recommended workflow from the Create high-quality instructions for Amazon SageMaker Ground Truth labeling jobs post to create the following instructions for the labeler:\nMake sure you include bad examples in your instructions and remind labelers what not to do when labeling:\nWhen you iterate on instructions for a SageMaker Ground Truth job, you can either use the console or use the boto3 SDK. If it\xe2\x80\x99s your first time using the service, we suggest that you use the SageMaker Ground Truth console. For iterating the custom instructions, we found it easier to directly edit HTML and work through a Jupyter notebook. Here\xe2\x80\x99s the Jupyter notebook we used to create custom instructions for submitting labeling jobs to Ground Truth. Feel free to run it on your Amazon SageMaker notebook instance and modify the parameters to suit your project.\nReviewing labels from SageMaker Ground Truth\nYou can monitor the SageMaker Ground Truth console for the completion of your labeling jobs.\nSageMaker Ground Truth result review tips:\n Take advantage of the bounding box visualizations in the console to review the label quality and iterate on your labeling job configurations.\nIf you use multiple workers for labeling jobs,  SageMaker Ground Truth automatically performs annotation consolidation to join together multiple workers\xe2\x80\x99 output. Different confidence scores are assigned to each bounding box, depending on how many workers have labeled that same area. Experiment with filtering out labels with low confidence scores and visualize the results in your own scripts.\n'"
175,"Introducing Secure Tunneling for AWS IoT Device Management, a new secure way to troubleshoot IoT devices",b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/introducing-secure-tunneling-for-aws-iot-device-management-a-new-secure-way-to-troubleshoot-iot-devices/,"b'AWS IoT Device Management has a breadth of tools that enable businesses to build  IoT applications for every industry. However, when it comes to remote access to devices, that typically has involved a customer sending a control message either through a MQTT topic, or updating the device\xe2\x80\x99s shadow and then having the device agent take action on those messages. This has meant that the hardware development teams have needed to explicitly build those specific control capabilities into the devices\xe2\x80\x99 firmware.\nDevice management outside of these pre-configured flows has been especially tricky when the devices are behind a firewall. On a normal desktop computer, this would be a trivial problem as you could simply install a remote management application or use a tool such as VNC. However, to date, this sort of capability has been difficult to implement on IoT devices.\nWhat\xe2\x80\x99s launching today?\nToday we\xe2\x80\x99re launching Secure Tunneling, a new feature in AWS IoT Device Management, which provides a secure remote access solution that directly integrates with AWS IoT to allow you to remotely access your IoT devices from anywhere. The endpoint is secured with Identity and Access Management (IAM) and communication happens over Transport Layer Security (TLS).\nHow does it work?\nI\xe2\x80\x99ll start by installing a proxy application on my device (a Raspberry Pi) which will facilitate the secure WebSocket connection to the Secure Tunneling service.  Authentication tokens are generated when the open-tunnel CLI command is called. These tokens are then passed to the proxy that is running on the device. Since I am using devices managed in the Thing Registry, the delivery of the device token is handled for me. After authenticating to the Secure Tunneling service, a token will be delivered to both the user and device. The IoT device launches the proxy upon receipt of the token.  Let\xe2\x80\x99s do a high-level walk-through using the AWS Command Line Interface (CLI). I\xe2\x80\x99ll need to make sure that\xe2\x80\x99s configured before getting started.\nStart proxy on target device\nNow that I have a thing in the Thing Registry, I\xe2\x80\x99ll install the device\xe2\x80\x99s private key and certificate onto my device. This key pair enables the device to subscribe to a reserved MQTT topic, $aws/things/<thing-name>/tunnels/notify. Secure Tunneling uses this MQTT topic to publish a token that will be used to establish a tunnel to my Raspberry Pi.\nNow that my device is able to receive this token information, I can use the AWS IoT Device SDK\xe2\x80\x99s to initialize the tunneling proxy. To achieve this, I modify the IoT Device SDK to listen for notifications on the MQTT topic for tunneling, and once a token is received on my device, I use it to start the proxy.\n  json_message = json.loads(message.payload.decode(\'utf-8\'))\nif message.topic == ""$aws/things/<thing-name>/tunnels/notify"":\n    subprocess.run([\n        ""./localproxy"",\n        ""-t"", json_message[\'clientAccessToken\'],\n        ""-r"", ""us-east-1"",\n        ""-d"", ""localhost:22""\n   ])\nPython\nI\xe2\x80\x99m hard-coding the host and port here (localhost:22) for demonstration purposes. In practice you might want to dynamically load the host and port mappings from a configuration file based on the services passed through the open-tunnel CLI command.\nStart proxy on the local machine\nWith the target device now listening and ready for access, I\xe2\x80\x99ll need to switch to my local machine I previously configured with my AWS credentials. I\xe2\x80\x99ll use the CLI to open a tunnel \xe2\x80\x93 see documentation for more details.\nThe open-tunnel CLI command gives back a sourceAccessToken that is used to start the proxy. Simultaneously, because I\xe2\x80\x99m using managed token delivery, Secure Tunneling will send the destinationAccessToken to the previously mentioned special topic to my device. From there, my modified device code will start the proxy.\nOnce that\xe2\x80\x99s done, I am ready to remotely access the device!\nAccess!\nIn my case, I want to open an SSH session to the device. So I\xe2\x80\x99ll open up a shell and run a standard SSH connection command using the \xe2\x80\x9c-p\xe2\x80\x9d to specify the proxy port (I specified this port when I started the source proxy on my local machine).\nssh pi@localhost -p 8000\nAnd just like that, I\xe2\x80\x99ve connected to my device over the Internet through a firewall, two firewalls actually!\nWhat\xe2\x80\x99s next?\nNow with Secure Tunneling you can implement several use cases for remote operations and interacting with your devices. For example, as a Fleet Manager you can combine Secure Tunneling with AWS IoT Jobs or AWS Federated Identities. You could federate access of your AWS account to an external identity provider for your users of Secure Tunneling using a service such as ADFS, AWS Single Sign-On, Okta or Ping. To learn more, refer to the developer guide.\nWe think providing a managed, secure tunneling solution to customers will enhance their ability to be able to manage and troubleshoot their devices. And we\xe2\x80\x99re excited by the use cases that will be unlocked.\nSecure Tunneling for AWS IoT Device Management is available today.\n   '"
176,Route data directly from IoT Core to your web services,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/route-data-directly-from-iot-core-to-your-web-services/,"b'In this blog post, we will explain how you can use AWS IoT Core Rules Engine\xe2\x80\x99s HTTP action to send data directly to your existing HTTPS endpoint without writing additional code or making changes to published code. With this feature, you can integrate AWS IoT with your own web services without additional latency and complexity associated with the use of an intermediate service. For more information about this feature, refer to the HTTP action documentation. If you are new to AWS IoT rules, check out this Tutorial.\nThis blog assumes that:\nYou have access to AWS IoT console or have AWS CLI installed;\nYou have an existing HTTPS endpoint with a valid certificate signed by a public certificate authority (CA); and,\nYou can access that HTTPS endpoint\xe2\x80\x99s logs or can read messages sent to that endpoint.\nWe will walk you through the following:\nCreate a topic rule with an HTTP action using AWS console;\nConfirm and enable a topic rule destination using AWS console;\nCreate a topic rule with an HTTP action using AWS CLI;\nDefine an HTTP action endpoint with and without substitution templates,\nDefine an HTTP action with headers and authentications,\nManage topic rule destinations using AWS CLI;\nCreate topic rule destinations,\nConfirm topic rule destinations,\nUpdate topic rule destinations,\nList topic rule destinations,\nDelete topic rule destinations.\nReady to get started?\nIn order for your web service to receive data from AWS IoT, you first need to create a topic rule with a new HTTP action. HTTP action will POST message payloads as well as any headers specified in the action to the designated HTTPS endpoint every time the action is executed. Because you can ingest data from your endpoint using HTTPS POST, you will not need to make any code changes for your endpoint to integrate with AWS IoT.\nCreate a topic rule with an HTTP action via AWS Console\nThe steps below detail how to create a topic rule with HTTP action via the AWS IoT console:\n1. In the AWS IoT console, in the navigation pane, choose Act, then Rules.\n2. On the Rules page, choose Create.\n3. On the Create a rule page, enter a name and description for your rule.\n4. Under Rule query statement, choose the latest version from the Using SQL version list. For rule query statement, enter: SELECT * FROM \xe2\x80\x98my/topic\xe2\x80\x99\nThis will take the entire payload data that was published on my/topic and execute rule actions to send it to downstream services. If you are new to writing AWS IoT Rules SQL statement, please see the SQL Reference page.\n5. Choose Add Action.\n6. On Select an action page, choose Send a message to a downstream HTTPS endpoint.\nThis is where you can specify the URL of your HTTPS endpoint. When this action executes, Rules Engine will construct a POST request to that endpoint, add headers specified in the action, and add the message payload to the request body after SQL statement evaluation.\n7. On Configure action page, enter HTTPS Endpoint to point to your existing HTTPS endpoint, e.g. https://www.example.com/ingest.\nHTTPS Endpoint supports substitution templates. As a result, there are many ways you can specify an endpoint. See Define HTTP Action Endpoint section below to learn more about ways to configure an HTTPS endpoint.\n8. Choose Add Action.\n9. Choose Create rule.\nAt this point, you have a topic rule that would take data published on AWS IoT\xe2\x80\x99s \xe2\x80\x98my/topic\xe2\x80\x99 and send it to https://www.example.com/ingest. It is very important to note that in order for this to flow through properly (and not be blocked by Rules Engine), you must first validate that you control the endpoint.\nIntroducing the concept of Topic Rule Destinations\nTo ensure data is sent to an endpoint that you control, AWS IoT Rules Engine requires a confirmation that you can access the data sent to that endpoint. To keep track of your endpoints, a new AWS IoT Topic Rule Destination resource is added. Rules Engine will try to create a new topic rule destination when you create or update a topic rule with HTTP action.\nWhen a topic rule destination is created for HTTP action, Rules Engine issues a challenge message to the specified endpoint with a token. If you can get the token and send that back to Rules Engine, then you can prove that you have access to the data on the receiving side, which would complete the confirmation process. Endpoint confirmation is a one-time operation. Once confirmed and enabled, the same endpoint can be used for multiple rules without additional confirmations.\nNote that the token is valid for three days, after which you need to create a new HTTP action or follow the steps in Update Topic Rule Destination section to restart the confirmation process. See the Working with HTTP Action Destinations documentation for more details.\nConfirm and Enable Topic Rule Destinations via AWS Console\nThe steps below show you how to confirm and enable a destination via the AWS IoT console:\n1. In the AWS IoT console, in the navigation pane, choose Act, then Destinations.\n2. Select a Destination entry that has your endpoint, e.g. https://www.example.com/ingest\n3. In the details of that Destination, select Actions then choose Confirm and Enable.\nYou should see a dialog like this for your HTTPS endpoint.\nA confirmation token is required to proceed. When a destination is created, Rules Engine issues a challenge message to your endpoint. That message contains the confirmation token and has a format like this:\nHTTP POST {confirmationUrl}/?confirmationToken={confirmationToken}\n\nHeaders:\n    x-amz-rules-engine-message-type: DestinationConfirmation\n    x-amz-rules-engine-destination-arn: <Destination ARN>\n    Content-Type: application/json\n    ...\n\nBody: \n{ \n    ""arn"": <ARN for the destination that needs to be confirmed>,\n    ""confirmationToken"": <Confirmation Token, same as {confirmationToken} in URL>,\n    ""enableUrl"": <Callback URL to complete the confirmation. Make HTTP GET request to this URL to finish confirmation>,\n    ""messageType"": ""DestinationConfirmation""\n}\nIf you control that endpoint, you can simply look in your service logs for POST requests to that resource with the confirmationToken URI query, extract that token value, and paste it back into the AWS IoT console.\nTip: Make sure to enable URI Query (cs-uri-query) W3C Logging Field for this endpoint in your server, otherwise query parameters with confirmationToken could get filtered out.\n4. Enter {confirmationToken} in Confirm Destination dialog.\n5. Choose Confirm and Enable.\nAt this point, if the token is correct, the destination entry for your endpoint should show as Enabled. AWS IoT Rules Engine will now send data to that endpoint any time your rule is triggered.\nPLEASE NOTE THAT AT THE POINT OF WRITING THIS BLOG:\nHTTP action only supports POST to HTTPS endpoint with a valid certificate signed by a public certificate authority (CA).\nHTTP action only supports ports 443 and 8443.\nHTTP action has a timeout limit of 3 seconds to complete HTTP request(s) (including retries).\nStandard EC2 Data Transfer costs listed here apply to HTTP action.\nFor the latest limits on HTTP action, please see the AWS IoT Limit page.\nCreate a topic rule with an HTTP action via AWS CLI\nYou can also create topic rules with HTTP action, as well as manage topic rule destinations using AWS CLI. You can use the following command line to create a topic rule.\nCreate A Topic Rule\naws iot create-topic-rule --rule-name test_http_action --topic-rule-payload file://<path/to/your/file.json> --region <your_region>\ntopic-rule-payload describes the topic rule as well as action(s) associated with it. You can find examples of topic-rule-payload below.\nWhen creating topic-rule-payload, you will need to specify url, an HTTP endpoint where your web service can receive messages. url supports substitution templates. As a result, there are many ways you can configure url, and each has its own rule to follow (no pun intended). We created five examples below to explain how you can define this endpoint in your topic-rule-payload.\nDefine HTTP Action Endpoint\nOption 1: Hard-coded endpoint\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nIn this example, url is hard-coded, meaning no substitution template is used. Once this action is added, Rules Engine automatically creates a topic rule destination for https://www.example.com URL and issues a challenge to that URL. Once you confirm and enable the URL by responding to the challenge, Rules Engine will deliver data to that endpoint. A confirmationUrl is not required in this case since it can be inferred from url value. This is only possible if url has no substitution templates.\nOption 2: Hard-coded endpoint with sub-paths or query parameters\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com/subpath?myqueryparams=staticdata"",\n                ""confirmationUrl"": ""https://www.example.com""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nThis option is similar to Option 1, but you can also specify a confirmation (base) URL. confirmationUrl is used to create the topic rule destination, which is the destination for the confirmation challenge. It is required to be a prefix of the url where message payload is delivered. Once you confirm and enable confirmationUrl, the base URL (https://www.example.com) and all sub paths/query parameters will be allowed for all rules.\nOption 3: Dynamic endpoint with hard-coded domain name\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com/${clientid()}/data"",\n                ""confirmationUrl"": ""https://www.example.com""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nFor this option, url is not determined until a message is processed, therefore, confirmationUrl is required. Once confirmationUrl is enabled, Rules Engine can send data not only to https://www.example.com, but to any sub paths/query parameters for this destination. If the destination was not previously enabled, creating this action will automatically create the topic rule destination based on confirmationUrl. You will need to enable that destination before Rules Engine can send messages to url.\nOption 4: Dynamic endpoint with dynamic domain name\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://${value_from_payload}.example.com/${clientid()}/data"",\n                ""confirmationUrl"": ""https://${value_from_payload}.example.com""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nThis is the most complicated scenario, because both url and confirmationUrl are not known until a message is evaluated. In such cases, Rules Engine will not automatically create a topic rule destination when the rule is created. Rules Engine has two requirements:\nconfirmationUrl with substitution templates (${value_from_payload}) needs to be a prefix of url; and,\nCustomer needs to manually create, confirm and enable all possible topic rule destinations for confirmationUrl after substitutions.\nIn the example above, confirmationUrl is the prefix of url, so the rule gets successfully created. Suppose ${value_from_payload} is a set of possible values (\xe2\x80\x9ctest\xe2\x80\x9d, \xe2\x80\x9cprod\xe2\x80\x9d, \xe2\x80\x9cbeta\xe2\x80\x9d). You would need to manually create and enable topic rule destinations for these possible confirmationUrl values: (https://test.example.com, https://prod.example.com, https://beta.example.com). See Manually Create Topic Rule Destination section below to learn how to create topic rule destinations using AWS CLI.\nWhen a message gets evaluated, Rules Engine checks if confirmationUrl after substitutions was confirmed and is Enabled. So, if ${value_from_payload} gets substituted to \xe2\x80\x9cbeta\xe2\x80\x9d, Rules Engine checks if https://beta.example.com destination has been confirmed and is Enabled before sending data to https://beta.example.com/123456789012/data.\nOption 5: Fully dynamic endpoint\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""${full_control_from_payload}"",\n                ""confirmationUrl"": ""${full_control_from_payload}""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nThis option is very similar to Option 4. The value of confirmationUrl must be the prefix of url, and you need to manually create, confirm, and enable all possible destinations for confirmationUrl after substitutions. In addition, Rules Engine makes sure data is targeting HTTPS endpoints on port 443 (default) or 8443.\nNow let\xe2\x80\x99s look at how you can add headers to your HTTP action.\nDefine HTTP Action with Headers\nHeaders are defined in key-value pairs and you can specify up to 100 headers in each HTTP action. Note that only value field supports substitution templates, and certain headers are implicitly defined by default (e.g. Content-Type, User-Agent). You can overwrite Content-Type header via headers key-value pair.\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com"",\n                ""headers"": [\n                    {\n                        ""key"": ""static_header_key"",\n                        ""value"": ""static_header_value""\n                    },\n                    {\n                        ""key"": ""substitutable_header_key"",\n                        ""value"": ""${value_from_payload}""\n                    }\n                ]\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nDefine HTTP Action with Authentications\nHTTP action supports authentication methods such as Basic Auth and API key based authentication. The examples below teach you how to configure these authentication methods using HTTP headers and query parameters.\nDefine Basic Authentication\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com"",\n                ""headers"": [\n                    {\n                        ""key"": ""Authorization"",\n                        ""value"": ""Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==""\n                    }\n                ]\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nFollowing \xe2\x80\x98Basic\xe2\x80\x99 HTTP Authentication Scheme defined by Internet Engineering Task Force (IETF), this HTTP action will construct an HTTP POST request with header Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== to https://www.example.com.\nDefine API Key based Authentication\n{\n    ""actions"": [\n        {\n            ""http"": {\n                ""url"": ""https://www.example.com/something?api_key=abcd1234"",\n                ""confirmationUrl"": ""https://www.example.com""\n            }      \n        }\n    ],\n    ""sql"": ""select * from \'a/b\'"",\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nIn this example, the endpoint authenticates using an API key query parameter. Alternative query parameters or headers can be used to specify the API key, depending on the target service implementation.\nManage Topic Rule Destinations using AWS CLI\nIn this section we will show you how to create, confirm, update, list, and delete topic rule destinations using AWS CLI.\nManually Create Topic Rule Destination\naws iot create-topic-rule-destination --destination-configuration \'{""httpUrlConfiguration"": {""confirmationUrl"": ""https://www.example.com""}}\' --region <your_region>\nThis command will create a new topic rule destination and will issue a confirmation challenge to https://www.example.com. The topic rule destination status will be IN_PROGRESS with a status reason Awaiting confirmation. If the confirmation is not complete within three days, the state will be moved to ERROR.\nYou will need to use this command line to manually create topic rule destinations if confirmationUrl of your HTTP action contains substitution templates.\nConfirm Topic Rule Destination\naws iot confirm-topic-rule-destination --confirmation-token \'confirmationToken\' --region <your_region>\nOnce you have the confirmation token from the confirmation message, you can use the command line above to confirm the corresponding topic rule destination.\nFor security reasons, the topic rule destination will be in DISABLED status after confirmation. You will need to enable the destination using the update-topic-rule-destination command line (see below) or in the console in order for Rules Engine to send traffic to this destination.\nUpdate Topic Rule Destination\naws iot update-topic-rule-destination --arn \'arn\' --status \'ENABLED|DISABLED|IN_PROGRESS\' --region <your_region>\nYou can use this command line to enable/disable a topic rule destination, or resend a new confirmation message to the destination. An arn is used to identify the topic rule destination, and you can receive the arn via the list-topic-rule-destination command line (see below) or in the console. status is the desired new status state for a destination. Note that status must be in the ENABLED state in order for Rules Engine to send traffic to this destination.\nTo resend the confirmation challenge message, you can update the topic rule destination status to IN_PROGRESS. For more information see the UpdateTopicRuleDestination API documentation.\nList Topic Rule Destination\naws iot list-topic-rule-destinations --max-results <value> --region <your_region>\nThe command line above lists your topic rule destinations including arn of each destination.\nDelete Topic Rule Destination\naws iot delete-topic-rule-destination --arn \'arn\' --region <your_region>\nTo delete a topic rule destination, simply use the command line above with the arn of the destination.\nReady to send data from AWS IoT Core directly to your own web services for processing without writing a single line of code? HTTP action is available in all AWS regions where AWS IoT Core is available, and with this addition, AWS IoT Core now supports 17 action types. For more information, refer to the AWS IoT documentation.'"
177,Implementing a CI/CD pipeline for AWS IoT Greengrass projects,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/implementing-a-ci-cd-pipeline-for-aws-iot-greengrass-projects/,"b'This post demonstrates how to build a continuous integration and continuous deployment (CI/CD) pipeline for AWS IoT Greengrass projects. Readers should be familiar with AWS IoT Greengrass.\nThis post focuses on streamlining the development process for AWS IoT Greengrass projects rather than explaining the technology itself. If you are not familiar with AWS IoT Greengrass, you can learn about it using the tutorials at Getting Started with AWS IoT Greengrass.\nCI/CD is a modern software development practice that enables the frequent release of small, tested changes into a production software environment. Delivering changes frequently makes their business value available to users as soon as it is ready. Small change sets make it easier to identify the root causes of errors and recover from them. For more information about the benefits and adoption of CI/CD for your team, see Practicing Continuous Integration and Continuous Delivery on AWS.\nIn this post\xe2\x80\x99s example:\nA developer pushes a code change to the master branch of the project\xe2\x80\x99s AWS CodeCommit Git repository.\nThis change triggers an AWS CodePipeline pipeline that uses AWS CodeBuild to perform the following tasks:\nDeploys the change to a test AWS IoT Greengrass group.\nExecutes integration tests for the AWS IoT Greengrass application in the test environment.\nIf the Integration Tests succeed, Deploys the changes to the prod AWS IoT Greengrass group, making the new capabilities available to users.\nThe example builds on the AWS CloudFormation patterns established in the post Automating AWS IoT Greengrass Setup with AWS CloudFormation to establish test and prod AWS IoT Greengrass groups. Each group resides on its own dedicated Amazon EC2 instance. In your project, your AWS IoT Greengrass groups may reside on the edge devices that you chose for your implementation.\n  Prerequisites\nComplete the following steps before proceeding:\nCreate a non-production account in which to create your resources at the AWS Account Signup Page. Alternatively, you can use AWS Organizations to create and govern new accounts easily and securely.\nInstall the AWS Command Line Interface (AWS CLI) and configure it to use the access credentials and AWS Region that you have chosen for this exercise. For more information, see Installing the AWS CLI and Configuring the AWS CLI.\nCreate an EC2 key pair for creating AWS IoT Greengrass groups. For more information, see Creating a Key Pair Using Amazon EC2. Key pairs are not necessary to use AWS IoT Greengrass itself, but allow you to log in to the EC2 instances that act as your deployment environments.\nCreate the test AWS IoT Greengrass group by launching the test group CloudFormation template and completing the following steps:\nSelect your key pair.\nTo restrict SSH access to the created EC2 instance, set the SecurityAccessCIDR.\nAcknowledge that the template creates IAM roles and choose Create.\nLet the stack creation finish.\nCreate the prod AWS IoT Greengrass group by launching the prod group CloudFormation template and repeating the preceding steps.\nTo create a source repository and a build/deployment pipeline, launch the repo and pipeline AWS CloudFormation template.\nYou can use the default parameter values.\nAcknowledge that the template creates IAM roles and choose Create.\nNavigating the template\nAt this point, you should see the following resources in their respective areas of the AWS Console:\nThe following stacks in CloudFormation:\ngg-cicd-pipeline\ngg-cicd-prod-environment\ngg-cicd-test-environment\nA CodeCommit repository (greengrass-cicd-project) to hold the project code.\nA CodePipeline pipeline to build, test, and deploy the project code (gg-cicd-pipeline-BuildAndDeployPipeline, ending with your own custom suffix generated by CloudFormation). It is normal that the pipeline be in an error state when first created.\nTest and prod AWS IoT Greengrass groups (gg-cicd-test and gg-cicd-prod) in which to run integration tests and production code, respectively. These newly created groups only have cores associated with them. The pipeline updates their definitions to add AWS Lambda functions and subscriptions based on your project code.\nCreating a sample AWS IoT Greengrass project\nTo start, create a directory to work in, using the following commands in your terminal window:\n$> mkdir my_work_dir\n$> cd my_work_dir\nIn the working directory, clone the empty Git repo to your computer. For help with setting up access to your repo, see Setting Up for AWS CodeCommit. Your Git URL may look a little different than the following:\n$> git clone ssh://git-codecommit.us-east-1.amazonaws.com/v1/repos/greengrass-cicd-project\nDownload this project archive and unzip it into your local repository directory. The archive may download to a different directory than the following:\n$> cp ~/Downloads/greengrass-cicd-project.zip .\n$> cd greengrass-cicd-project\n$> unzip ../greengrass-cicd-project.zip\n  This archive contains a sample AWS IoT Greengrass project:\n$> ls -R\nLICENSE           README.md         buildspec.yml     requirements.txt  src/              test/\n./src:\ndeploy.sh*          sample_function/ template.yml\n./src/sample_function:\n__init__.py         requirements.txt    sample_function.py\n./test:\ninit.py               certs/                    requirements.txt\nintegration_tests.py      setup_parameter_store.sh*\n./test/certs:\nroot.ca.pem\nThis project contains a simple Lambda function in src/sample_function/sample_function.py, as follows.\nimport os\nimport json\nfrom datetime import datetime\nimport greengrasssdk\n\n\ncounter = 0\nclient = greengrasssdk.client(\'iot-data\')\n\ndef function_handler(event, context):\n    \'\'\'Echo message on /in topic to /out topic\'\'\'\n\n    response = json.loads(event)\n    \n    # maybe do something with the event before sending it back\n    \n    response_string = json.dumps(response)\n\n    client.publish(\n        topic=\'{}/out\'.format(os.environ[\'CORE_NAME\']),\n        payload=response_string\n    )\n  In AWS IoT Greengrass, you communicate with Lambda functions using the MQTT protocol over the Message Broker for AWS IoT. The set of topics to which a Lambda function subscribes and the set of topics to which it publishes its results acts as its API.\nAWS IoT provides a single endpoint per Region within an AWS account. Because a single endpoint can serve multiple applications and deployment environments, it is a best practice to use a pattern like /{application}-{environment}/... when defining topics for your AWS IoT Greengrass applications.\nThe application prefix allows you to segregate traffic for multiple MQTT-based applications running in a single AWS account and Region.\nThe environment path element allows you to segregate environments such as prod and test.\nIn each of your environments, the topic gg-cicd-<env>/in serves as an input to your Lambda function, where <env> is either test or prod, depending on the AWS IoT Greengrass group where the function runs. The Lambda function echoes its input to the gg-cicd-<env>/out topic. You pass the CORE_NAME value into the function\xe2\x80\x99s execution environment and format it into the MQTT topic that you are using.\nThe definition of AWS IoT Greengrass groups updates via the AWS Serverless Application Model (AWS SAM) template in src/template.yml, shown in the following code. This template defines the AWS IoT Greengrass Lambda function and topics that comprise your AWS IoT Greengrass groups. For more details about defining AWS IoT Greengrass Groups with CloudFormation, see Automating AWS IoT Greengrass Setup with AWS CloudFormation.\nThe AutoPublishAlias property in the definition of GGSampleFunction causes your Lambda function to publish a new version for deployment to your AWS IoT Greengrass groups whenever the function code changes. If you don\xe2\x80\x99t publish a new version, the previous Lambda definition continues to be active.\nAWSTemplateFormatVersion: \'2010-09-09\'\nTransform: AWS::Serverless-2016-10-31\nDescription: Our Application\n\nParameters:\n  CoreName:\n    Description: Greengrass Core on which your resources are deployed\n    Default: ""coreName""\n    Type: String\n\nResources:\n  GreengrassGroupVersion:\n    Type: AWS::Greengrass::GroupVersion\n    Properties:\n      GroupId: {\'Fn::ImportValue\': !Sub \'${CoreName}-environment-GreengrassGroupId\'}\n      CoreDefinitionVersionArn: !Ref GreengrassCoreDefinitionVersion\n      FunctionDefinitionVersionArn: !GetAtt FunctionDefinition.LatestVersionArn\n      SubscriptionDefinitionVersionArn: !GetAtt SubscriptionDefinition.LatestVersionArn\n\n  GreengrassCoreDefinition:\n    Type: AWS::Greengrass::CoreDefinition\n    Properties:\n      # use CoreName + ""_Core"" as ""thingName""\n      Name: !Join [""_"", [!Ref CoreName, ""Core""] ]\n\n  GreengrassCoreDefinitionVersion:\n    # Example of using GreengrassCoreDefinition referring to this\n    # ""Version"" resource\n    Type: AWS::Greengrass::CoreDefinitionVersion\n    Properties:\n      CoreDefinitionId: !Ref GreengrassCoreDefinition\n      Cores:\n        - Id: !Join [""_"", [!Ref CoreName, ""Core""] ]\n          ThingArn: !Join\n            - "":""\n            - - ""arn:aws:iot""\n              - !Ref AWS::Region\n              - !Ref AWS::AccountId\n              - !Join\n                - ""/""\n                - - ""thing""\n                  - !Join [""_"", [!Ref CoreName, ""Core""] ]\n          CertificateArn: !Join\n            - "":""\n            - - ""arn:aws:iot""\n              - !Ref AWS::Region\n              - !Ref AWS::AccountId\n              - !Join\n                - ""/""\n                - - ""cert""\n                  - {\'Fn::ImportValue\': !Sub \'${CoreName}-environment-IoTThingCertificateId\'}\n          SyncShadow: ""false""\n\n  FunctionDefinition:\n    Type: \'AWS::Greengrass::FunctionDefinition\'\n    Properties:\n      Name: FunctionDefinition\n      InitialVersion:\n        DefaultConfig:\n          Execution:\n            IsolationMode: GreengrassContainer\n        Functions:\n          - Id: !Join [""_"", [!Ref CoreName, ""sample""] ]\n            FunctionArn: !Ref GGSampleFunction.Version\n            FunctionConfiguration:\n              Pinned: \'true\'\n              Executable: index.py\n              MemorySize: \'65536\'\n              Timeout: \'300\'\n              EncodingType: binary\n              Environment:\n                Variables:\n                  CORE_NAME: !Ref CoreName\n                AccessSysfs: \'false\'\n                Execution:\n                  IsolationMode: GreengrassContainer\n                  RunAs:\n                    Uid: \'1\'\n                    Gid: \'10\'\n\n  GGSampleFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      AutoPublishAlias: live\n      CodeUri: sample_function\n      Handler: sample_function.function_handler\n      Runtime: python2.7\n      Role: {\'Fn::ImportValue\': !Sub \'${CoreName}-environment-LambdaExecutionArn\'}\n\n  SubscriptionDefinition:\n    Type: \'AWS::Greengrass::SubscriptionDefinition\'\n    Properties:\n      Name: SubscriptionDefinition\n      InitialVersion:\n        # Example of one-to-many subscriptions in single definition version\n        Subscriptions:\n          - Id: Subscription1\n            Source: \'cloud\'\n            Subject: !Join\n              - ""/""\n              - - !Ref CoreName\n                - ""in""\n            Target: !Ref GGSampleFunction.Version\n          - Id: Subscription2\n            Source: !Ref GGSampleFunction.Version\n            Subject: !Join\n              - ""/""\n              - - !Ref CoreName\n                - ""out""\n            Target: \'cloud\'\n          - Id: Subscription3\n            Source: !Ref GGSampleFunction.Version\n            Subject: !Join\n              - ""/""\n              - - !Ref CoreName\n                - ""telem""\n            Target: \'cloud\'\n\nOutputs:\n  GroupId:\n    Value: {\'Fn::ImportValue\': !Sub \'${CoreName}-environment-GreengrassGroupId\'}\nThe pipeline executes the actions in the buildspec.yml file, located in the top level of your project directory, using CodeBuild. The template does the following:\nInstalls build/test dependencies.\nDeploys code to the test group using the helper script src/deploy.sh.\nRuns integration tests in the test environment.\nIf the tests succeed, deploys the code to the prod group using src/deploy.sh.\nDeploying to test, running the integration tests, and deploying to prod could be done in three separate CodeBuild actions. Doing so would allow you to independently retry each step of the pipeline. In this example, all three phases are in one build step for simplicity:\nversion: 0.2\n\nenv:\n  parameter-store:\n    IOT_ENDPOINT: /gg-cicd-test/IOT_ENDPOINT\n\nphases:\n  install:\n    commands:\n      - pip install -q --upgrade pip\n      - pip install -q aws-sam-cli\n      -\n      - cd test\n      - pip install -q -r requirements.txt\n      - cd ..\n  build:\n    commands:\n      - echo ""deploying to test core""\n      - cd src\n      - ./deploy.sh test\n      - cd ..\n      -\n      - echo ""running integration tests""\n      - cd test\n      - aws ssm get-parameter --name /gg-cicd-test/integration-testing-client.cert.pem --with-decryption --output text --query Parameter.Value > certs/integration-testing-client.cert.pem\n      - aws ssm get-parameter --name /gg-cicd-test/integration-testing-client.private.key --with-decryption --output text --query Parameter.Value > certs/integration-testing-client.private.key\n      - python -m unittest integration_tests.py\n      - cd ..\n      -\n      - echo ""deploying to production core""\n      - cd src\n      - ./deploy.sh prod\n      - cd ..\nThe deployment script src/deploy.sh uses the AWS SAM CLI to package the Lambda function and execute the AWS SAM template. The template deploys the resources to the AWS IoT Greengrass group specified as its command line argument. The script uses the following code:\n#!/bin/bash -e\n\nif [[ $# -ne 1 ]] || ([[ $1 != ""test"" ]] && [[ $1 != ""prod"" ]]); then\n  echo ""Usage $0 <deployment environment (test|prod)>""\n  exit 1\nfi\n\nDEPLOYMENT_ENVIRONMENT=$1\nSTACK_NAME=""gg-cicd-application-${DEPLOYMENT_ENVIRONMENT}-stack""\n\nsam package \\\n    --template-file template.yml \\\n    --output-template-file packaged.yml \\\n    --s3-bucket ${ARTIFACTS_BUCKET}\n\nsam deploy \\\n    --template-file packaged.yml \\\n    --stack-name ${STACK_NAME} \\\n    --capabilities CAPABILITY_IAM \\\n    --parameter-overrides CoreName=gg-cicd-${DEPLOYMENT_ENVIRONMENT} \\\n    --no-fail-on-empty-changeset\n\nGROUP_ID=`aws cloudformation describe-stacks --stack-name ${STACK_NAME} --query \'Stacks[0].Outputs[0].OutputValue\' --output text`\nGROUP_VERSION_ID=`aws greengrass list-group-versions --group-id ${GROUP_ID} --query \'Versions[0].Version\' --output text`\n\naws greengrass create-deployment --group-id ${GROUP_ID} --group-version-id ""${GROUP_VERSION_ID}"" --deployment-type NewDeployment\nAWS CloudFormation for AWS IoT does not currently support deployment to AWS IoT Greengrass groups. As such, deploy.sh retrieves the GROUP_ID of the target AWS IoT Greengrass group and the GROUP_VERSION_ID of the newly created group version. It supplies them to the AWS CLI to perform the group deployment.\nIntegration testing\nIntegration testing determines if your code functions correctly when connected to your other application components in an environment that approximates your production systems. In this case, those components are the Lambda code and the two MQTT topics with which it interacts. The test AWS IoT Greengrass group, deployed to its corresponding EC2 instance, is the environment that approximates production.\nThe test_echo() function, which resides in test/integration_tests.py, implements the integration test. The test starts by subscribing to the gg-cicd-test/out topic, then publishes a unique message to the gg-cicd-test/in topic. If it sees the published message on gg-cicd-test/out within 25 seconds, the test is successful.\nTo see how the tests use the AWS IoT Python SDK to subscribe to MQTT topics and register a callback function to process received messages, look at the listen_on_topic() function in this file. Use the AWS IoT SDK to subscribe to topics because the AWS SDK for Python (Boto 3) does not currently have that functionality.\nclass TestSampleFunction(unittest.TestCase):\n\n    def setUp(self):\n        set_received_messages({})\n\n    def test_echo(self):\n        input_topic = \'gg-cicd-test/in\'\n        output_topic = \'gg-cicd-test/out\'\n\n        listen_on_topic(client_id=\'TestSampleFunction.test_echo\', response_topic=output_topic)\n\n        iot_client = boto3.client(\'iot-data\')\n\n        message = {\n            \'id\': str(uuid.uuid4()),\n            \'processed_at\': str(datetime.now())\n        }\n\n        received_valid_response = False\n        for i in range(5):\n            if received_valid_response:\n                break\n\n            iot_client.publish(topic=input_topic, qos=1, payload=json.dumps(message))\n            time.sleep(MESSAGE_WAIT_TIME)\n\n            responses = get_received_messages()\n\n            key = \':\'.join([message[\'id\'], output_topic])\n            if key in responses:\n                received_valid_response = echo_response_is_valid(message, responses[key])\n\n        assert received_valid_response\nDeploying the project\nThe integration tests interact with your deployed Lambda function using the AWS IoT Core MQTT topics. Before you deploy for the first time, run the following commands to create the necessary AWS IoT certificates for the test\xe2\x80\x99s MQTT client, and store them in Systems Manager Parameter Store. This makes them available to the tests in CodeBuild securely.\n$> cd test\n$> ./setup_parameter_store.sh\n$> cd ..\nNext, push the project code to your repo to kick off the pipeline:\n$> git add .\n$> git commit -m \'adding project code\'\n$> git push -u origin master\nAfter the pipeline has completed successfully, you see actions for PullSource and CodeBuildAndDeployStage in the CodePipeline console for your pipeline. From BuildAndDeploy, choose Details to see the output from CodeBuild.\n  In the CloudFormation stacks list, there are two new Application stacks: gg-cicd-application-prod-stack and gg-cicd-application-test-stack. Each deploys your project to the test and prod AWS IoT Greengrass groups, respectively.\nYour AWS IoT Greengrass groups now show a recent deployment and have a Lambda function and subscriptions associated with them.\nInteracting with the deployed Lambda function\nUsing the AWS IoT MQTT client, subscribe to the gg-cicd-test/out topic and send messages to the gg-cicd-test/in topic to interact with your deployed test group. To interact with your deployed prod group, use gg-cicd-prod/out and gg-cicd-prod/in instead.\nPushing a change\nUse your favorite editor or integrated development environment (IDE) to add a timestamp to the responses generated by the Lambda function in src/sample_function/sample_function.py. It should look like the following:\nimport os\nimport json\nfrom datetime import datetime\nimport greengrasssdk\n\n\ncounter = 0\nclient = greengrasssdk.client(\'iot-data\')\n\ndef function_handler(event, context):\n    \'\'\'Echo message on /in topic to /out topic\'\'\'\n\n    response = json.loads(event)\n        \n    # Add the time we processed the message to our response\n    response[\'processed_at\'] = str(datetime.now())\n    \n    response_string = json.dumps(response)\n\n    client.publish(\n        topic=\'{}/out\'.format(os.environ[\'CORE_NAME\']),\n        payload=response_string\n    )\nWhile in the greengrass-cicd-project directory, commit the change and push it to the master branch of your CodeCommit repo:\n$> git add .\n$> git commit -m \'adding a timestamp to our Lambda response\'\n$> git push -u origin master\nThis change kicks off your pipeline to test and deploy the change, but this time the pipeline fails. The CodeBuild output, shows that the message sent by the integration test has a slightly different processed_at timestamp than that in the response. This difference is because the Lambda function and your test both use processed_at to record their timestamps. The Lambda function is overwriting the timestamp set by the test, so the response differs from the original message.\nFixing the bug\nTo fix the bug, change the key that your Lambda function uses from processed_at to echo_processed_at. Now your test and Lambda function store their timestamps in different message fields.\nEdit src/sample_function/sample_function.py so that it matches the following code:\nimport os\nimport json\nfrom datetime import datetime\nimport greengrasssdk\n\n\ncounter = 0\nclient = greengrasssdk.client(\'iot-data\')\n\ndef function_handler(event, context):\n    \'\'\'Echo message on /in topic to /out topic\'\'\'\n\n    response = json.loads(event)\n        \n    # Add the time you processed the message to the response\n    response[\'echo_processed_at\'] = str(datetime.now()) # use echo_processed_at\n    \n    response_string = json.dumps(response)\n\n    client.publish(\n        topic=\'{}/out\'.format(os.environ[\'CORE_NAME\']),\n        payload=response_string\n    )\nCommit and push the change to CodeCommit:\n$> git add .\n$> git commit -m \'put the echo timestamp in its own message field\'\n$> git push -u origin master\nBash\nThis time, the pipeline succeeds. You fixed the bug!\nVerifying the fix\nYou can verify that your new code is deployed to your prod group using the IoT MQTT client. Subscribe to the gg-cicd-prod/out topic and send messages to the gg-cicd-prod/in topic. Your Lambda function has added the echo_processed_at timestamp to your input message, as shown in the following screenshot.\n  Cleaning up\nWhen you are finished with the resources created in this post, you can delete the CloudFormation stacks that you used to create them. Keep the following in mind when doing so:\nWhen deleting the gg-cicd-pipeline stack, you might first have to empty the artifact bucket that it has created.\nBefore deleting the gg-cicd-<test|prod>-environment stacks, reset the group deployments.\nWhen deleting the gg-cicd-<test|prod>-environment stacks, you may encounter a GroupDeploymentReset issue. If so, delete the stack again.\nAdditionally, you can manually delete the following resources using the console:\nParameter Store entries\xe2\x80\x94Delete /gg-cicd-test/IOT_ENDPOINT, /gg-cicd-test/integration-testing-client.cert.pem and /gg-cicd-test/integration-testing-client.private.key.\nIntegration test AWS IoT certificate\xe2\x80\x94Delete the certificate with the gg-cicd-test-integration-test-client policy attached.\nIntegration testing AWS IoT policy\xe2\x80\x94Delete the policy named gg-cicd-test-integration-test-client.\nTroubleshooting errors\nIf you encounter errors when you deploy the stack, review the Status reason column in the Events section. For more information, see Automating AWS IoT Greengrass Setup with AWS CloudFormation.\n  Here are some common errors and their resolution:\nGroupDeploymentReset\xe2\x80\x94This error usually occurs when an IAM service role is not associated with AWS IoT Greengrass in the AWS Region deploying the stack. Check the CloudWatch stream logs for errors. For information about associating an IAM service role, see Greengrass Service Role.\nTemplate Format Error: Unrecognized resource types \xe2\x80\x94This error occurs when the template launches and indicates that AWS IoT Greengrass is not available in the AWS Region. Be sure to use a Region that supports AWS IoT Greengrass. For more information, see AWS Regions and Endpoints.\nMaximum VPCs reached\xe2\x80\x94This error occurs when you cannot create additional VPCs in the AWS Region. You can either request a service limit increase in the same AWS Region, or deploy the stack in a different AWS Region that supports AWS IoT Greengrass.\nIncorrect root.ca.pem\xe2\x80\x94If the checked root.ca.pem is not the right one for your certificates, select the appropriate one from the Amazon Trust Services Repository.\nSummary\nThis post covers the architecture of a CI/CD pipeline for an AWS IoT Greengrass project and demonstrates:\nUsing AWS CloudFormation stacks to create separate test and production AWS IoT Greengrass environments\nUsing CodePipeline and CodeBuild to update the test AWS IoT Greengrass environment when pushing a code change to the master branch of your CodeCommit Git project repository\nUsing the Boto3 and AWS IoT Python SDKs to implement an integration test in the test environment\nUpdating the production environment only when tests have passed.\nIntroducing a bug and preventing deployment to production with an integration test\nFixing the bug and deploying the fix from the pipeline to production\nAdopting these techniques should enable you to start using CI/CD practices to quickly deliver business value and reduce operational risk in your AWS IoT Greengrass projects!\n '"
178,Getting Aggregate Information of Devices with AWS IoT Device Management Fleet Indexing,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/getting-aggregate-information-of-devices-with-aws-iot-device-management-fleet-indexing/,"b'AWS IoT Device Management Fleet Indexing has launched three APIs for getting aggregate information of devices: GetStatistics, GetPercentiles and GetCardinality. With these APIs, you can quickly answer questions like: What\xe2\x80\x99s the percentage of the devices connecting to AWS IoT? What\xe2\x80\x99s the maximum, minimum and average of device battery level? How many OS versions are present?\nIn this blog post, we will walk you through a data center temperature monitoring simulation to understand how to use Fleet Indexing APIs to get aggregate information of the devices. A data center may have many sensors monitoring server temperatures. You will learn how to use GetStatistics to get the min/max/avg temperature; use GetPercentiles to get the 90th percentile of temperature; use GetCardinality to get the number of server racks with abnormal temperatures.\nSet Up\nEnsure you have the latest version of the AWS CLI installed.\nAssuming you are operating a data center with 10 temperature sensors connected to AWS IoT, distributed among 6 server racks. Some sensors are reporting abnormal temperatures. Let\xe2\x80\x99s use the script below to create 10 things representing the sensors. Each thing will have three attributes:\ntemperature: Number type \xe2\x80\x93 temperature value in Fahrenheit. Note that using thing attribute here is for simplicity of demonstration only. For best practices, please use AWS IoT Device Shadows for frequently changing fields.\nrackId: String type \xe2\x80\x93 id of the server rack where the sensor belongs. Ranging from Rack1 to Rack6.\nstateNormal: Boolean type \xe2\x80\x93 indicating if the temperature value is within normal range: [60 to 80]. Rack5 and Rack6 are in abnormal state.\n# Bash script. If in other shells, type `bash` before running\n\nTemperatures=(70 71 72 73 74 75 47 97 98 99)\nRacks=(Rack1 Rack1 Rack2 Rack2 Rack3 Rack4 Rack5 Rack6 Rack6 Rack6)\nIsNormal=(true true true true true true false false false false)\n\nfor ((i=0; i<10 ; i++))\ndo\n  thing=$(aws iot create-thing --thing-name ""TempSensor$i"" --attribute-payload attributes=""{temperature=${Temperatures[i]},rackId=${Racks[i]},stateNormal=${IsNormal[i]}}"")\n\n  aws iot describe-thing --thing-name ""TempSensor$i""\ndone\nBash\nTo get aggregate information of these sensors, you need to enable Fleet Indexing and define what fields to aggregate with the UpdateIndexingConfiguration API. In the sample code below, thing-indexing-configuration defines how things are indexed.\nthingIndexingMode: One of \xe2\x80\x9cOFF\xe2\x80\x9d|\xe2\x80\x9dREGISTRY\xe2\x80\x9d|\xe2\x80\x9dREGISTRY_AND_SHADOW\xe2\x80\x9d. Here REGISTRY means Fleet Indexing will only index the registry data of a thing.\ncustomFields: a list of field name and type pairs. In order to perform aggregation queries on a field, we have to include the field name and type, when setting up the indexing configuration. However, this does not apply to AWS IoT managed fields such as thingName, thingId and registry.version. Managed fields support aggregation queries by default.\naws iot update-indexing-configuration --thing-indexing-configuration ""thingIndexingMode=REGISTRY,customFields=[{name=attributes.temperature,type=Number},{name=attributes.rackId,type=String},{name=attributes.stateNormal,type=Boolean}]""  \nBash\nAfter turning on indexing, Fleet Indexing will create an index called AWS_Things. The index will first be in the BUILDING or REBUILDING state. After the existing things are indexed, the index status will flip to ACTIVE and be ready for queries. With 10 things, your index should be ACTIVE within seconds to a minute. You can check the index status with the following command\naws iot describe-index --index-name ""AWS_Things""\n\nResult:\n{\n    ""indexName"": ""AWS_Things"",\n    ""indexStatus"": ""ACTIVE"",\n    ""schema"": ""REGISTRY""\n}\nBash\nPerform Aggregation Queries\nOnce the index is ACTIVE, you can use GetStatistics API to monitor the statistics of all temperature sensors.\naggregation-field specifies which field to aggregate. Note, only custom fields defined with UpdateIndexingConfiguration or AWS IoT managed fields can be aggregated.\nquery-string defines a filter on things matching the query criteria.\naws iot get-statistics --aggregation-field ""attributes.temperature"" --query-string ""thingName:TempSensor*""\n\nResult:\n{\n    ""statistics"": {\n        ""count"": 10,\n        ""average"": 77.6,\n        ""sum"": 776.0,\n        ""minimum"": 47.0,\n        ""maximum"": 99.0,\n        ""sumOfSquares"": 62578.0,\n        ""variance"": 236.04000000000013,\n        ""stdDeviation"": 15.36359332968691\n    }\n}\nBash\nThe max and min temperatures are 99 and 47, which indicates some sensors are reading anomalies. To better understand the distribution, you can leverage GetPercentiles. This feature returns a list of probability and non-exceedance field value pairs. For example, in the following result you have {percent:90.0, value:98.1}. This means 90% of the temperature values are below 98.1. The input percentages defines a list of percentiles to return. Notice GetPercentiles gives approximation results. Larger aggregation set leads to more accurate estimations.\naws iot get-percentiles --aggregation-field ""attributes.temperature"" --query-string ""thingName:TempSensor*"" --percents 10 25 50 75 90\n\nResult:\n{\n    ""percentiles"": [\n        {\n            ""percent"": 10.0,\n            ""value"": 67.7\n        },\n        {\n            ""percent"": 25.0,\n            ""value"": 71.25\n        },\n        {\n            ""percent"": 50.0,\n            ""value"": 73.5\n        },\n        {\n            ""percent"": 75.0,\n            ""value"": 91.75\n        },\n        {\n            ""percent"": 90.0,\n            ""value"": 98.1\n        }\n    ]\n}\nBash\nCombining the two responses above, you can conclude a few sensors are detecting anomalies. Among them, most are reporting high temperatures. With GetCardinality, you can quickly check if the temperature problem is happening at one location (in one or two racks) or across the entire data center (all racks). Same as GetPercentiles, the results are estimations and accuracy improves over the scale. The result below means only two racks are having abnormal temperatures.\naws iot get-cardinality --aggregation-field ""attributes.rackId"" --query-string ""thingName:TempSensor* AND attributes.stateNormal:false""\n\nResult:\n{\n    ""cardinality"": 2\n}\nBash\nAmong all the racks, let\xe2\x80\x99s assume you know Rack6 has more servers than others. You can quickly look at the status of Rack6 using GetStatistics. From the result below, you can confirm Rack6 is too hot as the average temperature is 98.0.\naws iot get-statistics --aggregation-field ""attributes.temperature"" --query-string ""thingName:TempSensor* AND attributes.rackId:Rack6""\n\nResult:\n{\n    ""statistics"": {\n        ""count"": 3,\n        ""average"": 98.0,\n        ""sum"": 294.0,\n        ""minimum"": 97.0,\n        ""maximum"": 99.0,\n        ""sumOfSquares"": 28814.0,\n        ""variance"": 0.6666666666666666,\n        ""stdDeviation"": 0.816496580927726\n    }\n}\nBash\nAfter mitigating the problem, you can investigate the low temperature value of 47 with another Fleet Indexing API: SearchIndex. This API returns all the things satisfying the query string. Based on the result below, you know the low value is from TempSensor6 and actions are needed at Rack5.\naws iot search-index --query-string ""thingName:TempSensor* AND attributes.temperature<60""\n\nResult:\n{\n    ""things"": [\n        {\n            ""thingName"": ""TempSensor6"",\n            ""thingId"": ""45b45d4e-ad95-495f-828e-47df5454ab7c"",\n            ""attributes"": {\n                ""rackId"": ""Rack5"",\n                ""stateNormal"": ""false"",\n                ""temperature"": ""47""\n            }\n        }\n    ]\n}\nBash\nClean Up\nIf you no longer need the resources in the example, the following script can help to delete all the things.\nfor ((i=0; i<10; i++))\ndo\n  aws iot delete-thing --thing-name ""TempSensor$i""\ndone\nBash\nIt is recommended to keep Fleet Indexing enabled so the devices are always ready for queries. Optionally, you can turn thing indexing off with the following command.\naws iot update-indexing-configuration --thing-indexing-configuration thingIndexingMode=OFF\nBash\n'"
179,Using a Trusted Platform Module for endpoint device security in AWS IoT Greengrass,b'Asim Kumar Sasmal',2019-12-02T08:36:29+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/11/01/root_of_trust.png,https://aws.amazon.com/blogs/iot/using-a-trusted-platform-module-for-endpoint-device-security-in-aws-iot-greengrass/,"b'Co-authored by Aniruddh Chitre, AWS Solutions Architect\nThis post demonstrates how AWS IoT Greengrass can be integrated with a Trusted Platform Module (TPM) to provide hardware-based endpoint device security. This integration ensures the private key used to establish device identity can be securely stored in tamper-proof hardware devices to prevent it from being taken out of the devices for impersonation and other malicious activities.\nWith the ever-increasing adoption of IoT in various industries, managing the security of device fleets is a priority for any successful implementation. Industrial IoT also has to contend with devices deployed in remote, unmanned areas that cannot be easily secured. A compromised device can have ripple effects across the complete IoT solution ecosystem (equipment, devices, applications and network) with potentially damaging consequences for consumers and organizations.\nNormal IT-related scenarios, software countermeasures, e.g. usage of Anti-Virus software, are taken for granted to secure the system. These programs are active only after the boot sequence completes and the OS takes control of the system and launches the antivirus program.\nHowever, in IoT, another type of attack vector, commonly called bootkit or bootloader rootkit, can infect the master boot record. These bootkits subvert the normal booting process and allow for malicious programs to be executed before loading of the operating system. The bootkits escape detection by standard OS processes as they reside outside of the file system.\nTo handle these scenarios, the Trusted Computing Group (TCG) has developed Trusted Computing paradigm to protect computing infrastructure and billions of IoT devices. The TCG has created the specifications of a TPM that enforces specific behaviors and protects systems from unauthorized changes and attacks, such as malware and bootkits.\nWhat is a TPM?\nA TPM is a cryptographic processor present on most commercial PCs and servers. Ubiquitous in nature, it can be used for a wide variety of use cases, such as storing keys for VPN access and encryption keys for hard disks, or preventing dictionary attacks to retrieve private keys.\nWhile a typical TPM provides several cryptographic capabilities, three key features are relevant for this post:\nEstablishing a root of trust\nSecure boot\nDevice identification\nEstablishing a root of trust\nA TPM can prevent a bootkit attack by providing a trusted sequence of boot operation. The following questions often arise in a running system:\nIs the operating system that is running appropriately secure?\nIs the firmware booting the OS appropriately secure?\nIs the underlying hardware appropriately secure?\nEach layer has to trust the layer below, as illustrated in the following diagram.\nAt the root of this chain is the hardware, which has to be inherently trusted and forms the base on which the chain of trust has been established. In more technical terms, a root of trust is all of the following:\nSet of functions in a trusted computing module that is always trusted by the firmware/OS\nPrerequisite for secure boot process\nComponent that helps in detection of bootkits\nSecure boot\nA secured boot builds on the underlying notion of a root of trust to protect the boot process from being compromised on the device. This whole process by which the trustworthiness of a device is established right from the chip is called a \xe2\x80\x9cSecure Boot\xe2\x80\x9d. In case a chain of trust is broken, the boot process is aborted and the device attempts to go back to its last known good state.\nAn extension to secured boot process is a measured boot \xe2\x80\x93 where the device does not halt the boot process. Instead, it records the identity of each component that participates in the boot process so that these component identities can be verified later against a list of approved component identities for that device. This is called a measured boot.\nThese two processes are illustrated in the following diagram.\nA typical sequence of a measured boot is as follows:\nThe boot ROM acts as the root of trust.\nUpon a device reset, each image that forms part of the boot sequence is validated (measured) before execution.\nThe measurements are stored in a TPM.\nEach measurement serves as the proxy for the root of trust for the subsequent step in the boot sequence.\nNormally, only critical and security-sensitive process and configuration files are considered for the measurement.\nAfter the security-sensitive processes are completed, the device enters the unmeasured boot stage before entering normal system operation state.\nDevice identification\nIn IoT solution deployments, it is important to check the identity of the device that is communicating with the messaging gateway. The usual method is to generate key pairs for the devices, which are then used to authenticate and encrypt the traffic. However, key pairs residing on the disk are susceptible to tampering.\nThe TPM steps in here by storing the keys in tamper-resistant hardware. The keys are generated inside the TPM itself and are thereby protected from being retrieved by external programs. In fact, even without harnessing the capabilities of a hardware root of trust and secure boot, the TPM is also valuable just as a hardware key store. The private keys are protected by the hardware and offer far better protection than a software key.\nThe rest of this post focuses on how to integrate and use features of TPMs to protect the edge gateways running AWS IoT Greengrass. This integration uses the PKCS#11 protocol as the interface to the TPM.\n  What is AWS IoT Greengrass?\nAWS IoT Greengrass is software that extends cloud capabilities to local devices. Specifically, AWS IoT Greengrass provides cloud-based management of application logic that runs on devices. This enables devices to collect and analyze data closer to the source of information, react autonomously to local events, and communicate securely with each other on local networks. AWS IoT Greengrass developers can use AWS Lambda functions and pre-built connectors to create serverless applications that are deployed to devices for local execution.\nThe following diagram shows the basic architecture of AWS IoT Greengrass.\nUsing AWS IoT Greengrass, devices securely communicate on a local network and exchange messages with each other without having to connect to the cloud. Locally deployed AWS Lambda functions and connectors are triggered by local events, messages from the cloud, or other sources. If connectivity is lost, AWS IoT Greengrass provides a local pub/sub message manager that can intelligently buffer messages to preserve inbound and outbound messages to the cloud.\nAn AWS IoT Greengrass core is an AWS IoT thing (device). Like other AWS IoT devices, a core exists in the registry, has a device shadow, and uses a device certificate to authenticate with AWS IoT. The core device runs the AWS IoT Greengrass core software, which enables it to manage local processes for Greengrass groups, such as communication, shadow sync, and token exchange.\nDuring the registration of the AWS IoT Greengrass core, the keys and the certificates generated are stored in the local drives of the devices by default and are easily accessible. The following sections provide a deep dive into how the keys can be securely stored in tamper-proof hardware provided by the TPM.\nSecuring AWS IoT Greengrass with Infineon OPTIGA TPM\nWe will look at the steps required to secure AWS IoT Greengrass with the Infineon OPTIGA TPM products.\nThis integration requires the following components:\nA Raspberry Pi 3B+ running Raspbian Stretch.\nAWS IoT Greengrass v1.7+.\nInfineon OPTIGA TPM. This blog uses the Infineon OPTIGA SLB 9670. However the other supported OPTIGA TPMs are OPTIGA SLI 9670 and OPTIGA SLM 9670 which can also be used for automotive and industrial applications respectively.\nSetting up AWS IoT Greengrass on Raspberry Pi 3B+\nBecause the AWS IoT Greengrass core is an AWS IoT device, it has to be registered with the AWS IoT Core and comply with all security restrictions. It should have the following:\nA private key and public key pair.\nA certificate signed by a certificate authority (CA).\nFor more information, see the following documentation:\nSetting up a Raspberry Pi for AWS IoT Greengrass\nInstalling AWS IoT Greengrass Core Software\nAs part of the setup, the keys and certificate are stored in the folder /greengrass/certs/. After the device is registered with AWS IoT, you must take additional steps to ensure that the device keys are secured.\nFrom v 1.7.0, AWS IoT Greengrass supports the use of Hardware Security Modules (HSM) through the PKCS#11 interface for secured storage and offloading of the private keys. This prevents the keys from being exposed or duplicated in software. The private keys can be securely stored on hardware modules such as HSMs, Trusted Platform Modules (TPM) or other cryptographic elements.\nAWS has partnered with TPM manufacturers to protect the private keys inside a TPM. One of the TPM Manufacturer is Infineon Technologies, who provide a hardware TPM based security solution with their OPTIGA TPM products which can be used on embedded PC, mobile and other IoT Devices. All the OPTIGA TPM products comply with the Trusted Computing Group (TCG) standards.\nThe rest of the blog provides a step-by-step guide demonstrating how to use an Infineon OPTIGA TPM as an HSM for AWS IoT Greengrass on a Raspberry Pi 3 Linux environment. It can be performed with one of the following Infineon Iridium OPTIGA TPM SPI Boards:\nOPTIGA TPM SLB 9670 TPM2.0\nOPTIGA TPM SLI 9670 TPM2.0\nOPTIGA TPM SLM 9670 TPM2.0\nThis example uses the OPTIGA TPM SLB 9670 TPM2.0 for the AWS IoT Greengrass HSM integration.\nPrerequisites for setting up the TPM on the Raspberry Pi\nThe Infineon OPTIGA TPM uses the SPI interface to connect to the Pi on the GPIO Pins. Once the OPTIGA\xe2\x84\xa2 TPM is plugged into the PI, it should look as follows:\nGo through the following steps to validate the initial setup of the TPM and to check if the Raspberry Pi is able to recognize the TPM on reboot. For more information, see Preparation and Hardware Setup.\nReboot your Raspberry Pi and check that /dev/tpm0 is available. Update your system with the following command:\nsudo apt update && sudo apt upgrade\nBash\nInstall latest kernel using the following command:\nsudo rpi-update\nBash\nEdit /boot/config.txt and add the following line:\ndtoverlay=tpm-slb9670\nBash\nThis value for the dtoverlay parameter applies to SLB 9670, SLI 9670 and SLM 9670)\nRestart your Raspberry Pi and check if the TPM is recognized on reboot using ls /dev/tpm*. The output should resemble the following:\nA detailed verification can also be done by running a small utility, eltt2, provided by Infineon Technologies AG and available on GitHub. All of the following setup packages are created and built under the infineon-tpm directory.\nmkdir infineon-tpm \ngit clone https://github.com/infineon/eltt2\ncd eltt2\nmake\nsudo ./eltt2 -g\ncd ..\nBash\nThe output of the preceding command should resemble the following:\nThis output confirms that the TPM is working correctly. Understanding the different properties of the TPM is not required for the rest of the integration.\nIntegrating AWS IoT Greengrass with Infineon OPTIGA TPM\nFor a TPM to function, it requires a complete software stack including drivers, resource managers, and other tools. Each of these components is available from GitHub (see links in the following sections) and has been built to the specifications laid out by the Trusted Computing Group (TCG). These software components include:\nTPM TSS Library: This library consists of the TCG\xe2\x80\x99s TPM2 Software Stack (tpm2-tss) specification. This library comprises various software components that implement the low-level and high-level APIs, transmission of commands to the TPM, and the marshalling and un-marshalling of all the data structures defined by the TPM2 specification.\nTPM PKCS#11: The PKCS#11 is a public key cryptography standard that defines a standard method to access cryptographic services from tokens or devices such as HSMs or smart cards. In this example, the Infineon TPM serves as the HSM.\nTPM2 Access Broker and Resource Manager: These are system daemon processes that implement the TPM2 Access Broker (TAB) and Resource Manager (RM) spec from the TCG.\nThough all the above APIs are required for the proper functioning and use of TPM operations, AWS IoT Greengrass uses only the PKCS#11 APIs for storing and retrieving the primary keys.\nInstallation preconditions\nBefore installing the software stack and tools, ensure that the Raspberry Pi has all the packages required to build the TPM libraries. This includes upgrading the SSL and PKCS#11 packages, as the default packages in the Raspberry Pi are outdated.\nsudo apt update && sudo apt upgrade\nsudo apt -y install autoconf automake libtool pkg-config gcc libssl-dev \\\n\nlibcurl4-gnutls-dev libdbus-1-dev libglib2.0-dev autoconf-archive libcmocka0 \\\n\nlibcmocka-dev net-tools build-essential git pkg-config gcc g++ m4 libtool \\\n\nautomake libgcrypt20-dev libssl-dev uthash-dev autoconf doxygen pandoc \\\n\nlibsqlite3-dev python-yaml p11-kit opensc gnutls-bin libp11-kit-dev \\\n\npython3-yaml cscope\n\nsudo apt-get build-dep libengine-pkcs11-openssl1.1\nBash\nThe preceding steps build the basic dependencies to update the Raspberry Pi with the required libraries for compiling the source code in the subsequent steps.\nDownload the TPM2 software repositories\nDownload the following repositories:\ngit clone https://github.com/tpm2-software/tpm2-tss\ngit clone https://github.com/tpm2-software/tpm2-tools\ngit clone https://github.com/tpm2-software/tpm2-abrmd\ngit clone https://github.com/tpm2-software/tpm2-pkcs11\ngit clone https://github.com/OpenSC/libp11.git\n  Install a recent version of libp11\nUnfortunately, the version of the libp11 PKCS#11 engine for OpenSSL provided on Raspbian Stretch is too old (0.4.4) and not compatible with this software. Install it manually from the repositories. Compile and install the correct version:\ncd libp11\ngit checkout libp11-0.4.9\n./bootstrap\n./configure\nmake -j4\nsudo make install\ncd ..\nBash\nDownload the autoconf-archive and deploy to the projects\nThe version of autoconf-archive provided on Raspbian Stretch is not compatible with the TPM software stack. Download it manually and copy it to the respective repositories.\nwget https://github.com/autoconf-archive/autoconf-archive/archive/v2018.03.13.tar.gz\ntar -xvf v2018.03.13.tar.gz\ncp -r autoconf-archive-2018.03.13/m4/ tpm2-tss/\ncp -r autoconf-archive-2018.03.13/m4/ tpm2-abrmd/\ncp -r autoconf-archive-2018.03.13/m4/ tpm2-tools/\ncp -r autoconf-archive-2018.03.13/m4/ tpm2-pkcs11/\nBash\nInstall the TPM2 Software Stack library\nInstall the tpm2-tss library.\ncd tpm2-tss\ngit checkout 740653a12e203b214cba2f07b5395ffce74dfc03\n./bootstrap -I m4\n./configure --with-udevrulesdir=/etc/udev/rules.d --with-udevrulesprefix=70-\nmake -j4\nsudo make install\nsudo useradd --system --user-group tss\nsudo udevadm control --reload-rules && sudo udevadm trigger\nsudo ldconfig\ncd ..\nBash\nInstall the TPM2 Access Broker and Resource Manager (tpm2-abrmd)\nInstall the TPM2 Access Broker and Resource Manager.\ncd tpm2-abrmd\ngit checkout 2.1.1\n./bootstrap -I m4\n./configure --with-dbuspolicydir=/etc/dbus-1/system.d \\\nwith-systemdsystemunitdir=/lib/systemd/system \\\nwith-systemdpresetdir=/lib/systemd/system-preset \\\ndatarootdir=/usr/share\nmake -j4\nsudo make install\nsudo ldconfig\nsudo pkill -HUP dbus-daemon\nsudo systemctl daemon-reload\nsudo systemctl enable tpm2-abrmd.service\nsudo systemctl start tpm2-abrmd.service\ndbus-send --system --dest=org.freedesktop.DBus --type=method_call \\\nprint-reply /org/freedesktop/DBus org.freedesktop.DBus.ListNames \\\n| grep ""com.intel.tss2.Tabrmd"" || echo ""ERROR: abrmd was not installed correctly!""\ncd ..\nBash\nInstall the TPM2 Tools (tpm2-tools)\nInstall the TPM2 Tools.\ncd tpm2-tools\ngit checkout 3e8847c9a52a6adc80bcd66dc1321210611654be\n./bootstrap -I m4\n./configure\nmake -j4\nsudo make install\ncd ..\nBash\nInstall adaptation of PKCS#11 for TPM2 (tpm2-pkcs11)\nInstall the adaptation of PKCS#11 for TPM2.\nsudo mkdir -p /opt/tpm2-pkcs11\nsudo chmod 777 /opt/tpm2-pkcs11\ncd tpm2-pkcs11/\ngit checkout a82d0709c97c88cc2e457ba111b6f51f21c22260\n./bootstrap -I m4\n./configure --enable-esapi-session-manage-flags --with-storedir=/opt/tpm2-pkcs11\nmake -j4\nsudo make install\ncd ..\nBash\nUsing the PKCS11 Provider for AWS IoT Greengrass hardware security.\nIn this section, you create a keystore in which you create the keys and refer to the same in the AWS IoT Greengrass configuration.\nInitializing the keystore and token\nThe keystore is created under /opt/tpm2-pkcs11. The location should be readable and writeable to the logged-in user.\ncd tpm2-pkcs11/tools/\nBash\nInitializing the keystore\nUse the following command:\n./tpm2_ptool.py init --pobj-pin=123456 --path=/opt/tpm2-pkcs11/\nBash\nThe details of the options used in this command are:\n--pobj-pin POBJ_PIN   The authorization password for adding secondary objects under the primary object.\n--path PATH           The location of the store directory.\nBash\nInitializing the token\nUse the following command:\n./tpm2_ptool.py addtoken --pid=1 --pobj-pin=123456 --sopin=123456 --userpin=123456 --label=greengrass --path=/opt/tpm2-pkcs11/\nBash\nThe details of the options used in this command are:\n--pid PID             The primary object id to associate with this token.\n\n--sopin SOPIN         The Administrator pin. This pin is used for object recovery.\n\n--userpin USERPIN     The user pin. This pin is used for authentication for object use.\n\n--pobj-pin POBJ_PIN   The primary object password. This password is use for authentication to the primary object.\n\n--label LABEL         A unique label to identify the profile in use, must be unique.\n\n--path PATH           The location of the store directory.\nBash\nAdding a key\nUse the following command:\n./tpm2_ptool.py addkey --algorithm=rsa2048 --label=greengrass --userpin=123456 --key-label=greenkey --path=/opt/tpm2-pkcs11/\nBash\nThe details of the options used in this command are:\n--id ID               The key id. Defaults to a random 8 bytes of hex.\n\n--sopin SOPIN         The Administrator pin.\n\n--userpin USERPIN     The User pin.\n\n--label LABEL         The tokens label to add a key too.\n\n--algorithm {rsa2048,ecc256}\n                      The type of the key. Only RSA 2048 and ECC 256 are supported.\n\n--key-label KEY_LABEL\n                      The key label to identify the key. Defaults to an integer value.\n\n--path PATH           The location of the store directory.\nBash\nFinding the PKCS#11 URL\nAWS IoT Greengrass and other tools use a PKCS#11 URL to find the token and key object. This URL can be determined using p11tool:\nThis yields a result similar to the following:\npkcs11:model=p11-kit-trust;manufacturer=PKCS%2311%20Kit;serial=1;token=System%20Trust\npkcs11:model=SLI9670;manufacturer=Infineon;serial=0000000000000000;token=greengrass\nBash\nA screenshot of the same in this setup looks similar to the following:\nThe URL for the private key can then be determined using the following command:\n$ p11tool --list-privkeys pkcs11:manufacturer=Infineon\nBash\nThis yields a result similar to the following:\nObject 0:\n    URL: pkcs11:model=SLI9670;manufacturer=Infineon;serial=0000000000000000;token=greengrass;id=%37%33%61%36%62%30%31%37%39%66%39%33%39%38%62%38;object=greenkey;type=private\n    Type: Private key\n    Label: greenkey\n    Flags: CKA_NEVER_EXTRACTABLE; CKA_SENSITIVE;\n    ID: 37:33:61:36:62:30:31:37:39:66:39:33:39:38:62:38\nBash\nThe result is shown in the following screenshot:\nThe URL can be trimmed of certain components, as long as it remains unique, such as in the following example:\npkcs11:model=SLI9670;manufacturer=Infineon;token=greengrass;object=greenkey;type=private\nBash\nThis setup uses the complete URL, as follows:\npkcs11:model=SLB9670;manufacturer=Infineon;serial=0000000000000000;token=greengrass18;object=greenkey;type=private\nBash\nThe PIN can be appended to the URL:\npkcs11:model=SLI9670;manufacturer=Infineon;token=greengrass;object=greenkey;type=private;pin-value=123456\nBash\nThis is the URL to use for the AWS IoT Greengrass configuration.\nGenerate a certificate signing request\nUse the following command to generate a certificate signing request:\nopenssl req -engine pkcs11 -new -key ""pkcs11:model=SLI9670;manufacturer=Infineon;token=greengrass;object=greenkey;type=private;pin-value=123456"" -keyform engine -out /tmp/req.csr\nBash\nAnswer the questions that OpenSSL asks you for the certificate signing request. This information is incorporated into the certificate.\nAfter you have completed the request, log in to AWS and navigate to the AWS IoT console. On the left navigation pane, under Security, choose Certificates, Create.\nChoose Create with CSR and select the CSR file that you created using OpenSSL (for example, /tmp/req.csr).\nDownload the root.ca.crt and the resulting xxxxxx-certificate.pem.crt, where xxxxxx stands for a unique ID, and copy both to /greengrass/certs/.\nBefore closing the window, activate the certificate and attach it to an object or policy in the dialog on the AWS IoT security page.\nConfigure and run AWS IoT Greengrass with HSI\nTo enable and use the TPM as HSI, enable it in the AWS IoT Greengrass config. Edit /greengrass/config/config.json and replace the configuration with the content based on your OpenSSL configuration and location of the keys. A complete example of the AWS IoT Greengrass configuration with the setup completed in the preceding sections resembles the following:\n{\n  ""coreThing"" : {\n    ""thingArn"" : ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_NUMBER>:thing/<GG_Thing_Name>"",\n    ""iotHost"" : ""XXXXXXXXXXXXXXX-ats.iot.us-east-1.amazonaws.com"",\n    ""ggHost"" : ""greengrass-ats.iot.us-east-1.amazonaws.com"",\n    ""keepAlive"" : 600\n  },\n  ""runtime"" : {\n    ""cgroup"" : {\n      ""useSystemd"" : ""yes""\n    }\n  },\n  ""managedRespawn"" : false,\n  ""crypto"" : {\n    ""PKCS11"": {\n ""OpenSSLEngine"": ""/usr/lib/arm-linux-gnueabihf/engines-1.1/pkcs11.so"",\n ""P11Provider"": ""/usr/lib/arm-linux-gnueabihf/pkcs11/libtpm2_pkcs11.so"",\n ""SlotLabel"": ""greengrass18"",\n ""SlotUserPin"": ""123456""\n    },\n    ""principals"" : {\n      ""IoTCertificate"" : {\n        ""privateKeyPath"" : ""pkcs11:model=SLB9670;manufacturer=Infineon;serial=0000000000000000;token=greengrass18;object=greenkey;type=private"",\n        ""certificatePath"" : ""file:///greengrass/certs/2330b4c8b2-certificate.pem.crt""\n      },\n      ""MQTTServerCertificate"" : {\n        ""privateKeyPath"" : ""pkcs11:model=SLB9670;manufacturer=Infineon;serial=0000000000000000;token=greengrass18;object=greenkey;type=private"",\n        ""certificatePath"" : ""file:///greengrass/certs/2330b4c8b2-certificate.pem.crt""\n      }\n    },\n    ""caPath"" : ""file:///greengrass/certs/root.ca.pem""\n  }\n}\nBash\nAdjust the certificatePath, privateKeyPath, thingArn and iotHost accordingly. After this, you can start your AWS IoT Greengrass daemon using the following commands:\ncd /greengrass/ggc/core\nsudo ./greengrassd start\nBash\n'"
180,Support for Secure Elements in FreeRTOS,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/support-for-secure-elements-in-freertos/,"b'Secure elements represent a category of devices intended to enhance security in connected devices. For microcontroller (MCU)\xe2\x80\x93based devices, secure elements provide tamper-resistant storage of private keys and certificates, and offloading of cryptographic functions from the host microcontroller.\nYou can now leverage two new qualifications that include support for secure elements within Amazon FreeRTOS.  These qualifications expand choice and enhance security in development and deployment processes to securely connect Amazon FreeRTOS devices to mutually authenticated cloud services, such as AWS IoT Core.\nUsing a secure element means that the secret keys are not exposed to the host microcontroller and application. Memory-constrained devices can benefit from running cryptographic functions offloaded to a secure element. Also, the device provisioning process can be simplified and made more secure by taking advantage of secure elements with pre-provisioned keys, generated keys, and certificates.\nAmazon FreeRTOS uses secure elements through the open standard PKCS#11 interface. Device credentials and secret keys are accessed indirectly through handles, reducing the risk of data leakage. Use cases include Transport Layer Security (TLS), verifying signed Over the Air update (OTA) images, and device provisioning.  When secure elements are available, cryptographic functions are mapped to the features provided by the secure element.\nThe following diagram represents the data flow between the customer application, Amazon FreeRTOS libraries, the silicon vendor\xe2\x80\x93provided PKCS #11 implementation, and the secure element.\n    There are two reference integrations that use secure elements:\n\xc2\xb7 The Amazon FreeRTOS windows simulator implementation is connected to the Microchip ATECC608A secure element\n\xc2\xb7 The Infineon XMC4800 IoT Connectivity Kit with OPTIGA Trust-X\nBoth reference integrations have been qualified using AWS IoT Device Tester for Amazon FreeRTOS.\nWith these two new qualifications, you can use secure elements on these configurations, and use them as references when porting to other configurations. For more information about the use of secure elements with Amazon FreeRTOS, see PKCS#11 Cryptographic Libraries , and review the Securing Amazon FreeRTOS devices at scale with Infineon OPTIGA Trust X post.'"
181,Securing Amazon FreeRTOS devices at scale with Infineon OPTIGA Trust X,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/securing-amazon-freertos-devices-at-scale-with-infineon-optiga-trust-x/,"b'Post by David Walters, Senior Partner Specialist Solutions Architect, IoT at Amazon Web Services, and Artem Yushev, Applications Engineer, Embedded Security Systems, at Infineon.\nOne of the most significant challenges for device manufacturers developing new microcontroller-based IoT devices is how to manufacture and provision those devices at scale without compromising security.\nIn this blog post, we explore the options, considerations, and challenges for manufacturing IoT devices at scale. We examine how Amazon FreeRTOS provides security on the device. You learn how the secure provisioning model with AWS IoT Core and Amazon FreeRTOS can scale to millions of devices with the help of AWS partners like Infineon.\nFirst, we examine how AWS IoT authenticates devices to connect to the platform with X.509 certificates.\nAWS IoT certificate-based authentication\nAWS IoT uses Public Key Infrastructure (PKI) and Transport Layer Security (TLS) with X.509 certificates to authenticate devices connecting to the platform.\nIn a previous blog post, Setting Up Just-in-Time Provisioning with AWS IoT Core, we outlined the just-in-time provisioning (JITP) process. If you aren\xe2\x80\x99t familiar with JITP, we recommend that you spend some time familiarizing yourself with the process before reading on.\nThere are several certificates required to connect to AWS IoT Core using JITP. Some certificates are held on the device and others in a secure physical location on-premises.\nAmazon Trust Services (ATS) Endpoint Certificate\nThe ATS certificate is signed by a certificate authority (CA) owned by Amazon. When the device first connects to AWS IoT Core, this certificate is used by the device to verify that it is actually connecting to the AWS IoT server.\nCA signer certificate\nThe device manufacturer\xe2\x80\x99s designated CA signs the CA signer certificate. It is uploaded to AWS IoT to verify each device provisioned using the JITP process.\nThe CA signer certificate\xe2\x80\x99s private key should always be held in a secure location, on a hardware security module, in the factory or on-premises. You should exert control over who in your manufacturing and production supply chain can access the private key. If compromised, an attacker could use the CA signer certificate\xe2\x80\x99s private key to issue additional device certificates.\nDevice certificate\nEach device needs a uniquely generated device certificate, sometimes referred to as a client certificate, signed by the CA signer certificate\xe2\x80\x99s private key using a certificate signing request (CSR). The device certificate includes a public key and is signed with the CA signer certificate.\nWhen the device connects to AWS IoT for the first time, AWS IoT verifies that the device certificate has been signed with the CA signer certificate.\nOn some occasions, there may be a chain of certificates from the signer certificate to the device certificate.\nSecurely manufacturing IoT devices\nAt a certain point in your product development lifecycle, you are confident in your application and device design. Consider how you manufacture thousands, hundreds of thousands, or even millions of devices using the AWS IoT PKI model.\nSecure elements\nSecure elements provide tamper-resistant storage of private keys, certificates, and other data, as well as a host of cryptographic functions that can be performed on the module rather than in software.\nUsing a secure element ensures that the sensitive crypto elements are never exposed to the main microcontroller and application. In addition, power-constrained devices can benefit from running cryptographic functions on a secure element, because the cryptographic functions are more power efficient and several times faster than in software.\nChoosing a CA\nYou may choose to use your own CA, a partner\xe2\x80\x99s CA, or the ATS endpoint certificate provided by Amazon. If you choose to use your own CA, you must put the proper security measures in place to ensure that your root certificate is never compromised.\nDevice certificate generation and provisioning\nDevelopers often start developing their IoT devices with the security credentials baked into the firmware of the device. This approach is fine for prototyping and testing, but it\xe2\x80\x98s difficult to create custom firmware images for a large number of devices.\nIn a production scenario, it\xe2\x80\x99s common to generate and inject the device certificate and private keys at manufacturing time. Implement a delivery mechanism and the ability to write those credentials to a secure place on the microcontroller. With this method, take extra care to ensure your CA Signer Certificate and device certificate private keys are not compromised in transit.\nIf you have a secure element on your device, it may be possible to generate the device certificate\xe2\x80\x99s private key on the secure element. This means that your private key is never exposed to the factory, reducing the risk of your device credentials being compromised in transit.\nSecure storage of certificates\nConsider how to secure those credentials at rest on the device. You may choose to store them in an area in the microcontroller flash that is programmed one time, and never rewritten (One Time Programming, OTP), or a write-protected flash memory sector. A secure element can be used to store the certificates when tamper-resistant security is needed.\nAmazon FreeRTOS\nAmazon FreeRTOS (a:FreeRTOS) is an open-source operating system for microcontroller devices. Amazon FreeRTOS uses the real-time operating system FreeRTOS at its heart. The service adds in numerous additional libraries such as Bluetooth Low Energy, over-the-air (OTA) updates, an MQTT client, and all of the necessary security libraries to connect, secure, deploy, and manage the device.\nIn this post, we focus on the PKCS #11 library as it relates to managing the security of your devices.\nPKCS #11\nPKCS #11 is a standard that defines an API for security object lifecycle including retrieving and creating security objects like private keys and certificates. Amazon FreeRTOS uses PKCS #11 to access and modify security tokens to perform operations such as Transport Layer Security, OTA updates, and provisioning.\nAmazon FreeRTOS provides two ways for device manufacturers to leverage PKCS #11: software implementation and hardware secure elements.\nPKCS #11 software implementation\nThe software implementation of PKCS#11 works under the assumption that your security tokens are held on a specific area in flash on the microcontroller. All cryptographic operations are done in software inside Amazon FreeRTOS with mbedTLS, as shown in the following diagram. This area in flash should never be written to after programming the device, and is preferably write-protected.\nPKCS #11 interface with secure elements\nAmazon FreeRTOS provides a PKCS #11 API that can be implemented to interact with a secure element, as shown in the following diagram. The application simply calls these PKCS #11 APIs to perform actions like TLS handshakes or decryption of data, and the API makes the appropriate calls to perform the action on the secure element.\nInfineon OPTIGA Trust X with Amazon FreeRTOS\nOPTIGA\xe2\x84\xa2 Trust X by Infineon is a turnkey secure element solution based on a high-end security microcontroller, shown in the following image.\nThis secure element natively supports the following crypto primitives:\nFour slots to store user credentials such as a device certificate and a corresponding private key\nTwo certificate slots to store trusted certificates such as the ATS endpoint certificate\nUp-to 4.5 kBytes user provided data (excluding storage for certificates and private keys\nElliptic cryptography (EC):\nKey-pair generation for NIST P-256/P-384 curves\nSignature generation and verification for EC Digital Signature Algorithm (ECDSA)\nShared Secret generation using EC Diffie-Hellmann (ECDH)\nTrue and deterministic random number generation\nI2C interface\nCommon Criteria certified EAL6 + hardware\nIntegration with Amazon FreeRTOS\nInfineon has implemented the PKCS #11 APIs in Amazon FreeRTOS to interface with the OPTIGA\xe2\x84\xa2 Trust X. Amazon FreeRTOS provides a reference example of the integration of the OPTIGA\xe2\x84\xa2 Trust X with the XMC4800 Connectivity Kit development board.\nIn addition, Amazon FreeRTOS provides a demo application with instructions to provision a secure element with the correct certificates and private keys to connect to AWS IoT Core.\nNext, we examine how a single OPTIGA Trust X chip registers with AWS IoT and uses the ATS endpoint CA to generate device certificates, as shown in the following diagram.\nThe process is as follows:\nGenerate a new key pair on the OPTIGA Trust X and export the public key.\nGenerate a CSR.\nSend the CSR to the AWS IoT server\nAWS IoT constructs a new certificate based on the CSR and signs it with the ATS endpoint CA\nAWS IoT sends the resulting certificate back to the user.\nThe received certificate is written in the OPTIGA Trust X and linked to the private key slot.\nThis process demonstrates how the OPTIGA Trust X can be provisioned for devices in small numbers by a manual process.\nInfineon secure manufacturing\nWhen you are ready to manufacture your devices at scale, Infineon is able to pre-provision your OPTIGA\xe2\x84\xa2 Trust X secure elements in their security certified manufacturing facility.\nPre-enrolling all OPTIGA Trust X secure elements removes the complexity and security challenges that come with maintaining the certificate infrastructure in the AWS IoT PKI model. When you place the secure element chip on your device in the manufacturing process, your devices are ready to connect to AWS IoT and you know your devices were provisioned in a highly secure environment.\nInfineon takes extra precautions to protect all sensitive security tokens from being leaked or exposed during the provisioning process. The OPTIGA Trust X is Common Criteria EAL6+ certified and the personalization process is covered under this certification. The CC certificate can be found at www.bsi.bund.de by searching for BSI-DSZ-CC-0961 (Hardware Identifier IFX_CCI_00000Bh).\nJITP with secure elements\nInfineon\xe2\x80\x99s secure manufacturing process, along with JITP, enables your devices to connect to AWS IoT at scale when using OPTIGA Trust X secure elements. This is accomplished with the process shown in the following diagram and outlined below.\nThe process is as follows:\nInfineon creates a new dedicated CA issued by the Infineon root CA.\nUsing this new CA as the signer, Infineon securely provisions all OPTIGA Trust X secure elements with the necessary device certificates and private keys. The device certificate is set to read-only access and the private key will never leave the secure element.\nInfineon sends the provisioned OPTIGA Trust X secure elements to you along with the CA certificate.\nYou will register the CA Certificate with AWS IoT.\nAWS IoT requires proof of possession of the private key for the CA certificate, so must send this request back to Infineon. Infineon provides this registration certificate while preventing the private key from being exposed.\nYou use the registration certificate to complete the CA registration procedure on AWS IoT and set up a bulk provisioning template per the JITP process.\nAll of your devices with an OPTIGA Trust X can now be connected and provisioned to AWS IoT using JITP.\n'"
182,Converting industrial protocols with AWS IoT Greengrass,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/converting-industrial-protocols-with-aws-iot-greengrass/,"b'Gaining access to sensor data or telemetry of industrial machines is a key requirement for implementing high-value use cases around smart manufacturing or Industry 4.0. For instance, predictive maintenance or automated quality control is not possible without having such data at a high temporal resolution.\nGiven the heterogeneous environment of modern industrial production lines with many different machine types, it\xe2\x80\x99s difficult to access machine data because the machines\xe2\x80\x99 interfaces may use different protocols.\nThis post provides a detailed look at the conversion of industrial protocols and extracting data from industrial machines. The solution uses the AWS IoT platform and a fully automated setup using AWS CloudFormation with a virtual drill. You can derive a general design pattern for implementing protocol conversions using AWS IoT Greengrass.\nPrerequisites\nTo follow the content of this post, you need an AWS account and access rights to deploy a CloudFormation template that creates a VPC, a subnet and two EC2 instances. Code samples are provided in Python as part of AWS Lambdas deployed by the CloudFormation script.\nObtaining near real-time data from an industrial drill\nThis post provides a real-world example that allows you to explore and experiment with Industrial IoT technology. In this scenario, you want to connect an automated drill to AWS and retrieve its telemetry data every second. You can use the telemetry data to monitor production output or quality, detect anomalies, or do predictive maintenance.\nTo limit the scope of this post, the scenario focuses on connecting this drill. For more information, see Using AWS IoT for Predictive Maintenance.\nThe automated drill repeatedly executes the following operation:\nIt starts in an idle state.\nBased on a trigger not covered here, the drill starts a drilling procedure that lasts up to 15 seconds.\nDuring this work period, the drill spins up, and the motor speed (red line), as well as the spindle speed (blue line), increase to values between 1300 and 1600 rpm.\nAfter the drilling finishes, the drill spins down and returns to idle, waiting for the next trigger.\nThe following diagram shows six periods of this procedure. In some cases, the procedures deviate from the usual behavior. For example, in periods one, four, and six, the spindle speed and the motor speed are not in sync.\nGraph that illustrates functions and states of industrial drill\nTo allow hands-on experimenting and learning, this post uses an AWS CloudFormation template that deploys resources that simulate industrial assets, as well as the necessary structures in the AWS backend: Though both devices are simulated on Amazon EC2 instances, the setup is similar to that in a manufacturing plant. The gateway, as well as the drill, are in a subnet in which they can communicate with each other. The gateway has a connection to the internet and sends the data to AWS IoT Core. The gateway uses AWS IoT Greengrass with Lambdas to extract telemetry data from the drill.\nResources/Architecture deployed by AWS CloudFormation\nAs this post focuses on the conversion of industrial protocols, the drill has three interfaces that provide the same data, but use three different protocols:\nOPC-UA \xe2\x80\x93 A modern industrial protocol standard that includes security mechanisms as well as meta-data. Only the most recent versions of industrial assets typically have such an interface.\nModbus TCP \xe2\x80\x93 An industrial protocol invented in 1979. This protocol is an example for many other dated protocols used in existing machines, which lack security mechanisms as well as structure to the data they deliver.\nTCP  \xe2\x80\x93 This scenario includes a Transmission Control Protocol (TCP) to show that you can apply the protocol extraction pattern demonstrated here to custom or proprietary protocols. This also occurs with industrial assets that provide any binary payloads, such as images.\nThe drill has four main output variables that update every 500ms:\nStatus  \xe2\x80\x93 This indicates whether the drill is currently lifted (idle), drilling (working), or in a transition between idle and working.\nSpindle Speed  \xe2\x80\x93 The drill\xe2\x80\x99s spindle speed in RPM.\nMotor Speed  \xe2\x80\x93 The speed at which the motor of the drill rotates.\nPressure  \xe2\x80\x93 The pressure on the bit at the top of the drill.\nYou can turn the data about drilling operations obtained from the three preceding interfaces into JSON and push via MQTT over TLS 1.2 to AWS IoT Core.\nDeploying the AWS CloudFormation template\nTo deploy the AWS CloudFormation template which provides the resources shown in the aforementioned architecture diagram, execute the following steps:\nStep 1: log in to your AWS account\nStep 2: click on one of the following six links, depending on which AWS Region you would like to use:\nus-east-1 (North Virginia)\nus-west-2 (Oregon)\neu-west-1 (Ireland)\neu-central-1 (Frankfurt)\nap-northeast-1 (Tokyo)\nap-southeast-2 (Sydney)\nYou can check which Region you are deploying to by looking at the top right of the AWS Management Console. This scenario uses eu-west-1, but any AWS Region from the preceding list produces similar results.\nStep 3: Any of the preceding links result in a browser window showing AWS CloudFormation with the following fields:\nFor Stack name, you can optionally change the name of the stack.\nFor Parameters, you have the following User Options:\nFor EC2 Instance Type to be used, enter a different instance type. The pre-configured type t2.micro is sufficient for this post.\nFor Name tag to be appended to resources, enter a name tag that is easy to identify, such as Drill-Blog.\nThe stack deployment fails if you change the stack name or the name tag to values that are too long.\nStep 4: There are two check boxes at the bottom of the screen: I acknowledge that AWS CloudFormation might create IAM resources with custom names, and I acknowledge that AWS CloudFormation might require the following capability: CAPABILITY_AUTO_EXPAND. Select both boxes\nStep 5: Start the deployment process by clicking Next. The deployment of the stack takes up to 10 minutes. The stack uses nested stacks to deploy some basic resources.\nStep 6: When all stacks show the status CREATE COMPLETE, open the AWS IoT Core console.\nStep 7: On the left navigation pane, choose Greengrass Groups. Choosing Groups opens a page showing a deployed and configured AWS IoT Greengrass group.\nStep 8: Select the deployed group.\nStep 9: Click Actions at the top right and select Deploy.\nStep 10: If a corresponding pop-up appears, use Automatic detection. The AWS IoT Greengrass deployment should finish in under two minutes. It indicates the finish at the top left of the screen with a green icon and the message \xe2\x80\x9cSuccessfully completed\xe2\x80\x9d (instead of \xe2\x80\x9cNot deployed\xe2\x80\x9d).\nThe deployment starts the data extraction using Lambda functions that the AWS CloudFormation template created. This post goes through the different deployment steps and the corresponding Lambda functions.\nThe two EC2 instances, as well as the traffic, create charges to your AWS account. During a test run in eu-west-1, deploying and running the preceding architecture with 3 msg/s (1 msg/s from each conversion Lambda function) results in costs less than $0.15 per hour. To avoid unnecessary costs to your AWS account, make sure that you delete the stack when you are done.\nConverting protocols on AWS IoT Greengrass\nThe conversion of protocols with AWS IoT Greengrass relies on the ability to deploy Lambda functions to the AWS IoT Greengrass Core. For the conversion of protocols using AWS Lambda\xe2\x80\x94even beyond those discussed here\xe2\x80\x94adhere to the following four steps:\nLoad a protocol-specific library.\nConnect to the industrial asset.\nRead or retrieve data from the industrial asset.\nOptionally, convert the retrieved data into a usable format.\nPublish the read result to an MQTT topic.\nFollowing these four steps extracts the data from the drill and publishes the result of the conversion to a protocol-specific topic on AWS IoT Core. The code of the Lambda functions deployed using the AWS CloudFormation template contains comments that mark these steps.\nAccessing OPC-UA interfaces\nAll of the following sections use openly available libraries to access the drill. For more information, see the Python library on GitHub. All code examples\xe2\x80\x94those in this post as well as those deployed by AWS CloudFormation\xe2\x80\x94are optimized for readability at the cost of efficiency, error resiliency, or monetary cost.\nTo review the full code of the OPC-UA extraction function, open Lambda on the AWS Management Console. You can see a list of Lambda functions. The entries for the (1) OPC-UA extraction Lambda function as well as the extraction functions for (2) Modbus, and (3) raw TCP contain the code that executes on the AWS IoT Greengrass Core. To see the executed code, select the function whose name contains OPCUA.\nDeployed Lambda functions for protocol conversion lambdas\nBecause it is a long-running function, it only has an entry point that calls a function poll_opcua_server. This function has code similar to the following, which polls data from the OPC-UA interface of the drill every second:\nfrom opcua import Client as OPCUAClient """""" Step 1 """"""\n"""""" Step 2 """"""\nclient = OPCUAClient(""opc.tcp://"" + os.environ[""OPCUA_SERVER_HOSTNAME""] + "":4840"")\nclient.connect() # connect to the data source\nwhile True:\n """""" STEP 3 - Read/Retrieve data from the industrial asset """"""\n rootNode = client.get_root_node() # get the root node of the OPCUA tree\n results = {}\n for name, path in OPCUA_VARIABLES.items(): # payload defines names -> path relations\n  results[name] = rootNode.get_child(path).get_data_value() # get the value from the node identified by path\n """""" STEP 4 - Publish the read result to MQTT / AWS IOT Core. """"""\n extractResult = convertResultsToDict(results)\n iotclient.publish(topic=generateRawTopicName(), payload=json.dumps(extractResult))\n time.sleep(1) # get new value every second\nPython\nThe preceding Lambda code first creates a URL and an OPC-UA client instance. It reads the hostname from a system variable and constructs a URL from it. The actual extraction starts at the root node of the OPC-UA and retrieves data from its child nodes.\nA dictionary called OPCUA_VARIABLES maps names like SpindleSpeed to node path objects conforming to the OPC-UA standard, such as ns=2; s=Objects.PLC1.MAIN.Drill.SpindleSpeed.\nAfter the Lambda function retrieves these results, it converts them into JSON that follows the format described previously, and publishes the JSON as an MQTT.\nTo review the JSON sent by the OPC-UA, open the AWS IoT console. On the left navigation pane, choose Test. You can use the test function of AWS IoT Core to see incoming messages. For Subscription topic, enter opcua/#. This page shows all messages in the MQTT topics starting with opcua/.  Choose Subscribe to topic.\nThe following is an example of a message delivered to AWS IoT Core. It contains a timestamp, the state of the drill, as well as the telemetry data for motor speed, spindle speed, and pressure in JSON format:\n{\n   ""timestamp"": 1568012615.4760735,\n   ""MotorSpeed"": 16.707550552488215,\n   ""State"": ""DrillState.COOLDOWN"",\n   ""SpindleSpeed"": 21.89205389937024,\n   ""Pressure"": 2.4648222246416243\n}\nJSON\nAccessing Modbus TCP interfaces\nAccessing Modbus assets with Python requires the library pymodbus. For more information, see the Python modbus project on GitHub.\nCompared with the well-typed and structured format of OPC-UA, Modbus has a much lower abstraction level, but the general approach remains the same. To review the code, select the function from the Lambda console whose name contains Modbus (2).\nList of deployed Lambda functions including the Modbus Lambda (2)\nAs with the previous OPC-UA, the long-running Lambda function calls a function poll_measurements, which retrieves data from the Modbus master every second. The following is a condensed version of the code in this function:\n"""""" Step 1 """"""\nfrom pymodbus.client.sync import ModbusTcpClient as ModbusClient\n"""""" Step 2 """"""\nmbClient = ModbusClient(os.environ[""MODBUS_MASTER_HOSTNAME""], port=5020)\nmbClient.connect()\nwhile True\n """""" Step 3 Read/Retrieve data from the industrial asset """"""\n readResult = mbClient.read_holding_registers(address=0x0, count=32, unit=1)\n """""" Step 4 Publish the read result to MQTT / AWS IOT Core. """"""\n # transform the binary result into a dictionary\n extractResult = decodePayloadToDictionary(readResult=readResult)\n # publish the result to MQTT topics\n iotclient.publish(topic=generateRawTopicName(), payload=json.dumps(extractResult))\n time.sleep(frequency)\nPython\nThe first two steps of the Lambda function are similar to the one for OPC-UA: it imports the TCP client class of the library pymodbus. The Modbus TCP client connects to the given hostname/IP and a port, which it uses to read holding registers.\nGiven the low abstraction level of Modbus, you must provide correct memory addresses and the size of the memory area to read. The implementation of the client depends on the way you write the data, such as its order. The result of this read process is an unstructured binary object, which is then decoded.\nA call to a customized method decodePayloadToDictionary, which reads the various variables of the drill in order, simplifies the method of decoding this unstructured binary object. You can examine the code of this method in the Lambda function deployed through the AWS CloudFormation template. The result of this decoding procedure is published to a topic whose name starts with modbus/.\nTo view the messages published by this function, use the same steps described previously to subscribe to the topic modbus/#. The following is an example of such a message:\n{\n   ""timestamp"": 1568012917.0377738,\n   ""MotorSpeed"": 16.11205287977468,\n   ""SpindleSpeed"": 21.170123345258368,\n   ""Pressure"": 2.314612395615421,\n   ""State"": ""DrillState.IDLE""\n}\nJSON\nConfiguring the Modbus serial and RTU connectors\nThis post uses TCP as its underlying transport mechanism. Modbus also provides a protocol variant using serial connections and User Datagram Protocol (UDP). You can use the function described previously for this serial protocol, with the following minor changes:\nDepending on whether you use a UDP or serial connection, load a different client library.\nIn the case of a serial connection, the address of the endpoint from which the function has to retrieve data is not an IP address.\nFor example, connecting to a serial Modbus master needs the following code for steps 1 and 2:\nfrom pymodbus.client.sync import ModbusSerialClient as ModbusClient # Step 1\nclient = ModbusClient(method=\'rtu\', port=\'/dev/ttyp0\') # Step 2\nPython\nAWS IoT Greengrass needs hardware access to use a serial connection, therefore you need to configure it properly by adding the serial port as a local resource. Additionally, AWS IoT Greengrass offers a Modbus RTU Connector to retrieve Modbus data over a serial connection.\nAccessing raw TCP interfaces\nWhile many industrial assets use some application protocols like Modbus or OPC-UA, there are use cases that need to extract data from assets using fully proprietary protocols. Furthermore, there are use cases where industrial assets provide binary results, such as images or sound recordings.\nIn many of these cases, the interface to these assets is a TCP interface without any openly available application protocol. To review the Lambda code that extracts raw TCP from the drill, select from the Lambda console the function that contains Lambda (3).\nList of deployed Lambda functions including the raw TCP Lambda (3)\nThe long-running Lambda function calls a function poll_tcp_server, which retrieves data from the drill every second. The following code example shows how to use the socket library of Python to connect to such a machine and retrieve a binary payload:\nimport socket """""" Step 1 """"""\ntcpSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n"""""" Step 2 """"""\ntcpSocket.connect((os.environ[""TCP_SERVER_HOSTNAME""], os.environ[""TCP_SERVER_PORT""]))\nwhile True:\n """""" Step 3  - Read/Retrieve data from the industrial asset """"""\n data = tcpSocket.recv(1024)\n """""" Step 4  - Publish the read result to MQTT / AWS IOT Core. """"""\n result = json.loads(decodeBinaryPayload(payload=data))\n iotclient.publish(topic=generateRawTopicName(), payload=json.dumps(result))\n time.sleep(1) # wait for 1 sec and then read again \nPython\nSteps 1 to 3 are similar to the previous examples, but they use the socket library for Python. As with Modbus, step 4 starts with decoding the binary message into a format that you can convert to JSON. You can review the details of this method in the Lambda function deployed by AWS CloudFormation.\nFor other applications, you need different conversion methods, for example, if the binary payload contained an image. Because the payload for this drill example already contains a string, you can parse this string using the json.loads function.\nAs in the previous examples, the function pushes the JSON content to a topic starting with tcp/. You can see these messages by subscribing to tcp/# in the test function of AWS IoT Core:\n{\n   ""state"": ""DrillState.WORKING"",\n   ""motor"": 1397.3864579172175,\n   ""spindle"": 1358.69176246319,\n   ""pressure"": 10.208308057019503,\n   ""timestamp"": 1568013211.0736094\n}\nJSON\nInstead of publishing the telemetry data to AWS IoT Core, you can store a file directly to Amazon S3 using temporary access credentials associated with the AWS IoT Greengrass group. For more information, see Configure the Group Role. You need a direct file upload to S3 (or other services) if the industrial asset generates binary data, such as images or sound files.\n'"
183,Integrating IoT data with your data lake with new AWS IoT Analytics features,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/integrating-iot-data-with-your-data-lake-with-new-aws-iot-analytics-features/,"b'Post by Asim Kumar Sasmal, an AWS Senior Data Architect, and Vikas Panghal, an AWS Senior Product Manager\n  AWS IoT Analytics offers two new features to integrate IoT data ingested through AWS IoT Analytics with your data lake in your own AWS account: customer-managed Amazon S3 and dataset content delivery to Amazon S3.\nPreviously, your AWS IoT Analytics data could only be used with an Amazon S3 bucket managed by the AWS IoT Analytics service. This post describes a new end-to-end flexible, cost-effective, secure, and reliable solution to integrate IoT data with your data lake using these two recently released features.\nOverview\nAWS IoT Analytics is a fully managed IoT service that lets you filter, transform, and enrich real-time streaming IoT data. It stores data in a data store for analysis using a built-in SQL query engine and performs complex analytics such as machine learning inference.\nThe service also provides out-of-the-box integration for data visualization with Amazon QuickSight. AWS IoT Analytics also offers advanced data-exploration capabilities with Jupyter notebooks hosted and managed by Amazon SageMaker. You can containerize and schedule the execution of the Jupyter notebooks with just a few clicks.\nCustomers often ask how to bring their IoT data ingested using AWS IoT Analytics to their non-IoT data assets in their data lake on AWS seamlessly in near real time (~1\xe2\x80\x935 minutes). These data assets can include reference data such as ERP, financial, third-party weather data etc.\nThe goals are as follows:\nBuild an open, flexible, and consistent data store downstream on S3 for all your data assets in the company.\nDemocratize access to users for self-serve analytics.\nUse all the undifferentiated heavy-lifting offered by AWS IoT Analytics for high-velocity streaming data ingestion and processing.\nSolution\nWith the customer-managed Amazon S3 feature, you can create AWS IoT Analytics channels and data stores in an S3 bucket that you manage in your own AWS account. With the dataset content delivery to Amazon S3 feature, you can send AWS IoT Analytics dataset content results (materialized views of your AWS IoT Analytics data) to your S3 bucket in your AWS account.\nAs a result, you can now automatically create an AWS Glue catalog table containing the schema of your AWS IoT Analytics dataset content results and run queries with Amazon Athena. Because the dataset content results are saved in your S3 bucket, you can apply your own S3 permissions and manage them according to your governance policies.\nFollowing architecture diagram illustrates the high-level end-to-end solution you will build in this blog post.\nWalkthrough\nThis step-by-step walkthrough consists of the following sections:\nPrerequisites\nSetting up the AWS IoT Analytics channel, pipeline, and data store\nIngesting sample data into the AWS IoT Analytics channel\nCreating a dataset with dataset content delivery to S3\nIntegrating IoT data with other data stored in your data lake on AWS\nPrerequisites\nFor this use case, make sure that you have the following resources:\nAn AWS account in the same AWS Region where AWS IoT Analytics is available. This use case uses the US East (N. Virginia) Region. However, you can choose another AWS Region where AWS IoT Analytics is available.\nThe AdministratorAccess policy granted to your AWS account (for production, we recommend restricting this further).\nThe AWS CLI installed and configured to use with your AWS account.\nThis post provides an AWS CloudFormation template here to set up the required prerequisites. The template requires the following eight parameters with their default values. Replace aks with your own unique prefix. This avoids any conflict with AWS global resources across AWS accounts such as bucket names, which are unique across AWS accounts.\nParameter: DataLakeGoldIoTADatasetS3Bucket; Default Value: aks-datalake-gold-iota-dataset\nParameter: DataLakeRawIoTAChannelS3Bucket; Default Value: aks-datalake-raw-iota-channel\nParameter: DataLakeSilverIoTADatastoreS3Bucket; Default Value: aks-datalake-silver-iota-datastore\nParameter: DataLakeGoldS3Bucket; Default Value: aks-datalake-gold\nParameter: IoTAGlueDB; Default Value: aks_datalake_iota_glue_db\nParameter: IoTAGlueTable; Default Value: aks_device_telemetry_stats\nParameter: DataLakeGoldGlueDB; Default Value: aks_datalake_gold_glue_db\nParameter: DataLakeGoldDeviceSpecsGlueTable; Default Value: aks_device_specs\nThe AWS CloudFormation template creates the following resources:\nFour S3 buckets in your data lake, with the default encryption as AES-256 (SSE-S3):\naks-datalake-raw-iota-channel\naks-datalake-silver-iota-datastore\naks-datalake-gold-iota-dataset\naks-datalake-gold\nA bucket policy for aks-datalake-silver-iota-datastore to grant necessary permissions to AWS IoT Analytics.\nAn IAM role named iota_cmsb_role with trust relationships for AWS IoT, AWS Glue, and AWS IoT Analytics, and to grant necessary IAM permissions. This role allows the AWS IoT Core rules engine to publish MQTT messages to the AWS IoT Analytics channel and AWS IoT Analytics to process the real-time streaming data and create datasets.\nIf you create the AWS IoT Analytics resources (channel, pipeline, data store, dataset) from the AWS Management Console, the console creates the IAM role to grant necessary permissions. However, in an actual production environment, set up your IAM role ahead of time, with minimal permissions per your security standards.\nAn AWS Glue database named aks_datalake_iota_glue_db to use for AWS IoT Analytics dataset creation. It stores the necessary schema/metadata of the dataset content written to S3 for Athena to query the data content.\nAn AWS Glue Data Catalog table named aks_device_telemetry_stats in aks_datalake_iota_glue_db for Athena to query the dataset content.\nAn AWS Glue database named aks_datalake_gold_glue_db to use in an Athena query. It integrates your AWS IoT Analytics dataset written to S3 with your existing device specifications data in your data lake.\nAn AWS Glue Data Catalog table named aks_device_specs that has the schema/metadata for the device specification file on S3 (your existing data lake).\nCopy and save the Amazon Resource Name (ARN) for the IAM role named iota_cmsb_role created by the AWS CloudFormation template.\nUsing the AWS CLI, copy the device specifications CSV file named device_specs.csv from here to aks-datalake-gold bucket, as follows:\naws s3 cp device_specs.csv s3://aks-datalake-gold/aks_datalake_gold_glue_db/aks_device_specs/ --region \'us-east-1\'\nupload: ./device_specs.csv to s3://aks-datalake-gold/aks_datalake_gold_glue_db/aks_device_specs/device_specs.csv\nSetting up the AWS IoT Analytics channel, pipeline, and data store\nCreate an AWS IoT Analytics channel named aks_datalake_raw_iota_channel with Customer-managed Amazon S3 bucket as the storage type. Replace the IAM role with the ARN that you noted earlier and the aks prefix with your own prefix.\naws iotanalytics create-channel --cli-input-json file://mychannel.json --region \'us-east-1\'\n{\n    ""channelName"": ""aks_datalake_raw_iota_channel"",\n    ""channelArn"": ""arn:aws:iotanalytics:us-east-1:841719529236:channel/aks_datalake_raw_iota_channel""\n}\nThe file mychannel.json contains the following code:\n{\n    ""channelName"": ""aks_datalake_raw_iota_channel"",\n    ""channelStorage"": {\n        ""customerManagedS3"": {\n            ""bucket"": ""aks-datalake-raw-iota-channel"",\n            ""keyPrefix"": ""myhome_raspberrypi/"",\n            ""roleArn"": ""arn:aws:iam::xxxxxxxx:role/iota_cmsb_role""\n        }\n    }\n}\nJSON\nCreate an AWS IoT Analytics rule that sends messages to the channel that you created earlier. Replace the IAM role ARN with the one that you noted earlier and the aks prefix with your own prefix.\naws iot create-topic-rule --rule-name aks_iota_datalake_raw_iota_channel --topic-rule-payload file://rule.json --region \'us-east-1\'\nThe file rule.json contains the following code:\n{\n    ""sql"": ""SELECT * FROM \'iota/topic/myhome_raspberrypi\'"",\n    ""ruleDisabled"": false,\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""actions"": [\n        {\n            ""iotAnalytics"": {\n                ""channelName"": ""aks_datalake_raw_iota_channel"",\n                ""roleArn"": ""arn:aws:iam::841719529236:role/iota_cmsb_role""\n            }\n        }\n    ]\n}\nJSON\nCreate an AWS IoT Analytics data store named aks_datalake_silver_iota_datastore with Customer-managed Amazon S3 bucket as the storage type. Replace the IAM role ARN with the one that you noted earlier and the aks prefix with your own prefix.\naws iotanalytics create-datastore --cli-input-json file://mydatastore.json --region \'us-east-1\'\n{\n""datastoreName"": ""aks_datalake_silver_iota_datastore"",\n""datastoreArn"": ""arn:aws:iotanalytics:us-east-1:841719529236:datastore/aks_datalake_silver_iota_datastore""\n}\nThe file mydatastore.json contains the following code:\n{\n    ""datastoreName"": ""aks_datalake_silver_iota_datastore"",\n    ""datastoreStorage"": {\n        ""customerManagedS3"": {\n            ""bucket"": ""aks-datalake-silver-iota-datastore"",\n            ""keyPrefix"": ""myhome_raspberrypi/"",\n            ""roleArn"": ""arn:aws:iam::841719529236:role/iota_cmsb_role""\n        }\n    }\n}\nJSON\nCreate an AWS IoT Analytics pipeline named aks_datalake_iota_pipeline with the pipeline source as aks_datalake_raw_iota_channel and the pipeline output as aks_datalake_silver_iota_datastore. Replace the aks prefix with your own prefix.\naws iotanalytics create-pipeline --cli-input-json file://mypipeline.json --region \'us-east-1\'\n{\n""pipelineName"": ""aks_datalake_iota_pipeline"",\n""pipelineArn"": ""arn:aws:iotanalytics:us-east-1:841719529236:pipeline/aks_datalake_iota_pipeline""\n}\nThe file mypipeline.json contains the following code:\n{\n    ""pipelineName"": ""aks_datalake_iota_pipeline"",\n    ""pipelineActivities"": [\n        {\n            ""channel"": {\n                ""name"": ""mychannelactivity"",\n                ""channelName"": ""aks_datalake_raw_iota_channel"",\n                ""next"": ""mystoreactivity""\n            }\n        },\n        {\n            ""datastore"": {\n                ""name"": ""mystoreactivity"",\n                ""datastoreName"": ""aks_datalake_silver_iota_datastore""\n            }\n        }\n    ]\n}\nJSON\nIngesting sample data into the AWS IoT Analytics channel\nA Unix shell script generates the sample MQTT messages with the following code (replace the mqtttopic, region, and profile parameters per your environment). If you have the AWS CLI available and configured for your AWS demo environment, execute the shell script from your laptop or Amazon EC2. For this use case, send 1000 messages (iterations=1000).\n#!/bin/bash\n\nmqtttopic=\'iota/topic/myhome_raspberrypi\'\niterations=1000\nwait=5\nregion=\'us-east-1\'\nprofile=\'default\'\n\nfor (( i = 1; i <= $iterations; i++)) {\n\n  CURRENT_TS=`date +%s`\n  DEVICE=""P0""$((1 + $RANDOM % 5))\n  FLOW=$(( 60 + $RANDOM % 40 ))\n  TEMP=$(( 15 + $RANDOM % 20 ))\n  HUMIDITY=$(( 50 + $RANDOM % 40 ))\n  VIBRATION=$(( 100 + $RANDOM % 40 ))\n\n  # 3% chance of throwing an anomalous temperature reading\n  if [ $(($RANDOM % 100)) -gt 97 ]\n  then\n    echo ""Temperature out of range""\n    TEMP=$(($TEMP*6))\n  fi\n\n  echo ""Publishing message $i/$ITERATIONS to IoT topic $mqtttopic:""\n  echo ""current_ts: $CURRENT_TS""\n  echo ""deviceid: $DEVICE""\n  echo ""flow: $FLOW""\n  echo ""temp: $TEMP""\n  echo ""humidity: $HUMIDITY""\n  echo ""vibration: $VIBRATION""\n\n  aws iot-data publish --topic ""$mqtttopic"" --payload ""{\\""deviceid\\"":\\""$DEVICE\\"",\\""current_ts\\"":$CURRENT_TS,\\""flow\\"":$FLOW,\\""temp\\"":$TEMP,\\""humidity\\"":$HUMIDITY,\\""vibration\\"":$VIBRATION}"" --profile ""$profile"" --region ""$region""\n\n  sleep $wait\n}\nBash\nAfter the Unix shell script gets kicked off, you see the following output:\nPublishing message 1/ to IoT topic iota/topic/myhome_raspberrypi:\ncurrent_ts: 1559504319\ndeviceid: P03\nflow: 92\ntemp: 29\nhumidity: 81\nvibration: 127\nPublishing message 2/ to IoT topic iota/topic/myhome_raspberrypi:\ncurrent_ts: 1559504324\ndeviceid: P01\nflow: 67\ntemp: 21\nhumidity: 87\nvibration: 134\n\xe2\x80\xa6\xe2\x80\xa6\nThe sample script ingests data to the AWS IoT Analytics channel \xe2\x80\x93 aks_datalake_raw_iota_channel. At ingestion, AWS IoT Analytics partitions the data per day for both the channel and the data store to help with query performance. Go to your respective S3 buckets for your channel and data store. Confirm that you see data similar to the following screenshots.\nIn the AWS IoT Analytics console, choose Channel, aks_datalake_raw_iota_channel to monitor IncomingMessages, as shown in the following graph.\nCreating a dataset with dataset content delivery to S3\nStreaming data is being ingested to the AWS IoT Analytics channel and data store using the pipeline. Create an AWS IoT Analytics dataset named aks_datalake_gold_iota_dataset with Customer-managed Amazon S3 bucket as the storage type.\nRecently, AWS IoT Analytics released a new enhancement to support faster SQL dataset refresh intervals, so you can now refresh your SQL datasets as frequently as 1 minute. For this use case, refresh the schedule every 5 minutes as shown in the following code. Replace the IAM role ARN with the one that you noted earlier and the aks prefix with your own prefix.\naws iotanalytics create-dataset --cli-input-json file://mydataset.json --region \'us-east-1\'\n{\n    ""datasetName"": ""aks_datalake_gold_iota_dataset"",\n    ""datasetArn"": ""arn:aws:iotanalytics:us-east-1:841719529236:dataset/aks_datalake_gold_iota_dataset""\n}\nThe file mydataset.json contains the following code:\n{\n    ""datasetName"": ""aks_datalake_gold_iota_dataset"",\n    ""actions"": [\n        {\n            ""actionName"": ""myaction"",\n            ""queryAction"": {\n                ""sqlQuery"": ""SELECT current_timestamp dtts, deviceid, avg(temp) avg_temp, avg(flow) avg_flow, avg(humidity)  avg_humidity, avg(vibration) avg_vibration FROM aks_datalake_silver_iota_datastore where   from_unixtime(cast(current_ts as double)) > current_timestamp - interval \'5\' minute group by deviceid""\n            }\n        }\n    ],\n    ""contentDeliveryRules"": [\n        {\n            ""destination"": {\n                ""s3DestinationConfiguration"": {\n                    ""bucket"": ""aks-datalake-gold-iota-dataset"",\n                    ""key"": ""aks_datalake_iota_glue_db/aks_device_telemetry_stats/!{iotanalytics:scheduleTime}_!{iotanalytics:versionId}.csv"",\n                    ""glueConfiguration"": {\n                        ""tableName"": ""aks_device_telemetry_stats"",\n                        ""databaseName"": ""aks_datalake_iota_glue_db""\n                    },\n                    ""roleArn"": ""arn:aws:iam::841719529236:role/iota_cmsb_role""\n                }\n            }\n        }\n    ],\n    ""triggers"": [\n        {\n            ""schedule"": {\n                ""expression"": ""cron(0/5 * * * ? *)""\n            }\n        }\n    ]\n}\nJSON\nAfter the dataset is created, wait five minutes for the dataset to run as scheduled or run it one time manually from the AWS CLI as follows:\naws iotanalytics create-dataset-content --dataset-name ""aks_datalake_gold_iota_dataset"" --region \'us-east-1\'\n{\n    ""versionId"": ""02f6f531-ee49-4a8e-a43d-bf808e00a26b""\n}\nWait for the content to be created by running the following command. For your dataset content to be available on S3, the state should show as \xe2\x80\x9cSUCCEEDED.\xe2\x80\x9d\naws iotanalytics get-dataset-content --dataset-name ""aks_datalake_gold_iota_dataset"" --region \'us-east-1\'\n{\n    ""entries"": [\n        {\n            ""dataURI"": ""https://<bucket-name>.s3.amazonaws.com/results/4e5e1fd7-0cea-46c6-ae5b-0fff951a33f4.csv?X-Amz-Security-Token=AgoGb3JpZ2luEKL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSKAAhMtFbDcxGLCP9k3zF1jBMD3jUY5lKG5DUQPIc6CE%2F5qxkchbjfo0qVnY4qjmH04n9bCXl%2F0kY8uKBM3h%2F8p9ZWlKGmZZ01eQd2tXmmjGjUZQ3uoJfO8nMrv4lpe%2BSNOyhKhLT8sjTN7jf5hRGRDV9zWmNra1Pp1d8bMWfLiMAwe4FNy%2Bncma9xuutMuhGUuClxcxD12Ez1YanrS1qcvkLBMR3AwJAOuEDiyYOjV8GTWTDjdn%2Bz1EperZjgRd4mbCwIOTSsJu4fVkoEPuP8DJKidcSI2IE7mIit5Tpl6O0RaZ0aDy6sBVFsHHygdhpvr9LgcqgJoff4Eefez%2FgBOJRYq8gIIdxABGgwyMjE5OTE5MjIyNDciDGs74tSk4qge1k9cvCrPAqw%2Fvgbh%2FUpvbAAVOZB%2Fh%2FfW0uXyUm%2FSqAjs9kptzfI8lXxGci6etkBeFZqLuSXUSEIiy0OScGS%2Bu3sPudxQL9WgoRj0NzgReJN6Mw7IGGdBgmKouAhb1WeNq2QavtZ1jpnxGZwzKg0rC9qC7p%2Fyklx%2BGbG7xpkWynWHVnW%2FFcV2dlWcmy61aKjIo%2B5OHi1mYoP8dNRFIIofE%2BjnSwP1PX9nWwgPwOeuU6hUxduitUTDSMq30e1oAfDJp6wh43PPSGodeXCEHOKohx0bFmQ54Ua51YhiXkT7DHrRF78oxuFVuinYcIceMczpLb9lXK%2Fs1TM5g2dYFdz9Nq17vWP8XLqTVEe6eYBLcQq80ZDe4YYKgml3rFV2a4NjV1ZMXxq9C5YjZLpKTFmslewRXK7uOoLPV5UaymokNrFUF0mLff1e0r9JXTtnyJDynwCLBSt5MIGr9OcF&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20190609T141945Z&X-Amz-SignedHeaders=host&X-Amz-Expires=7200&X-Amz-Credential=ASIATHL575JD6AI7UM53%2F20190609%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=66635d16dbe1631d6fea60113a27c801e8ae1a57d6d0ec58766b790b5f54f960""\n        }\n    ],\n    ""timestamp"": 1560089957.29,\n    ""status"": {\n        ""state"": ""SUCCEEDED""\n    }\n}\nTo see 10 rows from the AWS IoT Analytics dataset that you created in the previous step:\nIn the Athena console, for Database, choose aks_datalake_iota_glue_db.\nFor New query 1, set the new query to run against the AWS Glue Data Catalog table named aks_device_telemetry_stats, and choose Run query.\nIntegrating IoT data with other data stored in your data lake on AWS\nAt the beginning of this post, you have set up an AWS Glue catalog table named aks_device_specs in your data lake. This table points to the file stored on S3 (your existing data lake) and is available for querying using Athena.\nTo see the data from the aks_device_specs table:\nIn the Athena console, for Database, select aks_datalake_gold_glue_db (which is your existing data lake).\nFor New query 1, set the new query to run against the AWS Glue Data Catalog table aks_device_specs, and choose Run query.\nYou can now integrate IoT data from the aks_device_telemetry_stats table in your AWS IoT Analytics with the aks_device_stats table in your existing data lake. Use the following commands to see how many times each device crossed the maximum temperature and humidity thresholds in the last two hours using an Athena query:\nselect\n        a.deviceid ,\n        sum(case \n                when cast(a.avg_temp as double) > b.max_temp_c \n                then 1 \n                else 0 \n        end) count_max_temp_crossed,\n        sum(case \n                when cast(a.avg_humidity as double) > b.max_humidity \n                then 1 \n                else 0 \n        end) count_max_humidity_crossed\nfrom\n        ""aks_datalake_iota_glue_db"".""aks_device_telemetry_stats"" a\ninner join ""aks_datalake_gold_glue_db"".""aks_device_specs""                b on a.deviceid = b.deviceid\nwhere date_parse(substr(dtts,1,19),\'%Y-%m-%d %H:%i:%s\') > current_timestamp - interval \'2\' hour\ngroup by \n        1\norder by \n        1;\nSQL\nThe following table shows the results.\nNow, instead of using the five-minute average from the aks_device_telemetry_stats data, do the same threshold check on the lowest grain data stored in the AWS IoT Analytics data store (aks_datalake_silver_iota_datastore). This check avoids losing the peaks and valleys of the actual readings from your devices.\nYou already have the lowest grain telemetry data in near-real time in the AWS IoT Analytics data store S3 bucket, named aks-datalake-silver-iota-datastore. Before you can query the same data using Athena, you must set up an AWS Glue crawler to run every 5 minutes, which is the lowest-scheduled frequency that you can set). Keep an AWS Glue catalog table named aks_datalake_silver_iota_datastore up-to-date with the telemetry data at near-real time (within 5 minutes of data ingestion):\naws glue create-crawler --cli-input-json file://mycrawler.json --region us-east-1\nThe file mycrawler.json contains the following code:\n{\n    ""Name"": ""aks_datalake_silver_iota_datastore_glue_crawler"",\n    ""Role"": ""arn:aws:iam::841719529236:role/iota_cmsb_role"",\n    ""DatabaseName"": ""aks_datalake_iota_glue_db"",\n    ""Description"": """",\n    ""Targets"": {\n        ""S3Targets"": [\n            {\n                ""Path"": ""s3://aks-datalake-silver-iota-datastore/myhome_raspberrypi/datastore/aks_datalake_silver_iota_datastore""\n            }\n        ]\n    },\n    ""Schedule"": ""cron(0/5 * * * ? *)""\n}\nJSON\nAfter the AWS Glue crawler is successfully created, wait five minutes for the crawler to execute as scheduled or run it once manually from AWS CLI using the following command:\naws glue start-crawler \xe2\x80\x94name ""aks_datalake_silver_iota_datastore_glue_crawler"" \xe2\x80\x94region us-east-1\nAfter the crawler run completes, execute the following Athena query using the lowest grain data from the AWS IoT Analytics data store. See how many times each device crossed the maximum temperature and humidity thresholds in the last two hours:\nselect\n        a.deviceid ,\n        sum(case \n                when cast(a.temp as double) > b.max_temp_c \n                then 1 \n                else 0 \n        end) count_max_temp_crossed,\n        sum(case \n                when cast(a.humidity as double) > b.max_humidity \n                then 1 \n                else 0 \n        end) count_max_humidity_crossed\nfrom\n        ""aks_datalake_iota_glue_db"".""aks_datalake_silver_iota_datastore"" a\ninner join ""aks_datalake_gold_glue_db"".""aks_device_specs""                b on a.deviceid = b.deviceid\nwhere from_unixtime(current_ts) > current_timestamp - interval \'2\' hour\ngroup by \n        1\norder by \n        1;\nSQL\nThe following table shows the results.\nNotice from the lowest grain data that the number of times the devices crossed the maximum temperature and humidity thresholds is much higher compared to the five-minute average. There are many other integration use cases you can do. For example, you could integrate with third-party weather data stored in your data lake to see if there is any correlation with weather changes.\nAlso, you can use Amazon QuickSight to visualize the last two hours of the lowest grain data from the aks_datalake_silver_iota_datastore overlain with the maximum temperature and humidity thresholds from aks_device_specs (the device-specification data in your data lake). Use the following sample Athena query (refer to the Amazon QuickSight documentation to create an Amazon QuickSight dataset with an Athena query):\nselect\n        from_unixtime(current_ts) as timestamp        ,\n        a.deviceid    ,\n        a.temp    ,\n        a.humidity,\n        b.min_temp_c  ,\n        b.max_temp_c  ,\n        b.min_humidity,\n        b.max_humidity\nfrom\n        ""aks_datalake_iota_glue_db"".""aks_datalake_silver_iota_datastore"" a\ninner join ""aks_datalake_gold_glue_db"".""aks_device_specs""                b on a.deviceid = b.deviceid\nwhere from_unixtime(current_ts) > current_timestamp - interval \'2\' hour\nSQL\nSummary\nIn this post, you learnt how to use two new AWS IoT Analytics features to integrate IoT data with the rest of your data stored in your data lake on AWS. Try using the customer-managed Amazon S3 and dataset content delivery to Amazon S3 features on your own projects.\nHopefully, you have found this post informative and the proposed solution helpful. As always, AWS welcomes feedback. Please submit comments or questions below.'"
184,Building microcontroller-based IoT applications using HTTPS client in Amazon FreeRTOS,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/build-your-mcu-based-applications-using-https-with-freertos/,"b'Today, AWS announced general availability for HTTPS client support in Amazon FreeRTOS. Now you can use the HTTP/HTTPS protocol to connect your microcontroller-based IoT devices to AWS IoT Core and download files to those devices.\nYou might want to use HTTPS on your IoT devices running Amazon FreeRTOS for a variety of reasons:\nTo download new features, images, and security patches to your home appliances\nTo add music files to your library\nTo conform to existing HTTPS-based legacy systems\nFor higher-bandwidth downloads\nWith this release, you can download firmware files, assets, and images using HTTPS.\nIn this post, we discuss how to use HTTPS client support in Amazon FreeRTOS to support your IoT fleet. We explain how the HTTPS client library works, and provide links to source code and demos to get started.\nHTTPS client library\nThe HTTPS client library in Amazon FreeRTOS supports the HTTP 1.1 protocol with HTTP GET requests. The library supports both synchronous and asynchronous programming models. The protocol blocks applications using a synchronous programming model of the HTTP client library from running instructions until the current HTTP request runs. The protocol allows applications using an asynchronous programming model of the HTTP client library to run instructions on the calling thread while the HTTP request runs on a different thread.\nYou can store these files on Amazon S3 or any other hosted service and specify the URL from which files download. You can transfer files in pieces and specify the size of each payload piece. Store your AWS access secret key outside your IoT device, on a secure Sigv4 presigned URL that you create. Your file transfers securely using TLS 1.2.\nGetting started\nDownload source code containing the HTTPS client library from the Amazon FreeRTOS GitHub repository or the Amazon FreeRTOS console. The console gives you the flexibility to download only the libraries that you need for your application and development board. The download contains demos to help you to get started quickly.\n'"
185,Building a virtual fob with Amazon Key for Business and AWS IoT,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/key-for-business-aws-iot-image.jpg,https://aws.amazon.com/blogs/iot/building-a-virtual-fob-with-amazon-key-for-business-and-aws-iot/,"b'For many people, getting a package delivered from Amazon is painless. However, problems can arise in access-controlled properties such as apartment complexes, condominiums, and businesses. This post tells how an Amazon team developed Amazon Key for Business to address this issue.\nOverview\nAmazon strives to make its package delivery process quick and easy for customers. However, sometimes an Amazon delivery associate can\xe2\x80\x99t access a building for several reasons:\nThe mail room is on a floor accessible only to authorized residents.\nThe leasing office or business reception area is closed.\nElevator access is restricted.\nIn these scenarios, customers must \xe2\x80\x9cbuzz\xe2\x80\x9d drivers into the building and meet them in the lobby or even outside, which takes coordination on both ends. If the customer is not available, the delivery is even more difficult.\nIf there\xe2\x80\x99s no safe location to leave the package, the delivery associate tries a re-delivery on a different day. This leads to delivery delays, calls to customer support, reorders, and sometimes many re-attempts before a successful delivery. Ultimately, it results in a poor customer experience.\nSolution\nTo solve this problem, an Amazon team created the Key for Business service, which integrates with a building\xe2\x80\x99s existing access system to grant authorized people temporary access to complete deliveries. This solution doesn\xe2\x80\x99t disrupt tenant access, so residents and business owners can continue to use their existing access method (access card or remote control). Amazon is also looking into creating standalone units.\nThe Key for Business service consists of two parts:\nAn Amazon proprietary smart fob unit, shown as follows\nThe Amazon Flex delivery app, with the Deliver page shown as follows\n  The service involves four steps:\nA delivery associate uses the Amazon Flex app to request access to a building.\nThe service verifies the delivery associate\xe2\x80\x99s details, along with the building location and time of day.\nThe service grants the delivery associate time-bounded temporary access.\nThe delivery associate delivers the package to the relevant location (such as the lobby or mail room).\nArchitecture\nTo build a solution that millions of delivery drivers around the world can use to access buildings, the team used the following AWS services:\nAmazon FreeRTOS\nAWS IoT Core\nAmazon DynamoDB\nAWS Lambda\nAmazon API Gateway\nAmazon FreeRTOS\nFirst, the team selected an appropriate microcontroller unit (MCU) for this smart building use case. Rather than spending hours scouring the web for pre-built hardware kits, they went directly to the AWS Partner Device catalog. This resource contains a list of hardware qualified to work with AWS IoT services, so they could rapidly prototype a proof-of-concept (POC).\nFor hardware, the team chose a Curiosity PIC32MZ EF modularized hardware development kit. With this kit, they could easily add customized peripherals such as a building-access controller protocol chip, cellular connectivity, Bluetooth, and so on. Most of these peripherals came with vendor or community drivers and firmware, which further accelerated application development.\nFor software, the team used Amazon FreeRTOS as the software stack for their MCU. This operating system extends the popular FreeRTOS kernel with security and connectivity libraries to make it fast and easy to connect MCU-based devices to AWS IoT.\nBecause Amazon FreeRTOS operates under an open source MIT license, it\xe2\x80\x99s free to download and deploy. The FreeRTOS kernel has a low 6\xe2\x80\x9315 KB\xe2\x80\x93memory footprint, making it the de facto, real-time operating system for MCUs. Its main features include:\nLocal and cloud connectivity libraries to connect to AWS IoT Greengrass and AWS IoT Core.\nSecure cryptography through certificate authentication, key management, and code signing.\nOver-the-air (OTA) updates via a single TLS-secured connection.\nFor more information, see Amazon FreeRTOS features.\nBecause the devices are offsite, the team added a dedicated cryptography chip to store AWS credentials on the physical device itself. They enabled TLS1.2 so that MQTT messages between the device and the AWS Cloud can be exchanged securely. For remote updates, they used the OTA functionality, which allowed them to easily update the device\xe2\x80\x99s software on an impromptu or scheduled basis.\nAnother benefit of choosing that particular MCU is that the vendor provided an integrated development environment (IDE) out of the box. This allowed the team to develop the application quickly on top of the Amazon FreeRTOS baseline and even to verify it with the kit.\nAfter the POC phase, the team iterated the prototype device into a production version that reduced costs more than if they had used off-the-shelf hardware.\nAWS IoT Core\nWith prototyping and POCs, you usually start with one device, then scale up to 10 or 100. However, the team needed something to help manage tens of thousands of devices. They chose AWS IoT Core, as it allowed them to manage devices at scale and paired well with Amazon FreeRTOS.\nFirst, they used the AWS command line interface (CLI) to create unique AWS IoT credentials and then pushed them to the device. Next, they created a unique thing for each device and onboarded each to AWS IoT Core.\nAWS IoT Core acts as an entry point for all the IoT devices and as a bridge to connect the devices to other AWS services. For example, MQTT messages are sent from AWS Lambda to every device and receive/validate a response. Devices also periodically send their status to AWS IoT Core, which kicks off an IoT rule to route them to AWS IoT Analytics for generating business metrics.\nDynamoDB\nThe team needed a place to store data\xe2\x80\x94in this case, device configurations. Due to their low-response-time needs, they used Amazon DynamoDB. This NoSQL offering provides single-digit millisecond performance at any scale, enabling the team to provide a low latency user experience.\nBecause their deployment occurs in phases, they opted for the on-demand capacity mode provided by DynamoDB so that they could start small and quickly scale out. This choice ended up giving the team the best balance between performance and cost. They also used the DynamoDB backup and restore feature to periodically back up their tables and recover immediately from disruptions.\nFor those readers wondering, \xe2\x80\x9cWhat about business metrics?,\xe2\x80\x9d the team set up an AWS Data Pipeline pipeline to convert the DynamoDB data into Amazon Redshift tables. That way, they could run any SQL query against these tables to generate business metrics.\nLambda and API Gateway\nBecause the team decided to use a serverless approach for their computing needs, all business logic was written as Lambda functions. There\xe2\x80\x99s no need to manage server infrastructure because Lambda functions are written once, then called only when needed.\nWhen a delivery associate uses the mobile app to request temporary access to a property, the calls are passed on to Amazon API Gateway. API Gateway then provides a RESTful API endpoint for the calls\xe2\x80\x99 backend Lambda functions. API Gateway authenticates the calls from the mobile app, and, after authorization, routes messages to Lambda accordingly.\nBy pairing Lambda and API Gateway, the team could perform upfront authentication, which allowed them to authorize application access to AWS IoT Core. Lambda automatically scaled up to meet their demand by only running functions in response to each trigger from API Gateway. With no servers to manage, the user is not billed for unused capacity. Instead, they are charged only when the functions are invoked.\nThe following diagram shows the complete solution architecture described in this post.\nResults\nA pilot using this smart fob solution launched in 2018 in five buildings that had a relatively high volume of re-deliveries because of an unsuccessful first-delivery attempt (known as a high defect rate). The results showed that:\nDelivery associates accessed buildings to make a delivery without bothering residents or businesses.\nThe first-delivery-attempt success rate increased from 96% to 98.1%.\nThe building defect rate decreased from 2.4% to 0.8%.\nAfter the pilot, production devices were rolled out to hundreds of buildings, with more scheduled for the future.\nSummary\nThe team successfully used AWS IoT offerings to reduce the rate of undelivered packages. These services provided the following capabilities:\nOnboarding of devices to AWS IoT Core using the AWS CLI.\nSecure boot and OTA updates of devices with Amazon FreeRTOS.\nManagement of devices as things through AWS IoT Core.\nSecure messaging with TLS 1.2 encryption between devices and AWS IoT Core.\nRouting of metrics and stats to AWS IoT Analytics through the IoT rules engine.\nThe Amazon FreeRTOS abstracted IoT platform allowed the team to focus on creating the application and getting it to market as quickly as possible.\nWant to experience the benefits of this successful delivery solution for yourself? To sign up for your own residential or business delivery, see Amazon Key for Business.\nBut wait, there\xe2\x80\x99s more\xe2\x80\xa6\nIf you enjoyed reading about the development of Key for Business, check out our video walkthrough on an episode of IoT all the Things program. In the episode Connecting Buildings to New Opportunities with IoT, we talk about this solution\xe2\x80\x94and even demonstrate the application and smart fob! Hope you enjoy the show!\nAbout the authors\nFrank Li is a senior embedded engineer at Last Mile IoT. He supports Amazon Last Mile customers by using IoT as both a technology and problem-solving approach to improve and reinvent deliveries.\n          Rudy Chetty is a senior solutions architect and hails from Cape Town, South Africa. He supports customers that fall under the Amazon umbrella, including Amazon Robotics, Fulfillment Technology, and Amazon.com. When not working, he yearns for a good Nando\xe2\x80\x99s burger meal in his hometown along with enjoying the view from the top of Table Mountain. Howzit Kaapstad!'"
186,"Improving industrial safety with video analytics, AWS IoT Core, and AWS IoT Greengrass",b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Improving-industrial-safety-with-video-analytics-AWS-IoT-Core-and-AWS-IoT-Greengrass.png,https://aws.amazon.com/blogs/iot/improving-industrial-safety-with-video-analytics-aws-iot-core-and-aws-iot-greengrass/,"b'Industrial customers are increasingly using the AWS Cloud to meet their targets for predictive quality, predictive maintenance, and asset condition monitoring. For more examples, see the Top Use Cases for Industrial IoT Applications ebook. The first of these, predictive quality, is often strongly correlated with the level of safety in an operating environment.\nIn this post, I describe a safety solution that harnesses AWS IoT Core and AWS IoT Greengrass. It was created by Bigmate, an AWS customer. Bigmate has integrated these services with preexisting CCTV cameras placed around infrastructural settings, such as warehouses, transport centers, and manufacturing sites. These AWS services equip the system to analyze, report on, and alert operators about anomalous or unexpected inputs, increasing industrial safety at the edge.\nUsing edge-based software and cloud-based services, Bigmate developed a platform that performs image analysis and object detection on an edge gateway. This platform can then predict an object\xe2\x80\x99s path based on its previous behavior. The platform can alert operators to potential accidents and unsafe behavior.\nIn a typical warehouse environment, the objects being analyzed might be people and forklifts. The platform can predict and alert operators about potential collisions based on deviations from objects\xe2\x80\x99 predicted paths, as shown in the following diagram.\nThe platform uses AWS IoT Greengrass, AWS IoT Core, Amazon DynamoDB, and Amazon EC2. The BigMate platform will soon incorporate Amazon SageMaker as well.\nBigmate initially developed the platform on standalone NVIDIA Jetson TX-2 Edge Gateways, but they quickly realized that this approach would be difficult to manage at scale across multiple facilities, edge gateways, and cameras. To enable easier scaling, they built their platform management functionality using AWS Lambda functions running locally inside AWS IoT Greengrass. This enabled the following benefits:\nUnattended deployment of software and configurations across many environments, without the need for a developer to work onsite.\nDirect from-the-edge integration with AWS services such as Amazon S3 to collect image samples and improve image classification model training.\nThe use of Amazon SageMaker to expedite improvement and deployment of AI models to the edge, which also expands the captured scenarios that populate the object detection library.\nThe Dropbear application (shown in the preceding diagram) performs multiple functions, including image capture, object detection, tracking, and depth analysis of CCTV camera streams. Dropbear is written in C++ so as to minimize latency, which is a critical factor in safety-related applications. Dropbear uses the AWS IoT SDK to communicate locally with AWS IoT Greengrass. It also uses the AWS SDK to enable image transfers to Amazon S3.\nThe benefit of this approach is that alerts and sirens can be triggered locally from AWS IoT Greengrass with mere milliseconds of latency. The system continues to work even without internet connectivity, ensuring that anomalies and safety concerns are detected quickly and alerts to personnel are reliable and timely.\nData is streamed to the cloud, where it is used to generate a consolidated multi-factory view on Bigmate\xe2\x80\x99s custom-built visualization platform, which uses DynamoDB and Amazon EC2. If an internet outage occurs, data can be spooled and saved. When the connection is reinstated, the platform sends the data.\nBy analyzing data across multiple facilities, operators can run analytics to compare varying levels of safety across facilities\xe2\x80\x94critical for an enterprise-wide assessment of organizational safety performance.\nIoT Edge and control services\nBigmate chose the NVIDIA Jetson TX2 chipset for their edge device because of its performance with AI workloads. Bigmate\xe2\x80\x99s application code\xe2\x80\x94including local Lambda functions and ML inference models\xe2\x80\x94can be ported to other NVIDIA GPUs. It gives the company a lot of choice and flexibility in future deployments. This flexibility is critical, considering the workloads required to detect, continuously track, and assess event generation policy, as well as calculate distance, across live video frames at the edge.\nPeter Girgis, CTO of Bigmate, said that AWS IoT Greengrass helped save them 2\xe2\x80\x933 weeks of development time by incorporating AWS security services instead of building security measures from scratch. Security is a critical requirement for Bigmate and their customers because the platform manages the confidentiality and integrity of CCTV and worker safety data.\nUsing AWS IoT and AWS IoT Greengrass, Bigmate achieved a 15\xe2\x80\x9320% reduction in development resource efforts overall, allowing the team to spend more time on the core application. By using native AWS services like AWS IoT Core and Amazon S3, they have also been able to achieve \xe2\x80\x9chigher overall availability.\xe2\x80\x9d\nBigmate quickly integrated their solution into existing CCTV infrastructure at scale by leveraging their existing video skills. There are several common protocols in use across the industry, such as UDP, RTP, and RTSP. Typically, a process can request a feed from a CCTV camera (with appropriate authentication), or a customer can configure a camera to push a camera feed to an IP address. However, video quality tuning (including jitter and bandwidth optimization) can require some experience to perform. The configuration for camera feeds is a JSON file hosted on the edge gateway. The process then deploys the configuration as an AWS IoT shadow document.\nThe edge gateway can connect to local devices such as sirens to alert operators to potential collisions. Bigmate tested a Sonoff SV connected to a battery in a custom 3D-printed case as an alerting device. It took approximately two hours to build this proof-of-concept. \xe2\x80\x9cYou couldn\xe2\x80\x99t do that a few years ago,\xe2\x80\x9d said Peter Girgis.\nMachine learning\nInitially, Bigmate prototyped their platform using a machine learning model based on YOLO and Darknet, mainly to speed up their time-to-market. Managing the prototype was a time-consuming manual process; it was great for early experimentation but too restrictive for production model deployments, functionality, and scaling. Bigmate has moved toward developing its own models using TensorRT, Amazon SageMaker, and Amazon SageMaker Neo. Consequently, Bigmate can now evolve its platform as problems arise, giving the company a high degree of flexibility in future deployments.\nBigmate has also implemented depth calculation for objects in CCTV frames from a single camera. Depth calculation allows the system to estimate the object\xe2\x80\x99s speed and the distance between objects, making for even more accurate alerts regarding safety issues.\nLessons learned\nBigmate CTO Peter Girgis was impressed with AWS IoT Greengrass: \xe2\x80\x9cFundamentally, AWS IoT Greengrass has enabled us to build our platform without having to develop the functionality ourselves.\xe2\x80\x9d\nThey have been able to rapidly develop their platform in a little over nine months with a core development team of only 3\xe2\x80\x934 people. The platform can be retrofitted and integrated into existing industrial sites. After it\xe2\x80\x99s installed, it can detect accidents before they happen and provide insights about improving safety across facilities. Looking toward the future, Bigmate is planning new features that will continue to make industrial workplaces safer and more secure.\n'"
187,Announcing Mitigation Actions for AWS IoT Device Defender,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/08/02/Start-Mitigation-Task-Duplicate-Certificate-1024x715.png,https://aws.amazon.com/blogs/iot/announcing-mitigation-actions-for-aws-iot-device-defender/,"b'There\xe2\x80\x99s a new way for you to act on information discovered by AWS IoT Device Defender audits. Now you can create mitigation actions for audit results that automate a response to alerts from an audit.\nAWS IoT Device Defender customers often say that it\xe2\x80\x99s invaluable for how AWS gives them visibility into potential malicious device activity. You can do the following:\n\xc2\xb7      Audit customer fleet to check for security best practices\n\xc2\xb7      Detect unusual activity by monitoring the behavior of your devices\nUsing the auditing capability of AWS, you can reference a report in the AWS IoT dashboard of all non-compliant devices. If a device becomes non-compliant, you receive an Amazon SNS notification.\nThis post describes how you can now select default mitigation actions. At the same time, you can still create a custom response using SNS. To see possible mitigation actions, look at an example alert scenario.\nOverview\nWhen you go to the AWS IoT Device Defender console, the first thing that you notice is a new tab under Defend called Mitigation actions. To create a new mitigation action, choose Create.\nAWS provides several default mitigation actions:\nAdd things to a thing group\nEnable IoT logging\xe2\x80\x94Use to enable global IoT logging.\nPublish a finding to SNS\nReplace the default policy version\xe2\x80\x94Use to replace a device\xe2\x80\x99s certificate policy with no policy; in other words, no permissions.\nUpdate the CA certificate\xe2\x80\x94Use to deactivate a CA certificate.\nUpdate the device certificate\xe2\x80\x94Use to deactivate a device certificate.\nWalkthrough\nFor this example, create a new thing group called \xe2\x80\x9cQuarantine\xe2\x80\x9d in the Thing Group dashboard. Then, create two new mitigation actions:\nAn action to completely disable a certificate, with the following configuration:\nAction name: Disable_Device\nAction type: Update device certificate\nAction execution role: AWSIoTDeviceDefenderAuditRole\nAction: Deactivate\nAn action to move things into a special \xe2\x80\x9cthing\xe2\x80\x9d group called \xe2\x80\x9cQuarantine,\xe2\x80\x9d with the following configuration:\nAction name: Quarantine\nAction type: Add things to thing group\nAction execution role: AWSIoTDeviceDefenderAuditRole\nThing groups: Select a thing group\nOverride dynamic groups: Select this option\nThe new thing group called \xe2\x80\x9cQuarantine\xe2\x80\x9d is selected in AWS IoT Device Defender as the target for the Quarantine mitigation action. You ask the mitigation action to remove the thing from all dynamic thing groups. You might use this action if you\xe2\x80\x99re using dynamic thing groups to perform over-the-air (OTA) updates using AWS IoT jobs. In that case, you don\xe2\x80\x99t want any further data sent to the compromised devices.\nFor any mitigation action, you give AWS IoT Device Defender a role (in this case called AWSIoTDeviceDefenderAudit) with the permissions it must have to perform the associated remediations. For a list of the necessary permissions by mitigation action, see the AWS IoT Device Defender Help documentation.\nNow, run a test. In this example, suppose that there are two connections open simultaneously with the same authentication certificate. This could mean that a device is provisioned incorrectly, or that a bad actor is in control of a device or its key pair.\nUsually, your default is to disable the certificate immediately until you determine what\xe2\x80\x99s happening. However, because there is a chance that there\xe2\x80\x99s simply a bug on the device, you don\xe2\x80\x99t want to delete the certificate. So what do you do?\nWhile drilling down into the results of an audit on the Audits results page, you notice that you have one non-compliant certificate that is shared.\nWhen you choose On-demand, you see the details of the audit findings, as shown in the following screenshot.\nBefore mitigation actions, you had two options:\nManually disable the non-compliant certificate.\nDisable the non-compliant certificate using an SNS notification that triggers an action through an AWS Lambda function.\nWith the new mitigation actions, just choose Start mitigation actions on the upper right to act immediately.\nWhen you choose Start mitigation actions, a pop-up appears showing categories of findings that need attention along with compatible mitigation actions. Under Select actions for Device certificate shared, three compatible mitigation actions appear: quarantine the thing, publish to SNS, or disable the certificate.\nTo correct this issue, choose one or more mitigation actions. You can even choose Select all to perform all the actions simultaneously. You\xe2\x80\x99re done!\n'"
188,Determining state in systems with high-frequency updates using AWS IoT Greengrass,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Determining-state-in-systems-with-high-frequency-updates-using-AWS-IoT-Greengrass.png,https://aws.amazon.com/blogs/iot/determining-state-in-systems-with-high-frequency-updates-using-aws-iot-greengrass/,"b'AWS IoT Greengrass extends AWS managed services to edge device systems, providing security, message routing, and local state processing. It also provides a central hub for connectivity with other AWS services using AWS Lambda functions.\nSome edge systems with multiple devices produce high-frequency updates, such as device shadow updates. It can be difficult to determine the definitive state of the system at a particular point in time. It also may prove difficult to move data from the edge to the cloud for further processing.\nPre-processing data from AWS IoT Greengrass devices at the edge before sending to the cloud can result in the following benefits:\nDecreased risk of reporting an inaccurate state: evaluating all received data from devices allows for smart determination of system state, rather than accepting device updates at face value.\nDecreased network traffic: pre-processing can reduce the size and volume of data that is transmitted to the cloud.\nDecreased data processing (compute) costs: processing is performed on the edge device running AWS IoT Greengrass Core, which does not incur additional usage costs for invoking local Lambda functions.\nChallenges associated with determining state in edge systems with multiple devices\nIn a system containing multiple devices that monitor the same real-life object, each one of these devices publishes an update event when it detects a state change in the real-life object.  In theory, these updates should all reflect the same change. However, in systems using unreliable methods to determine a state change (like ML models), device updates can disagree.\nThe problem of determining the state of a real-life object in a system such as this becomes more complex when considering systems with hundreds of devices.  For example, consider a use case wherein hundreds of IoT devices are being used to monitor safety conditions, such as carbon monoxide emissions, inside a factory.  In this scenario, whenever carbon monoxide emissions rise above a certain level, all devices should emit an update. However, device malfunctions or inaccurate readings might cause any single device to issue an \xe2\x80\x9cincorrect\xe2\x80\x9d update.\nConsider the simple system in the following diagram. Four devices monitor the same real-life object.  When the state of the real-life object changes, one device publishes an update that does not agree with the majority of updates from other devices.  If these devices publish updates at a high frequency, it can be difficult to determine the state of a system at any point in time.\nSo\xe2\x80\x94how can you reduce the risk of the system reporting inaccurate state information to downstream systems while simultaneously reducing network traffic and processing costs?\nIn this post, you create a local Lambda function running on an AWS IoT Greengrass core. The core is subscribed to all device update events, which collates received data and derives the state of the system at a given point in time.\nIf you are not familiar with AWS IoT Greengrass, check out Getting Started with AWS IoT Greengrass.\nSolution overview\nConsider a scenario: an edge system with 100 carbon monoxide detectors monitoring air quality in a factory.  These detectors publish a device shadow update one time every 1\xe2\x80\x935 seconds with 90% accuracy. The following is an example shadow document, with the \xe2\x80\x9cproperty\xe2\x80\x9d quality representing the parts per million (ppm) of carbon monoxide measured by the device.\n{\n   ""current"":{\n      ""state"":{\n         ""desired"":{\n            ""property"":""32""\n         }\n      },\n      ""version"":1116,\n      ""metadata"":{\n         ""desired"":{\n            ""property"":{\n               ""timestamp"":1559069499\n            }\n         }\n      }\n   },\n   ""previous"":{\n      ""state"":{\n         ""desired"":{\n            ""property"":""8""\n         }\n      },\n      ""version"":1115,\n      ""metadata"":{\n         ""desired"":{\n            ""property"":{\n               ""timestamp"":1559069498\n            }\n         }\n      }\n   },\n   ""clientToken"":""027d760a-3854-4e9e-a7a2-e98e69389b57""\n}\nJSON\nIn this system, there are multiple device updates each second, each reporting slightly different amounts of carbon monoxide.  So what is the state of the system at any point in time?  Build a local Lambda function to average the received data and send a single, authoritative state that is stored in Amazon DynamoDB.\nCreate a Lambda function for pre-processing\nThe Lambda function uses the concept of a \xe2\x80\x9cdecision window,\xe2\x80\x9d which is a time period bookended by two timestamps. Within the decision window, the average state of shadow updates is calculated and written to DynamoDB.\nConsider a 10-second decision window\xe2\x80\x94that is, publishing one state update every 10 seconds. This provides the following benefits:\nMore accurate system state observations.\nYou can now say \xe2\x80\x9cthe PPM was 60.5 over this 10-second window.\xe2\x80\x9d\nReduced network traffic.\nTransmits only one message every 10 seconds to DynamoDB.\nReduced processing costs.\nPerforms all message processing at the edge and only writes one row to DynamoDB.\nUpon receiving a shadow update, the Lambda function evaluates the timestamp and places the message in a queue with other received messages that exist within the same decision window. If there\xe2\x80\x99s no existing decision window, the Lambda function creates a new one. When the decision window expires (that is, the current time is past the end of the decision window), the messages in the queue are evaluated, averaged, and written to DynamoDB.\nUse two data structures to help calculate the average of a decision window:\nUPDATE_TIMESTAMP_WINDOWS: A double-ended queue (deque) structure containing a list of the start and end timestamps of decision windows. For example: [1553485283, 1553485284]\nCO_DETECTOR_UPDATE_QUEUES: A dictionary of queue objects containing shadow updates that fall into each decision window. The key for these queue objects is a hash of the sum of the start/stop timestamp of the decision window.\nIn the following code, upon invocation of the Lambda function using function_handler(), perform this procedure:\n1.     Check if the received shadow update timestamp falls into a decision window that currently exists, by checking the timestamp of the message against start/stop timestamps in UPDATE_TIMESTAMP_WINDOWS.  In this example, I have limited the deque to track only the 10 most recent decision windows.\n2.     If the message is found to be within an existing decision window, add it to the queue corresponding to that decision window and return from the function.\n3.     If the message is not within any existing decision windows, create a new decision window and corresponding hash key. Then, create a new queue, add the message, create a new Python Timer object, and return from the function.\nCreate the timer with the hash key and start/stop timestamps as arguments and point to the aggregate_co_detector_state() method.  This Timer object executes after DECISION_WINDOW_LENGTH seconds.\n""""""\nThis module contains an example Lambda function (Python 2.7) to be deployed with AWS Greengrass that aggregates messages received via devices\n""""""\n# pylint: disable=global-statement\nimport logging\nimport hashlib\nimport collections\nfrom datetime import datetime\nfrom threading import Timer\nfrom multiprocessing import Queue\nimport boto3\nfrom botocore.exceptions import ClientError\n\n# Define decision window length\nDECISION_WINDOW_LENGTH = 10\n\n# Attempt to create a DynamoDB table if not already created\nDYNAMO_DB = boto3.resource(\'dynamodb\', region_name=\'us-east-1\')\nTABLE_NAME = ""CODetectorStats""\n\ntry:\n    TABLE = DYNAMO_DB.create_table(\n        TableName=TABLE_NAME,\n        KeySchema=[\n            {\n                \'AttributeName\': \'Time\',\n                \'KeyType\': \'HASH\'\n            }\n        ],\n        AttributeDefinitions=[\n            {\n                \'AttributeName\': \'Time\',\n                \'AttributeType\': \'S\'\n            }\n        ],\n        ProvisionedThroughput={\n            \'ReadCapacityUnits\': 5,\n            \'WriteCapacityUnits\': 5\n        }\n    )\n\n    TABLE.meta.client.get_waiter(\'table_exists\').wait(TableName=TABLE_NAME)\nexcept ClientError as exception:\n    if exception.response[\'Error\'][\'Code\'] == \'ResourceInUseException\':\n        print(""Table already created"")\n    else:\n        raise exception\n\n# Initialize Logger\nLOGGER = logging.getLogger()\nLOGGER.setLevel(logging.INFO)\n\n# Declare aggregation data structures\nUPDATE_TIMESTAMP_WINDOWS = collections.deque(maxlen=10)\nCO_DETECTOR_UPDATE_QUEUES = dict()\n\n# Define aggregation function\ndef aggregate_co_detector_state(hash_key, start_time, end_time):\n    """"""Aggregate CO Detector Data""""""\n    global CO_DETECTOR_UPDATE_QUEUES\n    global TABLE_NAME\n    # Dequeue all messages in a time window and calculate average\n    total_reported_ppm = 0\n    total_messages = 0\n    while not CO_DETECTOR_UPDATE_QUEUES[hash_key].empty():\n        event = CO_DETECTOR_UPDATE_QUEUES[hash_key].get()\n        ppm_value = event[""current""][""state""][""desired""][""property""]\n        total_reported_ppm += int(ppm_value)\n        total_messages += 1\n    ppm_average = total_reported_ppm / total_messages\n    # Update DynamoDB\n    table = DYNAMO_DB.Table(TABLE_NAME)\n    table.put_item(\n        Item={\n            \'Time\':str(datetime.utcnow()),\n            \'StartTime\': start_time,\n            \'EndTime\': end_time,\n            \'TotalMessages\':total_messages,\n            \'PPMAverage\':ppm_average,\n        }\n    )\n\n# Define Lambda function handler\ndef function_handler(event, context):\n    """"""Handle Lambda Invocations""""""\n    global DECISION_WINDOW_LENGTH\n    global CO_DETECTOR_UPDATE_QUEUES\n    global UPDATE_TIMESTAMP_WINDOWS\n    LOGGER.info(""Received Event: %s. Context: %s"", str(event), str(context))\n    # Check if event fits into existing decision window\n    for update_timestamp_window in UPDATE_TIMESTAMP_WINDOWS:\n        start_time = update_timestamp_window[0]\n        end_time = update_timestamp_window[1]\n        if end_time >= event[""current""][""metadata""][""desired""][""property""][""timestamp""] >= start_time:\n            hash_string = str(start_time + end_time)\n            hash_key = int(hashlib.sha256(hash_string.encode(\'utf-8\')).hexdigest(), 16) % 10**8\n            CO_DETECTOR_UPDATE_QUEUES[hash_key].put(event)\n            LOGGER.info(""Enqueued event into decision window: %s"", str(event))\n            return\n    # Create new decision window and add event\n    try:\n        start_time = event[""current""][""metadata""][""desired""][""property""][""timestamp""]\n        end_time = event[""current""][""metadata""][""desired""][""property""][""timestamp""] + DECISION_WINDOW_LENGTH\n        UPDATE_TIMESTAMP_WINDOWS.append([start_time, end_time])\n        hash_string = str(start_time + end_time)\n        hash_key = int(hashlib.sha256(hash_string.encode(\'utf-8\')).hexdigest(), 16) % 10**8\n        CO_DETECTOR_UPDATE_QUEUES[hash_key] = Queue()\n        CO_DETECTOR_UPDATE_QUEUES[hash_key].put(event)\n        new_timer = Timer(\n            DECISION_WINDOW_LENGTH,\n            aggregate_co_detector_state,\n            args=(hash_key,\n                  start_time,\n                  end_time,)\n            )\n        new_timer.start()\n        LOGGER.info(""Created new decision window and enqueued event: %s"", str(event))\n    except: # pylint: disable=bare-except\n        LOGGER.info(""Unable to Process Event: %s"", str(event))\n        return\nPython\nConfiguring the Lambda function on AWS IoT Greengrass for pre-processing\nTo successfully perform pre-processing, you must ensure that the Lambda function is deployed with the following configurations:\nThe Lambda function lifecycle is set to \xe2\x80\x9clong-lived.\xe2\x80\x9d\nThe Lambda function is subscribed to all device updates.\nConfiguring the Lambda function as \xe2\x80\x9clong-lived\xe2\x80\x9d allows you to temporarily store received shadow updates in-memory in the Lambda container before performing processing and sending them to DynamoDB.\nThis configuration creates a single persistent container that starts automatically when AWS IoT Greengrass Core starts, then runs indefinitely.  Any variables or pre-processing functionalities that are defined outside the function handler persist for every invocation of the function handler.\nAdditionally, you must make sure that the Lambda function is subscribed to all device updates.  In this example, you use device shadow updates, so configure the Lambda function as follows:\nResults\nThis Lambda function is able to capture updates from multiple devices and provide consolidated updates to DynamoDB. The following screenshot shows some sample results from this function. Note how updates from multiple devices are averaged into a single DynamoDB entry covering a given time period:\nSummary\nIn systems with large numbers of IoT devices, performing pre-processing at the edge can provide a number of benefits:\nSimplification of data streams involving large numbers of devices.\nIncreased system state accuracy.\nReduced network traffic.\nReduced compute costs.\nThis approach is not limited to the aggregation of shadow updates.  You can expand it to any type of message in an IoT system, as well as variously complex processing logic. For instance, this example does not account for extreme outliers, any consensus among connected devices, or messages received with large time delays. However, it does provide a good general example of the benefits of edge pre-processing and message aggregation.'"
189,Designing dataflows for multi-schema messages in AWS IoT Analytics,b'Dan Noal',2019-10-30T15:51:04+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Designing-dataflows-for-multi-schema-messages-in-AWS-IoT-Analytics.png,https://aws.amazon.com/blogs/iot/designing-dataflows-for-multi-schema-messages-in-aws-iot-analytics/,"b'The AWS IoT Analytics platform offers configurable dataflows for processing messages from IoT devices, which can be either uni-schema or multi-schema. When you have billions of messages and millions of IoT devices, you need efficient designs for message-processing dataflows.\nIn this post, you do a deep dive into various aspects of designing dataflows. You learn about the types of dataflows, and then look at a simple use case and try to design a dataflow to match its example requirements.\nOverview\nThis post discusses the following topics:\nTypes of dataflows, including the pros and cons of each, and examples\nRules in AWS IoT Core that help send messages AWS IoT Analytics channels\nUse cases and analysis of how to choose a specific type of dataflow\nConsider the following points in each processing phase when selecting a particular dataflow to process IoT messages.\nPre-processing phase:\nTypes of IoT devices\nVolume of messages\nStructure of messages (uni-schema vs. multi-schema)\nWhether devices can be clustered in a group\nProcessing phase:\nList of activities for desired transformation\nOrder of activities for desired transformation\nSchedule of the processing dataflows\nDesired attributes for our analysis\nPost-processing phase:\nNumber of data stores needed\nData consumption\nAd hoc queries\nJupyter notebooks\nAmazon QuickSight\nTypes of dataflows\nTo process IoT messages efficiently on the AWS IoT Analytics platform, understand the different dataflow designs and select the best one for a particular use case. It\xe2\x80\x99s a challenging design problem\xe2\x80\x94you must clean, process, enrich, and transform incoming IoT messages quickly and at a low cost\nFor a simple dataflow for ingesting IoT messages, see Presenting AWS IoT Analytics: Delivering IoT Analytics at Scale and Faster than Ever Before.\nHere are some general requirements for dataflows:\nA pipeline must have a source and destination for the messages.\nEach pipeline can read messages from only one channel and can write the messages to only one data store.\nChannels can send data through multiple pipelines.\nData stores can generate multiple datasets, but the dataset can be generated from only one data store.\nTherefore, each message must go through at least one channel, one pipeline, and one data store. Based on the previous inferences, you can design four different types of dataflows:\nType 1: One channel, one pipeline, one data store\nType 2: N channels, N pipelines, one data store\nType 3: One channel, N pipelines, N data stores\nType 4: One channel, N pipelines, one data store\nType 1: One channel, one pipeline, one data store\nThis design offers a simple yet powerful configuration. A pipeline sources raw messages from one channel through one pipeline and stores the normalized messages in a data store, as shown in the following diagram.\nType 1 dataflow: 1 channel, 1 pipeline, 1 data store\n  To keep pipeline operations simple, it\xe2\x80\x99s best if all the messages follow the same structure (uni-schema) or if they vary predictably. For multi-schema messages or when the message schema varies widely across the devices, you might use a more complex pipeline architecture or run an AWS Lambda function for analytical requirements.\nExample: Consider a sensor placed in industrial equipment that emits messages about a specific parameter of the equipment, such as water level, internal temperature, or oil levels. The Type 1 dataflow would be best for this particular use case for the easy collection, transformation, and storage of transformed data for future analysis. Given the context of this example, here are the pros and cons of this kind of dataflow design:\nPros\nGood for fixed or uni-schema message processing (or when the message schema varies predictably).\nAll the messages are in one data store, which makes it easier to generate the datasets (for example, no dependency on other data stores).\nIncreased flexibility for analyzing the data, as all the attributes stored are in a normalized manner in the data store.\nCost-effective, as a message is ingested, processed, and stored only one time (two times, one in the channel and one in the data store).\nCons\nMessages with different schemas can\xe2\x80\x99t be handled.\nActivities in the pipeline can become complex.\nType 2: N channels, N pipelines, one data store\nIn this design, multiple pipelines each source data from their respective channel and store the transformed data stored in one data store, as shown in the following diagram.\nType 2 dataflow: N channels, N pipelines, 1 data store\nEach channel can either source data from a single IoT rule or from multiple IoT rules. If you want to perform analysis on different attributes originating from different sources and in different schemas, you can design dedicated pipelines for transforming such multi-schema messages. With this kind of design, you can store relevant data in one data store.\nExample: Consider the case of a car company, ABC Corporation, that manufactures three different types of car engines: Engine1, Engine2, and Engine3. These engines are designed for highly specialized applications, and ABC wants to analyze their performance while they\xe2\x80\x99re actively deployed across thousands of cars.\nEach type of engine is equipped with different types of sensors and emits data in a different message schema. This use case compares the engine performance across common parameters that can be derived from the engines\xe2\x80\x99 sensor data. To do this, ABC needs to process sensor data originating from each type of engine and design a dedicated transformation pipeline to convert the data into a common format.\nFor these types of use cases, this kind of dataflow design may be a good choice. Given the context of this example, here are the pros and cons of this type:\nPros\nMulti-schema messages are much easier to process than with the Type 1 dataflow.\nPipeline functionalities are easy to limit for a specific type of transformation.\nDatasets are easy to generate from one data store, so you don\xe2\x80\x99t have to worry about joining multiple data stores.\nMessages only go through the pipeline one time, saving the cost of replication at the channel level.\nCons\nData store may increase quickly as fed by multiple pipelines.\nQueries required to scan more data for creating datasets, which might increase the cost of creating datasets as the data store grows.\nType 3: One channel, N pipelines, N data stores\nThis design replicates the messages at the channel output. Each pipeline gets the same raw message received by the channel, and the channel acts as a broadcaster device. The following diagram shows this configuration.\nType 3 dataflow: One channel, N pipelines, N data stores\nEach pipeline can also act as a filter and be dedicated for a specific type of a message, thus each data store can store only a particular type of message.\nExample: Consider a fleet of cars emitting messages about engine, tires, cabin temperature, surrounding temperatures, and so on. You want to analyze each part\xe2\x80\x99s performance, and can have dedicated pipelines that each process messages from individual parts and filter out the rest of the messages. At the end of each pipeline, each data store contains only the processed messages of certain parts.\nGiven the context of this example, here are the pros and cons of this kind of dataflow design:\nPros\nCan perform the multiple independent transformations on the same message.\nBy filtering messages in the pipelines, individual data stores can be designed to store only subsets of all IoT messages.\nQuery for generating a dataset doesn\xe2\x80\x99t have to scan lots of data when pipelines are configured to filter out messages.\nCons\nMust consider the cost factor, as such configurations can increase cost due to the replication of messages among multiple pipelines. An alternative solution for such dataflow would be to create multiple channels, with each channel configured to receive specific types of messages from the IoT rule engine. In such a case, the solution would look like you repeated the Type 1 solution multiple times.\nType 4: One channel, N pipelines, one data store\nAs with Type 3, in this type of dataflow, the messages are replicated at a channel level. Each pipeline gets the same raw message received by the channel, as shown in the following diagram.\nType 4 dataflow: 1 channel, N pipelines, 1 data store\nThis kind of configuration is good for cases in which you want to derive different types of parameters. It\xe2\x80\x99s also good for enriching the data with different types of information for data that originates from a common source.\nExample: Consider route analysis for network routers. A network device manufacturing company performs trend analysis based on the health and performance of the network as the volume and composition of messages change over time. The company can use the data emitted by the network routers and design two different pipelines: one for processing health- and performance-related transformation and another for the volume and composition of message-related aggregation.\nAt the end, all transformed data can be put into one data store for further analysis based on notebooks or SQL-based datasets in the AWS IoT Analytics applications portal. Given the context of this example, here are the pros and cons of this kind of dataflow design:\nPros\nAbility to perform multiple independent transformations on the same message.\nThe transformed messages end up in one data store, making it easier to generate multiple datasets.\nCons\nIncreased cost due to replicating messages among multiple pipelines. An alternative solution for such dataflow is to create multiple channels, with each channel configured to receive specific types of messages from an IoT rule. In such a case, the solution appears to repeat the Type 1 dataflow multiple times.\nConnecting the AWS IoT rules engine to AWS IoT Analytics\nAWS IoT rules give you the ability to interact with AWS services, forward messages to Amazon DynamoDB, notify users through Amazon SNS, or send messages to AWS IoT Analytics channels. There are two ways to do this:\nOne AWS IoT rule can replicate messages to multiple channels, as shown in the following diagram.\n1 IoT Rule to N IoT Analytics Channel\nMultiple rules can forward messages to the same channel, as shown in the following diagram.\nN IoT Rules to 1 AWS IoT Channel\nUse case\nConsider a weather sensor device and a barometer sensor device responsible for following:\nWeather sensor: Sends out messages about humidity and temperature readings.\nBarometer sensor: Sends out messages about air pressure and temperature readings.\nThere are four different types of messages coming from these sensors, as shown in the following chart.\nWeather Sensor Messages\nMessage 1\n{\n""type"": ""weather"",\n""source"": {\n""epoch"": 1508629428,\n""humidity"": 67,\n""unit"": ""RH"",\n""full_topic"": ""rtjm/A020A6008464/weather/humidity"",\n}\n}\nMessage 2\n{\n""type"": ""weather"",\n""source"": {\n""epoch"": 1508629550,\n""temperature"": 12,\n""unit"": ""C"",\n""full_topic"":  ""rtjm/A020A6008464/weather/temperature"",\n}\n}\nBarometer Sensor Messages\nMessage 1\n{\n""type"": ""barometer"",\n""epoch"": 1508311359,\n""pressure"": 100660.53,\n""unit"": ""Pa"",\n""full_topic"":  ""rtjm/A020A6008464/barometer/pressure"",\n}\nMessage 2\n{\n""type"": ""barometer"",\n""epoch"": 1508311370,\n""temperature"": 19.41,\n""unit"": ""C"",\n""full_topic"":  ""rtjm/A020A6008464/barometer/temperature"",\n}\nBecause the schemas of weather messages and barometer messages are different, the same method to extract the key value parameters can\xe2\x80\x99t be applied.\nFor the final dataset, the goal is to see the attributes shown in the following list in one data store (unit and full_topic attributes can be dropped).\nType \xe2\x80\x93 Type of device from which the data originated\nEpoch \xe2\x80\x93 Timestamp when the message was generated\nHumidity \xe2\x80\x93 Relative humidity in percentages\nPressure \xe2\x80\x93 Barometric pressure reading (in Pascal)\ntemperature_weather \xe2\x80\x93 Temperature (in \xc2\xb0C) sensed by the weather sensor\ntemperature_barometer \xe2\x80\x93 Temperature (in \xc2\xb0C) sensed by the barometer sensor\nFeed all the messages through the AWS IoT console.\nThe following section evaluates the four different types of dataflows and describes how to choose one for this use case. Remember the following list that you saw earlier in the Overview section.\nPre-processing phase:\nTypes of IoT devices \xe2\x80\x93 2\nVolume of messages \xe2\x80\x93 10,000 per device\nStructure of messages (uni-schema vs. multi-schema) \xe2\x80\x93 Multi-schema messages\nWhether devices can be clustered in a group \xe2\x80\x93 Each device belongs to its own cluster.\nProcessing phase:\nList of activities for desired transformation\nFilter, addAttribute, removeAttribute\nLambda function\nOrder of activities for desired transformation\nFilter, addAttribute, removeAttribute\nSchedule of the processing dataflows\nOne time\nDesired attributes for the analysis\nType, epoch, humidity, pressure, temperature_weather, temperature_barometer\nPost-processing phase:\nNumber of data stores needed\nOne data store\nData consumption\nAd hoc queries\nChoosing a dataflow\nNow, consider each type of dataflow and evaluate its applicability to this use case:\nType 1: Because the messages have different schemas, a single pipeline can\xe2\x80\x99t handle all incoming messages without having a complex architecture or Lambda function.\nType 2: This kind of dataflow allows you to process messages of multiple schemas through their designated channels. But be careful how you choose the attributes and messages you want to store in the data store; a data store should contain only those attributes and messages that add value to the datasets. For the messages shown earlier, you can set up one pipeline for processing weather messages and another pipeline for processing the barometer messages. Because the messages are partitioned among various channels, each message goes through the pipeline once, thus reducing time and cost. Therefore, Type 2 appears to be a good choice for this use case.\nType 3: This kind of configuration would not be a good choice for this use case. Why? You don\xe2\x80\x99t intend to replicate the messages for multiple pipelines, and you don\xe2\x80\x99t want the weather data and barometer data stored in different data stores.\nType 4: Similar to Type 3, this kind of configuration would not be a good choice for this use case, because you do not intend to replicate messages for multiple pipelines. You also don\xe2\x80\x99t want weather data and barometer data stored in different data stores. You also don\xe2\x80\x99t have to replicate messages across pipelines, because then the pipelines would be processing unnecessary data.\nSolution\nBased on these findings, the best choice for this use case is the Type 2 dataflow, with N channels, N pipelines, and one data store. You can create two channels, each sourcing messages from their respective IoT rule, and each type of device can have its own IoT rule. From the channels, respective pipelines can source the messages and push out the processed messages to the same data store.\nCreate two pipelines for processing messages, as the schema of the weather and barometer messages are different. However, this also helps you handle the different types of messages originating from each device. The following diagram shows this configuration.\nSample solution for the use-case\nThe weather pipeline has one Lambda function activity to perform the following operations:\nRemove the fields that you marked as not required.\nFilter out the messages where the humidity or temperature value is 0.\nRename the temperature field to \xe2\x80\x9ctemperature_weather\xe2\x80\x9d.\nMeanwhile, the barometer pipeline has multiple pipeline activities to perform the following operations:\nRemove the fields that you marked as not required.\nFilter out messages where the barometer or temperature value is 0.\nRename the temperature field to \xe2\x80\x9ctemperature_barometer\xe2\x80\x9d.\nAs you remove the unnecessary attributes, you decrease the storage size needed for the processed messages.\n'"
190,Building Edge Solutions on OpenWrt with AWS IoT Greengrass,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/05/12/AWS-IoT-Greengrass.png,https://aws.amazon.com/blogs/iot/building-edge-solutions-on-openwrt-with-aws-iot-greengrass/,"b""Hardware and operating systems for edge devices are built and delivered to customers in a wide range of form factors, such as consumer gateways, industrial controllers, and in-vehicle infotainment systems.\nOriginal design manufacturers (ODMs) and original equipment manufacturers (OEMs) building commercial off-the-shelf products decide which hardware and software combinations to use. System integrators (SIs) developing broad solutions and customers creating customized hardware solutions also design edge solutions. Depending on the target use case, they may decide to use a specific type of Embedded Linux distribution that provides core capabilities to benefit system operation and the lifespan of the device itself.\nIn this post, I explore an option for ODMs, OEMs, SIs, and customers to deliver on these requirements when using AWS IoT Greengrass.\nOverview\nToday, AWS announced OpenWrt support for AWS IoT Greengrass for the ARMv7l and ARMv8 architectures. AWS IoT Greengrass seamlessly extends AWS to edge devices so they can act locally on the data that they generate, while still using the cloud for management, analytics, and durable storage.\nWhen working on solutions with customers, I found that OpenWrt can be an ideal operating system to help narrow the system footprint and gives strong options for running wear-leveling file systems.\nPreviously, to run AWS IoT Greengrass, you installed the glibc C runtime package, causing additional footprint. Today, using OpenWrt, you can design the operating system for AWS IoT Greengrass from the beginning to minimize footprint.\nCustomers, partners, and SIs now have an option to choose from smaller C runtime libraries for their OpenWrt image, completely eliminating the libc dependencies for AWS IoT Greengrass without increasing its footprint.\nThese improvements enable customers to deliver AWS Lambda functions and Amazon SageMaker Neo-compiled machine learning (ML) models (100x smaller footprint) with AWS IoT Greengrass, creating a smaller footprint IoT solution that is optimal for the resource-constrained OpenWrt-based gateway devices.\nThe AWS IoT Greengrass packages for OpenWrt are now available for download.\nOptimized for ML at the edge\nMany of our customers and partners are building compelling and innovative solutions on AWS and use AWS IoT Greengrass as part of their architecture.\nThe example described here is from one of our Advanced Tier AWS Partners, Smartiply, Inc. Smartiply has integrated AWS IoT Greengrass with the Smartiply IoT Gateway to deliver advanced AWS capabilities at the edge to enable new use cases and opportunities for two mutual customers.\nThe Smartiply IoT Gateway accelerates the adoption of IoT in environments that are challenged in infrastructure, or challenged geographically and economically. Target use cases are video surveillance, enterprise security, video streaming, and smart city. The core capabilities of the gateway include the following:\nSmart connectivity to deliver an uninterrupted video experience\nEmbedded intelligence (video, voice, data, and sensor analytics) in the fog for local decision-making\nData thinning to optimize traffic to the cloud\nSensor integration for monitoring\nRemote device management\nFigure 1. Smartiply Edge Device\nBeyond smart connectivity and edge intelligence, Smartiply\xe2\x80\x99s customers want to perform object classification inferencing at the edge, driven by AWS IoT Greengrass. Smartiply\xe2\x80\x99s device runs OpenWrt to optimize the device lifespan and operations. Smartiply has decided to use AWS IoT Greengrass to provide its customers seamless and secure IoT connectivity and more effective edge-to-cloud computing. AWS IoT Greengrass enables customers to continuously extend the value of their devices through programmatic extensions using Lambda functions and ML inference.\nA mutual customer in India is in the e-surveillance space. They most recently also received the Frost Sullivan award for technology leadership and for catering to the most diverse set of customers in India.\nTogether, we enable their customers to diversify and enter into new markets beyond bank ATM monitoring. These include environments that require higher-order capabilities to fulfill advanced needs, such as retail, logistics, and construction. Using the Smartiply IoT Gateway and building the solution on the AWS Cloud, our mutual customer uses IoT to deliver smart security solutions that include basic and advanced video analytics.\nThere is a camera in every location, primarily intended for security purposes. However, using advanced capabilities of AWS (specifically Amazon Rekognition) through AWS IoT Greengrass, Smartiply can deliver innovative computer vision solutions rapidly and efficiently through the edge-to-cloud framework.\nValue-added microservices could include any of the following:\nDetecting whether an employee in a fast-food establishment is wearing an apron or cap for compliance.\nIdentifying disturbing behavior (fights) in public facilities.\nCalculating average time to bill at a restaurant.\nMonitoring table occupancy.\nImproving queue management at POS workstations.\nAll of these open up new revenue opportunities for Smartiply and improve operational efficiency.\n\xe2\x80\x9cThe beauty of partnering with Amazon and integrating with AWS IoT Greengrass is that all stars get aligned perfectly. We don\xe2\x80\x99t have to reinvent the wheel, and we get to deliver solutions rapidly and most efficiently, starting from the edge itself. The hybrid model of enabling basic capabilities right at the edge but accessing the cloud for advanced computing is a perfect formula for many mission-critical applications. It not only saves costs but also improves performance, helping accelerate ROI that is direly needed across IoT deployments.\xe2\x80\x9d \xe2\x80\x93 Kaushik Pillalamarri, cofounder and CEO of Smartiply, Inc.\nAnother mutual customer, one of the largest local governments in Mexico, needs the Smartiply IoT Gateway to combine the ML capabilities of the AWS Cloud with video recognition for a smart city. The capability for the device to perform person and object recognition at the edge that continuously improves through automated, AWS Cloud-driven model training, and testing provides a powerful solution.\nBuilding system requirements\nWhen you build an Embedded Linux system\xe2\x80\x94whether it\xe2\x80\x99s Yocto, Buildroot, or OpenWrt\xe2\x80\x94all the system requirements are built into the image.\nNormally, there is no package manager tooling available on production, such as apt, yum, or opkg, except when building developer images. This means that, beyond kernel configuration requirements, all dependent packages for your target use case are prebuilt into the distribution image. Updates to packages mean constructing a firmware upgrade deliverable for customers.\nIt is out of scope for this post to have you construct a custom package, so install opkg and manually install AWS IoT Greengrass. Look for a future blog post about how to custom package AWS IoT Greengrass to OpenWrt.\nLaunch an Amazon EC2 instance\nIf you have a build machine for Embedded Linux, you may choose to use that machine. Make sure that all the system build dependencies are met.\nIf you don\xe2\x80\x99t have a build machine, launch an Amazon EC2 instance to build OpenWrt, and one that meets AWS IoT Greengrass container mode requirements. Follow the directions in the Launch instance wizard, but specify the following:\nOn the Choose an Amazon Machine Image (AMI) page, choose Public images and filter for Debian. Choose the latest Stretch distribution.\nTo build faster, choose a larger instance.\nChange the storage allocation to 120 GB.\nTo connect to your instance, run the following command while logged into your build system:\nssh -i ~/.ssh/xxx.pem admin@xx.xxx.xxx.x\nBash\nMany of the following steps come directly from the OpenWrt Project Quick Image Building Guide. After you connect to the EC2 instance, run the following commands to install the dependencies:\nsudo apt-get update\nsudo apt-get -y dist-upgrade\nsudo apt-get install -y subversion g++ zlib1g-dev build-essential git python time\nsudo apt-get install -y libncurses5-dev gawk gettext unzip file libssl-dev wget\nsudo apt-get install -y libelf-dev\nBash\nThen, check out the OpenWrt sources.\ngit clone https://git.openwrt.org/openwrt/openwrt.git/\ncd openwrt\n\n./scripts/feeds update -a\n./scripts/feeds install -a\nBash\nRun the following command to enter the menu system:\nmake menuconfig\nBash\nChoosing the correct board\nFollow these steps to choose the correct board.\nSelect Target System, scroll to Broadcom BCM27xx, and choose Enter.\nScroll to Subtarget and choose Enter.\nBecause this runs on a Raspberry Pi 3 Model B, scroll to BCM2710, and choose Enter.\nInstall utilities\nFollow these steps to install several utilities and the ca-certificates package.\nInstall the lsblk utility, used to list disks and partitions on the device:\nSelect Utilities and press Enter.\nSelect Disc and press Enter.\nSelect lsblk and enter Y.\nPress Tab to select Exit and press Enter.\nInstall the useradd and groupadd utilities, used to add the required AWS IoT Greengrass user and group. In production environments, automate adding the user and group to /etc/passwd and /etc/group, respectively.\nSelect Base system and press Enter.\nSelect busybox and press Enter.\nSelect Customize busybox options and press Y.\nSelect Login/Password Management Utilities and press Enter.\nFor each of the addgroups, support adding users to groups, adduser, mkpasswd, and chpasswd, press Y.\nPress Tab to select Exit and press Enter (three times).\nInstall the ca-certificates package, because it is required for AWS IoT Greengrass to perform the initial TLS 1.2 handshake with the AWS IoT Core gateway:\nSelect Base system and press Enter.\nSelect ca-certificates and press Y.\nPress Tab to select Exit and press Enter.\nPress Tab three times to select Save and press Enter. Press Enter again to save the configuration.\nPress Tab to select Exit and press Enter.\nCreate a file named LXC_PATCH in the current working directory. Copy and paste the following code block:\ncat <<OUT >> .config\nCONFIG_KERNEL_BLK_CGROUP=y\nCONFIG_KERNEL_CC_STACKPROTECTOR_REGULAR=y\nCONFIG_KERNEL_CFQ_GROUP_IOSCHED=y\nCONFIG_KERNEL_CGROUPS=y\nCONFIG_KERNEL_CGROUP_CPUACCT=y\nCONFIG_KERNEL_CGROUP_DEVICE=y\nCONFIG_KERNEL_CGROUP_FREEZER=y\nCONFIG_KERNEL_CGROUP_SCHED=y\nCONFIG_KERNEL_CPUSETS=y\nCONFIG_KERNEL_DEVPTS_MULTIPLE_INSTANCES=y\nCONFIG_KERNEL_FREEZER=y\nCONFIG_KERNEL_IOSCHED_DEADLINE=m\nCONFIG_KERNEL_IPC_NS=y\nCONFIG_KERNEL_LXC_MISC=y\nCONFIG_KERNEL_MEMCG=y\nCONFIG_KERNEL_MEMCG_SWAP=y\nCONFIG_KERNEL_MM_OWNER=y\nCONFIG_KERNEL_NAMESPACES=y\nCONFIG_KERNEL_NETPRIO_CGROUP=y\nCONFIG_KERNEL_NET_CLS_CGROUP=y\nCONFIG_KERNEL_NET_NS=y\nCONFIG_KERNEL_PID_NS=y\nCONFIG_KERNEL_POSIX_MQUEUE=y\nCONFIG_KERNEL_RESOURCE_COUNTERS=y\nCONFIG_KERNEL_USER_NS=y\nCONFIG_KERNEL_UTS_NS=y\nCONFIG_KERNEL_SECCOMP_FILTER=y\nCONFIG_KERNEL_SECCOMP=y\nOUT\nBash\nFinishing the configuration and compiling\nNow that the key changes have been set for the device, you can fill in the remaining baseline configuration by running the defconfig target:\nmake defconfig\nBash\nTo compile the system, run the following command. Consider how many cores you instantiated for your EC2 instance, add one to it, and apply it to the make command:\nmake -j X\nBash\nIf you chose a C4.8xlarge distribution earlier, this number would be 37:\nmake -j 37\nBash\nIf the build breaks, try continuing with X=1, because make dependencies may be broken. In my experience, running at that parallelism under the configuration defined in this post did not break the build. However, if you added other packages, it might happen.\nmake -j 1\nBash\nWhen I built using a C4.8xlarge EC2 instance, the build took less than 14 minutes.\nAfter the system is built, download the image to your workstation using scp.  The images are under the directory:\n~/openwrt/bin/targets/brcm2708/bcm2710\nBash\nEnter the command for downloading:\nscp -i ~/.ssh/xxx.pem admin@xx.xxx.xxx.xx:/home/admin/openwrt/bin/targets/brcm2708/bcm2710/openwrt-brcm2708-bcm2710-rpi-3-ext4-factory.img.gz .\nBash\nThe EC2 instance you used to build the OpenWrt system can be paused or deleted to save EC2 billing costs.\nFlashing the image to the microSD card\nNext, flash your microSD card with the image. This is similar to the process described in the previous section.\nsudo dd if=./openwrt-brcm2708-bcm2710-rpi-3-ext4-factory.img of=/dev/disk3 bs=2048\nsync\ndiskutil unmountdisk /dev/disk3\nBash\nRemove the microSD card from your workstation, insert the microSD to your Raspberry Pi, and power it on.\nConfiguring the network\nFor this post, use ethernet connectivity. Edit /etc/config/network to change eth0 to use DHCP. After editing, your network should look similar to the following:\nconfig interface 'loopback'\noption ifname 'lo'\noption proto 'static'\noption ipaddr '127.0.0.1'\noption netmask '255.0.0.0'\n\nconfig globals 'globals'\noption ula_prefix 'fd77:891b:69b8::/48'\n\nconfig interface 'lan'\noption type 'bridge'\noption ifname 'eth0'\noption proto 'dhcp'\nBash\nAfter editing the network, reload the network configuration to put the changes into effect:\nservice network reload\nBash\nConfigure user and group for AWS IoT Greengrass\nAdd the users to the system:\naddgroup ggc_group\nadduser -DH -G ggc_group ggc_user\nBash\nModify the boot parameter in /boot/cmdline.txt to mount the memory cgroup. Enter vi /boot/cmdline.txt, select the End key, select a, and then enter the following text:\ncgroup_enable=memory cgroup_memory=1\nBash\nPress Esc, then enter :wq! to write the buffer to file and exit vi. Reboot the system by entering reboot and choosing Enter.\nCreating your AWS IoT Greengrass group\nThe next step is to create your Greengrass group. Follow the directions in the Easy group creation wizard, but specify the following:\nPick a name for your group, such as openwrt-containermode.\nUnder Choose a root CA, save the Amazon Root CA 1 to the same directory where you saved the tar.gz downloads.\nUnder Choose your platform, download the OpenWrt distribution for Aarch64 to the same known directory.\nStarting AWS IoT Greengrass on your device\nNow you get to start AWS IoT Greengrass on your physical device.\nInsert a memory stick and copy all three files to your memory stick:\nThe group configuration tar.gz\nThe AWS IoT Greengrass software tar.gz\nThe root CA\nUnmount the memory stick and insert it to the Raspberry Pi.\nTo mount the memory stick, switch back to your serial connection window and run the following commands:\nlsblk # identifies the disk partition for your memory stick\nmkdir /media\nmount /dev/sda1 /media\nBash\nUnpack AWS IoT Greengrass and its configuration to the filesystem.\ncd /\ntar xzvf /media/[name of greengrass distribution file]\ncd greengrass\ntar xzvf /media/[name of greengrass configuration file]\ncp /media/AmazonRootCA1.pem certs/root.ca.pem\nBash\nStart AWS IoT Greengrass.\n/greengrass/ggc/core/greengrassd start\nBash\nDeployment\nNow you get to deploy the Greengrass group.  AWS IoT Greengrass is now running with your first deployment to an OpenWrt system.\nNext, you can begin working through tutorials, such as:\nLambda Functions on AWS IoT Greengrass Part 1\nLambda Functions on AWS IoT Greengrass Part 2\nInteracting with Devices in an AWS IoT Greengrass Group\nInteracting with Device Shadows\nAccessing Other AWS Services\nYou might also want to consider learning more about Hardware Security Integration when designing an AWS IoT Greengrass system that runs production workloads like finished consumer products.\n"""
191,New edX Course Helps Build AWS IoT Skills,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/06/18/IoT-Blog_800x400.jpg,https://aws.amazon.com/blogs/iot/new-edx-course-helps-build-aws-iot-skills/,"b'This post is contributed by Maureen Lonergan, Director, AWS Training and Certification\nAWS Training and Certification now offers a new course through edX entitled AWS IoT: Developing and Deploying an Internet of Things. This self-paced digital course focuses on developing skills to build and deploy Internet of Things (IoT) solutions for industrial, commercial, or consumer applications. These solutions include Connected Home and Industrial IoT.\nThe course was developed by AWS IoT experts and explains the following:\nWhat the Internet of Things is and how it works.\nHow to use AWS IoT edge software to connect your devices and operate them at the edge.\nHow to use AWS IoT control services to secure, control, and manage your devices from the cloud.\nHow to use AWS IoT data services to work with IoT data faster and extract value from it.\nThis intermediate-level digital course is recommended for those with:\nAt least one year of software development experience\nA basic understanding of AWS services and the AWS Management Console, either through previous experience or the AWS Developer Professional Series on edX.\nThe course is divided into four weekly lessons with an estimated two to five hours per week of study time. It features approximately 12 hours of video-based lectures, demonstrations, and hands-on lab exercises. Learners can set their own pace and deadlines. All learners may take weekly quizzes, which are not graded and allow unlimited retries.\nThis on-demand, 100%-digital course is available and is offered on a complimentary basis. To obtain a verified certificate, learners can enroll in edX\xe2\x80\x99s verified certificate track, and must successfully pass the end-of-course assessment that covers all the learning objectives and content.\nGet started today at AWS IoT: Developing and Deploying an Internet of Things.'"
192,Your guide to AWS IoT at re:Inforce 2019,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/06/18/reinforce.png,https://aws.amazon.com/blogs/iot/your-guide-to-aws-iot-at-reinforce-2019/,"b'The first-ever re:Inforce is almost here! As you plan your agenda, we don\xe2\x80\x99t want you to miss any IoT sessions. These sessions will help you better understand the best practices and technology to prepare for, detect, contain, eradicate, and respond to potential threats to your IoT devices, connections, and data. To protect users, devices, and companies, IoT devices and their data must be secured.\nHere are sessions from this year\xe2\x80\x99s lineup to help you plan your event agenda.\nKeynote \xe2\x80\x93 AWS Cloud Security: Moving forward in the cloud\nTuesday, June 24, 9:30am\nStephen Schmidt, VP and Chief Information Security Officer, AWS \nDuring this keynote, you will gain helpful insights into how Amazon Web Services (AWS) manages security at scale, and hear from customers in regulated industries about their experiences with security, compliance, identity, and governance in the cloud.\nSDD307-R \xe2\x80\x93 [REPEAT] Protecting your IoT fleet\nThis builder session takes place several times: \nTuesday, Jun 25, 11:30 AM \xe2\x80\x93 12:30 PM\xe2\x80\x93 Level 1, Room 151B, Table 3\nTuesday, Jun 25, 2:30 PM \xe2\x80\x93 3:30 PM\xe2\x80\x93 Level 1, Room 151B, Table 3\nTuesday, Jun 25, 5:30 PM \xe2\x80\x93 6:30 PM\xe2\x80\x93 Level 1, Room 151B, Table 3\nWednesday, Jun 26, 8:00 AM \xe2\x80\x93 9:00 AM\xe2\x80\x93 Level 1, Room 151B, Table 3\nWednesday, Jun 26, 11:00 AM \xe2\x80\x93 12:00 PM\xe2\x80\x93 Level 1, Room 151B, Table 3\nWednesday, Jun 26, 5:00 PM \xe2\x80\x93 6:00 PM\xe2\x80\x93 Level 1, Room 151B, Table 3\nWhether you\xe2\x80\x99re selling millions of IoT devices to customers or deploying thousands to your own factories, protecting your IoT fleet can be difficult. With AWS, you can quickly deploy, manage, and audit your devices\xe2\x80\x99 security posture consistently and continuously. In this builder session, learn how to securely deploy a provided IoT sensor with its own certificate, register the device with a simple function, and then audit the device\xe2\x80\x99s security posture against best practices. All attendees need a laptop, an active AWS account, an IAM administrator, and a familiarity with core AWS services.\nSEP203 \xe2\x80\x93 Leverage the security & resiliency of the cloud & IoT for industry use cases\nTuesday, Jun 25, 11:30 AM \xe2\x80\x93 1:30 PM\xe2\x80\x93 Level 2, Room 210B\nAnton Shmagin \xe2\x80\x93 Partner Solutions Architect, AWS IoT\nMichael South \xe2\x80\x93 Americas Regional Leader, Public Sector Security & Compliance, AWS\nThis non-technical two-hour Internet of Things (IoT) tabletop exercise benefits business and technology leaders and regulators in the Energy, Oil and Gas, Transportation, Healthcare, Financial, and Manufacturing sectors. Through discussion of a simulated cyber IoT incident, you explore required capabilities and processes. You learn how to leverage AWS for security, high availability, incident response, and continuity of operations for systems that include IoT. You also discuss the advantages of cloud security and resiliency over traditional on-premises environments to understand your opportunities. Finally, the effectiveness of international cybersecurity frameworks in improving an organization\xe2\x80\x99s posture is highlighted. No laptops required.\nSEP208 \xe2\x80\x93 Designing for data privacy on AWS\nTuesday, Jun 25, 1:00 PM \xe2\x80\x93 2:00 PM\xe2\x80\x93 Level 2, Room 207\nCarl Mathis \xe2\x80\x93 Security Architect, AWS\nAWS can help enterprises ensure that data privacy requirements are met in a timely and efficient way. In this session, we show you how you can use Amazon Athena to quickly address the right to be forgotten, erasure, or restriction of processing requests when sensitive data is held in Amazon S3. We show you how to use AWS Lambda for just-in-time privacy notices. We also show you how AWS IoT services can assist in adhering to \xe2\x80\x9cDo Not Track\xe2\x80\x9d requirements or address implied consent by modifying default browser settings. Learn how AWS services can be leveraged to support an architectural approach to help customers meet data privacy and protection requirements.\nDEV04 \xe2\x80\x93 IoT security: Prevent your devices from becoming attack vectors\nTuesday, Jun 25, 3:00 PM \xe2\x80\x93 3:30 PM\xe2\x80\x93 Level 0, Dev Lounge Hall A + B1\nAmir Kashani, VP of Cloud Native Development, Onica Group LLC \nThe Internet of Things (IoT) is enabling new and existing businesses to build better products, provide new services, and improve business outcomes through a more connected world. The same connectivity provides malicious actors with billions of new targets to steal data from, take control of systems from, or otherwise wreak havoc on. In this talk, we discuss key threats to be aware of when building an IoT device or platform. We also cover ways to mitigate the risks.\nSEP206 \xe2\x80\x93 Securing Internet of Things (IoT) deployment with AWS\nTuesday, Jun 25, 4:00 PM \xe2\x80\x93 5:00 PM\xe2\x80\x93 Level 2, Room 212\nMomena Cheema \xe2\x80\x93 Cloud Security Strategist, AWS Security \nDan Griffin \xe2\x80\x93 Software Development Engineer, AWS IoT\nLearn how AWS can enable business productivity and intelligence with security from the start using our suite of IoT services. This session addresses common IoT security questions across different industries and walks through the steps taken when building secure solutions that blend the AWS Cloud and AWS IoT services. It also highlights questions that security and engineering teams should ask as they architect their solutions and offer recommendations on IoT best practices such as pushing automatic patching updates and monitoring activity across devices.\nFND212 \xe2\x80\x93 Amazon FreeRTOS security best practices\nTuesday, Jun 25, 5:30 PM \xe2\x80\x93 6:30 PM\xe2\x80\x93 Level 0, Hall B2, Yellow\nDan Griffin \xe2\x80\x93 Software Development Engineer, AWS IoT\nAmazon FreeRTOS is an open-source operating system for cloud-connected embedded devices. As customers start working on embedded Internet of Things projects, they ask AWS for security best practices. In this session, we discuss provisioning, device authentication and authorization, secure software updates, and monitoring. Finally, we show these lifecycle considerations in context by demonstrating an over-the-air firmware update to an embedded developer board, highlighting the many security-relevant steps in the workflow.\nSEP318-L \xe2\x80\x93 Leadership session: Aspirational security\nWednesday, Jun 26, 11:45 AM \xe2\x80\x93 12:45 PM\xe2\x80\x93 Level 2, Room 253B\nEric Brandwine \xe2\x80\x93 VP/Distinguished Engineer, AWS Security \nHow does the cloud foster innovation? Join Vice President and Distinguished Engineer Eric Brandwine as he details why there is no better time than now to be a pioneer in the AWS Cloud, discussing the changes that next-gen technologies such as quantum computing, machine learning, serverless, and IoT are expected to make to the digital and physical spaces over the next decade. Organizations within the large AWS customer base can take advantage of security features that would have been inaccessible even five years ago; Eric discusses customer use cases along with simple ways in which customers can realize tangible benefits around topics previously considered mere buzzwords.\nFND330 \xe2\x80\x93 Securing the edge with AWS IoT services\nWednesday, Jun 26, 12:30-1:30 PM\xe2\x80\x93 Level 0, HallB2, Red\nScott Allison \xe2\x80\x93 Sr. Technical Product Manager, AWS IoT Greengrass \nIndraneel Mitra \xe2\x80\x93 Sr. Solutions Architect, IoT Specialist, AWS\nEdge computing is one of the most important enablers of the future. It saves lives, democratizes resources, and reduces costs in scenarios where near real-time action is required. This session covers how to keep edge computing secure. We dive deep into how AWS IoT Greengrass authenticates and encrypts device data for local and cloud communications so that data is never exchanged without proven identity. You can leverage hardware-secured, end-to-end encryption for messages exchanged between devices, an AWS IoT Greengrass core, and the AWS Cloud, and for messages between an AWS IoT Greengrass core and other local devices using the AWS IoT device SDK.\nSDD325 \xe2\x80\x93 Bose uses AWS IoT to securely connect millions of devices and improve IT agility\nWednesday, Jun 26, 1:15 PM \xe2\x80\x93 2:15 PM\xe2\x80\x93 Level 2, Room 205B\nPeter Bounora, Enterprise Solutions Architect, AWS \nSatyendra Thakur, CISO, Bose\nAs a result of moving to AWS, Bose retired its first data center in 2018, and its second data center is closing later this year. In this session, Bose\xe2\x80\x99s head of security discusses the company\xe2\x80\x99s journey to the cloud and how it moved hundreds of workloads and services to AWS using a shared services model. This included business-critical environments that are in scope for regulatory compliance and SAP applications that are paramount to running the business. On the product side, this session covers how Bose securely connected millions of devices to AWS IoT, which required multiple iterations of security controls, policies, and standards.\nFND321 \xe2\x80\x93 Keeping edge computing secure\nWednesday, Jun 26, 3:30 PM \xe2\x80\x93 4:30 PM\xe2\x80\x93 Level 1, Room 151B, Table 8\nNeel Mitra, Sr. SA, IoT Specialist\nEdge computing is one of the most important enablers of the future. It saves lives, democratizes resources, and reduces costs in scenarios where near-real time action is required. This session covers how to keep edge computing secure. We dive deep into how AWS IoT Greengrass authenticates and encrypts device data for local and cloud communications so that data is never exchanged without proven identity. You can leverage hardware-secured, end-to-end encryption for messages exchanged between devices, an AWS IoT Greengrass core, and the AWS Cloud, and for messages between an AWS IoT Greengrass core and other local devices using the AWS IoT device SDK.\nPlease note that session information is subject to change. For more information, see the re:Inforce catalog for sessions focused on IoT security.\n\nNot able to attend re:Inforce? Attend our upcoming webinar for more information about how you can use AWS IoT Greengrass, Amazon FreeRTOS, AWS IoT Core, and AWS IoT Device Defender. These services help you keep data secure, restrict access to devices and cloud resources, securely connect to the cloud, and audit device usage.\nSecuring Your Devices from the Edge to the Cloud\nJune 24 | 11:00 AM \xe2\x80\x93 12:00 PM PT\nRegister Now'"
193,Announcing Amazon FreeRTOS 201906.00 Major,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/announcing-amazon-freertos-20190600/,"b'Amazon FreeRTOS 201906.00 Major is now generally available. Amazon FreeRTOS extends the FreeRTOS kernel with individual software libraries, making it faster and easier to securely connect microcontroller-based IoT devices to the cloud.\nThis major release provides significant improvements to several underlying libraries, as well as an update to overall Amazon FreeRTOS versioning:\nGeneral availability of Bluetooth Low Energy support\nMQTT library v2.0.0\nAmazon FreeRTOS folder structure changes\nCMake\nImprovements to other existing libraries\nAdditional features\nUpdate to release numbering\nGeneral availability of Bluetooth Low Energy support\nWe moved Amazon FreeRTOS Bluetooth Low Energy libraries and companion Android/iOS SDKs out of beta. They are now part of the Amazon FreeRTOS GitHub master repository.\nThe general availability of Bluetooth Low Energy support in Amazon FreeRTOS includes the following updates:\nMQTT library: These updates provide increased flexibility and functionality, including the use of MQTT over both Bluetooth Low Energy and TCP/IP. For more information, see the MQTT Library v2.0.0 section later in this post.\nOver-the-air (OTA) updates: Use the existing OTA update functionality in AWS IoT Device Management to monitor, manage, and update firmware on your Bluetooth Low Energy devices through an authenticated Android/iOS proxy device.\nAWS IoT Device Tester integration: Run AWS IoT Device Tester to verify your Amazon FreeRTOS ports that support Bluetooth Low Energy. We also added separate tests to verify Wi-Fi provisioning over Bluetooth Low Energy.\nAmazon FreeRTOS console: You can select the Bluetooth Low Energy library and download the board-specific source code from the Amazon FreeRTOS console.\nMQTT library v2.0.0\nWe made the MQTT library transport independent using an abstraction layer. We also enabled all Amazon FreeRTOS features (such as OTA, AWS IoT Device Defender, and Device Shadows) to work on both Bluetooth Low Energy and TCP/IP. Updates include:\nThe ability to open one socket and re-use it across all Amazon FreeRTOS libraries.\nMQTT features such as Last Will and Testament, QoS1 with fully implemented retry logic, and persistent sessions.\nSupport for a non-blocking programming model in the MQTT library with a per-operation user-provided callback.\nThe ability to allocate memory dynamically or from statically allocated memory pools.\nAmazon FreeRTOS folder structure changes\nWe updated the folder structure of the Amazon FreeRTOS source code repository in GitHub. It now separates AWS partner-supplied code (such as drivers, ports, and tools) and core Amazon FreeRTOS components (such as the kernel, libraries, and tests) into separate directories. This creates a cleaner separation between AWS and non-AWS code to simplify distribution and maintenance.\nIf you migrate from a previous version, you must update your build scripts based on these changes. For more information, Porting Amazon FreeRTOS to Your Device contains additional details on this process.\nCMake\nAmazon FreeRTOS now supports a CMake-based build system. We provide CMake files for core Amazon FreeRTOS components (such as the kernel and libraries). This supports a standard build environment for supported boards.\nAmazon FreeRTOS still supports IDE projects.\nImprovements to other existing libraries\nWe modified the Device Shadows v2.0.0 and AWS IoT Device Defender v2.0.0 libraries to use the updated MQTT programming model.\nAdditional features\nWe introduce support for task pools in this release. Task pools enable you to configure your application\xe2\x80\x99s tasks and optimize the trade-off between performance and the memory footprint.\nUpdate to release numbering\nWith this release, we replaced semantic versioning with date-based versioning, so Amazon FreeRTOS 1.4.8 updates to Amazon FreeRTOS 201906.00.\nThis date-based versioning follows the format YYYYMM.NN:\nY represents the year (2019).\nM represents the month (June).\nN represents the release order within the designated month (00 being the first release in June).\nFor example, a possible second release in June 2019 would be 201906.01.\nEach Amazon FreeRTOS library still retains its semantic versioning. In semantic versioning, the version number itself (X.Y.Z) indicates if the release is a major, minor, or point release.This can create situations where semantic versioning indicates a major release based on changes that don\xe2\x80\x99t affect an individual application. By moving semantic versioning down to the individual library, individual customers can assess the scope and impact of a new release on their application. This release includes major version changes to multiple libraries including MQTT and Device Shadows.\nHow this release affects you\nThis update may affect your existing applications and device qualifications.\nTo allow your build scripts to use the updated libraries, you must update any existing applications based on previous versions of Amazon FreeRTOS. You can choose to use the new APIs for the updated libraries listed earlier. Or, you can use the included compatibility layer for applications that cannot be updated to use the modified APIs. You can find detailed information about migrating your application to the new release here.\nAll previously qualified reference boards remain qualified with this release. New qualifications also qualify on the new baseline. For more information, see AWS Device Qualification Program.\n'"
194,Announcing support for Bluetooth Low Energy in Amazon FreeRTOS,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Announcing-support-for-Bluetooth-Low-Energy-in-Amazon-FreeRTOS.png,https://aws.amazon.com/blogs/iot/aws-announces-bluetooth-low-energy-support-in-amazon-freertos-as-generally-available/,"b'Today, AWS announced general availability for Bluetooth Low Energy support in Amazon FreeRTOS. This release simplifies your development process to securely connect Amazon FreeRTOS devices using Bluetooth Low Energy to AWS IoT Core via Android and iOS devices. It also makes it easier to remotely update firmware on Amazon FreeRTOS devices using Bluetooth Low Energy.\nMillions of devices rely on Bluetooth Low Energy connectivity, including fitness trackers, headsets, smaller, battery-operated sensors, and much more. Most of these devices can benefit from connecting to AWS IoT.\nCurrently, to add Bluetooth Low Energy connectivity to applications running Amazon FreeRTOS, you must first select the microcontrollers and the compatible Bluetooth Low Energy stacks. You then integrate Amazon FreeRTOS libraries to corresponding software development kits (SDKs). Finally, you code and test the pairing process with mobile devices.\nAfter Bluetooth Low Energy devices deploy, you may find it complex to monitor, manage, or update firmware on these devices, especially with the challenges associated with the handling incompatible communication protocols and unique device management requirements.\nBluetooth Low Energy support in Amazon FreeRTOS enables you to use the standard Generic Access Profile (GAP) and Generic Attributes (GATT) profiles through a universal application programming interface (API) layer, shown as Bluetooth Low Energy Management Library in the following diagram.\nTaking advantage of this functionality, you can create Bluetooth Low Energy applications that are portable across Amazon FreeRTOS-qualified devices. You can then integrate companion Android/iOS SDKs with AWS IoT Core functionality. This support simplifies your development process by eliminating the need to port code yourself, or code and test against mobile SDKs.\nAmazon FreeRTOS Architecture with Bluetooth Low Energy Management Library\nAccording to the Bluetooth Low Energy specifications, GAP defines how Bluetooth Low Energy devices broadcast availability and communicate with each other. After the device connects, GATT describes how data transfers.\nAmazon FreeRTOS Bluetooth Low Energy supports the Bluetooth Low Energy Secure Connections pairing mechanism (in addition to Just WorksTM), giving you confidence that your Bluetooth Low Energy devices are connecting to a trusted entity. Bluetooth Low Energy support in Amazon FreeRTOS also makes it easy for you to monitor, manage, and update firmware on the Bluetooth Low Energy devices. Handle all your firmware needs through the authenticated Android/iOS device using the over-the-air (OTA) update functionality in AWS IoT Device Management. You can learn more on performing OTA updates using Bluetooth Low Energy here.\nAmazon FreeRTOS Bluetooth Low Energy devices can also use other AWS services such as AWS IoT Device Shadows and AWS IoT Device Defender.\nYou can get started in three steps:\nUse Amazon FreeRTOS on your choice of hardware. To simplify and accelerate your development process, AWS provides prequalified devices that run optimally with Amazon FreeRTOS using the AWS Partner Device Catalog. Today, AWS launches three popular development boards qualified for Amazon FreeRTOS Bluetooth Low Energy:\nEspressif\xe2\x80\x99s ESP32-DevKitC and ESP-WROVER-KIT, based on the ESP32 SoC. For more information, see Getting Started.\nNordic\xe2\x80\x99s nRF52840 DK, based on the nRF52 chipset. For more information, see Getting Started.\nDownload source code from the Amazon FreeRTOS console or the Amazon FreeRTOS GitHub repo. Download Android and iOS SDKs from GitHub, which also contains sample Android and iOS apps that you can build and deploy to your Bluetooth Low Energy device.\nReview the hardware-specific Getting Started section in the Amazon FreeRTOS User Guide.\nHow Bluetooth Low Energy in Amazon FreeRTOS works \nFitness trackers are a good example of Bluetooth Low Energy devices. Fitness trackers collect sensor data, including body temperature, number of steps, and heart rate, sending the data to the cloud for performance insights or progress toward a goal. These fitness trackers connect locally to a mobile device over Bluetooth Low Energy, and the mobile phone acts as a proxy to connect to the cloud.\nRunning Amazon FreeRTOS on these devices helps publish sensor data and subscribe to MQTT topics over Bluetooth Low Energy through the mobile device. Also, the MQTT library helps your device securely communicate with the AWS IoT MQTT broker. The iOS and Android SDKs provide proxy libraries and a sample app to help you create your custom app using APIs that the SDKs expose. The mobile device uses Amazon Cognito for authenticating with AWS IoT, as shown in the following diagram. If you have your identity management system, you can use X.509 certificates for authentication.\nBluetooth Low Energy devices communicate with AWS IoT MQTT broker via Android and iOS devices\nTo update your trackers\xe2\x80\x99 firmware for security patches or new features, you can use Amazon FreeRTOS over-the-air updates (OTA) over Bluetooth Low Energy. For more information, see OTA Tutorial. MQTT over Bluetooth Low Energy also enables you to access other AWS services such as AWS IoT Device Shadows and AWS IoT Device Defender.\nDevices such as home appliances typically connect to the cloud over Wi-Fi because of their proximity to a local Wi-Fi access point. However, during first installation, technicians more easily and cheaply provision the Wi-Fi credentials of such appliances (that is, the SSID and password) using Bluetooth Low Energy. Technicians connect to the home appliance over Bluetooth Low Energy using a secure company app and push the Wi-Fi credentials to the appliance securely. The next time the appliance boots up, it already has the right credentials to connect to the local Wi-Fi access point.\nThe Amazon FreeRTOS Bluetooth Low Energy library includes a GATT service for configuring Wi-Fi networks and demo examples to help you get started. You can save multiple Wi-Fi configurations. You can re-prioritize, add, and delete saved networks. AWS pairs your device and mobile phone using Bluetooth Low Energy Secure Connections with Numeric Comparison. This process ensures secure data transfer. You can also create your own GATT services using the Bluetooth Low Energy management API.\nFor more information about using MQTT over Bluetooth Low Energy, Wi-Fi provisioning over Bluetooth Low Energy, and establishing your own GATT services, see Bluetooth Low Energy Demo Applications. You can download these demo applications from GitHub or the Amazon FreeRTOS console.\nFor more information on this release, refer to the blog \xe2\x80\x93 Announcing Amazon FreeRTOS 201906.00 Major.\n '"
195,Perform OTA Updates on Espressif ESP32 using Amazon FreeRTOS Bluetooth Low Energy,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/perform-ota-firmware-updates-on-espressif-esp32-devices-using-amazon-freertos-bluetooth-low-energy-mqtt-proxy/,"b'Amazon FreeRTOS 2019.06.00 Major now includes Bluetooth Low Energy MQTT proxy support to simplify tasks such as Wi-Fi provisioning and secure connections to AWS IoT services. The Bluetooth Low Energy feature enables you to build low-power devices that can be paired to a customer\xe2\x80\x99s mobile device for connectivity without requiring Wi-Fi. Devices can communicate using MQTT by connecting through Android or iOS Bluetooth Low Energy SDKs that use generic access profile (GAP) and generic attributes (GATT) profiles. You can find details in the blog \xe2\x80\x93 Announcing support for Bluetooth Low Energy in Amazon FreeRTOS.\nAmazon FreeRTOS already gives you the flexibility to perform over-the-air (OTA) firmware updates. OTA allows you to change the functionality of devices and provide security fixes without user intervention. AWS IoT Device Management allows secure and scalable OTA updates as well as monitoring and reporting tools to simplify the update process. The Amazon FreeRTOS device OTA agent validates the authenticity of the update using X.509 certificates. If an issue is found, it rolls back to the previously functioning firmware.\nOTA updates\nIn this post, I walk you through an update to Espressif ESP32 microcontroller connected to an MQTT Bluetooth Low Energy proxy on an Android device. You update the device using AWS IoT OTA update jobs. The device connects to AWS IoT using Amazon Cognito credentials entered in the Android demo app. An authorized operator initiates the OTA update from the cloud. When the device connects through the Android demo app, the OTA update is initiated and firmware is updated on the device.\nHere are the steps to allow OTA updates over Bluetooth Low Energy:\nConfigure storage: Create an S3 bucket and policies and configure an IAM user that can perform updates.\nCreate a code-signing certificate: Create a signing certificate and allow the IAM user to sign firmware updates.\nConfigure Amazon Cognito authentication: Create a credential provider, user pool, and application access to the user pool.\nConfigure Amazon FreeRTOS: Set up Bluetooth Low Energy, client credentials, and the code-signing public certificate.\nConfigure an Android app: Set up credential provider, user pool, and deploy the application to an Android device.\nRun the OTA update script: Use the OTA update script to initiate an OTA update.\nFor more information about how the updates work, see Amazon FreeRTOS Over-the-Air Updates. For general information, see the Amazon FreeRTOS User Guide.\nFor information about how to set up the Bluetooth Low Energy MQTT proxy functionality, see the Using Bluetooth Low Energy with Amazon FreeRTOS on Espressif ESP32 post by Richard Kang.\nPrerequisites\nTo follow along with this solution, you need the following resources:\nAn ESP32 development board\nA MicroUSB to USB A cable\nAn AWS account (the Free Tier is sufficient)\nSufficient disk space (~500 Mb) for the Xtensa toolchain and Amazon FreeRTOS source code and examples.\nAn Android phone with Android v 6.0 or later and Bluetooth version 4.2 or later.\nAndroid Studio\nThe AWS CLI installed\nPython3 installed\nThe boto3 AWS Software Developer Kit (SDK) for Python\nThis post is written with the assumption that Xtensa toolchain, ESP-IDF, and Amazon FreeRTOS code are installed in the /esp directory in the user\xe2\x80\x99s home directory. You must add ~/esp/xtensa-esp32-elf/bin to your $PATH variable.\nStep 1: Configure storage\nYou can skip these steps by launching the AWS CloudFormation template.\nCreate an S3 bucket with versioning enabled to hold the firmware images.\nCreate an OTA update service role and add the following managed policies to the role:\nAWSIotLogging\nAWSIotRuleActions\nAWSIotThingsRegistration\nAWSFreeRTOSOTAUpdate\nAdd an inline policy to the role to allow it to perform actions on the IoT service and allow access to the S3 bucket that you created.\nCreate an IAM user that can perform OTA updates. This user can sign and deploy firmware updates to IoT devices in the account, and has access to do OTA updates on all devices. Access should be limited to trusted entities.\nAttach permissions with an OTA user policy.\nCreate an inline policy that allows the IAM user created to sign the firmware.\nStep 2: Create the code-signing certificate\nCreate a code-signing certificate that can be used to sign the firmware. Note the certificate ARN when the certificate is imported.\naws acm import-certificate --profile=ota-update-user --certificate file://ecdsasigner.crt --private-key file://ecdsasigner.key\n{\n""CertificateArn"": ""arn:aws:acm:us-east-1:<account>:certificate/<certid>""\n}\nBash\nThe ARN will be used later to create a signing profile. If desired, the profile can be created using the following command at this point:\naws signer put-signing-profile --profile=ota-update-user --profile-name esp32Profile --signing-material certificateArn=arn:aws:acm:us-east-1:<account>:certificate/<certid> --platform AmazonFreeRTOS-Default --signing-parameters certname=/cert.pem\n{\n""arn"": ""arn:aws:signer::<account>:/signing-profiles/esp32Profile""\n}\nBash\nStep 3: Cognito Authentication Configuration\nFollow Steps 1 and 2 in the AWS IoT Configuration section here.\nNext, follow Steps 1 through 3 in the Amazon Cognito Configuration section here.\nStep 4: Configure Amazon FreeRTOS\nTo download the latest version of the Amazon FreeRTOS code, use the Amazon FreeRTOS console or Amazon FreeRTOS GitHub repo.\nTo enable the OTA update demo, follow the steps in the Getting Started with the Espressif ESP32-DevKitC and the ESP-WROVER-KIT Only one demo can be enabled at a time in the Demo Runner.\nAdditional modifications to be made, by location:\nvendors/espressif/boards/esp32/aws_demos/config_files/aws_demo_config.h\nDefine CONFIG_OTA_UPDATE_DEMO_ENABLED.\nvendors/espressif/boards/esp32/aws_demos/common/config_files/aws_demo_config.h:\nChange democonfigNETWORK_TYPES to AWSIOT_NETWORK_TYPE_BLE.\ndemos/include/aws_clientcredential.h:\nAdjust the endpoint URL in clientcredentialMQTT_BROKER_ENDPOINT[].\nAdjust the thing name to ""esp32-ble"" in clientcredentialIOT_THING_NAME.\nCertificates don\xe2\x80\x99t have to be added when you use Amazon Cognito credentials.\nvendors/espressif/boards/esp32/aws_demos/common/config_files/aws_iot_network_config.h\nAdjustconfigSUPPORTED_NETWORKS and configENABLED_NETWORKS to only includeAWSIOT_NETWORK_TYPE_BLE.\ndemos/include/aws_ota_codesigner_certificate.h:\nAdjust signingcredentialSIGNING_CERTIFICATE_PEM with the certificate to be used to sign the firmware binary file.\nThe application should start up and print the demo version:\n11 13498 [iot_thread] [INFO ][DEMO][134980] Successfully initialized the demo. Network type for the demo: 2\n12 13498 [iot_thread] [INFO ][MQTT][134980] MQTT library successfully initialized.\n13 13498 [iot_thread] OTA demo version 0.9.20\n14 13498 [iot_thread] Creating MQTT Client...\nBash\nStep 5: Configure an Android app\nDownload the Android Bluetooth Low Energy SDK and a sample app from the amazon-freertos-ble-android-sdk GitHub repo.\nThe following sections explain the changes to be made.\nModify awsconfiguration.json\nThis file is located at:\napp/src/main/res/raw/awsconfiguration.json\nFill in Pool Id, Region, AppClientId, and AppClientSecret using the instructions in the following sample JSON.\n{\n  ""UserAgent"": ""MobileHub/1.0"",\n  ""Version"": ""1.0"",\n  ""CredentialsProvider"": {\n    ""CognitoIdentity"": {\n      ""Default"": {\n        ""PoolId"": ""Cognito->Manage Identity Pools->Federated Identities->mqtt_proxy_identity_pool->Edit Identity Pool->Identity Pool ID"",\n        ""Region"": ""Your region (eg. us-east-1)""\n      }\n    }\n  },\n\n  ""IdentityManager"": {\n    ""Default"": {}\n  },\n\n  ""CognitoUserPool"": {\n    ""Default"": {\n      ""PoolId"": ""Cognito-> Manage User Pools -> esp32_mqtt_proxy_user_pool -> General Settings -> PoolId"",\n      ""AppClientId"": ""Cognito-> Manage User Pools -> esp32_mqtt_proxy_user_pool -> General Settings -> App clients ->Show Details"",\n      ""AppClientSecret"": ""Cognito-> Manage User Pools -> esp32_mqtt_proxy_user_pool -> General Settings -> App clients ->Show Details"",\n      ""Region"": ""Your region (eg. us-east-1)""\n    }\n  }\n}\nJSON\nModify DemoConstants.java\nThis file is located at:\napp/src/main/java/software/amazon/freertos/DemoConstants.java\nSpecify the policy name (e.g.esp32_mqtt_proxy_iot_policy) created earlier.\nSet the Region (e.g. us-east-1).\nBuild and install the demo app\nFollow these steps:\nIn Android Studio, choose Build, Make Module app.\nChoose Run, Run app. You can go to the logcat window pane in Android Studio to monitor log messages.\nOn the Android device, create an account from the login screen.\nCreate a user. If a user already exists, enter the credentials.\nAllow AmazonFreeRTOS Demo to access the device\xe2\x80\x99s location.\nScan for Bluetooth Low Energy devices,\nMove the slider for the device found to the On\nPress \xe2\x80\x98y\xe2\x80\x99 on the serial port debug console for the ESP32.\nChoose Pair & Connect.\nThe More\xe2\x80\xa6 link becomes active after the connection. You see the connection state change to BLE_CONNECTED in the Android device logcat when the connection is complete:\n2019-06-06 20:11:32.160 23484-23497/software.amazon.freertos.demo I/FRD: BLE connection state changed: 0; new state: BLE_CONNECTED\nBash\nBefore the messages can be transmitted, the Amazon FreeRTOS device and the Android device negotiate the MTU. You should see the following print in logcat:\n2019-06-06 20:11:46.720 23484-23497/software.amazon.freertos.demo I/FRD: onMTUChanged : 512 status: Success\nBash\nThe device is connected to the app and starts sending MQTT messages using the MQTT proxy. To confirm that the device can communicate, make sure that you can see the MQTT_CONTROL characteristic data value change to 01:\n2019-06-06 20:12:28.752 23484-23496/software.amazon.freertos.demo D/FRD: <-<-<- Writing to characteristic: MQTT_CONTROL with data: 01\n2019-06-06 20:12:28.839 23484-23496/software.amazon.freertos.demo D/FRD: onCharacteristicWrite for: MQTT_CONTROL; status: Success; value: 01\nBash\nEnable BLE on the ESP32 console\nYou are asked to press \xe2\x80\x98y\xe2\x80\x98 on the ESP32 console when the device is paired with the device. The demo does not function until this step is performed.\nE (135538) BT_GATT: GATT_INSUF_AUTHENTICATION: MITM Required\nW (135638) BT_L2CAP: l2cble_start_conn_update, the last connection update command still pending.\nE (135908) BT_SMP: Value for numeric comparison = 391840\n15 13588 [InputTask] Numeric comparison:391840\n16 13589 [InputTask] Press \'y\' to confirm\n17 14078 [InputTask] Key accepted\nW (146348) BT_SMP: FOR LE SC LTK IS USED INSTEAD OF STK\n18 16298 [iot_thread] Connecting to broker...\n19 16298 [iot_thread] [INFO ][MQTT][162980] Establishing new MQTT connection.\n20 16298 [iot_thread] [INFO ][MQTT][162980] (MQTT connection 0x3ffd5754, CONNECT operation 0x3ffd586c) Waiting for operation completion.\n21 16446 [iot_thread] [INFO ][MQTT][164450] (MQTT connection 0x3ffd5754, CONNECT operation 0x3ffd586c) Wait complete with result SUCCESS.\n22 16446 [iot_thread] [INFO ][MQTT][164460] New MQTT connection 0x3ffc0ccc established.\n23 16446 [iot_thread] Connected to broker.\nBash\nStep 6: Run the OTA update script\nTo install the prerequisites, run the following commands:\npip3 install boto3\npip3 install pathlib\nBash\nDownload the python script.\nBump up the Amazon FreeRTOS application version in demos/include/aws_application_version.h and build a new .bin file.\nTo get help, run the following command in a terminal window:\npython3 start_ota.py -h\nBash\nHere\xe2\x80\x99s the help information:\nusage: start_ota.py [-h] --profile PROFILE [--region REGION]\n                    [--account ACCOUNT] [--devicetype DEVICETYPE] --name NAME\n                    --role ROLE --s3bucket S3BUCKET --otasigningprofile\n                    OTASIGNINGPROFILE --signingcertificateid\n                    SIGNINGCERTIFICATEID [--codelocation CODELOCATION]\nScript to start OTA update\noptional arguments:\n-h, --help            show this help message and exit\n--profile PROFILE     Profile name created using aws configure\n--region REGION       Region\n--account ACCOUNT     Account ID\n--devicetype DEVICETYPE thing|group\n--name NAME           Name of thing/group\n--role ROLE           Role for OTA updates\n--s3bucket S3BUCKET   S3 bucket to store firmware updates\n--otasigningprofile OTASIGNINGPROFILE\n                      Signing profile to be created or used\n--signingcertificateid SIGNINGCERTIFICATEID\n                      certificate id (not arn) to be used\n--codelocation CODELOCATION\n                      base folder location (can be relative)\nBash\nIf you used the provided AWS CloudFormation template to create resources, here\xe2\x80\x99s the example execution:\npython3 start_ota_stream.py --profile otausercf --name esp32-ble --role ota_ble_iot_role-sample --s3bucket afr-ble-ota-update-bucket-sample --otasigningprofile abcd --signingcertificateid <certificateid>\nBash\nYou should see the update start in the ESP32 debug console:\n38 2462 [OTA Task] [prvParseJobDoc] Job was accepted. Attempting to start transfer.\n---\n49 2867 [OTA Task] [prvIngestDataBlock] Received file block 1, size 1024\n50 2867 [OTA Task] [prvIngestDataBlock] Remaining: 1290\n51 2894 [OTA Task] [prvIngestDataBlock] Received file block 2, size 1024\n52 2894 [OTA Task] [prvIngestDataBlock] Remaining: 1289\n53 2921 [OTA Task] [prvIngestDataBlock] Received file block 3, size 1024\n54 2921 [OTA Task] [prvIngestDataBlock] Remaining: 1288\n55 2952 [OTA Task] [prvIngestDataBlock] Received file block 4, size 1024\n56 2953 [OTA Task] [prvIngestDataBlock] Remaining: 1287\n57 2959 [iot_thread] State: Active  Received: 5   Queued: 5   Processed: 5   Dropped: 0\nBash\nWhen the OTA update is complete, the device restarts as needed by the OTA update process and try to connect with the updated firmware. If the upgrade succeeds, the updated firmware is marked as active and you should see the updated version in the console:\n13 13498 [iot_thread] OTA demo version 0.9.21\nBash\n'"
196,AWS Insights from IoT World 2019,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2019/06/04/aws-iotworld-keynote-1-1024x614.jpg,https://aws.amazon.com/blogs/iot/aws-insights-from-iot-world-2019/,"b'  At IoT World Santa Clara, over 12,000 IoT leaders and innovators gathered to make connections and gain insights about how to digitally transform their businesses with IoT. The AWS IoT team spent the week meeting with customers and partners, sharing insights onstage, and showcasing a variety of AWS IoT use cases in AWS\xe2\x80\x99s own and partner booths on the expo floor.\nThe AWS IoT team was also honored to pick up the IoT World Award for \xe2\x80\x9cBest IoT Security Solution\xe2\x80\x9d for AWS IoT Device Defender, which is a testament to AWS\xe2\x80\x99s commitment to its ongoing efforts to provide customers with the technology they need to keep their IoT data and devices secure.\nIf you were not able to make the show, read below for a quick recap and for links to view our session decks.\nKey Insights\nMark Relph, the Global Head of Business Development & Strategy for AWS IoT, delivered a keynote at IoT World. In this keynote, he shared how the combination of connected devices, data, and machine learning can act as the springboard to transform operations, create new sources of revenue, and serve customers better. He shared the following insights about how businesses can transform their business with IoT.\nInsight #1: Organizational Buy-In Cannot Be Underestimated\nAWS\xe2\x80\x99 customers tell us that while technology is important, the real key to a successful IoT project is ensuring there is support from the organization. Many IoT proof-of-concept projects ultimately fail because the business is not truly bought-in. IoT has the potential to transform the fundamentals of a business, potentially evolving the core business model (i.e. moving from selling a physical product like an engine, to selling a service or result like uptime or performance). These transformations can cause friction if the organization is not ready to change at the same pace.\nInsight #2: Technology Should Be At Your Core\nAWS\xe2\x80\x99s most successful customers view their IoT infrastructure as critical technology. They want control over their destiny, but don\xe2\x80\x99t want to reinvent the wheel. Embracing Serverless IoT allows them to quickly build IoT applications at scale that can adapt to any solution or scenario. Serverless allows experimentation, and in production ensures they pay only for the services they consume. This also means that their teams can focus on building new services and innovating for their customers.\nInsight #3: Operate At The Edge \xe2\x80\x93 But With Modern Tools\nThe \xe2\x80\x9cedge\xe2\x80\x9d is an important consideration for any IoT project. There are durable reasons such has latency, unreliable connectivity, and dealing with data from industrial equipment. With software such as AWS IoT Greengrass, our customers can leverage the same tool chain at the Edge that they use in the cloud. This enables cloud developers to build for embedded systems.\nInsight #4: Nothing Gets Smarter Without The Data\nData drives efficiency, and can help create new sources of revenue. Dealing with data can be difficult. Many customers generate data, but unlocking it from industrial data sources and using it for advanced analytics can be difficult. We are working with customers to help them unlock data from OPC-UA servers and historians. With that data, these customers are able to create a cycle of training data in the cloud and using the insights at the edge.\nInsight #5: There Is No Compression Algorithm For Experience\nFinally, our customers tell us that nothing replaces experience. They are experts in what they do, often with decades of experience in their industry. IoT augments, rather that replaces, that experience. When they look for help, they need experts that have that same depth of experience. AWS, and Amazon more broadly, has the real world experience in what it takes to build these IoT solutions at scale. AWS also brings a powerful ecosystem of partners, to help customers augment their experience and accelerate their IoT projects.\nView Keynote Slides >>\nView our session presentations\nAside from the keynote, we had several sessions providing a deeper dive on specific IoT use cases, solutions, and trends:\n\xe2\x80\x9cDistributed Solar Systems: Revolutionizing Time-Series Predictive Analytics, IoT, and Machine Learning with AWS\xe2\x80\x9d Wale Oladehin\nIn this session, Wale shared how AWS customers use AWS IoT to synchronize their industrial time-series data from multiple sites to the AWS Cloud, where advanced analytics and machine learning can generate valuable insights about their business.\nView Slides >>\n\xe2\x80\x9cIoT Made Easy\xe2\x80\x9d Craig Williams, Principle Solutions Architect, IoT\nIn this session, Craig shared how AWS helps our customers around the world easily deploy IoT solutions by collecting and analyzing data using sophisticated techniques such as machine learning, taking preventative measures to secure their fleet of devices, actively monitoring devices, and deploying machine learning models onto devices.\nView Slides >>\n\xe2\x80\x9cBest Practices in IoT Architecture\xe2\x80\x9d Craig Williams, Principle Solutions Architect, IoT\nGeared towards developers, this session shared knowledge and best practices in IoT Architecture. Craig gave a cloud agnostic overview of IoT Architecture Patterns and Anti-Patterns, shared best practices for scaling and critical message processing patterns, and insights on how to optimize your workloads with AWS IoT.\nView Slides >>\n  What topics would you like to hear the AWS IoT team speak about at future events? Let us know in the comments!'"
197,Using AWS IoT to Create a Smart Home Water-Monitoring Solution,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Screen-Shot-2020-08-31-at-6.25.57-PM-1024x581.png,https://aws.amazon.com/blogs/iot/using-aws-iot-to-create-a-smart-home-water-monitoring-solution/,"b'2018 saw the fourth year of drought and the worst in recorded history for the city of Cape Town, South Africa. \xe2\x80\x9cDay zero\xe2\x80\x9d was a term coined by the city for the day when they would have to turn the water off for citizens. Fortunately, \xe2\x80\x9cday zero\xe2\x80\x9d was never realized, and Cape Town didn\xe2\x80\x99t go down in history as the first major city to run out of water. Water restrictions and augmentation plans alleviated the crisis until rainfall returned to the city, however, the city remains sensitive to water crises. Citizen behaviour must permanently change in order to use water in a sustainable manner.\nAWS presented this session at the AWS Summit in Cape Town where I met the CTO of a company called Apex Innovation who are now registered AWS partners. Apex Innovation has commercialized the entire architecture above. They spent time resolving the problem of using a hall-effect sensor in a commercial use case. Hall effect sensors are susceptible to a phenomenon called pulse drift which produces inaccurate pulse counts over time, rendering the water flow measurement inaccurate. Apex Innovation has many installations of this solution in commercial buildings across the continent and is working with city municipalities for large scale installations of more than 50,000 units to assist municipalities with accurate water consumption data.\nIn this blog post, I share an AWS IoT water solution that provides real-time water consumption information to home owners. The information can be used to encourage a change in consumption behavior to help the city conserve water. This solution uses AWS IoT core, Amazon Kinesis Data Firehose, Amazon S3, AWS Lambda, Amazon DynamoDB and an iOS application to create a real-time water consumption application.\nArchitecture\nThe diagram illustrates how simple it is to design a real-time water consumption application. I will delve into more detail of each component in the diagram in the sections below.\nThe physical install\nI installed a water flow sensor available on Amazon for $11.19 on the water mains supply line into my house. As the water flows through the sensor, it turns a cog. As the cog turns, it passes over a coil. Each pass produces an electrical pulse. By counting the pulses in a given time period and factoring the diameter of the pipe it\xe2\x80\x99s possible calculate the volume of water flowing through the sensor.\nThese photos show the installation of the water flow sensor on the main water supply.\nEach pulse is sent to a micro-controller board, which is similar to the ESP32 series of low-cost, low-power system on a chip microcontrollers. Pulses are counted over a period of one minute. The volume is calculated and sent to AWS IoT Core for processing. Before any communication can take place between the AWS Hex board and AWS IoT Core, you must register the AWS Hex board as a thing.\nA JavaScript method running on the micro-controller board:\nRuns the timer and the code to execute the flow calculation.\nSends an MQTT message to the AWS topic.\nThe timer method stores the number of pulses received in the last minute. Every minute, the flow is calculated by factoring the flow rate for 1L per minute, which for this size sensor is a factor of 4.5. Divide that by 60 to calculate the liters per minute, as follows:\n(pulse count / 4.5) / 60\nHere is the source code for the timer function and helper functions:\n// Load  Mongoose OS API\nload(\'api_timer.js\');\nload(\'api_uart.js\');\nload(\'api_sys.js\');\nload(\'api_mqtt.js\');\nload(\'api_config.js\');\n \n// Uart  number used for this example\nlet uartNo = 1;\n//  Accumulated Rx data, will be echoed back to Tx\nlet rxAcc = """";\n \nlet value = false;\n \n// Set the  global pulse counter\nlet pulseCounter = 0;\n \n// Set the  conversion factor for the hall effect calculation\nlet HEFactor = 4.5;\n \n/*\n * Configure UART at 115200 baud\n * Configure the water flow sensor pin: 22\n */\nUART.setConfig(uartNo, {\n    baudRate: 115200,\n    esp32: {\n        gpio: {\n            rx: 22,\n            tx: 23,\n        },\n    },\n});\n \n/*\n * Set dispatcher callback, it will be called  whenver new Rx data or space in\n * the Tx buffer becomes available.\n * The number of messages received per minute  x 4.5 is the L/min\n * Count the number of messages per minute.\n */\nUART.setDispatcher(uartNo, function (uartNo, ud) {\n    let ra = UART.readAvail(uartNo);\n    if (ra > 0) {\n        // Received new data:  print it immediately to the console, and also\n        // accumulate in the  ""rxAcc"" variable which will be echoed back to UART later\n        let data = UART.read(uartNo);\n        pulseCounter++;\n        print(""Received  UART data:"", data);\n        rxAcc += data;\n    }\n}, null);\n \n// Enable  Rx\nUART.setRxEnabled(uartNo, true);\n \n/**\n * Create a timer to run every minute.\n * This timer method will store the number of  pulses received in the last minute.\n * Once the timer is done, send data to AWS  IoT\n * Reset the pulse counter.\n * Rinse & repeat.\n * \n * Calculating the flow rate per hour.\n * For every litre of liquid passing through  the sensor per minute,\n * it pulses 4.5 times. Divide the pulseCount  by 4.5 to get the litres per minute.\n * Divide that by 60 to get litres per hour.\n * \n * (pulseCount / 4.5) / 60\n * \n */\nTimer.set(60000 /*  milliseconds */, true /* repeat  */, function () {\n    // Send the MQTT message\n    // Hard-coded device ID was  866191037731759\n    let topic = \'/things/waterflowcontrollers/\' + Cfg.get(\'device.id\');\n    // Set the date and time\n    let Timestamp = Timer.now();\n    // Date format day/month/year  hour:minute:second\n    let datetime = Timer.fmt(""%d/%m/%Y  %H:%M:%S"", Timestamp);\n    let flowRate = (pulseCounter / HEFactor) / 60;\n \n    let res = MQTT.pub(topic, JSON.stringify(\n        {\n            ""SerialNumber"": Cfg.get(\'device.id\'),\n            ""BatteryVoltage"": ""2080mV"",\n            ""QCCID"": ""8944538523012471069"",\n            ""GSN"": Cfg.get(\'device.id\'),\n            ""FlowRate"": flowRate,\n            ""FlowCalibration"": ""4.5"",\n            ""Date"": datetime\n        }\n    ), 1);\n    print(\'Published  flow rate: \', res ? flowRate : \'no\');\n \n    // Reset the pulse counter\n    pulseCounter = 0;\n}, null);\nPython\nBecause you configure most of this solution in AWS IoT Core, here is some background about the registry, AWS IoT policies, and X.509 certificates.\nRegistering a device in the registry\nThe registry allows you to keep a record of all of the devices that are registered to your AWS IoT account. It tracks metadata, such as device attributes and capabilities. In the case of the example used in this post, the registry supports metadata that describes whether a sensor reports temperature and if the data is Fahrenheit or Celsius. The registry assigns a unique identity to each device that is consistently formatted, regardless of the device type or the way the device connects.\nFor more information, see Register a Device in the AWS IoT Core Developer Guide.\nAWS IoT Policy\nX.509 certificates are used to authenticate your device with AWS IoT Core. AWS IoT Core policies are used to authorize your device to perform operations, such as subscribing or publishing to MQTT topics. Your device presents its certificate when it sends messages to AWS IoT Core. To allow your device to perform operations, you must create an AWS IoT policy and attach it to your device certificate.\nFor more information, see Create an AWS IoT Policy in the AWS IoT Core Developer Guide.\nAttach a certificate to your device\nA device must have a X.509 certificate, private key, and root CA certificate to authenticate with AWS IoT Core. AWS recommends that you also attach the device certificate to the thing that represents your device in AWS IoT Core. This way you can create AWS IoT Core policies that grant permissions based on certificates attached to your things.\nFor more information, see Attach a Certificate to a Thing in the AWS IoT Core Developer Guide.\nData\nIncoming messages from the thing are sent to an AWS IoT topic configured for the thing. Amazon Kinesis Data Firehose subscribes to the topic to send every message to Amazon S3 for long-term durable storage. When the message is received in Amazon S3, an S3 event triggers an AWS Lambda function that writes a copy of the message into Amazon DynamoDB, where analysis and visualization is performed. After the raw message has been copied to Amazon DynamoDB, the message is archived in Amazon Glacier to reduce storage costs.\nData from the thing is sent in JSON format for ease of use with applications. The timestamp is important for the downstream applications to collate the data into comprehensible time series data blocks. The flow rate is the calculated volume of water flowing through the water flow sensor per minute. A serial number uniquely identifies the thing and the longitude and latitude are the GPS coordinates of the installed device.\nHere is a sample JSON message:\n{\n    ""Date"": ""21/02/2019 16:14:10"",\n    ""FlowRate"": 28,\n    ""SerialNumber"": ""esp32_39B3F8"",\n    ""latitude"": -33.9399299,\n    ""longitude"": 18.4751000\n}\nJavaScript\nVisualization\nVisualizing the data from the water flow sensors in a format that is easily interpreted is crucial to the success of the application. A mobile application and a web application make it easy for the user to access and read the data. Different graphs are important for interpreting different trends in water usage.\nAn hourly graph is useful for leak detection, where a sudden spike in water usage over the last hour can alert the user to a potential leak. The user is notified of the high water usage with an SMS using Amazon SNS.\nA weekly and a monthly graph is useful for the user to quickly identify trends over the last few days or the last month. Additional visual space in the web dashboard allows us to provide comparative graphs for water consumption over years so the user can compare his or her water consumption at the same time in previous years. This is useful for seasonal changes in water consumption.\nMobile application\nIn this example, an iOS application was developed in XCode to visualize the data in graph format by connecting to a gateway in Amazon API Gateway which exposes AWS Lambda functions to fetch the data required to render each graph.\nHere are some photos of the mobile application screens.\nThe mobile app and the website both need security credentials in order to make programmatic requests to AWS. Amazon Cognito is ideal for this scenario. You can use this service with the AWS Mobile SDK for iOS and the AWS Mobile SDK for Android and Fire OS to create unique identities for users and authenticate them for secure access to your AWS resources.\nWeb application\nThe same AWS Lambda functions used by the iOS mobile application are accessed through Amazon API Gateway for the web application dashboard to render the graphs on the website. The website, hosted in Amazon S3, uses Node.js to access the gateway in Amazon API Gateway and render the graphs.\nHere is a dashboard in the web application.\nNext steps\nBeing able to accurately measure the water consumption in our house has changed my family\xe2\x80\x99s consumption of this most precious resource. We now actively reduce our water consumption. Now that you know how easy it is to measure important environmental data, like water usage using AWS IoT services, I recommend you find opportunities in your everyday life to leverage IoT technologies. Whether it\xe2\x80\x99s temperature, smart home utilities or metering. The ability for you to build IoT applications with simple devices unlocks a world of data and insights into your environment.'"
198,AWS Makes It Easier for Embedded Developers to Build IoT Applications with Additional Preconfigured Examples for FreeRTOS on Armv8-M Architectures,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/build-iot-applications-with-preconfigured-examples-freertos-kernel-armv8m-architectures/,"b'FreeRTOS is a real-time operating system for small, low-power devices. AWS maintains stewardship of the FreeRTOS kernel, a free and open operating system for microcontrollers that embedded developers have trusted and evolved for more than fifteen years. In the eighteen months that AWS has maintained the FreeRTOS project, we\xe2\x80\x99ve updated it to use an MIT License, added security and connectivity libraries with Amazon FreeRTOS, and contributed support for the open RISC-V instruction set architecture (ISA).\nToday, AWS announces availability of additional preconfigured examples for device manufacturers. Embedded developers can use these examples to more easily create IoT applications for microcontrollers that use the Armv8-M architecture on the officially supported FreeRTOS kernel. The latest MIT-licensed FreeRTOS multi-threading kernel release includes new, preconfigured example projects supporting Nuvoton, NXP, and STMicroelectronics that demonstrate the FreeRTOS Armv8-M port on Arm Cortex-M33 and now also Arm Cortex-M23 hardware. These examples, along with the officially supported FreeRTOS port for Armv8-M, provide users with a choice of hardware and build environments.\nThe FreeRTOS kernel Armv8-M port uses the memory protection unit (MPU) and TrustZone-M features of the Armv8-M core. Application writers can write sandbox code that must remain trusted to ensure system integrity or code that they simply want to keep private. The kernel can run in the secure or non-secure execution environments provided by the TrustZone-M hardware (commonly known as the secure side or secure world and non-secure side or non-secure world, respectively). Typically, security-focused functionality like secure boot, encryption, decryption, and management of keys and certificates are expected to execute on the secure side, and other features (including the kernel itself) on the non-secure side.\nWhen the kernel is executed on the non-secure side, support for the floating point unit (FPU), memory management unit (MPU), and TrustZone are all compile-time options. Non-secure tasks (or threads) can call secure-side trusted functions that, in turn, can call back to non-secure functions, all without breaching the kernel\xe2\x80\x99s prioritized scheduling policy. That flexibility makes it possible for application writers to create non-secure FreeRTOS tasks that interact with trusted secure-side firmware they created themselves or is provided by third-party open source or proprietary vendors. When the kernel is executed on the secure side, support for the FPU and MPU are compile-time options, but tasks cannot call non-secure functions.\nThe preconfigured examples show how to create partitioning by using dummy functions on the secure side, the entry points to which are exported to and called from the non-secure side. Those examples also show how to configure the MPU to provide FreeRTOS tasks with memory access rights, as appropriate for the task purpose and privilege.\nGetting started\nTo get started quickly, download FreeRTOS source code from SourceForge and use these preconfigured examples:\nNXP LPC55S69-EVK Development board with LPC55S6x MCU based on Arm Cortex-M33. Product Page | Preconfigured Example\nNuvoton NuMaker-PFM-M2351 with NuMicro-M2351 MCU based on Arm Cortex-M23. Product Page | Preconfigured Example\nSTMicroelectronics Nucleo-L552ZE-Q Development board with STM32L5 MCUs based on Arm Cortex-M33. Product Page | To obtain FreeRTOS code for STM32L5, please contact your local STMicroelectronics sales office or distributor.\nTo learn more, visit www.freertos.org.'"
199,How to Install a Face Recognition Model at the Edge with AWS IoT Greengrass,b'Richard Elberger',2019-06-20T18:48:00+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/How-to-Install-a-Face-Recognition-Model-at-the-Edge-with-AWS-IoT-Greengrass-1024x645.png,https://aws.amazon.com/blogs/iot/how-to-install-a-face-recognition-model-at-the-edge-with-aws-iot-greengrass/,"b'Editor Note: This post is co-authored by Gong Xinyue, one of Global Accounts Solution Architects.\nYou might already know how to use AWS IoT Core and AWS IoT Greengrass for remote device communication and control. With AWS IoT Greengrass Machine Learning (ML) Inference, you can run machine learning models on your local devices without any transmission delay. In this blog post, I will show you how to use AWS IoT Greengrass ML Inference on a Raspberry Pi to perform local facial recognition for home surveillance.\nUsing an Amazon Echo Dot, which is connected to the Alexa Voice Service, as the control device for the Raspberry Pi\xe2\x80\x99s camera, you\xe2\x80\x99ll be able to take a photo of people outside your door and, using the photo, perform facial detection and comparison with a local dataset using the pretrained ML model deployed to the Raspberry Pi. Although the comparison results can also be used with your door lock or other smart devices, these use cases are not covered in this post.\nPrerequisites\nInstall the AWS IoT Greengrass Core software on your Raspberry Pi device. Create an IoT Greengrass group and core. For instructions, see Getting Started with AWS IoT Greengrass in the AWS IoT Greengrass Developer Guide. The group and core are used in deployments.\nIn this post, I use a pretrained face-detection model, train it with TensorFlow, and then deploy it to the Raspberry Pi with AWS IoT Greengrass. You can use the same model, or you can use Amazon SageMaker to train one of your own. For information about how to prepare a model with Amazon SageMaker, see Get Started in the Amazon SageMaker Developer Guide.\nInstall the following dependencies.\nOpenCV 3.3\nTensorFlow\nNumpy\nScipy\nScikit-learn\nDlib\nAll image processing libraries\nUse the following commands to install the image processing dependencies.\nsudo apt-get install build-essential\nsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev\nsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev pkg-config graphicsmagick\nUse the following commands to install OpenCV 3.3.\ngit clone https://github.com/Itseez/opencv.git\ngit clone https://github.com/Itseez/opencv_contrib.git\ncd opencv\ngit checkout 3.1.0\ncd ../opencv_contrib/\ngit checkout 3.1.0\ncd ..\ncd opencv\nmkdir release\ncd release\ncmake -D CMAKE_BUILD_TYPE=RELEASE \\\n-D CMAKE_INSTALL_PREFIX=/usr/local \\\n-D INSTALL_PYTHON_EXAMPLES=ON \\\n-D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \\\n-D BUILD_EXAMPLES=ON ..\nmake -j4\nsudo make install\nsudo ldconfig\nThe ML model used in this post is TensorFlow. Use the following commands to install TensorFlow on your Raspberry Pi.\n# Install Wheel\nwget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.0.1/tensorflow-1.0.1-cp34-cp34m-linux_armv7l.whl\nsudo pip install tensorflow-1.0.1-cp34-cp34m-linux_armv7l.whl\nsudo pip install mock\n#Install Pip3\nsudo apt install libatlas-base-dev\npip install tensorflow\nUse the following commands to install Numpy, Scipy, and Scikit-learn.\npip install numpy scipy scikit-learn\nUse following commands to install Dlib.\n#Modify your swapfile\nsudo nano /etc/dphys-swapfile\n\nchange CONF_SWAPSIZE = 100 to CONF_SWAPSIZE=1024\nchange virtual memory from 100M to 1G\n\nsudo /etc/init.d/dphys-swapfile restart\n\nsudo raspi-config\n#Change you boot Options\n1)Boot Options => Desktop / CLI => Console Autologin\n2)Advanced Options => Memory Split => change GPU to 16\n\n#Doanload your Dlib\ndownload Dlib to your device : http://dlib.net/\nsudo python setup.py install\nML models and AWS Lambda functions\nYou will find two ML models on GitHub.\nFace Detection Model\n|\xe2\x80\x94-haarcascade_frontalface_default.xml\nFace Recognition Model\n|\xe2\x80\x94\xe2\x80\x93train_faces.model-500.data-00000-of-00001\n|\xe2\x80\x94\xe2\x80\x93train_faces.model-500.index\n|\xe2\x80\x94\xe2\x80\x93train_faces.model-500.meta\n|\xe2\x80\x94\xe2\x80\x93checkpoint\nYou will also find notes to that describe the Lambda functions used in this post.\nFaceDetection Lambda function on AWS IoT Greengrass\n#open camera\ncam = cv2.VideoCapture(0)\nwhile True:\n# capture an image from video stream\n_, img = cam.read()\n# convert RBG image to grayscale image\ngray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n# detect face\ndets = detector(gray_image, 1)\nif not len(dets):\n# detect face failed\nkey = cv2.waitKey(30) & 0xff\nif key == 27:\nsys.exit(0)\n# start recognition\nfor i, d in enumerate(dets):\nx1 = d.top() if d.top() > 0 else 0\ny1 = d.bottom() if d.bottom() > 0 else 0\nx2 = d.left() if d.left() > 0 else 0\ny2 = d.right() if d.right() > 0 else 0\nface = img[x1:y1, x2:y2]\n\nface = cv2.resize(face, (size, size))\n# compare image with dataset and compose JSON format message\nrecord_data = {}\nrecord_data[\'result\'] = is_my_face(face)\nprepared_record_data = json.dumps(record_data)\n# send MQTT message to \xe2\x80\x9crecord/webcam\xe2\x80\x9d topic\nclient.publish(topic = \'record/webcam\', payload = prepared_record_data)\nbreak;\nAlexa trigger Lambda function\ndef get_welcome_response():\n# public a message to IoT core\nclient.publish(\ntopic=\'listening/record\',\npayload=""Hi"",\nqos=1\n)\n# return message of this Alexa Skill\nsession_attributes = {}\ncard_title = ""Welcome""\nspeech_output = ""Sure. I will check the camera now.""\n# If the user either does not reply to the welcome message or says something\n# that is not understood, they will be prompted again with this text.\nreprompt_text = ""Sure. I will check the camera now.""\nshould_end_session = True\nreturn build_response(session_attributes, build_speechlet_response(\ncard_title, speech_output, reprompt_text, should_end_session))\nGet started\nThe architecture of the example described in this post is shown here. The facial recognition model and datasets, which are used to create AWS Lambda function for recognition, have been uploaded to an Amazon S3 bucket. AWS IoT Greengrass synchronizes the required files to the Raspberry Pi. Echo Dot runs as a trigger. When Echo Dot listens to a command such as,\xe2\x80\x9cAlexa, open Monitor,\xe2\x80\x9d it calls an Alexa skill to send a message to AWS IoT Core. AWS IoT Core invokes the recognition Lambda function, which is deployed on Raspberry Pi local storage, and if the Lambda function recognizes the identity of the guest, the door opens.\n\nLet\xe2\x80\x99s prepare the resources you will deploy on the Raspberry Pi.\nFirst, create an AWS Lambda function that will capture the frame from the Raspberry Pi camera, convert it to a JPG file, and then invoke the local ML model for analysis. The AWS Lambda function will send the analysis result in JSON format to AWS IoT Core.\nIn the AWS Lambda console, choose Create Function, and then choose Author from scratch. Give your AWS Lambda function a name like greengrassFaceRecognization. For Runtime, choose Python 2.7. Because this Lambda function will be deployed on edge devices, you can choose any role without impacting its function on the Raspberry Pi.\n\nIn the function code area, choose the option to upload a ZIP file, and then upload the ZIP package provided for this Lambda function from GitHub. From Actions, publish a new version. AWS IoT Greengrass doesn\xe2\x80\x99t support $LATEST as the version for Lambda aliases, so make sure you assign a version number (for example, version 1) to your Lambda function.\n\nWhen the Lambda function runs, it will call the local ML model for facial recognition. Use the following values to configure the Lambda function:\nAttribute Configuration\nMemory Limit 96\nTimeout 8\nLambda Lifecycle Make this function long-lived and keep it running indefinitely\nRead access to /sys directory Enable\nInput payload data type JSON\nThe Lambda function needs to invoke some local devices on your Raspberry Pi. Add those devices to your AWS IoT Greengrass resources.\nIn the AWS IoT Core console, choose AWS IoT Greengrass. Choose Groups, and then choose your Greengrass group (for example, greengrassFaceReco). In the left navigation pane, choose Resources. On the Local tab, choose Add a local resource.\n\nBecause the example in this post uses the Raspberry Pi camera, add two devices to the Greengrass group:\nvideoCoreSharedMemory\nvideoCoreInterface\nComplete the fields as follows:\n\nWhen you\xe2\x80\x99re done, your device configuration should look like this:\n\nAdd your ML model to this Greengrass group. In the left navigation pane, choose Resources, choose Machine Learning, and then choose Add machine learning resource.\n\nIn this example, the model is stored in an S3 bucket. If you use Amazon SageMaker to train your model, choose Amazon SageMaker as your model source. The local path is the directory on your edge device where you will store the model. Configure this path carefully. Otherwise, your model cannot be used on your edge device. You can see your model has been added to your Greengrass group:\n\nNow create a subscription so that the local analysis result can be sent to the AWS IoT Cloud for processing, such as storing the result in Amazon DynamoDB and performing result analytics in Amazon EMR. If you have another local device connected to Raspberry Pi, you can use the AWS IoT Greengrass core to control it through AWS Lambda based on the analysis result. In this example, the result is sent to the AWS IoT Cloud through an MQTT message.\n\nYou can now deploy the Greengrass group. From Actions, choose Deploy. Deployment times vary, depending on the size of the model. When the deployment is complete, the results appear in the console, as shown here.\n\nYour Raspberry Pi should now be able to recognize the face photo captured by the Pi camera. Use Echo Dot to voice control the Pi camera to get the image.\nCreate another Lambda function to trigger the AWS IoT Greengrass local face detection Lambda function through an MQTT message. The trigger Lambda function will send an MQTT message to the Greengrass core through AWS IoT Core. AWS IoT Greengrass will process this message through the local face detection Lambda function and then trigger the photo analysis. You can find this Lambda code based on Python 2.7 on GitHub. Make a note of the ARN for this Lambda function. You will use it when you configure Alexa skills.\nOpen the Amazon Developer Portal. Choose Alexa, choose Your Alexa Consoles, choose Skills, and then choose Create Skill. For information about creating your own Alexa skills, see Build Skills with the Alexa Skills Kit.\nFinally, build a smart home surveillance system by using your Echo Dot to send a voice control message to your Raspberry Pi to start the local face recognition process. The result will be sent back to the AWS IoT Cloud through an MQTT message.\n'"
200,Connecting Disparate Industrial Devices and Applications from the Plant Floor to AWS Using KEPServerEX,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2020/09/01/Connecting-Disparate-Industrial-Devices-and-Applications-from-the-Plant-Floor-to-AWS-Using-KEPServerEX-1024x381.png,https://aws.amazon.com/blogs/iot/connecting-disparate-industrial-devices-and-applications-from-the-plant-floor-to-aws-using-kepserverex/,"b'When managing Industrial Internet of Things (IIoT) data, it can be challenging to collect and send this data to the cloud for processing and advanced analytics (for example, to predict quality or equipment failure). There might be many different devices on a manufacturing floor, each with its own protocol.\nIn this blog post, we discuss how customers can address the industrial protocol challenges by using KepServerEX at the edge for industrial protocol conversion, AWS IoT Greengrass for edge processing, and AWS IoT for data ingestion into AWS. By the end of the post, you should have enough information to create a secure and reliable process for real-time industrial data so everyone from the shop floor to the top floor can make smarter decisions.\nFirst, we show you how to connect and configure KEPServerEX with AWS IoT Greengrass Core. This information is helpful if your application needs to connect to AWS IoT Greengrass Core by using the AWS IoT Core certificate chain. Most applications don\xe2\x80\x99t need the root CA to verify the server (AWS IoT Greengrass) certificate, but KEPServerEX requires it to verify the certificate chain.\nThe AWS IoT Greengrass Core software provides the following functionality:\nAllows deployment and execution of local applications that are created by using AWS Lambda functions and managed through the deployment API.\nEnables local messaging between devices over a secure network by using a managed subscription scheme through the MQTT protocol.\nEnsures secure connections between devices and the cloud using device authentication and authorization.\nProvides secure, over-the-air software updates of user-defined AWS Lambda functions.\nDeploys machine learning models optimized to run on AWS IoT Greengrass using Greengrass ML inference.\nPrerequisites\nIn this post, we recommend that you install the following software on EC2 instances in the same VPC.\nInstall KEPServerEX from the Kepware website on a Windows Amazon EC2 instance. For the Kepware IoT gateway to run, the server requires a working 32-bit JRE. You can download and install the current JRE from here.\nFollow the instructions in the AWS IoT Greengrass Developer Guide to install AWS IoT Greengrass Core software on Linux or Rasberry Pi:\nModule 1: Environment Setup for AWS IoT Greengrass\nModule 2: Installing the AWS IoT Greengrass Core Software\nKEPServerEX supports OPC UA and MQTT (stock implementation). We use MQTT messages to communicate with AWS IoT Greengrass.\nMake sure that KEPServerEX and the AWS IoT Greengrass Core software are running on the same network.\nFollow the instructions in the AWS CLI documentation to install the AWS CLI on your personal computer, and then configure it with your AWS access key and secret key.\nArchitecture diagram\nGetting started\nYou should now have the AWS IoT Greengrass Core software running on a gateway. If you followed the steps in the Getting Started modules, you should also have a Greengrass group (for example, MyFirstGroup) with one core device (for example, MyFirstGroup_Core) configured. The core device should be able to communicate with AWS IoT Core.\nThe resources you create in these procedures should be created in the same AWS Region.\n  Open the AWS IoT console and choose Greengrass, Groups, MyFirstGroup, and then Cores, you should see your core device:\nChoose your core device, and in the left pane, choose Connectivity. Make a note of the endpoint address and port.\nCreate AWS IoT Devices in an AWS IoT Greengrass Group\nNow we add the KEPServerEx device to the AWS IoT Greengrass group.\nIn the AWS IoT console, choose Greengrass, choose Groups, and then choose your group to open its configuration page. Next, choose Devices, and then choose Add your first Device (or Add Device).\nChoose Create New Device.\nTo create a registry entry for this device, in Name, enter KepServer, and then choose Next.\nOn the Set up security page, choose Use Defaults to use the 1-Click option. This option generates the required keys and certificates using the AWS IoT root CA and creates a default policy and IAM role with default permissions.\nOn the Download security credentials page, download the certificates for your device into a kepserver_certificates folder, and then extract them. Be aware that this is the only step in the process when you can download keys (so make sure you download them here or you will have to create a new AWS IoT device). Choose Finish.\nKepServer should now appear in the Devices list of your Greengrass group.\nConfigure subscription\nNow we enable the KEPServerEx device to send messages to the AWS IoT cloud.\nOn the group configuration page, choose Subscriptions, and then choose Add Subscription.\nFor Select a source, choose Select, Devices, and KepServer.\nFor Select Target, choose Select, Services, and IoT Cloud. Then choose Next.\nFor Optional topic filter, enter iotgateway, choose Next, and then choose Finish.\nOn the group configuration page, from the Actions menu, choose Deploy to deploy the updated group configuration to your Greengrass core device:\nTo confirm a successful deployment, choose Deployments. You should see Successfully completed in the Status column close to the time you initiated the deployment.\nConfigure KEPServer IoT gateway\nCopy the device certificates that you downloaded and extracted earlier. You can use the local file sharing feature of the Microsoft Remote Desktop Connection software.\nNow we configure the MQTT Agent and the IoT gateway to connect Kepware to the Greengrass core device.\nConfigure the IoT Gateway\nTo access the IoT gateway system settings, right-click the Administration icon in the system tray, and then choose Settings. Choose the IoT Gateway tab.\nTo configure the MQTT Agent, choose Manage Certificate.\nOn MQTT Agent Certificate, choose Import New Certificate.\nBrowse to your kepserver_certificates folder, choose the kepserverID.cert.pem file and the kepserverID.private.key.\nIf you are prompted for a password, leave it blank, and then choose OK.\nVerify that the common name is AWS IoT Certificate, and then choose Close.\nRetrieve AWS IoT Greengrass Core Certificate Authority (CA)\nTo retrieve the CA for your Greengrass group, type the following command in your terminal:\naws greengrass list-groups\nLook for MyFirstGroup, and copy the ID (referred to here as group-id).\naws greengrass list-group-certificate-authorities --group-id [your_group_id]\naws greengrass get-group-certificate-authority --certificate-authority-id [the_cert_auth_id_returned_above] --group-id [your_group_id] | awk -v beg=\'-----BEGIN CERTIFICATE-----\' -v end=\'-----END CERTIFICATE-----\' \'sub("".*""beg,beg){f=1} f; sub(end"".*"",end){exit}\' | awk \'{gsub(/\\\\n/,""\\n"")}1\' | sed \'$d\' > greengrassgroupCA.pem\nHere is the output :\n{\n""GroupCertificateAuthorityArn"": ""arn:aws:greengrass:[AWSregion]:[accountID]:/greengrass/groups/[group-id]/certificateauthorities/[certificate-authority-id]"",\n""GroupCertificateAuthorityId"": ""[certificate-authority-id]"",\n""PemEncodedCertificate"": ""-----BEGIN CERTIFICATE-----\\nMIIEFTCCAv2gAwIBAgIVAJq6/DGtiKHvt96VZSPDRe/UCbRyMA0GCSqGSIb3DQEB\\nCwUAMIGoMQswCQYDVQQGEwJVUzEYMBYGA1UECgwPQW1hem9uLmNvbSBJbmMuMRww\\nGgYDVQQLDBNBbWF6b24gV2ViIFNlcnZpY2VzMRMwEQYDVQQIDApXYXNoaW5ndG9u\\nMRAwDgYDVQQHDAdTZWF0dGxlMTowOAYDVQQDDDE3NTM0NTE0NTIwMTI6NDVjODhk\\nZGYtOTE4MC00OGFmLWI2NzAtZDRmN2Q2ODQ4NzBhMCAXDTE4MTAyODAzMjU1MFoY\\nDzIwOTgxMDI4MDMyNTQ5WjCBqDELMAkGA1UEBhMCVVMxGDAWBgNVBAoMD0FtYXpv\\nbi5jb20gSW5jLjEcMBoGA1UECwwTQW1hem9uIFdlYiBTZXJ2aWNlczETMBEGA1UE\\nCAwKV2FzaGluZ3RvbjEQMA4GA1UEBwwHU2VhdHRsZTE6MDgGA1UEAwwxNzUzNDUx\\nNDUyMDEyOjQ1Yzg4ZGRmLTkxODAtNDhhZi1iNjcwLWQ0ZjdkNjg0ODcwYTCCASIw\\nDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAJtpEpUd4UQNf8w401nwuOxy0U7H\\nCIMXidsMQMUz7reKCkNd36RYi/fk3L8I0HjJQV4FeqSEgrn0R0+5/tTUsnLKWL2v\\nhD1uoeYokQ093hOKXJ8sdZQX6+1C+5Cg2rzw5Z+yloebiaRuJ/1kBYBL48rhQOuj\\nl/A9/hqRnK8MTratjFvvgLwens1LEFuEFECqgrAo8WcxyJH5mn2FpIi6+k1MY0Cu\\njnASU44HbsGcWPEXf3wYCVJkXJdGJpDMT0HSIVY6t1ssDGqYv0N05Ho9jRU57qgc\\nAfsWCVMf48ENwrcgJpV100R7t05vl8fBGR4Aw5fX89YPmm2fLSOII/wO3h8CAwEA\\nAaMyMDAwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUh1qliQIyct02aaLJDTTq\\n0iaEOy4wDQYJKoZIhvcNAQELBQADggEBACPQruUOeGr+O/ulUc2TjX3gHxK58JhJ\\n9P0SMKW/Gm/mRFQQsRG/fkvLl2ypmBfyxCYcJjXAYyKuu94HaB0+qmwastdbeLCI\\niD8ytR66SoREKPtIKXHCczNIy5x7HLwfnmD97Vmr+WsDUp9jA/xAGmNE8vKuTil8\\nzYh0KssxU0QpifzjqnEmaqjvIJQLWj9dP8AZGyv5UPT4fcG5VvNnBG6nTEaEIOzR\\nSlzP0MPF88RfArVKV4MYLT/bfGIGF9m0JmOYIPkO1zuoEjEmag+IEAA2xCgubbEn\\nkDOxT1ZC906HZsYP3krOf216BW9PBeF82S/S0XYDp+9+TvWpz2wcNv8=\\n-----END CERTIFICATE-----\\n""\n}\nCopy the PemEncodedCertificate value and paste it in a text editor. Edit the content, replacing any newline character (\\n) with a carriage return (Enter).\nYour file should have the following template:\n-----BEGIN CERTIFICATE-----\nMIIEFTCCAv2gAwIBAgIVAJq6/DGtiKHvt96VZSPDRe/UCbRyMA0GCSqGSIb3DQEB\nCwUAMIGoMQswCQYDVQQGEwJVUzEYMBYGA1UECgwPQW1hem9uLmNvbSBJbmMuMRww\nGgYDVQQLDBNBbWF6b24gV2ViIFNlcnZpY2VzMRMwEQYDVQQIDApXYXNoaW5ndG9u\nMRAwDgYDVQQHDAdTZWF0dGxlMTowOAYDVQQDDDE3NTM0NTE0NTIwMTI6NDVjODhk\nZGYtOTE4MC00OGFmLWI2NzAtZDRmN2Q2ODQ4NzBhMCAXDTE4MTAyODAzMjU1MFoY\nDzIwOTgxMDI4MDMyNTQ5WjCBqDELMAkGA1UEBhMCVVMxGDAWBgNVBAoMD0FtYXpv\nbi5jb20gSW5jLjEcMBoGA1UECwwTQW1hem9uIFdlYiBTZXJ2aWNlczETMBEGA1UE\nCAwKV2FzaGluZ3RvbjEQMA4GA1UEBwwHU2VhdHRsZTE6MDgGA1UEAwwxNzUzNDUx\nNDUyMDEyOjQ1Yzg4ZGRmLTkxODAtNDhhZi1iNjcwLWQ0ZjdkNjg0ODcwYTCCASIw\nDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAJtpEpUd4UQNf8w401nwuOxy0U7H\nCIMXidsMQMUz7reKCkNd36RYi/fk3L8I0HjJQV4FeqSEgrn0R0+5/tTUsnLKWL2v\nhD1uoeYokQ093hOKXJ8sdZQX6+1C+5Cg2rzw5Z+yloebiaRuJ/1kBYBL48rhQOuj\nl/A9/hqRnK8MTratjFvvgLwens1LEFuEFECqgrAo8WcxyJH5mn2FpIi6+k1MY0Cu\njnASU44HbsGcWPEXf3wYCVJkXJdGJpDMT0HSIVY6t1ssDGqYv0N05Ho9jRU57qgc\nAfsWCVMf48ENwrcgJpV100R7t05vl8fBGR4Aw5fX89YPmm2fLSOII/wO3h8CAwEA\nAaMyMDAwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUh1qliQIyct02aaLJDTTq\n0iaEOy4wDQYJKoZIhvcNAQELBQADggEBACPQruUOeGr+O/ulUc2TjX3gHxK58JhJ\n9P0SMKW/Gm/mRFQQsRG/fkvLl2ypmBfyxCYcJjXAYyKuu94HaB0+qmwastdbeLCI\niD8ytR66SoREKPtIKXHCczNIy5x7HLwfnmD97Vmr+WsDUp9jA/xAGmNE8vKuTil8\nzYh0KssxU0QpifzjqnEmaqjvIJQLWj9dP8AZGyv5UPT4fcG5VvNnBG6nTEaEIOzR\nSlzP0MPF88RfArVKV4MYLT/bfGIGF9m0JmOYIPkO1zuoEjEmag+IEAA2xCgubbEn\nkDOxT1ZC906HZsYP3krOf216BW9PBeF82S/S0XYDp+9+TvWpz2wcNv8=\n-----END CERTIFICATE-----\nSave the file as greengrassgroupCA.pem.\nAdd AWS IoT Greengrass Core Certificate Authority (CA) to Windows\nFrom the Windows Start menu, open Run.\nType mmc, and choose OK.\nIn the console window, from the File menu, choose Add/Remove Snap-in.\nChoose Certificates, and then choose Add. Choose Computer account, and then choose Next.\nChoose Finish, and then choose OK.\nExpand Certificates, Trusted Root Certification Authorities, and then choose Certificates.\nOn the right menu, choose Certificates, choose More Actions, All Tasks, and then Import.\nOn the Import Wizard page, choose Next. Browse your local folder, or the shared folder where you saved the greengrassgroupCA.pem file, and choose Open.\n\nNote: If you can\xe2\x80\x99t see the file, in File name, enter the wildcard * and choose Open to see all of the files with the extension of *.pem.\nChoose Next, and then choose Finish. You should see a message that confirms the certificate was imported successfully. Close the console window and choose No if you are prompted to save the template.\nConfigure an agent\nAt least one agent must be configured with one active tag for the gateway service to start. Configure the agents and tags in the IoT Gateway section.\nUnder IoT Gateway, choose Add Agent.\nConfigure the agent with the following parameters:\nName: Kepserver\nType: MQTT ClientChoose Next.\nUsing the connectivity parameters you saved earlier, configure the MQTT Client Broker with the following parameters:\nURL: ssl://Greengrass_Core IPAddress:8883\nTopic: iotgateway\nQOS: 0 (At most once)Keep the other parameters at their defaults, and then choose Next.\nConfigure the MQTT Client Security as follows:\nClient ID: KepServer\nUsername: < Leave empty >\nPassword: < Leave empty >The client ID must match the device name in the AWS IoT console. Choose Finish.\nRight-click the KEPServer Agent you just created, and then choose Properties.\nGo to Security, and modify the TLS configuration so the KEPServer client sends its certificate:\nClient Certificate: Enable\nGo to Message, and then customize the default template as follows:\nMessage Format: Advanced Template\nTemplate:\n{\n""timestamp"": |SERVERTIMESTAMP|,\n""values"": Hello IoT Cloud\n}\nChoose OK.\nYour MQTT Agent configuration should look like this:\nSelect the KEPServer Agent, and choose Add IoT items:\nChoose IoT_Gateway_ / Kepserver branch, and then choose the _PublishesSent tag. Choose Apply.\nUnder Publish, choose Every scan.\nConnect KEPServer to Greengrass core\nBoth the KEPServerEX and Greengrass group are now configured. In this step, we verify that the connection from KEPServer is successful, and then subscribe to the topic in AWS IoT Core.\nVerify the connection is successful\nIn KEPServer:\nFrom the Runtime menu, choose Reinitialize.\nIn the event log window, you should see a message that confirms the MQTT Agent KEPServer is connected to the Greengrass core device:\n  If you get one of the following errors in the event log window:\n\'Software caused connection abort: recv failed\'.\nCheck that you have enabled the client certificate option in the security options, and review AWS IoT Greengrass logs to resolve connectivity issues.\nYou can also enable Amazon CloudWatch logs and look there.\n\'unable to find valid certification path to requested target\'\nCheck that the Greengrass Core certificate authority (CA) has been added to the Windows certificates store.\nTest topic subscription\nTo test the topic subscription, in the left pane of the AWS IoT console, choose Test.\nChoose Subscribe to a topic, and in Subscription topic, enter iotgateway, and then choose Subscribe to topic.\nYou should see the messages published by KEPServer:\n  Wrapping up\nIn this blog, we looked at how to connect and configure KEPServerEX with AWS IoT Greengrass Core. We installed the AWS IoT Core certificate chain to allow these services to communicate with each other.\nWe are now able to process the IoT messages from disparate industrial devices in the AWS environment.\nSummary and additional resources\nBy following the steps in this post, you can collect industrial data from programmable logic controllers (PLCs), SCADA systems, plant historians, and other manufacturing systems and in a few hours get data flowing into AWS securely, efficiently, and cost-effectively. After the industrial data is ingested in AWS, it can be used for a variety of smart manufacturing use cases, including building ML models for predictive maintenance. See for yourself. Get started today with connecting industrial assets and applications from the plant floor to AWS.\nLearn More:\nIndustrial Internet of Things: https://aws.amazon.com/iot/solutions/industrial-iot/\nAWS IoT: https://aws.amazon.com/iot/?nc2=h_iot_\nAWS IoT Analytics User Guide: https://docs.aws.amazon.com/iotanalytics/latest/userguide/welcome.html\nAmazon SageMaker Getting Started Developer Guide: https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html\nML model building: https://aws.amazon.com/blogs/machine-learning/predict-march-madness-using-amazon-sagemaker/\nUsing AWS IoT for Predictive Maintenance: https://aws.amazon.com/fr/blogs/iot/using-aws-iot-for-predictive-maintenance/'"
201,Deploy AWS IoT Greengrass as a Snap to Your Edge Devices,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/deploy-aws-iot-greengrass-as-a-snap-to-your-edge-devices/,"b'Canonical and AWS have collaborated to offer AWS IoT Greengrass as snap, a containerized software package that can run on a variety of Linux distributions. The combination of AWS IoT Greengrass and Ubuntu Core provides IoT developers with a fast path from development to production for their secure device. The AWS IoT Greengrass snap, available through Snapcraft, is maintained and published by the AWS IoT Greengrass team.\nAs part of this release, we\xe2\x80\x99ve also worked with Rigado, a smart building solution provider, and Prologis, a global logistics real estate company, to create an AWS Tech Talk that describes how their teams are using the AWS IoT Greengrass snap to enable their \xe2\x80\x9cwarehouse of the future.\xe2\x80\x9d Prologis Labs is focused on developing and testing new technologies, particularly digital infrastructure that includes IoT sensors, asset tracking, robotics, and more. Prologis and Rigado combined AWS IoT Greengrass with the Rigado Cascade 500 device running Ubuntu Core 16 to create a proof of concept gateway that they can use to capture data from sensors in the Prologis Labs warehouse. To learn more about what they built, you can watch the AWS Tech Talk here.\n\xe2\x80\x9cThe combination of Ubuntu Core with AWS IoT Greengrass gives Rigado customers a containerized platform to quickly deploy IoT applications that leverage the power and scale of AWS Lambda functions,\xe2\x80\x9d says Toban Zolman, Rigado\xe2\x80\x99s Vice-President of Product.\nTo get started with snaps, see the Canonical release notes. After you\xe2\x80\x99ve configured your Greengrass snap, you\xe2\x80\x99ll be ready to deploy AWS Lambda functions, add more edge devices to your Greengrass group, and experiment with Amazon SageMaker ML models using AWS IoT Greengrass tools. When a new version of AWS IoT Greengrass is available, your snap is updated automatically so you can take advantage of the latest IoT Greengrass features. (You can turn off these automatic updates for more control.)\nFor more information about snaps, see snapcraft.io.'"
202,Automating AWS IoT Greengrass Setup With AWS CloudFormation,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/automating-aws-iot-greengrass-setup-with-aws-cloudformation/,"b'In this blog post, I will show you how you can use AWS CloudFormation to set up AWS IoT Greengrass quickly and in a repeatable manner. I will discuss the AWS IoT Greengrass resource types and how they are related to a Greengrass group deployment. I will also demonstrate a deployment that uses an AWS CloudFormation template to:\nLaunch an EC2 instance running the AWS IoT Greengrass Core software.\nDeploy a Lambda function at the edge.\nSet up subscriptions to communicate between AWS IoT Core and AWS IoT Greengrass resources.\nUse cases for AWS CloudFormation with AWS IoT Greengrass\nAWS CloudFormation makes it possible for you to describe and provision all of the infrastructure resources in your cloud environment. Although Greengrass or edge devices are not cloud resources, AWS CloudFormation still provides support for a number of use cases.\nProduction deployment of complete workloads that include cloud and physical device components. For example, if you provide a smart building management solution as a software-as-a-service (SaaS) offering, one of the components might be a Greengrass core provisioned and deployed at the customer\xe2\x80\x99s location. With AWS CloudFormation support, the Greengrass group can be created as part of the AWS CloudFormation deployment. This type of use case is suitable for deployments where a discrete number of Greengrass cores are part of the solution.\nDevelopment and test tasks. When you use AWS CloudFormation as part of a CI/CD process, you can quickly create, test against, and tear down Greengrass resources and groups. For example, you can use AWS CloudFormation to automate testing new versions of AWS Lambda functions or AWS IoT Greengrass connectors. The tests can run with the Greengrass group, and when they are complete, the entire stack can be deleted.\nAWS IoT Greengrass architecture overview\nThe following diagram shows the collection of settings and components known as a Greengrass group.\nA Greengrass group definition is a collection of information about the Greengrass group, which in turn maps to a Greengrass deployment, AWS IoT Core, and other AWS resources, such as AWS Lambda functions. AWS CloudFormation can be used to create a Greengrass core, Lambda functions, and subscriptions resources. Although connectors, devices, and resources are not used in the AWS CloudFormation template for this post, they can be defined and created by AWS CloudFormation, too.\nFor each resource type, there is a definition and a definition version. Based on the resource type, there are certain conditions for associations, such as one-to-one or one-to-many. For more information, see the AWS IoT Greengrass Resource Types Reference in the AWS CloudFormation User Guide.\nAn AWS::Greengrass::CoreDefinitionVersion resource referenced from an AWS::Greengrass::GroupVersion resource is required to create a Greengrass group. Each GroupVersion can refer to different resource version ARNs which, in turn, can have one or more resources.\nThe following diagram shows how the GroupVersion and GroupVersionDefinition are defined. The CoreDefinitionVersion is one-to-one while the definitions can be one-to-many.\nThis shows how the associations for AWS IoT Greengrass look in AWS CloudFormation:\nType: ""AWS::Greengrass::Group""\nProperties:\n  # Required properties\n  RoleArn: String\n  Name: MyNewGroup\n  # ""InitialVersion"" is Optional property, not used in this example\n  # If used, the AWS::Greengrass::GroupVersion would not be required\n  InitialVersion:\n    LoggerDefinitionVersionArn: String\n    DeviceDefinitionVersionArn: String\n    FunctionDefinitionVersionArn: String\n    CoreDefinitionVersionArn: String\n    ResourceDefinitionVersionArn: String\n    ConnectorDefinitionVersionArn: String\n    SubscriptionDefinitionVersionArn: String \n\nType: ""AWS::Greengrass::GroupVersion""\nProperties:\n  # Required properties\n  GroupId: String\n  CoreDefinitionVersionArn: String\n  # Optional properties\n  LoggerDefinitionVersionArn: String\n  DeviceDefinitionVersionArn: String\n  FunctionDefinitionVersionArn: String\n  ResourceDefinitionVersionArn: String\n  ConnectorDefinitionVersionArn: String\n  SubscriptionDefinitionVersionArn: String\nYAML\nWhen deployed, the group definition, Lambda functions, connectors, resources, and subscription table are copied to a Greengrass core device. In the example used in this post, the Greengrass deployment process is manual so you can see what happens from an AWS CloudFormation stack perspective.\nPrerequisites\nAll of the steps for creating and deploying a Greengrass group and core are included in the AWS CloudFormation template.\nAWS CloudFormation must be able to work with other AWS services, including AWS Identity and Access Management (IAM), so your AWS account must have administrative access.\nTo review how the AWS IoT Greengrass software runs on the instance, I will use SSH to connect to the instance. If you do not have an SSH key pair or don\xe2\x80\x99t recognize any of the key names when you enter parameters during the launch of the template, you must create a key pair in your AWS Region. For instructions, see Amazon EC2 Key Pairs in the Amazon EC2 User Guide for Linux Instances.\nThe Oregon (us-west-2) Region is used in the deployment example, but it can run in all AWS Regions where AWS IoT Greengrass is supported.\nAWS CloudFormation template details\nThere are two main sections defined by comment headers in the AWS CloudFormation template.\nIn the GREENGRASS RESOURCES SECTION:\nA group needs, at minimum, a Core definition version. In the template, the Function and Subscription definition versions are also used. Other definitions are included, but commented out.\nA Core definition version requires a ThingArn and certificateId (associated with a policy and the thing). In the GreengrassCoreDefinitionVersion resource, the ThingArn and CertificateId are created from the execution of the custom resource IoTThing that creates the thing, certificate, and policy.\nThe general Definition type of resource requires either a DefinitionVersion or all of the values that make up an InitialVersion of the resource. For example, the GreengrassCoreDefinition references the GreengrassCoreDefinitionVersion resource, while the FunctionDefinition uses the InitialVersion to create the Lambda function resources.\nThe SUPPORTING RESOURCES SECTION of the template includes the resources used to create the environment in which the Greengrass software executes and to help with resource creation and cleanup.\nDeploying the the AWS IoT Greengrass stack using AWS CloudFormation\nNow you are ready to use AWS CloudFormation to create and deploy the AWS IoT Greengrass stack. Based on the input parameters, the template will perform:\nCloud resource setup\nDeploy an EC2 instance with a public IP address into a newly created VPC and:\nDownload and install AWS IoT Greengrass Core 1.8.0.\nCreate all AWS IoT Core and AWS IoT Greengrass config.json settings and certificate files.\nReboot the instance, which starts the Greengrass core in a not deployed state.\nCreate a Lambda function that will be deployed to the Greengrass group.\nAWS IoT Greengrass setup\nCreate the subscription resources for publish/subscribe to AWS IoT Core.\nConfigure the Lambda function to be long-lived (that is, to run continuously).\nCreate the Greengrass group.\nCreate a Greengrass core.\nThis example shows a stack named gg-test in the AWS CloudFormation console:\nThe following parameters are required:\nStack name: This is the AWS CloudFormation stack name. Other resources might include this stack name as part of their names.\nCoreName: This is the Greengrass core name. The CoreName, with _Core appended (for example, gg_cfn_Core), will appear as the AWS IoT thing name. The AWS IoT Thing name will also be created during execution of the AWS CloudFormation stack.\nSecurityAccessCIDR: This is the IP address or addresses that can SSH into the EC2 instance. The default is to allow access from any public IP address.\nmyKeyPair: This is the SSH key pair used to to authenticate the Ubuntu user who connects to the instance. If there is no drop-down list in this field, you need to create a key pair.\nTo complete the stack creation process, choose Next, and then choose the Create Stack button. This will create all of the resources. It should take less than five minutes.\nNote: The resources in this AWS CloudFormation stack might result in charges to your AWS account. To avoid ongoing charges, be sure to delete the stack and any Amazon CloudWatch log files when you are done.\nFrom the Output tab on the AWS CloudFormation stack, copy the value of EC2IPAddress. This is the publicly accessible IP address of the EC2 instance. You connect to that instance using SSH later on.\nTroubleshooting errors\nIf you encounter errors when you deploy the stack, review the Status reason column in the Events section.\nHere are some common errors and their resolution:\nGroupDeploymentReset: This error usually results when an IAM service role is not associated with AWS IoT Greengrass in the AWS Region where the stack is being deployed. Check the CloudWatch stream logs for errors. For information about associating an IAM service role, see Greengrass Service Role in the AWS IoT Greengrass Developer Guide.\nTemplate format error: Unrecognized resource types. This error is displayed when the template is launched and indicates that AWS IoT Greengrass is not available in the AWS Region. Be sure to use a region where AWS IoT Greengrass is supported. For information, see AWS Regions and Endpoints in the AWS General Reference.\nThe maximum number of VPCs has been reached. This error occurs when no additional VPCs can be created in the AWS region. You can either request a service limit increase in the same AWS region, or you can deploy the stack in a different AWS region where AWS IoT Greengrass is supported.\nDeployment results\nThe AWS resources created during deployment of the AWS CloudFormation stack will look similar to this:\nThe IoTThing custom resource is executed to create and return a thing, certificate, and policy.\nThe returned values of certificate and private key are passed to the instance creation, where the UserData command performs the following:\nInstalls dependencies and the AWS IoT Greengrass Core software.\nSaves the certificate and private key.\nGenerates a config.json file.\nConfigures AWS IoT Greengrass to start at boot time.\nRestarts the instance.\nA second custom resource is used to reset the deployment status before the resources are deleted. This is to ensure the deletion process does not leave artifacts behind.\nA VPC with an instance is created along with all of the resources required to create a Greengrass group definition.\nVerifying and testing the stack deployment\nIn the AWS IoT console, choose Greengrass, choose Groups, and then verify that the Greengrass group and resources have been created:\nYou should see a group with the name you provided when you launched the AWS CloudFormation template. To verify the subscription and Lambda function definitions were created, choose the Greengrass group, and then choose each entry. It should look similar to this:\nand:\nYou\xe2\x80\x99ll see the subscriptions and Lambda function definitions were created by the AWS CloudFormation stack. You\xe2\x80\x99ll also see that the Greengrass group is not yet deployed. You can use the console or the AWS IoT Greengrass APIs to perform a deployment. In this post, I use the console.\nTo see what a new Greengrass core looks like, and the changes performed by a deployment, use the IP address and key pair to connect using SSH to the Ubuntu instance. (The user name is ubuntu.) Then check for the greengrass process and connection to AWS IoT Core on TCP port 8883:\nlaptop$ ssh -i EC2_KEY_FILE ubuntu@EC2IPAddress\nubuntu@ip-172-31-0-231:~$ ps ax | grep greengrass\n 1186 ?        Sl     0:00 /greengrass/ggc/packages/1.8.0/bin/daemon -core-dir /greengrass/ggc/packages/1.8.0 -greengrassdPid 1143\nubuntu@ip-172-31-0-231:~$ netstat -na | grep 8883\ntcp        0      0 172.31.0.231:35878      34.213.234.177:8883     ESTABLISHED\nRun ps ax | grep greengrass to verify that the Greengrass daemon is running. Next, run netstat -na | grep 8883, which will show the single persistent Greengrass connection to AWS IoT Core waiting for the deployment action.\nIn the AWS IoT Greengrass console, from Actions, choose Deploy, and then choose Automatic Detection:\nAfter the deployment is complete, a \xe2\x80\x9cSuccessfully completed\xe2\x80\x9d message is displayed in the console, and the Greengrass core is now operating with our deployed resources. You can verify by running the ps -ef command. This command will also show the process owner and additional processes that are now running:\nubuntu@ip-172-31-0-231:~$ ps -ef | grep ""greengrass\\|lambda""\nroot      1186     1  0 13:49 ?        00:00:02 /greengrass/ggc/packages/1.8.0/bin/daemon -core-dir=/greengrass/ggc/packages/1.8.0 -port=8000 -connectionManager=true -cloudSpooler=true -shadow=true -shadowSync=true -tes=true -deviceCertificateManager=true -secretManager=true\nggc_user  1825  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=connectionManager\nggc_user  1841  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=shadowSync\nggc_user  1865  1186  0 14:23 ?        00:00:00 /lambda/ipdetector\nggc_user  1895  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=cloudSpooler\nggc_user  1911  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=shadow\nggc_user  1925  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=tes\nggc_user  1941  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=deviceCertificateManager\nggc_user  1958  1186  0 14:23 ?        00:00:00 /lambda/greengrassSystemComponents -runAs=secretManager\ndaemon    1983  1186  0 14:23 ?        00:00:00 python2.7 -u /runtime/python2.7/lambda_runtime.py --handler=index.function_handler\nIn the last line of the output, the Lambda function is a long-running process that performs two functions:\nEvery five seconds, the Lambda function publishes an incrementing value on core_name/telem topic (gg_cfn/telem is the default). This demonstrates the setting of a long-running function using the Pinned: \'true\' parameter.\nThe Lambda function also subscribes to the gg_cfn/in topic, and any messages received are republished intact (echoed) to the gg_cfn/out topic. This shows how multiple subscriptions can be assigned to a SubscriptionDefinitionVersion. You can test by subscribing to gg_cfn/out and publishing a message to gg_cfn/in and see the echoed message.\nAt this point, you have tested the functionality deployed in this stack, namely that the defined resources were created and operate on the subscriptions. After you review the deployment of the AWS CloudFormation stack, you can delete the resources by navigating to the stack and deleting it. This will delete the Greengrass group, its resources, the EC2 instance, and all VPC resources.\nSummary\nIn this post, I covered the architecture of a Greengrass group and how the Greengrass resources are defined as AWS CloudFormation resources. I used an AWS CloudFormation template that automated the deployment of the Greengrass resources and supporting components. Finally, I deployed the Greengrass group definition to our Greengrass core and tested the functionality through MQTT messages published to and from different topics.\nI hope this blog post was helpful in understanding how AWS CloudFormation resources can be used to automate the setup and launch of AWS IoT Greengrass in your workloads.'"
203,Automating Security Remediation Using AWS IoT Device Defender,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/automating-security-remediation-using-aws-iot-device-defender/,"b'An IoT solution requires managing a large number of devices, usually hundreds of thousands or millions. When you start to work at a large scale, you need to keep your fleet protected by continuously checking if it is following security best practices. It can be challenging for organizations to audit all devices and automatically remediate issues.\nIn this blog post, you will learn how to use AWS IoT Device Defender to simplify this task. The sample architecture shows an example of how to inspect and update AWS IoT policies that are too permissive and don\xe2\x80\x99t follow AWS IoT best practices.\nYou will walk through a solution which has the following tasks:\nCreate an Amazon SNS topic to receive notifications from AWS IoT Device Defender.\nCreate an AWS Lambda function to process the audit results and fix detected issues.\nCreate the required AWS Identity and Access Management (IAM) roles and policies.\nCreate a sample permissive AWS IoT policy.\nRun an on-demand audit.\nMonitor the progress of the audit.\nValidate the mitigation action.\nThe diagram below depicts the AWS services used in this solution and the main steps executed after completing the setup. You should only use the architecture and sample code displayed below as a guideline.\nCreating the required infrastructure\nYou need to create the following components:\nAn SNS topic to receive notifications from AWS IoT Device Defender upon finishing an audit\nA Lambda function to parse the audit findings and fix potential problems\nIAM policies and roles allowing the Lambda function to collect the audit results and change IoT policies\nAn IAM role allowing AWS IoT Device Defender to post to a specific topic in SNS\nLambda permission allowing SNS to call the Lambda function\nYou can do this quickly by using AWS CloudFormation, following these steps:\nClick the following link to open the template available only in us-east-1 (N. Virginia): https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=DeviceDefenderStack&templateURL=https://s3.amazonaws.com/aws-iot-blog-assets/aws-iot-device-defender-automating-actions/cloudformation.yml\nScroll to the end of the Specify stack details page, and click Next.\nScroll to the end of the Options page, and then click Next.\nSelect I acknowledge that AWS CloudFormation might create IAM resources.\nSelect I acknowledge that AWS CloudFormation might create IAM resources with custom names.\nIf you are using the new AWS CloudFormation console, select I acknowledge that AWS CloudFormation might require the following capability: CAPABILITY_AUTO_EXPAND\nChoose Create Stack.\nIt can take a few minutes to complete the stack creation. After finishing it, note the SNS topic name and the role required by AWS IoT Device Defender to publish to SNS.\nOpen the AWS CloudFormation console.\nClick on the name of the stack that was created. For example, \xe2\x80\x9cMyDevDefenderStack\xe2\x80\x9d.\nChoose the Outputs tab, located on the top.\nLocate SnsTopicName and note the content of the Value column. For example, \xe2\x80\x9cDeviceDefenderStack-DevDefenderSnsTopic-16IZWWFS9PXHR\xe2\x80\x9d.\nLocate DevDefenderPublishToTopicRole and note the content of the Value column. For example, \xe2\x80\x9cDeviceDefenderStack-DevDefenderPublishToTopicRole-1WEAG4BWI6429\xe2\x80\x9d.\nUnderstanding the sample permissive AWS IoT policy\nThe AWS CloudFormation template created a permissive AWS IoT policy that will be caught by AWS IoT Device Defender after running an audit. The sample policy that is created is shown below.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Action"": [\n        ""iot:Connect"",\n        ""iot:Publish"",\n        ""iot:Subscribe"",\n        ""iot:Receive""\n      ],\n      ""Resource"": [\n        ""*""\n      ],\n      ""Effect"": ""Allow""\n    }\n  ]\n}\nJSON\nThis policy doesn\xe2\x80\x99t comply with the best practices because it has very broad permissions. For example, the actions aren\xe2\x80\x99t constrained to specific resources. This allows a device using this policy to publish messages to any topic, and potentially interfere with other devices. You can find more information about the analysis performed by AWS IoT Device Defender here: https://docs.aws.amazon.com/iot/latest/developerguide/device-defender-audit.html\nIn a production environment, you should follow a least-privilege policy by default, that is, your device should have only the permissions required to complete its activities. Continuous auditing can help you detect and take action in the event a policy has been created that isn\xe2\x80\x99t in line with best practices.\nUnderstanding the AWS Lambda Function, Permission, and Role\nThe Lambda function receives an SNS message and gets the audit task ID for querying the detailed findings later.\n...\n    msg = json.loads(event[\'Message\'])\n    task_id = msg[\'taskId\']\n...\nPython\nThen it determines whether the results contain a noncompliant check.\n...\n    for audit in msg[\'auditDetails\']:\n        if audit[\'checkRunStatus\'] != ""COMPLETED_COMPLIANT"":\n        logger.info(""ERROR: {}"".format(audit[\'checkName\']))\n...\nPython\nThe function processes only overly permissive policy findings (IOT_POLICY_OVERLY_PERMISSIVE_CHECK), but you can customize it and add handlers to other issues.\n...\n    if audit[\'checkName\'] == ""IOT_POLICY_OVERLY_PERMISSIVE_CHECK"":\n        handle_overly_permissive_policy(task_id)\n    else:\n        handle_security_issue(task_id, issue_name)\n...\nPython\nTo handle permissive issues, the function queries the AWS IoT Device Defender findings and iterates over them.\n...\n    r = iot.list_audit_findings(taskId=task_id, checkName=\'IOT_POLICY_OVERLY_PERMISSIVE_CHECK\')\n    \n    for f in r[\'findings\']:\n        resource = f[\'nonCompliantResource\']\n...\nPython\nTo avoid changing existing policies provisioned on the account, the sample code acts only on the policy created by the AWS CloudFormation template. Additionally, the permissions attached to the Lambda function allow updates only on the permissive AWS IoT policy.\n...\n    if TARGET_POLICY_NAME == policy_name:\n        fix_overly_permissive_policy(policy_name, policy_version)\n...\nPython\nIt will change the current permissive policy to the following predefined restrictive policy, which allows a device to manipulate only its own shadow.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Sid"": ""ConnectUsingClientId"",\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:*:*:client/${iot:Connection.Thing.ThingName}"",\n      ""Condition"": {\n        ""Bool"": {\n          ""iot:Connection.Thing.IsAttached"": ""true""\n        }\n      }\n    },\n    {\n      ""Sid"": ""UpdateAndQueryOwnShadow"",\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Publish""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:*:*:topic/$aws/things/${iot:Connection.Thing.ThingName}/shadow/update"",\n        ""arn:aws:iot:*:*:topic/$aws/things/${iot:Connection.Thing.ThingName}/shadow/get""\n      ]\n    },\n    {\n      ""Sid"": ""ReceiveShadowChanges"",\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:Subscribe"",\n        ""iot:Receive""\n      ],\n      ""Resource"": [\n        ""arn:aws:iot:*:*:topicfilter/$aws/things/${iot:Connection.Thing.ThingName}/shadow/+/accepted"",\n        ""arn:aws:iot:*:*:topicfilter/$aws/things/${iot:Connection.Thing.ThingName}/shadow/+/rejected""\n      ]\n    }\n  ]\n}\nJSON\nThe code to fix this issue is defined on the fix_overly_permissive_policy() function. It handles a few different situations, but the main idea is to delete the offending policy, and replace it with a new default one with restrictive permissions.\ndef fix_overly_permissive_policy(policy_name, policy_version):\n...\n    r = iot.delete_policy_version(\n        policyName=policy_name,\n        policyVersionId=policy_version\n    )\n...\n    r = iot.create_policy_version(\n        policyName=policy_name,\n        policyDocument=RESTRICTIVE_DEFAULT_POLICY,\n        setAsDefault=True\n    )\n...\nPython\nThis sample function will work for a few issues. If you need to address a large number of issues at a time, you have to decouple the results analysis from the remediation using Amazon SQS, for example.\nConfiguring AWS IoT Device Defender to post results on an SNS topic\nYou need to connect your AWS IoT Device Defender to the SNS topic created by the AWS CloudFormation template. Each completed audit task triggers the Lambda function.\nTo complete this task, follow these steps:\nOpen the AWS IoT Core console.\nIf this is the first time on the AWS IoT Core console, click on Get Started\nIn the left navigation pane, choose Defend, and then choose Settings.\nIf you haven\xe2\x80\x99t done it previously, complete the AWS IoT Device Defender setup wizard to create the required permissions clicking Get started with an audit.\nScroll down until you locate SNS alerts.\nChoose Edit.\nChoose Enabled.\nChoose Select under Topic to select the topic you want.\nChoose the topic created during the AWS CloudFormation execution.\nUnder Role, choose Select.\nChoose the role created during the AWS CloudFormation execution.\nChoose Update to finish the configuration.\nCreating an On-Demand Audit\nAfter finishing the setup, you will run an on-demand audit to check if the remediation strategy is working. Each completed audit task will trigger the Lambda function.\nTo complete this task, follow these steps:\nOpen the AWS IoT Core console.\nIn the left navigation pane, choose Defend.\nChoose Audit and then Schedule.\nOn the upper right, choose Create.\nSelect only IoT policies overly permissive. You can use AWS IoT Device Defender to create separated schedules for each type of check. For example, a daily audit for Device certificate shared and a weekly audit for CA Certificates expiring.\nScroll to the Set Schedule session.\nChoose Run audit now (once).\nChoose Create to start the audit.\nChecking the Audit Progress\nDepending on the number of devices and checks selected, the Audit execution can take more time to finish. You can follow the progress using the console or the APIs.\nOpen the AWS IoT console.\nIn the left navigation pane, choose Defend.\nChoose Audit and then Results.\nChoose the audit you created.\nCheck the results.\nChoose the check name IoT policies overly permissive to see a detailed report.\nValidating the Mitigation Action\nAfter completing the audit, the AWS Lambda function is triggered and the target policy is updated. You can check that the mitigation strategy was successfully implemented by looking at the policy in the console.\nTo complete this task, follow these steps:\nOpen the AWS IoT Core console.\nIn the left navigation pane, choose Secure, and then choose Policies.\nSearch for the specific policy by using the text box on the upper right.\nEnter the name of the policy (for example, \xe2\x80\x9cMyPermissiveIoTPolicy\xe2\x80\x9d).\nChoose Search.\nChoose the policy displayed on the right panel.\nScroll down to locate the Policy Document section.\nCheck if the policy document was updated with the restrictive policy you want.\n'"
204,Use AWS IoT Device Management fleet indexing to identify and visualize fleet state,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/use-aws-iot-device-management-fleet-indexing-to-identify-and-visualize-fleet-state/,"b'In this blog post, we\xe2\x80\x99ll show you how to use new capabilities of AWS IoT Device Management fleet indexing. Starting now, you can use aggregation queries in conjunction with AWS Lambda and Amazon CloudWatch to automate fleet monitoring.\nWhen managing Internet of Things (IoT) devices, it can be challenging to monitor the state of the fleet. The complexity is due to many factors: the number of devices, number of dynamic states to monitor, and number of notification mechanisms for fleet state change. AWS IoT Device Management is a service that enables you to onboard, organize, monitor, and manage remotely connected devices at scale.\nWithin AWS IoT Device Management, fleet indexing allows you to index the registry, device shadow, and connection state for every device in your fleet, and search for devices based on any combination of these attributes. You can use fleet indexing to query which devices are running a particular version of firmware, or to query which devices are actively connected to AWS IoT services.\nAt a high level, this blog post walks through four steps:\nEnable fleet indexing.\nDefine AWS Identity and Access Management (IAM) role and permissions for the Lambda function.\nDefine and configure the Lambda function.\nBuild fleet management dashboard and configure alarms using CloudWatch.\nThe blog post uses the AWS Management Console to execute the steps. You can also execute the same steps by using the AWS Command Line Interface (AWS CLI).\nEnable fleet indexing\nYou can enable fleet indexing by choosing Settings in the AWS IoT Device Management console. Be sure that thing connectivity indexing is enabled, as we\xe2\x80\x99ll be using connectivity fields in the aggregation queries.\n  Using aggregation count queries\nIn the AWS IoT Device Management console, choose Things, Search Things to test the aggregation query before building the Lambda function. The following is an example request and response.\nYou can change the query string to include any registry or shadow parameters.\nIAM role definition for the Lambda function\nThe Lambda function needs permissions to publish metrics to CloudWatch, and to allow iot::GetStatistics action on the index resource. These permissions are additional to the standard Lambda permission to publish logs to CloudWatch to debug runtime issues with the Lambda function.\nGetStatistics permission is required to run aggregation queries. There are two steps for this permission definition: first, a policy needs to be created, then a role can be created and the policy in the first step can be attached to the role.\nCREATE POLICY\nThe policy needs permissions to publish the CloudWatch logs, publish CloudWatch metrics, and allow the iot:GetStatistics action on the index resource. Create the policy in the IAM console by choosing Policies, Create Policy.\nLet\xe2\x80\x99s us create a policy named IoTFleetMetricPublishPolicy. The following JSON document can be used to define the policy. Replace ACCOUNT_ID with an actual account ID.\n{\n    ""Version"": ""2012-10-17"",\n       ""Statement"": [\n            {\n                ""Effect"": ""Allow"",\n                ""Action"": ""cloudwatch:PutMetricData"",\n                ""Resource"": ""*""\n            },\n            {\n                ""Effect"": ""Allow"",\n                ""Action"": [\n                    ""iot:GetStatistics""\n                ],\n                ""Resource"": ""arn:aws:iot:*:ACCOUNT_ID:*""\n            },\n            {\n                ""Effect"": ""Allow"",\n                ""Action"": [\n                    ""logs:CreateLogGroup"",\n                    ""logs:CreateLogStream"",\n                    ""logs:PutLogEvents""\n                ],\n                ""Resource"": ""arn:aws:logs:*:*:*""\n            }\n    ]\n}\nJSON\nCREATE ROLE\nIn this step, a new role named IoTFleetMetricPublishRole will be created, and the IoTFleetMetricPublishPolicy created in the previous step will be attached to the role. Create the role in the IAM console by choosing Roles, Create role.\nSelect AWS Lambda as the service that will use this role\nAttach IoTFleetMetricPublishPolicy to the new role\nAdd any optional tags\nReview and create the role\n  Define and configure the Lambda function\nIn this step, we create and define a Lambda function named IoTFleetMetricPublisher. The function will query the fleet index every five minutes to find the number of connected devices, and then publish it as a metric to CloudWatch.\nCREATE AND CONFIGURE THE LAMBDA FUNCTION\nIn this step, we create a Lambda function and configure it to run every five minutes. Create the Lambda function in the Lambda console by choosing Functions, Create function.\nCreate the Lambda function named IoTFleetMetricPublisher\nConfigure the IoTFleetMetricPublisher to run every five minutes by adding an Amazon CloudWatch Events trigger\n\nDefine the lambda function\nWe\xe2\x80\x99ll choose Node.js as the programming language for creating the Lambda function (Java and Python are the other alternatives). The Lambda function calls fleet indexing to find the number of connected devices. The result of the call is published as a CloudWatch metric named ConnectedDevices under the namespace IoTFleetManagement. The Node.js code is shown below.\n// Configuring the AWS SDK\nvar AWS = require(\'aws-sdk\');\n// Configuring the AWS Region\nAWS.config.update({ region: \'us-east-1\' });\nexports.handler = (event, context, callback) => {\n  // Create a CloudWatch service object\n  var cw = new AWS.CloudWatch({ apiVersion: \'2010-08-01\' });\n  // Create an AWS IoT service object\n  var iot = new AWS.Iot({ apiVersion: \'2015-05-28\' });\n  var queryParams = {\n    queryString: \'connectivity.connected:true\'\n  };\n  iot.getStatistics(queryParams, function(err, data) {\n    if (err) console.log(err, err.stack); // an error occurred\n    else {\n      console.log(data); // successful response\n      // Create parameters JSON for putMetricData\n      var params = {\n        MetricData: [{\n          MetricName: \'ConnectedDevices\',\n          Dimensions: [],\n          Unit: \'None\',\n          Value: data.statistics.count\n        }, ],\n        Namespace: \'IoTFleetManagement\'\n      };\n\n      cw.putMetricData(params, function(err, data) {\n        if (err) {\n          console.log(""Error"", err);\n        }\n        else {\n          console.log(""Success"", JSON.stringify(data));\n        }\n      });\n    }\n  });\n};\nJavaScript\nIn this step, for Code entry type, choose Edit code inline, and for Runtime, choose Node.js 8.10. Then copy the previous code listing to the inline code editor window, as shown below.\nSave the Lambda function.\nDefine a Lambda Layer to use the latest AWS SDK\nThe default version of AWS SDK available under the Lambda run time is not latest. In this step we will define a Lambda layer and associate the Lambda layer to the Lambda function.  First we have to create a zip file which contains the latest AWS SDK. Execute the following commands in a command line to create the zip file.\nmkdir nodejs\ncd nodejs\nnpm init\nnpm install --save aws-sdk\ncd ..\nzip -r nodejs.zip nodejs/\nBash\nAfter creating the zip file, you can define the Lambda Layer by choosing Lambda,Layers,Create layer.  Create a Lambda layer called awsSDKLambdaLayer. Select the nodejs.zip created in the previous step for uploading.\nThe last step is to attach the newly created Lambda layer, awsSDKLambdaLayer to the IoTFleetMetricPublisherLambda function.\nBuild a fleet management dashboard and configure alarms using CloudWatch\nAfter the previous step, Lambda will automatically start publishing the metric to Cloudwatch every five minutes. In this step, we build a dashboard and configure an alarm in CloudWatch using the metric published by the Lambda function.\nCREATE a dashboard\nYou can define the dashboard in the CloudWatch console by choosing Dashboards, Create Dashboard. The Create Dashboard workflow allows you to choose a name for the dashboard, and then pick the metrics to show in the dashboard.\n\nCreate an alarm on the CONNECTED DEVICES METRIC\nYou can create alarms in the CloudWatch console by choosing Alarms, Create Alarm. In this step, we create an alarm named ConnectedDevicesAlarm that is triggered if the number of connected devices metric falls below 5 for two data points within a 15-minute window.\nWrapping up\nIn this blog post, we looked at how to create an IoT fleet management dashboard. You can modify the Lambda function to specify additional queries and other metrics. Some examples of metrics you can build include finding all devices that are connected with thing \xe2\x80\x9ctype X\xe2\x80\x9d and firmware \xe2\x80\x9cversion Y\xe2\x80\x9d, finding all devices that are connected with battery usage more than 90 percent, or finding all devices that have shadow.reported.state.temperature greater than 50.\nYou can also use aggregation queries against the thing group index.\nAlthough the example here is a start, there\xe2\x80\x99s much more that AWS IoT Device Management offers to onboard, organize, monitor, and remotely manage connected devices at scale.\nLearn more\nAWS IoT Device Management\nhttps://aws.amazon.com/iot-device-management\nAWS IoT Device Management Features\nhttps://aws.amazon.com/iot-device-management/features/\nAWS CloudWatch\nhttps://aws.amazon.com/cloudwatch/\nAWS Lambda\nhttps://aws.amazon.com/lambda/\nAWS IAM Roles\nhttps://aws.amazon.com/iam/'"
205,Your Guide to AWS IoT at NVIDIA GTC 2019,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/your-guide-to-aws-iot-at-nvidia-gtc-2019/,"b'NVIDIA\xe2\x80\x99s GPU Technology Conference (GTC) 2019 is almost here! We don\xe2\x80\x99t want you to miss any IoT content, so in this blog post we\xe2\x80\x99ll share some technical demonstrations that show how emerging technologies, including IoT, edge computing, AI and machine learning, and robotics, will shape our world.\nIn the AWS Booth (#1221)\nAnomaly Detection in The Seattle Spheres\nThe Spheres is an innovative Amazon building project and home to more than 40,000 plants from the cloud forest regions of more than 30 countries. We\xe2\x80\x99ve collected environmental data since its opening, and a complex MXNet model has been trained to detect anomalies. This demonstration shows time-series anomaly detection using ML inference at the edge powered by the NVIDIA Jetson AGX Xavier module, AWS IoT Greengrass, and Amazon SageMaker Neo. NVIDIA Jetson AGX Xavier runs the AWS IoT Greengrass binary and the cross-compiled MXNet model directly on the device, which is faster and less memory-intensive than running the model natively on the MXNet framework.\nTrain Machine Learning Models Once, Run Them Anywhere with 2x Performance with Amazon SageMaker Neo\nThis demonstration shows how AWS customers can use Amazon SageMaker to train a computer vision model in the cloud, use AWS Sagemaker Neo to optimize the ML model for inference on the NVIDIA Jetson Nano AI computer, and use AWS IoT Greengrass to manage a fleet of Jetson Nano devices running ML inference.\nIn the NVIDIA Jetson Pavilion (#1543 and #1545)\nImproving Patient Care with Fall Detection\nDesigned to improve patient care in elder care facilities and hospitals, this solution monitors human movement and alerts facility staff if a patient falls. This demonstration shows an NVIDIA Jetson TX2 edge device running AWS IoT Greengrass that performs local inference to detect a fall. AWS IoT Greengrass uses the AWS IoT rules engine to send messages to Amazon Simple Notification Service (Amazon SNS), which then sends emails or text messages to facility staff.\nDinosaur World Search\nThis demonstration envisions a future where vehicles patrol a theme park to identify dinosaur and other rare species and alert scientists of any anomalies or unknown species, all powered by NVIDIA Jetson modules controlled through AWS IoT services. The vehicles travel in predetermined paths, continuously looking for dinosaurs and alert scientists when an unknown species is detected. Scientists can then use Amazon SageMaker Ground Truth to classify new species, retrain the model using AWS SageMaker, and redeploy the improved model using AWS IoT Greengrass.\nDeveloping Robots with AWS RoboMaker\nExperience the AWS RoboMaker iterative development, testing, and deployment workflow for robotics applications through a warehouse mapping and navigation application for NVIDIA Jetson devices. Customers can use the AWS Cloud9 development environment for AWS RoboMaker to edit robot application code, test in the AWS RoboMaker simulation using a 3D warehouse simulation environment, and then use AWS IoT Greengrass to deploy the application to a NVIDIA Jetson device.\nStop by the AWS booth or the NVIDIA Jetson pavilion to learn more about our collaboration to bring AI, machine learning, and robotic development to millions of edge devices.'"
206,Using AWS IoT Services for Asset Condition Monitoring,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-aws-iot-services-for-asset-condition-monitoring/,"b'The Industrial Internet of Things (IIoT) presents an unparalleled opportunity for every industry to address core business challenges, such as reducing downtime, improving safety, increasing system output, reducing operating costs, and creating innovative services and business models. In this blog post, I will show how you can use AWS IoT services to build an asset condition monitoring solution that captures data from physical assets so you can understand their status and performance and take appropriate action.\nWhy monitor your assets?\nWhen you monitor the status of industrial assets like machinery, remote infrastructure, and vehicles, you can use the data collected to quickly respond to changing conditions, identify operational trends, and improve forecasting to maximize the performance and efficiency of the larger system. Data can be collected in near real-time (sub-second), hourly, or daily, depending on your business requirements, connectivity, and budget. You can use AWS IoT Greengrass to process, store, and analyze this data in the cloud or at the edge. AWS IoT Greengrass is software that brings memory and compute closer to the physical asset. It provides local compute and machine learning inference capabilities at the device level. As you connect more assets, the data set becomes richer, providing a high fidelity view of your operations. This gives you deeper insight and the ability to identify larger trends for data-driven decision making.\nMany industrial organizations look to a future where distributed systems continuously analyze data from assets using machine learning (ML) models and autonomously adapting inputs and outputs to ensure maximum performance. The first step is to connect assets and begin collecting, processing, and analyzing data at the edge and in the cloud.\nDefine business objectives and outcomes\nWe recommend that you start small. Clearly define the business problem and identify measurable outcomes (for example, improving equipment up-time by 60% or reducing food spoilage across a cold chain distribution network by 85%). You might want to use user stories, which are a feature of agile development. For example, \xe2\x80\x9dAs an airport operations manager, I want to see the real-time status of the baggage conveyor system so that I can quickly resolve faults and ensure the system is 99.9% operational.\xe2\x80\x9d You can iterate on and scale the solution using AWS IoT services.\nCase Study: Maximizing Wind Turbine performance\nConsider a wind farm with turbines distributed over hundreds of square miles. Energy operators must generate consistent, profitable power output by maximizing turbine performance. Although routine scheduled maintenance is key to continuous operations, this does not prevent turbines from going offline before the next maintenance window. Energy operators want to maximize wind farm output by providing operations staff near real-time data into turbine mechanical performance. Access to this real-time data makes it possible to schedule maintenance based on current conditions and initiate immediate action when a fault is detected. Then alerts can be sent automatically to onsite engineers through a mobile device.\nBuilding a solution\nYou can break down these business requirements into the following solution objectives:\nObtain continuous, near real-time sensor data from turbines at the edge.\nSecurely transport and ingest data into the AWS cloud.\nProcess the data and automatically trigger mobile alerts on anomalous values (for example, if vibration (Hz) becomes too high, then investigate a potential fault).\nVisualize the turbines\xe2\x80\x99 metrics for operational staff and provide a permanent historical data set for ad-hoc analysis, research, and future input for a machine learning model.\n1. Collecting data from industrial equipment at the Edge\nData can be collected from industrial equipment (in this example, wind turbines) through sensors. Sensor data is transmitted from equipment to an AWS IoT Greengrass core running on a qualified gateway device. AWS IoT Greengrass provides local compute using AWS Lambda functions, a local message broker to support local device-to-device and device-to-cloud communication, device shadows for managing equipment state, and machine learning inference using deep-learning models trained in Amazon SageMaker. You can use the AWS Management Console or AWS CLI to create Lambda functions and configure AWS IoT Greengrass, which simplifies the development and deployment process. Wind turbines can communicate their state to AWS IoT Greengrass using MQTT, a lightweight publish-subscribe messaging protocol. Messages are routed between publishers and subscribers by the local message broker through topics, which serve as bi-directional communication channels between devices, AWS IoT Greengrass, and AWS IoT Core.\nAWS IoT Greengrass also provides support for OPC-UA and local protocol conversion using prebuilt connectors or Lambda functions. This makes it possible for you to interface with equipment that uses proprietary protocols like Modbus RTU without deploying a new sensing overlay. There is an advantage to adding more sensors, however. You create a new acquisition layer separate from your existing operational technology systems, which can improve security and make it possible for your development team to innovate more quickly. If you are using microcontrollers to build new sensing devices, you can use Amazon FreeRTOS, an open source real-time operating system (RTOS) that supports many hardware architectures and provides libraries to simplify network connectivity to AWS IoT, manage security, and execute over-the-air (OTA) updates. Amazon FreeRTOS is free to download under the MIT license and can be modified without permission of AWS. You can find a list of qualified microcontrollers here.\n2. Securely transporting and ingesting data to AWS\nMQTT messages are transmitted securely from AWS IoT Greengrass to AWS IoT Core, the entry point to the AWS Cloud. AWS IoT Core provides several key features:\nAn identity service for authentication and authorization.\nA device gateway to connect devices.\nA message broker to route messages.\nA rules engine to trigger actions.\nA device shadow to enable applications to interact with devices when they are offline.\nA registry that enables automatic device registration.\nYou use AWS IoT Core to define a turbine as a thing and generate an X.509 device certificate, private key, and root CA certificate that is placed on the device for authentication. You then use AWS IoT Device Management to define a thing group and add metadata for each turbine, such as model number, GPS coordinates, manufacturer. This metadata is useful for data analysis, remote device management, and implementation of future predictive maintenance. You also configure a rule in the AWS IoT rules engine to route all messages received from site1 (turbines/site1/#) in the MQTT topic stream to AWS IoT Analytics for processing.\nThis diagram shows wind turbine publishing state information to a topic. AWS IoT Greengrass is subscribed to the topic and forwards it to AWS IoT Core when connectivity is available. AWS IoT Greengrass can communicate with turbines locally even if connectivity to the cloud is lost. To reduce latency and data transmission costs, you could also process and analyze data locally at the edge using a Lambda function running on AWS IoT Greengrass.\n3. Processing data, detecting anomalies and triggering action\nThere is now a steady stream of data being ingested from the turbines. You need to process and \xe2\x80\x9cclean\xe2\x80\x9d this data before you analyze it and make it available to upstream applications. AWS IoT Analytics can be used for the collection, processing, and storage of unstructured data, or alternatively, this data can be analyzed using SQL or Jupyter Notebooks. The turbine data received from AWS IoT Core is processed in stages as follows:\nA channel receives data from AWS IoT Core, filtered by the MQTT topic turbines/site1/#\nA pipeline processes messages from this channel. You can enrich the data through filters and transformations. It is here that you can trigger action on the incoming data by invoking a Lambda function that contains logic to send a message to Amazon PinPoint. If vibration readings exceed 100 Hz, which indicates an impending failure, Amazon PinPoint generates an SMS notification to onsite field engineers. You can enrich the stream with data from other sources (for example, weather data) for context and clean any noisy or corrupted messages or false readings that might hinder analysis.\nFinally, the data is stored in a time-series data set where it is ready for visualization or analysis using SQL and Jupyter Notebooks. You can also schedule an automatic refresh of the query every 15 minutes to ensure that the latest data is available to upstream applications.\n4. Analyzing and Visualizing data to enable insight and action\nWith a processed data set, you can use Amazon QuickSight, a business intelligence (BI) service, to directly connect to the data set in AWS IoT Analytics and create a dashboard that displays turbine speed, vibration, and current power output for a specific turbine model. This allows you to analyze asset performance over time, gain new insights, and then identify actions to improve efficiency and maximize wind farm performance. These insights increase in value as more devices are connected by providing more fidelity to the data. For example, you might overlay weather, GPS location, and vibration data to discover that turbine models of the exact same type perform quite differently due to local weather conditions or temperature. This insight can then be used to modify turbine mechanical attributes as needed and also serve as a continuous feedback loop into product development of new turbines, with the goal of maximizing energy output and overall turbine performance.\nYou can also create ad-hoc queries on the AWS IoT Analytics data store using SQL. For example, to locate turbines with potential mechanical issues, you can use the following query to search for vibration readings of more than 100 Hz:\nSELECT thingid, vibration, datetime FROM turbine_datastore WHERE vibration > 100\nThe output is displayed in the AWS IoT console and is provided as a downloadable CSV file.\nFor more sophisticated analysis and prediction, you can also use the integrated Jupyter Notebooks with ML analytics and Python. There are several sample notebooks available for use cases. For example, the Contextual Anomaly Detection notebook can be used to locate sensor readings outside the normal operating range. You can also download Jupyter notebooks locally onto your system.\nSystem Architecture\nHere is the high-level architecture of the solution. It shows how AWS services are used for asset condition monitoring:\nCost Optimization\nIn this solution, data is continuously streamed to AWS for processing and analysis. Because excessive data transport from remote locations could increase costs, you can use Lambda functions deployed onto an AWS IoT Greengrass core and send only the data required by your use case to the cloud. For example, in this scenario, you could implement logic in a Lambda function that analyzes data streaming from turbines locally (at the edge) and send a message to AWS IoT Core only if an anomalous value is detected.\nThe value of Partners for IoT projects\nIoT projects span many devices and technology domains\xe2\x80\x94from sensors and actuators to sophisticated machine learning algorithms. The AWS network of consulting partners specializes in guiding you through the development of production scale IoT solutions. Your business outcome improvements are limited only by your team\xe2\x80\x99s imagination. To learn more, visit the AWS Partner Network.\nNext Steps\nIn this post, I have shown how you can use Amazon FreeRTOS and AWS IoT Greengrass to sense physical attributes at the edge, transport data to AWS using AWS IoT Core, and perform analysis using AWS IoT Analytics. Asset condition monitoring is the first step toward a larger digital transformation strategy. AWS IoT services makes continuous innovation possible through its integration with other services. Now that data is flowing from your equipment, you can modify this architecture to use machine learning and enable predictive maintenance. This helps you maximize asset performance and predict failures ahead of time.\nLearn More\nLearn more about industrial IoT use cases on our Industrial IoT solutions webpage\nVisit IoT Atlas to learn about tried and tested design patterns for developing robust IoT production systems\nStart learning with Internet of Things Foundation Series\nFind an AWS partner to guide your organization through creating an IoT strategy'"
207,Before Developing Real Devices: Exploring a Business Outcome with Simulated Devices,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/before-developing-real-devices-exploring-a-business-outcome-with-simulated-devices/,"b'Realize business outcomes with the IoT Device Simulator, AWS IoT Analytics, Amazon QuickSight, Microsoft Power BI, and Tableau\nCustomers often get wrapped up in slower hardware development cycles before they have real, potential business outcomes identified and agreed upon for their business. This post highlights how customers should consider using simulated devices to explore business outcomes in parallel to the actual development and engineering of the devices. Real devices can then be built and deployed to provide real instrumented data to materialize actual business outcomes.\nThis paradigm shift increases both collaboration opportunities across functional areas (business and engineering/IT) during development and deployments, as well as creates solid foundations to realize the full value proposition of IoT implementations. We describe this benefit as \xe2\x80\x9cdevices can be quickly built to meet the Minimum Loveable Product\xe2\x80\x9d (MLP) which reinforces the focus on device telemetry when developing the actual device hardware and software.\nSequential IoT Implementations\nOftentimes, traditional IoT developments and implementations follow a prescriptive sequential pattern.\nZoom-in on, design, or acquire IoT devices and perform field testing;\nAttach sensors to devices and perform functional testing;\nDevelop and test IoT device software;\nSecure devices and connect them to AWS IoT Core (with or without AWS Greengrass);\nDefine AWS policies for users and applications and attach to certificates;\nPerform data storage and basic analytics functions;\nIncorporate telemetry data into existing or new visualizations and reporting;\nDevelop IoT operational reporting metrics (both KPIs for device operations and KPIs driven by the IoT solution);\nEvolve business integration capabilities and regularly communicate results;\nContinually ROI the IoT value proposition by making IoT data and analytics as the key starting points;\nTypically, business teams and key stakeholders may not be able to assess how an IoT implementation is performing until devices have been deployed at scale. This approach can delay the adoption of IoT driven capabilities since 1) intrinsic business value can not be easily understood and communicated, 2) the time gap between physical device development and actual IoT data generation, capture, and use can dampen adoption enthusiasm, and 3) testing and validation of large scale IoT implementations can shift the focus away from analytics and possibly derail the overall IoT implementation success.\nIterative IoT Developments Start with Data and Analytics\nWith new capabilities driven by both analytics and device simulators there are options to actually begin developing IoT solution starting with simulated data in an iterative/agile fashion. The difference between data generated by simulators and data generated by actual devices can be modeled in such a way that they are indistinguishable. What kinds of data are best for a particular IoT implementation? How frequently is the data being generated? What kinds of visualizations are best to complement or enrich existing business intelligence functions?\nA typical iterative IoT analytics development pattern would look like below.\nSimulate device data and iteratively fine-tune simulations with business, software, and engineering stakeholders. The main objective is to obtain data from device simulators almost identical to device generated data during production;\nIdentify metadata needed to create analytics and visualizations. Some of it could be in S3 buckets;\nDocument enrichment, transformation, and filtering of data;\nPrototype visualizations with available BI tools, such as Power BI, Tableau, or QuickSight.\nIterate steps 1 through 4 until business and technical objectives are met;\nCreate design documents, information models, and artifacts needed to develop, test, and deploy the solution into production;\nIoT Migrations Have a Head Start with AWS IoT Analytics\nAnother powerful reason to use IoT device simulators is to help position migrations of existing IoT implementations to AWS IoT. Existing IoT implementations already generate data and using AWS IoT Core and AWS IoT Analytics may help organizations obtain a realistic representation of how AWS can help close some of the existing gaps of currently implemented analytics solutions. In addition, IoT simulations and visualizations can be done from a business perspective first and then possibly affect the migration strategies at the technical levels.\nThe underlying data plane (data model, data types, frequency, etc.) can remain the same as the current implementations while data ingestion and analytics cycles get additional innovation iterations using AWS out-of-the-box capabilities to integrate with existing BI tools and visualizations.\nOverall Solution Architecture\nSet Up the IoT Device Simulator\nAfter getting an AWS account, the next pre-requisite for obtaining business value out of IoT solutions is to set up the IoT device simulator. The IoT Device Simulator is a solution deployed against your AWS account and uses a web interface to enable \xe2\x80\x98soft\xe2\x80\x99 devices to interact with the AWS IoT end-point of the region in your account.\nAfter the IoT Device Simulator is deployed and you log on you should see a window similar to the one below.\nLet\xe2\x80\x99s set up a new device type, and under it let\xe2\x80\x99s create new devices (widgets). All devices created under a device type generate data with the same structure and frequency defined during define type creation.\nI\xe2\x80\x99ve created a device type called tankfillsensor with the following JSON payload. The data transmission duration is 6000 seconds (or 6000000 milliseconds), with a frequency of 5 seconds (5000 milliseconds). The device type publishes data on MQTT topic liquidtank/fillpercentage.\n{\n  ""deviceid"": ""799fc110-fee2-43b2-a6ed-a504fa77931a"",\n  ""fillpercentage"": 99.4,\n  ""batterystatus"": ""true"",\n  ""datetime"": ""2018-02-15T21:50:18"",\n  ""latlong"": ""{ \'latitude\': 38.9072, \'longitude\': 77.0369 }"",\n  ""gridlocationid"": 1000,\n  ""attribute1"": ""asdqwiei1238""\n}\nJSON\nAfter navigating to Widgets on the left hand side, we can click on Add Widget and we add 10 devices of the same type, tankfillsensor. After completion, we start each of them and the device simulation has begun.\nWe navigate to AWS IoT Core and then Test and we subscribe to liquidtank/fillpercentage and we can see the data being published by devices defined. We notice that the device simulator actually adds a device id associated with your device (_id_), in case you forget to add one in your MQTT payload\nWe can now, engage the rule engine to send the data to an AWS IoT Analytics Channel. We create a new rule called IoTAnalytics_liquid_tank_fill and the SQL statement is as following.\nSELECT *, parse_time(""yyyy-MM-dd HH:mm:ss z"", timestamp()) as ingest_dt FROM \'liquidtank/fillpercentage\'\nSQL\nFor an action we select to send the MQTT messages to an IoT Analytics Channel called liquid_tank_fill which we create at the same time we create the rule action.\nWe navigate to IoT Analytics and we can see that the liquid_tank_fill channel has the data retention set to an indefinite period.\nWe then click on Pipeline and create a new pipeline called pipeline_ltf and define a few actions and store the data in a data store called fillpercentage_ds1. We have added 2 activities to the pipeline: divide the fill percentage by 10 and create a new field to store the decimal value as fieldpercentage1=fieldpercentage/100 and batterystate = batterystatus+1.\nNow, we have the data store created with 2 new additional attributes defined in the pipeline processing and we can create a data set using the data store just created.\nOn the IoT Analytics window click on Analyze and then Data Sets. Create a data set called fillpercentage_dataset1 with a very simple query as below. We can see that we have both fillpercentage1 and batterystate added in addition to the original incoming fields.\nSELECT * FROM fillpercentage_ds1 where __dt >= current_date - interval \'7\' day\nSQL\nSchedule the data set to run every hour.\nYou can access the data set for reporting in Jupyter notebooks or directly in QuickSight. However, if you have Power BI or Tableau for your broader enterprise reporting needs, you may need to download the file and import it into your own enterprise BI applications.\nAn example of a visualization created using QuickSight can be seen below. In QuickSight, to connect to a data set from IoT Analytics, click on Manage Data and then New Data Set and scroll down to AWS IoT Analytics and then select fillpercentage_dataset1.\n  The raw data set can be accessed via the CSV on the left-hand side and the file can be downloaded for use in Power BI or Tableau. Another option is to use a Python script similar to the one below -executed hourly, with a 30 minute offset \xe2\x80\x93 and download the CSV data sets from AWS IoT Analytics.\nThe script below gets the CSV data set fillpercentage_dataset1 and saves it as filetoimport.csv. It is also saved to your own S3 bucket.\n#!/usr/bin/python\n# -*- coding: latin_1 -*- \n\nimport awscli\nimport os\nimport sys\nimport urllib\nimport boto3\n\n# define where the aws cli command output will be stored\n# define the AWS IoT Anaytics data set\nfilename = \'foobar.txt\'\nawsiotdataset = \'fillpercentage_dataset1\'\ns3bucket = \'iotidcv\'\ns3filename =\'filetoimport_s3.csv\' \n\n# build the AWS CLI command to get the URL of the dataset\ncommand = \'aws iotanalytics get-dataset-content --dataset-name \' + awsiotdataset + \' > \' + filename\n\n# execute the command\nos.system(command)\n\n## utility functions for string manipulation\ndef left(s, amount):\n    return s[:amount]\n\ndef right(s, amount):\n    return s[-amount:]\n\ndef mid(s, offset, amount):\n    return s[offset:offset+amount]\n\n#################\n\n# function to save file to s3 bucket \ndef save_to_s3(bucket,filename, content):\n    client = boto3.client(\'s3\')\n    # can change the S3 key as you see fit\n    k = ""folder/subfolder/""+filename\n    client.put_object(Bucket=bucket, Key=k, Body=content)\n #############   \n\n# open file\nf = open(filename)\n\n# read in file lines\nlines = f.readlines()\n\n# get the second line of the AWS CLI command line file output - 0 is the first line\nlinewithurl = lines[1]\n\n# extract the pre-signed URL from the line\n# extract the pre-signed URL of the S3 bucket where the AWS IoT dataset is stored in AWS\n# url = linewithurl[-(len(linewithurl)-len(\'ENTRIES \')):]\n\n# extract the pre-signed URL of the S3 bucket where the dataset is stored\nurl = right(linewithurl, len(linewithurl)-len(\'ENTRIES \'))\n\n# open up the presigned url and download the file as a CSV called filetoimport.csv\ncsvfile = urllib.URLopener()\n\ncsvfile.retrieve(url, ""filetoimport.csv"")\n\n\n# optional, save the csv to your s3 bucket\n# just for confirmation, show the presigned URL\nprint(url) + \'\\n URL length: \' + str(len(url)) + \'. Total line length with URL in it is: \' + str(len(linewithurl)) + + \'. IoT Data Set saved as filetoimport.csv\'\n\n# uncomment the line below---------------------------to activate s3 save\n# change the name of the bucket to match yours at the top of the script\nsave_to_s3(s3bucket, s3filename, open(\'filetoimport.csv\',\'rb\'))\n\nprint(\'CSV file saved to S3 bucket name: \' + s3bucket + \', file name: folder/subfolder/\' + s3filename + \'.\')\n# ------------------------------------\nPython\nThe script above uses the aws cli, but you can easily change it to use the corresponding REST API, retrieve the JSON response, and access the URI (add import json as well as import requests at the top and retrieve the dataURI from the payload).\nclient = boto3.client(\'iotanalytics\')\n\nresponse = client.get_dataset_content(\n    datasetName=\'aws_iota_dataset\',\n    versionId=\'$LATEST_SUCCEEDED\'\n)    \n    \ndata = reponse.json()\nurl = data([0],[\'dataURI\'])\nBash\nOn the instance with Power BI installed I can now connect to the S3 bucket where the CSV is stored and use the get data menu and enter the URL of the S3 bucket and file name https://s3.amazonaws.com/iotidcv/folder/subfolder/filetoimport_s3.csv. I could also use the CSV file from my desktop.\nA screen similar to the one below is presented and I can begin creating a visualization in Power BI within minutes.\nThis is an example of a Power BI visualization that shows the tank fill percentage values by datetime and device id based on the CSV file generated by AWS IoT Analytics.\nThe example below displays a Power BI visualization filtered for a particular device and with a trend line.\nIn Tableau I download the file from the S3 bucket and connect to it. I get a screen similar to the one below.\nTableau also can be used to connect to Amazon Athena. https://www.tableau.com/about/blog/2017/5/connect-your-s3-data-amazon-athena-connector-tableau-103-71105\nAnd we can use the CSV data to create Tableau visualizations.\nHere is a time series visual example that zooms-in on a particular device data.\n  This blog explores how AWS IoT Analytics is used as an active iterative and interactive platform around which IoT solutions can be quickly prototyped, developed, deployed, and monitored. Hard dependencies on device telemetry are eliminated by using the IoT Device Simulator and business outcomes are visualized on a variety of reporting tools from Amazon QuickSight to Microsoft Power BI and Tableau.\nTo summarize, AWS IoT Analytics together with IoT Device Simulator can be used both strategically (planning, ideation, and data mappings) as well as tactically. From the early stages of IoT application development to production, it helps to not only visualize IoT generated data but also to identify the potential sensors and metrics associated with each device and this approach directly informs stakeholders on key business metrics. Clean data sets generated by AWS IoT Analytics can be quickly integrated with existing Jupyter notebooks (Python), BI dashboards, enterprise visualization tools, and operational reporting. In addition, clean IoT data sets can be directly used for developing and operationalizing machine learning models using Amazon SageMaker.'"
208,Use AWS IoT Device Defender to detect statistical anomalies and to visualize your device security metrics,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/use-aws-iot-device-defender-to-detect-statistical-anomalies-and-to-visualize-your-device-security-metrics/,"b'AWS IoT Device Defender supports your efforts to secure your IoT device fleet. AWS IoT Device Defender Detect establishes a baseline behavior for IoT devices and then identifies devices that do not conform as anomalous. AWS IoT Device Defender Detect operates on security profiles, which are applied to the entire device fleet, or to a thing group. From a security standpoint, security profiles specify your IoT device\xe2\x80\x99s expected behavior. We recommend that you group devices that are expected to behave similarly into a thing group. Next, you should configure behaviors and thresholds for AWS IoT Device Defender metrics generated by IoT devices and set up appropriate actions when a violation occurs.\nThe following new features help customers configure thresholds, analyze device behavior in production deployments, and investigate potential issues:\nDefender metrics visualization in the AWS management console makes it possible for you to view metrics generated by devices that belong to a security profile as statistical aggregations.\nConfigurable alerting means you can configure, per device, the number of consecutive violations after which an alert is triggered.\nStatistical anomaly detection lets you express thresholds in terms of percentiles calculated across metrics generated by all devices in the security profile. You can also express thresholds in terms of static values.\nIn this blog post, I will show you how to set up AWS IoT Device Defender Detect using a scenario of 10,000 ID card scanners installed at all ingress/egress points of factories located in multiple cities. I will also show how these new features in AWS IoT Device Defender Detect help me in the process.\nLet\xe2\x80\x99s review the process of setting up in this use case. These ID card scanners have the following characteristics:\nEvery time the device scans an ID card, it captures some data about the card.\nThese devices collect the ID card data over an hour and upload it to the server.\nThese devices communicate to the server through TCP connections.\nThreshold configuration\nIn this scenario, my objective is monitor the security of these ID card scanners and receive an alert if a security incident takes place.\nLet\xe2\x80\x99s start by breaking down a security incident. A malicious attacker (for example, someone behind a DDoS botnet or spam email campaign) must establish a communication channel to the IoT device, on which the malware and commands would be sent to the device.\nThe following are some metrics that can be captured that can help identify this security incident:\nRemote Address: An IP address communicating with the device. In addition to legitimate IP addresses, this metric will also contain the attacker\xe2\x80\x99s IP address.\nNumber of TCP connections: The number of connections between a server and the IoT device. In addition to legitimate communication between the server and the device, this metric will also contain the connection between the attacker and the device.\nIncoming bytes: The number of bytes received by the device. In addition to legitimate communication with the device, this metric will also include the number of bytes that correspond to malware and commands sent by the attacker.\nOutgoing bytes: The number of bytes sent from the device. In addition to the legitimate number of bytes sent by the device, this metric will also include the number of bytes sent to a server (DDoS) or user (spam email).\nFor the purpose of this demo, I will configure thresholds for the outgoing bytes metric, Bytes out.\nI will begin by creating a security profile for these ID card scanners and collecting the metrics I\xe2\x80\x99m interested in.\nOn the Expected behaviors page of the AWS IoT console, I enter a name and description for the security profile, and then choose Next.\nSetting up of behaviors used to be a required part of creating a security profile. Now you can simply choose to retain the metrics you are interested in and configure the thresholds later.\nFor the purpose of this demo, I will not set up any alert target in this security profile:\nNext, I will attach the security profile to the appropriate thing group (FactoryIDCardScanner_ThingGroup) and then choose Save.\nWhen the security profile confirmation page is displayed, the process is complete.\nLet\xe2\x80\x99s assume that I collect a sufficient amount of metrics from these ID card scanners. Now let\xe2\x80\x99s take a look at how the new features in AWS IoT Device Defender Detect help me configure appropriate thresholds for my security profile.\nDefender metrics\nThe Defender metrics allow me to visualize metrics generated by all devices in a security profile as statistical aggregations in the AWS IoT management console. This visualization appears on the dashboard for my security profile. Let\xe2\x80\x99s see the p0 (minimum value) and p100 (maximum value) values for the Bytes out metric. (Here \xe2\x80\x9cp\xe2\x80\x9d refers to percentiles.)\nNote: Data is available for visualization as soon as it is received by AWS IoT Device Defender. Data is stored for a rolling window of 14 days. Customers don\xe2\x80\x99t need to wait 14 days for visualizations to be populated.\nBy analyzing these graphs, I can make the following observations, which were unknown to me until now:\nBytes out varies between 0 to 17.5 kB.\nThere are peaks at 8 A.M. and at 8 P.M., which might simply indicate when people enter and leave the factory for the day.\nBecause there is variance in the metrics, it would be insufficient to say that Bytes out should be less than 17.5 kB (a static rule) because the baseline behavior for these devices is changing at each time interval. For situations like this, I would use statistical anomaly detection.\nStatistical anomaly detection\nTo configure the threshold to Every device in this security group should behave in a certain percentile of all devices in this security group, on the Expected behaviors page, under Check Type, I choose Statistical Threshold. Under Statistical Threshold, I choose a percentile value.\nThe following shows the threshold in the security profile was successfully updated.\nConfigurable alerting\nAnomalous behavior can be a result of a transient error, such as a temporary network outage. Alerts raised in response to such errors are false. To make anomaly detection more robust, I can configure AWS IoT Device Defender Detect to generate an alert only if a device has been in violation of the thresholds for a specified number of continuous time intervals.\nIt is important to emphasize that this configuration is a trade off between false and legitimate security alerts. For example, if the security incident were to last only for one time period, and if AWS IoT Device Defender Detect is configured to generate an alert only after two consecutive violations, the security incident will be missed and the appropriate alert action will not be taken.\nTo set up configurable alerting, on the Expected behaviors page, I would have to update values for the following:\nDatapoints to alarm. (An alarm occurs if a device is in violation of a behavior for this many consecutive datapoints.)\nDatapoints to clear. (An alarm is cleared if the device is no longer in violation of the behavior for this many consecutive datapoints.)\nWhen an alarm occurs, I want to investigate the behavior of the device. The following view is available on the Defender metrics for that device. It provides me with access to the raw values.\nNote: Metrics discussed in this blog post can only be observed from the device. To capture these metrics, customers must send them to AWS IoT Device Defender. (Sample implementation is provided here.)\nWrapping up\nIn this post, I\xe2\x80\x99ve shown you how to set up a security profile, attach it to a thing group, observe statistical aggregations, and use statistical anomaly detection. I\xe2\x80\x99ve also shown you how to tune the sensitivity of alerts using the configurable alerting feature.\nLearn more\nAWS IoT Device Defender at https://aws.amazon.com/iot-device-defender\nAWS IoT Device Defender documentation at https://docs.aws.amazon.com/iot/latest/developerguide/device-defender.html'"
209,Get Started with the IoT Foundation Series from AWS Training and Certification,b'Edouard Kachelmann',2019-04-23T21:48:15+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/get-started-with-the-iot-foundation-series/,"b'The IoT Foundation Series, a new curriculum dedicated to IoT on AWS, is now available online on the AWS Training and Certification website. This curriculum contains self-directed online training classes that are scenario-based and aligned with the library of IoT design patterns called the IoT Atlas and IoT best practices in AWS whitepapers.\nThis curriculum is recommended for business decision makers, data engineers, device engineers, fleet managers, line-of-business developers, and security architects who want to get started with IoT and find out which AWS services to use. By the end of this curriculum, you will be better prepared to dive into technical topics related to IoT.\nThe first two modules, Telemetry and Command & Control, help you sense the environment and act in the physical world. From there, you can work your way up to more complex scenarios like those in the Predictive Maintenance and Fleet Management courses. The information in these courses provides you with the knowledge and skills required to overcome business challenges using AWS IoT Core and associated services.\nStay tuned for more training on IoT! Don\xe2\x80\x99t forget to get started today!'"
210,Announcing the IoT Atlas,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/announcing-the-iot-atlas/,"b'Since announcing the availability of AWS IoT in 2015, our conversations with customers have made it clear that long-standing IoT design patterns from mature domains such as as sensor networks, control system architectures, and machine-to-machine networks had to be revised to include cloud development concepts. The IoT Atlas is a collection of IoT designs available in an easy to use, searchable website (https://iotatlas.net). It updates and expands on industry designs by assuming that a hyper-scale cloud is available to those who are building IoT solutions. The IoT Atlas is a resource for new and long-time solution builders alike.\nBecause the designs are cloud-service agnostic, the IoT Atlas is being published as a repository on GitHub. By publishing the content under a Creative Commons license, we hope to facilitate customer, field, and partner contributions of design ideas, considerations, and examples. We also hope to spark conversation and understanding about new IoT patterns in solutions.\nThe following designs are now available in the IoT Atlas:\nCommand: A requesting entity reliably asks a device to perform a single action, with acknowledgement of status.\nDevice Bootstrap: An unregistered device becomes registered and fully functional in an IoT solution.\nDevice State Replica: A logical representation of a physical device\xe2\x80\x99s reported state or desired future state.\nGateway: A device acts as an intermediary between local devices as well as devices and the cloud.\nSoftware Update: A device obtains new software, performs an update on itself, and confirms completion.\nTelemetry: Collect data from sensors in a remote environment and make the measurements available for use by other components of an IoT solution.\nTelemetry Archiving: A device\xe2\x80\x99s measurements are saved and made available for use in their original or processed form.\nFor example, historical telemetry-oriented solutions might obtain sensor data from on-premises devices and send that data using FTP, HTTP, or another mechanism to a self-managed server. The telemetry design in the IoT Atlas uses a managed, scalable, cloud-based IoT messaging protocol and protocol endpoint. For this reason, the original telemetry design benefits from a revision that includes a global, hyper-scale cloud.\nBecause this is day one for our publication of IoT designs, we would appreciate your help to make the IoT Atlas a rich and growing resource. Please read, review, comment, and take a moment to contribute your ideas and content for IoT designs, considerations, and examples. Together we can create maps that guide the industry toward successful IoT solutions.'"
211,Provision Devices Globally with AWS IoT,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/provision-devices-globally-with-aws-iot/,"b'Customers are building globally distributed IoT solutions with AWS IoT. A device that connects to AWS IoT must be provisioned in an AWS Region. However, when devices are shipped globally, you don\xe2\x80\x99t know in which AWS IoT Region the device will connect when it starts operation. In this blog post, I will describe a global AWS IoT device provisioning process.\nProvisioning an IoT device\nA device must be provisioned to work with AWS IoT Core. To provision a device:\nThe device should be created as a thing in the registry.\nIts X.509 certificate must be registered and associated with the thing.\nAn IoT policy must be attached to the certificate.\nTo connect to AWS IoT, the device must know the AWS IoT endpoint.\nGlobal device provisioning\nTo automate global device provisioning, I use an architecture built on Amazon API Gateway, AWS Lambda, AWS IoT Core, and Amazon DynamoDB. The device sends a provisioning request to an Amazon API Gateway endpoint. Amazon API Gateway calls an AWS Lambda function, which implements a method to find the best region for the device and then provisions the device in that region.\nYou\xe2\x80\x99ll find this sample implementation, documentation, and an AWS CloudFormation template at GitHub. The AWS CloudFormation template is provided to create the AWS resources for the sample implementation. For information about setting up the sample implementation and provisioning a device, see https://github.com/aws-samples/aws-iot-global-device-provisioning.\nIn this example, the best region is the one geographically closest to the device. To determine the closest region, you must determine the device\xe2\x80\x99s IP address and geolocation so the distance to the closest AWS Region can be calculated. If the geolocation cannot be retrieved, a default AWS Region is used.\nIn my implementation, I use ipstack.com to look up the geolocation for the device\xe2\x80\x99s IP address. To use the ipstack.com API, you need an API access key. Follow the sign-up steps at https://ipstack.com. The AWS Lambda function that determines the best region gets the API access key from an environment variable.\nUpon successful provisioning, the following are returned to the device:\nA private key (if the device does not already have a private key).\nA X.509 certificate.\nThe AWS IoT endpoint.\nTo secure the provisioning process, the device must sign the thing name and send the signature in the provisioning request to Amazon API Gateway. This approach is similar to the one used for custom authorizers in AWS IoT. Every device must be fitted with the private key for provisioning and the URL for the API gateway.\nAfter the signature is verified, a lookup in a DynamoDB table is performed. An \xe2\x80\x9cunprovisioned\xe2\x80\x9d status means that the device can be provisioned and the provisioning process will start.\nArchitecture\nProvisioning Process\nThe GitHub repository includes a program that is able to interact with the provisioning solution on the device. In addition to installing the program onto your device, you also need a private key and the URL for your API gateway.\nHere is the workflow for provisioning a device:\nThe device signs its thing name with a private key and sends a provisioning request to Amazon API Gateway. The device uses its own private key or uses a private key issued by AWS IoT Core. If the device uses its own private key, it provides a code-signing request (CSR) in the provisioning request. If \xe2\x80\x9cCSR\xe2\x80\x9d is not present in the request, AWS IoT creates the private key.\nSample provisioning request:\n{\'thing-name\': \'mydevice3\', \'thing-name-sig\': \'R725rxa+vnrMkvsydqS/lbZDDPzBTBXlKI5teO4OX1pKE9jRn/cUailOJczie2zMXUFUtO83sPr+HtRkjJQHDBrA2HDH87G21nMQdJT8K4RGHP6KRfpOhBYT7e162TnKc8DdUBh+Yh4T78dMePuaW4/PPkEbaRf6O7ieBZMITYmeETRDkkDwRD/jAcuEthmBSxRFw1YOzphw36atqS3+J0chc6lnAgCwbZhfPDI98HkLzgVaaXJlJ12ryXtyPA3D1Ptf+mUIci+DbharLsRCiaGsLrnCnoaL4y+vnD2LO0SwS05xhQtFI+0khq3pvGBMtw4HC/+AExI3I1jV3f9EBA==\'}\nAmazon API Gateway calls the AWS Lambda function\nThe AWS Lambda function performs the following steps:\nVerifies the signature for the thing name. If the verification fails, the Lambda function sends an error message and then terminates.\nDetermines if the device is a provisioning candidate by performing a lookup for the thing name in a DynamoDB table. The Lambda function checks if the prov_status attribute for the device (thing_name) is set to unprovisioned. If so, the device will be provisioned. If not, an error message will be returned. There are more sophisticated and secure ways to verify if a device should be provisioned (a token, for example). Similar to the approach for signing the thing name, tokens can also be signed by a key.\nSample entry in DynamoDB:\n{ ""thing_name"": { ""S"": ""mydevice3"" }, ""prov_status"": { ""S"": ""unprovisioned"" } }\nCalculates the best AWS Region for IoT. The calculation finds the shortest distance between the location of the device\xe2\x80\x99s IP address and an AWS Region.\nProvisions the device. That means the device will be created in the device registry. A certificate and, optionally, a key will be created. If one does not already exist, an IoT policy will be created, too.\nUpdates the DynamoDB table with the time and the region in which the device has been provisioned.\nReturns the answer, in JSON format. The answer contains the IoT endpoint, certificate, and private key, if no CSR was sent in the provisioning request.\nAfter receiving the response, the device stores the key, certificate and endpoint. The device is now ready to immediately interact with the AWS IoT Core.\n'"
212,Using AWS IoT Analytics to Prepare Data for QuickSight Time-Series Visualizations,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-aws-iot-analytics-to-prepare-data-for-quicksight-time-series-visualizations/,"b'Introduction\nVisualizing IoT data that can vary significantly over short periods of time (seconds) is important for several reasons: exploration and discovery of patterns, assessing trends and cyclicity, as well as observing potential correlations and anomalies. Insightful time-series visualizations can help identify anomalies, raise alerts based on these anomalies, and improve communication between various stakeholders, especially between data consumers and engineering.\nIn this blog post, I will show how to accomplish three common time-series analytics tasks:\nDemonstrate how to process raw IoT data using native AWS IoT Analytics capabilities;\nProvide examples of how to transform timestamp fields so that time-series data sets can be visualized easily;\nShowcase several visualizations of IoT time-series data using Amazon QuickSight;\nTo accomplish these goals, we will use a real-life use case and leverage an open source data set.\nIt is assumed that the reader has hands-on experience with AWS IoT Core and  AWS IoT Analytics platform as well as the QuickSight business analytics service. Throughout this blog post we will use the AWS Command Line Interface (CLI) and for the initial set up of the CLI on your device please follow these instructions. Additionally, the reader should be able to set up IAM credentials and know how to run a Python program to publish messages up to the IoT Core.\nIoT Data Set\nIoT Analytics can ingest data generated by IoT devices and sensors in both direct and batch modes. When using direct ingestion mode, the IoT Core rules engine immediately routes the payload to an IoT Analytics channel. In batch ingest mode, data can be ingested from a JSON repository, such as an Amazon S3 bucket.\nFor the purposes of this blog post we will batch a data set from from an open source provided by the city of Melbourne, Australia to AWS IoT Core and then on to an AWS IoT Analytics channel.\nThe city of Melbourne deployed environmental sensors in 2014, measuring light levels, humidity and temperature in two locations: Fitzroy Gardens and Docklands Library. The data collected was used to better understand and communicate the impact of canopy cover for urban cooling. Data was collected from sensor readings, with temperature, light, humidity every 5 minutes at 8 locations (a trial period during 2014 and 2015).\nWe will tap into the raw JSON data collected from the sensors. Here is a sample of a single JSON payload from one of the sensors installed in Docklands Library.\n{\n ""boardid"": ""509"",\n ""boardtype"": ""1"",\n ""humidity_avg"": ""47.7"",\n ""humidity_max"": ""47.7"",\n ""humidity_min"": ""47.7"",\n ""latitude"": ""-37.8199043"",\n ""light_avg"": ""93.7"",\n ""light_max"": ""93.7"",\n ""light_min"": ""93.7"",\n ""location"": ""Docklands Library"",\n ""longitude"": ""144.9404851"",\n ""mac"": ""0013a20040b31583"",\n ""model"": ""ENV"",\n ""rowid"": ""509-20141216210500"",\n ""temp_avg"": ""13.9"",\n ""temp_max"": ""13.9"",\n ""temp_min"": ""13.9"",\n ""timestamp"": ""2014-12-16T21:05:00.000""\n}\nJSON\nBy inspecting the payload, we can see that the timestamp generated by this particular sensor has an ISO 8601 format (day and time) and we know it is in the Australian/Perth time-zone.\nFor our demo purposes, we will be using the first 1,000 sample JSON messages generated from the sensors at both locations (Fitzroy Gardens and Docklands Library). All sample JSON messages used during our blog can be found at the following data location (you can right click and then Save As to save the data set on your device).\nHigh-Level AWS IoT Analytics Architecture\nThe JSON data will be sent to the AWS IoT Core on an MQTT topic and from there it will sent via the IoT rules engine to an AWS IoT channel. A pipeline with invoke a Lambda function that will transform the date-time into a different format and a data store will be created to store the data. Two data-sets will be created, one for each source location, and QuickSight visualizations will be created to represent time-series data.\nPublish raw JSON data to AWS IoT Core from the open source file;\nAdd to each JSON message payload the following, given the existing Australian ISO 8601 timestamp (e.g. 2014-12-16 21:05:00.000):\nUNIX epoch timestamp in UTC (1418677200);\nUSA Pacific time-zone ISO 8601 timestamp (12/15/2014 13:00:00.000);\nStore the JSON messages into a single AWS IoT Analytics datastore;\nCreate two AWS IoT Analytics data sets by querying the datastore and filtering the data based on the two sensor locations (Fitzroy Gardens and Docklands Library);\nPlease note that for production workloads you may need to consider by-passing the AWS IoT Core and publish the JSON payload data directly into an AWS IoT Analytics channel using the BatchPutMessage API.\nAWS IoT Data Ingestion, AWS IoT Analytics, and QuickSight Visualizations Steps\nCreate a Lambda function to enrich the original payload and add two additional time formats as specified above (UNIX epoch and US PT);\nCreate an IoT Analytics channel, a pipeline, and a data store;\nCreate two IoT Analytics data sets;\nUsing a Python script, ingest source data from the JSON file into IoT Core. This will trigger the rule to send the data to the IoT Analytics channel created at step 1;\nImport data sets and create time-series visualizations in QuickSight;\nStep 1\nCreate a Lambda function (Python 2.7) called transform_pipeline with the code below.\nimport time\nimport sys\nimport pytz\nimport datetime as DT\nfrom datetime import datetime\nfrom pytz import timezone\n\ndef lambda_handler(event, context):\n   for e in event:\n       if \'timestamp\' in e:\n           # Converting timestamp string to datetime object\n            d_aus_unaware = datetime.strptime(e[\'timestamp\'],\'%Y-%m-%dT%H:%M:%S.%f\')\n\n           # Adding Australia/Perth timezone to datetime object\n            timezone_aus = pytz.timezone(""Australia/Perth"")\n            d_aus_aware = timezone_aus.localize(d_aus_unaware)\n\n           # Determining UTC epoch timestamp from input Australian timestamp\n            d_utc = d_aus_aware.astimezone(timezone(\'UTC\'))\n            epoch = time.mktime(d_utc.timetuple())\n\n           # Determining PST timestamp from input Australian timestamp\n            d_uspst = d_aus_aware.astimezone(timezone(\'US/Pacific\'))\n\n           # Adding Epoch and PST timestamp to message payload\n            e[\'timestamp_aus\'] = d_aus_aware.strftime(\'%m/%d/%Y %T\')\n            e[\'timestamp_us\'] = d_uspst.strftime(\'%m/%d/%Y %T\')\n            e[\'epoch\'] = epoch\n\n   return event\nPython\nThe function above (transform_pipeline) uses the pytz library which has to be imported as a package. For more information on how to do this, please visit the AWS Lambda Deployment Package in Python page.\nWe use the CLI to give IoT Analytics permission to call the above Lambda function. Please note that the statement-id is a unique statement identifier as documented here.\naws lambda add-permission --function-name transform_pipeline --statement-id stat_id_100 --principal iotanalytics.amazonaws.com --action lambda:InvokeFunction\nBash\nStep 2\nTo create an IoT Analytics channel, a pipeline, and a data store, log on to the AWS console and follow the instructions that can be found here. Alternatively, you may elect to use a CloudFormation template to create IoT Analytics resources.\nA channel is used to ingest data from IoT Core or an S3 bucket and feed a pipeline while keeping a copy of the raw messages for a selected period of time (or indefinitely).\nFor our use case, a single channel is created to store all incoming and unprocessed raw JSON messages and will be named mychannel_aus_weather. Using the IoT Analytics console, create the channel named mychannel_aus_weather. When prompted for an IoT Core topic, use iot/aus_weather and it will create a rule in IoT Core for you that passes messages into this channel. You can have the console create the IAM role needed there as well.\nA pipeline is used to filter, enrich, and transform the incoming JSON payloads. The pipeline name is mypipeline_aus_weather. Create a pipeline where the data source is the channel mychannel_aus_weather. In Step 1 of this blog, you created a Lambda function named transform_pipeline. Add one Lambda activity to your pipeline and select this function from the list.\nAt the end of the pipeline creation flow, you can create your data store and then select it for the output of the pipeline. A data store is used to store data after it has been processed via pipelines. We will create a single data store for the purpose of our blog and will name it mydatastore_aus_weather.\nStep 3\nLet\xe2\x80\x99s use the CLI to create the data sets from our data store. Alternatively, you can use the console and create the data set interactively.\nDocklands Library Data Set\naws iotanalytics create-dataset --dataset-name=""aus_weather_docklands_library"" --cli-input-json file://dataset_docklands.json\nBash\nWhere the input is found in the following JSON file.\n{\n  ""actions"" :[{\n    ""actionName"":""myaction1"",\n    ""queryAction"":{\n      ""sqlQuery"":""select * from mydatastore_aus_weather where location = \'Docklands Library\' order by timestamp_aus""\n                  }\n             }]\n}\nJSON\nFitzroy Gardens Data Set\naws iotanalytics create-dataset --dataset-name=""aus_weather_fitzroy_gardens"" --cli-input-json file://dataset_fitzroy.json\nBash\nWith the corresponding JSON file.\n{\n  ""actions"" :[{\n    ""actionName"":""myaction2"",\n    ""queryAction"":{\n      ""sqlQuery"":""select * from mydatastore_aus_weather where location = \'Fitzroy Gardens\' order by timestamp_aus""\n                  }\n             }]\n}\nJSON\nPlease observe that timestamp_aus is an attribute that did not exist on the original data set. It was added by our Lambda function to each JSON payload. The order by statement was also added so that we can plot the data sequentially against this attribute in QuickSight.\nStep 4\nThe previous steps have been used to set up the data ingestion, transformation, and structures for visualizations but we have no data yet. In this step, we will ingest the data from the open source data set to IoT Core.\nWe download from the open source data set the 1,000 data records programmatically.\ncurl -XPORT \'https://data.melbourne.vic.gov.au/resource/277b-wacc.json\' > input_aus.json\nBash\nBefore we can pipe the data from the open source data set to the IoT Core we need to set up the CLI. Instructions for installing and configuring the CLI for Windows or OS can be found here.\nDuring configuration, you will be asked to enter the AWS Access Key and the AWS Secret Access Key associated with your AWS user ID. To obtain the access keys, navigate to the AWS console and, in the search bar, search for IAM (Identity Access Management), then select users, click on your user name, and, under security credentials, select Create Access Key and make sure to copy and save the secret access key.\nWe write a Python function to ingest the data into IoT Core and name it upload_raw_aus.py.\nimport json\nimport boto3\nimport fileinput\nimport multiprocessing as mp\nimport os\n\nprocesses = 4\n\n# An array of boto3 IoT clients\nIotBoto3Client = [boto3.client(\'iot-data\') for i in range(processes)]\n\ndef publish_wrapper(lineID, line):\n    # Select the appropriate boto3 client based on lineID\n    client = IotBoto3Client[lineID % 4]\n\n    line_read = line.strip()\n    print ""Publish: "", os.getpid(), lineID, line_read[:70], ""...""\n    payload = json.loads(line_read)\n\n    # Publish JSON data to AWS IoT\n    client.publish(\n        topic=\'iot/aus_weather\',\n        qos=1,\n        payload=json.dumps(payload))\n\nif __name__ == \'__main__\':\n    pool = mp.Pool(processes)\n    jobs = []\n    print ""Begin Data Ingestion""\n    for ID, line in enumerate(fileinput.input()):\n       # Create job for each JSON object\n       res = jobs.append(pool.apply_async(publish_wrapper, (ID, line)))\n\n    for job in jobs:\n       job.get()\n\n    print ""Data Ingested Successfully""\nPython\nBefore running the Python script above we need to install jq. If you have a Windows machine, please see the download instructions here.\nsudo yum install jq\nBash\nWe can now use the CLI to invoke the function above and pass it the file downloaded programmatically with the curl command.\ncat input_aus.json | jq -c \'.[]\' | python upload_raw_aus.py\nBash\nThe Python script uses four processes to ingest data in parallel. Four IoT boto3 clients are created and the job of publishing each raw JSON message is distributed among them in a round-robin fashion. Notice that the MQTT topic iot/aus_weather, is the same topic we used to create the topic rule, during step 2, for our channel subscription.\nAfter the execution of the cat script above we have two data sets ready to be consumed by our QuickSight visualizations.\nStep 5\nAWS IoT Analytics Transformed Data Sets Used for Visualizations:\naus_weather_docklands_library: contains IoT data for Docklands Library\naus_weather_fitzroy_gardens: contains IoT data for Fitzroy Gardens\nAt this point, we open QuickSight and begin designing and creating time-series visualizations.\nOn QuickSight, click on New analysis, followed by New data set.\nNext, click on AWS IoT Analytics.  In our QuickSight analysis, we have to add both data sets (aus_weather_docklands_library and aus_weather_fitzroy_gardens). For now, choose any one of them and select Create data source. Repeat the above steps for aus_weather_fitzroy_gardens. We can now visualize each data set separately or together.\nIn this blog, we will visualize them together. Click on one data set. For this blog, we will us the \xe2\x80\x98aus_weather_docklands_library\xe2\x80\x98. Click on Create analysis.\nThe QuickSight visualization screen will appear. Let\xe2\x80\x99s now add the other data set into our analysis (aus_weather_fitzroy_gardens). Click on the aus_weather_docklands_library data set. A pop block will appear in which if we click on Edit analysis data sets, we will have the option to add another data set. Add the aus_weather_fitzroy_gardens data set as shown in the diagrams below.\nWe can now see both data sets imported into our analysis.\nOur analysis has all the data we need, and we can start to develop our visualizations. Let us first plot humidity_avg, light_avg and temp_avg v/s epoch for Docklands Library. Click on the aus_weather_docklands_library set. Select the line plot from the graph options in the lower left-hand corner. Above the graph drag the epoch field to the X axis and the humidity_avg, light_avg, temp_avg fields to the Value column.\nFor each value field, select the aggregate type as average (default is sum).\nWe now have a visualization that depicts the variation of humidity, temperature, and light over time. The blue window below the graph can be scrolled or expanded to analyze the visual at different time-intervals. We can also change the graph title by simply clicking and editing it.\nNow, we can repeat the steps to visualize the data for Fitzroy Gardens as well. At the top left corner, click on the + button and select Add visual. A new blank visual is created below the existing visual graph. Select the aus_weather_fitzroy_gardens data set and we can now create the graph in the same manner as we created for aus_weather_docklands_library. The diagram below shows the final result.\nThe final result should look like below.\nBoth visualizations use the Epoch time format for the time horizontal) axis and we need to change that to use an ISO 8601 format. We have already added a timestamp_aus column that shows time in mm/dd/yyyy HH:MM:SS format. By default, QuickSight treats it as a date format. If we try to plot our data (humidity, light and temperature) versus this column in date format, we see the following visualization.\nUnfortunately, the unit of measurement on the X axis is a day. Since we have sample data points at minute granularity, this is not an accurate representation of our IoT data. In order to get the precision we have at the data label, we need the date in a string format vs. the normal date format.\nWe accomplish this by taking the following steps.\nChanging the format of the timestamp_aus field from date to string.\nEnsuring the data is lexically sorted by the timestamp_aus column. We have taken care of this step when we created our data set query. Our query contains order by timestamp_aus to sort the data appropriately when the data set is created from the datastore (\nselect * from mydatastore_aus_weather where location = \'Fitzroy Gardens\' order by timestamp_aus\nJSON\n).\nTo accomplish step 1, click on the data set name (aus_weather_docklands_library) and click Edit analysis data sets. Next to aus_weather_docklands_library, click Edit. We can now edit any column as needed. Click on the column timestamp_aus and change its data format to string.\nWe will repeat this process for aus_weather_fitzroy_gardens data set. We can now plot the graph in the same way as we plotted with UNIX epoch timestamp. For X axis, we can use timestamp_aus instead of epoch. Our graphs will be the same as epoch timestamps but the X axis now shows timestamps in ISO 8601.\nIn QuickSight, we have a feature to create new data fields (columns) from existing ones. For example, we could change our plot above to represent the data for each day and month. If we observe the visuals above, we see that the sample points expand over 2 days (12/14/2014, 12/15/2014).\nWe can divide each plot into 2, based on the day by creating new calculated fields. Given that our timestamp_aus field has value in the string format \xe2\x80\x98MM/DD/YYYY HH:MM:SS\xe2\x80\x99, substring starting at character 12 and spanning over 5 characters will give us the hour and minute (HH:MM). Substring at character 1 and spanning over 10 characters will gives us the date (MM/DD/YYYY). We can extract these and create two new fields: HH:MM and MM/DD/YYYY.\nClick on the data set name (aus_weather_docklands_library) and click Edit analysis data sets. Next to aus_weather_docklands_library, click Edit. On the left-hand corner, click on the Fields tab and then click New Field.\nFirst, we will be creating a new field that takes out the hour and minute from the timestamp_aus field. For this, we will use the substring() provided by QuickSight. For more information on QuickSight functions, visit the QuickSight Functions Supported page. Click substring and type the name of the new field as HH:MM. Refer to the diagrams below. Repeat the same process to obtain the day and month into a new calculated field called MM/DD/YYYY.\nClick on Save and Visualize at the top. We are now ready to create our plot. For simplicity, let us only plot humidity_avg. Select the line plot, drag HH:MM on the X axis, humidity_avg on the Value and MM/DD/YYYY on the Color column. The visual below is created and shows 2 line plots of humidity_avg, one for each day. Repeat the above steps for aus_weather_fitzroy_gardens data set.\nFinal Result for Docklands Library\nFinal Result for Fitzroy Gardens\nQuickSight also helps us locate the sensors on a location map if we know the location coordinates (latitude, longitude). Our data sets includes these attributes. Click on the global icon on the bottom left hand corner and click on the latitude and longitude columns.\nWe now have a QuickSight analysis which consist of stories. We have shown how to 2 stories (showing timeseries data and geospatial location of sensors). Let\xe2\x80\x99s rename our analysis. At the top our analysis name is given by default to be aus_weather_docklands_library. We can change that to something like \xe2\x80\x98Melbourne Weather Analysis\xe2\x80\x99. The analysis becomes accessible anytime on the new analysis page.\nVisualizing data helps to improve communication between stakeholders and increase collaboration. QuickSight provides a useful snapshot tool, called dashboard, for sharing visuals with stakeholders. The dashboard tool serves as an important mechanism for capturing a visual and saving its state. It allows us to share the visual with other active users. Let\xe2\x80\x99s create a dashboard for our analysis and share it with another QuickSight user. On the right-hand corner, click on share and then click on Create dashboard.\nOn the Create a dashboard page, type in the name we want to give to our dashboard (Melbourne IoT Weather Analysis) and then click Create dashboard.\nOn the next page, type in the username or email address of the user we want to share the dashboard with. Note that the user must have a QuickSight account registered already. The picture below shows us typing a fictitious user called Pat. If the username/email is valid, we can click Share. If sharing is not required, we can click Cancel. On the next page, we can allow users to create their own analysis by clicking Can create analyses next to the user. Click on Close. After that on the next page, Choose Confirm to confirm that we grant the users access to the data.\nUsers are sent an email with a link to the shared dashboard.\n  '"
213,Introducing AWS CloudFormation support for AWS IoT Analytics,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/introducing-aws-cloudformation-support-for-aws-iot-analytics/,"b'AWS CloudFormation support for AWS IoT Analytics resources was launched on December 18th, 2018. In this blog post, we introduce conventions for building IoT Analytics projects using CloudFormation and provide an array of sample templates to help you get started.\nAs a refresher, every AWS IoT Analytics project has three required resources for data ingestion, and one or more optional resources for analyzing or visualizing your data. On the data ingestion side, each project will have a minimum of a channel, pipeline, and data store. Channels receive and store raw IoT messages from AWS IoT Core or via the BatchPutMessage API (for existing data stored prior to IoT Analytics). MQTT messages received by a channel are processed by any connected pipelines, where those messages can be enriched, cleansed, filtered, and generally transformed to fit your analysis. Finally, messages processed by the pipeline are kept in a data store for later analyses.\nOn the analysis side, your projects will use one or more data sets to query data out of your data store. Think of this as a materialized view, or subset of the data store to be analyzed. The most basic query for a data set\xe2\x80\x93although not recommended to be performed on very large data stores\xe2\x80\x93is \xe2\x80\x9cselect * from my_data_store\xe2\x80\x9d which fetches the entire contents of the data store and caches it as a CSV file for you. This content can then be utilized by a hosted Jupyter Notebook for machine learning, executed by a container application in Elastic Container Service, or imported into Amazon QuickSight for visualization and analytical exploration.\nTemplates for ingestion patterns\nWe\xe2\x80\x99ll first start with three CloudFormation templates that initialize patterns for ingesting data to IoT Analytics projects. The first pattern is a basic \xe2\x80\x9cdata workflow,\xe2\x80\x9d where a distinct channel, pipeline, and data store are created as a linked group. The concept for this pattern is that all the data in this project is similar, should be processed by the same pipeline for transformations, and stored in the same data store. It also includes a single data set that queries the data store on a daily basis, fetching the previous 24-hour chunk of records.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nThe second pattern represents a fan-in model, where multiple pairs of channels and pipelines feed into a single data store. This is useful for merging dissimilar data schema, or when data retention needs are unique for each channel. In the following example template, there are two channels, two pipelines to normalize the data from their respective channels, one data store and one data set. The first channel is assumed to receive messages with a temperature measurement as \xe2\x80\x9ctemp\xe2\x80\x9d and units of Fahrenheit. It has a data retention policy for 30 days. The second channel is assumed to receive messages with a temperature measurement as \xe2\x80\x9ct\xe2\x80\x9d and units of Centigrade. It has a data retention policy of 7 days. The pipelines convert either \xe2\x80\x9ctemp\xe2\x80\x9d or \xe2\x80\x9ct\xe2\x80\x9d to the attribute \xe2\x80\x9ctemperature\xe2\x80\x9d and normalize output as Centigrade. The data set in this example scans every fifteen minutes for records above and below the liquid temperatures of water.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nThe third pattern represents a fan-out analytics model, where a single channel of raw data is processed by multiple pipelines and stored in multiple data sets. This is common when the same input data is used for disparate analyses. This represents a convention for supplying data consumers (such as business analysts or data scientists) their own customized copies of the data on which to work. In the following example template, there is a single channel, two pipelines, and two data stores. Each pipeline receives messages from the same channel, but has different functions for processing the messages and stores them in separate data stores.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nTemplates for analytical patterns\nIf you\xe2\x80\x99re integrating your IoT Analytics project with an Amazon SageMaker notebook instance for machine learning use cases, this next template will create an end-to-end project. It includes the provisioning of a SageMaker instance that is compatible with our plugin for building containerized versions of your notebook for use in our \xe2\x80\x9ccontainer data set\xe2\x80\x9d feature. This template is handy for creating a full project that handles all the authorization details of setting up IoT Analytics with SageMaker. Note, once this project is configured, you\xe2\x80\x99ll still need to create an actual notebook using the IoT Analytics console. You can start with a blank notebook, or use any one of our templates to jump-start your journey into machine learning with IoT data.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nAlready have your own containerized application in Elastic Container Service? This next template builds an end-to-end project where your container will be executed on a schedule you provide. This is useful when you already have a container image, perhaps one provided by a community resource or colleague, which is not already deployed in your AWS account or specific region.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nIf you have your own container and want to execute it when an IoT Analytics data set triggers creation of new content (instead of on a scheduled timer like the previous example), check out this next template.\nDownload template \xe2\x80\x94 Launch template in CloudFormation\nWe hope you will value the time savings of using CloudFormation to start or advance your next IoT Analytics project. If you have any questions or want to share a template you created, please visit our forum.'"
214,Machine Learning at the Edge: Using and Retraining Image Classification Models with AWS IoT Greengrass (Part 2),b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2018/11/30/cover_image-1024x768.jpg,https://aws.amazon.com/blogs/iot/machine-learning-at-the-edge-using-and-retraining-image-classification-models-with-aws-iot-greengrass-part-2/,"b'In part 1 of this blog post, we created an image classification model for a recycling facility\xe2\x80\x99s sorter to identify four beverage containers. We deployed it to our AWS IoT Greengrass Core device using the new AWS IoT Greengrass Image Classification connector. AWS IoT Greengrass connectors, announced at this year\xe2\x80\x99s re:Invent, make it possible for IoT Greengrass Core devices to connect to third-party applications, on-premises software, and AWS services without writing code.\nAt the end of part 1, we noticed that our beverage container predictions weren\xe2\x80\x99t always correct or consistently of high confidence. In part 2, we will extend our application to upload images breaching a threshold for prediction confidence, label those images, and retrain and deploy our model back to our IoT Greengrass Core device.\nNote: The information in this blog post is heavily dependent on part 1. If you haven\xe2\x80\x99t already done so, complete the steps in part 1 before you proceed.\nOverview\nIn this post, we will extend the beverage classifier Lambda function we created in part 1 by adding an additional step in the code to check the prediction confidence of captured images. Images whose prediction confidence falls below a minimum or above a maximum threshold will be uploaded to Amazon S3 where they can be labeled manually for use in future Amazon SageMaker model training jobs. That is, our Amazon SageMaker notebook will download these newly labeled images, combine them with the original Caltech 256 data set, and create a new model with the combination of new and original data. Finally, we will update the model in our IoT Greengrass group connector and redeploy to our Core device.\nAt the end of part 2, we will have an architecture like the one shown here. You\xe2\x80\x99ll see that numbers are used to show the sequence of the flow for retraining the model.\nPrerequisites\nTo access Amazon S3 from our Lambda function we will use the AWS SDK for Python (Boto3). Run the following command to install it on your Raspberry Pi:\n$ sudo pip install boto3\nExtending and testing the application\nTo upload our images to S3, we need to give our Core device permission to access our S3 bucket.\nConfigure S3 permissions\nOn the group\xe2\x80\x99s setting page in the AWS IoT console, make a note of the value in Group Role. If a role isn\xe2\x80\x99t already configured for your group, see Configure IAM Roles in the AWS IoT Greengrass Developer Guide.\nTo grant the group access to S3, we need to use the IAM console to add the AmazonS3FullAccess policy to its role. In the IAM console, choose Roles. Find and choose the role you identified for your IoT Greengrass group. On the summary page, choose Attach policies.\nSearch for AmazonS3FullAccess, select the check box, and then choose Attach policy.\nPerform a deployment to your group. Your group will now have permission to read and write to S3.\nFor information about interacting with other AWS services, see Module 6: Accessing AWS Cloud Services in the AWS IoT Greengrass Developer Guide.\nExtend the beverage classifier Lambda function\nIn this step, we will extend the beverage container classifier Lambda function. The new code integrates with S3. It provides logic for when to upload images to be labeled and used as new training data. We want to upload images that fall:\nAbove a high threshold, to be used as data to validate our less confident predictions.\nBelow a low threshold, to be tagged and incorporated into our dataset.\nUpdate your beverage classifier Lambda function with the code found on GitHub.\nCreate a new deployment.\nCollect data in the field\nThe beverage classifier can now collect data in the field and upload it to S3 for manual labeling. You should now see the following in the image-classification folder in your S3 bucket:\nTake some time to use the updated application. Try to collect images for each of the five categories. During our testing, we collected 50 additional images per category. We took pictures of a variety of objects in each class and at different angles to capture a broad set of test data. Remember, you can classify images and view results on the Test page of the AWS IoT console by publishing to the /request/classify/beverage_container topic and subscribing to the /response/prediction/beverage_container topic as we did in part 1.\nHere are some of the images we captured:\n\n\nLabel field data\nTo label the data, we need to review the images in the raw_field_data folder in your S3 bucket and move them to their respective category folders in the labeled_field_data folder. We recommend that you use the AWS CLI to do this.\nSync your S3 bucket to a folder on your desktop:\naws s3 sync s3://[S3 Bucket]/image-classification/raw_field_data [local raw field data dir]\naws s3 sync s3://[s3 Bucket]/image-classification/labeled_field_data [local labeled field data dir]\nGo through the images in your local raw_field_data folder. Review each image and move them to their respective folders in your local labeled_field_data folder:\nAfter labeling, run the following commands to update S3. This will move the unlabeled images to their correctly labeled folders.\naws s3 sync [local raw field data dir]  s3://[S3 Bucket]/image-classification/raw_field_data\naws s3 sync [local labeled field data dir] s3://[s3 Bucket]/image-classification/labeled_field_data\nRetrain your model\nWe now have new labeled data that can be used to retrain our model. Return to the Amazon SageMaker notebook we used in part 1 (copied from our notebook here). Follow the steps in the notebook, and return here when you have reached the end.\nNote: You can rerun part 2 of the notebook any time you add training data. Doing so will create a new model that you can deploy to your Core device.\nRedeploy your model\nWe now have a retrained model that we can deploy. Return to your IoT Greengrass group and edit the machine learning resource you created in part 1. In the drop-down menu for Amazon SageMaker training jobs, choose your new training job. Choose Save, and then create a deployment. When the deployment is complete, your new model will be used by the Lambda function.\nTest your new model\nNow that our new model has been deployed, we can test to see how it performs. In our testing, we saw an improvement in our model\xe2\x80\x99s ability to consistently identify our test objects. Give it a try and see how your model performs.\nFor more information about measuring a model\xe2\x80\x99s performance, see the Amazon SageMaker image classification sample notebooks.\nRecap\nIn parts 1 and 2 of this post, we created an AWS IoT Greengrass application that used the new AWS IoT Greengrass Image Classification connector to identify several categories of beverage containers. We extended this application in part 2 to allow us to collect data in the field and retrain the model we created in part 1.\nWe look forward to seeing what you build! Keep an eye out for what\xe2\x80\x99s in store next from AWS IoT Greengrass.\nThings to try next\nIf you would like to continue playing around with the example in this post, here are some ideas that you can try next. For information about how to retrain and improve your model, see the Amazon SageMaker Image Classification documentation.\nYou might also want to try:\nUsing Amazon SageMaker Ground Truth.\nAdding a new class to your model.\nExperimenting with training parameters in the Amazon SageMaker notebook to improve your model\xe2\x80\x99s accuracy.\nUpdating the training configuration in the AmazonSageMaker notebook to use iterative training. See Image Classification Algorithm in the Amazon SageMaker Developer Guide.\nAdding a buffering mechanism to store captured images when the Core device is offline and upload to S3 when connectivity to the cloud is restored.\nTo learn more, visit https://aws.amazon.com/greengrass/.'"
215,Real-time metrics with AWS IoT Analytics and Amazon CloudWatch,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/real-time-metrics-with-aws-iot-analytics-and-amazon-cloudwatch/,"b'A question frequently asked by our customers in relation to our AWS IoT Analytics offering, is how to achieve a real-time dashboard of data flowing through IoT Analytics. In this blog, I\xe2\x80\x99ll show you one pattern for achieving real-time metrics by utilizing Amazon CloudWatch and the AWS Lambda activity of a pipeline.\nI\xe2\x80\x99ve simulated 25 smart pump devices that send messages continuously as I use them with IoT Device Simulator, a solution that that enables you to create and simulate hundreds of virtual connected devices, without having to configure and manage physical devices or develop time-consuming scripts. These smart pumps report the temperature, humidity, pressure, and vibration data. Messages from these devices flow into my Amazon S3 bucket. I\xe2\x80\x99d like to visualize the data flowing through these smart pumps in real-time to find any anomalous or alarming patterns so that I can proactively repair these devices.\nIoT Analytics helps me build a dashboard and analytical workflow that I can set up in minutes to visualize the data from my smart pumps. I use the BatchPutMessage API of IoT Analytics to send these stored messages to a channel. Messages flow from the channel into the pipeline, where they are processed. After processing, the pipeline sends messages to the data store. The pipeline is the key to getting my near real-time metrics.\nFirst I look at the attributes sent by my devices in the pipeline as it infers the message attributes from my channel.\nPipeline inferring my smart pump messages\n  Now the first step is to create a Lambda function that routes data to Amazon CloudWatch, where we will build our dashboard. In this example, I\xe2\x80\x99ve named the Lambda function metrics_to_cloudwatch. Once the Lambda function is created, it can be added to our pipeline as an activity.\nThe Lambda activity in IoT Analytics\nLet\xe2\x80\x99s take a closer look at how this Lambda function works. As it pertains to the pipeline, this Lambda simply returns the messages it receives so they can continue to be processed.\nimport json\nimport boto3\n \ncloudwatch = boto3.client(\'cloudwatch\')\n \n# You can change these payload attributes based on your device message schema\nATTRIBUTES = [""temperature"", ""pressure"", ""vibration"", ""humidity""]\n# The payload attribute which represents your device identifier\nDEVICE_ID_ATTRIBUTE = ""_id_""\n# You can change this namespace name per your device and preferences\nCLOUDWATCH_NAMESPACE = ""SmartPump/Monitoring""\n \n# Publish metric data to CloudWatch\ndef cw(deviceId, metricValue, metricName):\n    metric_data = {\n        \'MetricName\': metricName,\n        \'Dimensions\': [{\'Name\': \'DeviceId\', \'Value\': deviceId}],\n        \'Unit\': \'None\', \n        \'Value\': metricValue\n    }\n \n    cloudwatch.put_metric_data(MetricData=[metric_data],Namespace=CLOUDWATCH_NAMESPACE) \n    return\n\n# The handler loops through all the messages and evaluates if the message\n#  has attributes for pressure, humidity, vibration or temperature.\n#  These are the attributes that I want to graph in near real-time in\n#  this example. If the attribute exists in the message, we call the cw() \n#  function to emit the custom metric to Amazon CloudWatch.\ndef lambda_handler(event, context):\n    for e in event:\n        print(""Received a message: {}"".format(str(e)))\n        # Validate this event payload contains a device ID\n        if DEVICE_ID_ATTRIBUTE in e:\n            # Iterate through each attribute we want to publish to CloudWatch\n            for attribute in ATTRIBUTES:\n                # Validate the event payload contains the current attribute\n                if attribute in e:\n                    print(""publishing {} to CloudWatch"".format(attribute))\n                    cw(e[DEVICE_ID_ATTRIBUTE],e[attribute], attribute)\n \n    return event\nPython\n  Hopefully the code is self-explanatory, but in essence what happens is that the Lambda function in a pipeline is passed an array of messages, with the size of the array dependent on the batch size that you configure for the activity. The default of 1 means that the Lambda function will be invoked for each individual message, which is fine for scenarios where messages only arrive in the channel every few seconds. When you have a high frequency of incoming messages (every millisecond for example) or when BatchPutMessage API puts multiple messages into the channel at a time, you might want to set the batch size greater than 1 to consolidate Lambda execution.\nAn important permission step is that you need to make sure you have granted the Lambda function permission to access Amazon CloudWatch.\nLambda function can send messages to Amazon CloudWatch\nYou also must make sure that you have granted IoT Analytics permission to invoke your Lambda function, and you can do this with the following AWS CLI command:\naws lambda add-permission --function-name metrics_to_cloudwatch --statement-id \nmetrics_to_cloudwatch_perms --principal iotanalytics.amazonaws.com --action \nlambda:InvokeFunction\nBash\nIf you forget this, and you have configured your logging options (see the Setting up CloudWatch Logs documentation), you\xe2\x80\x99ll see error messages like this for your Amazon CloudWatch log stream \xe2\x80\x9caws/iotanalytics/pipelines\xe2\x80\x9d.\n[ERROR] Unable to execute Lambda function due to insufficient permissions; dropping \nthe messages, number of messages dropped : 1, functionArn : arn:aws:lambda:us-west-2:\n<accountid>:function:metrics_to_cloudwatch\nBash\nThat\xe2\x80\x99s it! We can now use the dashboarding features of Amazon CloudWatch to plot our custom metrics on graphs and dashboards with fine-grained time resolution. For example, this is my dashboard of my data at 30-second intervals:\nExample real-time metrics from the IoT Analytics Pipeline showing in Amazon CloudWatch\nUsing this real-time dashboard, I created a CloudWatch Alarm for high temperatures on my smart pumps. This alarm notifies me when the temperature value exceeds an acceptable threshold:\nExample alarm from Amazon CloudWatch\nIn conclusion, we\xe2\x80\x99ve seen how we can leverage the Lambda activity that is available in the AWS IoT Analytics pipeline to route the message attributes we want to a near real-time dashboard in AWS CloudWatch, and trigger alarms when needed.\nHappy dashboarding!'"
216,Machine Learning at the Edge: Using and Retraining Image Classification Models with AWS IoT Greengrass (Part 1),b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2018/11/30/cover_image-1024x768.jpg,https://aws.amazon.com/blogs/iot/machine-learning-at-the-edge-using-and-retraining-image-classification-models-with-aws-iot-greengrass-part-1/,"b'With the introduction of the AWS IoT Greengrass Image Classification connector at this year\xe2\x80\x99s re:Invent, it has become easier than ever to use image classification at the edge through AWS IoT Greengrass. Because it is software that lives on a local device, AWS IoT Greengrass makes it possible to analyze data closer to the source (a sensor, etc). Using AWS IoT Greengrass connectors, AWS IoT Greengrass Core devices can connect to third-party applications, on-premises software, and AWS services without writing code. The AWS IoT Greengrass Image Classification connector gives an AWS IoT Greengrass Core device the ability to classify an image into one of multiple categories (for example, categorizing microchips in a factory as defective/not defective, classifying types of inventory, or determining the kind of dog you\xe2\x80\x99re following on Instagram). This prediction is referred to as an inference. Together, image classification and AWS IoT Greengrass make it possible for you to perform inference even when a device is disconnected from the cloud!\nBehind the scenes, the AWS IoT Greengrass Image Classification connector uses a machine learning model that has been trained using the image classification algorithm in Amazon SageMaker. By deploying the connector, all of the Lambda functions and machine learning libraries (MXNet) required to make a prediction are pulled down and configured on an AWS IoT Greengrass Core device automatically.\nIn these two posts, we will walk through an end-to-end example of creating an application that uses image classification. In part 1, we will create a new image classification model in Amazon SageMaker and get you up and running with the AWS IoT Greengrass Image Classification connector. In part 2, we will collect data in the field, retrain our model, and observe changes in our inference results.\nWhat we\xe2\x80\x99re building\nWe\xe2\x80\x99ll be tackling a real world problem that can be addressed through the use of image classification: sorting beverage containers in a recycling facility. We will train our model to identify whether an image contains a beer mug, wine bottle, coffee mug, or soda can. We will also include a clutter category in case the image does not belong to one of these classes.\nFirst, we will build our image classification model using the Caltech 256 dataset. Then, we will create an AWS IoT Greengrass Image Classification connector and interact with it through a Lambda function dedicated to classifying beverage containers. At the end of part 1, we will have the following architecture:\nPrerequisites\nTo follow along with the instructions in this post, you will need:\nRaspberry Pi 3 Model B\nRaspberry Pi Camera Module V2 \xe2\x80\x93 8 Megapixel, 1080p\nMake sure that you have a Greengrass group deployed to your Raspberry Pi that is running AWS IoT Greengrass Core v1.7.0. Make sure that your Greengrass group has an IAM group role with, at minimum, the AWSGreengrassResourceAccessRolePolicy and AWSGreengrassFullAccess policies attached. You can do this by opening the AWS IoT console and choosing Settings. For information about setting up a device with AWS IoT Greengrass, visit Getting Started with AWS IoT Greengrass in the AWS IoT Greengrass Developer Guide.\nTo use the IoT Greengrass Image Classification connector, we need to install required dependencies for MXNet, the machine learning library we use for image classification. Follow the installation script outlined for ARMv7 in the Image Classification connector documentation.\nNote: To install the dependencies on a Raspberry Pi, you must increase the swap file size. We recommend setting the size to 1000. This installation can take up to one hour.\nFinally, per the troubleshooting section of the Image Classification connector documentation, run the following command to prevent a Raspberry Pi/opencv-specific issue from occurring during deployments:\n$ sudo ln /dev/null /dev/raw1394\nIf you have trouble performing these steps, see the troubleshooting section in the AWS IoT Greengrass documentation.\nBuilding and testing the application\nWe will start by creating a Lambda function that can take pictures using the Pi camera and make predictions using an image classification model.\nCreate a Lambda function\nCreate a Lambda function. Download beverageclassifier.py from GitHub into a new directory and then download and unzip the AWS IoT Greengrass Machine Learning SDK into the same location. Compress the directory into a .zip file and use it to create a Lambda function in the AWS Lambda console. We called our Lambda function beverage_classifier. In the AWS IoT console, add this Lambda function to your group and configure it as a long-lived Lambda function with a memory limit of 128 MB and timeout of 10 seconds, as shown in the following screenshot. For more information about creating and packaging Lambda functions, see Create and Package a Lambda Function in the AWS IoT Greengrass Developer Guide.\nRun the following command on your Raspberry Pi to install the AWS IoT Greengrass Core SDK:\n$ pip install greengrasssdk\nTo use the Pi camera, we need to set up the Raspberry Pi and some local resources. Follow the steps in Configure the Rasberry Pi and Add Resources to the Greengrass Group sections of the AWS IoT Greengrass Developer Guide.\nNotice that interaction with the Image Classification connector occurs through the AWS IoT Greengrass Machine Learning SDK.\nCreate a model\nWe will use Amazon SageMaker to create and train our image classification model. In the Amazon SageMaker console, create a notebook using the sample we have provided on GitHub.\nFollow the notebook\xe2\x80\x99s instructions for part 1. Upon completion, you will have an Amazon SageMaker training job that can be used to configure an Image Classification connector.\nConfigure an Image Classification connector\nNow that we have a training job, we can set up our connector. Deploying the connector to our Core device will make our image classification model ready to be used locally by the Lambda function we created in the previous step.\nBegin by creating a machine learning resource in your Greengrass group. You can find your group in the Greengrass group page of the AWS IoT console. On the page, under Resources, choose the Machine Learning tab, and then choose Add a machine learning resource. Use the values in following screenshot to complete the fields. For SageMaker model, be sure to choose the Amazon SageMaker model we created in the previous step.\nChoose Save and create a deployment.\nNow we\xe2\x80\x99re ready to create a connector. Navigate to your Greengrass group, choose the Connectors tab, and then choose Add a connector. We will be deploying this connector to a Raspberry Pi, so on Select a connector, choose the Image Classification ARMv7 connector.\nOn the next page, we will configure some parameters for our connector. Choose the machine learning resource you created in the previous step. For Local inference service name, enter beverage-classifier. This name will be used in our Lambda code when we call the connector through the AWS IoT Greengrass Machine Learning SDK. Use the values in this screenshot to configure the rest of your connector\xe2\x80\x99s parameters.\nChoose Add and then create a new deployment. Our Lambda function can now access our image classification model!\nIf you have trouble with any of these steps, see the troubleshooting section of the Image Classification connector documentation.\nConfigure subscriptions\nNow that our connector and Lambda function are set up, let\xe2\x80\x99s create a way to interact with our application. Using the Test page in the AWS IoT console, we will configure subscriptions between the AWS Cloud and the beverage_classifier Lambda function so that we can trigger the device to capture images and view our inference results in the console. In practice, any MQTT message can trigger the beverage_classifier Lambda function. We use the AWS IoT console to trigger events for this example because it offers easy debugging feedback, but there are other ways to trigger these events. In a production environment, you might instead send these MQTT events from other devices or Lambda functions. (It\xe2\x80\x99s possible to send messages between devices and a Greengrass Core device even when the Core device is disconnected from the cloud!) Depending on your use case, AWS IoT Jobs offer another way to interact with your Greengrass Core device.\nIn the AWS IoT console, configure the following subscriptions for your group:\nAWS IoT Cloud (source) to beverage_classifier Lambda (target) on /request/classify/beverage_container (topic). Messages on this topic will trigger the Lambda code.\nbeverage_classifier Lambda (source) to AWS IoT Cloud (source) on /response/prediction/beverage_container (topic). These messages will appear in the AWS IoT console and report predictions.\nSet up local resources\nConfigure a volume resource for the local directory where we will store the images we capture:\nBefore we deploy, we need to create the /home/ggc_user/raw_field_data directory on the device. We also need to give read and write permissions to ggc_user:\n$ sudo mkdir -p /home/ggc_user/raw_field_data\n$ sudo chown -R ggc_user:ggc_group /home/ggc_user/raw_field_data/\nYou can alternatively give permission to your own user ID/group ID by setting the Run as field in the beverage classifier AWS IoT Greengrass Lambda function configuration. For more information, see Controlling Execution of Greengrass Lambda Functions by Using Group-Specific Configuration in the AWS IoT Greengrass Developer Guide.\nCreate a deployment.\nTest\nNow that everything is set up, we can test our beverage container classifier. In the AWS IoT console, choose Test, and subscribe to topic /response/prediction/beverage_container. Publishing to the topic /request/classify/beverage_container will capture and classify an image! Place a coffee mug, beer mug, wine bottle, or soda can in front of your Pi camera and choose Publish to topic. Your Core device will capture an image, make a prediction, and emit the result back to the AWS IoT console:\n'"
217,AWS IoT Analytics Oil and Gas Customer Use Case,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-analytics-oil-and-gas-customer-use-case/,"b'Our oil and gas customer wanted to deploy AWS IoT Analytics to help them:\n Better understand their assets in the field (for example, pumps, generators, valve assemblies, and so on).\n Derive actionable insights from their data.\n Build a predictive maintenance solution to help reduce their costs.\nBy using IoT Analytics, our customer can:\nPre-process the IoT data coming from their field assets.\nEnrich that data with various internal and external data sources.\nProvide a time-series optimized data store.\nEmpower their in-house data science team to build and train machine learning models on top of data sets derived from the data store.\nBusiness and technical challenges\nAmong the challenges our customer faced, the first was the inability to access their IoT data. Other business units in the enterprise owned and controlled the assets in the field. Although many had IoT data, they could not let that data leave their on-premises environment. To prove the value of pushing IoT data to the cloud, our customer used some connected assets and had data flow through an AWS IoT Greengrass core, which is software that lets you run local compute and data caching for connected devices. From the IoT Greengrass core, the data was sent to the cloud to AWS IoT Core and then ingested by IoT Analytics.\n  The second challenge was technical in nature and common when building IoT solutions: how to handle massive volumes of data. Our customer needed a large dataset generated from their connected assets so that they could be confident that IoT Analytics could handle volumes of streamed data moving from IoT Core through IoT Greengrass. Because time was also of the essence, our customer used historical IoT data and loaded it directly into IoT Analytics. This made it possible for the data science team to build and test their anomaly-detection models on years of data generated by assets owned by various business units. This also allowed our customer to iterate on the IoT Analytics pipeline preprocessing and enrichment steps on a large amount of data. This approach ensured our customer was getting the desired output from the pipeline process and then storing that output in their data store before having a live stream of IoT data feeding the service. It provided confidence in the pipeline output and the data schema of the data store.\nWhy did our customer choose AWS IoT Analytics?\nOur customer chose AWS IoT Analytics for a couple of key reasons:\nThe robust IoT ecosystem of services provided by AWS, including IoT Greengrass, IoT Core, and IoT Analytics.\nThe integration of IoT Analytics and Amazon SageMaker. Our customer wanted the ability to build analytics models and deploy them at the edge through IoT Greengrass ML inference.\nThis is arguably the most compelling reason for our customer. Now, they can derive immediate value from data sitting in storage for years and bypass the long process of connecting IoT assets to the cloud, an effort that can take up to 18 months due to various security, compliance, and privacy requirements.\nWhat has our customer learned?\nToday, our customer is exploring machine learning models through our Jupyter Notebook templates. They can quickly modify the template to meet their use cases and then build and test it against their historical IoT data they can load directly in IoT Analytics. They can quickly validate their hypothesis and derive great value just from their historical IoT data. They have even gotten other business units engaged and excited about what is possible with AWS IoT Analytics. Lastly, our customer learned how challenging it can be to get IoT data from connected assets in the field and then stream that data to the cloud.\nTo reduce risk, our customer took a parallel approach to the project, showing value from their IoT data early on through IoT Analytics while prototyping an IoT device connectivity solution using IoT Greengrass. Through these efforts, they have rallied more support from the business, can access IoT data for analytics, and can scale with their growing volumes of data.\nExpected technical and business benefits\nOur customer\xe2\x80\x99s goals were to validate their hypothesis that IoT data, with proper analysis, provides meaningful value to the enterprise. They also wanted to create a prototype that provides the other business units with a blueprint for connecting devices to the AWS Cloud, unlocking IoT device data from assets in the field, and moving that data to IoT Analytics for analysis.\nIn the near future, our customer plans to test their anomaly-detection models in IoT Analytics and deploy them at the edge using IoT Greengrass ML inference. This is for use cases where even milliseconds are not fast enough. A round-trip to the cloud and back yields too much latency or is not assured due to connectivity challenges.'"
218,Using Bluetooth Low Energy with Amazon FreeRTOS on Espressif ESP32,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-bluetooth-low-energy-with-amazon-freertos-on-espressif-esp32/,"b'Today Amazon Web Services (AWS) announced the beta of Amazon FreeRTOS BLE, a feature that makes it possible for embedded developers to securely connect Amazon FreeRTOS devices that use Bluetooth Low Energy (BLE) to AWS IoT through Android or iOS devices. BLE support in Amazon FreeRTOS lets developers create new applications for devices that need lower power than any other forms of connectivity, including Wi-Fi.\nWith BLE support in Amazon FreeRTOS, developers can use the standard Generic Access Profile (GAP) and Generic Attributes (GATT) profiles through a universal API layer to create BLE applications that are portable across any Amazon FreeRTOS-qualified device and use companion Android and iOS SDKs to integrate with AWS IoT functionality. According to the BLE specifications, GAP defines how BLE devices broadcast availability and communicate with each other. GATT describes how data is transferred once a connection is established.\nGetting Started with Amazon FreeRTOS BLE\nIn this post, I provide a use case of a BLE device connecting to AWS IoT through an Android proxy. This allows the BLE device to use the same MQTT protocol, agnostic to the underlying communication carrier of either BLE or Wi-Fi. Because BLE offers lower power compared to Wi-Fi, devices can use the MQTT protocol to connect to AWS IoT services over BLE. This brings the best of low power and rich AWS IoT services, such as Amazon FreeRTOS over-the-air updates, to the devices in the field.\nConnecting Espressif ESP32 to AWS IoT via BLE with Amazon FreeRTOS BLE\nAt the start of the cycle after reset, ESP32 is in advertising mode and uses the GAP layer to broadcast data out to nearby BLE devices. One of the nearby BLE devices is an Android app which, when started, is in scanning mode. Advertising mode is a one-to-many transfer and offers no guarantees about data coherence.\nIn the Android app it will scan for devices that match the name or address of the ESP32, and once the connect switch is toggled, both ESP32 and the Android app will enter into connected mode. BLE device will expose a custom GATT profile to allow the client to behave as a proxy and access AWS IoT services from the AWS cloud. During the authentication process the BLE device uses the AWS Cloud service certificate to securely wrap a challenge directed to the cloud service through the un-authenticated client. The challenge contains information about the BLE device and the client to be authenticated. If the challenge is satisfied, then the BLE device may grant the authenticated client proxy the ability to access AWS IoT services on behalf of the device. Data packets are delivered to the BLE device through a custom GATT profile.\nThese are the high level steps to connect a ESP32 to AWS IoT using the BLE proxy running on an Android phone:\nAWS configuration \xe2\x80\x93 Create AWS IoT thing and policy, create a Cognito user pool and configure Cognito identity\nESP32 \xe2\x80\x93 Download, configure and run the Amazon FreeRTOS BLE on the ESP32\nBLE pass-through app \xe2\x80\x93 Download, configure and run the Amazon FreeRTOS example MQTT proxy app on an Android phone\nPrerequisite\nESP32 development board\nMicroUSB to USB A cable\nAWS account (Free Tier is sufficient)\nSufficient disk space (~500Mb) for the Xtensa toolchain and Amazon FreeRTOS source code and examples. This post is written with the assumption that Xtensa toolchain, ESP-IDF, and Amazon FreeRTOS code is installed in the esp directory in the user\xe2\x80\x99s home directory, ~/esp. You must add ~/esp/xtensa-esp32-elf/bin to your $PATH variable.\nAn Android phone with Android 4.3 or later.\nAndroid Studio with Android 4.3 or later (API Level 18 or later) SDK installed.\nYou can find information about the setup of the ESP32 hardware and build instructions in the Connect Microcontroller-Based Devices to the Cloud with Amazon FreeRTOS and Espressif ESP32 blog post written by my colleague, Anton Shmagin.\nAWS Configuration\nAWS IoT configuration\nFirst, I set up the AWS IoT thing and policy. Because I am using the MQTT proxy on my Android phone, which will be authenticated using Amazon Cognito, my ESP32 device does not need the AWS IoT certificates.\nStep 1 \xe2\x80\x93 Create an AWS IoT Policy\nBefore you create the AWS IoT Policy, you need to know your AWS region and AWS account number.\nSign in to the https://console.aws.amazon.com/iot/.\nFrom the upper-right corner of the AWS Management Console, choose My Account. Under Account Settings, make a note of the 12-digit account ID.\nBrowse to the AWS IoT console.\nBrowse to the AWS IoT Core console.\nFrom the left navigation pane, choose Settings. In Custom endpoint, make a note of the endpoint value.\nThe endpoint should be something like \xe2\x80\x9cxxxxxxxxxxxxxx.iot.us-west-2.amazonaws.com\xe2\x80\x9d, in this case, the AWS region will be us-west-2.\nFrom the left navigation pane, choose Secure, choose Policies, and then choose Create.\nIf you do not have any policy created in your account, you will see the message \xe2\x80\x9cYou don\xe2\x80\x99t have any policies yet\xe2\x80\x9d is displayed. Choose Create a policy.\nEnter a name for your policy (for example, esp32_mqtt_proxy_iot_policy).\nIn the Add statements section, choose Advanced mode. Copy and paste the following JSON into the policy editor window. Replace the aws-account-id with your account ID (step 2). Replace aws-region with us-west-2 (step 4).\nChoose Create.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Connect"",\n      ""Resource"": ""arn:aws:iot:<aws-region>:<aws-account-id>:*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:<aws-region>:<aws-account-id>:*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Subscribe"",\n      ""Resource"": ""arn:aws:iot:<aws-region>:<aws-account-id>:*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Receive"",\n      ""Resource"": ""arn:aws:iot:<aws-region>:<aws-account-id>:*""\n    }\n  ]\n}\nJSON\nStep 2 \xe2\x80\x93 Create an AWS IoT Thing\nTo create an AWS IoT thing:\nSign in to the https://console.aws.amazon.com/iot/.\nFrom the left navigation pane, choose Manage, and then choose Thing. From the top-right corner, choose Create.\nIf you do not have any IoT things registered in your account, the message \xe2\x80\x9cYou don\xe2\x80\x99t have any things yet\xe2\x80\x9d is displayed. Choose Register a thing.\nOn the Creating AWS IoT things page, choose Create a single thing.\nOn the Add your device to the thing registry page, enter a name for your thing (for example, esp32-ble). Only alphanumeric, hyphen (\xe2\x80\x9c-\xe2\x80\x9c) and underscored (\xe2\x80\x9c_\xe2\x80\x9d) are allowed. Choose Next.\nOn the Add a certificate for your thing page, under Skip certificate and create thing, choose Create thing without certificate.\nBecause I am using the BLE proxy mobile app that uses an Amazon Cognito credential for authentication and authorization, no device certificate is required.\nAWS Cognito Configuration\nAmazon Cognito is required for authentication of the MQTT proxy mobile app. An IAM policy is attached to the authenticated identity to allow the principal to attach the AWS IoT policy to the credential.\nStep 1 \xe2\x80\x93 AWS Cognito user pool\nSign in to the Amazon Cognito console at https://console.aws.amazon.com/cognito/users/.\nFrom the right top navigation banner, choose Create a user pool.\nEnter the pool name (for example, esp32_mqtt_proxy_user_pool.\nChoose Review defaults.\nIn the App Clients, click Add app client, and then choose Add an app client.\nEnter a app client name (for example mqtt_app_client).\nMake sure the Generate client secret is selected.\nChoose Create app client.\nChoose Return to pool details.\nOn the Review page of the user pool, choose Create pool.\nYou should see a message that says \xe2\x80\x9cYour user pool was created successfully.\xe2\x80\x9d\nMake a note of the pool ID.\nIn the navigation pane, choose App clients.\nClick Show Details.\nMake a note of the app client ID and the app client secret.\nStep 2 \xe2\x80\x93 Create An AMAZON Cognito Identity Pool\nSign in to the Amazon Cognito console at https://console.aws.amazon.com/cognito/federated\nChoose Create new identity pool.\nEnter a name for the identity pool (for example, mqtt_proxy_identity_pool).\nExpand Authentication providers.\nChoose the Cognito tab.\nEnter the user pool ID and app client ID from the previous step.\nChoose Create Pool.\nOn the next page, choose Allow to create new roles for authenticated and unauthenticated identities.\nMake note of the Identity pool ID, which is in the format of us-east-1:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\nStep 3 \xe2\x80\x93 Attach IAM policy to the authenticated identity\nAttach an IAM policy to the authenticated identity so that the credential can attach the IoT policy to it.\nOpen the Amazon Cognito console at https://console.aws.amazon.com/cognito/federated\nChoose the identity pool that you just created (in my example, mqtt_proxy_identity_pool).\nChoose Edit identity pool.\nMake note of the IAM Role assigned to the Authenticated role (for example, Cognito_mqtt_proxy_identity_poolAuth_Role).\nOpen the IAM console at https://console.aws.amazon.com/iam/home\nIn the navigation pane, choose Roles.\nSearch for the role (in my example,Cognito_mqtt_proxy_identity_poolAuth_Role), and then choose it.\nChoose Add inline policy, and then choose JSON.\nEnter the following policy:\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": [\n   {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n         ""iot:AttachPolicy"",\n         ""iot:AttachPrincipalPolicy"",\n         ""iot:Connect"",\n         ""iot:Publish"",\n         ""iot:Subscribe""\n      ],\n      ""Resource"": ""*""\n   }]\n}\nJSON\nChoose Review Policy\nEnter a policy name (for example, mqttProxyCognitoPolicy)\nChoose Create policy\nSetting up ESP32 with Amazon FreeRTOS BLE\nHardware Setup\nFor this post, I use the ESP32-DevKitC V4 developed by Espressif.\nMake sure that drivers for the board are installed. If you are installing the driver for Silicon Labs CP2104 on macOS High Sierra, you might need to restart installation after you whitelist the installation package in System Preferences > Security & Privacy.\nConnect the ESP32 development board\nThe UART to USB should appear as follows.\nOn Windows the driver would enumerate the port as COMx:\nOn macOS:\n$ ls /dev/tty.S*\n/dev/tty.SLAB_USBtoUART\nBash\nOn Linux:\n$ ls /dev/ttyUSB* /dev/ttyUSB0\nBash\nDownload instructions for Amazon FreeRTOS BLE for ESP32\nClone the Amazon FreeRTOS from GitHub repository at https://github.com/aws/amazon-freertos . The branch is feature/ble-beta\n$ cd ~/esp \n$ git clone -b feature/ble-beta --single-branch https://github.com/aws/amazon-freertos\nBash\nSet your baud rate and serial port. The example Makefile for respective hardware is in amazon-freertos-library-share/demos/<manufacturer>/<hardware kit name>/make/.\nFor Espressif ESP32 it is in amazon-freertos-library-share/demos/espressif/esp32_devkitc_esp_wrover_kit/make/\n$ cd ~/esp/amazon-freertos-library-share/demos/espressif/esp32_devkitc_esp_wrover_kit/make\n$ make menuconfig\nBash\n\nSave the configuration\nConfigure Amazon FreeRTOS\nOpen amazon-freertos-library-share/demos/espressif/esp32_devkitc_esp_wrover_kit/common/application_code/main.c. Make note of the mainBLE_DEVICE_NAME. You will need it for the Android app to match the BLE name (for example, ESP32).\nOpen ~esp/amazon-freertos-library-share/demos/common/include/aws_clientcredential.h\nChange the following:\nclientcredentialMQTT_BROKER_ENDPOINT to the AWS IoT Endpoint\nclientcredentialIOT_THING_NAME to the AWS IoT Thing you created earlier (in my example, esp32-ble).\nCompile and Flash the Amazon FreeRTOS onto the ESP32\nFlash the program to ESP32\n$ make flash monitor\nBash\nIf the program is successfully flashed, you should see this in your terminal\nI (719) wifi: Init dynamic tx buffer num: 32\nI (719) wifi: Init data frame dynamic rx buffer num: 32\nI (719) wifi: Init management frame dynamic rx buffer num: 32\nI (729) wifi: Init static rx buffer size: 1600\nI (729) wifi: Init static rx buffer num: 10\nI (739) wifi: Init dynamic rx buffer num: 32\n0 49 [Btc_task] Started advertisement. Listening for a BLE Connection.\nBash\nDownload, configure and run the example Android app for MQTT Proxy\nClone the example Amazon FreeRTOS MQTT proxy app for Android from the GitHub repository at https://github.com/aws/amazon-freertos-ble-android-sdk\n$ cd ~/android\n$ git clone https://github.com/aws/amazon-freertos-ble-android-sdk\nBash\nChoose Open an existing Android Studio project to open the project from Android Studio\nNavigate to and open ~/android/amazon-freertos-ble-android-sdk\nOpen amazonfreertossdk/src/main/java/com/amazon/aws/amazonfreertossdk/AmazonFreeRTOSManager.java and edit TEMPORARY_IOT_ENDPOINT to use the AWS IoT endpoint\nOpen app/src/main/java/com/amazon/aws/freertosandroid/AuthenticatorActivity.java and edit the following:\nFor AWS_IOT_POLICY_NAME, use the name of the IoT Policy (in my example, esp32_mqtt_proxy_iot_policy).\nForCOGNITO_POOL_ID, use the pool ID\nForAWS_REGION, use the region of the AWS services\nOpen app/src/main/java/com/amazon/aws/freertosandroid/MainActivity.java and edit ESP_NAME.\nIn our example, the ESP_NAME is ESP32\nOpen app/src/main/res/raw/awsconfiguration.json, and edit the file\n{\n  ""UserAgent"": ""MobileHub/1.0"",\n  ""Version"": ""1.0"",\n  ""CredentialsProvider"": {\n    ""CognitoIdentity"": {\n      ""Default"": {\n        ""PoolId"": ""<Cognito Identity Pool ID, e.g. us-east-2:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx>"",\n        ""Region"": ""<AWS region, e.g. us-east-2>""\n      }\n    }\n  },\n  ""IdentityManager"": {\n    ""Default"": {}\n  },\n  ""CognitoUserPool"": {\n    ""Default"": {\n      ""PoolId"": ""<Cognito user pool ID, such as us-east-2_0000XXXXX>"",\n      ""AppClientId"": ""<Cognito user pool app client ID>"",\n      ""AppClientSecret"": ""<Cognito user pool app client secret>"",\n      ""Region"": ""<AWS region, e.g. us-east-2>""\n    }\n  }\n}\nJSON\nConnect your Android phone to your computer.\nGoto Run \xe2\x86\x92 Run \xe2\x80\x98app\xe2\x80\x99.\nIn Select Deployment Target, choose the phone in Connected Devices and choose OK.\nMQTT Proxy\nRegistration and login\nIf the Android app compiles and launches successfully on your Android phone, you should see the following sign-in screen:\nChoose Create New Account. Enter your email address and password to create an Amazon Cognito user.\nAmazon Cognito will send a confirmation code to your email address.\nOn the next screen, enter the confirmation code sent to your email address.\nRun the MQTT proxy\nChoose Scan to scan for nearby BLE devices\nAfter a device that matches the ESP_ADDR or ESP_NAME is found, the Connect switch is enabled.\nToggle the Connect switch\nAfter the Android app is connected to the ESP32, you should be able to see these messages in the ESP32 terminal. You can ignore the MQTT error for now, because you activate the MQTT proxy next.\n2 16681 [Btc_task] BLE Connected to remote device, connId = 0\n3 16682 [Tmr Svc] Creating MQTT Echo Task...\n4 16682 [MQTTEcho] MQTT echo attempting to connect to a1jgguqwhae8ke-ats.iot.us-east-2.amazonaws.com.\n5 16682 [MQTTEcho] Sending command to MQTT task.\n6 16683 [MQTT] Received message 10000 from queue.\n7 16683 [MQTT] Failed to send notification, mqtt proxy state:1 \n8 16683 [MQTT] Failed to send CONNECT message, sent = 0\n9 16683 [MQTT] MQTT_Connect failed!\nBash\nChoose Discover to discover and register all GATT services from the esp32.\nChoose Set MTU to increase the default MTU from 20 to 500.\nToggle the MQTT Proxy switch to enable the MQTT proxy.\nAfter the MQTT proxy is enabled, you should see these messages in the ESP32 terminal:\n65 4316 [MQTTEcho] MQTT echo attempting to connect to a1jgguqwhae8ke-ats.iot.us-east-2.amazonaws.com.\n66 4316 [MQTTEcho] Sending command to MQTT task.\n67 4316 [MQTT] Received message 70000 from queue.\n68 4446 [Btc_task] MQTT Connect was accepted. Connection established.\n69 4446 [Btc_task] Notifying task.\n70 4446 [MQTTEcho] Command sent to MQTT task passed.\n71 4446 [MQTTEcho] MQTT echo connected.\n72 4446 [MQTTEcho] Sending command to MQTT task.\n73 4446 [MQTT] Received message 80000 from queue.\n74 4558 [Btc_task] MQTT Subscribe was accepted. Subscribed.\n75 4558 [Btc_task] Notifying task.\n76 4558 [MQTTEcho] Command sent to MQTT task passed.\n77 4558 [MQTTEcho] MQTT Echo demo subscribed to freertos/demos/echo\n78 4558 [MQTTEcho] Sending command to MQTT task.\n79 4559 [MQTT] Received message 90000 from queue.\n80 4582 [Btc_task] MQTT Publish was successful.\n81 4582 [Btc_task] Notifying task.\n82 4583 [MQTTEcho] Command sent to MQTT task passed.\n83 4583 [MQTTEcho] Echo successfully published \'Hello World 0\'\n84 4593 [Echoing] Sending command to MQTT task.\n85 4593 [MQTT] Received message a0000 from queue.\n86 4617 [Btc_task] MQTT Publish was successful.\n87 4617 [Btc_task] Notifying task.\n88 4617 [Echoing] Command sent to MQTT task passed.\n89 4619 [Echoing] Message returned with ACK: \'Hello World 0 ACK\'\nBash\nAndroid Studio output\nIf you have Android Studio connected to your phone, you can filter the messages in the Logcat by choosing Show only selected application.\n2018-11-09 11 (tel:2018110911):50:31.398 26628-26643/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: Characteristic changed for: MQTT_TX with data: {""type"":3,""topic"":""ZnJlZXJ0b3MvZGVtb3MvZWNobw=="",""qoS"":1,""msgID"":272,""payloadVal"":""SGVsbG8gV29ybGQgNDI=""}\n2018-11-09 11 (tel:2018110911):50:31.405 26628-26643/com.amazon.aws.freertosandroid I/AmazonFreeRTOSManager: Received Mqtt Message type : 3\n2018-11-09 11 (tel:2018110911):50:31.419 26628-26643/com.amazon.aws.freertosandroid I/AmazonFreeRTOSManager: Sending mqtt message to IoT on topic: freertos/demos/echo message: Hello World 42\n2018-11-09 11 (tel:2018110911):50:31.524 26628-29470/com.amazon.aws.freertosandroid I/AWSIotMqttManager: delivery is complete\n2018-11-09 11 (tel:2018110911):50:31.524 26628-29470/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: Publish msg delivery status: Success\n2018-11-09 11 (tel:2018110911):50:31.524 26628-29470/com.amazon.aws.freertosandroid I/AmazonFreeRTOSManager: Sending PUB ACK back to device.\n2018-11-09 11 (tel:2018110911):50:31.532 26628-29470/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: Processing BLE command: WRITE_CHARACTERISTIC queue size: 0\n2018-11-09 11 (tel:2018110911):50:31.534 26628-29470/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: Writing to characteristic: MQTT_RX with data: {""msgID"":272,""type"":4}\n2018-11-09 11 (tel:2018110911):50:31.634 26628-26643/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: onCharacteristicWrite for: MQTT_RX; status: Success\n2018-11-09 11 (tel:2018110911):50:31.634 26628-26643/com.amazon.aws.freertosandroid D/AmazonFreeRTOSManager: There\'s no ble command in the queue.\nBash\nMonitor the MQTT messages in AWS IoT MQTT client\nYou can monitor the MQTT messages are being received in AWS IoT using the MQTT test client\nSign in to the AWS IoT console at https://console.aws.amazon.com/iot\nIn the navigation pane, choose Test.\nSubscribe to the freertos/demos/echo.\nYou should be able to see the MQTT messages in the AWS IoT console.\n'"
219,AWS IoT Device Tester for Amazon FreeRTOS and AWS IoT Device Tester for AWS Greengrass,b'Brett Francis',2019-02-13T22:02:03+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-device-tester/,"b'AWS IoT Device Tester is now available. AWS IoT Device Tester is a Windows/Linux/macOS test automation application that enables silicon vendors and OEMs to easily perform qualification testing to determine if their devices can run Amazon FreeRTOS or AWS IoT Greengrass and interoperate with AWS IoT services. AWS IoT Device Tester produces a test report that serves as qualification evidence for silicon vendors and OEMs who want to list their devices on the AWS Partner Device Catalog. There are two versions of AWS IoT Device Tester: AWS IoT Device Tester for Amazon FreeRTOS and AWS IoT Device Tester for AWS IoT Greengrass. In this blog post, I discuss both versions.\nAWS IoT Device Tester for Amazon FreeRTOS\nAmazon FreeRTOS provides connectivity and security libraries that make it possible for embedded developers, silicon vendors, and OEMs to develop easily cloud-enabled microcontroller-based devices like fitness trackers, sensors, smart power meters, and the like. Because these devices come with different connectivity (Wi-Fi, Ethernet, BLE) and security capabilities (for example, Secure Element), embedded developers implement device-specific Amazon FreeRTOS libraries. To confirm that their implementation is correct, embedded developers perform qualification tests, which are time-consuming and cumbersome. They have to manually run tests that involve modifying the source code to configure test case parameters, compiling and flashing of the test cases onto the microcontroller for execution. In addition, they have to learn about AWS IoT Core and set up cloud resources to perform end-to-end testing.\nWith AWS IoT Device Tester for Amazon FreeRTOS, it is easier for embedded developers to test if Amazon FreeRTOS works on their devices. AWS IoT Device Tester automatically executes the right set of tests based on device capabilities and then aggregates and stores the results on the computer where it is running. AWS IoT Device Tester for Amazon FreeRTOS also sets up the AWS resources required for end-to-end tests (such as MQTT, OTA) and automates compiling and flashing of test cases to the microcontroller by integrating with the microcontroller\xe2\x80\x99s development toolchain.\nAWS IoT Device Tester for Amazon FreeRTOS in action\nTo show you how AWS IoT Device Tester works, I will pretend to be an embedded developer and use it to test the STM32L4 Discovery Kit IoT Node. The capabilities of this kit include Wi-Fi connectivity and TCP/TLS processing. The embedded developers at STMicroelectronics saved the day by implementing the required Amazon FreeRTOS libraries (Wi-Fi and TLS/TCP) and making it available on the GitHub for anyone to use. (Other silicon vendors with qualified devices have their libraries in GitHub, too.) All I have to do now is to use AWS IoT Device Tester to test their implementation. My faithful Windows laptop works as my embedded development machine. It is connected to the STM32L4 kit through a USB cable.\n I downloaded Amazon FreeRTOS from GitHub to my laptop. It has all the required libraries, including the qualification tests. To get started, I simply downloaded Device Tester from here to my laptop. I then extracted the downloaded zip to the devicetester_afreertos_win folder and configured Device Tester to test the attached STM32L4 kit.\nFirst, to provide AWS IoT Device Tester with my AWS account information, I edited the .\\devicetester_afreertos_win\\configs\\config.json template file in the configs directory. AWS IoT Device Tester uses this information to set up AWS IoT Core cloud resources required for the tests (for example, creating things, downloading certificates, and so on). I provided my credentials through environment variables, so I set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY as environment variables in Windows.\nSecond, to provide capabilities of the STM32L4 kit, I edited the features section of the device.json template file in the configs folder. Device Tester chooses the right set of tests to run based on the features I entered in the template file. I also provided the Windows port that the STM32L4 kit is connected to.\nLastly, to let AWS IoT Device Tester automate the process of building and flashing the test cases onto the STM32L4 kit for execution, I provided the build and flash scripts in the userdata.json template file in the configs folder. I also provided the path to the Amazon FreeRTOS source code on my laptop. If you are using microcontrollers from other vendors like Espressif, NXP, and Microchip, you can configure their build and flash commands in a similar way.Executing tests\nAWS IoT Device Tester provides a command line interface to run test cases. On my power shell, I ran the following command from the bin folder to let AWS IoT Device Tester execute the required qualification test cases on STM32L4 kit.\nAWS IoT Device Tester for Amazon FreeRTOS also provides an option to run a specific test group instead of the entire qualification test suite.\nViewing results\nIt took less than 30 mins for AWS IoT Device Tester to run the tests. I browsed to the .\\results\\<uid_of_test_run>\\logs folder and opened the devicetester_report.xml to find the status of the tests. The report shows which tests were run and their status. The test report is in JUnit format. You might find this useful if you want to integrate AWS IoT Device Tester results into your existing CI/CD systems like Jenkins, Bamboo, or Hudson. My test report showed all tests passed. Bingo!\nAWS IoT Device Tester for Amazon FreeRTOS is available for download now. To get started, visit here.\nAWS IoT Device Tester for AWS IoT Greengrass\nAWS IoT Greengrass is software that extends the benefits of AWS IoT Core to the edge. Linux devices that can run AWS IoT Greengrass vary widely in hardware configurations (for example, x86, ARMv7l, ARMv8), Linux versions (Ubuntu, Yocto, and customized Linux to run on appliances), and peripherals (such as Secure Element). OEMs who manufacture these devices wanted an easy and scalable way to verify if AWS IoT Greengrass works on their choice of Linux device.\nLike AWS IoT Device Tester for Amazon FreeRTOS, AWS IoT Device Tester for AWS IoT Greengrass is designed to run a set of standardized, automated tests to verify if the Linux device can run AWS IoT Greengrass and interoperate with AWS IoT services. Device Tester for AWS IoT Greengrass sets up the resources required by test cases. This includes creating a Greengrass group, certificates for authentication with AWS IoT Core, and Lambda functions. The Device Tester for AWS IoT Greengrass not only checks if the device hardware and OS meet Greengrass requirements, it also checks if key functionality (such as local resource access, device shadow, and OTA) work correctly on the device.\nAWS IoT Device Tester for AWS IoT Greengrass in action\nLogic Supply shipped me one of their industrial computers, the ML100G-50, to test whether AWS IoT Greengrass works on the device. The ML100G-50 has a 6th generation \xe2\x80\x9cSkylake\xe2\x80\x9d Intel Core i5-6300U CPU with 4 GB RAM and 128 GB SSD storage. AWS IoT Greengrass v1.6 was already installed on the device.\nAfter I connected the device to my network, I downloaded Device Tester from here to my Windows laptop and then extracted it to the devicetester_greengrass_win folder. I provided Device Tester with my AWS account and AWS Region information. The mechanics of this step are identical to what I did in the first configuration step for Device Tester for Amazon FreeRTOS.\nSecond, to enable passwordless SSH access to the Logic Supply device for the Device Tester, I copied the public key of my Windows laptop to the device. Now with Linux utilities built in into Windows 10, I used ssh-keygen from bash shell to generate private/public keys and then used ssh-copy-id to copy the public key over to the Logic Supply device.\nLastly, I edited the devices.json template file in the .\\devicetester_greengrass_win\\configs folder to provide device CPU architecture, OS, Greengrass root folder location on the device, and connectivity information. The Logic Supply device uses Ubuntu 16.04 OS with x86_64 architecture. Device Tester requires root access on the device under test, so I created a user with root privileges on the device and added the user name in the devices.json file.\nExecuting tests\nLike the Amazon FreeRTOS version, the AWS IoT Device Tester for AWS IoT Greengrass provides a command line interface to run test cases. In PowerShell, I ran the following command from the .\\devicetester_greengrass_win\\bin folder to let AWS IoT Device Tester execute the qualification test cases on ML100G-50. By default, it runs all of the tests in the Greengrass qualification suite.AWS IoT Device Tester for AWS IoT Greengrass also provides an option to run a specific test group instead of the entire qualification test suite.\nViewing results\nIt took about 45 mins for AWS IoT Device Tester to run the tests. I browsed to the .\\devicetester_greengrass_win\\results\\GGQ\\ folder and opened the devicetester_report.xml to find the status of the tests. The report shows which tests were run and the status. My test report showed that all tests passed. Hurray!AWS IoT Device Tester for AWS IoT Greengrass is available for download now. To get started, visit here. Happy testing!\n   '"
220,"AWS IoT Greengrass now enables simplified deployments, enhanced security, and greater flexibility",b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-greengrass-now-enables-simplified-deployments-enhanced-security-and-greater-flexibility/,"b'AWS IoT Greengrass allows you to bring local compute, messaging, data caching, sync, and ML inference capabilities to edge devices. Our newest release introduces features that simplify the deployment of Lambda functions to Greengrass, provide more flexibility so you can deploy Greengrass to new environments, and add easy-to-use security capabilities. Starting today, you can use new features that extend the capabilities of AWS IoT Greengrass devices, including connections to third-party applications and AWS services, isolation and permission settings that increase AWS IoT Greengrass configuration options, and hardware root of trust private key storage.\nSimplified deployments: AWS IoT Greengrass connectors\nYou can use AWS IoT Greengrass at the edge to perform a variety of functions: from translating between devices that use different industrial protocols, moving data from devices to on-premises applications and services, and extending the fabric of AWS and third-party services to their edge environments. With new AWS IoT Greengrass connectors, you can enable these common edge use cases in AWS IoT Greengrass without writing code. You can simply install reusable, configurable connectors to popular services like Amazon Simple Notification Service (Amazon SNS) or Amazon CloudWatch and start building!\n  You can use the AWS IoT Greengrass console, CLI, or API to attach and deploy AWS IoT Greengrass connectors to AWS IoT Greengrass groups. Each connector is individually configurable and has editable parameters that control its operation. For example, an Amazon SNS connector prompts you for the Amazon Resource Name (ARN) of an SNS topic to send notifications. After this parameter is set, you can deploy the connector to your AWS IoT Greengrass core. Then, messages sent to the connector through a predefined MQTT topic are sent to Amazon SNS automatically as notifications.\n  Greater flexibility: AWS IoT Greengrass groups and per-Lambda isolation and permission configurations\nYou can now use your preferred deployment mechanism and access a range of device resources. With new isolation configurations, you can get proof of concepts up and running faster by deploying AWS IoT Greengrass to other Open Container Initiative (OCI) container environments and directly accessing device resources like Bluetooth Low Energy (BLE) devices, sensors, or USB devices like Wi-Fi or camera dongles. You can also have more granular control over the permissions that you grant each function.\nNew configuration options allow you to run AWS IoT Greengrass groups and individual Lambda functions without the Greengrass container environment.\nYou can also choose to assign new group IDs and user IDs to a Lambda function, allowing functions to run with the permissions associated with that identity.\n                      Running Greengrass Lambda functions as OS processes without containers allows you to run AWS IoT Greengrass in a Docker container. You can now run Greengrass inside a Docker container on Windows 10 or macOS X machines.\nEnhanced security: AWS IoT Greengrass and Secrets Manager\nSecurity is a top concern as more edge devices gather and analyze sensitive information using services like AWS IoT Greengrass. A new integration between AWS IoT Greengrass and AWS Secrets Manager makes it easier to securely store, access, rotate, and manage secrets (credentials, keys, configurations, and more) at the edge. AWS IoT Greengrass connectors and Lambda functions can now access secrets as resources from an AWS IoT Greengrass group, eliminating the need to manually manage secrets or hard-code into Lambda functions or environment variables.\nYou can begin by storing, versioning, and rotating your secrets in AWS Secrets Manager. After you\xe2\x80\x99ve stored secrets in AWS Secrets Manager, they become available for deployment on the Resources tab in the AWS IoT Greengrass console and are ready for use by Lambda functions and AWS IoT Greengrass connectors.\nAWS IoT Greengrass Secrets Manager is fully integrated with AWS IoT Greengrass connectors. If a AWS IoT Greengrass connector needs a secret to authenticate with an application or service, you can select and deploy a secret to the AWS IoT Greengrass core as part of the connector configuration.\nEnhanced security: AWS IoT Greengrass hardware security integration\nAWS IoT Greengrass hardware security integration introduces hardware root of trust private key storage to the AWS IoT Greengrass security model. You can leverage hardware secure elements in addition to the use of X.509 certificates for Transport Layer Security (TLS) mutual authentication and encryption of data both in transit and at rest. You can also use AWS IoT Greengrass connectors to more securely store secrets on an AWS IoT Greengrass core by storing private keys on a hardware secure element.\nTo get started, you can configure your AWS IoT Greengrass core to use a private key generated on a secure element. Then, the Greengrass core will make calls through an integrated PKCS#11 crypto-standard interface to use this private key as the key that verifies the Greengrass core\xe2\x80\x99s identity during messaging with the AWS IoT Cloud and local devices with the AWS IoT Greengrass SDK.\nSecure element vendors Intel, NXP, Microchip, Infineon, Yubico, Soracom, STMicroelectronics, and Zymbit will support secure element integration with AWS IoT Greengrass. Vendors including Logic Supply and Vitro Technology offer boards and gateways with integrated secure elements.\nHow to get started\nLooking to get started and try out a connector, change your Lambda isolation configurations, or add new security capabilities to your IoT architecture?\nFor the list of available AWS IoT Greengrass connectors, see the developer guide.\nTo test new isolation and permissions configurations, you can change your AWS IoT Greengrass group and Lambda settings in the AWS IoT Greengrass console. For more information about isolation and permission configurations, see the developer guide.\nYou can find documentation about how you can pull the Greengrass Docker image from AWS ECR here.\nIf you want to purchase a device with root of trust security capabilities, you can use this link to filter for AWS IoT Greengrass Hardware Security Integration in our APN Device Portal to see compatible hardware devices. If you have a piece of hardware qualified by eligible vendors already, update to Greengrass v1.7, and reach out to your vendor for the firmware update that will enable this capability.'"
221,Using Dynamic Thing Groups to Continuously Update Software on Devices,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-dynamic-thing-groups-to-continuously-update-software-on-devices/,"b'When managing Internet of Things (IoT) devices, it can be challenging to maintain or improve device functionality through upgrades to device software and configuration. The complexity is due to a number of factors: the number of devices, multiple versions of the devices, different software versions based on device attributes and state, inability to discover and keep inventory of all devices, auditing, and reliability requirements. Consider typical use cases like upgrading the software on all devices to match the same version or patching all devices with a potential software vulnerability.\nIn this blog post, we look at existing solutions and limitations and then show how AWS IoT Device Management, specifically dynamic thing groups and continuous jobs, can be used to automate software updates on devices that meet certain criteria.\nExisting solution and limitations\nWhen a security vulnerability is discovered in a software version of devices, to mitigate the vulnerability, all of the connected devices should be upgraded to a newer software version. Device manufacturers need to be able to see how many devices are being upgraded and how many are pending an upgrade.\nA common solution is to use a scheduler job that periodically scans a device repository to identify which devices need upgrades. After those devices are identified, a job can be set up to update the devices. The limitations with this approach are additional costs associated with running these search queries, building logic to filter out devices that were processed in a previous run, and delays in upgrading the devices (they are upgraded only after scheduler jobs are run).\nSolution using dynamic thing groups and continuous jobs\nDynamic thing groups are a special type of thing group whose membership is defined by a fleet indexing search query. Things are added automatically to the group as they satisfy the membership condition specified by the query. Similarly, things are removed from the group when they fall out of the condition. Instead of periodically running queries, you can use dynamic thing groups to identify devices that meet certain criteria.\n\nFor example, we want to find all devices that are connected to AWS IoT services that have a particular software version and then perform software updates on these devices. First, we create a dynamic thing group. Then we attach this group as a target for continuous jobs, a feature that will perform the software patches.\nCreating a dynamic thing group\nBefore we create a dynamic thing group, make sure AWS IoT fleet indexing is turned on.\n$ aws iot update-indexing-configuration \\\n--thing-indexing-configuration thingIndexingMode=REGISTRY,thingConnectivityIndexingMode=STATUS\nPowerShell\nNow let\xe2\x80\x99s create the dynamic thing group to find all things that are connected and are running software version 5. In this example, the software version is stored as a thing attribute.\n$ aws iot create-dynamic-thing-group \\\n--thing-group-name onlineAndVersion5Devices \\\n--query-string ""connectivity.connected:true AND attributes.softwareVersion:5"" \\\n--thing-group-properties thingGroupDescription=""Group for devices that are connected and on version 5""\nPowerShell\nThe dynamic thing group now goes into BUILDING state as things that match the group\xe2\x80\x99s query condition are added to the group. After all matching things have been added to the group, the group\xe2\x80\x99s status transitions to the ACTIVE state.\n$ aws iot describe-thing-group \\\n--thing-group-name onlineAndVersion5Devices\n\n{\n    ""thingGroupName"": ""onlineAndVersion5Devices"",\n    ""thingGroupArn"": ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_ID>:thinggroup/onlineAndVersion5Devices"",\n    ""version"": 1,\n    ""thingGroupMetadata"": {\n        ""creationDate"": 1540772228.753\n    },\n    ""thingGroupProperties"": {\n        ""thingGroupDescription"": ""Group for devices that are connected and on version 5""\n    },\n    ""thingGroupId"": ""d2a5b68b-dxe5-4z93-8c76-f64e69bsdad9"",\n    ""queryString"": ""connectivity.connected:true AND attributes.softwareVersion:5"",\n    ""queryVersion"": ""2017-09-30"",\n    ""status"": ""ACTIVE"",\n    ""indexName"": ""AWS_Things"",\n}\nPowerShell\nTesting the dynamic thing group\nSo far, no things have been added to the group.\n$ aws iot list-things-in-thing-group \\\n--thing-group-name onlineAndVersion5Devices\n\n{\n    ""things"": []\n}\nPowerShell\nTo test this, let\xe2\x80\x99s first create a thing with the softwareVersion property.\n$ aws iot create-thing \\\n--thing-name device1 \\\n--attribute-payload ""{\\""attributes\\"": {\\""softwareVersion\\"": \\""5\\""}}""\nPowerShell\nNext, let\xe2\x80\x99s connect it to AWS IoT. Open the AWS IoT console and in the navigation pane, choose Test. If you are automatically connected with an auto-generated client ID, choose Disconnect. We need to connect using the name of the thing we just created, device1, as the client ID.\nBash\n\nNow, we can specify the client ID and connect to AWS IoT.\n\ndevice1 meets the criteria of the dynamic thing group and has been added to the group.\n$ aws iot list-things-in-thing-group \\\n--thing-group-name onlineAndVersion5Devices\n\n{\n    ""things"": [\n        ""device1""\n    ]\n}\nPowerShell\nFinally, we can create a continuous job that specifies this dynamic thing group as a target to perform the software upgrade. All devices that meet the criteria of the dynamic thing group become members of the group and receive software upgrades.\nWrapping up\nUsing dynamic thing groups, you can simplify and automate tasks like device discovery and categorization, and then trigger actions on newly added devices to groups. You can also use dynamic thing groups with the following AWS IoT features:\nEach time a device is added to or removed from a dynamic thing group, a notification is sent to an MQTT topic. You can then configure AWS IoT rules on these topics and take powerful actions, such as writing to Amazon DynamoDB, invoking an AWS Lambda function, or sending a notification to Amazon SNS.\nYou can define a security profile on a dynamic thing group. Devices that become of a member of the group are audited by the security profile defined on the group.\nYou can specify a log level on a dynamic thing group. This is useful if you only want to see logs for devices that meet certain criteria. For more information about fine-grained logging, see the AWS IoT Developer Guide.\nAlthough the examples here are a start, there is much more that AWS IoT Device Management offers to onboard, organize, monitor, and remotely manage connected devices at scale.\nLearn more\nAWS IoT Device Management\nhttps://aws.amazon.com/iot-device-management\nAWS IoT Device Management Features\nhttps://aws.amazon.com/iot-device-management/features/\nAWS IoT Device Provisioning\nhttp://docs.aws.amazon.com/iot/latest/developerguide/iot-provision.html'"
222,Your Guide to AWS IoT at re:Invent 2018,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/your-guide-to-aws-iot-at-reinvent-2018/,"b'AWS re:Invent 2018 is almost here! As you plan your agenda, we don\xe2\x80\x99t want you to miss any IoT sessions. This year we have a lot of great technical content about our IoT services as well as use case specific sessions for industrial and the connected home \xe2\x80\x93 over 100 breakout sessions, hands-on workshops, deep-dive chalk talks, and more. You\xe2\x80\x99ll hear success stories from our customers and partners including Pentair, Vestel, VIZIO, Thermo Fisher Scientific, GE, Enel, Analog Devices, the City of San Jose, Ayla Networks, Deutsche Bahn, Fender, Hudl, FormCell, AISIN AW, and many more. This year\xe2\x80\x99s re:Invent also includes an AWS IoT pub crawl, Tuesday, November 27, 6:00pm at the ARIA where you can relax and enjoy some food and drink with AWS IoT experts.\nYou will not want to miss the IoT Thought Leadership session delivered by Dirk Didascalou, VP of AWS IoT. Another do not miss session is AIoT: AI Meets IoT with AWS IoT GM, Sarah Cooper and James Gosling, Distinguished Engineer. Below are few highlights from this year\xe2\x80\x99s lineup to help you plan your event agenda. For a full list of sessions, see the re:Invent session catalog.\nIndustrial IoT Sessions\nIndustrial IoT (IIoT) bridges the gap between legacy industrial equipment and infrastructure and new technologies such as machine learning, cloud, mobile, and edge computing. IIoT helps customers optimize industrial operations and increase productivity and efficiency. You can use IIoT applications for predictive quality and maintenance and to remotely monitor operations from anywhere. Attend the sessions below to learn more about to use AWS IoT for industrial applications.\nHow Fender is Automating Its Manufacturing Operations with AWS (Session IOT220-R)\nIn this session, we explain how combining IoT and AI technologies, such as computer vision, enables you to increase the productivity of a manufacturing process. Using AWS IoT services and analytics, we show you how to sense and control environmental conditions. Finally, we show you how to quickly transition from a patrol-based model to a notification-based model for replenishment scenarios.\nIndustrial IoT: Connecting Existing Machines to Tomorrow\xe2\x80\x99s IoT, ft. Deutsche Bahn (Session IOT303-R)\nThe overwhelming majority of today\xe2\x80\x99s industrial machines is not internet-ready. This is because many industrial machines lack connectivity or have proprietary or industry-specific interfaces. The value of these machines is in their access to data and metadata that can be used to unlock new business opportunities. In this session, we provide a detailed view into how to use AWS Greengrass and AWS Lambda to connect machines with industrial interfaces, such as OPC UA, Modbus, Ethernet/IP, and EuroMap63. We also walk you through a demonstration and show you how to connect to industrial machines and provide data and metadata at the edge and in the cloud.\nServerless Industry 4.0 & AI: Drive Business Insights from Machine Data Workshop (Workshop IOT402-R)\nIn this workshop, we provide a hands-on approach for building the complete Industry 4.0 AI dataflow \xe2\x80\x93 from accessing data on machines to deploying AI models on the edge. Learn how to combine fully managed AWS IoT services for such a solution. First, we connect different industrial devices using AWS Greengrass with industry protocols (e.g., OPC UA). Next, we use AWS IoT Analytics to create AI models with Amazon SageMaker. Finally, we deploy and run models with AWS Greengrass Machine Learning (ML) Inference.\nIndustrial IoT Applications: Making the Connection and Extracting Value Chalk Talk (Chalk Talk IOT342-R)\nIndustrial IoT applications are rapidly emerging across industries such as oil and gas, manufacturing, and agriculture. In this chalk talk, we help you architect end-to-end solutions that will deliver value like predictive maintenance, manufacturing quality, and process monitoring. In this interactive session, we help you understand how to connect greenfield and brownfield infrastructure with AWS that leverages both AWS Greengrass (on premises) and other AWS Cloud services. Along the way, we show how the AWS Industrial IoT Reference Architecture is incorporated to build your industrial application.\nConnected Home Sessions\nA connected home brings devices and services together for an integrated, autonomous experience that improves a consumer\xe2\x80\x99s life. Connected home experiences include everything from voice-controlled lights, house-cleaning robots, machine learning-enabled security cameras, and WiFi routers that troubleshoot for you. You can use AWS IoT for home automation, home security and monitoring, and home networking. Attend the sessions below to learn more about to use AWS IoT for connected home applications.\nAlexa and AWS IoT, ft. VIZIO (Session IOT302-R)\nVoice is a natural interface to interact not just with the world around us, but also with physical assets and things, such as connected home devices, including lights, thermostats, or TVs. In this session, we discuss how you can connect and control devices in your home using the AWS IoT platform and Alexa Skills Kit. We also hear from customer, VIZIO, on how they are using AWS IoT and Alexa to bring a voice-controlled television experience to their hundreds of thousands of customers.\nBuilding IoT Applications for a Smart Home, ft. Vestel (Session IOT306-R)\nThe IoT transformation begins at home. Today, device manufacturers and network providers are building groundbreaking connected devices and applications to make your home smarter. In this session, we dive into the best practices and common patterns for building connected devices and applications for a Smart Home. This session focuses on securely onboarding your devices to a consumer\xe2\x80\x99s account, leveraging IoT, using ML at the edge, and video streaming for home security. By the end of the session, you\xe2\x80\x99ll have a set of best practices for how to build IoT products in the Smart Home. Also hear from Vestel about their smart home application.\nIoT Analytics in the Connected Home (Builders Session IOT339-R)\nHow can you make the smart home smarter? In this session, learn the most common use cases for analytics in the connected home. Attendees get hands-on experience implementing AWS IoT Analytics using data points common in connected home applications.\nAmbient Intelligence \xe2\x80\x93 Bringing ML and AI to the Connected Home (Chalk Talk IOT350-R1)\nAWS IoT Analytics is a fully managed service that makes it easy to run and operationalize sophisticated analytics on massive volumes of IoT data. In this session, we demonstrate how AWS IoT Analytics can help you incorporate the power of ambient intelligence into your IoT workflow and extract valuable insights from your generated IoT data. In addition, as we walk you through a specific example, we describe each of the service components, how to use them, and general best practices.\nAWS IoT Services Sessions\nAnatomy of a Successful IoT Project, ft. Pentair (Session IOT202)\nPatterns of IoT project success are starting to emerge across industries and project types. In this session, we identify and review high-level challenges, and we describe the most common solutions to those challenges. Leave this session with an understanding of the common phases and personae necessary for your project as well as general guidelines for orienting your project and organization toward success. A representative from Pentair discusses the company\xe2\x80\x99s IoT project as an example case study.\nComputing at the Edge with AWS Greengrass and Amazon FreeRTOS, ft. Enel (Session IOT213)\nEdge computing is all about moving compute power to the source of the data instead of having to bring it to the cloud. The edge is a fundamental part of IoT, and it is not only about connecting things to the internet. In this session, we discuss how AWS Greengrass, which is an IoT edge software, can power devices small and large, from a sensor all the way to a wind turbine. With AWS Greengrass, these IoT devices can securely gather data, keep device data in sync, and communicate with each other while still using the cloud for management, analytics, and durable storage. Join us to learn more about the edge of IoT.\nKeep Your IoT Devices Secure (Session IOT205)\nHelping you manage the security of your IoT fleet is a top priority for AWS. You can use AWS IoT Device Defender to audit device fleets for best practices and drift in security settings, detect abnormal device behavior, and receive alerts to investigate issues. In this session, we will show you how you can use AWS IoT Device Defender to implement and maintain secure policies and controls to keep data and devices secure. Come away understanding how to spot insecure device configurations and how to set up metrics that can be used to spot a DDoS and botnet attacks. We will also look at how AWS IoT Device Defender works with AWS IoT Core and AWS IoT Device Management to respond to security alerts.\nManaging Connected Devices at Scale with AWS IoT Device Management, ft. Hudl (Session IOT207-R)\nIoT deployments often consist of thousands to millions of devices deployed across multiple locations. It is essential to have a solution to track, monitor, and manage your connected device fleets at scale. In this session, learn how AWS IoT Device Management can help you onboard, remotely manage, and monitor your connected devices. In this session, we discuss key features of AWS IoT Device Management, including fleet indexing and search, remote commands, over-the-air (OTA) updates, and device monitoring. Learn how AWS IoT Device Management can help you scale your fleets and reduce the cost and effort of managing IoT device deployments. Also, representatives from Hudl, the world leader in sports video analysis, discuss how the company is changing the recording and upload process for high schools across the country with their newest product, Hudl Focus.\nThe Essentials of AWS IoT Device Management (Chalk Talk IOT326-R)\nIn this session, learn how to use AWS IoT Device Management to onboard and manage devices at scale. We discuss a customer use case, provide a demo, and share best practices to solve the fleet management challenges that you may be facing.\nAmazon FreeRTOS: IoT Operating System for Microcontrollers (Session IOT208-R)\nIn this presentation, we take a deeper look at Amazon FreeRTOS. As OEMs work to squeeze more functionality onto cheaper and smaller IoT devices, they face a series of challenges in development and operations that result in security vulnerabilities, inefficient code, compatibility issues, and unclear licensing. With Amazon FreeRTOS, it is now easier to build, deploy, and update connected microcontroller-based devices quickly and economically, while retaining confidence that the devices are secure.\nMachine Learning at the IoT Edge (Session IOT214)\nWhether it\xe2\x80\x99s connected cars, smart home devices, or industrial applications, IoT applications are rapidly becoming more intelligent. Edge computing is helping lead this transformation as IoT devices not only collect and transmit data, but also perform predictive analytics and respond to local events, even without cloud connectivity. In this session, learn about ML inference at the edge, why it matters, and how to use it to build intelligent IoT applications. Through customer use cases, we demonstrate how to use AWS Greengrass to locate cloud-trained ML models, deploy them to your AWS Greengrass devices, enable access to on-device computing power, and apply the models to locally generated data without connection to the cloud.\nCustomer Showcase for AWS IoT Analytics (Session IOT219)\nSee how our customers are using AWS IoT Analytics.\nOperationalizing Your Analysis With IoT Analytics (Session IOT358-R)\nAWS IoT Analytics makes it easy to run and operationalize sophisticated analytics on massive volumes of IoT data without having to worry about the cost and complexity required to build your own IoT analytics platform. It collects and prepares data for analysis and also lets you explore and visualize your IoT data so you can make better and more accurate business decisions. AWS IoT Analytics is a fully-managed service that makes it easy to run and operationalize sophisticated analytics on massive volumes of IoT data without having to worry about the cost and complexity typically required to build an IoT analytics platform. It is the easiest way to run analytics on IoT data and get insights to make better and more accurate decisions for IoT applications and machine learning use cases. Models built and trained in AWS IoT Analytics can be run on connected devices. Join us for a deep dive and demo on how to operationalize your analytical workflows with AWS IoT Analytics.\nImplementing Multi-Region AWS IoT, ft. Analog Devices (Session IOT401)\nYour devices are being shipped across the globe. You have consumers who use their hardware across different countries. How can you build an IoT application that reflects the geographic reach of your devices? In this session, we walk you through the stages of going multi-region with AWS IoT. We first tackle common challenges around setting up your accounts and permissions for AWS IoT. We then dive into different modes of multi-region deployments using multiple AWS services. We also cover the nuances of moving devices across locations and how you can plan, monitor, and execute on your IoT application. Throughout this session, we dive into code and architectures that show the good, the bad, and the ugly of multi-region deployments in IoT, and we share how best to tackle them on day 1 as you take your applications global. We also highlight a customer example from Analog Devices.\nWant to find out about all of the IoT activities at re:Invent? Download our re:Invent IoT Guide here.'"
223,Containerize your IOT application with AWS IOT Analytics,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/containerize-your-iot-application-with-aws-iot-analytics/,"b'Overview\nIn an earlier blog post about IoT Analytics, we discussed how AWS IoT Analytics enables you to collect, visualize, process, query and store large amounts of time series data generated from your connected devices. In this blog post, I will show how you can use your custom application to interact with AWS IoT Analytics. Specifically, we will discuss \xe2\x80\x93\nHow to bring your custom code as a docker image to AWS IoT Analytics\nHow the docker based application can process batch data on a schedule\nScenario\nWe\xe2\x80\x99ll use an example of a smart building in NYC that uses AWS IoT to become energy efficient. The building is equipped with sensor enabled conference rooms , phone booths and offices. The telemetry data from various sensors across different floors & rooms are analyzed in certain intervals against the corporate meeting calendar data to identify if the rooms are in use. If not, the Lights and Air conditioner of the rooms are turned off.\nThis is how the flow works \xe2\x80\x93\nThe telemetry data from various sensors are published from the building through a device gateway to AWS IoT Core topic (for example : building/sensors) on the cloud.\nAWS IoT Core in turn uses Rules engine to route the data to data stores in AWS IoT Analytics.\nThe data in the data store is analyzed by a containerized application integrated with AWS IoT Analytics. In this blog, we will use it to determine how many rooms have Light & AC turned on.\nThe result set is then validated against the corporate calendar , to determine if any of the rooms are reserved for this time period or can energy be conserved by turning off the Lights or AC. And the output is stored in a landing zone for further actions.\nPre-Requisites\nThis blog assumes that the reader have completed the the following steps prior to moving to the Solution section :\nCreate a ssh key-pair to be able to log into the EC2 instance\nA ssh key-pair can be generated or imported in the AWS console under EC2 -> Key Pairs\nLaunch the cloudformation template to provision the environment for this lab \xe2\x80\x93\nUS-WEST-2\nUS-EAST-1\nCheck if the telemetry data is being published once the cloudformation stack is successfully created\nGo to IoT Core Console, Click Test on the left pane \xe2\x80\x93\nSubscription topic: workshop/telemetry\nClick Subscribe to topic\nSolution\nCreate SQL Data Set\nA SQL data set is similar to a materialized view from a SQL database. We will create a SQL data set below that will store the telemetry data generated in the section above.\nOn the IoT Analytics console home page, in the left navigation pane, choose Analyze.\nClick on Data sets \xe2\x86\x92 Create\nChoose SQL Data Sets \xe2\x86\x92 Create SQL\nChoose a ID for the SQL Data Set and select the datastore :\nID \xe2\x86\x92 mydataset, Data Store Source \xe2\x86\x92 mydatastore , click Next\nPaste the below SQL into the Query window, click Next\nSELECT floor_id,room_id,day,time FROM mydatastore where light = 1 and hvac = 1\nSQL\nKeep delta selection window as None (default) , click Next\nSchedule the data set to run on every 15 minutes\nChoose Minute of hour \xe2\x80\x93 0 , Click Next\nChoose the the default retention for the data set (Indefinitely) and Create Data set.\nQuery Data\nClick on the Data Set you just created.\nOn the data set page, in the upper-right corner, choose Actions, and then choose Run now\nIt can take few minutes for the data set to show results. Check for SUCCEEDED under the name of the data set in the upper left-hand corner. The Content section contains the query results (left pane).\nCreate Custom Container for Analysis\nPlease follow the instructions below to create the docker image with custom application code \xe2\x80\x93\n1. SSH to EC2 instance (copy command from cloudformation output tab) & navigate to the docker directory:\ncd ~/docker-setup\naws s3 cp ./calendar.csv s3://<paste-s3-bucket-name-from-cloudformation-output> \nBash\n2. Build the docker image:\ndocker build -t container-app-ia .\nBash\n3. You should see a new image in your Docker repo. Verify it by running:\ndocker image ls | grep container-app-ia\nBash\n4. Create a new repository in ECR:\naws ecr create-repository --repository-name container-app-ia\nBash\nPlease copy the repositoryUri from the output for use in step 7 & 8\n5. Get the login to your Docker environment:\naws ecr get-login --no-include-email\nBash\n6. Copy the output and run it. The output should look something like:\ndocker login -u AWS -p <password> https://<your-aws-account-id>.dkr.ecr.amazonaws.com\nBash\n7. Tag the image you created with the ECR Repository Tag:\ndocker tag container-app-ia:latest <<paste repositoryUri copied earlier>>:latest\nBash\n8. Push the image to ECR:\ndocker push <<paste repositoryUri copied earlier>>\nBash\nCreate the Container Data Set\nA container data set allows you to automatically run your analysis tools and generate results. It brings together a SQL data set as input, a Docker container with your analysis tools and needed library files, input and output variables, and an optional schedule trigger. The input and output variables tell the executable image where to get the data and store the results.\nOn the IoT Analytics console home page, in the left navigation pane, choose Analyze.\nClick on Data Sets \xe2\x86\x92 Create\nChoose Container Data Sets \xe2\x86\x92 Create Container\nChoose a unique ID for the Container Data Set \xe2\x86\x92 container_dataset, click Next\nChoose the option \xe2\x86\x92 Link an existing data set\xe2\x80\x99s query \xe2\x86\x92 Link\nSelect a trigger for your analysis \xe2\x86\x92 Choose mydataset \xe2\x86\x92 Schedule will be automatically populated, click Next\nSelect from your ECR Repository \xe2\x86\x92 Choose the repository container-app-ia (as per screenshot below)\nSelect your image \xe2\x86\x92 Choose the image with latest tag\n  Configure the input variables (as below) \xe2\x86\x92 Click Next :\nName Type Value\ndatasetv Content version mydataset\nresulturi Output file output.csv\ninputDataS3BucketName String <<paste s3 bucket name from cloudformation output>>\ninputDataS3Key String calendar.csv\nSelect a Role \xe2\x86\x92 Choose the IAM Role \xe2\x86\x92 search & select iotAContainerRole\nConfigure the capacity for container :\nCompute Resource : 4 vCPUs and 16 GiB Memory\nVolume size (GB) : 1\nConfigure the retention of your results \xe2\x86\x92 Keep its default (indefinitely) and Click on Create Data set\nQuery & Validate Container Data Set\nOn the IoT Analytics console home page, in the left navigation pane, choose Analyze.\nSelect Data Set \xe2\x86\x92 container_dataset\nOn the data set page, in the upper-right corner, choose Actions, and then choose Run now\nIt can take few minutes for the data set to show results. Check for SUCCEEDED under the name of the data set in the upper left-hand corner. Check if the output file exists under Content tab (left pane) , or in your S3 bucket and download it.\nThe output data once downloaded should be similar to below \xe2\x80\x93\nThus you completed the workflow to ingest telemetry data from your smart building, enrich the data using your custom docker code to gain insight into the availability of rooms, and store the processed data into a landing zone for further actions like turning off the lights & AC in the free rooms .\nClean Up\nPlease follow the instructions below to clean-up the resources created part of this blog \xe2\x80\x93\nSSH to EC2 instance & navigate to the clean-up directory:\ncd ~/clean-up\n./clean-up.sh\nEnter name of the device > smart-building\nEnter device type > sensors\nEnter S3 bucket > <<paste your s3 bucket name>>\nBash\nNavigate to AWS Console -> Choose Cloudformation -> Select and Delete the stack created earlier\nNavigate to AWS Console -> Choose ECS -> Select Repositories (left pane) -> Delete the ECR repository \xe2\x80\x9ccontainer-app-ia\xe2\x80\x9d\nTroubleshooting\nIf SQL Data Set execution fails, run the below to check the error for the respective version \xe2\x80\x93\nSSH to EC2 instance and run the below :\naws iotanalytics list-dataset-contents --dataset-name mydataset\nBash\nIf Container Data Set execution fails, you can check the the logs in \xe2\x80\x93\nCloudwatch -> Log Groups \xe2\x86\x92 /aws/sagemaker/TrainingJobs\nFor any other issues, please refer to here \xe2\x80\x93 Link\n'"
224,Connect your devices to AWS IoT using LoRaWAN,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/connect-your-devices-to-aws-iot-using-lorawan/,"b'4/15/21 AWS IoT Editorial Team Update: \nSince the time of this blog post, we have announced AWS IoT Core for LoRaWAN. AWS IoT Core for LoRaWAN is a fully-managed feature that allows you to connect and manage wireless devices that use LoRaWAN connectivity with the AWS Cloud. Using AWS IoT Core for LoRaWAN, enterprises can setup a private LoRaWAN network by connecting their LoRaWAN devices and gateways to the AWS Cloud \xe2\x80\x93 without developing or operating a Network Server (NS) for LoRaWAN themselves.\nLearn more about AWS IoT for LoRaWAN, visit the feature page. To get started, see this workshop for step-by-step instructions for how to start using AWS IoT Core for LoRaWAN:  https://iotwireless.workshop.aws/.\n__\nFor many IoT use-cases, sensors only ever need to transmit infrequent and low bit-rate data. These sensors may communicate over large distances and have battery lives spanning in years, which means they are replaced infrequently. A couple of common use-cases would be in Smart Cities (eg. Parking or Waste sensors) and Agriculture (eg. Soil Monitoring sensors). LoRaWAN networks are a good fit for these use-cases and a great way of collecting sensor data.\nThis post looks at the characteristics of LoRaWAN devices and networks and how customers can integrate these with AWS. We\xe2\x80\x99ll provide an overview of LoRaWAN technology and demonstrate how to build a demonstration kit that integrates directly with AWS IoT Core.\nTo build this demo you\xe2\x80\x99ll need the following:\na LoPy4 development board with Espressif chipset. You can set the LED color on this board as an example of changing state using the AWS IoT shadow service. This board runs MicroPython.\na LoPy4 LoRa antenna kit.\na Pysense sensor shield to provide sample telemetry data.\nThe Things Network (TTN) \xe2\x80\x93 A world-wide community based LoRaWAN network. They have detailed documentation on how to configure AWS IoT integration with their platform. You\xe2\x80\x99ll need to set up an account with The Things network.\nQuick LoRaWAN overview\nLoRaWAN is a low-power wide-area network (LPWAN) technology. Other LPWAN technologies include Narrowband IoT & Sigfox. LPWAN technologies support long range communication, low power requirements and low bit rates.\nLoRaWAN is a protocol specification built on top of the LoRa technology developed by the LoRa Alliance. It uses unlicensed sub-1GHz Industrial, Scientific and Medical (ISM) bands. End-devices communicate with LoRaWAN gateways over a single hop and these gateways provide a TCP/IP uplink to the LoRaWAN Network server, which is responsible then for routing messages between devices and the LoRaWAN \xe2\x80\x9cApplication\xe2\x80\x9d. End-devices can connect to multiple gateways for redundancy and the Network server manages duplicate packets etc. This is shown in the diagram below:\nAll communications are encrypted twice within the LoRaWAN network, once with a Network Session Key between the end device and the Network Server and secondly with an Application Session Key used to encrypt data between an end-device and an Application. These keys can be generated per session or at time of manufacture.\nHow do you get LoRaWAN data into AWS so you can build great solutions?\nEnd-devices have a LoRa interface which communicates directly with gateway(s) using RF. Secure access to the network and identification is therefore managed by the LoRaWAN network and not AWS IoT; LoRaWAN devices therefore do not have the AWS IoT SDK installed. To get device data flowing from a LoRaWAN network into AWS IoT the Network Server is integrated with the AWS IoT service. Many LoRaWAN providers are now building AWS IoT integration into their products.\nAWS IoT LoRaWAN integration must perform several functions (shown below in the diagram):\n  Synchronize device information and attributes between the AWS IoT Device Management service and the LoRaWAN Network Server. If an attribute is changed in one it should propagate to the other.\nSupport bidirectional communication so you can ingest sensor data, and also send back control data. LoRaWAN supports bidirectional communications over several classes of communication.\nBe able to abstract the AWS IoT Shadow Service so you can at all times get and set the state of things from AWS IoT over the LoRaWAN network to the LoRa-enabled device.\nBe able to convert between LoRaWAN data, which is typically composed of bytes (to minimize overhead), to a JSON document expected of the AWS IoT service.\nBe reliable, scalable and fit for purpose. That is, make sure you test and validate your LoRaWAN network is suitable for your use-case.\nAll of these components can run in a single customer AWS account but it is more common to see the Network Server (and sometimes also the AWS IoT Integration tier) running in the LoRaWAN network provider\xe2\x80\x99s AWS account and the AWS IoT and end-user application components running in a customer\xe2\x80\x99s AWS account.\nDemonstrating LoRaWAN AWS Integration using The Things Network\nTo demonstrate how this integration works I\xe2\x80\x99ve built a small demo project using a LoPy4 device and The Things Network (TTN). Pycom provide extensive documentation on how to set up and manage a LoPy4 device. I set up and run this demo using the Pymakr plugin with Atom (you can also use VS Code).\nThe high-level steps to configure this demo are:\n1. Follow the Pycom documentation for hardware setup of the LoPy4, antenna and Pysense and then update the firmware and configure the development environment for the board.\n2. Configuring the LoRaWAN Application & Device in the TTN console.\n3. Creating JavaScript code in the TTN console to decode bytes into JSON and encode JSON back into bytes and JSON for temperature data and shadow changes.\nThe decoder and encoder functions used are shown below:\nfunction Decoder(bytes, port) {\n  // Decode an uplink message from a buffer\n  // (array) of bytes to an object of fields.\n  var decoded = {};\n  var colors = [""off"", ""red"", ""green"", ""blue""];\n  var color = colors[bytes[2]];\n  var temperature = (bytes[0] * 256 + bytes [1])/100;\n\n  return {\n    temperature: temperature,\n    state: {\n      color: color\n    }\n  }\n}\n\nfunction Encoder(object, port) {\n  var colors = [""off"", ""red"", ""green"", ""blue""];\n  var bytes = [];\n  if (object.state && object.state.color) {\n    bytes.push(colors.indexOf(object.state.color));\n  }\n  return bytes;\n}\n4. Install & test the TTN AWS IoT integration in an AWS account. This is provided as a CloudFormation script that installs an Elastic Beanstalk (EB) application that performs the integration. This EB application, which runs by default on a t2.micro EC2 instance, authenticates itself with the TTN Network Server and Application using the Application Access Key generated by TTN. By default, this will synchronize the TTN Application details with the AWS IoT Device Management service every 10 minutes (this is configurable).\n5. Install, configure and test the Micropython code on the LoPy device. You must be in range of The Things Network. Configure the correct LoRaWAN region for your geography (in Australia both AU915 and AS923 band plans are supported) and the correct credentials for your LoRaWAN Application.\nimport binascii\nimport pycom\nimport socket\nimport time\nfrom network import LoRa\nfrom pysense import Pysense\nfrom MPL3115A2 import MPL3115A2\n\n\n# Colors\noff = 0x000000\nred = 0xff0000\ngreen = 0x00ff00\nblue = 0x0000ff\ncolors = [off, red, green, blue]\n\n# Turn off heartbeat LED\npycom.heartbeat(False)\n\n# Initialize LoRaWAN radio\nlora = LoRa(mode=LoRa.LORAWAN, region=LoRa.AU915, adr=False, tx_retries=0, device_class=LoRa.CLASS_A)\n\n# Set network keys\napp_eui = binascii.unhexlify(\'xxxxxxxxxxxxxxxx\')\napp_key = binascii.unhexlify(\'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\')\n\n# remove some channels (in Australia)\nfor i in range(16, 65):\n  lora.remove_channel(i)\nfor i in range(66, 72):\n  lora.remove_channel(i)\n\n# Join the network\nlora.join(activation=LoRa.OTAA, auth=(app_eui, app_key), timeout=0)\npycom.rgbled(red)\n\n# init the libraries\npy = Pysense()\ntemp = MPL3115A2()\n\n# Loop until joined\nwhile not lora.has_joined():\n  print(\'Not joined yet...\')\n  pycom.rgbled(off)\n  time.sleep(0.1)\n  pycom.rgbled(red)\n  time.sleep(2)\n\nprint(\'Joined\')\npycom.rgbled(blue)\n\ns = socket.socket(socket.AF_LORA, socket.SOCK_RAW)\ns.setsockopt(socket.SOL_LORA, socket.SO_DR, 5)\ns.setblocking(False)\ncolorindex = 3\n\nwhile True:\n  # Read data from the libraries and place into string\n  data = temp.temperature()\n  print(""Sending %.5s"" % data)\n  data = int (data * 100);\n  # send the data over LPWAN network\n  s.send(bytes([int(data / 256), data % 256, colorindex   ]))\n  s.settimeout(3.0) # configure a timeout value of 3 seconds\n  try:\n    rx_pkt = s.recv(64)   # get the packet received (if any)\n    print(rx_pkt)\n    colorindex = int.from_bytes(rx_pkt, ""big"")\n  except socket.timeout:\n    print(\'No packet received\')\n\n  pycom.rgbled(green)\n  time.sleep(0.1)\n  pycom.rgbled(colors[colorindex])\n  time.sleep(29.9)\n6. The code runs an infinite loop converting temperature readings and the LED color from the Pysense to bytes and sending these bytes to the TTN Application, which then forwards the data to AWS IoT. Each time a packet is sent it checks to see if there is a return packet based on a Shadow state change (LoRaWAN has three classes for supporting directional communications) and if so it receives that packet and changes the LED color to the new desired state.\nTesting the TTN AWS IoT integration\nThere are several ways of testing the integration.\n1. Confirm that the LoPy device is present in both the AWS IoT and TTN consoles.\n2. Confirm that your LoPy4 device is being activated and is sending uplink messages in the TTN console.\n3. Confirm that uplink messages are being converted from bytes to JSON and being sent to the AWS IoT Core service by using the MQTT Test client\n4. Create an AWS IoT Action and send data to DynamoDB.\n5. Update the AWS IoT device shadow state in the console, observe the downlink message in the TTN console and if all goes well watch the LED on your device change color!\n6. You can also simulate uplink and downlink messages from the TTN console if you need to troubleshoot.\nIn summary\nLoRaWAN technology offers customers a great way to build IoT networks that support low bit-rates, low energy use and long device lifespan over large geographical areas. And now with AWS IoT integration customers can leverage the best of both worlds by bringing the power of the cloud to their IoT data! If you\xe2\x80\x99d like to learn more about AWS and our IoT network partners, follow these links:\nAWS IoT Partner Solutions \xe2\x80\x93 Technology for Connectivity\nDemocratizing LoRaWAN and IoT with The Things Network'"
225,Integrating AWS IoT and AWS Greengrass into the Automotive Grade Linux Software Stack,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/integrating-aws-iot-and-aws-greengrass-into-the-automotive-grade-linux-software-stack/,"b'Post by Hitendra Nishar, AWS Solutions Builder\nAutomotive Grade Linux (AGL) is an open source project to accelerate the development and adoption of a fully open software stack for connected vehicles. AGL is building a Linux-based, open software platform that can serve as the de facto industry standard and enable rapid development of new features and technologies. With the platform, automakers and suppliers can decrease development time, speed innovation, and bring new features to market faster.\nAGL plans to address the entire software stack within a vehicle: infotainment, instrument cluster, Heads-up Display (HUD), telematics and connectivity, functional safety, Advanced Driver Assistance Systems (ADAS), and Autonomous Driving. For more information, see www.automotivelinux.org.\nAWS IoT Framework for AGL\nTo help Amazon Web Services (AWS) customers leverage AGL\xe2\x80\x99s open platform, the AWS Solutions team has developed the AWS IoT Framework for AGL, a reference implementation that helps you integrate AWS IoT and AWS Greengrass into the AGL software stack. The framework consists of AWS Greengrass Core and an AWS IoT binding service built using the AGL Application Framework and the AWS IoT Device SDK.\nThe AWS Greengrass Core manages a secure connection between your edge device and AWS IoT using certificate-based mutual TLS authentication, providing a secure message broker. The AWS Greengrass Core also allows you to run local AWS Lambda functions on AGL.\nThe AWS IoT binding service is built using the AGL Application Framework which provides components for running the binding service in an isolated, secure environment, and for managing the application life cycle. The Application Framework exposes the service API to publish or subscribe to MQTT topics on AWS Greengrass Core. Other AGL applications and services can invoke the binding service API using supported protocols such as WebSockets or D-Bus. For more information, see AGL framework overview.\nThe binding service also uses the AWS IoT Device SDK for C++ to securely communicate with the AWS Greengrass Core using MQTT. For more information, see AWS IoT Device SDK.\nThe diagram below shows how an application running on AGL can send telemetry data to AWS IoT using the framework.\nAWS IoT Framework for AGL architecture\nWhen the telemetry application starts, the framework loads dependent services, such as CAN bus and AWS IoT binding services; performs the necessary security checks; and establishes the connections for these services to interact with the telemetry application via the WebSocket or D-Bus protocols.\nThe AWS IoT binding service uses the AWS Greengrass API to discover the AWS Greengrass Core endpoint and securely connect to it. The binding service also exposes the publish and subscribe APIs used by the telemetry application to send the data to and from the AWS Cloud via the AWS Greengrass Core using MQTT topics.\nThe CAN bus binding service exposes the subscribe APIs that the telemetry application invokes to consume the telemetry data.\nThe framework provides isolated security context for all the services and processes running on the AGL software stack.\nTo get started on the reference implementation, please check the open-source Github repository at github.com/awslabs/aws-iot-framework-for-agl \n '"
226,Configuring Cognito User Pools to Communicate with AWS IoT Core,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/configuring-cognito-user-pools-to-communicate-with-aws-iot-core/,"b'AWS IoT Core supports certificate-based mutual authentication, custom authorizers, and Amazon Cognito Identity as way to authenticate requests to the AWS IoT device gateway. Amazon Cognito User Pools was made generally available last year. It allows customers to easily add user sign up and sign in to mobile and web apps. You can use Cognito User Pools identities to talk to AWS IoT Core by linking them to Cognito Federated Identities.\nIn this blog post, I will walk you through how to set up Amazon Cognito User Pools with Amazon Cognito Federated Identities to talk to AWS IoT Core using an authenticated Amazon Cognito identity over WebSocket. I assume you are familiar with the basic components and functionality of AWS IoT and Cognito.\nTo create a user pool\nSign in to the AWS Management Console and navigate to Amazon Cognito.\nIn the Amazon Cognito console, choose Manage User Pool, and then choose Create a user pool.\nFor Pool name, enter demo-pool.\nMake a note of the user pool ID. You\xe2\x80\x99ll need it later.\nTo create an app client\nFrom the navigation pane, choose App clients, and then choose Add an app client.\nFor App client name, enter demo-app-client.\nMake a note of the app client ID. You\xe2\x80\x99ll need it later.\nClear the Generate client secret check box.\nReview the demo pool settings, and then choose Create app client.\nTo create an identity pool\nNext, create a federated identity pool using Amazon Cognito User Pools as the identity provider. Use the user pool ID and app client ID created in the previous steps.\nIn the Amazon Cognito console, choose Federated Identities.\nCreate an identity pool and name it demo identity pool.\nFor authentication provider, choose Cognito.\nEnter the user pool ID. (You can find the ID under User Pools \xe2\x86\x92 demo-pool \xe2\x86\x92 General Settings \xe2\x86\x92 Pool ID)\nEnter the app client ID. (You can find it under User Pools \xe2\x86\x92 demo-pool \xe2\x86\x92 App Integration \xe2\x86\x92 App client settings \xe2\x86\x92 demo-app-client\xe2\x86\x92 ID)\nFinally, create an identity pool that looks like the following:\nChoose Create Pool.\nNote: Two IAM roles will be created for you: one for an authenticated pool and another for an unauthenticated pool. In this post, we will use the authenticated pool only.\nTo grant AWS IoT permission to the Amazon Cognito identity pool\nEach unique user who signs in receives a unique identity provided by the Cognito Identity authenticated pool. The authenticated pool policy applies to that identity, so make sure you add AWS IoT-specific permission to the IAM role policy for the authenticated pool.\nIn the Action for the allowed statement, add \xe2\x80\x9ciot:Connect\xe2\x80\x9d, \xe2\x80\x9ciot:Publish\xe2\x80\x9d, \xe2\x80\x9ciot:Subscribe\xe2\x80\x9d, \xe2\x80\x9ciot:Receive\xe2\x80\x9d, \xe2\x80\x9ciot:GetThingShadow\xe2\x80\x9d\nand \xe2\x80\x9ciot:AttachPrincipalPolicy.\xe2\x80\x9d I\xe2\x80\x99m adding the \xe2\x80\x9ciot:AttachPrincipalPolicy\xe2\x80\x9d for demonstration purposes only. You should not use it in production.\nTo create an AWS IoT policy for Amazon Cognito identities\nAn Amazon Cognito authenticated user needs two policies to access AWS IoT. The first policy is attached to the role of the authenticated pool to authenticate and authorize the Cognito user to communicate with AWS IoT. The second policy is attached to the authenticated Cognito user ID principal for fine-grained permissions.\nSign in to AWS IoT console.\nFrom the navigation pane, choose Secure , and then choose Policies.\nOn the Create a policy page, for Name, enter demo-policy.\nIn Add statements, for Action, enter iot:Connect. For Resource ARN, enter *.\nAdd another statement. For Action, enter iot:Publish. For Resource ARN, enter the topic name (demoTopic) at the end of resource ARN.\nChoose Create.\nTo register the user and get the Cognito Identity ID\nIn this blog post, I am using a JavaScript example from the amazon cognito auth JS GitHub repository.\nTo complete the app client setup for the demo, go back to the App client settings page in the Amazon Cognito console and grant permission to request code and choose allowed scopes. To set up redirect URLs, we\xe2\x80\x99ll use localhost.\nFor Callback URL(s) and Sign out URL(s), enter http://localhost:8000.\nUnder Allowed OAuth Flows, select Authorization code grant and Implicit grant.\nUnder Allowed OAuth Scopes, select email and openid.\n\nChoose Save changes.\nGet the domain name for your app client.\nIn the Amazon Cognito console, under App Integration, choose Domain name.\nEnter a domain name for your app (for example, iot\xe2\x80\x93).\nChoose Check availability.\n\nChoose Save changes.\nSample Code to Get Cognito Identity Credentials\nBecause the AWS IoT JavaScript SDK is in Node.js, it won\xe2\x80\x99t run directly in the browser. For this demo, I use Browserify to convert the SDK into browser-supported JavaScript.\nInstall the AWS IoT JavaScript SDK.\nCreate a file named AWSIotDeviceSdk.js with the following contents:\nvar AwsIot = require(\'aws-iot-device-sdk\');\nwindow.AwsIot = AwsIot; // make it global\nJavaScript\nInstall Browserify to make the demo to work with a browser.\nRun the following command in a terminal to browserify AWSIotDeviceSdk.js to bundle.js.\nterminal> browserify path/to/AWSIotDeviceSdk.js -o bundle.js\nBash\nDownload the latest version of the AWS JavaScript SDK.\nDownload this sample from amazon-cognito-auth-js.\nIn the sample\xe2\x80\x99s index.html, replace the sample code\xe2\x80\x99s initCognitoSDK JavaScript function as shown. Use your values to request an identity. Make sure you import the aws sdk js and bundle.js as shown in the code.\n    <script src=""/path/to/aws-sdk.js""></script>\n    <script src=""/path/to/bundle.js""></script>\n    <script type=""text/javascript"">\n      function initCognitoSDK() {\n        AWS.config.region = \'<REGION>\'; // like: us-east-1\n        var authData = {\n            ClientId: \'<YOUR_CLIENT_ID>\', // Your client id here\n            AppWebDomain: \'<YOUR APP WEB DOMAIN>\',\n            TokenScopesArray: [\'email\', \'openid\'], // e.g.[\'phone\', \'email\', \'profile\',\'openid\', \'aws.cognito.signin.user.admin\'],\n            RedirectUriSignIn: \'<REDIRECT_SIGN_IN_URI>\',\n            RedirectUriSignOut: \'<REDIRECT_SIGN_OUT_URI>\',\n            UserPoolId: \'<USER_POOL_ID>\', // Your user pool id here\n        };\n        var login = {};\n        var auth = new AmazonCognitoIdentity.CognitoAuth(authData);\n        auth.userhandler = {\n            onSuccess: function (result) {\n                //alert(""Sign in success"");\n                showSignedIn(result);\n                var loginKey = \'cognito-idp.\' + AWS.config.region + \'.amazonaws.com/\' + authData[\'UserPoolId\'];\n                login[loginKey] = result.getIdToken().getJwtToken();\n                AWS.config.credentials = new AWS.CognitoIdentityCredentials({\n                    IdentityPoolId: \'<COGNITO_IDENTITY_POOL_ID>\',\n                    Logins: login\n                });\n                AWS.config.credentials.refresh((error) => {\n                    if (error) {\n                        console.error(error);\n                    } else {\n                        var principal = AWS.config.credentials.identityId;\n                        console.log(""IdentityId: "" + principal);\n\n                        //Now we have cognito identity and credentials to make AWS IoT calls.\n                        //Attach pre-created IoT policy to this principal. \n                        //IMPORTANT: Make sure you have granted AttachPrincipalPolicy API permission in IAM to Cognito Identity Pool\'s Role.\n                        //It is done here for the demo purpose only while cognito user should NOT be allowed to call AttachPrincipalPolicy in production, this step must be done by Administrator only\n                        attachPrincipalPolicy(""demo-policy"", principal);\n\n                        //Now we can use this principal for IoT actions\n                        //We\'ll need aws-iot-device-sdk-js for mqtt over websocket calls using these cognito credentials.\n                        connect();\n                    }\n                });\n            },\n            onFailure: function (err) {\n                alert(""Error!"");\n            }\n        };\n        return auth;\n      }\n\n      //Need aws-sdk.js to work\n      function attachPrincipalPolicy(policyName, principal) {\n          new AWS.Iot().attachPrincipalPolicy({ policyName: policyName, principal: principal }, function (err, data) {\n            if (err) {\n                    console.error(err); // an error occurred\n                }\n          });\n       }\n       \n       //Need bundle.js to work\n       function connect() {\n            var clientID = \'webapp:\' + new Date().getTime(); //needs to be unique\n            device = AwsIot.device({\n                clientId: clientID,\n                host: \'<YOUR_AWS_IOT_ENDPOINT>\', //can be queried using \'aws iot describe-endpoint\'\n                protocol: \'wss\',\n                accessKeyId: AWS.config.credentials.accessKeyId,\n                secretKey: AWS.config.credentials.secretAccessKey,\n                sessionToken: AWS.config.credentials.sessionToken\n            });\n            device.on(\'connect\', function () {\n                console.log(""connected"")\n                publishMessage(device, \'demoTopic\', \'demo success!\')\n            });\n            function publishMessage(device, topic, msg) {\n                device.publish(topic, msg, { qos: 1 }, function (err) {\n                    if (err) {\n                        alert(""failed to publish iot message!"");\n                        console.error(err);\n                    } else {\n                        console.log(""published to demoTopic"");\n                        showMessage(""Message Published"", ""Topic: "" + topic, ""Message: "" + msg);\n                    }\n                });\n            }\n       }\n    </script>\nJavaScript\nNow we are ready to send MQTT messages over WebSocket to AWS IoT using Amazon Cognito Identity credentials.\nRun the local server to receive credentials back to the localhost callback URL, as defined in the app client settings.\nterminal> cd path/to/cognito/sample\nterminal> python3 -m http.server\nBash\nYou should get output like \xe2\x80\x98Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) \xe2\x80\xa6\xe2\x80\x99\nType http://localhost:8000/ in your browser to load our modified index.html from sample.\nChoose Sign In to create a user or sign in with an existing one.\nAfter you are signed in, you should see a message published to the AWS IoT demoTopic notification, as shown here.\nWe can also subscribe to the demoTopic from the AWS IoT console to see if this worked.\nIn the navigation pane, choose Test.\nUnder Subscribe to a topic, enter demoTopic, and then choose Subscribe to topic.\nTry refreshing the index.html page to publish the message again using the authenticated Cognito credentials. You should receive a message on the AWS IoT console.\n'"
227,Detect anomalies on connected devices using AWS IoT Device Defender,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/detect-anomalies-connected-devices/,"b'We often see security breaches depicted in media and popular culture. In the HBO series Silicon Valley, a compromised refrigerator is used by hacker Gilfoyle to run a malicious piece of software. The reality of connected devices isn\xe2\x80\x99t very different from this fictitious scenario.\nThe compromised refrigerator can send consumer data to unauthorized endpoints. Connected devices such as a connected refrigerator need to be secured to ensure safe operation of IoT applications.\nHowever, it can be a challenge for organizations to manage the security of connected devices. Despite all the security measures in place, a determined hacker such as Gilfoyle can still manage to infiltrate your connected devices. Detecting a compromised device is critical to taking timely action. AWS IoT Device Defender, in conjunction with an agent running on your device, enables you to detect abnormal device behavior and take necessary action.\nIn this article, we walk you through the following:\nSetting up a connected device to talk to AWS IoT Core\nDeploying and configuring an AWS IoT Device Defender agent for gathering diagnostic data from the device\nCreating cloud resources to monitor and detect misbehaving devices\nRunning a rogue agent on your device to simulate a compromised device\nValidating a notification being sent in response to malicious activity\nThe following diagram shows the high-level architecture for our setup\nSet up your connected device\nFollow these steps to create a representation of your device in AWS IoT Core, and generate the necessary security credentials to allow your device to talk to AWS IoT Core.\nLet\xe2\x80\x99s call the device \xe2\x80\x9cMyDevice\xe2\x80\x9d. At this point, you will have a \xe2\x80\x9cMyDevice\xe2\x80\x9d AWS IoT Thing created in your AWS account. You should also have downloaded a security certificate onto your device. The newly created device should appear in your AWS IoT console, as shown here.\nInstall and configure the AWS IoT Device Defender agent\nDownload the AWS IoT Device Defender agent into a folder \xe2\x80\x9cDDAgent\xe2\x80\x9d on your device.\nCopy the following x.509 certificate, private key, and root CA that you created previously during setup of connected device, into the \xe2\x80\x9cDDAgent\xe2\x80\x9d folder:\nMyDevice.cert.pem\nMyDevice.private.key\nroot-CA.crt\nRun the following command to start the AWS IoT Device Defender agent. You might have to run the agent with elevated privileges to allow it to collect necessary metrics.\nPython ./agent.py \\\n  --endpoint ""xxxxxxxxxxxx.iot.us-east-1.amazonaws.com"" \\\n  -r ./root-CA.crt -c ./MyDevice.cert.pem -k MyDevice.private.key \\\n  -id MyDevice  --format json -i 300\nBash\nThe AWS IoT Device Defender agent should now be publishing metrics and you should see logs in the terminal, as shown here.\nAWSIoTPythonSDK.core.protocol.mqtt_core - INFO - Performing sync publish...\nReceived a new message: \n{""thingName"":""MyDevice"",""reportId"":1532146181,""status"":""ACCEPTED"",""timestamp"":1532146183087}\nfrom topic: \n$aws/things/MyDevice/defender/metrics/json/accepted\nBash\nCreate cloud resources to monitor and detect abnormal behavior\nThe cloud infrastructure involves the following:\nGrouping devices in the form of an AWS IoT Thing Group to target anomaly detection.\nA security profile that defines anomalous behaviors for a group of devices or for all devices in your account, and that specifies what actions to take when an anomaly is detected.\nBehaviors that tell AWS IoT Device Defender how to recognize when a device is doing something abnormal. A behavior is defined using a metric, an operator on the metric, a value to compare the metric against and, in some cases, a time period.\nAn alert that is sent out when the device performs an action that does not match the behavior defined in step 2.\nAnomaly detection target grouping\nWe create an AWS IoT Thing Group named \xe2\x80\x9callMyDevices\xe2\x80\x9d to associate with the AWS IoT Device Defender security profile. We will add the \xe2\x80\x9cMyDevice\xe2\x80\x9d Thing we created above to this group.\nNavigate to the AWS IoT console.\nIn the Manage section, choose Groups.\nChoose Create.\nIn the Create a thing group dialog box, specify \xe2\x80\x9callMyDevices\xe2\x80\x9d for Name, and then choose Create thing group.\nYou should see the details of the newly created group, as shown here\nNow choose Add a thing under Actions, and select MyDevice.\nAlert\nWe will create an SNS notification, \xe2\x80\x9cMisbehavingDevices\xe2\x80\x9d, and add an email subscription to it.\nOpen the Amazon SNS console.\nChoose Create topic.\nName your topic \xe2\x80\x9cMisbehavingDevices\xe2\x80\x9d.\nChoose Create topic.\nChoose Create subscription under the newly created SNS topic, choose Email as the protocol, and provide your email address for Endpoint. Then choose Create subscription.\nYou will get an email at the end of this process. Follow the link in the email to complete the SNS notification process. Make a note of the ARN of the SNS topic we created. We will need this during the security profile definition.\nSecurity profile\nWe will now create a security profile named \xe2\x80\x9cCheckRogueDevices\xe2\x80\x9d, and associate it with the target grouping \xe2\x80\x9callMyDevices\xe2\x80\x9d that we created previously. We\xe2\x80\x99ll also add the alert \xe2\x80\x9cMisbehavingDevices\xe2\x80\x9d that we created.\nIn the security profile, we will add two behaviors: one cloud side and one device side. The device-side behavior is reported by the AWS IoT Device Defender agent that we installed previously.\nThe first behavior, \xe2\x80\x9cmsgReceive\xe2\x80\x9d, verifies that every five minutes the number of messages received from our device is less than 100. This behavior doesn\xe2\x80\x99t need any device-side agent to be running.}The second behavior, \xe2\x80\x9cbytesOut\xe2\x80\x9d, verifies that every five minutes the number of bytes sent out by the device is less than 10,000 (approximately 10 K). AWS IoT Device Defender relies on the agent to report this metric, so the agent must be running on the device for this metric.\n{\n  ""name"": ""bytesOut"",\n  ""metric"": ""aws:all-bytes-out"",\n  ""criteria"": {\n      ""comparisonOperator"": ""less-than"",\n      ""value"": {\n          ""count"": 10000\n      },\n      ""durationSeconds"": 300\n  }\n}\nJSON\nGo back to the AWS IoT Device Defender console. Navigate to Security profiles under the Defend, Detect section, and then choose Create. Name your security profile \xe2\x80\x9cCheckRogueDevices\xe2\x80\x9d. Create two behaviors: \xe2\x80\x9cmsgReceive\xe2\x80\x9d and \xe2\x80\x9cbytesOut\xe2\x80\x9d by selecting Add behavior and selecting the appropriate Metric, Operator, and Value, as shown in the following figure.\nChoose Detect, Security profiles, CheckRogueDevices. At this point you should see the following screen in your AWS IoT Device Defender console.\nRun the rogue agent\nNow let\xe2\x80\x99s simulate a hacked device by running an agent that generates random packets of data, sends them to AWS IoT Core, and also receives the same packets. The amount of traffic generated by this rogue agent is more that the criteria we have specified in the behaviors we created above and should be sufficient to generate AWS IoT Device Defender violations.\n  Here is the code snippet of the rogue agent that is generating malicious traffic.\n# MQTT message callback\ndef messageReceivedCallback(client, userdata, message):\n    print(\'From topic %s, Received data %s\\n\' % (message.topic, message.payload))\n\n# Connect and subscribe to AWS IoT\nrogueAgent.connect()\nrogueAgent.subscribe(topic, 1, messageReceivedCallback)\ntime.sleep(2)\n\n# Publish to the same topic in a loop forever every 1 sec\nwhile True:\n    message = {}\n    # Generate random 100 character string\n    message[\'message\'] = \'\'.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(100))\n    messageJson = json.dumps(message)\n    rogueAgent.publish(topic, messageJson, 1)\n    print(\'To topic %s: Published data: %s\\n\' % (topic, messageJson))\n    time.sleep(1)\nPython\nCopy the code for the rogueAgent.py file in the DDAgent folder you created earlier.\nRun the following command to start the rogue agent:\npython ./rogueAgent.py \\\n  --endpoint ""a2axmuvv63ixxq.iot.us-east-1.amazonaws.com"" \\\n  -r ./root-CA.crt -c ./MyDevice.cert.pem -k MyDevice.private.key \\\n  -id RogueAgent\nBash\nThe rogue agent should be sending and receiving random messages to AWS IoT Core. You should see messages in your console, as follows:\nPublished to topic /rogue/agent: Published data: {""message"": ""411BV90X7CO4XHOU77U3QFPJZ1E9JWVIZRMF9ET1QPFO6LY14FQF4WD6XFF9F6PP7SAHPIOEM6UHY0WNKBWQEWD1K8Y1UBF60V57""}\n\nFrom topic /rogue/agent, Received data {""message"": ""411BV90X7CO4XHOU77U3QFPJZ1E9JWVIZRMF9ET1QPFO6LY14FQF4WD6XFF9F6PP7SAHPIOEM6UHY0WNKBWQEWD1K8Y1UBF60V57""}\nBash\nViolation notifications\nGive the rogue agent about five minutes to do its job. The traffic from the rogue agent should result in two AWS IoT Device Defender violations: \xe2\x80\x9cmsgReceive\xe2\x80\x9d and \xe2\x80\x9cbyteOut\xe2\x80\x9d. You should get an email from the Amazon SNS notification for these violations. You can also view the violations in the AWS IoT Device Defender console. In the navigation pane, choose Defend, Detect, Violations:\n'"
228,How AWS IoT Core is Helping Customers Navigate the Upcoming Distrust of Symantec Certificate Authorities,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-core-ats-endpoints/,"b'NOTE: This blog post describes important public key infrastructure (PKI) issues related to browser and mobile application connectivity to AWS IoT Core. For information about public key certificates and TLS, see Chain of Trust and Certificate Authorities in High Performance Browser Networking.\nOverview\nGoogle, Apple, and Mozilla have announced that, starting October, 2018, they will deprecate trust in all Symantec root certificate authorities (CAs), including the VeriSign Class 3 Public Primary G5 root CA used to sign AWS IoT Core server certificates. For information, see the Google announcement, the Apple announcement, and the Mozilla announcement.\nThe decision to no longer include these CA certificates will disrupt mobile and web applications that rely on the certificate trust stores provided by their mobile operating systems or browsers. Users might see warning notifications in their browsers. Mobile applications might be unable to establish connections to their AWS IoT Core endpoints.\nDeprecating trust in a CA is a normal process on the internet. Web servers typically address this by switching to a different trusted CA to sign their server certificates. The process is transparent to end users because browsers include a large trust store with many CAs. In the IoT space, the story is a little bit more complicated. Due to memory constraints, devices might trust only a single CA and it might be difficult to update firmware on those devices to add new CA certificates. Changing the signing CA for a server certificate of an endpoint will prevent those devices from connecting to that endpoint.\nThe AWS IoT Core solution\nAWS IoT now provides additional customer endpoints that present Amazon Trust Services (ATS) signed server certificates. ATS CAs are trusted, by default, in most popular browsers and operating systems, including iOS, Android, Chrome, Firefox, Windows, and most common Linux distributions. Earlier this year, the AWS Security team published a blog post that outlined our efforts to migrate AWS services to ATS signed server certificates. Many AWS services, including Amazon DynamoDB and Amazon EC2, are already presenting these server certificates when customers call their APIs.\nTo maintain backward compatibility with devices that only trust server certificates signed by the VeriSign Class 3 Public Primary G5 root CA, AWS IoT Core will continue to provide endpoints that authenticate with server certificates signed by that CA. These certificates will continue to be renewed on a regular basis.\nWe strongly recommend that all customers use the following instructions to get their new Amazon Trust Services endpoint and use it in mobile and browser apps that connect to AWS IoT Core. We also recommend that customers start migrating their device fleets to trust Amazon Trust Services root CAs and connect to Amazon Trust Services endpoints.\nKeep these things in mind when you update your mobile or browser app or migrate your fleet:\nYou must explicitly request an Amazon Trust Services endpoint for each region in your account. Any existing customer endpoint you have is most likely a VeriSign endpoint. If your endpoint has \xe2\x80\x9c-ats\xe2\x80\x9d at the end of the first subdomain, then it is an Amazon Trust Services endpoint. For example, \xe2\x80\x98asdfasdf-ats.iot.us-east-2.amazonaws.com\xe2\x80\x99 is an ATS endpoint.\nIoT endpoints for jobs and the credentials provider are not affected. They are already serving Amazon Trust Services signed certificates.\nVeriSign and Amazon Trust Services endpoints in the same account and region are interoperable. The only difference between the endpoints is the root CA of the certificate they serve. Devices can switch back and forth (provided they have both certificates) and communicate with each other with no additional changes or registration. This means a phased transition is possible (and recommended).\nNew regions launched after May, 2018 serve Amazon Trust Services signed certificates only.\nRegion name Region Available root CAs*\nUS East (Ohio) us-east-2 VeriSign, ATS\nUS East (N. Virginia) us-east-1 VeriSign, ATS\nUS West (Oregon) us-west-2 VeriSign, ATS\nAsia Pacific (Singapore) ap-southeast-1 VeriSign, ATS\nAsia Pacific (Sydney) ap-southeast-2 VeriSign, ATS\nAsia Pacific (Tokyo) ap-northeast-1 VeriSign, ATS\nAsia Pacific (Seoul) ap-northeast-2 VeriSign, ATS\nEU (Frankfurt) eu-central-1 VeriSign, ATS\nEU (Ireland) eu-west-1 VeriSign, ATS\nEU (London) eu-west-2 VeriSign, ATS\nChina (Beijing) cn-north-1 VeriSign, ATS\nAsia Pacific (Mumbai) ap-south-1 ATS\nAWS GovCloud (US) us-gov-west-1 ATS\n*AWS IoT Core regions added in the future will support the Amazon Trust Services root CA only\nHow to set up your Amazon Trust Services endpoint\n Create your ATS endpoint\nCall the describe-endpoint API with the endpointType parameter set to iot:Data-ATS. In the AWS CLI, you can use the following command: aws iot describe-endpoint --endpoint-type iot:Data-ATS .\nIf successful, you should receive an endpoint in the form prefix-ats.iot.region.amazonaws.com. This API call is idempotent in the sense that the first call creates an endpoint, and subsequent calls return the same endpoint.\nDownload the ATS root CAs to your devices.\nRefer to the documentation on Server Authentication in AWS IoT Core and follow the links to the desired Amazon Trust Services CA Certificates (ex. RSA or ECC).\nSave these certificates as .pem files and copy them to your devices\nConnect Away!\nUpdate your mobile and browser apps and the firmware of your devices with the new endpoint.\nTest & Deploy!\nNOTE:  ATS endpoints are now presented by default in the console.  If you need to get a VeriSign endpoint, simply call the describe-endpoint API with no \xe2\x80\x9c\xe2\x80\x93endpoint-type\xe2\x80\x9d flag.  \nWorkaround on Java Development Kit (JDK) distrusting connections to endpoints with server certificates signed by Symantec CA\nOracle and OpenJDK have recently added a policy to distrust connections to endpoints with TLS server certificates issued after April 16, 2019 and anchored by a distrusted legacy Symantec root CA [1,2]. As part of standard security best practices, AWS IoT Core renews all server certificates of its endpoints on a regular basis. As such, all customer endpoints using server certificates signed by the VeriSign Class 3 Public Primary G5 root CA will be rejected by Java clients (8u212 or above, 7u221 or above, 11.0.3 or above), resulting in failure to connect. To continue to be able to connect to customer endpoints using server certificates signed by VeriSign Class 3 Public Primary G5 root CA, the following modifications are required:\nCreate a file to override the default JDK security policy and save it in your home folder (for example $HOME) with the name of symantec.policy. The file should contain the following text: jdk.security.caDistrustPolicies=null.\nReference the policy file when launching your Java virtual machine (JVM): Djava.security.properties=$HOME/symantec.policy where $HOME is the directory containing the symantec.policycreated in the previous step. This should make the JDK ignore the distrust policy set by default.\nVerify that the policy change took place by inspecting the Security property of the same name:\n// This variable should be null when the security property is applied to the VM, else it is SYMANTEC_TLS\nString policies = java.security.Security.getProperty(""jdk.security.caDistrustPolicies"");\nNote:\nSetting caDistrustPolicies=null will also remove any other distrust policies for the JVM. As of now, the only distrust policy supported by the JVM is SYMANTEC_TLS, but additional distrust policies may be added and will require modification. It is strongly recommended to adjust client software to connect to customer endpoints using ATS-signed server certificates instead.'"
229,Ensure Secure Communication with AWS IoT Core Using the Certificate Vending Machine Reference Application,b'Tatiana Cooke',2018-11-27T15:29:01+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/ensure-secure-communication-with-aws-iot-core-using-the-certificate-vending-machine-reference-application/,"b'X.509 certificates are used to ensure secure communication between IoT devices and AWS IoT Core. Devices use these certificates to connect to AWS IoT Core using TLS mutual authentication. AWS IoT Core uses TLS mutual authentication to encrypt data as it moves between AWS IoT Core and other devices or other AWS services.\nA X.509 certificate installed on devices must meet either of the following conditions:\nIt must be issued by AWS IoT Core.\nThe CA certificate used to sign an IoT device certificate must have already been imported into your AWS account and associated with your AWS IoT implementation\nBecause we understand that you have devices that do not meet these conditions, we provide a reference application called Certificate Vending Machine (CVM) to demonstrate how you can provision devices with certificates created in AWS IoT Core. This blog post provides the design ideas and associated source code to help you get started with CVM.\nWho should use CVM?\nCertificate Vending Machine is ideal for those who do not have certificates preinstalled on devices and cannot use CA certificates to provision device certificates during the manufacturing process. You can use CVM to allow the device to apply for its own certificate. Because the IoT device in our example does not have a certificate for TLS mutual authentication, we need to pay attention to three points:\n\xc2\xb7       To prevent a man-in-middle attack when devices and CVM are communicating, the server certificate should be used to validate the authenticity of the endpoint. Specifically, when generating device certificates, there must be secured communication, such as TLS tunnel or IPsec VPN, between the device and CVM.\n\xc2\xb7      An IoT device that requests a certificate should have a unique identifier, such as a serial number, client ID, or product ID that will be used for policy binding and to ensure that the device is valid.\n\xc2\xb7      All certificates submitted by CVM are AWS IoT Core certificates. If you need to use a custom CA certificate, you can use bulk provisioning. For more information, see the Just-in-Time Registration of Device Certificates on AWS IoT blog post.\n  Implementation methodology\nThe CVM implementation can be divided into three modules: IoT devices, CVM server, and AWS IoT Core.\nIoT device\nRequests a device certificate via HTTPS connection.\nSubmits the device serial number and the registration token when requested. The registration token is a one-time token to avoid device serial number spoofing.\nCVM server\nProvides remote access to IoT devices for certificate application.\nGenerates secured certificate for each IoT device that can be used to communicate to AWS IoT Core.\nUses DynamoDB to store information such as the device ID, key registration information, and the applied device certificate.\nAssociates IoT thing name, certificate policy, and certificate ID by querying the association table in DynamoDB. In parallel, CVM modifies the certificate status attribute in DynamoDB to ensure that a device can only register for a single active certificate.\nAWS IoT Core\nGenerates the certificate and private key pair that is then vended to an individual IoT device.\n  Here is the basic CVM workflow:\nHere is the CVM architecture:\n  Using Amazon API Gateway and AWS Lambda for scalability, here is the workflow:\nWhen the IoT device requests access to AWS IoT Core, it triggers a certificate application to CVM. The IoT device sends an API call to API Gateway for IoT device certificate application.\nAPI Gateway invokes Lambda to initiate a certificate request to AWS IoT Core.\nAfter it receives the request from API Gateway, Lambda checks Amazon DynamoDB to validate the request is legitimate and then applies to AWS IoT Core for a certificate.\nCVM uses the AWS SDK to make a series of API calls to AWS IoT Core. These API calls perform actions such as creating a thing in the registry and creating an associated device certificate.\nAWS IoT Core generates a device certificate and key pairs and returns the certificate information and the certificate ID to CVM.\nLambda uses a series of API calls to associate the thing name, certificate, and policy on AWS IoT Core by querying a DynamoDB association table according to product serial number.\nAWS Lambda updates the DynamoDB association table with information for the current device.\nCVM returns the certificate to the IoT device.\n  Security\nTo ensure the security of CVM, the AWS Lambda function must be scoped to the minimum permissions required to create a device in AWS IoT Core. To complete the certificate application and the issuance process, CVM must have IAM permissions to:\nAccess DynamoDB for querying, modifying, and updating device associations in the DynamoDB table.\nAccess AWS IoT Core to request X.509 certificates and attach IoT policies to certificates.\n  The following steps show how to assign the correct IAM role permissions to CVM. Here is the policy example for the IAM role with restricted permission for CVM only.\n  {\n     ""Version"": ""2012-10-17"",\n     ""Statement"": [\n     {\n        ""Sid"": ""IoTCWlogsPolicy"",\n        ""Effect"": ""Allow"",\n        ""Action"": [\n                ""logs:*"",\n                ""iot:CreateThing"",\n                ""iot:AttachPolicy"",\n                ""iot:AttachThingPrincipal"",\n                ""iot:CreatePolicy"",\n                ""iot:CreateKeysAndCertificate""\n         ],\n        ""Resource"": ""*""\n        },\n     {\n        ""Sid"": ""cvmDynamodbPolicy"",\n        ""Effect"": ""Allow"",\n        ""Action"": [\n                ""dynamodb:Query"",\n                ""dynamodb:UpdateItem""\n        ],\n       ""Resource"": ""arn:aws:dynamodb:us-west-2:xxxxxxxxxxxx:table/{table_name}""\n     }\n  ]\n}\nNow add a trust relationship so that AWS Lambda can assume this role.\n\nYou need to create an association table in DynamoDB for the binding relationship between the device, certificate, and policy. Specifically, you need to create the following database fields in DynamoDB:\nProduct ID: IoT device ID\nAccess token: IoT token\ntimestamp: certificate request timestamp\napplyState: request status (if the certificate is set to -1, it means that the device has already registered the certificate)\ncertID: certificate ID associated with the device\nThis table will be used to record all device certificate application progress to ensure only an authorized device is able to apply for a device certificate.\n  Code description\nThe following CVM reference source code uses the AWS IoT Core interface provided by the  AWS SDK for JavaScript in Node.js to complete the certificate request and add the associated thing name and policy.\n  //Use createKeysAndCertificate to create certificate\xef\xbc\x8cThis API will response certificate and certificate ID\n\niot.createKeysAndCertificate (params = {}, callback) \xe2\x87\x92 AWS.Request\n\n# if CSR is in use, you can use following API call\n\n# iot.createCertificateFromCsr(params = {}, callback) \xe2\x87\x92 AWS.Request\n\n//Attach policy to current certificate\n\niot.attachPrincipalPolicy(params = {}, callback) \xe2\x87\x92 AWS.Request\n\n//Attach IoT thing name to current certificat\n\niot.attachThingPrincipal(params = {}, callback) \xe2\x87\x92 AWS.Request\n    You\xe2\x80\x99ll find the source code for CVM in GitHub using the following link:\nhttps://github.com/awslabs/aws-iot-certificate-vending-machine\n  '"
230,Using AWS IoT for Predictive Maintenance,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-aws-iot-for-predictive-maintenance/,"b'The interest in machine learning for industrial and manufacturing use cases on the edge is growing. Manufacturers need to know when a machine is about to fail so they can better plan for maintenance. For example, as a manufacturer, you might have a machine that is sensitive to various temperature, velocity, or pressure changes. When these changes occur, they might indicate a failure.\nPrediction, sometimes referred to as inference, requires machine-learning (ML) models based on large amounts of data for each component of the system. The model is based on a specified algorithm that represents the relationships between the values in the training data. You use these ML models to evaluate new data from the manufacturing system in near real-time. A predicted failure exists when the evaluation of the new data with the ML model indicates there is a statistical match with a piece of equipment in the system.\nTypically, an ML model is built for each type of machine or sub-process using its unique data and features. This leads to an expansive set of ML models that represents each of the critical machines in the manufacturing process and different types of predictions desired. Although the ML model supports inference of new data sent to the AWS Cloud, you can also perform the inference on premises, where latency is much lower. This results in a more real-time evaluation of the data. Performing local inference also saves costs related to the transfer of what could be massive amounts of data to the cloud.\nThe AWS services used to build and train ML models for automated deployment to the edge make the process highly scalable and easy to do. You collect data from the machines or infrastructure that you want to make predictions on and build ML models using AWS services in the cloud. Then you transfer the ML models back to the on-premises location where they are used with a simple AWS Lambda function to evaluate new data sent to a local server running AWS Greengrass.\nAWS Greengrass lets you run local compute, messaging, ML inference, and more. It includes a lightweight IoT broker that you run on your own hardware close to the connected equipment. The broker communicates securely with many IoT devices and is a gateway to AWS IoT Core where selected data can be further processed. AWS Greengrass can also execute AWS Lambda functions to process or evaluate data locally without an ongoing need to connect to the cloud.\nBuilding ML models\nYou need to build and train ML models before you start maintenance predictions. A high-level ML process to build and train models applies to most use cases and is relatively easy to implement with AWS IoT.\nStart by collecting supporting data for the ML problem that you are trying to solve and temporarily send it to AWS IoT Core. This data should be from the machine or system associated with each ML model. A dedicated AWS Direct Connect connection between the on-premises location of the machines and AWS IoT Core supports high-volume data rates. Depending on the volume of data you are sending to the cloud, you might need to stagger the data collection for your machines (that is, work in batches).\nAlternatively, an AWS Snowball appliance can transfer large amounts of data to your private AWS account using a secure hardened storage device you ship with a package delivery service. The data is transferred from AWS Snowball to Amazon S3 buckets you designate in your account.\nAWS IoT Analytics supports the efficient storage of data and pipeline processing to enrich and filter the data for later use in ML model building. It also supports feature engineering in the pipeline processing with custom AWS Lambda functions that you can write to derive new attributes to help classify the data. You can visualize the results of the pipeline processing in AWS IoT Analytics using Amazon QuickSight to validate any transformations or filters you apply.\nAmazon SageMaker supports direct integration with AWS IoT Analytics as a data source. Jupyter Notebook templates are provided to get you started quickly in building and training the ML model. For predictive maintenance use cases, linear regression and classification are the two most common algorithms you can use. There are many other algorithms to consider for time-series data prediction and you can try different ones and measure the effectiveness of each in your process. Also consider that AWS Greengrass ML Inference supports Apache MXNet, TensorFlow and Chainer pre-built packages that make deployment easier. Either of these ML frameworks simplify the deployment process to AWS Greengrass, but you can use others with additional setup. For example, you could use the popular Python library scikit-learn to analyze data.\nCost-optimized\nMany users like the elasticity of the AWS Cloud combined with its pay-for-what-you-use pricing structure. When ML models are built and trained or later retrained, large amounts of raw data are sent to AWS IoT Core. In addition, you need large amounts of compute to speed the processing along using Amazon SageMaker. When the ML models are complete, you can archive the raw data to a lower cost storage service with Amazon Glacier or delete it. The compute resources allocated for the training are also released and costs decrease.\nDeploying ML models to the edge\nRunning predictions locally requires the real-time machine data, ML model, and local compute resources to perform the inference. AWS Greengrass supports deploying ML models built with Amazon SageMaker to the edge. An AWS Lambda function performs the inference. Identical machines can receive the same deployment package that contains the ML model and inference Lambda function. This creates a low-latency solution. There is no dependency on AWS IoT Core to evaluate real-time data and send alerts or commands to infrastructure to shut down, if required.\nRunning local predictions\nThe AWS Lambda function linked to the ML model as part of the AWS Greengrass deployment configuration performs predictions in real time. The AWS Greengrass message broker routes selected data published on a designated MQTT topic to the AWS Lambda function to perform the inference. When an inference returns a high probability of a match, then multiple actions can be executed in the AWS Lambda function. For example, a shutdown command can be sent to a machine or, using either local or cloud messaging services, an alert can be sent to an operations team.\nFor each ML model, you need to determine the threshold for inference confidence that equates to a predicted failure condition. For example, if an inference for a machine you are monitoring indicates with high confidence (let\xe2\x80\x99s say a level of 90%), then you would take appropriate action. However, if the confidence level is 30%, then you might decide not to act on that result. You can use using AWS IoT Core to publish inference results on a dedicated logging and reporting topic.\nAnother consideration for running inference locally is ensuring you have a large enough server or multiple servers to support the amount of compute required. Factors that influence hardware sizing include:\nNumber of machines being monitored (for example, is it 1 or 100 machines?)\nAmount of data sent from each machine (for example, is it 50,000 bytes or 1,000 bytes?)\nThe rate at which data is sent from each machine (for example, is it once a minute or every 10 milliseconds?)\nHow CPU-intensive is the ML model when performing inference and what are the memory requirements? (Some models require more system resources and might benefit from GPUs, for example.)\nWhat other processing is occurring on the host and are any processes resource-intensive?\nSystem architecture\nThe end-to-end architecture includes:\nThe collection of data to build and train a model.\nThe deployment of models back to the factory.\nThe evaluation of data to perform local inference.\nAWS Greengrass supports accessing local resources and AWS IoT Core to help keep your manufacturing process up and running.\nTestimonial: Environment Monitoring Solutions sees 500% ROI by using AWS IoT\nEnvironmental Monitoring Solutions specializes in solutions that help petrol retailers gather and analyze data on the performance of their petrol stations. By using AWS IoT to detect fuel leaks early to minimize environmental impact, the company received a 500% ROI. AWS IoT made it possible to connect sensors in the underground tanks and pumps of each petrol station and collect all data at 30-second intervals. The data is aggregated on cloud-computing infrastructure and displayed on a web-enabled interface in near-real time.\nAccording to Russell Dupuy, the company\xe2\x80\x99s founder and managing director, \xe2\x80\x9cWith our AWS IoT\xe2\x80\x93enabled Fuelsuite solution, customers manage their petrol stations proactively rather than reactively\xe2\x80\xa6 to dramatically improve efficiencies and detect fuel leaks early to minimize environmental impacts.\xe2\x80\x9d\nSee for yourself. Get started today using AWS IoT for predictive maintenance.\nLearn More:\nIndustrial Internet of Things: https://aws.amazon.com/iot/solutions/industrial-iot/\nAWS IoT: https://aws.amazon.com/iot/\nAWS IoT Analytics User Guide: https://docs.aws.amazon.com/iotanalytics/latest/userguide/welcome.html\nAmazon Sagemaker \xe2\x80\x93 Getting Started Developer Guide: https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html\nML model building: https://aws.amazon.com/blogs/machine-learning/predict-march-madness-using-amazon-sagemaker/'"
231,Using Continuous Jobs with AWS IoT Device Management,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-continuous-jobs-with-aws-iot-device-management/,"b'In an earlier Using Over-the-Air Updates with AWS IoT Device Management blog post, we showed you how to create a simple AWS IoT snapshot job and track its progress. In this post, we will show you step-by-step how to configure and create an AWS IoT continuous job. A continuous job is a long running job that reacts to changes to your deployment targets by automatically deploying job executions. For example, a continuous job can be deployed to an initial group of 100 devices. When new devices are added to your deployment group, those new devices will automatically be notified about the continuous job.\nA continuous job is useful when:\nA factory reset is performed on a device that resets its software to v1. A continuous job can automatically update a device\xe2\x80\x99s software to the latest version after it is reset to v1.\nA device with an older firmware version is turned on after sitting in the warehouse for several months. A continuous job can update the device firmware to the latest version.\nA device is recycled. A continuous job can remove all pending job executions on the device.\nIn the next few sections, we are going to create a continuous job continuous-job-V1-to-V2 to update devices\xe2\x80\x99 firmware version from V1 to V2. Devices with firmware version V1 are grouped by thing group FirmwareV1Group, and devices with firmware version V2 are grouped by thing group FirmwareV2Group. Once a device successfully updates to firmware V2, a pre-configured Lambda function will automatically remove this device from FirmwareV1Group and add to FirmwareV2Group. While continuous job continuous-job-V1-to-V2 is running, new devices that got added to FirmwareV1Group will also automatically get the V2 firmware update job. The steps are\nCreate firmware deployment groups\nAdd thing to the initial deployment group\nConfigure and test a Lambda function to move device between deployment groups\nCreate a continuous job for firmware V1 to V2 update\nConfigure Deployment Groups\nFirst, we are going to create three thing groups, each with a different firmware version (V1, V2, V3).\n$ aws iot create-thing-group --thing-group-name ""FirmwareV1Group""\n$ aws iot create-thing-group --thing-group-name ""FirmwareV2Group""\n$ aws iot create-thing-group --thing-group-name ""FirmwareV3Group""\nPowerShell\nIn this example, the device is registered with thing name MyRaspberryPi. Add MyRaspberryPi to thing group FirmwareV1Group.\n$ aws iot add-thing-to-thing-group \\\n--thing-name ""MyRaspberryPi"" \\\n--thing-group-name ""FirmwareV1Group""\nPowerShell\nIn a real scenario when a device starts up, we recommend that you run a startup program to bring your device online and initialized its settings. In the startup program, you can add the device to corresponding deployment group. In addition, the program that resets the device to factory settings should also include a step to add the device to corresponding deployment group.\nConfigure a Lambda Function\nWe are going to write a Lambda function that is triggered whenever a device is successfully updated from firmware version V1 to V2. This Lambda function does the following:\nRemoves the thing from thing group FirmwareV1Group.\nAdds the thing to ThingGroup FirmwareV2Group.\nFirst, navigate to the IAM console to create a role, LambdaRoleForV1ToV2FirmwareUpdate, with the following policy. Replace AWS_REGION with your AWS region and <AWS_ACCOUNT_ID> with your AWS account ID.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""logs:CreateLogGroup"",\n        ""logs:CreateLogStream"",\n        ""logs:PutLogEvents""\n      ],\n      ""Resource"": ""arn:aws:logs:*:*:*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:RemoveThingFromThingGroup""\n      ],\n      ""Resource"": ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_ID>:thinggroup/FirmwareV1Group""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""iot:AddThingToThingGroup""\n      ],\n      ""Resource"": ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_ID>:thinggroup/FirmwareV2Group""\n    }\n  ]\n}\nJSON\nNavigate to the AWS Lambda console. On the Create function page, select Blueprints. Under Blueprints, choose hello-world, and then choose Configure.\n\nUnder Basic information, type a name for this Lambda function. For Role, choose the role you created in the previous step (LambdaRoleForV1ToV2FirmwareUpdate), and then choose Create function.\n\nOn the next page, update the function code with the following code snippet, and then choose Save.\n  \'use strict\';\n\nconsole.log(\'Loading function\');\n\n// Load the AWS SDK\nvar AWS = require(""aws-sdk"");\n\n// Set up the code to call when the Lambda function is invoked\nexports.handler = (event, context, callback) => {\n    // Log a message to the console, you can view this text in the Monitoring tab\n    // in the Lambda console or in the CloudWatch Logs console\n    console.log(""Received event:"", event);\n    console.log(""Thing Arn is:"", event.thingArn);\n    \n    var iot = new AWS.Iot();\n    \n    // Remove the thing from V1 group\n    var removeParams = {\n        thingGroupName: ""FirmwareV1Group"",\n        thingArn: event.thingArn\n    };\n    iot.removeThingFromThingGroup(removeParams, function(err, data) {\n        if (err) console.log(err, err.stack); // an error occurred\n        else console.log(data);               // successful response\n    });\n    \n    // Add the thing to V2 Group\n    var addParams = {\n        thingGroupName: ""FirmwareV2Group"",\n        thingArn: event.thingArn\n    };\n    iot.addThingToThingGroup(addParams, function(err, data) {\n        if (err) console.log(err, err.stack); // an error occurred\n        else console.log(data);               // successful response\n    });\n\n};\nJavaScript\nTo configure the trigger for this Lambda function, under Designer, choose AWS IoT. In the Configure triggers section, we will create a custom IoT rule to filter succeeded job executions events for a continuous job with the job ID continuous-job-V1-to-V2. To learn more about Job Events, see Job Events documentation in the AWS IoT Developer Guide. Create a new rule named \xe2\x80\x9cSucceededJobExecutionsForV1toV2Update\xe2\x80\x9d, and input the following SQL statement for the Rule query statement:\nSELECT * FROM \'aws/events/jobExecution/continuous-job-V1-to-V2/succeeded\'\nSQL\nAfter you have configured the trigger, click Add and then click Save.\nTest the Lambda Function\nTo test the Lambda function, configure a test event in the AWS Lambda console. From Select a test event, choose Configure test events.\n\nName the test event SucceededJobExecution, and replace the test event payload with the following job execution event payload. Replace AWS_REGION with your AWS region and <AWS_ACCOUNT_ID> with your AWS account ID. Choose Create to save your changes.\n{\n  ""eventType"": ""JOB_EXECUTION"",\n  ""eventId"": ""ba44f124-61fd-40c8-b747-f7f00a50515c"",\n  ""timestamp"": 1519870643,\n  ""operation"": ""succeeded"",\n  ""jobId"": ""continuous-job-V1-to-V2"",\n  ""thingArn"": ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_ID>:thing/MyRaspberryPi"",\n  ""status"": ""SUCCEEDED""\n}\nJSON\nAfter you have created the test event, you are directed back to the AWS Lambda console. Select the SucceededJobExecution test event, and choose Test. You should see the thing MyRaspberryPi is removed from FirmwareV1Group and add to FirmwareV2Group from AWS IoT console. For information about creating a Lambda function and how to monitor and debug a Lambda function with CloudWatch, see Create a Simple Lambda Function in the AWS Lambda Developer Guide.\nCreate a Continuous Job to Update Firmware\nNow create a continuous job, continuous-job-V1-to-V2, on thing group FirmwareV1Group.\n$ aws iot create-job \\\n--job-id ""continuous-job-V1-to-V2"" \\\n--targets ""arn:aws:iot:<AWS_REGION>:<AWS_ACCOUNT_ID>:thinggroup/FirmwareV1Group"" \\\n--document file://<DIRECTORY_TO_JOB_DOCUMENT>/FirmwareUpdateV1ToV2.json \\\n--description ""Continuous job to update firmware from V1 to V2"" \\\n--target-selection CONTINUOUS\nPowerShell\nWhen the continuous-job-V1-to-V2 job is in progress, it will notify all target devices that belong to the FirmwareV1Group thing group about the job. Each device executes the job and reports its job execution status. For each successful job execution, the Jobs service sends a job execution event. The job execution event triggers the Lambda function, which removes devices from FirmwareV1Group and adds them to FirmwareV2Group.\nConfigure Continuous Deployments\nWe\xe2\x80\x99ve walked through how to create a continuous job on deployment group FirmwareV1Group to update the firmware version on devices from V1 to V2. We\xe2\x80\x99ve shown how to remove the device from FirmwareV1Group and add it to FirmwareV2Group after the device has successfully executed the job. So how about updating V2 devices to V3?\nTo bring device firmware up to date, you can create another continuous job, continuous-job-V2-to-V3, on the FirmwareV2Group deployment group, and configure a similar Lambda function to remove a device from FirmwareV2Group and add it to FirmwareV3Group.\nContinuous jobs do not have to be incremental. Whether your update model is an incremental update or a direct update to a specific version, it is easy to create a continuous job to bring your devices to the desired state. For example, say you have 10 different firmware versions available: V1 \xe2\x80\x94 V10. Due to a compatibility issue between some versions, V1, V2, and V3 can only be directly updated to V7, not to V10. All other versions can be directly updated to V10. With continuous jobs, you can easily set up one job for V1, V2, and V3 deployment groups and update devices to V7. You can set up another job for V4 \xe2\x80\x94 V9 deployment groups and update devices to V10. By the time a newer version, V11, is released, you can easily create a third continuous job on the V10 deployment group and update devices to V11.\n'"
232,Using Chainer Neural Network Framework with AWS Greengrass ML Inference,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-chainer-neural-network-framework-with-aws-greengrass-ml-inference/,"b'Starting today, Greengrass ML inference includes a pre-built Chainer package for all devices powered by Intel Atom, NVIDIA Jetson TX2, and Raspberry Pi. So, you don\xe2\x80\x99t have to build and configure the ML framework for your devices from scratch. With this launch, we now provide pre-built packages for three popular machine learning frameworks including TensorFlow, Apache MXNet, and Chainer. This blog post shows how to use Chainer with AWS Greengrass ML.\nAs a deep learning framework, Chainer Neural Network has been added to Greengrass MLI for several reasons.\nEmpowers data scientists to take advantage of flexibility, power, and efficiency.\nFosters quick iterative experiments and uses a bi-directional computational approach (forward-backwards) to converge on the best performing model.\nUses familiar Python-based programing concepts complemented with dynamic network construction scheme and popular open source matrix libraries.\nChainer works in a similar fashion as existing Greengrass ML frameworks in that it depends on a library on the Greengrass and a set of model files generated using Amazon SageMaker and/or stored directly in an Amazon S3 bucket. From Amazon SageMaker or Amazon S3 the ML models can be deployed to AWS Greengrass to be used as a local resource for ML inference.\nConceptually, AWS IoT Core functions as the managing plane for deploying ML inference to the edge. A typical IoT analytics and ML cycle is represented below.\nData is generated by device sensors and sent to AWS Greengrass and then on to AWS IoT Core. Data is also consumed by ML models deployed to AWS Greengrass.\nAn AWS IoT rule sends the data to a channel on AWS IoT Analytics and a cleansed, transformed, and enriched data set is generated using a pipeline.\nAWS IoT Analytics data sets are consumed by ML modeling with the goal to generate trained ML models that can be stored in Amazon S3 and Amazon SageMaker from where, in conjunction with Lambda functions, can be deployed to AWS Greengrass for ML inference. When deploying an ML model to AWS Greengrass please note that it can originate in an Amazon S3 bucket or Amazon SageMaker.\n  From AWS IoT Core, Software, then Machine Learning Libraries select Chainer, the platform you are using, and then Configure Download. Move/copy the entire .gz file to your Greengrass, uncompress, and run the install.\n  On the defined AWS Greengrass group you can add Chainer model files as a Machine Learning resource.\nAnd then add a model from either Amazon SageMaker or from an Amazon S3 bucket.\nMultiple ML models can be added to a Greengrass group at the same time and for each one of them there must exist a corresponding Lambda function association.\nFrom this point on, Chainer ML models can be consumed for AWS Greengrass ML inference by following existing documentation.\nFor step-by-step details on setting up AWS Greengrass ML Inference please consult the developer\xe2\x80\x99s guide at https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-inference.html and https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-console.html.\n     '"
233,How M3 Health Used AWS IoT 1-Click to Improve Healthcare Delivery,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-m3-health-used-aws-iot-1-click-to-improve-healthcare-delivery/,"b'M3 Health is a strategic technology partner serving the healthcare and life sciences industries. With almost 20 years of experience developing and delivering innovative technology solutions, they enable their clients to better engage their audience, and solve the challenges they face to improve communications, drive sales, and ensure customer loyalty. When they decided to create a new product to address the challenges of connecting Pharmaceutical & Biotechnology companies to Healthcare Providers and Patients, they chose to build their technology solution using AWS IoT 1-Click, a new IoT service from Amazon Web Services.\nOne of the main problems facing healthcare is maintaining effective communication between Pharmaceutical & Biotechnology companies and their stakeholders. Healthcare providers are dealing with complicated and growing volumes of information on the available treatments for their patients and need a quick and convenient way to connect to these companies to get the service they need at the time they need it. Patients have to maintain compliance with their therapy while continuing to manage the burdens of everyday life and navigating the puzzling roadblocks presented by a complex healthcare system, and need a way easily connect with their providers to get the help and information they need. Pharmaceutical & Biotechnology companies need a secure, clear, and engaging method of connecting to each of these stakeholders.\nAWS IoT 1-Click is a service that enables simples devices to trigger AWS Lambda functions that execute an action. The devices supported on AWS IoT 1-Click are pre-provisioned with certificates to securely connect to AWS IoT right out of the box. At launch, the service supports the new AWS IoT Enterprise Button to connect over Wi-Fi and the AT&T LTE-M Button to connect over the cellular network. You can use any of these devices to enable quick and easy customer interactions, while leveraging the power of AWS IoT and AWS Lambda to integrate with backend systems to schedule re-supply or deliver educational material. For further simplicity, the service also comes with a mobile app for configuration on the move.\nPing\xe2\x84\xa2 System Architecture\nM3 Health leveraged AWS IoT 1-Click to build a solution called Ping\xe2\x84\xa2. AWS IoT 1-Click brings together all the features that M3 Health needed to solve the problem of Pharmaceutical & Biotechnology companies connecting to Healthcare Providers and Patients by enabling them to easily deploy thousands of buttons to customers without a complicated provisioning process. AWS IoT Enterprise and the AT&T LTE-M buttons are provisioned in advance at the factory, but the AWS IoT 1-Click app can also be used to perform just-in-time provisioning while a salesperson is visiting. Once deployed, Healthcare Providers and/or Patients can simply press their IoT buttons in their sample closet or medicine cabinet to contact sales repre sentatives and get the information needed in order to write proper prescriptions or get educational materials. AWS Lambda\xe2\x80\x99s ability to integrate with other AWS services also makes it easy to attach other services such as Amazon Connect and Amazon Lex, allowing M3 Health to provide amazing automated language support through Alexa to both Healthcare providers and Patients.\nCustomers can easily get started using AWS IoT 1-Click with supported devices that can be ordered here. Device manufacturers can easily onboard devices on to AWS IoT 1-Click by contacting us here.'"
234,How to Implement MQTT with TLS Client Authentication on Port 443 from Client Devices (Python),b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-implement-mqtt-with-tls-client-authentication-on-port-443-from-client-devices-python/,"b'Application Layer Protocol Negotiation (ALPN) is an extension to TLS that enables clients connecting to a TLS server to pass an extra parameter, known as a ProtocolNameList. The ProtocolNameList is a preference-ordered list of the application protocols that the client would like to use to communicate. AWS IoT Core now allows you to connect devices over MQTT with TLS client authentication on port 443 using the ALPN TLS extension. For background about why this is useful, see this blog post.\nIn this blog post, I will walk you through two ways to connect your devices to AWS IoT Core over MQTT on port 443.\nMethod 1: Using Paho-MQTT client and OpenSSL\nMost common TLS implementations, including OpenSSL and mbedTLS support the ALPN TLS extension. In this example, we will use a Paho-mqtt client and the OpenSSL library to connect your devices to the AWS IoT endpoint.\nPrerequisites\nBefore you connect your devices, check the software version of Python and OpenSSL to ensure they support ALPN extension.\nPython 2.x: you need version 2.7.10 or later\nPython 3.x: you need version 3.5 or later\nOpenSSL: you need version 1.0.2 or later\nTo check your environment\n1.     Check the OpenSSL version:\nopenssl version\nOpenSSL 1.0.2k-fips  26 Jan 2017\n2.     Check the Python version.\npython --version\nPython 2.7.13\n3.     Check the version of OpenSSL that Python references.\npython\n>>> import ssl\n>>> print ssl.OPENSSL_VERSION\nOpenSSL 1.0.2k-fips  26 Jan 2017\n\n*If the reference is to older version of OpenSSL, you have to update it.\nThis sample script uses Paho as the MQTT library to publish messages. The latest stable version of the Paho-MQTT client is available in Python Package Index (PyPi). Install it using pip:\npip install paho-mqtt\nEach connected device must have a credential to access the message broker or the Device Shadow service. The sample script uses X.509 certificates as an authentication mechanism to connect to the AWS IoT endpoint. You can use the AWS IoT console or CLI to create an AWS IoT certificate. For more information, see Create and Register an AWS IoT Device Certificate in the AWS IoT Developer Guide and create-keys-and-certificate in the AWS CLI Command Reference.\nThe following very simple example creates a connection to the AWS IoT endpoint and publishes a message to it. Copy the following script into a file and save the file as alpn_mqtt.py.\nfrom __future__ import print_function\nimport sys\nimport ssl\nimport time\nimport datetime\nimport logging, traceback\nimport paho.mqtt.client as mqtt\n\nIoT_protocol_name = ""x-amzn-mqtt-ca""\naws_iot_endpoint = ""AWS_IoT_ENDPOINT_HERE"" # <random>.iot.<region>.amazonaws.com\nurl = ""https://{}"".format(aws_iot_endpoint)\n\nca = ""YOUR/ROOT/CA/PATH"" \ncert = ""YOUR/DEVICE/CERT/PATH""\nprivate = ""YOUR/DEVICE/KEY/PATH""\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)\nhandler = logging.StreamHandler(sys.stdout)\nlog_format = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\nhandler.setFormatter(log_format)\nlogger.addHandler(handler)\n\ndef ssl_alpn():\n    try:\n        #debug print opnessl version\n        logger.info(""open ssl version:{}"".format(ssl.OPENSSL_VERSION))\n        ssl_context = ssl.create_default_context()\n        ssl_context.set_alpn_protocols([IoT_protocol_name])\n        ssl_context.load_verify_locations(cafile=ca)\n        ssl_context.load_cert_chain(certfile=cert, keyfile=private)\n\n        return  ssl_context\n    except Exception as e:\n        print(""exception ssl_alpn()"")\n        raise e\n\nif __name__ == \'__main__\':\n    topic = ""test/date""\n    try:\n        mqttc = mqtt.Client()\n        ssl_context= ssl_alpn()\n        mqttc.tls_set_context(context=ssl_context)\n        logger.info(""start connect"")\n        mqttc.connect(aws_iot_endpoint, port=443)\n        logger.info(""connect success"")\n        mqttc.loop_start()\n\n        while True:\n            now = datetime.datetime.now().strftime(\'%Y-%m-%dT%H:%M:%S\')\n            logger.info(""try to publish:{}"".format(now))\n            mqttc.publish(topic, now)\n            time.sleep(1)\n\n    except Exception as e:\n        logger.error(""exception main()"")\n        logger.error(""e obj:{}"".format(vars(e)))\n        logger.error(""message:{}"".format(e.message))\n        traceback.print_exc(file=sys.stdout)\nPython\nRun the Python script\nRun the Python script you created by executing the following command:\npython alpn_mqtt.py\n\n2018-03-15 11:03:25,174 - root - INFO - start connect \n2018-03-15 11:03:25,254 - root - INFO - connect success \n2018-03-15 11:03:25,255 - root - INFO - published:<timestamp> \n2018-03-15 11:03:26,256 - root - INFO - published:<timestamp>\nWhen you see the \xe2\x80\x9cconnect success\xe2\x80\x9d and \xe2\x80\x9cpublished:< timestamp >\xe2\x80\x9d messages in the console, the connection to AWS IoT Core was successfully established  and the message was published.\nIf you see any errors in the execution of the script, check the AWS IoT endpoint or certificate information you provided.\nTest whether AWS IoT received the client message\nTo confirm that AWS IoT receives the client message, sign in to the AWS IoT console. In the left navigation pane, choose Test, and then choose Subscribe. Subscribe to the test/date topic.\nAfter you have subscribed, you will see published messages from the client device on the console every second, as shown here.\n  If your client device is running on Linux, you can use tcpdump to test.\n tcpdump port 443\nMethod 2: Using the AWS IoT Device SDK for Python\nThe AWS IoT Device SDK for Python allows developers to write a Python script to use their devices to access AWS IoT. Currently, you can choose either MQTT over TLS on port 8883 or MQTT over the WebSocket protocol on port 443. Support for MQTT on port 443 is not provided by default. You have to modify the Device SDK to enable the functionality. Because the OpenSSL library built with the Device SDK supports ALPN extension, to enable MQTT communication over port 443, you have to modify how the SSL library is configured. In this example, I show the changes you need to make in the Device SDK to connect to an AWS IoT endpoint over MQTT on port 443.\nThe AWS IoT Device SDK for Python is built on top of a modified Paho-MQTT Python client library. Modify the client.py file in the AWSIoTPythonSDK/core/protocol/paho/ folder.\nExample:  /usr/local/lib/python2.7/site-packages/AWSIoTPythonSDK/core/protocol/paho/client.py\nThe changes that you need to make are shown here:\n--- a/AWSIoTPythonSDK/core/protocol/paho/client.py\n+++ b/AWSIoTPythonSDK/core/protocol/paho/client.py\n@@ -787,15 +787,26 @@ class Client(object):\n            self._ssl = SecuredWebSocketCore(rawSSL, self._host, self._port, self._AWSAccessKeyIDCustomConfig, self._AWSSecretAccessKeyCustomConfig, self._AWSSessionTokenCustomConfig)  # Overeride the _ssl socket\n                 # self._ssl.enableDebug()\n        else:\n-           self._ssl = ssl.wrap_socket(\n-               sock,\n-               certfile=self._tls_certfile,\n-               keyfile=self._tls_keyfile,\n-               ca_certs=self._tls_ca_certs,\n-               cert_reqs=self._tls_cert_reqs,\n-               ssl_version=self._tls_version,\n-               ciphers=self._tls_ciphers)\n-\n+           if self._port == 8883:\n+               self._ssl = ssl.wrap_socket(\n+                   sock,\n+                   certfile=self._tls_certfile,\n+                   keyfile=self._tls_keyfile,\n+                   ca_certs=self._tls_ca_certs,\n+                   cert_reqs=self._tls_cert_reqs,\n+                   ssl_version=self._tls_version,\n+                   ciphers=self._tls_ciphers)\n+           else:\n+               context = ssl.SSLContext(self._tls_version)\n+               context.load_cert_chain(self._tls_certfile, self._tls_keyfile)\n+               context.verify_mode = self._tls_cert_reqs\n+               context.load_verify_locations(self._tls_ca_certs)\n+               context.set_alpn_protocols([""x-amzn-mqtt-ca""])\n+               \n+               self._ssl = context.wrap_socket(sock, server_hostname=self._host, do_handshake_on_connect=False)\n+                   \n+               self._ssl.do_handshake()\n+               \n            if self._tls_insecure is False:\n                if sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] < 5):  # No IP host match before 3.5.x\n                    self._tls_match_hostname()\nPython\nAfter making the changes, create a simple Python script that creates a connection to the AWS IoT endpoint and publishes a message to it. For more information, see the AWS IoT Device SDK for Python.\n# Import SDK packages\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient\n\n# For certificate based connection\nmyMQTTClient = AWSIoTMQTTClient(""myClientID"")\n\n# Configure the MQTT Client\nmyMQTTClient.configureEndpoint(<YOUR_AWS_IOT_ENDPOIT>, 443)\nmyMQTTClient.configureCredentials(""YOUR/ROOT/CA/PATH"", YOUR/DEVICE/KEY/PATH "", "" YOUR/DEVICE/CERT/PATH "")\nmyMQTTClient.configureOfflinePublishQueueing(-1)  # Infinite offline Publish queueing\nmyMQTTClient.configureDrainingFrequency(2)  # Draining: 2 Hz\nmyMQTTClient.configureConnectDisconnectTimeout(10)  # 10 sec\nmyMQTTClient.configureMQTTOperationTimeout(5)  # 5 sec\n\n# Connect to AWS IoT endpoint and publish a message\nmyMQTTClient.connect()\nprint (""Connected to AWS IoT"")\nmyMQTTClient.publish(""alpn/devicesdk"", ""Hello over MQTT on port 443"", 0)\nmyMQTTClient.disconnect()\nPython\nRun the Python script\nRun the Python script you created by executing the following command.\npython aws-iot-with-alpn.py \nConnected to AWS IoT\nWhen you see the \xe2\x80\x9cConnected\xe2\x80\x9d message in the console, the connection to AWS IoT Core was successfully established and the message was published.  If you see any errors in the execution of the script, check the device certificates and make sure that the attached policy allows AWS IoT Core access.\nSummary\nIn this post, I\xe2\x80\x99ve shown you two ways to connect your IoT devices to AWS IoT Core over MQTT on port 443. If you have had a constraint in the past to open port 8883 in your corporate firewalls, you can now use a standard port for HTTPS traffic (443) to send your messages over MQTT to AWS IoT Core endpoint.\nFor more information about AWS IoT Core, see the AWS IoT Core Developer Guide'"
235,Using Device Jobs for Over-the-Air Updates,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-device-jobs-for-over-the-air-updates/,"b'Whether it\xe2\x80\x99s a firmware update or security patch, an update to a config file on a device, or a factory reset, all products need maintenance after they are in your customers\xe2\x80\x99 hands. And to manage your fleet, you need to know which devices in your fleet have received and processed, either successfully or unsuccessfully, any of your updates. AWS IoT Device Management facilitates the deployment and tracking of management tasks to your fleet of devices with the Jobs service, whether you manage hundreds, thousands, or even millions of devices. Using Jobs, you can send remote actions to one or many devices at once, control the deployment of your jobs to your devices, and track the current and historical status of job executions for each device.\nJobs can be used to manage your fleet of devices in many ways:\nTo update firmware, software or other files such as security certificates on your devices.\nTo perform administrative tasks, such as restarting devices or performing diagnostics.\nTo restore devices to factory settings or other known good state\nThis blog post walks you through the creation and deployment of an example job to a device: setting up a device, configuring it to communicate with AWS IoT, creating a job, and tracking the job processing events.\nFor an overview of the way AWS IoT Core works with AWS IoT Device Management, see the AWS IoT Core Features and the Jobs documentation.\nSetting Up Your Device\nAfter your device operating system is set up and has network connectivity, do the following:\nFollow the steps in the AWS IoT Raspberry Pi tutorial found here. Although the steps are written for the Raspberry Pi, you can use them for other Linux-based devices, too. After you complete the tutorial, you will have an IoT thing registered in your AWS account called \xe2\x80\x9cMyRaspberryPi.\xe2\x80\x9d You will also have configured security certificates to download onto your device.\nFollow the instructions here to install and use the AWS IoT Device SDK for JavaScript on your device. Certificates referred to in this blog post are the certificates set up in the previous step.\nYour device is now configured to communicate with AWS IoT, including the Jobs service.\nRunning the Example on Your Device\nOne of the examples included in the AWS IoT Device SDK for JavaScript is called jobs-example.js. Run this example using the following command, substituting the path to your certificates and the name of the file you used for your thing configuration:\n$ node examples/jobs-example.js \xe2\x80\x93f ./certs \xe2\x80\x93F config.json\nYour device is now ready to process jobs and send and receive AWS IoT Core messages.\nCreate a Job Document\nA job document is a free form valid JSON document that provides all of the information that your device needs to execute the job. Although the job document can contain anything you deem relevant to your device, by convention the AWS IoT Device SDK for JavaScript uses the property \xe2\x80\x9coperation\xe2\x80\x9d to route job documents to specific handlers. The jobs-example.js program has a sample handler for an operation called \xe2\x80\x9ccustomJob\xe2\x80\x9d, so we are going to create a job document JSON file called \xe2\x80\x9cexample-job.json\xe2\x80\x9d. For this blog post, this is what \xe2\x80\x9cexample-job.json\xe2\x80\x9d should contain:\n{\n    ""operation"":""customJob"",\n    ""otherInfo"":""someValue""\n}\nFor other job document examples, see the jobs-agent example in the AWS IoT SDK for JavaScript readme.\nCreate a Job\nIt is now possible to create a job that delivers the job document to all of the devices you specify. You can use the AWS IoT console, the SDK, or the AWS CLI to create a job.\nHere is an example of how to create a job through the AWS CLI:\n$ aws iot create-job \\\n--job-id ""example-job-01"" \\\n--targets ""arn:aws:iot:::thing/MyRaspberryPi"" \\\n--document file:///example-job.json \\\n--description ""My First test job"" \\\n--target-selection SNAPSHOT\nIf you\xe2\x80\x99d like to store your job document on S3, you might use the `\xe2\x80\x93document-source` parameter instead of the `\xe2\x80\x93document` parameter to specify the S3 URL for the job document.\nAlternatively, to create the job through the AWS IoT console, follow these steps:\nUpload the job document to an S3 bucket. For information about uploading documents to S3, see How Do I Upload Files and Folders to an S3 Bucket in the Amazon Simple Storage Service Console Guide.\nIn the AWS IoT console, choose Manage and then choose Jobs.\n  On the Select a job page, choose Create custom job.\nOn the Create a job page, enter a unique job ID. Under Select devices to update, select your previously created thing, as shown here:\nScroll down and choose the \xe2\x80\x9cexample-job.json\xe2\x80\x9d file you uploaded to the S3 bucket. Under Job type, select Your job will complete after deploying to the selected devices/groups (snapshot). The other selection, continuous jobs, is used to deploy a job to groups of devices as devices are added to the groups. Leave Job executions rollout configuration unchanged, as shown here:\nChoose Create and then you\xe2\x80\x99ll see your newly created job.\nExecute the Job on a Device\nAfter your job is created, the Jobs service will send notification of a pending job to your device. Your device will get the job details and document through the NextJobExecutionChanged API which it is subscribed to. The jobs-example.js program will execute the job on the device, and then publish its completed status using UpdateJobExecution API. During that process, you should see the following output on your IoT client.\n$ node examples/jobs-example.js -f ./certs -F config.json\nconnect\nstartJobNotifications completed for thing: MyRaspberryPi\ncustomJob operation handler invoked, jobId: example-job-01\nIf you refresh the Jobs page, you should see that your job was completed successfully.\nTracking Job Progress with Job and Job Execution Events\nYou can also use job and jobExecution events to track the progress of your job. This can be helpful to alert users, system administrators, or other parts of your system that a job is complete or a job execution has changed its status. For example, you can alert a user about a firmware update on a device or inform a system administrator of an issue in their fleet that needs to be investigated and resolved.\nJob events are sent to the following topics when a job is completed or canceled.\n$aws/events/job/example-job-01/completed\n$aws/events/job/example-job-01/canceled\nJob execution events are sent to the following topics when a job execution reaches a final status.\n$aws/events/jobExecution/example-job-01/succeeded\n$aws/events/jobExecution/example-job-01/failed\n$aws/events/jobExecution/example-job-01/rejected\n$aws/events/jobExecution/example-job-01/canceled\n$aws/events/jobExecution/example-job-01/removed\nWhen the job execution on MyRaspberryPi is successful, you should receive a JobExecution succeeded event. You can see this event by navigating to the AWS IoT test page and subscribing to the following topic:\n$aws/events/jobExecution/example-job-01/succeeded\n\nWhen the job execution for your device is complete, you should see the following message:\n\nAfter the entire job example-job-01 is complete, you should also receive a job completed event after you subscribe to the following topic:\n$aws/events/job/example-job-01/completed\n'"
236,Developing Amazon FreeRTOS with Texas Instruments’ Code Composer Studio Version 8,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/developing-amazon-freertos-with-texas-instruments-code-composer-studio-version-8/,"b'Update: This issue was patched in Amazon FreeRTOS version 1.2.4 to overcome the out-of-the-box experience challenges.  The root cause will be fixed in the upcoming Texas Instruments compiler release.\n  Last month, Texas Instruments (TI) launched Code Composer Studio (CCS) version 8, which includes the TI MCU compiler version 18.1.1. The Amazon FreeRTOS project for Code Composer Studio is configured for the TI MCU compiler version 16.9.3. Amazon FreeRTOS includes the open source Concise Binary Object Representation (CBOR) Library (tinycbor), which does not compile with version 18.1.1. Amazon FreeRTOS does not build when there is no preexisting 16.9.3 compiler (or compatible compiler) on the system.\nIn this blog post, I\xe2\x80\x99ll show you how to add the TI MCU compiler version 16.9.3 to Code Composer Studio version 8 so that you can build Amazon FreeRTOS with the new IDE.\nObserving the compilation problem\nYou can observe the problem signature by installing Code Composer Studio version 8 from the TI website.\nDownload version 8 from the Code Composer Version 8 Downloads page.\nInstall version 8.\nPerform a clean clone of the Amazon FreeRTOS repository: git clone https://github.com/aws/amazon-freertos amazon-freertos-ccsv8.\nOpen version 8.  Open the Code Composer Studio project to the workspace.  From File, choose Open Projects from File System.\nSelect the Code Composer Studio project amazon-freertos/demos/ti/cc3220_launchpad/ccs.\nFrom Project, choose Clean, and then build the project. You should see errors like the following:\n  Installing TI MCU compiler version 16.9.4\nNow let\xe2\x80\x99s install the earlier version of the TI MCU compiler.\nIf the IDE is open, close it.\nDownload the ARM 16.9.4 compiler.\nInstall the ARM 16.9.4 compiler.\nNow check that the IDE detects version 16.9.4. In Code Composer Studio:\nRight-click the project root node, and then choose Properties.\nIn the General pane, under Tool-chain, choose the Compiler version drop-down box. The TI MCU compiler 16.9.4 should be listed.\nInstall the ARM 16x compiler from here:\nhttp://www.ti.com/tool/download/ARM-CGT-16/16.9.4.LTS\nConfiguring and building the project\nNow that you have installed the correct compiler version, you can configure the demonstration project and compile Amazon FreeRTOS clean.\nConfigure aws_clientcredential_keys.h and aws_clientcredential.h, as described in the Amazon FreeRTOS User Guide.\nConfigure the project for the TI MCU compiler version 16.9.4.\nOpen Code Composer Studio.\nRight-click the project root node, and then choose Properties.\nNow configure the compiler version for the project:\nIn the General pane, under Tool-chain, choose the Compiler version drop-down box.  Select the TI v16.9.3.LTS compiler.\nChoose Apply, and then choose Close.\nBuild the project clean. From Project, choose Clean to clean all compiled objects and start the compilation.\nThe compilation should now be completed successfully.\n'"
237,AWS IoT-Driven Precision Agriculture,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/aws-iot-driven-precision-agriculture/,"b'Precision Agriculture Needs IoT\nThe current world population of 7.3 billion people is estimated to reach 9.7 billion by 2050. Around 83 million people are added to the global population each year. This growth must be met by corresponding increases in food production.\nCompared to current yields, agricultural output would have to grow by at least one third to keep up with food demand. Because farm land acreage can\xe2\x80\x99t keep up with population growth, farmers have started to transition their operations to precision agriculture.\nAt its core, precision agriculture is deploying intelligence to fields so that farmers can gain visibility into crop yields and cost factors as they grow crops. Intelligence is collected by smart devices or IoT things equipped with sensors that continuously act on the data and transmit it to data processing locations. Today, farmers are using newly developed techniques to manage crops on micro portions of their fields to assess soil composition, control fertilizer and pesticide types, and obtain accurate yield estimates.\nPrecision farming would not be possible without IoT-driven solutions because they speed up farmers\xe2\x80\x99 understanding of the main causes for changes in crop yields and factors that affect the measured yields and production cost drivers, including the following.\nFertilizers and their application timing and methods.\nIrrigation and precipitation patterns.\nAir temperature and moisture levels.\nSoil composition and treatment.\nCrop care processes.\nTypes of seeds used.\nMeasuring and collecting field, crop, and ambient data are key capabilities enabled by mature IoT solutions.\nMost farms are in remote locations where data network connectivity can be spotty. Frequent weather fluctuations can cause damage to or loss of sensors and devices. These types of challenges require robust, simple, and easy to manage IoT solutions.\nYanmar IoT Smart Greenhouse\nYanmar is a Japanese company that specializes in diesel engine design and manufacturing. Its presence in smart farming includes actively managing plant growth in greenhouses. One of their challenges is administering the right amount of water (smart hydroponics) and environmental support, including fans and air conditioners, for greenhouse plants, such as tomatoes.\nYanmar\xe2\x80\x99s R&D group would like to make their greenhouse operations smarter by automatically detecting and recognizing the main growth stages of vegetables in order to adjust nutrition, care, and environment to maximize yields.\nYanmar has defined several growth stages for tomato plants. To monitor these stages, they plan to install up to 12 cameras in each greenhouse to take pictures of the plants on a regular basis. Yanmar plans to use machine learning (ML) algorithms deployed on the camera ecosystem to recognize (by height, number of leaves, number of flowers, and fruits) plant growth stages and perform attribution against plant care factors, such as hydroponics application patterns and frequency, in addition to moisture and temperature.\nPictures from the smart cameras will be used to regularly monitor, recognize, and count plant leaves, flowers, plant height, and to calculate predicted greenhouse yields. Optimizing greenhouse operations by effectively using the appropriate inputs of nutrients, water, and other elements at the most appropriate plant stage growth makes greenhouse farming more economically and environmentally sustainable.\nHere are a few of the challenges related to implementing a cost-efficient smart greenhouse solution with image recognition:\nThe amount of data generated by the cameras.\nThe bandwidth and cost required to transmit the data for processing off-site.\nAccess to image recognition intelligence on the cameras.\nYanmar\xe2\x80\x99s R&D group decided to deploy AWS Greengrass ML Inference using Lambda functions, on the greenhouse camera ecosystem because it addresses the following key challenges.\nFirst, Yanmar does not need to send the pictures collected from the cameras to AWS IoT Core over a 3G network, thereby avoiding 3G usage fees.\nSecond, Greengrass accesses trained and deployed deep learning ML models to process greenhouse plant pictures and store the data in a simple format for transmission to AWS IoT Core.\nThird, Yanmar plans to use Lambda functions to perform logic processing using local ML models to detect environment anomalies (moisture, temperature, and humidity) and trigger both alerts and possibly initiate corrective actions.\n  Figure 1. Yanmar IoT Smart Greenhouse \xe2\x80\x93 Cameras with AWS IoT, AWS Greengrass ML Inference using a Deep Learning Model and Leveraging Lambda\n\nFigure 2. Yanmar IoT Smart Greenhouse Diagram shows greenhouse components, including fans, air conditioners, an edge computer, and sensors for temperature, humidity, sunlight, and CO2.\n'"
238,Setting Up Just-in-Time Provisioning with AWS IoT Core,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/setting-up-just-in-time-provisioning-with-aws-iot-core/,"b'In an earlier blog post about just-in-time registration of device certificates, we discussed how just-in-time registration (JITR) can be used to activate device certificates and attach policies to the certificates immediately after the device is auto-registered. JITR triggers a registration event. You must create an AWS IoT Core rule to listen for the registration event topic and, when the registration event is identified, your Lambda code is executed to onboard devices.\nIn this blog post, I will show you how a new feature, just-in-time provisioning (JITP), can be used to provision resources. JITP makes it possible for you to onboard your devices without creating the AWS IoT Core rule and Lambda function. You need to attach a provisioning template to the CA certificate together with an IAM role. JITP will create, update, and attach resources based on the provisioning template. The role is passed in to grant AWS IoT permission to call APIs required for provisioning on your behalf.\nThe following figure shows the difference between JITR and JITP.\nThe JITP flow has fewer steps than JITR\nCreate a CA certificate\nJust like JITR, you start by creating a CA certificate. We are using OpenSSL in a terminal to create a sample CA certificate.\n$ openssl genrsa -out rootCA.key 2048\n$ openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.pem\nBash\nAfter we execute these commands, we get two files, rootCA.key and rootCA.pem, which we will use later as our sample CA certificate.\nCreate a service role\nBecause JITP needs the permissions to call AWS IoT Core APIs, we will create a role and associate it with the CA certificate. It is easier to create this role through the IAM console than the CLI. We already have a policy, AWSIoTThingsRegistration, that can be used to create the service role specific to JITP.\nIn the IAM console, choose Roles, and then choose the Create role button.\nCreate a role for JITP\n  Under Choose the service that will use this role, choose IoT.\nChoose IoT as the trusted service\n  Review the policy. Type a name and description for the role.\nReview the policy\nProvide Role name and Role description\n  We now have a role named JITPRole, which we will use in the registrationConfig field when we register or update a CA certificate.\nCreate a provisioning template\nA provisioning template must be attached to the CA certificate so that the JITP workflow will provision resources specified in the template when the device first connects to AWS IoT Core. For JITP, we can use the following parameters in our template.\nAWS::IoT::Certificate::Country\nAWS::IoT::Certificate::Organization\nAWS::IoT::Certificate::OrganizationalUnit\nAWS::IoT::Certificate::DistinguishedNameQualifier\nAWS::IoT::Certificate::StateName\nAWS::IoT::Certificate::CommonName\nAWS::IoT::Certificate::SerialNumber\nAWS::IoT::Certificate::Id\nThe values for the first 7 provisioning template parameters are extracted from the subject field in the certificate of the device that is being provisioned. The AWS::IoT::Certificate::Id parameter refers to an internally generated ID, not an ID that is contained in the certificate. You can get the value of this ID using the principle() function inside an AWS IoT rule.\nWe are using the following sample template. We need to escape the JSON string of templateBody value in the template.\n{\n ""templateBody"":""{ \\""Parameters\\"" : { \\""AWS::IoT::Certificate::Country\\"" : { \\""Type\\"" : \\""String\\"" }, \\""AWS::IoT::Certificate::Id\\"" : { \\""Type\\"" : \\""String\\"" } }, \\""Resources\\"" : { \\""thing\\"" : { \\""Type\\"" : \\""AWS::IoT::Thing\\"", \\""Properties\\"" : { \\""ThingName\\"" : {\\""Ref\\"" : \\""AWS::IoT::Certificate::Id\\""}, \\""AttributePayload\\"" : { \\""version\\"" : \\""v1\\"", \\""country\\"" : {\\""Ref\\"" : \\""AWS::IoT::Certificate::Country\\""}} } }, \\""certificate\\"" : { \\""Type\\"" : \\""AWS::IoT::Certificate\\"", \\""Properties\\"" : { \\""CertificateId\\"": {\\""Ref\\"" : \\""AWS::IoT::Certificate::Id\\""}, \\""Status\\"" : \\""ACTIVE\\"" } }, \\""policy\\"" : {\\""Type\\"" : \\""AWS::IoT::Policy\\"", \\""Properties\\"" : { \\""PolicyDocument\\"" : \\""{\\\\\\""Version\\\\\\"": \\\\\\""2012-10-17\\\\\\"",\\\\\\""Statement\\\\\\"": [{\\\\\\""Effect\\\\\\"":\\\\\\""Allow\\\\\\"",\\\\\\""Action\\\\\\"": [\\\\\\""iot:Connect\\\\\\"",\\\\\\""iot:Publish\\\\\\""],\\\\\\""Resource\\\\\\"" : [\\\\\\""*\\\\\\""]}]}\\"" } } } }"",\n ""roleArn"":""arn:aws:iam::123456789012:role/JITPRole""\n}\nWe declare we are using two provisioning parameters, AWS::IoT::Certificate::Country and AWS::IoT::Certificate::Id, and we will use them in the Resource section. The JITP workflow will substitute the references with the values extracted from the certificate and provision the resources specified in the template.\nMore specifically, the JITP workflow will create:\nOne thing resource.\nOne policy resource.\nIt will then:\nAttach the policy to the certificate.\nAttach the certificate to the thing.\nUpdate the certificate status to ACTIVE.\nNow we will put the whole template together with the role ARN we got from the previous step into a local file, provisioning-template.json.\nFor more information about the provisioning template, see Provisioning Templates in the AWS IoT Core Developer Guide.\nRegister a CA certificate\nNow that we have created a sample CA certificate, we will register it with AWS IoT Core. To use JITP, we need to associate a template and a role with the CA certificate. This can be done at the time we register the CA certificate or later when we update the CA certificate. In this example, we will register the CA certificate with the template and the role ARN. You can also call UpdateCACertificate API or update-ca-certificate CLI command to change the status of the CA certificate, enable auto-registration status and set the registration configuration by providing a template and a role ARN.\nFollow these steps to register the CA certificate.\nFirst, we get a registration code from AWS IoT Core. This code will be used as the Common Name of the private key verification certificate.\n$ aws iot get-registration-code\nBash\nThen we generate a key pair for the private key verification certificate. We will get a file called verificationCert.key.\n$ openssl genrsa -out verificationCert.key 2048\nBash\nNow we execute the following command to create a CSR for the private key verification certificate. We will get a file called verificationCert.csr.\n$ openssl req -new -key verificationCert.key -out verificationCert.csr\nBash\nNow we need to set the Common Name field of the certificate with the registration code:\nCountry Name (2 letter code) [AU]:\nState or Province Name (full name) []:\nLocality Name (for example, city) []:\nOrganization Name (for example, company) []:\nOrganizational Unit Name (for example, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []: XXXXXXXREGISTRATION-CODEXXXXXXX\nEmail Address []:\nWe use the CSR to create a private key verification certificate. The verificationCert.pem file we get from this step will be used when we register the CA certificate.\n$ openssl x509 -req -in verificationCert.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out verificationCert.pem -days 500 -sha256\nBash\nLastly, we call the register-ca-certificate CLI command to register the CA certificate.\n$ aws iot register-ca-certificate --ca-certificate file://rootCA.pem --verification-cert file://verificationCert.pem --set-as-active --allow-auto-registration --registration-config file://provisioning-template.json\nBash\nWe get an HTTP 200 response back with the registered CA certificateArn and certificateId. After registering the CA certificate, we can still call UpdateCACertificate API or the update-ca-certificate CLI command to update the registered CA certificate, if needed.\nAuto-provision a device with a certificate signed by a CA certificate\nNow that we have registered a sample CA certificate with auto-registration-status enabled and associated it with a provisioning template, we can try using the CA certificate to create a device certificate. The device certificate is provisioned automatically when it first connects to AWS IoT Core.\nTo create a device certificate, we run the following commands in our terminal:\n$ openssl genrsa -out deviceCert.key 2048\nBash\n$ openssl req -new -key deviceCert.key -out deviceCert.csr\nBash\nAfter we run these commands, we can set the subject fields of the certificate, such as country name, common name, and so on and pass them to JITP.\nNow we connect to AWS IoT Core using the device certificate. At the time of connection, we need to send the device certificate and its registered CA certificate (the sample CA certificate).\n$ openssl x509 -req -in deviceCert.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out deviceCert.crt -days 365 -sha256\nBash\nThen we create a file that contains the device certificate and its registered CA certificate.\n$ cat deviceCert.crt rootCA.pem > deviceCertAndCACert.crt\nBash\nLastly, we need the MQTT Mosquitto client to connect and publish to AWS IoT Core using the device certificate:\n$ mosquitto_pub --cafile root.cert --cert deviceCertAndCACert.crt --key deviceCert.key -h <prefix>.iot.us-east-1.amazonaws.com -p 8883 -q 1 -t foo/bar -I anyclientID --tls-version tlsv1.2 -m ""Hello"" -d\nBash\nNote: The root.cert is the AWS IoT root certificate. To download it, click here. Save it in your current directory as \xe2\x80\x9croot.cert.\xe2\x80\x9d Because the <prefix> of the endpoint varies, we need to run the describe-endpoint command to retrieve it.\n$ aws iot describe-endpoint\nBash\nAfter connecting and publishing to AWS IoT Core, the provisioning workflow will auto-provision the resource specified in the template during the TLS handshake. In our example:\nA thing resource is created for the device.\nA certificate signed by the sample CA certificate is created, and its status is set to ACTIVE.\nA policy resource is created and attached to the certificate, and the certificate is attached to the thing resource.\nThe device now is full provisioned. You can use the AWS IoT console to verify these resources are provisioned as expected.\n'"
239,Using AWS IoT Core in a Low-Power Application,b'Kevin Oleniczak',2018-06-28T18:48:35+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-aws-iot-core-in-a-low-power-application/,"b'At AWS, we work closely with customers to assist them in building various types of IoT solutions. We often hear from customers about the need to manage power consumption appropriately in IoT. In this blog post, we\xe2\x80\x99ll discuss one of the options for achieving lower power consumption while connecting to AWS IoT Core. Specifically, we\xe2\x80\x99ll show how your choice of wireless transport can help extend battery life. Communication is assumed to be wireless and can use Wi-Fi or LPWAN.\nIn a large number of IoT projects, powering a device isn\xe2\x80\x99t an issue and line power can be used. In other projects, it may not be possible to run power directly to the device \xe2\x80\x93 this may be caused by building regulations; the cost to run the power lines or a need for the device to be somewhat mobile. In a situation like this, battery power will be considered for the device. A constraint on any solution design will be extending the battery life as long as possible.\nWi-Fi is well known and understood however it uses more power and provides a higher transfer rate. LPWAN is a low-power wide area network that uses less power than traditional Wi-Fi.\nThe following design will consider the Wi-Fi mechanism and a possible design option for that scenario.\nInitial Design\nA device keeps its current state and event log onboard in permanent storage. To extend battery life, it leaves the Wi-Fi radios powered down. As the following diagram shows, the device periodically performs the following actions:\nTurn on the Wi-Fi radio and connect to the Wi-Fi gateway.\nConnect to the endpoint.\nPublish the event history to an MQTT topic.\nUpload its current configuration settings (state) to an AWS IoT device shadow.\nDownload any new desired configuration settings (state) from an AWS IoT device shadow.\nMake any configuration setting changes based on the desired state.\nTurn off the Wi-Fi radio.\n  To extend battery life, you might consider the interval between data uploads. It can be set to a longer period when the device is not anticipated to be in active use.\nClusters of Devices\nYou can extend the initial design to include clusters of devices that are relatively close together and need to periodically communicate their state and event history.\nIn this scenario, not all the devices need to use energy-expensive Wi-Fi connections to transfer data. Bluetooth low energy (BLE) can provide a more energy-efficient method for getting the data from the devices to a combination BLE/Wi-Fi device in the cluster. This BLE/Wi-Fi device connects to the network and transfers data on behalf of the actual devices. We refer to this device as a device gateway in the rest of this post.\nBLE allows the individual devices to advertise themselves and provides additional information about their state or offered services. The individual devices can advertise information like:\nThe length of time since the event history was last retrieved.\nImportant events in their history.\nThe current battery level.\nFor an introduction to the advertising structure of BLE, see this post on the Bluetooth blog.\nInternal parameters like the following govern the actions of the device gateway:\nThe length of time an event history should remain on an individual device before collection is required.\nWhether the event history should be collected immediately from an individual device that has an important event in its history.\nThe device gateway then periodically listens for BLE advertisements that match the criteria, as shown in the following diagram.\nThe first BLE device in the diagram has exceeded the maximum time between uploads. The last BLE device in the diagram has important events that need to be uploaded.\nIf the event history for one or more individual device must be uploaded, the device gateway does the following (for each device):\nConnects to the device using BLE.\nRetrieves the device information.\nThis might include the serial number used to calculate the target MQTT topic(s) where the device data should be delivered or the MQTT topics themselves.\nTurns on the Wi-Fi radio and connect to the Wi-Fi gateway.\nConnects to the IoT endpoint.\nPublishes the individual device history to the MQTT topics generated/specified.\nInforms the independent device that the event history has been successfully transmitted.\nUploads the independent device\xe2\x80\x99s current configuration settings (state) to an IoT device shadow.\nDownloads any new desired configuration settings (state) from an AWS? IoT device shadow and transmit them to the individual device.\nSyncs the device\xe2\x80\x99s time with the gateway.\nTurns off the Wi-Fi radio.\nDisconnects the BLE radio from active usage.\nYou can increase battery life even more by decreasing the advertising intervals for the BLE devices and reducing the transmit power of the BLE radios to a reasonable level for the distances in the cluster. Depending on the data transmit interval requirements and number of devices, you can also turn off the BLE radios for periods of time (for example, in the scenario where data collection needs to occur hourly or more frequently). If the BLE radios in both the independent devices and the device gateway were turned off for 20 minutes every hour, there would still be a minimum of 10 minutes overlap when the radios are on. If this is enough time for all the devices to send data through the gateway, then this could be an option. It works whether the times are in sync or out of sync.\n'"
240,Using AWS IoT Device Management in a Retail Scenario to Process Order Requests,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/iot-device-management-group-policy/,"b'In this blog post, we will simulate a common business scenario to show you how to use the group policy feature in AWS IoT Device Management. Specifically, we will describe:\nHow to create a hierarchical group structure and assign your IoT devices to different groups.\nHow to publish messages to different IoT devices based on their group-based policy.\n  Scenario\nWe\xe2\x80\x99ll use an example of a retail shop in Seattle that publishes an order request to an IoT device gateway. The gateway sends the order message to AWS IoT Core for processing, and AWS IoT Core publishes the order message to the factory in San Francisco.\nIn this scenario, we will use AWS IoT Device Management to manage the fleet of IoT gateways in Seattle and the fleet of manufacturing equipment in San Francisco.\nEach group will be assigned different policies.\nFor the Seattle group, devices can publish their message only through specific topics. They cannot publish information about any other shop. The Seattle group will not receive messages from AWS IoT Core.\nFor the San Francisco group, devices can subscribe only to messages designated for San Francisco. This means those devices can\xe2\x80\x99t receive messages from another factory.\n    Notes\nBefore you begin, be aware that a group is hierarchical. You must define your parent group and child group carefully. The parent group cannot be changed after it\xe2\x80\x99s created. You cannot move a group to a different parent group.\nAccording to the group policy inheritance, the devices in the child groups inherit the policy of their parent group, so you must design your group hierarchy and policy inheritance carefully. In general, as a best practice, the parent group should have the least permissive group policy. Add more specific permissions to the child groups. Because of policy inheritance, if there is a conflict between the parent group and child group (for example, if there is both an Allow statement and a Deny statement on the same resource), then the action will be explicitly denied. Keep this in mind when you create your group policy tree.\n  Group configuration example\n1.     Sign in to the AWS Management Console, and open the AWS IoT console. You\xe2\x80\x99ll find the new Groups option under Manage. You can use the console or the following CLI commands to create a new group. For our scenario, we will first create a parent group, US, and then create two child groups, Seattle and San Francisco. You need to add two child groups into their partner group, US, and verify your group hierarchy.\n# Create Parent Group#\n\naws iot create-thing-group --thing-group-name \'US\'\n\n# Create Child Group and Assign to Parent Group\n\naws iot create-thing-group --thing-group-name \'Seattle\' --parent-group-name \'US\'\naws iot create-thing-group --thing-group-name \'San_Francisco\' --parent-group-name \'US\'\n2.     For our scenario, we will create two things: SeattleThing1 and SanFranciscoThing1. Each thing will be added to the thing registry and assigned to its named group. You need to attach a certificate to your newly created thing so that it can connect to the device gateway through MQTT TLS 1.2. You can use your own certificate or you can use the AWS IoT Core CA. In this example, we will use the AWS IoT Core CA to assign a new certificate to each thing.\n# Create a new IoT thing#\n\naws iot create-thing --thing-name SeattleThing1\naws iot create-thing --thing-name SanFranciscoThing1\n\n# Create certificate and set it as active status\n\n# Create certificate for SeattleThing1\n\naws iot create-keys-and-certificate --set-as-active\n\n# Create certificate for SanFranciscoThing1\n\naws iot create-keys-and-certificate --set-as-active\n\n# Attach certificate to IoT thing\n\naws iot attach-thing-principal --thing-name SeattleThing1 --principal <Certificate ARN>\naws iot attach-thing-principal --thing-name SanFranciscoThing1 --principal <Certificate ARN>\n\n# Add IoT thing to group#\n\naws iot add-thing-to-thing-group --thing-name SeattleThing1 --thing-group-name Seattle\naws iot add-thing-to-thing-group --thing-name SanFranciscoThing1 --thing-group-name San_Francisco\n3.     Before the release of AWS IoT Device Management, you needed to attach a policy to an individual certificate and manage the policy separately. Now you can attach the policy to a group instead of individual certificates. We will create the policies based on different group assignments. The Seattle group is only allowed to publish to the Seattle order status topic, and the San Francisco group is only allowed to subscribe to the order process topic from AWS IoT Core. You can use the console or the following command to create the policies.\naws iot create-policy --policy-name <Policy Name>--policy-document <Policy Value>\na.     For the US group, we will use the least permissive policies, which only allow devices to connect to AWS IoT Core without any publish/subscribe process.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n     {\n       ""Effect"": ""Allow"",\n       ""Action"": ""iot:Connect"",\n       ""Resource"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXXX:client/${iot:ClientId}""\n     }\n   ]\n}\nb.     For the Seattle group, we will use the following policy:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n     {\n      ""Effect"": ""Allow"",\n      ""Action"": ""iot:Publish"",\n      ""Resource"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXXX:topic/Seattle/${iot:Connection.Thing.ThingName}/*""\n     }\n   ]\n}\nc.     For the San Francisco group, we will use the following policy:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n     {\n       ""Effect"": ""Allow"",\n       ""Action"": ""iot:Subscribe"",\n       ""Resource"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXXX:topicfilter/San_Francisco/*""\n     },\n     {\n       ""Effect"": ""Allow"",\n       ""Action"": ""iot:Receive"",\n       ""Resource"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXXX:topic/San_Francisco/${iot:Connection.Thing.ThingName}/*""\n     }\n   ]\n}\n4.     After the policies are created, you can attach each policy to a different group individually. You can use the console or the following CLI command to attach a policy to a group.\naws iot attach-policy --target <Thing Group Arn> --policy-name <Policy Name>\n5.     After the three policies are attached, you can build your order request system. In this scenario, we will use MQTT.fx to act as an MQTT client (it represents the shop in Seattle and the factory in San Francisco) to connect to AWS IoT Core.\n6.     Now, let\xe2\x80\x99s get to the fun part. We can simulate the shop receiving the order in Seattle, and then any factory in San Francisco processing the order request process system using the IoT rule. We can create an IoT rule to select the OrderNumber attribute from Seattle/SeattleThing1/OrderStatus topic and republish to the San_Francisco/SanFranciscoThing1/ProcessOrder topic. In this way, the order request from the Seattle shop will be proceeded by the San Francisco factory. You need to create a rule action so that the message can be republished to the San Francisco topic. For information about the rules engine, see Rules for AWS IoT in the AWS IoT Developer Guide. You can use the console or the following CLI command to create an IoT rule:\naws iot create-topic-rule \xe2\x80\x93rule-name <Rule Name> --topic-rule-payload <Rule Value>\n7.     You can now publish an order message from the Seattle shop by using the MQTT.fx client.\n8.     The IoT rule will select the OrderNumber attribute in this message and republish to the San Francisco factory device. You will receive the result from MQTT.fx San Francisco device.\nAppendix\nWhen you attach a policy to a group, that policy is applied to all devices in the group. We recommend that you use the TestAuthorization API to test your policy locally so that you do not impact real devices in your production environment. You can use the following command to simulate the expected result.\n1.     First, use the following command to verify the current attached policy for your group:\n#Use the following command to verify the current effective policy on your thing, which only has one group policy attached#\n\naws iot test-authorization --auth-infos ""[{\\""actionType\\"": \\""CONNECT\\"", \\""resources\\"":[<Thing ARN>]}, {\\""actionType\\"": \\""PUBLISH\\"", \\""resources\\"": [<Topic ARN>\\""]}]"" --client-id <Thing Name> --principal <certificate-ARN>\nThe following shows the output of the command. As you can see, \xe2\x80\x9cCONNECT\xe2\x80\x9d is an allowed action, and \xe2\x80\x9cPUBLISH\xe2\x80\x9d is denied.\n{\n    ""authResults"": [\n     {\n       ""authDecision"": ""ALLOWED"",\n       ""authInfo"": {\n       ""actionType"": ""CONNECT"",\n       ""resources"": [\n          ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:client/SeattleThing1""\n        ]\n      },\n     ""denied"": {\n       ""implicitDeny"": {\n          ""policies"": []\n        },\n     ""explicitDeny"": {\n       ""policies"": []\n        }\n      },\n      ""missingContextValues"": [],\n       ""allowed"": {\n         ""policies"": [\n          {\n            ""policyName"": ""GroupManagement-US"",\n            ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-US""\n          }\n        ]\n        }\n      },\n      {\n       ""authDecision"": ""IMPLICIT_DENY"",\n       ""authInfo"": {\n         ""actionType"": ""PUBLISH"",\n         ""resources"": [\n            ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:topic/Seattle/SeattleThing1""\n           ]\n       },\n       ""denied"": {\n         ""implicitDeny"": {\n            ""policies"": [\n             {\n                ""policyName"": ""GroupManagement-US"",\n                ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-US""\n             }\n           ]\n         },\n       ""explicitDeny"": {\n         ""policies"": []\n         }\n       },\n       ""missingContextValues"": [],\n           ""allowed"": {\n               ""policies"": []\n              }\n          }\n     ]\n}\n2.     Before you attach a new group policy for the same group, use the following command to verify the result for this new policy:\n#Use the following command to verify the result after new group policy attached#\n\naws iot test-authorization --auth-infos ""[{\\""actionType\\"": \\""CONNECT\\"", \\""resources\\"": [<Thing ARN>]}, {\\""actionType\\"": \\""PUBLISH\\"", \\""resources\\"": [<Topic ARN>]}]"" --client-id <Thing Name> --principal <certificate-ARN> --policy-names-to-add ""[<New Group Policy Name>]""\nThe following shows the output of the command. As you can see, both \xe2\x80\x9cCONNECT\xe2\x80\x9d and \xe2\x80\x9cPUBLISH\xe2\x80\x9d are allowed actions.\n{\n    ""authResults"": [\n      {\n        ""authDecision"": ""ALLOWED"",\n        ""authInfo"": {\n            ""actionType"": ""CONNECT"",\n            ""resources"": [\n                ""arn:aws:iot:ap-northeast-1: XXXXXXXXXXX:client/SeattleThing1""\n             ]\n         },\n     ""denied"": {\n        ""implicitDeny"": {\n            ""policies"": [\n              {\n                ""policyName"": ""GroupManagement-Seattle"",\n                ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-Seattle""\n              }\n             ]\n        },\n     ""explicitDeny"": {\n        ""policies"": []\n        }\n      },\n     ""missingContextValues"": [],\n        ""allowed"": {\n            ""policies"": [\n              {\n                ""policyName"": ""GroupManagement-US"",\n                ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-US""\n              }\n            ]\n         }\n      },\n      {\n     ""authDecision"": ""ALLOWED"",\n        ""authInfo"": {\n            ""actionType"": ""PUBLISH"",\n            ""resources"": [\n                ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXXX:topic/Seattle/SeattleThing1""\n            ]\n        },\n     ""denied"": {\n        ""implicitDeny"": {\n            ""policies"": [\n             {\n                ""policyName"": ""GroupManagement-US"",\n                ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-US""\n             }\n             ]\n        },\n     ""explicitDeny"": {\n        ""policies"": []\n      }\n      },\n      ""missingContextValues"": [],\n        ""allowed"": {\n            ""policies"": [\n             {\n                ""policyName"": ""GroupManagement-Seattle"",\n                ""policyArn"": ""arn:aws:iot:ap-northeast-1:XXXXXXXXXXX:policy/GroupManagement-Seattle""\n             }\n             ]\n        }\n      }\n   ]\n}\nReference links:\n\xc2\xb7      Thing Groups in the AWS IoT Developer Guide\n\xc2\xb7      AWS IoT Policies in the AWS IoT Developer Guide\n\xc2\xb7      Rules for AWS IoT in the AWS IoT Developer Guide\n\xc2\xb7      MQTT.fx download page'"
241,MQTT with TLS client authentication on port 443: Why it is useful and how it works,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/mqtt-with-tls-client-authentication-on-port-443-why-it-is-useful-and-how-it-works/,"b'The AWS IoT Core service now allows you to connect devices using MQTT with TLS client authentication on port 443.  Previously this combination of protocol and authentication mechanism was only supported on port 8883.  So what\xe2\x80\x99s the big deal? Read on to learn more about how this feature makes it easier to connect your devices or skip to the final section to learn how you can start taking advantage of it today.\n443, 8883 \xe2\x80\x93 What\xe2\x80\x99s the difference?\nTCP connections are typically associated with a combination of IP address and port number. This immediately raises the question of which port number to use to ensure that your application can communicate with other 3rd party applications. To solve this problem, the Internet Assigned Numbers Authority (IANA) maintains a mapping of TCP and UDP port numbers to various messaging protocols that have registered with the organization. While this is not a canonical list, these standards are widely adopted, especially for more popular protocols. A quick search of their database shows that port 443 is the registered port for HTTP over TLS (i.e. internet traffic) and 8883 is the registered port for MQTT over TLS. AWS IoT Core complies with these standards as much as possible (see here), but as we have learned from our customers, there are scenarios where it makes sense to deviate from them.\nCorporate firewalls and even some home routers often restrict inbound and outbound traffic to be transmitted over a small range of TCP ports. This is done as a security measure to limit the attack surface for possible cyber attacks. Standard ports for things like HTTPS traffic (port 443) are left open but others that are used for less common protocols, such as MQTT (port 8883) may be intentionally blocked. If you are manufacturing IoT devices that will ultimately be used in IT environments that you do not control, this can cause serious headaches. For example, if you manufacture medical devices that are sold to hospitals around the country, you do not want to have to negotiate separately with each hospital\xe2\x80\x99s IT department to open port 8883 in their firewall so that your devices can connect to your IoT application running on AWS IoT Core. It just so happens that there is a standard extension to the TLS protocol that can help with precisely this issue.\nALPN \xe2\x80\x93 One port to rule them all\nApplication Layer Protocol Negotiation (ALPN) is an extension to TLS defined by RFC 7301 that is supported by many of the most common TLS implementations. ALPN enables clients connecting to a TLS server to pass an extra parameter, known as a ProtocolNameList, as part of the ClientHello message during the TLS handshake. The ProtocolNameList is a preference ordered list of the application protocols that the client would like to use to communicate. As part of the ServerHello message, the TLS server selects one protocol from this list that will be used to transmit application data over the connection.\nThe full TLS handshake including the ALPN extension works as follows:\nClient                                           Server\n\nClientHello                --------> \n(ALPN extension & \nlist of protocols)\n                                              ServerHello\n                                              (ALPN extension &\n                                              selected protocol)\n                                              Certificate*\n                                              ServerKeyExchange*\n                                              CertificateRequest*\n                           <--------          ServerHelloDone\n Certificate*\n ClientKeyExchange\n CertificateVerify*\n [ChangeCipherSpec]\n Finished                  -------->\n                                              [ChangeCipherSpec]\n                           <--------          Finished\n Application Data          <------->          Application Data\n\n* Indicates optional or situation-dependent messages that are not\n always sent.\nAWS IoT Core supports a special ProtocolName, \xe2\x80\x9cx-amzn-mqtt-ca\xe2\x80\x9d, that enables clients to specify that they will be using MQTT with TLS client authentication. It is necessary to use this special value instead of just \xe2\x80\x9cMQTT\xe2\x80\x9d because in addition to signalling which application protocol the client will be using, AWS IoT Core also uses the ProtocolName to signal that it should send a CertificateRequest as part of the TLS handshake. If the client were to send a certificate without AWS IoT Core requesting it, the TLS specification dictates that AWS IoT Core should terminate the handshake.\nHow can I connect my devices on port 443 using MQTT?\nEnsure your device\xe2\x80\x99s TLS client implementation supports the ALPN extension.\nConsult the manual to be certain, but this Wikipedia page provides a handy list.\nAmazon FreeRTOS source code supports the ALPN extension.\nRegister your device with AWS IoT Core by creating, activating, and downloading a certificate or bring your own certificate.\nConfigure the ALPN extension on your device with the \xe2\x80\x9cx-amzn-mqtt-ca\xe2\x80\x9d protocol*.\nConnect to AWS IoT Core on port 443.\n*NOTE: Currently \xe2\x80\x9cx-amzn-mqtt-ca\xe2\x80\x9d is the only supported ALPN ProtocolName and it is only supported on port 443. The most up to date mappings can always be found on the Protocols page in the AWS IoT Core Developers Guide'"
242,Using Device Time to Validate AWS IoT Server Certificates,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/using-device-time-to-validate-aws-iot-server-certificates/,"b'AWS IoT Core supports a wide variety of clients, including browsers running applications built using the AWS IoT Device SDK for JavaScript, smartphones running applications built on the AWS Mobile SDKs, and embedded applications built with the AWS IoT Device SDKs. Each of these environments has different capabilities; some have more memory or faster CPUs than others, not all of them have the same kinds of peripherals, and their operating systems may provide different types of services. This disparity in runtime environments poses unique challenges for software developers, especially at the low-cost end of the device spectrum.\nWhat Time Is It?\nFor most of us, finding out the current time is pretty easy; we can just look at our smartphone, our watch, or a clock on the wall \xe2\x80\x93 for a computer however, it\xe2\x80\x99s not so simple.\nTo start with, not all computers can keep track of time in the same way. Many computers have a peripheral called a Real-time Clock (RTC) (most PCs fall into this category). An RTC works like a watch that the computer can read or set, and it keeps time even if the computer is powered off. However, an RTC can\xe2\x80\x99t always be counted on to be accurate; it could be set to the wrong time due to user error, clock drift (running faster or slower than actual time due to environmental effects), a software bug, or because its battery has worn out. Because of this, the computer\xe2\x80\x99s operating system will probably have another way to find the current time.\nNetwork Time Protocol\nThe Network Time Protocol (NTP) is a network protocol for distributing time information over the internet. Many operating systems (e.g. MacOS, Windows, GNU/Linux) include an NTP client to keep the system (and the computer\xe2\x80\x99s RTC, if it has one) time up-to-date by synchronizing with an NTP server. The device you\xe2\x80\x99re reading this on probably uses an NTP client to know what time it is. On GNU/Linux for example, the NTP client is called ntpd.\nIoT Devices\nMany low-cost IoT devices do not include an RTC since adding one can add cost and complexity to the design. Such devices will not have any idea what time it is when they\xe2\x80\x99re powered on, and unless they have an NTP client and are connected to the Internet, they never will unless someone sets the time manually.\nX.509 Certificates and the Validity Period\nAWS IoT Core connections use Transport Layer Security (TLS). During the establishment of a TLS connection (called a TLS handshake), the server (in this case AWS IoT Core) will present a server certificate to the client. TLS certificates are in X.509 format and include a variety of information such as the organization\xe2\x80\x99s name and location, domain name, a public key, the type of algorithm used to verify signatures, and a validity period. The validity period is specified as a pair of time values called notBefore and notAfter. Services like AWS IoT Core use limited validity periods (e.g. one year) for their server certificates and begin serving new ones before the old ones expire.\nIn order for the client to know that it is connected to AWS IoT Core, it must validate the server certificate. The validation process involves ensuring that it has been signed by a trusted Certificate Authority (CA), that the domain name matches the one the client has connected to, and that the certificate has not expired or has yet to be activated. This check is where the client\xe2\x80\x99s concept of time becomes critical.\nIf the client doesn\xe2\x80\x99t know the correct time, it won\xe2\x80\x99t be able to evaluate the server certificate\xe2\x80\x99s validity based on the values of notBefore and notAfter. In the worst case, it might reject a valid server certificate because it thinks it was created in the future.\nCertificate validity checks are usually performed in a system library like OpenSSL or mbedTLS and it may not be clear why the check is failing unless your application closely examines the returned error code. In OpenSSL, for example, these failures will result in X509_V_ERR_CERT_NOT_YET_VALID or X509_V_ERR_CERT_HAS_EXPIRED errors.\nBest Practices for IoT Devices\nFailure to provide accurate time in an IoT device design could prevent it from being able to connect to AWS IoT Core. If you\xe2\x80\x99re building commercial IoT devices, remember that your products may be stored for extended periods before being sold. Real-time clocks can drift during this time and batteries can get discharged, so setting time in the factory is not sufficient. For most systems, this means that the device\xe2\x80\x99s software needs to include an NTP client and should wait until it has synchronized with an NTP server prior to attempting a connection with AWS IoT Core. If this isn\xe2\x80\x99t possible, the system should provide a way for a user to set the device\xe2\x80\x99s time so that subsequent connections can succeed.\nFinding an NTP Client\nIf you\xe2\x80\x99re developing for an IoT device which runs GNU/Linux, there\xe2\x80\x99s a good chance that the distribution you\xe2\x80\x99re using already includes and starts ntpd. If you\xe2\x80\x99re developing for a lightweight RTOS like Amazon FreeRTOS, you may need to find a small NTP client to port to your platform.\nConfiguring the NTP Client\nOnce you\xe2\x80\x99ve provided an NTP client to your IoT device software, you\xe2\x80\x99ll need to configure it so that it receives time updates from an appropriate NTP server. The proper NTP client configuration depends on your use case and is beyond the scope of this article; for more on this topic, we recommend starting with the excellent documentation provided by the NTP Pool Project. If you are building commercial IoT devices, please pay particular attention to the Information for Vendors on their project page.\nAccuracy\nIn order for a device to validate the server certificate presented by AWS IoT Core for an MQTT connection, the device\xe2\x80\x99s time should be within some reasonable distance of the server\xe2\x80\x99s time, e.g. no more than a few hours. Devices connecting using WebSocket/SigV4 authentication have an additional and more stringent requirement on the server side and must be within 15 minutes of the server\xe2\x80\x99s time.\nAlternatives to NTP\nNot all embedded devices may be able to use an NTP client. In these cases, devices will need a low-drift RTC as well as a method to set the time. Examples might include a front panel or local web interface which allows the user to set the time, or a mobile application which connects to the device over Bluetooth or Wi-Fi and sets the device time to the smartphone time.\n'"
243,Advancing Maintenance Maturity of Distributed IoT Applications with AWS Greengrass and AWS Step Functions,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/f6e1126cedebf23e1463aee73f9df08783640400/2018/01/23/pdmcurve.png,https://aws.amazon.com/blogs/iot/advancing-maintenance-maturity-of-distributed-iot-applications-with-aws-greengrass-and-aws-step-functions/,"b'Shane Baldacchino is a Solutions Architect at Amazon Web Services.\nCustomers have been asking how compute at the edge can be coupled with AWS services to advance maintenance maturity in their organization.\nIn this blog post, we will examine maintenance maturity through the lens of something very common: elevators. We will show how you can use AWS Greengrass and AWS IoT in combination with other AWS services to build an architecture that will help your organization predict, model, and identify a performance issue or impending failure before it occurs.\nThe following diagram shows a standard maintenance maturity model. Predictive maintenance (PdM) increases operational efficiency, safety, and customer satisfaction.\nProviding compute at the edge\nAWS Greengrass is software that provides local compute, messaging, data caching, and sync capabilities for connected devices in a secure way. With AWS Greengrass, connected devices can run AWS Lambda functions, keep device data in sync, and communicate with other devices securely, even when not connected to the internet. Using Lambda, Greengrass ensures your IoT devices can respond quickly to local events, operate with intermittent connections, and minimize the cost of transmitting IoT data to the cloud.\nMost elevator systems operate autonomously. They provide limited device-to-device interaction. Because the maintenance operator has no or limited visibility into the system, the total cost of ownership (TCO) is higher than optimal.\nIn this example, we use Greengrass to control IoT things, our elevators. The Greengrass core is the heart of Greengrass. It runs on both x86 and ARM architectures and has modest requirements. The core provides command and control of our elevators through local long-running Lambda functions. It also aggregates and filters data and performs iterative learning. Because elevators contain hundreds of sensors, we can use Greengrass to monitor everything from motor temperature to cab speed and we can feed this information into local Lambda functions to drive maturity in our maintenance practices.\nFor the purpose of this blog post, we use Raspberry Pi 3 to simulate Greengrass control of the elevators. The Greengrass core is running on a Raspberry Pi 3. Our two elevators are simulated by using Rapsberry Pi 3 with a combination of Raspberry Pi Sense HAT, local Lambda functions, and device code.\nLet\xe2\x80\x99s look at our physical architecture:\nKey elevator elements\nGreengrass core\nThe core is responsible for local Lambda execution, messaging, device shadows, and security, and for interacting directly with the AWS Cloud. It controls our elevators through local MQTT messages and local Lambda functions. It also sends elevator-specific metrics to the AWS Cloud.\nYou can invoke a Lambda function on the Greengrass core through device shadow updates or as a subscriber to a local MQTT topic. We are using a Lambda function for the following:\nTo publish elevator telemetry to a local MQTT topic. The Greengrass core aggregates the telemetry before it is streamed back to the AWS Cloud for more processing and aggregation.\nTo evaluate sensor data locally. This can result in an action being performed on the elevator. For example, if the elevator motor overheats, the elevator is taken out of service and placed into maintenance.\nElevator floor status and availability is tracked by device shadow updates. The device shadow updates are being consumed by a custom web interface which provides a means to visualize our elevators.\nTo determine, based on the local device shadow, if the elevators are available for use. If available, the Lambda function sends the elevators to a random floor by setting the desired state. Because a Lambda function can run for an unlimited amount of time on Greengrass, this Lambda function sleeps for 30 seconds before it sends the elevators to another random floor.\nDevice-specific code\nOn initial startup, the elevators use the Greengrass Discovery API to locate and connect securely to the Greengrass core. Our device-specific code publishes to the local MQTT queue elevator-specific data, such as motor temperature, shaft vibration, door speed, current floor, and availability. The device-specific code can also receive messages from the local MQTT queue, which provides a channel for duplex messaging.\nProviding local visualization\nWe can consume the MQTT device shadows to visualize the status of our elevators in a web application. We can also perform remote command and control by updating the desired state of the device shadows. This, in turn, synchronizes the AWS IoT device shadow with the Greengrass device shadow which is then interpreted by our device-specific code to provide command and control.\nUsing this pattern of remote command and control, we can optimize the morning rush so that the elevators are relocated to the ground floor to minimize waiting. Or we can take inputs from a building control system so that when a VIP uses a key card to enter the parking garage, an elevator is prioritized and dispatched.\nThis pattern also allows us to provide remote command and control to an operations center to remotely move stuck elevators or take elevators in and out of service during maintenance events.\nAll of these scenarios are accomplished by reading the reported state of the device in AWS IoT and setting the desired state. Changes set to the desired state flow through AWS IoT to the Greengrass core and to the elevators.\n  Increasing our capability maturity\nBy using multiple AWS services, we can build an architecture that will help us achieve PdM maturity\nStep 1: Providing detective capabilities\nSynchronizing elevator telemetry with AWS IoT opens up a world of possibility. The service has a rules engine that has a predict function that can evaluate IoT messages against an Amazon Machine Learning (Amazon ML) model.\nAs an example, we can create a model to predict motor reliability and evaluate data from messages being synchronized with AWS IoT against this model.\n{\n  \xe2\x80\x9dsql"": ""SELECT * FROM \'elevator/#/motor_temperature\'"",\n ""ruleDisabled"": false,\n ""actions"": [{\n  ""cloudwatchMetric"": {\n  ""roleArn"": ""arn:aws:iam::XXXXXXXXXXXX:role/iam_role"",\n  ""metricName"": ""maintenance-status"",\n  ""metricNamespace"": ""pm-metrics"",\n  ""metricValue"": ""${machinelearning_predict\n  (\'motor_reliability\',\n   \'arn:aws:iam::XXXXXXXXXXXX:role/iam_role\', *)\n  .predictedLabel}"",\n  ""metricUnit"": ""None""\n  }\n }]\n}\nJSON\n We are now moving into predictive territory.\nStep 2: Notifying and orchestrating\nLet\xe2\x80\x99s assume the AWS IoT rules engine used a predict function against an Amazon Machine Learning model and an anomaly or leading indicator for failure has been detected. This information can be used to orchestrate a workflow that will get the elevator repaired.\nBy using Amazon CloudWatch alarms and Amazon Simple Notification Service (Amazon SNS), you can use an approach like the one described in the \xe2\x80\x9cFanout\xe2\x80\x9d section of Common Amazon SNS Scenarios in the Amazon SNS Developer Guide. In this approach, you publish a message to an SNS topic not only to provide notification, but to start a workflow through a Lambda function\nStep 3: Providing state coordination\nWe can use AWS Step Functions, a service that is part of the AWS serverless platform, to provide branch logic and coordination. Step Functions makes it simple to orchestrate Lambda functions for serverless applications.\nUsing Step Functions, we can construct a state machine that can take input in the form of JSON from our Lambda function. Our state machine consists of steps and transitions between each step that, depending on the issue detected, take a different path for resolution.\n  Each step correlates to a Lambda function. A step could be performing a manual approval process and waiting for the building supervisor to approve the work or booking the job in the ERP platform. Step Functions logs the state of each step, so if things go wrong, you can diagnose and debug problems quickly.\nThis example uses a manual approval process. The state machine is waiting for approval of the maintenance request. For more information about the manual approval process used in this example, see the Implementing Serverless Manual Approval Steps in AWS Step Functions and Amazon API Gateway blog post.\nSummary\nIn this post, we described a pattern that you can use to advance PdM in your organization. AWS Greengrass brings compute to the edge, allowing you to respond to local events quickly and provide operational intelligence to your devices, even without access to the internet. Greengrass uses a Lambda programming model, which helps reduce the cost of developing IoT applications.\nWith local Lambda functions and the ability to use services such as Amazon Machine Learning and AWS Step Functions, you can drive maturity in your business, climb the PdM maturity curve, and ultimately save your organization time and money.\nFor video of the content included in this post, see the AWS Developer Day video.\nIf you have questions or other feedback, please leave it in the comments below.'"
244,Deploy Fleets Easily with AWS IoT Device Management Services,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/deploy-fleets-easily-with-aws-iot-device-management-services/,"b'Introduction\nThe Internet of Things (IoT) offers the potential for data acquisition and digital interaction in areas previously inaccessible at an unprecedented scale. The magnitude of this opportunity affects individuals, organizations, and governments in many different ways. In manufacturing, for example, many makers of existing products are racing to integrate connected features into their offerings and deliver these products to the market in substantial quantities. Startups and other organizations are creating completely new product lines built around connectability and cloud-based service integration.\nIn order to address the complexity of provisioning and managing connected things manufacturers need ways to simplify and automate tasks like provisioning device identities and providing those identities to the devices as they are being manufactured in a secure and repeatable fashion. Enabling this formidable task is a new feature from the AWS IoT Device Management service that enables bulk provisioning of connected things.\nThis new feature allows customers to register large number of devices at once. Certificates, things, and policy resources make up the principal and permissions configuration for each thing within AWS IoT Core. Regardless of the specific nature of your business, when developing a solution using AWS IoT Services, you will need to create a \xe2\x80\x98thing\xe2\x80\x99 to store information about each device, create a certificate to provide secure credentials for the \xe2\x80\x98thing\xe2\x80\x99, and set up permissions by attaching the certificate to an appropriate policy for the \xe2\x80\x98thing\xe2\x80\x99. AWS IoT bulk provisioning feature simplifies and automates the registration process.\nHere\xe2\x80\x99s a real world example from an AWS customer, Trimble. Best known for its GPS technology, Trimble integrates a wide range of positioning technologies including GPS, laser, optical, and inertial technologies with application software, wireless communications, and services to provide complete commercial solutions. \xe2\x80\x9cAWS IoT Device Management has helped streamline our device onboarding, which has enabled us to meet our planned production throughput for connected devices.\xe2\x80\x9d said Jim Coleman, Senior Engineer, Trimble. [1] Mr. Coleman also shared during his talk at AWS reInvent 2017 that his team achieved a 4x increase in device provisioning throughput using AWS IoT bulk provisioning feature. [2]\nFor more detail about AWS IoT certificates, things, policies and the rest of the AWS IoT security model have a look here in this article.\nUse Cases for IoT Fleet Provisioning\nHere at AWS we start with the customer and work backwards when we design services. When considering use cases for provisioning it is only natural that we should do the same. How will our customers interact with the connected device? Will it have a user interface? Will customers need to pair it with a mobile device? Might it have a WiFi access point that they can connect to and configure with a browser? Will it require any configuration at all? Will there be a service subscription associated with the device?\nWhile we won\xe2\x80\x99t attempt to answer all these questions in this blog post, we will use their influence to guide how we explore solution design for bulk provisioning. Let us consider this scenario: our customer obtains a device from a retail outlet and Bluetooth pairs it with a mobile device running an application used to configure the device. Once the device is configured, the mobile app is no longer required for general operations of the device. The device essentially operates stand-alone and has its own \xe2\x80\x9cidentity.\xe2\x80\x9d\nWhen the device was manufactured in the factory, the device was provisioned with a set of certificates, a thing name, and one or more AWS IoT policies. When the device is powered on and configured with Internet access by the mobile application, the device can then connect directly to the AWS IoT Core service, supply its credentials, and be authenticated by presenting valid certificates. The connected device is authorized to interact with the AWS IoT Core service based on provisioned policies.\nReviewing Options\nWhile this post focuses on the AWS IoT Device Management bulk provisioning feature, there are other available options within AWS IoT Core for use in provisioning devices at scale. AWS IoT Core includes a feature set called Just in Time Registration (JITR) that allows for pre-provisioned and device deployed certificates signed by a customer-provided certificate authority (CA) to be registered with AWS IoT Core the first time a device connects. More detail can be found on the AWS IoT JITR feature in this article.\nExploring AWS IoT Device Management Bulk Provisioning Features\nIn order to make productive use of the AWS IoT Device Management bulk provisioning feature you\xe2\x80\x99ll need to prepare a few AWS resources prior to starting the provisioning task. Those resources include a provisioning template, an S3 bucket location, a service role and a data file. Additionally, you will need to create X.509 certificates and generate certificate signing requests (CSRs). We\xe2\x80\x99ll go over each of those resources in greater detail next.\nCreate Provisioning Template\nA provisioning template contains variables that are replaced when the template is used to provision a device. A dictionary (map) is used to provide values for the variables used in a template. The bulk provisioning task will use the JSON data file as the replacement variable values when the task is run.\nThe following is a minimally complete example of a provisioning template. More detail on building these templates can be found in the AWS IoT Core documentation located here.\nPaste the contents below into a file and save it as provisioning-template.json.\n{\n  ""Parameters"": {\n    ""ThingName"": {\n      ""Type"": ""String""\n    },\n    ""SerialNumber"": {\n      ""Type"": ""String""\n    },\n    ""CSR"": {\n      ""Type"": ""String""\n    }\n  },\n  ""Resources"": {\n    ""thing"": {\n      ""Type"": ""AWS::IoT::Thing"",\n      ""Properties"": {\n        ""ThingName"": {\n          ""Ref"": ""ThingName""\n        },\n        ""AttributePayload"": {\n          ""version"": ""v1"",\n          ""serialNumber"": {\n            ""Ref"": ""SerialNumber""\n          }\n        }\n      }\n    },\n    ""certificate"": {\n      ""Type"": ""AWS::IoT::Certificate"",\n      ""Properties"": {\n        ""CertificateSigningRequest"": {\n          ""Ref"": ""CSR""\n        },\n        ""Status"": ""ACTIVE""\n      }\n    },\n    ""policy"": {\n      ""Type"": ""AWS::IoT::Policy"",\n      ""Properties"": {\n        ""PolicyDocument"": ""{\\""Version\\"": \\""2012-10-17\\"",\\""Statement\\"": [{\\""Effect\\"": \\""Allow\\"",\\""Action\\"": [\\""iot:Publish\\""],\\""Resource\\"": [\\""*\\""]}]}""\n      }\n    }\n  }\n}\n  Create Certificates and Certificate Signing Requests (CSRs)\nNext, we\xe2\x80\x99ll create certificates and signing requests for our devices. For the purpose of this example we will provision 3 devices which will use individually unique certificates. In this example, we\xe2\x80\x99ll be using the openssl command on an AWS EC2 instance running Amazon Linux to create the certificates. The commands below will create the certificate private key file and the CSR file for each of the 3 devices.\nopenssl req -new -newkey rsa:2048 -nodes -keyout device_one.key -out device_one.csr -subj ""/C=US/ST=WA/L=Seattle/O=MyOrg/CN=MyDept""\nopenssl req -new -newkey rsa:2048 -nodes -keyout device_two.key -out device_two.csr -subj ""/C=US/ST=WA/L=Seattle/O=MyOrg/CN=MyDept""\nopenssl req -new -newkey rsa:2048 -nodes -keyout device_three.key -out device_three.csr -subj ""/C=US/ST=WA/L=Seattle/O=MyOrg/CN=MyDept""\nGenerate JSON data file and copy to S3 bucket\nWith the provisioning template and CSR files created, we can now build our JSON data file. The data file must be a newline-delimited JSON file. Each line contains all of the parameter values for provisioning a single device. For this example, our data file should appear as follows:\n{""ThingName"": ""device-one"", ""SerialNumber"": ""001"", ""CSR"": ""*** CSR FILE CONTENT ***""}\n{""ThingName"": ""device-two"", ""SerialNumber"": ""002"", ""CSR"": ""*** CSR FILE CONTENT ***""}\n{""ThingName"": ""device-three"", ""SerialNumber"": ""003"", ""CSR"": ""*** CSR FILE CONTENT ***""}\n  Note that the CSR file content above was omitted in the above example. The CSR file contents should be formatted into a single line and included as the value for the CSR parameter. A properly formatted CSR file content string has the \xe2\x80\x94\xe2\x80\x93BEGIN CERTIFICATE REQUEST\xe2\x80\x94\xe2\x80\x93 and \xe2\x80\x94\xe2\x80\x93END CERTIFICATE REQUEST\xe2\x80\x94\xe2\x80\x93 lines removed and the line breaks, or carriage returns, converted into the escape sequence \\n so that the content fits into a single string.\nHere is an example of how to convert CSR file contents into a single string. Below we have an unmodified example CSR file content:\n-----BEGIN CERTIFICATE REQUEST-----\nMIICkjCCAXoCAQAwTTELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQH\nEwdTZWF0dGxlMQ4wDAYDVQQKEwVNeU9yZzEPMA0GA1UEAxMGTXlEZXB0MIIBIjAN\nBgkqhkiG9w0BAQEFAAZCAQ8AMIIBCgKCAQEA5F5erQEDXqR0QgwDPlAE8u36c6Xr\npxA080KyaW8BQl0ZOwrxwZwtO/hpcg86d97DfY1gpw8RqftPEaVJe3451CWoc8a5\nAKpJg82LQroQI8DNkdHl+wgdkaf9GvYzFiDLIQ3oNGa27Zx58Ve8qh+ymAo6g3+d\nkdCfbcJhW/XqaJZeF5+lXGDXdrNotRealnm6kVJxMAqxEcJGpxDIRCaTjAES\nyLcZPyOnEGBuUs68eKT6P2Wiyv8rTaO9E59FaSNcl8AMiK23AJt5sql1ZybBV8o+\nWCQ3L2+nZnJVK9TME0ZZ+18AnfVKFhZYcoV2/UxXMAa3T6LFzw6DAhrH3QIDAQAB\noAAwDQYJKoZIhvcNAQEFBQADggEBAKCaWAvRargxBa9k1zZ2nI7y1mpuzTcgoOMj\nIDR/9DxGjS913AtDfpYm/cM+1x38lNfe3qRQHTmw3UnPUlNJSLTA6rCepllpMQSe\nXgaG60PTJ6/h0zvPwdUg1JOEE3lxlSJz4pHiT2Sdmyleg1hp7jezFqGEelKd+Xfd\nbfp7rNBESIq1ymWdagXnsyWjN34JqvWiS6J4NWzO2zlFkHghkbMOwOZJRrZuyOVs\ncjDZVgqYHt9xJD4Rm6U4L6uFQabHElw2IwT6izSCzU50Ahjj89snBCKnLWCe0XTb\nojVkIg5RofqzP1VwYtx5ORq93/YOxHqrpWDTa7q64BFzp1v7LlQ=\n-----END CERTIFICATE REQUEST-----\n  With the content above contained in a file named device-one.csr, you can run the following commands to process the file into a properly formatted string.\ngrep -v REQUEST device-one.csr | awk \'NF {sub(/\\r/, """"); printf ""%s\\\\n"",$0;}\' > single-string-file.out\nThe file single-string-file.out contains the CSR file formatted as a single string for use in the bulk-provisioning-data.json file.\nAn example output of the command above is as follows. Notice that the line feeds have become \xe2\x80\x9c\\n\xe2\x80\x9d and that the BEGIN and END lines have been removed. Include the single string CSR content for each device specified in your data file.\n\nMIICkjCCAXoCAQAwTTELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQH\\nEwdTZWF0dGxlMQ4wDAYDVQQKEwVNeU9yZzEPMA0GA1UEAxMGTXlEZXB0MIIBIjAN\\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5F5erQEDXqR0QgwDPlAE8u36c6Xr\\npxA080KyaW8BQl0ZOwrxwZwtO/hpcg86d97CfY1gpw8RqftPEaVJe3451CWoc8a5\\nAKpJg82LQroQI8DNkdHl+wgdkaf9GvYzFiDLIQ3oNGa27Zx58Ve8qh+ymAo6g3+d\\nkdCfbcJhW/XqaJZeF5+lXGDXdrPccioASwybogusVJxMAqxEcJGpxDIRCaTjAES\\nyLcZPyOnEGBuUs68eKT6P2Wiyv8rTaO9E59FaSNcl8ASillYAJt5sql1ZybBV8o+\\nWCQ3L2+nZnJVK9TME0ZZ+18AnfVGFhZYcoV2/UxXMAa3T6LFzw6DAhrH3QIDAQAB\\noAAwDQYJKoZIhvcNAQEFBQADNotRealAKCaWAvRargxBa9k1zZ2nI7y1mpuzTwooOMj\\nIDR/9DxGjS913AtDfpYm/cM+1x38lNfe3qRQHTmw3UnPUlNJSLTA6rCepllpMQSe\\nXgaG60PTJ6/h0zvLwdUg1JOEE3lxlSJz4pHiT2Sdmyleg1hp7jezFqGEelKd+Xfd\\nbfp7rNBESIq1ymWdagXnsyWjN34JqvWiS6J4NWzO2zlFkHghkbMOwOZJRrZuyOVs\\ncjDZVgqYHt9x\nSave this JSON file as bulk-provisioning-data.json and copy this file to a location in an S3 bucket located in the region where you will be running the provisioning task.\nCreate Service Role\nWhen the provisioning task is executed, the IoT service will need to locate the data file in an S3 bucket. You can use an existing bucket or create a new one specifically for use in provisioning a device in the AWS IoT Core service. With either choice, you will need to create a role that allows AWS IoT Core to access the bucket to retrieve the data file.\nWhen creating the role, the trust policy should appear like this example:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Sid"": """",\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""Service"": ""iot.amazonaws.com""\n      },\n      ""Action"": ""sts:AssumeRole""\n    }\n  ]\n}\n  Create a policy to provide permissions to your S3 bucket. Be sure that your bucket name is properly entered.\nUse the example below as a guide:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:GetObject""\n      ],\n      ""Resource"": [\n        ""arn:aws:s3:::replace_with_your_bucket_name/*""\n      ]\n    }\n  ]\n}\n  Attach the policy to the role.\nNext you can attach an AWS managed policy to the role to provide the AWS IoT Core Service permissions necessary to successfully execute the provisioning steps. In the IAM console, you can search for \xe2\x80\x98AWSIoTThings\xe2\x80\x99 to find the \xe2\x80\x98AWSIoTThingsRegistration\xe2\x80\x99 AWS managed policy. Attach this policy to your role in addition to the S3 permissions policy created in the previous steps.\nNow that you\xe2\x80\x99ve created the role, note the role ARN as you will require it in later steps.\nRun the Bulk Provisioning Task\nNow to the part you\xe2\x80\x99ve been waiting for, running the bulk provisioning task! All the steps prior to this created data or configuration used for this activity. In order to run the bulk provisioning, you will need to have the AWS CLI installed and configured for a AWS IoT Core supported region with a user that has the proper permissions. For this example, an IAM user with the AWS managed policy arn:aws:iam::aws:policy/AWSIoTFullAccess attached was used. In addition to this policy, ensure that the IAM user executing the commands has the IAM:PassRole permission.\nThe IAM:PassRole permission can be added to the IAM user via an inline policy. An example policy is as follows:\n{\n   ""Version"": ""2012-10-17"",\n     ""Statement"": [\n     {\n       ""Effect"": ""Allow"",\n       ""Action"": ""iam:PassRole"",\n       ""Resource"": ""*""\n     }\n  ]\n}\n  Remember to replace the values in the example command below with your values for the template file, data file, data file bucket and role ARN.\naws iot start-thing-registration-task --template-body file:///home/ec2-user/provisioning-template.json --input-file-bucket replace_with_your_bucket_name --input-file-key bulk-provisioning-data.json --role-arn arn:aws:iam::123456789012:role/iot-bulk-provisioning-role\nAfter running the command successfully, you should receive a task id output like the following:\n{\n""taskId"": ""5d111206-093c-4ab3-1234-b2f14b0c208d""\n}\nYou can inspect your recently executed tasks using the list-thing-registration-tasks command as shown below.\naws iot list-thing-registration-tasks\n{\n""taskIds"": [\n""d62ded50-1ac6-4424-5678-84fed7b9f916"",\n""5d111206-093c-4ab3-1234-b2f14b0c208d""\n]\n}\nNext, you can see the details and check the status of the registration task using the describe-thing-registration-task command as shown below.\naws iot describe-thing-registration-task --task-id 5d111206-093c-4ab3-1234-b2f14b0c208d\n{\n""status"": ""Completed"",\n""successCount"": 3,\n""creationDate"": 1511202602.898,\n""templateBody"": \xe2\x80\x9c** removed for readability **"",\n""lastModifiedDate"": 1511202604.694,\n""roleArn"": ""arn:aws:iam::123456789012:role/iot-bulk-provisioning-role"",\n""inputFileKey"": ""bulk-provisioning-data.json"",\n""inputFileBucket"": ""my_bucket"",\n""taskId"": ""5d111206-093c-4ab3-1234-b2f14b0c208d"",\n""failureCount"": 0,\n""percentageProgress"": 100\n}\nLastly, you can also get a more detailed report using the list-thing-registration-task-reports command as shown below.\naws iot list-thing-registration-task-reports --task-id eacb0860-e99a-1234-5678-f7a976fc2408 --report-type RESULTS\n{\n""resourceLinks"": [\n""https://aws-iot-btp-prod-us-east-1.s3.amazonaws.com/123456789012/a779514e-51f1-4027-beef-73447cafebaca/successful/a779514e-51f1-4027-bd2e-73447efcbaca-1?X-Amz-Security-Token=FQoDYXdzEE4aDOjiGWbWwt7xASULzSLYAb37lzpZBsW7HPpYS0ko8MtWntXCed0QhYKZ0i4hBJZ6JAoqvBE58LcytLTgmxUwg3NS2ZnbYEzH%2FH%2Fxd1XalbertMZCpYg2lF0fpbAjt2B%2FJog%2Fj0FtyflWztC9s0NdaolhFuEj3XNQpL3qHK41jKhITYA3imKdX75Z6x2%2BHRSjCpvvTrQllDLHS3dC1nFOXYXGd1ChjxnkjKkhQGPQlrAoGPR3TMMCpi73fDAtR72yQ0mTF%2FJHEZ4g6umLj%2FAbHlBeiA%2BQ99QhCaUQ3Sco1xL7BpJ7jkuYmCj%2B5ZbRBQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20171204T204440Z&X-Amz-SignedHeaders=host&X-Amz-Expires=86400&X-Amz-Credential=ASIAIOE5MA3ZIRF7WHAT%2F20171204%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=600b27c36c484cb8b3bfa707beefde0fe279d92ccb9f2a4848a13e95442b854""\n],\n""reportType"": ""RESULTS""\n}\nNavigate to the link returned in \xe2\x80\x9cresourceLinks\xe2\x80\x9d for a JSON file containing the signed certificate values, the thing ARNs and the policy ARNs for the newly provisioned things.\nIf the list-thing-registration-task-reports with report type RESULTS returns an empty list then there may have been errors processing the data file. Details on the errors can be retrieved by issuing the list-thing-registration-task-reports command with the \xe2\x80\x94report-type parameter value as ERRORS. The link returned will be a link to an error report which is helpful for troubleshooting.\nWith our IoT things now fully provisioned, we can provide the certificate files to manufacturing to be copied to the devices as they come off of our assembly line. Then our products can be packed and shipped to retailers where they can be purchased and enjoyed by customers.\nWrapping Up\nUsing AWS IoT bulk provisioning feature, device manufacturers and suppliers can simplify and automate tasks like provisioning device identities in a secure and repeatable fashion as demonstrated by the examples. While the examples here are a start, there is much more that AWS IoT Device Management offers organizations for deploying and managing large fleets of connected things. I hope you found the blog useful and informative, and I encourage you to learn more about the new features of the AWS IoT Core to help your organization make the most of these and other enabling new technologies from AWS.\nLearning More\nMore on AWS IoT Device Management\nhttps://aws.amazon.com/iot-device-management\nAWS IoT Device Management \xe2\x80\x93 Features\nhttps://aws.amazon.com/iot-device-management/features/\nAWS IoT Device Provisioning\nhttp://docs.aws.amazon.com/iot/latest/developerguide/iot-provision.html\nCitations\n[1] AWS Announces a Slew of New IoT Services; Brings Machine Learning to the Edge\nhttp://www.businesswire.com/news/home/20171129006079/en/AWS-Announces-Slew-New-IoT-Services-Brings\n[2] AWS re:Invent 2017: AWS IoT Device Management (IOT330)\nhttps://youtu.be/Qi1FVPXDPQc?t=1065'"
245,Building Connected Vehicle Solutions on the AWS Cloud,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/building-connected-vehicle-solutions-on-the-aws-cloud/,"b'In response to massive technological changes that are transforming the global automotive industry, the AWS Solutions team has developed the AWS Connected Vehicle solution in order to address the industry\xe2\x80\x99s need for scalability, security, and flexibility when connecting products and services for next-generation vehicles. This reference architecture is designed in accordance with AWS best practices, and can be easily extended to solve a number of problems common to automotive manufacturers and suppliers. The AWS Connected Vehicle solution uses AWS CloudFormation to automatically deploy the architecture into your AWS account so you can start building your own automotive solutions in a matter of minutes.\nThe AWS Connected Vehicle solution consists of four layers: an ingestion services layer, a data services layer, an application services layer, and a platform API layer. Each layer strategically implements key AWS services that work together to enable secure, fast, simple, and scalable consumption, delivery, storage, and analysis of connected vehicle data.\nHere\xe2\x80\x99s a quick tour of the solution and some of the architectural considerations that drove the development of this reference architecture.\nThe bedrock of any successful cloud-based connected vehicle solution is the secure and scalable ingestion and rapid processing of connected vehicle data. To accomplish this, the AWS Connected Vehicle solution leverages AWS IoT, a managed cloud platform that lets connected devices easily and securely interact with cloud applications and other devices. Click here for a detailed introduction to the AWS IoT platform components.\nThe AWS IoT Device SDK makes it easy to seamlessly authenticate and connect devices with the Device Gateway and securely communicate with your AWS environment. AWS IoT automatically scales to support billions of devices and trillions of messages, and can reliably process and route those messages to other AWS services using a simple rules engine.\nTo add enhanced local compute, messaging, caching, and sync capabilities to your vehicle, you can use AWS Greengrass. AWS Greengrass Core is software that runs on your connected vehicle and works in conjunction with the IoT Device SDK to extend AWS to act locally on data produced by the vehicle. As a result, you can easily preprocess vehicle data, enable offline interaction, and manage over-the-air updates using the same simple code you use to write AWS Lambda functions.\nOnce you\xe2\x80\x99ve delivered your connected vehicle data into the AWS Cloud, you need a reliable way to store it. Because connected vehicle solutions can store sensitive data from hundreds of thousands of vehicles from all over the world, your storage solution must be secure, scalable, and globally available. Amazon S3 meets all of these requirements and is designed to provide 99.99% availability and 99.999999999% durability of data. But how do we move connected vehicle data from AWS IoT to an Amazon S3 bucket?\nThe answer is Amazon Kinesis Firehose, a managed and scalable data delivery service capable of capturing, transforming, compressing, and encrypting terabytes of streaming data before delivering it to Amazon S3. This makes connected vehicle data storage as simple as specifying Amazon Kinesis Firehose as a destination in the AWS IoT rules engine.\nIt is important to consistently load batches of raw data from AWS IoT to Amazon S3 so it can later be queried, analyzed, and replayed. But, certain events, such as warnings or anomalies, require real-time processing. For these use cases, you can leverage Amazon Kinesis Analytics and Amazon Kinesis Streams.\nAmazon Kinesis Analytics makes it easy to build real-time streaming analytics applications using standard SQL code. As connected vehicle data moves through your Kinesis Firehose delivery stream, your streaming application will execute SQL code against the flowing data and extract interesting records. Using Amazon Kinesis, you can perform advanced anomaly detection and windowed aggregate functions, and enable real-time processing with just a few lines of simple SQL code. The following sample SQL code employs an unsupervised machine learning algorithm called random cut forest in order to assign anomaly scores to oil temperature records:\nCREATE OR REPLACE STREAM ""TEMP_STREAM"" (\n  ""ts"" TIMESTAMP,\n  ""oil_temp"" DOUBLE,\n  ""trip_id"" VARCHAR(64),\n  ""vin"" VARCHAR(32),\n  ""ANOMALY_SCORE"" DOUBLE);\n \nCREATE OR REPLACE STREAM ""ANOMALY_OUTPUT_STREAM"" (\n  ""ts"" TIMESTAMP,\n  ""value"" DOUBLE,\n  ""trip_id"" VARCHAR(64),\n  ""vin"" VARCHAR(32),\n  ""ANOMALY_SCORE"" DOUBLE, \n  ""telemetric"" VARCHAR(32));\n\nCREATE OR REPLACE PUMP ""STREAM_PUMP"" AS INSERT INTO ""TEMP_STREAM"" \nSELECT STREAM ""ts"",""val"", ""trip_id"", ""vin"", ANOMALY_SCORE FROM \n  TABLE(RANDOM_CUT_FOREST(\n    CURSOR(SELECT STREAM * FROM ""SOURCE_SQL_STREAM_001"" WHERE ""name"" = \'oil_temp\')));\n\nCREATE OR REPLACE PUMP ""OUTPUT_PUMP"" AS INSERT INTO ""ANOMALY_OUTPUT_STREAM"" \nSELECT STREAM *,\'oil_temp\' as telemetric FROM ""TEMP_STREAM"";\nSQL\nYou can then extract these anomalies and send them to an Amazon Kinesis Stream to be processed by custom microservices. When developing these microservices, you should build them in an agile, scalable, and maintainable way. The easiest way to do this on the AWS Cloud is to use AWS Lambda functions which natively enable event-driven, on-demand data processing and automatically scale to meet the demand of your connected vehicle data. Additionally, since Lambda functions are serverless, you can run your code without provisioning or managing servers. Just upload your code, define a trigger, and Lambda takes care of everything required to run and scale your code.\nOnce your microservices process the data, you need to make sure that downstream applications can easily consume the results. One simple way to accomplish this is with Amazon DynamoDB, a fast, flexible, and massively scalable database solution that allows you to query terabytes of data with millisecond latency.\nWith your data in managed DynamoDB tables, you now need a streamlined method for retrieving this data for a variety of mobile, web, or in-vehicle applications. One easy method is to use Amazon\xe2\x80\x99s managed API creation, management, and publishing service, API Gateway. The AWS Connected Vehicle solution is deployed with a tailored RESTful API that acts as a \xe2\x80\x98front door\xe2\x80\x99 for a Lambda function that can process requests from mobile and web apps and third-party service providers. Authorization and access control is handled via integration with Amazon Cognito User Pools, allowing drivers with authenticated profiles to retrieve only the data they own. With a few clicks, you can add methods to the API and provide extended access to backend data and business logic.\nWhile there is no limit to the kinds of connected vehicle services and applications you can build with the AWS Connected Vehicle solution, the reference architecture comes packaged with a variety of high-level services to showcase solutions that address common problems in the automotive space, and help demonstrate microservice application development on top of the AWS Connected Vehicle solution.\nThe just-in-time-registration (JITR) use case shows you how to simplify the process of registering a new vehicle with AWS IoT. The JITR workflow triggers an AWS Lambda function that activates a signed, unknown vehicle certificate, and attaches a custom security policy to it, enabling it to be used for authentication and authorization with AWS IoT.\nThe anomaly detection use case demonstrates how you can detect outliers in streaming data using Amazon Kinesis. As raw vehicle sensor data streams to Amazon S3 through an Amazon Kinesis Firehose delivery stream, an Amazon Kinesis Analytics application analyzes each record, extracts anomalies, and sends those records to an Amazon Kinesis Stream, triggering an AWS Lambda function that stores the data and notifies the driver of any issues.\nThe trip data use case demonstrates the consumption and storage of connected vehicle data that was previously processed by AWS Greengrass. Vehicle sensor data is aggregated on the vehicle and pushed to the AWS Connected Vehicle solution at regular intervals, and then stored in an Amazon DynamoDB table. Upon completion of a trip, a driver safety score microservice is triggered, which uses the aggregated trip data to calculate a safety score based on the driver\xe2\x80\x99s speed, idling, and acceleration metrics, then subsequently notifies the driver.\nFinally, diagnostic trouble code (DTC) detection is a simple but valuable use case that improves the vehicle ownership and maintenance experience. When DTCs are detected by AWS IoT, it invokes an AWS Lambda function that stores the DTC in an Amazon DynamoDB table, translates the DTC into layman\xe2\x80\x99s terms, and then alerts the driver of the issue.\nIn addition to providing scalable, modular, API-driven applications, the AWS Connected Vehicle solution uses AWS services that are entirely managed and serverless. Therefore, you do not need to worry about patching, managing, or scaling your infrastructure to meet the demand of more users or vehicles. Furthermore, since this reference architecture is open-source, and leverages a pay-as-you-go pricing model, there is no need to worry about software licenses or contracts, or long-term purchase agreements. As with other AWS services, you pay for only what you use. As a result, users of the AWS Connected Vehicle solution can focus on building innovative applications and solutions instead of worrying about overhead management and administrative tasks.\nBuild away, automotive innovators and industry changers! We can\xe2\x80\x99t wait to see what you create with the AWS Connected Vehicle solution.\nAWS CloudFormation\nAWS IoT\nAWS Greengrass\nAmazon S3\nAmazon Kinesis Firehose\nAmazon Kinesis Analytics\nAmazon Kinesis Streams\nAmazon DynamoDB\nAmazon API Gateway\nAmazon Cognito'"
246,How to Use Substitution Templates in the Rules Engine to Enrich IoT Messages,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-use-substitution-templates-in-the-rules-engine-to-enrich-iot-messages/,"b'Post by Marcos Ortiz, an AWS Solutions Architect\nThe AWS IoT platform allows you to use substitution templates to augment the JSON data returned when a rule is triggered and AWS IoT performs a rule action. The syntax for a substitution template is ${expression}, where expression can be any expression supported by AWS IoT in SELECT or WHERE clauses. For more information about supported expressions, see AWS IoT SQL Reference.\nThe substitution template is an important feature for AWS IoT customers, especially when there\xe2\x80\x99s a need  to dynamically add some contextual information that is not stored in the payload but is part of the MQTT communication (for example, the MQTT client ID or the MQTT topic structure) to some of your actions.\nBackground\nIn this blog post, we use a fictitious company called ACME Offshore, a rig contractor that leases drilling rigs to oil and gas operators. ACME Offshore wants to differentiate itself from its competitors by implementing an ambitious plan to transform its rigs into what they call next generation rigs. The idea is to provide all the rig sensors data in near real-time to its customers. In this post, we will show how to leverage the AWS IoT substitution templates in IoT rules so you can dynamically configure your IoT actions with functions provided by the AWS IoT SQL Reference.\nWe provide an AWS CloudFormation template that will allow you to create all the AWS resources required to run a demo. At the end of the post, we provide instructions for automatically deleting all the resources created.\nArchitecture\nThe following diagram shows the overall architecture.\nAs the rigs operate, thousands of sensors are continuously generating data. That data is being collected, aggregated, used locally on the rig, and sent to the AWS IoT platform. All the data sent by a rig will go to a \xe2\x80\x9cmyrigs/id\xe2\x80\x9d topic, where \xe2\x80\x9cid\xe2\x80\x9d is the unique identifier for the rig. The rig can send two types of data: data points and events.\nThe following is an example of a payload sent by a rig:\n{\n    ""datapoints"":[\n        {""recorded_at"":1498679312, ""well_depth"":10, ""bit_depth"":0.0},\n        {""recorded_at"":1498679313, ""well_depth"":10, ""bit_depth"":0.1},\n        {""recorded_at"":1498679314, ""well_depth"":10, ""bit_depth"":0.2}\n    ],\n    ""events"": {\n        ""errors"": [\n            {""recorded_at"":1498679312, ""code"":1001, ""message"":""Error 1001""},\n            {""recorded_at"":1498679313, ""code"":1002, ""message"":""Error 1002""}\n        ],\n        ""warnings"": [\n            {""recorded_at"":1498679313, ""code"":1003, ""message"":""Error 1003""},\n            {""recorded_at"":1498679314, ""code"":1004, ""message"":""Error 1004""}\n        ],\n        ""infos"": [\n            {""recorded_at"":1498679314, ""code"":1005, ""message"":""Error 1005""},\n            {""recorded_at"":1498679314, ""code"":1006, ""message"":""Error 1006""}\n        ]\n    }\n}\nJSON\nEach payload can have a combination of data points and events. There are three AWS IoT rules to process the data coming from the rigs.\n1. Data Points Rule\nThe data points rule subscribes to the \xe2\x80\x9cmyrigs/+\xe2\x80\x9d topic so it will be able to augment data points sent by any rig. It matches on the MQTT topic only and triggers two IoT actions when new data points are available. The \xe2\x80\x9c+\xe2\x80\x9d and the \xe2\x80\x9c#\xe2\x80\x9d characters are wildcards that can be used to subscribe to IoT topics. For more information about topic wildcards, see Topics in the AWS IoT Developer Guide.\n1.1 Anomalies Action\nThis action sends all the data points to an Amazon Kinesis stream. An AWS Lambda function reads from that stream in order to detect any anomalies in the data points. In the demo portion of this post, the Lambda function checks for the following scenarios:\nbit_depth values less than 0.\nwell_depth values less than 0.\nbit_depth values greater than well_depth values, where both bit_depth and well_depth are greater than 0.\nWhen an anomaly is detected, the Lambda function writes it to a DynamoDB table. Recording data anomalies is important not just for sensor maintenance and quality control, but also for operations and security.\n1.2 Firehose Action\nThis action sends all the data points to an Amazon Kinesis Firehose delivery stream. The purpose of the Data Points IoT rule is to create a data lake of rig telemetry in near real time. That data can be used later on for replay purposes. The ability to replay data makes it possible to reprocess the data against new versions of data point-consuming systems. It is also important for auditing and reporting.\n2. Events Rule\nThe events rule subscribes to the \xe2\x80\x9cmyrigs/+\xe2\x80\x9d topic so it can process all events being sent by any rig. It queries only the events portion of the payload and triggers one AWS IoT action when new events are available.\nEvents can be generated manually or automatically in cases like the following:\nA rig operator requests support from the onshore team.\nThe rig state changes.\nPumps are turned on.\n2.1 Events Action\nThis action sends all the events received to a Kinesis Firehose delivery stream. Events can be stored in a S3 bucket.\n3. Error Events Rule\nThe error events rule subscribes to the \xe2\x80\x9cmyrigs/+\xe2\x80\x9d topic so it can process all error events sent by any rig. It queries only the error events portion of the payload and triggers two AWS IoT actions when new error events are available.\n3.1 Republish Action\nThis action republishes all error events coming from a given rig to a specific MQTT topic. For example, error events coming from rig 99 will be republished to \xe2\x80\x9cmyrigs/99/errors\xe2\x80\x9d. This allows monitoring systems and remote support drilling engineers to be notified in real time of any errors occurring on rigs. All that\xe2\x80\x99s required is to subscribe to the error event topic.\nSystems can receive all errors coming from all rigs by subscribing to the \xe2\x80\x9cmyrigs/+/errors\xe2\x80\x9d topic.\n3.2 Notification Action\nThis action routes all error events to an Amazon SNS topic named \xe2\x80\x9cacme-rigs\xe2\x80\x9d. This allows the same remote support drilling engineers to receive notification (e-mail or text) even if they are not in front of a computer. Amazon SNS can also notify external monitoring systems through, for example, an HTTP callback request whenever error events are received for a given rig.\nProvisioning the Demo\nClick the Launch Stack button below.\nThis will redirect you to the AWS CloudFormation console. This demo is deployed in the US East (Northern Virginia) Region. Click Next.\nOn the Specify Details page, type the following. For SnsSubscriberEmail, type your e-mail address so you can receive e-mail notifications from Amazon SNS. Click Next.\nYou can customize options (tags, permissions, notifications) on the following page or simply click Next to continue with the default options.\nOn the Review page, select the I acknowledge that AWS CloudFormation might create IAM resources box, and then click Create to launch the AWS CloudFormation stack.\nAfter a few minutes, the provisioning should be complete.\nSelect the AWS CloudFormation stack, and on the Outputs tab, copy the value for the S3BucketName key. Our Kinesis Firehose delivery stream will write data points and events to this bucket.\nAfter the provisioning is complete, you will receive an e-mail from Amazon SNS.\nClick Confirm subscription so you can receive emails from Amazon SNS whenever a rig sends error events.\nBefore we start testing the demo, let\xe2\x80\x99s review the AWS IoT substitution templates. On the Rules page in the AWS IoT console, you will see the three rules we created.\nOn the acmeRigDatapoints AWS IoT rule, we use the newuuid() AWS IoT function to set the value of our Kinesis Streams partition key. The newuuid() function returns a random 16-byte UUID, so no matter how many payloads AWS IoT receives, we will always be evenly distributing traffic between all the shards of our Kinesis stream.\nWe also use the topic AWS IoT function on a query statement so we can add the rig_id information when writing the data points to DynamoDB or S3.\nOn the acmeRigAllEvents AWS IoT rule, we only use the topic function on the query statement, so we can add the rig_id information when writing the events to the Amazon S3 bucket.\nOn the acmeRigErrorEvents, we use the topic function to dynamically set the republishing topic for our AWS IoT republish action. This allows us to dynamically republish any errors published to the \xe2\x80\x9cmyrigs/id\xe2\x80\x9d topic to the \xe2\x80\x9cmyrigs/id/errors\xe2\x80\x9d topic. For example, rig 99 sends payloads to \xe2\x80\x9cmyrigs/99\xe2\x80\x9d and any errors are republished to \xe2\x80\x9cmyrigs/99/errors\xe2\x80\x9d. If we are talking about rig 5, those topics would be \xe2\x80\x9cmyrigs/5\xe2\x80\x9d and \xe2\x80\x9cmyrigs/5/errors\xe2\x80\x9d, respectively.\nWe also use the same topic function to add rig_id context to the payload of our SNS notification.\nTesting the Demo\nNow you should be all set to test the demo. On the Test page in the AWS IoT console, in Subscription topic, type \xe2\x80\x9cmyrigs/1\xe2\x80\x9d and then click Subscribe to topic.\nFollow the same steps to subscribe to the \xe2\x80\x9cmyrigs/1/errors\xe2\x80\x9d topic. We want to subscribe to this topic so we can test our AWS IoT republish action.\nTo simulate a rig sending a payload to your AWS IoT endpoint, copy the following JSON payload to your clipboard. (In this case, the rig ID is 1.)\nThe sample payload we are using has the following anomalies:\nAt 1498679312, well_depth is less than 0.\nAt 1498679313, bit_depth is less than 0.\nAt 1498679314, bit_depth is greater than well_depth\nClick the \xe2\x80\x9cmyrigs/1\xe2\x80\x9d topic, delete all the context in the text area, and then paste the payload you just copied to your clipboard into that text area. Now click Publish to topic.\nIf you click on the \xe2\x80\x9cmyrigs/1/errors\xe2\x80\x9d topic, you should be able to see that it received the errors you published on the payload.\nNavigate to the DynamoDB table. On the Items tab, you will be able to see these three anomalies saved on that table.\nCheck the email you used on our AWS CloudFormation stack. You should receive a message with the errors we sent on our sample payload:\nAfter you publish the test payload, it should take about one minute for Amazon Kinesis Firehose to write the data points and events to the S3 bucket.\nCleaning Up\nAfter you finish testing, be sure to clean up your environment so you are not charged for unused resources.\nGo to the Amazon S3 console and delete the bucket contents.\nGo to the AWS CloudFormation console, select the \xe2\x80\x9cacme-iot\xe2\x80\x9d stack, and then click Delete Stack.\n'"
247,Bites of IoT: Creating AWS IoT Rules with AWS CloudFormation,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/bites-of-iot-creating-aws-iot-rules-with-aws-cloudformation/,"b'Welcome to another installment in the Bites of IoT blog series.\nIn this bite, we will use AWS CloudFormation, the AWS IoT rules engine, and AWS Lambda to automate the setup and teardown of two AWS IoT rules.  You can use the AWS IoT console to create and edit rules by hand, but in production you might want to use automation to make your deployments of rules repeatable and easier to manage.  AWS CloudFormation enables you to deploy rules consistently across applications, manage updates, share your infrastructure with others, and even use revision control to track changes made over time.\nConfigure the CLI\nAs with all Bites of IoT posts, we are using the AWS IoT ELF client available in AWS Labs on GitHub. If you aren\xe2\x80\x99t familiar with the ELF, see the first post in this series.\nWhat Are Rules?\nAWS IoT rules are SQL statements that can be used to perform three kinds of functions on MQTT messages:\nTest: A rule can test an MQTT message to determine if it meets some criteria.  For example, a rule could check to see if a temperature field is above or below a threshold, or if a text field contains a certain string.\nTransform: A rule can pass an MQTT message through without changing it or it can transform it in some way.  There are several SQL functions to support transformations.  For more information, see the AWS IoT SQL Reference.  Common transformations include changing a value from one system of measurement to another (e.g. Fahrenheit to Celsius), hashing sensitive information to obscure it from downstream systems (e.g. MD2, MD5, SHA1, SHA224, SHA256, SHA384, SHA512), removing information when it isn\xe2\x80\x99t useful in another data processing stage, or adding information required by other processes (e.g. timestamps).\nTrigger: When a rule is evaluated and its test criteria (if any) is met, it triggers an action.  The examples in this post cover the republish action and the AWS Lambda action.  The republish action takes a message and republishes it to another topic.  The AWS Lambda action sends the message to an AWS Lambda function.  There are several other actions available that you can use to tie into other AWS services.\nCreating a SQL-Only Rule with AWS CloudFormation\nThe first rule we are going to create will receive the \xe2\x80\x9cIoT ELF hello\xe2\x80\x9d message from ELF.  It will republish a new message on an output topic that indicates which client sent the message.  We will create the rule using the SQL rules engine in AWS IoT.\nHere is the SQL statement for our first rule:\nSELECT concat(topic(2), "" says hello!"") AS feedback FROM \'input/#\'\nLet\xe2\x80\x99s walk through each part to see what it does:\nSELECT \xe2\x80\x93 All SQL statements in the rules engine start with SELECT.\nconcat(topic(2), "" says hello!"") \xe2\x80\x93 The concat function combines two strings.\nThe first string is obtained from the topic(2) function, which means it uses the second segment of the topic.  Because ELF publishes messages on input/thing_X where X is the thing\xe2\x80\x99s ID, this string will be either thing_0 or thing_1.\nThe second string is simply  says hello!.  This part of the statement will evaluate to either thing_0 says hello! or thing_1 says hello!\nAS feedback \xe2\x80\x93 This means that, in our output message, the string we just constructed will be referred to as feedback.  Our full output message will be either { ""feedback"": ""thing_0 says hello!"" } or { ""feedback"": ""thing_1 says hello!"" }.\nFROM \'input/#\' \xe2\x80\x93 This means that we want this rule to receive messages on any topic under the topic input.  This would match input/thing_0, input/thing_1, or even input/thing_0/one_more_level.  If we didn\xe2\x80\x99t want to match all topics under input, we could change input/# to input/+.  That would only match input followed by one additional level in the topic hierarchy.  We wouldn\xe2\x80\x99t process messages on the topic input/thing_0/one_more_level if we were to use input/+.\nYAML AWS CloudFormation Template for SQL-Only Rule\nAWSTemplateFormatVersion: 2010-09-09\nDescription: A SQL only IoT republish rule that responds to a device saying hello\n\nResources:\n  SQLRepublishTopicRule:\n    Type: AWS::IoT::TopicRule\n    Properties:\n      RuleName: SQLRepublish\n      TopicRulePayload:\n        RuleDisabled: false\n        Sql: SELECT concat(topic(2), "" says hello!"") AS feedback FROM \'input/#\'\n        Actions:\n          - Republish:\n              Topic: output/${topic(2)}\n              RoleArn: !GetAtt SQLRepublishRole.Arn\n  SQLRepublishRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Action:\n              - sts:AssumeRole\n            Principal:\n              Service:\n                - iot.amazonaws.com\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: iot:Publish\n                Resource: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":topic/output/*"" ] ]\nYAML AWS CloudFormation Template Explained\nLet\xe2\x80\x99s break this down into pieces.\nSQLRepublishTopicRule Section\n  SQLRepublishTopicRule:\n    Type: AWS::IoT::TopicRule\n    Properties:\n      RuleName: SQLRepublish\n      TopicRulePayload:\n        RuleDisabled: false\n        Sql: SELECT concat(topic(2), "" says hello!"") AS feedback FROM \'input/#\'\n        Actions:\n          - Republish:\n              Topic: output/${topic(2)}\n              RoleArn: !GetAtt SQLRepublishRole.Arn\nThis section creates an AWS resource that is a topic rule (AWS::IoT::TopicRule) with several properties.\nThe first property is the rule name SQLRepublish. You\xe2\x80\x99ll see this rule name in the AWS IoT console after this template has been launched.\nThe second property is the topic rule payload. The topic rule payload contains several attributes:\nThe first attribute indicates that the rule is enabled.  Rules can be disabled so they aren\xe2\x80\x99t executed, but remain in AWS IoT console.  That way, you can easily enable them rather than creating them again.\nThe second attribute is the SQL statement we explained earlier.\nThe third attribute contains the actions performed when the rule\xe2\x80\x99s criteria is met.  In this case, we want to republish to an output topic using an IAM role specified in the next section of the AWS CloudFormation template.  We specify the role using the role\xe2\x80\x99s ARN attribute.  !GetAtt is the YAML syntax\xe2\x80\x99s get attribute intrinsic function.  All functions in YAML templates are prefixed with an exclamation point !.\nThere are other intrinsic functions that are useful for managing your stack. They provide variables that are available during runtime only.\nThe topic here is output/${topic(2)}.  This syntax means that it will extract the second segment of the input topic (e.g. thing_0 from input/thing_0) and use it in that location.  If we received an input message from thing_0, our output topic would be output/thing_0.  This syntax allows the rule to dynamically publish to any of a number of output topics without a separate rule for each thing or each input topic.\nSQLRepublishRole Section\n  SQLRepublishRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Action:\n              - sts:AssumeRole\n            Principal:\n              Service:\n                - iot.amazonaws.com\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: iot:Publish\n                Resource: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":topic/output/*"" ] ]\nThis section creates an AWS resource that is an IAM role (AWS::IAM::Role) with several properties:\nThe first property is the assume role policy document.  This property allows AWS IoT to assume this role in your account so it can republish messages from the rules engine.\nThe second property is the list of policies associated with this role.\nThis role has one policy assigned to it called root, but the name is unimportant. It can be changed to something else, if you like.  The policy contains one statement that has three attributes:\nThe first attribute indicates that the effect of this statement is to allow access to a particular action.\nThe second attribute declares the action.  In this case, it is the iot:Publish action that lets an application publish an MQTT message.\nThe third attribute is a resource that we\xe2\x80\x99ll break down in sections.\nHere is the full resource statement:\nResource: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":topic/output/*"" ] ]\nThe !Join function joins together a list of strings. It includes a separator string between each pair of strings.  In our case, we don\xe2\x80\x99t want to add strings, so we specified an empty string ("""") as the separator.  This means the strings will be joined exactly as they are specified.\nThe next few statements build the ARN of the topic that we want to republish to.  AWS IoT topic ARNs look like this:\narn:aws:iot:<region>:<accountId>:topic/<topicName>\nThe beginning of the ARN is always arn:aws:iot: followed by the region, a colon, the current account ID, a colon, the string topic/, and the topic name.  The topic name can include wildcards because it is an IAM resource, but the use of the MQTT wildcards # and + are not allowed.  You can only use * and ?.\nTo make this code reusable across accounts and regions, we use !Ref ""AWS::Region"" and !Ref ""AWS::AccountId"" to fill in the region and account ID automatically.  The !Ref function tells AWS CloudFormation to handle this for us.\nDeploying the SQL-Only Rule\nHere are the steps for deploying the rule:\nSave the entire template to a file named sql-hello.yaml.\nSign in to the AWS Management Console, and then open the AWS CloudFormation console.\nChoose Create Stack.\nUnder Choose a template, click Choose file, select sql-hello.yaml, and then choose Next.\nFor stack name, type SQLRule, and then choose Next.\nOn the Options page, leave the fields at their defaults, and then choose Next.\nOn the Review page, select I acknowledge that AWS CloudFormation might create IAM resources, and then choose Create.\nThe state displayed for your AWS CloudFormation stack should be CREATE_IN_PROGRESS.  You can periodically click the circular arrow in the upper-right corner to refresh the view.  When the stack has been created, the state displayed for your stack will be CREATE_COMPLETE.\nTesting the SQL-Only Rule\nWe can now use the ELF client to test the rule.  If your client hasn\xe2\x80\x99t been cleaned up since the last time you used it, you must first execute this command:\npython elf.py clean\nNow open two terminals.  One terminal will publish messages. The other will subscribe to the messages coming from our rule.\nIn the first terminal, execute these commands:\npython elf.py create 2\npython elf.py send --topic input --append-thing-name --duration 60\nIn the second terminal, execute this command:\npython elf.py subscribe --topic output --append-thing-name --duration 60\nIn the first terminal, you should see messages like this:\nINFO - ELF thing_0 posted a 24 bytes message: {""msg"": ""IoT ELF Hello""} on topic: input/thing_0\nINFO - ELF thing_1 posted a 24 bytes message: {""msg"": ""IoT ELF Hello""} on topic: input/thing_1\nIn the second terminal, you should see messages like this:\nINFO - Received message: {""feedback"":""thing_0 says hello!""} from topic: output/thing_0\nINFO - Received message: {""feedback"":""thing_1 says hello!""} from topic: output/thing_1\nIf you see messages in both terminals, then everything is working.  Now you can go back to the AWS CloudFormation console, choose your SQLRule stack, and then choose Delete Stack. Wait until the stack has been deleted, and then try the commands again in the two terminals. You should see the same messages in the first terminal, but no messages in the second.\nCreating a Rule with AWS CloudFormation to Route Messages to AWS Lambda\nNow we\xe2\x80\x99ll create a rule that routes MQTT messages to AWS Lambda.  AWS Lambda will receive the message and publish a new MQTT message based on what it receives from the rules engine.\nYAML AWS CloudFormation Template for AWS Lambda Rule\nAWSTemplateFormatVersion: 2010-09-09\nDescription: A simple IoT republish rule that responds to a device saying hello with AWS Lambda\n\nResources:\n  LambdaRepublishTopicRule:\n    Type: AWS::IoT::TopicRule\n    Properties:\n      RuleName: LambdaRepublish\n      TopicRulePayload:\n        RuleDisabled: false\n        Sql: SELECT topic(2) AS thing_name, msg FROM \'input/#\'\n        Actions:\n          - Lambda:\n              FunctionArn: !GetAtt LambdaHelloFunction.Arn\n  LambdaRepublishRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Action: sts:AssumeRole\n            Principal:\n              Service:\n                - lambda.amazonaws.com\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: logs:*\n                Resource: arn:aws:logs:*:*:*\n              - Effect: Allow\n                Action: iot:Publish\n                Resource: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":topic/output/*"" ] ]\n  LambdaHelloFunction:\n    Type: AWS::Lambda::Function\n    Properties:\n      FunctionName: LambdaHello\n      Role: !GetAtt LambdaRepublishRole.Arn\n      Timeout: 5\n      Handler: index.lambda_handler\n      Runtime: python2.7\n      MemorySize: 512\n      Code:\n        ZipFile: |\n                  import boto3\n                  import json\n\n                  def lambda_handler(event, context):\n                      client = boto3.client(\'iot-data\')\n                      thing_name = event[\'thing_name\']\n                      payload = {}\n                      payload[\'feedback\'] = thing_name + "" said hello to Lambda!""\n                      payload = bytearray(json.dumps(payload))\n                      response = client.publish(topic=\'output/\' + thing_name, qos=0, payload=payload)\n  LambdaInvocationPermission:\n    Type: AWS::Lambda::Permission\n    Properties:\n      SourceArn: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":rule/"", !Ref ""LambdaRepublishTopicRule"" ] ]\n      Action: lambda:InvokeFunction\n      Principal: iot.amazonaws.com\n      FunctionName: !GetAtt LambdaHelloFunction.Arn\n      SourceAccount: !Ref AWS::AccountId\nYAML AWS CloudFormation Template Explained\nAlthough this template is similar to the SQL-only template, there are some important differences.\nThe first is the SQL statement, which looks like this:\nSELECT topic(2) AS thing_name, msg FROM \'input/#\'\nWe\xe2\x80\x99re using SQL to extract the topic(2) value to a field called thing_name and we\xe2\x80\x99re passing through the msg field.  This creates a JSON message with two fields that will be sent to our Lambda function.  When we were using the republishing feature of the rules engine, we could access this value directly and use it to specify our output topic.  When Lambda receives the JSON message from AWS IoT, the information it needs for its processing must be included in the message.\nLambdaRepublishRole Section\n  LambdaRepublishRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Action: sts:AssumeRole\n            Principal:\n              Service:\n                - lambda.amazonaws.com\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: logs:*\n                Resource: arn:aws:logs:*:*:*\n              - Effect: Allow\n                Action: iot:Publish\n                Resource: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":topic/output/*"" ] ]\nThis section creates a role that Lambda can assume. It allows Lambda to perform the following actions in our account:\nWrite to Amazon CloudWatch Logs with logs:* and arn:aws:logs:*:*:*\nPublish to the output topic hierarchy as we did in the other template\nAWS IoT no longer needs publish permission because Lambda will handle publishing the messages for us.\nLambdaHelloFunction Section\n  LambdaHelloFunction:\n    Type: AWS::Lambda::Function\n    Properties:\n      FunctionName: LambdaHello\n      Role: !GetAtt LambdaRepublishRole.Arn\n      Timeout: 5\n      Handler: index.lambda_handler\n      Runtime: python2.7\n      MemorySize: 512\n      Code:\n        ZipFile: |\n                  import boto3\n                  import json\n\n                  def lambda_handler(event, context):\n                      client = boto3.client(\'iot-data\')\n                      thing_name = event[\'thing_name\']\n                      payload = {}\n                      payload[\'feedback\'] = thing_name + "" said hello to Lambda!""\n                      payload = bytearray(json.dumps(payload))\n                      response = client.publish(topic=\'output/\' + thing_name, qos=0, payload=payload)\nThis section defines our Lambda function:  It\xe2\x80\x99s written in Python, gets 512 MB of RAM, has a five-second timeout, uses the role we just defined to publish messages in AWS IoT, and its code is specified inline.\nThe code creates an IoT data client with Boto 3, extracts the thing name, builds a payload in which the feedback field is populated with our message, converts the payload dictionary to JSON, converts the JSON to a byte array, and then publishes it to the correct output topic by appending the thing name to output/. The IoTDataPlane publish function in Boto 3 requires that the data passed to it is either a byte array or a reference to a file.\nLambdaInvocationPermission Section\n  LambdaInvocationPermission:\n    Type: AWS::Lambda::Permission\n    Properties:\n      SourceArn: !Join [ """", [ ""arn:aws:iot:"", !Ref ""AWS::Region"", "":"", !Ref ""AWS::AccountId"", "":rule/"", !Ref ""LambdaRepublishTopicRule"" ] ]\n      Action: lambda:InvokeFunction\n      Principal: iot.amazonaws.com\n      FunctionName: !GetAtt LambdaHelloFunction.Arn\n      SourceAccount: !Ref AWS::AccountId\nThis final section is different from the SQL republish template.  This permission allows the Lambda function to be invoked by the AWS IoT rule.  Without this permission, even if the rule is executed, Lambda will not allow AWS IoT to run the code.\nDeploying and Testing the AWS Lambda Rule\nSave this template as lambda-hello.yaml, launch it the same way we launched the last template but use the name LambdaRule, and then run the ELF commands in the two terminals again.  You\xe2\x80\x99ll see output like this in the second terminal:\nINFO - Received message: {""feedback"": ""thing_0 said hello to Lambda!""} from topic: output/thing_0\nINFO - Received message: {""feedback"": ""thing_1 said hello to Lambda!""} from topic: output/thing_1\nWhat\xe2\x80\x99s Next?\nYou now have two templates that you can use as a starting point to develop rules that republish messages. You created a rule using the SQL rules engine in AWS IoT that invokes Lambda functions written inline in Python.  As you build new templates with new rules, you can use AWS CloudFormation to make sure they\xe2\x80\x99re set up consistently, repeatably, and easily.  What will you connect AWS IoT to next?'"
248,Samsung Selects AWS IoT for Cloud Print with Help from ClearScale,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/samsung-selects-aws-iot-for-cloud-print-with-help-from-clearscale/,"b'Background\nClearScale was founded in 2011, with a focus on delivering best-of-breed cloud systems integration, application development, and managed services. We are an AWS Premier Consulting Partner with competencies in Migration, DevOps, Marketing & Commerce, Big Data, and Mobile. Our experienced engineers, architects, and developers are all certified or accredited by AWS.\nWe have a long track record of successful IoT projects and the proven ability to design and automate IoT platforms, build IoT applications and create infrastructure on which connected devices can easily and securely interact with each other, gather and analyze data and provide valuable insights to your business and customers.\nOur firm is unique in that we offer a breadth of technical experience coupled with a holistic organizational view. This allows us to truly partner with our customers and translate complex business requirements into solid, scalable, cloud-optimized solutions. At ClearScale, we understand best practices for driving the maximum business value from cloud deployments.\nSamsung partnered with our firm to launch a Cloud Solutions Platform for delivering robust infrastructure and printing solutions at cloud-scale for any device from any location. In order to architect the device management component of the platform, we conducted a competitive analysis between the AWS IoT and the incumbent solution based on Ejabberd messaging platform.\nWith the goal of this effort focused around delivering to Samsung a methodology that would allow them to get the most reliable printing services for their customer base, the analysis needed to leverage a key item; the device management component. This component handles the authentication and messaging between devices, in this case printers, and the Cloud infrastructure. In addition, it allows for collecting instrumentation data from the devices for later analysis which in turn would allow Samsung to understand the health and utilization of each device to identify issues that required remote troubleshooting and subsequent proactive maintenance.\nHigh Level Application Overview: \nDefining the Test Rules\nWorking with Samsung, we defined a set of criteria for evaluating AWS IoT versus Ejabberd for their device management capability. The attributes were prioritized and weighted based on Samsung\xe2\x80\x99s business requirements. While these key areas are applicable to any IoT evaluation the subsequent scoring methodology may differ somewhat depending on the client\xe2\x80\x99s specific use case(s) and requirements.\nThe analysis needed to address two major areas: functional testing and load testing. For the functional testing, we wanted to compare the Eiabberds\xe2\x80\x99 solution to AWS IoT evaluating each solution\xe2\x80\x99s core capabilities, security posturing and the ubiquity of its technology. For the load testing, we needed to understand the availability, scalability, maintainability, performance and reliability of each solution so that the metrics gathered around each area of concern could be applied to a scoring matrix as shown below.\n* A score was awarded for each quality attribute, with a total score being the sum of all scores for the quality attributes. The maximum total score for a solution was deemed to be 100.\nFunctional Testing\nFunctional testing was performed first, with the goal of ensuring each system could fulfill the defined functional requirements, and only after which were the more expensive \xe2\x80\x9cload testing\xe2\x80\x9d performed. We deployed a small environment for Ejabberd and configured the AWS IoT service, so that they were functionally identical. Five functional tests were performed to validate the solutions and both solutions satisfied Samsung\xe2\x80\x99s requirements without any issues.\nLoad Testing\nDefining the Scenarios\nBefore comparing Ejabberd and AWS IoT, we needed to design the load testing criteria by opting to run two distinct scenarios.\nSimulate peak load conditions\nDemonstrate system stability\nThe message rates were calculated from the following profile:\nConsumer (2-3 jobs per week)\nSMB (10-20 jobs per week)\nEnterprise (150-300 jobs per week)\nProposed distribution: 50%, 30%, 20%\nTotal number of agents: 500,000\nAVERAGE NUMBER OF MESSAGES PER SECOND\nAvgMsgs = MsgsPerJob * NumOfAgents * JobsPerWeek / SecondsPerWeek\n= 2 * 500,000 * 300 / (7 * 24 * 60 * 60)\n= 496.032\nWhere:\nMsgsPerJob = Number of messages resulting from each job (2; see note)\nAvgJobs = Average number of jobs per second\nNumOfAgents = Total number of agents (500,000)\nJobsPerWeek = Number of jobs a week per one agent\nSecondsPerWeek = Number of seconds in a week (7 * 24 * 60 * 60)\nNote: Results are doubled due to SCP behavior. For each job, XoaCommMtgSrv sends a PING message to an Agent. After the Agent executes the job, XoaCommMtgSrv sends another PING message to XCSP Service.\nMAXIMUM NUMBER OF MESSAGES PER SECOND\nNumber of jobs executed during busy hours: 90%\nNumber of busy hours per week: 10 (2 hours per day; 5 days per week)\nMaxMsgs = MsgsPerJob * BusyHourJobs * NumOfAgents * JobsPerWeek / BusyHours\n= 2 * 0.9 * 500,000 * 240 / 36,000\n= 6,000\nWhere:\nMsgsPerJob = Number of messages resulting from each job (2; see note)\nBusyHourJobs = Percentage of jobs expected to be executed during busy hours (90% = 0.9)\nNumOfAgents = Total Number of agents (500,000)\nJobsPerWeek = Number of jobs a week per one agent\nBusyHours = Number of seconds in busy hours a week (2 * 5 * 3600)\nLoad Generation\nWe selected Apache JMeter as our load generation engine. It is an extensible solution with which customized tests are easy to develop. The product is widely used and has strong community support.\n\xe2\x80\x9cThe Apache JMeter\xe2\x84\xa2 application is open source software, a 100% pure Java application designed to load test functional behavior and measure performance. Apache JMeter may be used to test performance on static/dynamic resources and dynamic web applications. It can be used to simulate a heavy load on a server, group of servers, network or object to test its strength or to analyze overall performance under different load types.\xe2\x80\x9d\nEjabberd and AWS IoT utilize different protocols, so we developed custom plugins for Apache JMeter (XMPP and MQTT, respectively). The plugins allowed us to create custom logging for deeper analysis and address connection persistence and manage secure connections. Our goal was to have the load generation closely emulate the actual system functionality including connection security and persistence. This included requests/messages from devices (Agents) as well as requests/responses from the Samsung\xe2\x80\x99s device management application (XoaCommMtgSrv).\nBy using an existing tool and extending its functionality, we reduced the overall time needed to develop the load generation code. The following custom JMeter plugins were created to provide capabilities required by the test methodology:\nMQTT protocol plugin for JMeter \xe2\x80\x93 used for AWS IoT testing\nXMPP protocol plugin for JMeter \xe2\x80\x93 used for Ejabberd testing\nThere are several reasons to use custom plugins:\nThe test model can more closely emulate the actual system\nEmulate a few number of XoaCommMtgSrv servers and a huge number of Agents\nSupport persistent connections \xe2\x80\x93 not supported by existing plugins\nSupport secure connections \xe2\x80\x93 not supported by existing plugins\nCustom logging\nDistinguish XoaCommMtgSrv server actions from Agent actions\nAssociate specific JMeter engine node to the XoaCommMtgSrv/Agent a log messages\nCapture job execution sequences and identify out-of-order job processing\nEnable low level debugging\nThe JMeter test plans for each solution have the same high-level behavior:\nWhile testing the JMeter MQTT plugin, we determined that a single JMeter engine node was capable of emulating 8,000 agents without a performance bottleneck. In order to emulate 500,000 agents, as called for by the test methodology, we used 64 JMeter engine nodes for AWS IoT load generation.\nWhile testing the JMeter XMPP plugin, it was discovered that a single JMeter engine node was capable of simulating 6,500 agents without a performance bottleneck. In order to emulate 500,000 agents as called for by the Test Methodology, we used 80 JMeter engine nodes for Ejaberd load generation. This was an important step to ensure that the metrics were not skewed by limitations on the load generation side of the equation.\nWe deployed the JMeter management node and engine nodes on C4.xlarge EC2 instances. The JMeter cluster was deployed within a single Availability Zone (AZ) for simplicity.\nTest Execution\nPreparing to load test AWS IoT (MQTT message broker) was a straight forward process. We configured the service and AWS handled all of the resources and scaling behind the scenes. To properly simulate unique devices, we generated 512,000 client certificates and policy rules. These certificates and policies were required for clients to authenticate to the MQTT message broker provided by AWS IoT.\nPreparing the Ejabberd environment took a bit more effort; we needed to conduct single node load tests to identify suitable instance sizes and maximum capacity of each node. They elected to run the full load tests against two instance types and deployed two Ejabberd clusters (attached to MySQL on EC2) using c4.2xlarge instances with 9 nodes and c4.4xlarge instances with 4 nodes. In order to replicate real-world scenarios, we provisioned an extra node per cluster for HA purposes.\nFor Stability and Busy Hours testing, the following configurations were used:\nc4.2xlarge with 9 nodes\nc4.4xlarge with 4 nodes\nTable: Ejabberd Single Node Limits\n\nThe common bottleneck for both instance types is \xe2\x80\x9cAuth Rate\xe2\x80\x9d. To be able to support 1,500 auth/sec it\xe2\x80\x99s needed to have 3 c4.2xlarge instances. Because of High Availability requirement, we added 1 extra instance for a total of 4 nodes in the cluster. We used the same formula to calculate the 9 node cluster of c4.2xlarge instances.\nWe ran two iterations of the Peak test scenario and two iterations of the Stability test scenario in order to compare results. They cleared the JMeter engines of previous test data and temporary files and restarted the instances to ensure the load generation platform was clean and would provide accurate and reliable results from one test run to the next without having the results skewed by previous test result data.\nTest Results\nAWS IOT\nGeneral Information\nBoth test cases for AWS IoT were passed. The number of errors was less than 0.01%.\nTable: AWS IoT Load Test Results\n\xe2\x80\x9cError Distribution\xe2\x80\x9d diagrams show cumulative number of errors that happen during time. The relationship is almost linear.\nStability Load Testing\nTable: Stability Testing \xe2\x80\x93 Summary\nDiagram: Stability Testing \xe2\x80\x93 Message Latency Histogram\nNotes:\nHistograms for all tests represent a distribution of message latency (the amount of time needed to send a message from a publisher to a subscriber). The values will differ from real values because testing environment is located in the same Region as tested services. But in a real life scenarios, agents will be global so Internet related delays will apply.\nThe purpose of the histograms presented in this document is to show if there are any delays related to buffering or overload (service degradation)\nDiagram: Stability Testing \xe2\x80\x93 Error Distribution (Cumulative)\nBusy Hour Load Testing\nTable: Busy Hour Load Testing \xe2\x80\x93 Summary\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Message Latency Histogram\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Error Distribution (Cumulative)\nNotes:\nDuring the first test 1712 threads lost their connection (16-37 threads on each engine node) between 22:39:17 \xe2\x80\x93 22:41:52 UTC. Threads were reconnected to different AWS IoT endpoint IP\xe2\x80\x99s.\nAll threads reconnected successfully, but only after the message receive timeout. In this case AWS IoT was dropping messages because there were no agents subscribed to topics, and this can\xe2\x80\x99t be considered as an AWS IoT error.\nIt was decided to normalize the first diagram by removing the data for that time period.\xc2\xad\xc2\xad\nEJABBERD\nGeneral Information\nStability and busy hour load test cases were for AWS Ejabberd both passed. The number of errors is less than 0.01%.\nStability Load Testing\nTest case was executed twice for each instance size, and was passed without errors.\nTable: Stability Testing \xe2\x80\x93 Summary\nNotes:\nAll tests were finished successfully\nTest #1 for c4.4xlarge was stopped because of the overtime. One message was not received due test stop\nDiagram: Stability Testing \xe2\x80\x93 Message Latency Histogram (c4.2xlarge)\nDiagram: Stability Testing \xe2\x80\x93 Message Latency Histogram (c4.4xlarge)\nDiagram: Stability Testing \xe2\x80\x93 Error Distribution (c4.2xlarge)\nDiagram: Stability Testing \xe2\x80\x93 Error Distribution (c4.4xlarge)\nBusy Hour Load Testing\nTable: Stability Testing \xe2\x80\x93 Summary\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Message Latency (c4.2xlarge)\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Message Latency (c4.4xlarge)\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Error Distribution (c4.2xlarge)\nDiagram: Busy Hour Load Testing \xe2\x80\x93 Error Distribution (c4.4xlarge)\nComparing Results\nAt the conclusion of the load testing we found the following:\nThe analysis showed that both solutions could provide very comparable services for the load profile and use cases.\nCost Analysis\nWe conducted a cost comparison based on capital expenses (CAPEX) and operational expenses (OPEX). For this particular analysis, they defined CAPEX as the cost of development and deployment of the given solution. OPEX was defined as monthly/yearly infrastructure and maintenance costs. For ease of calculations, they did not include human resource and common organizational expenses for this exercise.\nCAPEX costs are based on actual work, performed by ClearScale, for other clients to develop and deploy similar solutions.\nUpon further review it was apparent that the AWS IoT solution was extremely cost effective from a capital expenditure perspective. The huge difference in CAPEX costs also indicated that AWS IoT would take less time to deploy.\n'"
249,How to route messages from devices to Salesforce IoT Cloud,b'Gus Liu',2018-02-23T02:25:16+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-to-route-messages-from-devices-to-salesforce-iot-cloud/,"b'AWS IoT customers can now route messages from devices directly to Salesforce IoT Cloud with a new AWS IoT Rules Engine Action that requires only configuration.\nAs part of the strategic relationship between AWS and Salesforce, the combination of AWS IoT and Salesforce IoT Cloud allows you to enrich the messages coming from your devices with customer data residing in Salesforce. This results in deeper insights and allow customers to act on those newly created insights within the Salesforce ecosystem.\nIn this article, we are going to walk you through a step by step example so you can learn how to configure and test this new action type.\nBring case management to your connected devices\nWe are going to take an industrial solar farm as an example, which is inspired from a demonstration that took place at Re:Invent 2016.\nThis demonstration showcases AWS IoT-connected products reporting a critical failure. As a result, a new record in the case management system gets created in Salesforce Service Cloud which instructs a technician to go on-site, assess the situation and make repairs.\nTo learn more about it, visit the AWS YouTube channel.\nCreate an AWS IoT Rule with a Salesforce action type\nStart by logging into the AWS IoT console.\nClick on the Rules section and select Create a rule.\n  Name your rule solarPanelTelemetry and then enter a meaningful description.\nWe will create a simple rule to forward all the data coming from a solar panel to Salesforce IoT Cloud. Enter * as the Attribute of the rule to allow all data coming from the device to be passed on. Enter solarPanels/D123456 as the topic filter and leave the condition field blank.\nOnce you\xe2\x80\x99re done click on Add action.\n  Select the Salesforce action type and click on Configure action.\nGo to the Salesforce IoT Cloud console and copy/paste the value displayed on the Input Stream for the URL and the Token. To learn more about Input Streams please refer to the Salesforce documentation.\n  Click on Add action and review the AWS IoT Rule. You should see the Salesforce action you just added. Click on Create rule.\n  Test your configuration\nWe are going to test the AWS IoT Rule we just created by simulating a message coming from a solar panel. Go to the Test section of the AWS IoT Console.\nEnter solarPanels/D123456 as the Subscription topic and push the Subscribe to topic button. This will enable you to verify that the sample message you are sending is published to the topic matching the rules\xe2\x80\x99 configuration.\nNext enter solarPanels/D123456 for the topic name in the Publish section and copy/paste the following JSON:\n{\n  ""deviceId"": ""D123456"",\n  ""volts"": 70,\n  ""amps"": 1.5,\n  ""watts"": 90,\n  ""latitude"": ""45.0000"",\n  ""longitude"": ""-122.0000"",\n  ""timestamp"": ""1493750762445""\n}\nFinally, push the Publish to topic button to send the message.\nIf you want to monitor the rule\xe2\x80\x99s execution, you can set up Cloudwatch Logs for AWS IoT.\n  Log into the Salesforce IoT Cloud console to see the message that was sent from AWS IoT.\n  Next steps\nRefer to the AWS IoT developer documentation for more information on how to use this new action.\nOr, sign into the AWS IoT console to try it.\nTo learn more about AWS IoT, visit the AWS website. To learn more about Salesforce IoT Cloud, visit the Salesforce website.'"
250,Understanding the AWS IoT Security Model,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/understanding-the-aws-iot-security-model/,"b'According to Gartner, the Internet of Things (IoT) has enormous potential for data generation across the roughly 21 billion endpoints expected to be in use in 2020(1). Internet of Things (IoT) devices in use. Its easy to get excited about this rapid growth and envisage a future where the digital world extends further into our world. Before you take the decision to deploy devices into the wild, it\xe2\x80\x99s vital to understand how you will maintain your security perimeter.\nIn this post, I will walk you through the security model used by AWS IoT. I will show you how devices can authenticate to the AWS IoT platform and how they are authorized to carry out actions.\nTo do this, imagine that you are the forward-thinking owner of a Pizza Restaurant. A few years ago, most of your customers would have picked up the phone and actually spoken to you when ordering a pizza. Then it all moved on-line. You now want to give your customers a new experience, similar to the Amazon Dash Button. One press of an order button and you will deliver a pizza to your customer.\nThe starting point for your solution will be the AWS IoT Button. This is a programmable button based on Amazon Dash Button hardware. If you choose to use an AWS IoT Button, the easiest way to get up and running is to follow one of the Quickstart guides. Alternatively, you can use the Getting Started with AWS IoT section of the AWS Documentation.\nWho\xe2\x80\x99s Calling?\nWhen someone presses an AWS IoT Button to order a pizza, it\xe2\x80\x99s important to know who they are. This is obviously important as you will need to know where to deliver their pizza, but you also only want genuine customers to order. In much the same way as existing, on-line customers identify themselves with a username, each AWS IoT Button needs an identity. In AWS IoT, for devices using MQTT to communicate, this is done with an X.509 certificate.\nBefore I explain how a device uses an X.509 certificate for identity, it is important to understand public key cryptography, sometimes called asymmetric cryptography (feel free to skip to the next section if you are already familiar with this). Public key cryptography uses a pair of keys to enable messages to be securely transferred. A message can be encrypted using a public key and the only way to decrypt it is to use the corresponding private key:\nA key pair is a great way for others to send you secret data: if you keep your private key secure, anyone with access to the public key can send you an encrypted message that only you can decrypt and read.\nIn addition, public and private keys also allow you to sign documents. Here, a private key is used to add a digital signature to a message. Anyone with the public key can check the signature and know the original message hasn\xe2\x80\x99t been altered:\nIn addition to demonstrating a message hasn\xe2\x80\x99t been tampered, a digital signature can be used to prove ownership of a private key. Anyone with the public key can verify a signature and be confident that when the message was signed the signer was in possession of the private key.\nCreate an Identity\nAn X.509 certificate is a document that is used to prove ownership of a public key. To make a new X.509 certificate you need to create a Certificate Signing Request (CSR) and give it to a Certificate Authority (CA). The CSR is a digital document that contains your public key and other identifying information. When you send a CSR to a CA it first validates that the identifying information you\xe2\x80\x99ve supplied is correct, for example you may be asked to prove ownership of a domain by responding to an email. Once your identity has been verified, the CA creates a certificate and signs it with a private key. Anyone can now validate your certificate by checking its digital signature with the CA\xe2\x80\x99s public key.\nAt this point you may be wondering why you should trust the CA and how you know the public key it gave you is genuine. The CA makes it easy to prove the ownership of its public key by publishing it in an X.509 certificate. The CA\xe2\x80\x99s certificate is itself signed by another CA. This sets up a chain of trust where one CA vouches for another. This chain goes back until a self-signed root certificate is reached.\nThere are a small number of well-known root certificates. For example you can find lists of certificates that are installed in MacOS Sierra or available to Windows computers as part of the Microsoft Trusted Root Certification Program (free TechNet account needed to view). The chain of trust allows anyone to check the authenticity of any certificate by examining it all the way to a well-known, trusted root certificate:\nSince each of your pizza order buttons will need a separate identity, you will need an X.509 certificate for each device. The diagram below shows how a new X.509 certificate is made for a device by AWS IoT. When creating a new certificate, you have three choices. The easiest (option 1 below) is to use the one-click generation. Here, AWS will create a public and private key and follow the process through to create a new certificate signed by the AWS IoT CA. The second option is to provide your own CSR. This has the advantage that you never give AWS sight of your private key. As with option 1, the new certificate generated from the CSR is signed by the AWS IoT CA. The final option is to bring your own certificate signed by your own trusted CA. This choice is best if you already generate your own certificates as part of your device manufacture or you already have a large number of devices in the field. You can find out more about using your own certificates in this blog post.\nAt the end of this you should be in possession of both the new device certificate and its private key. Whether you need to download these from AWS depends whether you choose option 1 (you need to download the certificate and the private key), option 2 (you just need to download the certificate) or option 3 (you already have both the certificate and the key, so don\xe2\x80\x99t need to download anything).\nAt this point, you also need to get a copy of the root certificate used by the AWS IoT server. As you will see below, this is important when establishing an authenticated link with the AWS IoT service.\nAll three files (the private key, the device certificate and the AWS IoT server certificate) need to be put onto your pizza ordering button. Note that if you are using an AWS IoT Button, you don\xe2\x80\x99t need to put the root certificate onto the device explicitly because it was put onto the device for you when it was manufactured.\nAuthenticating to AWS IoT\nNow that the certificates and private key are on our AWS IoT Button, you are ready to establish a connection to AWS IoT and authenticate. The protocol used is Transport Layer Security (TLS) 1.2, which is the successor to Secure Sockets Layer (SSL). This is the same protocol that you use to securely shop or bank on the internet but, in addition to server authentication, the client also uses a X.509 certificate prove its identity.\nThe connection starts with the AWS IoT Button contacting the Authentication and Authorization component of AWS IoT with a hello message:\nThe hello message is the start of a TLS handshake, which will establish a secure communication channel between the AWS IoT Button and AWS IoT. During the handshake, the client and server will agree on a shared secret, rather like a password, which will be used to encrypt all messages. A shared secret is preferred over using asymmetric keys as it less expensive in terms of computing power needed to encrypt messages, so you can get better communication throughput. The hello message contains details of the various cryptographic methods that the AWS IoT Button is able to use.\nWhen the server receives a hello message it picks the cryptographic method it wants to use to establish the shared secret and returns this, together with its server certificate, to the AWS IoT Button:\nNow that the AWS IoT Button has a copy of the server certificate it can check that it is really talking to AWS IoT. It does that by using the AWS IoT Service root certificate, that you downloaded and put on the device. The public key that\xe2\x80\x99s embedded in the root certificate is used to validate the digital signature on the server certificate:\nIf the digital signature checks out with the root certificate\xe2\x80\x99s public key then the AWS IoT Button trusts that it has made contact with the AWS IoT service. It now needs to do two things; first it needs to authenticate itself with AWS IoT and second it needs to establish a shared secret for future communication.\nTo authenticate itself with AWS IoT, the AWS IoT Button first sends a copy of its device certificate to the server:\nTo complete the authentication process, the AWS IoT Button calculates a hash over all the communication records that are part of the current session with the AWS IoT Server. It then calculates a digital signature for this hash using its private key:\nThe digital signature is then sent to AWS IoT.\nAWS IoT is now in possession of the devices\xe2\x80\x99 public key (which was in the device certificate) and the digital signature. Whilst the TLS handshake has been proceeding, the AWS IoT Service has also been keeping a record of all communication and calculates the same hash as the AWS IoT Button. It uses the device\xe2\x80\x99s public key to check the accuracy of the digital signature:\nIf the signature checks out, AWS IoT can be confident that it is talking to a pizza ordering device belonging to one of your customers. By using the unique identifier of the certificate, it knows exactly which device is establishing a MQTT session.\nThe exact method by which a shared secret is established depends on the key exchange algorithm that the server and client agreed on at the beginning of the handshake. However, the process is started by the AWS IoT Button encrypting a message using the server\xe2\x80\x99s public key (which it got from the server\xe2\x80\x99s certificate). The message might be a pre-master-secret, a public key or nothing. This is sent to the server and can be decrypted using the server\xe2\x80\x99s private key. Both the server and the AWS IoT Button then use the contents of the message to establish a shared secret without needing further communication. From then on, all messages between the device and AWS IoT are secured using the shared secret.\nPermission to Order\nThe pizza order button has used its X.509 certificate to prove its identity and secure the messages it exchanges with AWS IoT. It is now ready to order pizza. Each AWS IoT Button publishes MQTT messages to its own topic, for example:\niotbutton/G03XXXXXXXXXXXXX\nThe second part is the serial number of the AWS IoT Button. It\xe2\x80\x99s important that your system implements least privilege security and only permits an AWS IoT Button to publish to its own topic. For example, a nefarious customer could re-program their button to publish to a neighbor\xe2\x80\x99s topic. When the pizza turns up, it\xe2\x80\x99s simple social engineering to intercept the delivery and claim a free meal.\nAs you\xe2\x80\x99ve seen, a device certificate is similar to a user\xe2\x80\x99s username; it\xe2\x80\x99s their identity. To give this identity permissions, you need to attach a policy to the certificate, in much the same way as you would attach permissions or policies to an IAM user.\nThe default policy for an AWS IoT Button is shown below. The default policy grants the owner of the certificate rights to publish to the topic specified in the \xe2\x80\x98Resource\xe2\x80\x99 attribute.\nIn this policy, the serial number is hard-coded. This solution will not scale well as you will need a separate policy for each AWS IoT Button.\nFortunately, the policy language can help us with variable substitutions. For example, the following policy can be applied to all our devices. Instead of hard coding the serial number, the AWS IoT Service obtains it from the certificate that was used to authenticate the device. This assumes that when you created the certificate, the serial number was part of the identifying information.\nYou can check out the documentation for further information on AWS IoT Policies and the substitution variables that you can use.\nSummary\nIn this post, I have introduced you to the AWS IoT Security model and showed you how devices are authenticated against the service and how devices can be authorised to carry out actions.\nYou can purchase your own AWS IoT Button here or, if you plan a more sophisticated solution, you may want to check out this page that has lots of idea for getting started on AWS IoT, including some starter kits.\nIf you have any questions or suggestions, please leave a comment below.\n  (1) Gartner, Press Release, Gartner Reveals Top Predictions for IT Organizations and Users in 2017 and Beyond, October 2016,  http://www.gartner.com/newsroom/id/3482117'"
251,How AI Will Accelerate IoT Solutions for Enterprise,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/how-ai-will-accelerate-iot-solutions-for-enterprise/,"b'Artificial intelligence (AI) is going mainstream, which has long-lasting implications for how enterprises build and improve their products and services.\nAs announced at re:Invent 2016, AWS is simplifying artificial intelligence (AI) adoption through three low-cost, cloud-based services built for AI-specific uses cases. Instead of creating proprietary algorithms, data models or machine learning techniques, all levels of developers from Global 2000 enterprises through start-ups can leverage the Amazon Lex, Amazon Rekognition and Amazon Polly APIs to innovate quickly and build new Internet of Things (IoT) product and service offerings. Accenture, is delivering these innovative offerings by supporting clients with vertical industry applications powered by Amazon AI.\nCombining AI with IoT is essential because it enables businesses to collect data in the physical world\xe2\x80\x93from wearables, appliances, automobiles, mobile phones, sensors and other devices\xe2\x80\x94and add intelligence to deliver a better response or outcome. In other words, AI is the automation brainpower to make IoT device-driven data more useful.\nFor example, a telecommunications company could create an AI-powered mobile chat bot to automate customer service processes. One use case would be to monitor incoming IoT data from cable boxes installed in homes. If a device started to malfunction, the mobile chat bot could notify the customer via text or voice interaction of a possible service issue, and offer the convenience of scheduling a service technician. This device-driven data could leverage AWS Lambda for serverless functions, as well as AWS Greengrass for embedded software on the edge. Thereby, leveraging the use of AWS cloud as needed when processing, storing and computing.\nAPI functionality overview and real-world uses\nUsed separately or in combination, developers can embed the APIs into existing smart product and service roadmaps, or inject them into cloud-native programming processes.\nAmazon Lex\xe2\x80\x94AI-driven processing engine that computes voice input or sensor data to better understand and personalize an experience or outcome (part of Alexa voice platform)\nAmazon Rekognition\xe2\x80\x94Image and facial analysis to detect and understand environment and what is happening in real-life scenario or picture\nAmazon Polly\xe2\x80\x94Text-to-speech service that synthesizes structured text data into natural voice-like capability (in male or female voice and in 24 languages) to enrich response.\nToday, businesses typically run analytics in the cloud on transactional datasets, such as customer purchases or location-based information. But, IoT data combined with AI provides a deeper level of insights. By collecting real-time data from IoT devices (or what is known as device-driven data), a business can use an AI engine to automate the information processing and connect different sources of unstructured/structured data to contextualize what a person is asking for. From this understanding, the machine can provide a personalized response or experience directly to the end user, or route the response back into the enterprise to automate another process.\nThis capability opens an entirely new set of IoT-based product or service offerings. Accenture recently released their Technology Vision 2017, which explains the benefits of AI for the Enterprise. For instance, a healthcare business could implement Amazon Lex and Amazon Rekognition to improve the process of monitoring house-bound or elderly patients who need assisted living. In one use case, the service could install a video camera to take pictures of an individual, analyze the images in the cloud to keep track of movements, and send an automatic alert to a healthcare giver or family member if the patient has not moved in a specified amount of time or has fallen.\nExpanding AI and IoT opportunities\nIn the future, AI combined with IoT will introduce even more scenarios in which robots (aka automated machines) collaborate with people to supply intelligent information and augment human interaction. This will help people to complete tasks more efficiently, interact in a more personalized way or supply on-demand services.\nIn a retail setting, for example, a business could create a collaborative artificial intelligence (\xe2\x80\x9ccobot\xe2\x80\x9d) application using Amazon Lex and Amazon Rekognition that analyzes facial features of in-store shoppers in real-time and combines this information with purchase transaction history. The cobot could then prompt sales associates to offer customized help to each customer as they choose items. Or in a hospital situation, Amazon Lex and Amazon Rekognition could be built into an application that uses AI and cloud-based big data, all connected with IoT, to help physicians better diagnose their patients. Examples include detecting skin anomalies with image analysis or stress-related symptoms.\nAWS\xe2\x80\x99s new AI-driven APIs, developing IoT products and services with AI capabilities is becoming cost effective and accessible for all businesses and leveraging Accenture to deliver new, applied, solutions give Enterprises a quick way to adopt at scale.\n '"
252,Connect your devices to AWS IoT using the Sigfox network,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/connect-your-devices-to-aws-iot-using-the-sigfox-network/,"b'Connectivity is a key element to evaluate when designing IoT systems as it will weigh heavily on the performance, capabilities, autonomy of battery powered objects, and cost of the overall solution. There is no one network that fits all scenarios which is why AWS partners with many different network providers. By partnering, you can then choose the most relevant network to satisfy your business requirements. In this blog post, we\xe2\x80\x99ll explore providing LPWAN connectivity to your objects using the Sigfox network. Pierre Coquentin (Sigfox \xe2\x80\x93 Software Architect) will explain what Sigfox is and how to connect objects while Jean-Paul Huon (Z#bre \xe2\x80\x93 CTO) will share his experience using Sigfox with AWS in production.\nWhy Sigfox?\nSigfox provides global, simple, cost-effective, and energy-efficient solutions to power the Internet of Things (IoT). Today, Sigfox\xe2\x80\x99s worldwide network and broad ecosystem of partners are already enabling companies to accelerate digital transformation and to develop new services and value.\nIn order to connect devices to its global network, Sigfox uses an ultra-narrow-band (UNB) radio technology. The technology is key to providing a scalable, high-capacity network with very low energy consumption, while maintaining a light and easy-to-rollout infrastructure. The company operates in the ISM bands (license-free frequency bands), on the 902MHz band in the U.S., as well as the 868MHz band in Europe.\nOnce devices are connected to the Sigfox network, data can be transmitted to AWS IoT, enabling customers to create IoT applications that deliver insight into and the ability to act upon their data in real-time.\nPlease find more information at https://www.sigfox.com/\nSend data from Sigfox to AWS IoT\nWe\xe2\x80\x99ll start from the assumption that you already have objects connected and sending data to the Sigfox network. All that is left to do, is to configure the native AWS IoT connector to push your data to the AWS Cloud. To make things a bit more interesting, we will store all the data sent by your devices in an Amazon DynamoDB table.\nIn order to implement this architecture, we are going to perform the following steps:\nConfigure the AWS IoT Connector in the Sigfox Console\nProvision the necessary resources on AWS so Sigfox can send data into your AWS account securely through the AWS IoT connector using a CloudFormation script that will generate IAM roles and permissions.\nManually create a rule in AWS IoT and a DynamoDB table so we can store the data coming from Sigfox into the DynamoDB table\nIn our example, we are using the US East 1 region. We recommend you go through this tutorial once by using the exact same configuration. Once you gain knowledge on how to configure the different pieces, then customize the implementation to fit your needs.\nFirst, log into the Sigfox console, go to the \xe2\x80\x9cCallbacks\xe2\x80\x9d section and click on the \xe2\x80\x9cNew\xe2\x80\x9d button to create a new \xe2\x80\x9cCallback\xe2\x80\x9d.\nNow select the \xe2\x80\x9cAWS IoT\xe2\x80\x9d option as the type of \xe2\x80\x9cCallback\xe2\x80\x9d.\nPlease copy the \xe2\x80\x9cExternal Id\xe2\x80\x9d given to you in your clipboard, it will be useful later. The \xe2\x80\x9cExternal Id\xe2\x80\x9d is unique to your account and enables greater security when authorizing third party to access your AWS resources, you can find more information here.\nNext click on \xe2\x80\x9cLaunch Stack\xe2\x80\x9d and leave the \xe2\x80\x9cCROSS_ACCOUNT\xe2\x80\x9d option selected.\nThis will redirect you to the AWS CloudFormation console, click \xe2\x80\x9cNext\xe2\x80\x9d on the first screen.\nOn the following screen, enter the following inputs:\nStack name: Choose a meaningful name for the connector.\nAWSAccountId: Input your AWS Account Id, you can find it here.\nExternal Id: Copy/paste the external Id given to you in the Sigfox console.\nRegion: Choose the region where AWS IoT will be used.\nTopic Name: Choose the topic name you wish to send data to.\nClick \xe2\x80\x9cNext\xe2\x80\x9d once you are ready.\nThe next screen is optional, if you wish you can customize options (Tags, Permissions, Notifications) otherwise click on \xe2\x80\x9cNext\xe2\x80\x9d to continue with the default options. You should now be on the review screen, check the \xe2\x80\x9cI acknowledge that AWS CloudFormation might create IAM resources\xe2\x80\x9d  box and click on \xe2\x80\x9cCreate\xe2\x80\x9d to launch the CloudFormation stack.\nAfter a few minutes the provisioning should be completed.\nAfter selecting the AWS CloudFormation stack, click on the \xe2\x80\x9cOutputs\xe2\x80\x9d tab and copy the value for the \xe2\x80\x9cARNRole\xe2\x80\x9d key, the \xe2\x80\x9cRegion\xe2\x80\x9d key and the \xe2\x80\x9cTopic\xe2\x80\x9d key.\nGo Back to the Sigfox console and paste the values you copied from the \xe2\x80\x9cOutput\xe2\x80\x9d section of the AWS CloudFormation stack. Please also fill out the \xe2\x80\x9cJson Body\xe2\x80\x9d field in the Sigfox console. This JSON represents the payload that will be sent to AWS IoT using the native connector and contains the payload from the connected device as well as some metadata. This is a point for future customization using the Sigfox documentation if you wish to do so.\n{\n  ""device"" : ""{device}"",\n  ""data"" : ""{data}"",\n  ""time"" : ""{time}"",\n  ""snr"" : ""{snr}"",\n  ""station"" : ""{station}"",\n  ""avgSnr"" : ""{avgSnr}"",\n  ""lat"" : ""{lat}"",\n  ""lng"" : ""{lng}"",\n  ""rssi"" : ""{rssi}"",\n  ""seqNumber"" : ""{seqNumber}""\n}\nFinally, click \xe2\x80\x9cOk\xe2\x80\x9d.\nYou now have successfully created your callback and can visualize the data sent to it.\nNow that the data is being sent to AWS IoT via the native connector, we will create an AWS IoT Rule to store the data into an Amazon DynamoDB table.\nStart by logging into the Amazon DynamoDB table and then click \xe2\x80\x9cCreate table\xe2\x80\x9d.\nGive the table the name \xe2\x80\x9csigfox\xe2\x80\x9d and create a Partition Key \xe2\x80\x9cdeviceid\xe2\x80\x9d as well as a Sort Key \xe2\x80\x9ctimestamp\xe2\x80\x9d. Then create the table.\nAfter a couple minutes, the Amazon DynamoDB table is created. Now, go to the AWS IoT console and create a new rule.\nNow we will send every message payload coming from Sigfox in its entirety to the DynamoDB table. To do this we are using \xe2\x80\x9c*\xe2\x80\x9d as the attribute, \xe2\x80\x9csigfox\xe2\x80\x9d as the topic filter, and no conditions.\nNext add an action, select \xe2\x80\x9cInsert a message into a DynamoDB table\xe2\x80\x9d.\nSelect the Amazon DynamoDB table we created previously. In the Hash Key value input \xe2\x80\x9c${device}\xe2\x80\x9d and \xe2\x80\x9c${timestamp()}\xe2\x80\x9d for the Range Key value. With this configuration, each Device\xe2\x80\x99s ID will represent a Hash Key in the table and data stored under that Hash Key will be ordered using the timestamp generated by the AWS IoT Rules Engine and used as the Sort Key. Finally, create a new role by clicking on the \xe2\x80\x9cCreate a new role\xe2\x80\x9d button. Name it \xe2\x80\x9cdynamodbsigfox\xe2\x80\x9d and click again on the \xe2\x80\x9cCreate a new role\xe2\x80\x9d, you can now select it in the drop-down list. Thanks to this IAM role, AWS IoT can push data on your behalf to the Amazon DynamoDB table using the \xe2\x80\x9cPutItem\xe2\x80\x9d permission.\nAdd the action to the rule and create the rule. You should now be able to visualize the newly created rule in the AWS Console.\nThe final step is to go back to the Amazon DynamoDB Console and observe the data sent from Sigfox to AWS IoT thanks to the native connector. That can be achieved by selecting your table and use the \xe2\x80\x9citem\xe2\x80\x9d tab to observe the items. Once you see the item tab, click on a record to see the payload value.\nUsing this example\xe2\x80\x99s basic flow, you can now create other AWS IoT rules that route the data to other AWS services. You might want to perform archiving, analytics, machine learning, monitoring, alerting and other functions. If you want to learn more about AWS IoT, here are a few links that should help you:\nAWS IoT website\nAWS IoT State of the Union at RE:Invent 2016\nYoutube playlist of the IoT MiniCon at RE:Invent 2016\nZ#BRE testimony \xe2\x80\x93 Use case with Sigfox\nZ#BRE has developed an IoT solution for social care based on AWS IoT and Sigfox: \xe2\x80\x9cZ#LINK for Social Care\xe2\x80\x9d. The goal is to improve efficiency of social care & create a social link for elderly people. Society is increasingly connected and people are sharing more real-time information with their community. In the context of elderly people, this means they are sharing information with their community, in particular about care they are receiving each day.\nWe have developed a smart object that enables the elderly community (relatives, neighbors, care companies, etc.) to inform their community in real-time whenever a care practitioner delivers care. These real-time insights coming from care data enable public institutions to work better with care companies and to optimize costs while improving care quality.\nThanks to Sigfox connectivity we have created an object that does not require any setup nor Internet connection and can work at least two years with 4 batteries. This object\xe2\x80\x99s use of Sigfox is key when it comes to the simplicity and setup of the overall solution.\nThanks to that simple setup, Sigfox allow faster deployments time of the hardware. With low power consumption and the use of batteries, there is also no need for elderly people to plug or unplug the device, resulting in no risk that they will forget to recharge the device.\nOur infrastructure is based on different AWS services as shown in the following diagram:\nOur customer, the public council of the Loiret (a department in France), saves 3 million euros per year thanks to the implementation of this solution. More than 10,000 elderly people were equipped over a period of 5 months and more than 70 home care associations were involved in the project. As a result, this initiative was shown to have brought better care quality to elderly people.\nPlease find more information at https://zbre.io/\nNext steps\nThe release of this native connector is the first step in making it easier for customers to connect Sigfox-enabled objects to the AWS Cloud in order to make use of all the Cloud Computing services available on the AWS platform.\nWe are actively listening to any feedback from customers to continue iterating on this integration in the future and to add more capabilities. Please reach out to sigfox@amazon.com to provide feedback.\nAs the Sigfox network is growing fast globally, and the AWS IoT platform is adding new features, we are really looking forward to see what new projects customers will be deploying!\n '"
253,IoT for Non-IP Devices,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/iot-for-non-ip-devices-2/,"b'Connected devices have found their way into a myriad of commercial and consumer applications. Industries have already moved, or are in the process of moving to, operational models that require them to measure broad data points in real time and optimize their operations based on their analysis of this data. The move to smart connected devices can become expensive if expensive components must be upgraded across the infrastructure. This blog post explores how AWS IoT can be used to gather remote sensor telemetry and control legacy non-IP devices through remote infrared (IR) commands over the Internet.\nIn agriculture, greenhouses are used to create ideal growing conditions to maximize yield. Smart devices allow metrics like light level, temperature, humidity, and wind to be captured not just for historical purposes, but to react quickly to a changing environment. The example used in this blog post involves gathering light readings and activating an infrared-controlled sun shade in the greenhouse based on the current illuminance levels. A lux sensor will be placed directly under the area that we are going to control. Readings will be captured on a minute-by-minute basis. For more complex implementations, you can configure additional sensors and control devices.\nSolution Architecture\n    The IoT implementation has the following features:\nMeasures and transmits telemetry once a minute.\nUses TLS encryption to send telemetry.\nMonitors telemetry and issues alarms when thresholds are exceeded.\nEvent notifications are delivered to mobile device through SMS messages.\nIR commands over Ethernet are sent to operate the greenhouse controls.\nTelemetry is logged for reporting purposes.\nThe implementation includes the following hardware components:\nAdafruit Digital Light Sensor\nRaspberry Pi\nGlobal Cache iTach TCP/IP to IR\nWe\xe2\x80\x99re using the MQTT protocol because it is a lightweight yet reliable mechanism for sending telemetry. You can access other AWS services through IoT actions. In this implementation, we used actions to integrate with Amazon CloudWatch and Amazon DynamoDB. CloudWatch logs the telemetry and then raises an alarm if a threshold is breached. Amazon SNS invokes a Lambda function, which sends the IR command in an SNS topic to the remote devices. DynamoDB is used as a long-term, durable store of historic telemetry for reporting purposes.\nAWS Services Setup\nThis implementation uses several AWS services to create an end-to-end application to monitor and control greenhouse devices. In addition to the configuration of each service, we also need to create the roles and policies that will allow these services to work together.\nIAM\nWe use IAM roles to provide the appropriate amount of access to the AWS services.\nCreate the CloudWatch role\nStep 1. Create the CloudWatch Events role for AWS IoT to use.\nCopy and paste the following into a file named\naws_iot_role_policy_document.json.\nThis document contains a policy that will ensure that the\naws_iot_cloudwatchMetric\nrole we create in the next step can assume this role.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": {\n    ""Effect"": ""Allow"",\n    ""Principal"": {""Service"": ""iot.amazonaws.com""},\n    ""Action"": ""sts:AssumeRole""\n  }\n}\nStep 2. Create an IAM role named aws_iot_cloudwatchMetric.\nThis is the identity used by the AWS IoT action to send telemetry to CloudWatch.\nFrom the command line, run the following command.\naws iam create-role --role-name aws_iot_cloudwatchMetric --\nassume-role-policy-document \nfile://aws_iot_role_policy_document.json\nUpon successful execution of this command, an ARN for this role will be returned. Make a note of the ARN for the\naws_iot_cloudwatchMetric.\nYou will need it during the IoT action setup.\nStep 3. Create a policy document named\naws_iot_cloudwatchMetric.json.\nIt will allow the\naws_iot_cloudwatchMetric\nrole to access Amazon CloudWatch.\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Action"": ""cloudwatch:PutMetricData"",\n        ""Resource"": [\n           ""*""\n        ]\n    }\n}\nStep 4. Attach\naws_iot_cloudwatchMetric.json\nto the\naws_iot_cloudwatchMetric\nrole.\naws iam put-role-policy --role-name aws_iot_cloudwatchMetric --\npolicy-name aws_iot_cloudwatch_access --policy-document \nfile://aws_iot_cloudwatchMetric.json\nCreate the Lambda role\nNow we\xe2\x80\x99ll create a second role that will allow AWS Lambda to execute our function.\nStep 1. Copy and paste the following to a file named aws_lambda_role_policy_document.json.\nThis document contains a policy that will allow AWS Lambda to assume the role we will create in the next step.\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": {\n     ""Effect"": ""Allow"",\n     ""Principal"": {""Service"": ""lambda.amazonaws.com""},\n     ""Action"": ""sts:AssumeRole""\n   }\n}\nStep 2. Create an IAM role named aws_lambda_execution.\nThis is the identity used by Lambda to execute the function.\naws iam create-role --role-name aws_lambda_execution --assume-\nrole-policy-document file://aws_lambda_role_policy_document.json\nUpon successful execution of this command, an ARN for this role will be returned. Make a note of the ARN for the\naws_lambda_execution\nrole. You will need it during the Lambda setup.\nStep 3. Create the policy document named aws_lambda_execution.json\nthat will allow the\naws_lambda_execution\nrole to put events into CloudWatch.\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""logs:CreateLogGroup"",\n        ""logs:CreateLogStream"",\n        ""logs:PutLogEvents""\n      ],\n      ""Resource"": ""arn:aws:logs:*:*:*""\n    }\n  ]\n}\nStep 4. Attach the\naws_lambda_execution.json\nto the\naws_lambda_execution\nrole.\naws iam put-role-policy --role-name aws_lambda_execution --\npolicy-name aws_iot_lambda_access --policy-document \nfile://aws_lambda_execution.json\nCreate the DynamoDB role\nIn order to store the telemetry to a persistent data store, we will create a role for AWS IoT to use.\nStep 1. Create the Lambda execution policy document. Copy and paste the following to a file named aws_dynamodb_role_policy_document.json.\nThis document contains a policy that will allow DynamoDB to assume this role.\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": {\n     ""Effect"": ""Allow"",\n     ""Principal"": {""Service"": ""iot.amazonaws.com""},\n     ""Action"": ""sts:AssumeRole""\n   }\n}\nStep 2. Create an IAM role named aws_iot_dynamoDB.\nThis is the identity used by AWS IoT to send telemetry to DynamoDB.\naws iam create-role --role-name aws_iot_dynamoDB --assume-role-\npolicy-document file://aws_iot_dynamoDB_role_policy_document.json\nUpon successful execution of this command, an ARN for this role will be returned. Make a note of the ARN for the\naws_iot_dynamoDB\nrole. You will need it during the DynamoDB setup.\nStep 3. Create a policy document named aws_iot_dynamoDB.json\nthat will allow the\naws_iot_dyanmoDB\nrole to execute.\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": {\n     ""Effect"": ""Allow"",\n     ""Action"": ""dynamodb:PutItem"",\n     ""Resource"": ""arn:aws:dynamodb:us-east-1:000000000000:table/IoTSensor""\n   }\n}\nStep 4. Attach\naws_iot_dynamoDB.json\nto the\naws_iot_dynamoDB\nrole.\naws iam put-role-policy --role-name aws_iot_dynamoDB --policy-\nname aws_iot_dynamoDB_access --policy-document \nfile://aws_iot_dynamoDB.json\nNow that the IAM roles and policies are in place, we can configure AWS IoT and the associated rules.\nSet up AWS IoT\nLet\xe2\x80\x99s set up AWS IoT as the entry point for device communications. As soon as AWS IoT is communicating with the greenhouse sensors, we will use the AWS IoT rules engine to take further action on the sensor telemetry. The AWS IoT rules engine makes it easy to create highly scalable solutions that integrate with other AWS services, such as DynamoDB, CloudWatch, SNS, Lambda, Amazon Kinesis, Amazon ElasticSearch Service, Amazon S3, and Amazon SQS.\nCreate a thing\nFrom the AWS CLI, follow these steps to create a thing.\nStep 1. Create a thing that represents the lux meter.\naws iot create-thing --thing-name ""greenhouse_lux_probe_1""\nStep 2. Create the policy.\nStart by creating a JSON policy document. It will be linked to the\ncreate policy\nstatement. Copy and paste the following into a document. Be sure to replace 000000000000 with your AWS account number.\n   ""Version"": ""2012-10-17"",\n   ""Statement"": [\n{\n       ""Effect"": ""Allow"",\n       ""Action"": [\n         ""iot:Connect""\n       ],\n       ""Resource"": [\n         ""arn:aws:iot:us-east-1:000000000000:client/${iot:ClientId}""\n       ]\n     },\n     { \n        ""Effect"": ""Allow"",\n        ""Action"": [\n          ""iot:Publish""\n        ],\n        ""Resource"": [\n          ""arn:aws:iot:us-east-1:000000000000:topic/Greenhouse/${iot:ClientId}""\n      ]\n    }\n  ]\n}\nNow, run the following command to create the policy. Be sure to include the full path to the policy document.\naws iot create-policy --policy-name ""greenhouse_lux_policy"" --\npolicy-document file://iot_greenhouse_lux_probe_policy.json\nStep 3. Create a certificate.\nCreating a certificate pair is a simple process when you use the AWS IoT CLI. Use the following command to create the certificate, mark it as active, and then save the keys to the local file system. These keys will be required for authentication between the thing and AWS IoT.\naws iot create-keys-and-certificate --set-as-active --\ncertificate-pem-outfile IoTCert.pem.crt --public-key-outfile \npublicKey.pem.key --private-key-outfile privateKey.pem.key\nStep 4. Attach the thing and policy to the certificate.\nUsing the following as an example, replace 000000000000 with your AWS account number and 22222222222222222222222222222222222222222222 with your certificate ARN. This will attach the thing to the certificate.\naws iot attach-thing-principal \xe2\x80\x93thing-name\ngreenhouse_lux_probe_1 \xe2\x80\x93principal arn:aws:iot:us-east-\n1:000000000000:cert/22222222222222222222222222222222222222222222\nNow, attach the policy to the certificate.\naws iot attach-principal-policy --policy-name \ngreenhouse_lux_policy --principal arn:aws:iot:us-east-\n1:000000000000:cert/22222222222222222222222222222222222222222222\nNow that you have created a thing, policy, and certificate, you might also want to test connectivity to AWS IoT using a program like aws-iot-elf, which is available from the AWS Labs Github repo. After you have confirmed connectivity, you can build out the remainder of the application pipeline.\nConfigure the AWS IoT rules engine\nCreating rules is an extremely powerful and straightforward way to build a responsive, extensible architecture. In this example, we will record and respond to telemetry as fast as we can record and report it. Let\xc3\xads imagine we need to ensure that the crop is not exposed to light intensity greater than 35,000 lux. First, we will integrate AWS IoT with CloudWatch, so it can be used to decide what to do based on the received telemetry. Two rules are required to support this case: one rule called TooBright and a second rule called NotTooBright.\nStep 1. Create a JSON file named create-TooBright-rule.json\nwith the following content to serve as the rule policy. Be sure to use your AWS account number and the ARN for the\naws_iot_cloudwatchMetric\nrole.\n{\n   ""sql"": ""SELECT * FROM \'/topic/Greenhouse/LuxSensors\' WHERE \nlux > 35000"",\n   ""description"": ""Sends telemetry above 35,000 lux to \nCloudWatch to generate an alert"",\n   ""actions"": [\n   {\n       ""cloudwatchMetric"": {\n           ""metricUnit"" : ""Count"",\n           ""roleArn"": \n""arn:aws:iam::000000000000:role/aws_iot_cloudwatchMetric"",\n           ""metricValue"" : ""1"",\n           ""metricNamespace"" : ""Greenhouse Lux Sensors"",\n           ""metricName"" : ""ShadePosition""\n               }\n           }\n       ],\n    ""awsIotSqlVersion"": ""2016-03-23"",\n    ""ruleDisabled"": false\n}\nStep 2. From the command line, run this command to create the rule.\naws iot create-topic-rule --rule-name TooBright --topic-rule-\npayload file://create-TooBright-rule.json\nStep 3. Create a JSON file named create-NotTooBright-rule.json\nwith the following content to serve as the rule policy. Be sure to use the AWS account number and ARN for the\naws_iot_cloudwatchMetric\nrole that you created earlier. Change the WHERE clause to < 35000 and the metricValue to 0.\n{\n   ""sql"": ""SELECT * FROM \'/topic/Greenhouse/LuxSensors\' WHERE \nlux < 35000"",\n   ""description"": ""Sends telemetry above 35,000 lux to \nCloudWatch to generate an alert"",\n   ""actions"": [\n   {\n       ""cloudwatchMetric"": {\n           ""metricUnit"" : ""Count"",\n           ""roleArn"": \n""arn:aws:iam::000000000000:role/aws_iot_cloudwatchMetric"",\n           ""metricValue"" : ""0"",\n           ""metricNamespace"" : ""Greenhouse Lux Sensors"",\n           ""metricName"" : ""ShadePosition""\n               }\n           }\n       ],\n   ""awsIotSqlVersion"": ""2016-03-23"",\n   ""ruleDisabled"": false\n}\nStep 4. From the command line, run this command to create the rule.\naws iot create-topic-rule --rule-name NotTooBright --topic-rule-\npayload file://create-NotTooBright-rule.json\nSet up SNS\nWe will configure SNS to invoke the Lambda function and deliver an SMS message to a mobile phone. The SMS notification functionality is useful for letting the greenhouse operations team know the system is actively monitoring and controlling the greenhouse devices. Setting up SNS for this purpose is a simple process.\nStep 1. Create the SNS topic.\naws sns create-topic --name Sunshades\nThe SNS service returns the ARN of the topic.\n{\n    ""TopicArn"": ""arn:aws:sns:us-east-1:000000000000:Sunshades""\n}\nStep 2. Using the topic ARN and a phone number where the SMS message should be sent, create a subscription.\naws sns subscribe --topic-arn arn:aws:sns:us-east-\n1:000000000000:Sunshades --protocol SMS --notification-endpoint ""1 555 555 5555""\nThe SNS service confirms the subscription ID.\n{\n    ""SubscriptionArn"": ""arn:aws:sns:us-east-\n1:000000000000:Sunshades:0f1412d1-767f-4ef9-9304-7e5a513a2ac1""\n}\nSet up Lambda\nWe are going to use a Lambda function written in Python to make a socket connection to the remote Ethernet-to-IR device that controls the sun shade.\nStep 1. Sign in to the AWS Management Console, and then open the AWS Lambda console. Choose the Create a Lambda function button.\nStep 2. On the blueprint page, choose Configure triggers.\nStep 3. On the Configure triggers page, choose SNS. From the SNS topic drop-down list, choose the Sunshades topic.\nStep 4. Select the Enable trigger check box to allow the SNS topic to invoke the Lambda function, and then choose Next.\n  Step 6. On the Configure function page, type a name for your function (for example, Sunshade_Open).\nStep 7. From the Runtime drop-down box, choose Python 2.7.\nStep 8. Copy and paste the following Python code to create the Lambda functions that will open the sun shades. Be sure to use the IP address and port of the remote Ethernet-to-IR communication device. Include the IR code for your device as provided by the manufacturer.\nYou can get the IR code through the learning function of the IR repeater. This process typically requires sending an IR signal to the IR repeater so that it can capture and save the code as binary. The binary values for the IR command are then sent as part of the IP packet destined for the IR repeater.\nLambda function to open the sun shade\n#Lambda function to extend the sunshade\n#when the lux reading is too high\nimport socket\ndef lambda_handler(event, context):\nHOST = \'xxx.xxx.xxx.xxx\'# The remote host\nPORT = 4998             # The same port as used by the server\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.connect((HOST, PORT))\ns.sendall(\'sendir,1:1,15,37993,1,1,246,160,20,20,60,\\r,\\l\')\ndata = s.recv(1024)\ns.close()\nprint \'Received\', repr(data)\nIn Role, choose an existing role. In Existing role, choose the\naws_lambda_execution\nrole you created earlier, and then choose Next.\n  On the following page, review the configuration, and then choose Create function.\nChoose the blue Test button and leave the default Hello World template as it is. Choose Save and Test to see if the function ran successfully. The Lambda function should have issued the remote IR command, so check to see if the sun shade device responded to the Lambda invocation. If the execution result is marked failed, review the logs on the test page to determine the root cause. If the Lambda function was successful but the sun shade did not move, double-check that you used the appropriate IR codes.\nNow create the second Lambda function. \xe2\x80\x98Sunshade_Close\xe2\x80\x99 will be similar to \xc3\xacSunshade_Open,\xe2\x80\x99 except it will contain the IR code for closing the shade.\nSet up CloudWatch\nWe send a metric value of either 0 or 1 from the AWS IoT action to CloudWatch to indicate whether the sun shade should be opened or closed. In this example, 0 indicates that the lux level is below 35,000 and the shades should be open. 1 indicates a higher lux level that requires the sun shades to be closed. We\xc3\xadll have a problem if the power to the devices is cycled too frequently. Not only is this an inefficient way to control devices, it can also damage the equipment. For this reason, we will use CloudWatch alarms to set a threshold of 15 minutes to prevent devices from cycling between open and closed states too frequently. Each alarm will have triggers that respond to the value you put in the metric name type when you created the AWS IoT action.\nThe first alarm is called Trigger_SunShade_Open. This alarm will trigger when the variable ShadePosition value is greater or equal to 1 for 15 consecutive minutes. We will treat the ShadePosition value as a binary value where 1 indicates the lux is above the threshold and the sun shade should be opened. A value of 0 indicates that the sun shade should be closed. We define the period as a one-minute interval, which means the sun shade will change states no sooner than every 15 minutes. A second alarm called Trigger_SunShade_Close is created in the same way, except that the ShadePosition must be less than 1 for 15 minutes. Both alarms are configured with an action to send a notification to the appropriate SNS topic.\naws cloudwatch put-metric-alarm --alarm-name ""Trigger_SunShade_Open"" \n--namespace ""Greenhouse Lux Sensors"" --metric-name ""ShadePosition"" \n--statistic Sum --evaluation-periods ""15"" \n--comparison-operator ""GreaterThanOrEqualToThreshold"" \n--alarm-actions arn:aws:sns:us-east-1:000000000000:Sunshades \n--period ""60"" --threshold ""1.0"" --actions-enabled\nNext, create the\nTrigger_Sunshade_Close\nalarm in a similar manner to\nTrigger_SunShade_Open.\nThis alarm will trigger when the ShadePosition value is 1.\naws cloudwatch put-metric-alarm --alarm-name ""Trigger_SunShade_Close"" \n--namespace ""Greenhouse Lux Sensors"" --metric-name ""ShadePosition"" \n--statistic Sum --evaluation-periods ""15"" \n--comparison-operator ""LessThanOrEqualToThreshold"" \n--alarm-actions arn:aws:sns:us-east-1:000000000000:Sunshades \n--period ""60"" --threshold ""0"" --actions-enabled\nSign in to the AWS Management Console, open the CloudWatch console, and then look at the alarms.\nConfirm the two alarms were created. Because of the 15-minute evaluation period, you need to wait 15 minutes to verify the alarms are working.\nDepending on the reported value of the ShadePosition variable, the state displayed for one alarm should be OK and the other should be ALARM.\nAfter 15 minutes, we see the\nTrigger_Sunshade_Close\nalarm is in the OK state, which means the alarm has not been raised and therefore the sun shade should be not closed.\nConversely,\nTrigger_Sunshade_Open\nis in an ALARM state, which indicates the sun shade should be open.\nThis alarm state should also have generated an SMS message to the mobile device that was configured in the SNS topic.\nSet up DynamoDB\nDynamoDB is the repository for the historical lux readings because of its ease of management, low operating costs, and reliability. We\xe2\x80\x99ll use an AWS IoT action to stream telemetry directly to DynamoDB. To get started, create a new DynamoDB table.\naws dynamodb create-table --table-name Greenhouse_Lux_Sensor --\nattribute-definitions AttributeName=item,AttributeType=S \nAttributeName=timestamp,AttributeType=S --key-schema \nAttributeName=item,KeyType=HASH \nAttributeName=timestamp,KeyType=RANGE --provisioned-throughput \nReadCapacityUnits=1,WriteCapacityUnits=1\nDynamoDB will return a description of the table to confirm it was created.\nAWS IoT DynamoDB Action\nStep 1. Create a JSON file named create-dynamoDB-rule.json\nwith the following content to serve as the rule policy. Use your AWS account number and the ARN for the\naws_iot_dynamoDB\nrole you created earlier.\n{\n   ""sql"": ""SELECT * FROM \'/topic/Greenhouse/LuxSensors/#\'"",\n   ""ruleDisabled"": false,\n   ""awsIotSqlVersion"": ""2016-03-23"",\n   ""actions"": [{\n       ""dynamoDB"": {\n           ""tableName"": ""Greenhouse_Lux_Sensor"",\n           ""roleArn"": \n""arn:aws:iam::000000000000:role/aws_iot_dynamoDB"",\n           ""hashKeyField"": ""item"",\n           ""hashKeyValue"": ""${Thing}"",\n           ""rangeKeyField"": ""timestamp"",\n           ""rangeKeyValue"": ""${timestamp()}""\n       }\n   }]\n}\nStep 2. From the command line, run this command to create the rule.\naws iot create-topic-rule --rule-name Lux_telemetry_to_DynamoDB -\n-topic-rule-payload file://crate-dynamoDB-rule.json\nExecute this command to verify that telemetry is successfully being sent to DynamoDB.\naws dynamodb scan --table-name Greenhouse_Lux_Sensor --return-\nconsumed-capacity TOTAL\nThis command will scan the DynamoDB table and return any data that was written to it. In addition, it will return a ScannedCount with the number of objects in the table. If the ScannedCount is 0, make sure that telemetry is being sent to and received by AWS IoT.\nSummary\nYou now have a fully functional AWS IoT implementation that provides intelligent control of not-so-smart devices. You have also created a completely serverless solution that can serve a single device or billions of them, all without changing the underlying architecture. Lastly, charges for the services used in this implementation are based on consumption, which yields a very low TCO.\nThere are infinite uses for AWS IoT when you combine its cloud logic with the devices and sensors on the market. This post has shown the power of this AWS service can be extended to non-IP devices, which can now be managed and controlled as if they were designed for IoT applications.'"
254,Access Cross Account Resources Using the AWS IoT Rules Engine,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/access-cross-account-resources-using-aws-iot-rules-engine/,"b'The AWS IoT platform enables you to connect your internet-enabled devices to the AWS cloud via MQTT/HTTP/Websockets protocol. Once connected, the devices can send data to MQTT topic(s). Data ingested on MQTT topics can be routed into AWS services (like Amazon S3, Amazon SQS, Amazon DynamoDB, Amazon Lambda etc.), by configuring rules in AWS IoT Rules Engine.\nThis blog post explains how to set up rules for cross-account data ingestion, from an MQTT topic in one account, to a destination in another account. We will focus on the cross-account access from an MQTT topic (the source) to Lambda and SQS (the destinations).\nThe blog has been written with the assumption that you are familiar with AWS IoT and the Rules Engine, and have a fair understanding of AWS IAM concepts like users, role and resource-based permission.\nWe are going to use the AWS CLI to setup cross-account rules. If you don\xe2\x80\x99t have AWS CLI installed, you can follow these steps. If you have the AWS CLI installed, make sure you are using the most recent version.\nWhy do you need cross-account access via rules engine?\nRules with cross-account access allow you to ingest data published on an MQTT topic in one account to a destination (S3, SQS etc.) in another account. For example, Weather Corp collects weather data using its network of sensors and then publishes that data on MQTT topics in its AWS account. Now, if Weather Corp wishes to publish this data to an Amazon SQS queue of its partner, Forecast Corp\xe2\x80\x99s, AWS account, they can do so by enabling cross-account access via the AWS IoT Rules Engine.\nHow can you configure a cross-account rule?\nCross-account rules can be configured using the resource-based permissions on the destination resource.\nThus, for Weather Corp to create a rule in their account to ingest weather data into an Amazon SQS queue in Forecast Corp\xe2\x80\x99s AWS account, the cross account access can be set up by means of the two step method stated below:\n  Forecast Corp creates a resource policy on their Amazon SQS queue, allowing Weather Corp\xe2\x80\x99s AWS account to sqs:SendMessage action.\nWeather Corp configures a rule with the Forecast Corp queue URL as its destination.\nNote: Cross-account access, via AWS IoT Rules Engine, needs resource-based permissions. Hence, only destinations that support resource-based permission can be enabled for the cross-account access via AWS IoT Rules Engine. Following is the list of such destinations:\nAmazon Simple Queue Service (SQS)\nAmazon Simple Notification Service (SNS)\nAmazon Simple Storage Service (S3)\nAWS Lambda\nConfigure a cross-account rule\nIn this section, configuration of a cross account rule to access an AWS Lambda function and Amazon SQS queue in a different account has been explained. We used the AWS CLI for this configuration.\nSteps to configure a cross-account rule for AWS Lambda is different when compared to other AWS services that support resource policy.\nFor Lambda:\nThe AWS IoT Rules Engine, mandatorily requires resource-based policy to access Lambda functions; so a cross-account Lambda function invocation is configured just like any other IoT-Lambda rule. The process of enabling cross-account access for Lambda can be understood from the following example:\nAssume that Weather Corp, using AWS account# 123456789012, wishes to trigger a Lambda function (LambdaForWeatherCorp) in Forecast Corp\xe2\x80\x99s account (AWS account# 987654321012) via the Rules Engine. Further, Weather Corp wishes to trigger this rule when a message arrives on Weather/Corp/Temperature MQTT topic.\nTo do this, Weather Corp would need to create a rule (WeatherCorpRule) which will be attached to Weather/Corp/Temperature topic. To create this rule, Weather Corp would need to call the CreateTopicRule API. Here is an example of this API call via AWS CLI:\naws iot create-topic-rule --rule-name WeatherCorpRule --topic-rule-payload file://./lambdaRule\nContents of the lambdaRule file:\n{\n       ""sql"": ""SELECT * FROM \'Weather/Corp/Temperature\'"", \n       ""ruleDisabled"": false, \n       ""actions"": [{\n           ""lambda"": {\n               ""functionArn"": ""arn:aws:lambda:us-east-1:987654321012:function:LambdaForWeatherCorp""   //Cross account lambda\n            }\n       }]\n}\nForecast Corp will also have to give the AWS IoT Rules Engine permission to trigger LambdaForWeatherCorp Lambda function. Also, it is very important for Forecast Corp to make sure that only the AWS IoT Rules Engine is able to trigger the Lambda function and that it is done so only on behalf of Weather Corp\xe2\x80\x99s WeatherCorpRule (created above) rule.\nTo do this, Forecast Corp would need to use Lambda\xe2\x80\x99s AddPermission API. Here is an example of this API call via AWS CLI:\naws lambda add-permission --function-name LambdaForWeatherCorp --region us-east-1 --principal iot.amazonaws.com --source-arn arn:aws:iot:us-east-1:123456789012:rule/WeatherCorpRule --source-account 123456789012 --statement-id ""unique_id"" --action ""lambda:InvokeFunction""\nOptions:\n\xe2\x80\x93principal: This field gives permission to AWS IoT (represented by iot.amazonaws.com) to call the Lambda function.\n\xe2\x80\x93source-arn: This field makes sure that only arn:aws:iot:us-east-1:123456789012:rule/WeatherCorpRule rule in AWS IoT triggers this Lambda (no other rule in the same or different account can trigger this Lambda).\n\xe2\x80\x93source-account: This field makes sure that AWS IoT triggers this Lambda function only on behalf of 123456789012 account.\nNote: To run the above command, IAM user/role should have permission to lambda:AddPermission action.\nFor Other Services\nAs of today, the Rules Engine does not use resource policy to access non-Lambda AWS resources (Amazon SQS, Amazon S3, Amazon SNS ). Instead, it uses IAM role to access these resources in an account. Additionally, AWS IoT rules can only be configured with roles from the same account. This implies, that a rule cannot be created in one account that uses a role from another account.\nWhile, a role from another account cannot be used in a rule, a role can be set up in an account to access resources in another account. Also, for a cross-account role to work, you need a resource policy on the resource that has to be accessed across the account.\nThe process of rule creation with access to cross-account resources can be understood from the below example:\nLet\xe2\x80\x99s assume that Weather Corp, using AWS account# 123456789012, wishes to send some data to Amazon SQS (SqsForWeatherCorp) in Forecast Corp\xe2\x80\x99s account (AWS account# 987654321012) via rules engine. If Weather Corp wishes to trigger this rule when a message arrives on Weather/Corp/Temperature MQTT topic.\nTo do this, Weather Corp would need to do the following things:\nStep 1: Create an IAM policy (PolicyWeatherCorp) that defines cross-account access to SqsForWeatherCorp SQS queue. To do this, Weather Corp would need to call IAM\xe2\x80\x99s CreatePolicy API. Here is an example of this API call via AWS CLI:\naws iam create-policy --policy-name PolicyWeatherCorp --policy-document file://./crossAccountSQSPolicy\nWhere the contents of crossAccountSQSPolicy file are below:\n{\n   ""Version"": ""2012-10-17"",\n   ""Statement"": [\n       {\n           ""Sid"": \xe2\x80\x9cunique\xe2\x80\x9d,\n           ""Effect"": ""Allow"",\n           ""Action"": [\n               ""sqs:SendMessage""\n           ],\n           ""Resource"": [\n               ""arn:aws:sqs:us-east-1:987654321012:SqsForWeatherCorp"" //Cross account SQS queue\n           ]\n       }\n   ]\n}\nStep 2: Create a role (RoleWeatherCorp) that defines iot.amazonaws.com as a trusted entity. To do this Weather Corp would need to call IAM\xe2\x80\x99s CreateRole API. Here is an example of this API call via AWS CLI:\n  aws iam create-role --role-name RoleWeatherCorp  --assume-role-policy-document file://./roleTrustPolicy\nWhere the contents of roleTrustPolicy file are below:\n{\n ""Version"": ""2012-10-17"",\n ""Statement"": [\n   {\n     ""Sid"": """",\n     ""Effect"": ""Allow"",\n     ""Principal"": {\n       ""Service"": ""iot.amazonaws.com""\n     },\n     ""Action"": ""sts:AssumeRole""\n   }\n ]\n}\nStep 3: Attach policy to role. To do this, Weather Corp would need to call AttachRolePolicy API. Here is an example of this API call via AWS CLI:\naws iam attach-role-policy --role-name RoleWeatherCorp --policy-arn  arn:aws:iam::123456789012:policy/PolicyWeatherCorp\nStep 4: Create a rule (WeatherCorpRule) that is attached to Weather/Corp/Temperature topic. To create this rule, Weather Corp would need to call CreateRule API. Here is an example of this API call via AWS CLI:\naws iot create-topic-rule --rule-name WeatherCorpRule --topic-rule-payload file://./sqsRule\nWhere the contents of sqsRule file are below:\n{\n       ""sql"": ""SELECT * FROM \'Weather/Corp/Temperature\'"", \n       ""ruleDisabled"": false, \n       ""actions"": [{\n           ""sqs"": {\n               ""queueUrl"": ""https://sqs.us-east-1.amazonaws.com/987654321012/SqsForWeatherCorp"",\n               ""roleArn"": ""arn:aws:iam::123456789012:role/RoleWeatherCorp\xe2\x80\x9d, \n               ""useBase64"": false\n           }\n       }]\n}\nNote: To run the above command, IAM user/role should have permission to iot:CreateTopicRule with rule arn as resource. Also, it needs to have permission to iam:PassRole action with resource as role arn.\nFurther, Forecast Corp would need to give permission on SqsForWeatherCorp to Weather Corp\xe2\x80\x99s account, using resource policy. This can be done using SQS\xe2\x80\x99s add-permission API. Here is an example of this API call via AWS CLI:\naws sqs add-permission --queue-url https://sqs.us-east-1.amazonaws.com/987654321012/SqsForWeatherCorp --label SendMessagesToMyQueue --aws-account-ids 123456789012 --actions SendMessage\nIt is important to note, that by adding this resource policy, Forecast Corp not only allows AWS IoT rules engine to send messages to SqsForWeatherCorp, but also permits all users/roles in Weather Corp\xe2\x80\x99s account (which have the policy to allow sqs:SendMessage to SqsForWeatherCorp) to send messages to SqsForWeatherCorp.\nOnce the above setup is done, all messages sent to Weather/Corp/Temperature (which is in WeatherCorp\xe2\x80\x99s account) will be sent to SqsForWeatherCorp (which is in Forecast Corp\xe2\x80\x99s account) using the rules engine.\n'"
255,Identify APN Partners to Help You Build Innovative IoT Solutions on AWS,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/identify-apn-partners-to-help-you-build-innovative-iot-solutions-on-aws/,"b'AWS provides essential building blocks to help virtually any company build and deploy an Internet of Things (IoT) solution.  Building on AWS, you have access to a broad array of services including AWS IoT, a managed cloud platform that lets connected devices easily and securely interact with cloud applications and other devices, and low-cost data storage with high durability and availability for backup, archiving, and disaster recovery options to meet virtually an infinite number of scenarios and use cases. For example, Amazon S3 provides scalable storage in the cloud, Amazon Glacier provides low cost archive storage, and AWS Snowball enables large volume data transfers.  No solution is complete without information being generated from the system data collected. Here, you can utilize Amazon Machine Learning for predictive capabilities which can enable you to gain business insights from the data you\xe2\x80\x99ve collected. We strive to offer services commonly used to build solutions today, and regularly release new services purposely built to help you meet your IoT business needs today and in the future.\nWe are currently witnessing a major shift in how customers view their business. Customers across industries, including Financial Services, Manufacturing, Energy, Transportation, Industrial and Banking, are on a business transformation journey and are seeking guidance to help transform from product-centric to service-orientated companies, taking advantage of actionable insights they can drive through IoT.  Early adopters have already deployed a wide range of cloud-based IoT solutions, and many are seeking to optimize existing solutions. Some companies are just getting started.  Regardless of where your company is in your IoT journey, working with industry-leading AWS Partner Network (APN) Partners who offer value-added services and solutions on AWS can help you accelerate your success.\nToday, we launched the AWS IoT Competency to help you easily connect to APN Partners with proven expertise and customer success to help meet your specific business needs.\nWhat\xe2\x80\x99s the value of the AWS IoT Competency for your firm?\nThe IoT value chain is complex, and has many \xe2\x80\x9cactors.\xe2\x80\x9d Successful IoT implementations require services and technologies not traditionally part of the Enterprise DNA. As you seek to find best-in-breed partners for your specific needs, whether they be identifying edge or gateway devices or software, a platform to acquire, analyze, and act on IoT data, connectivity for edge and gateway devices, or consulting services to help you architect and deploy your solution, we want to make sure we help you easily connect with Consulting and Technology Partners who can help.\nAPN Partners who have achieved the AWS IoT Competency have been vetted by AWS solutions architects, and have passed a high bar of requirements such as providing evidence of deep technical and consulting expertise helping enterprises adopt, develop, and deploy complex IoT projects and solutions. IoT Competency Partners provide proven technology and/or implementation capabilities for a variety of use cases including (though not limited to) intelligent factories, smart cities, energy, automotive, transportation, and healthcare.  Lastly, public customer references and proven customer success are a core requirement for any APN Partner to achieve the AWS IoT Competency.\nUse Cases and Launch Partners\nCongratulations to our launch IoT Technology Competency Partners in the following categories:\nEdge:  Partners who provide hardware and software ingredients used to build IoT devices, or finished products used in IoT solutions or applications.  Examples include: sensors, microprocessors and microcontrollers, operating systems, secure communication modules, evaluation and demo kits.\nIntel\nMicrochip Technology\nGateway: Partners who provide data aggregation hardware and/or software connecting edge devices to the cloud and providing on premise intelligence as well as connecting to enterprise IT systems.  Examples include hardware gateways, software components to translate protocols, and platforms running on-premises to support local decision making.\nMachineShop\nPlatform Providers: Independent software vendors (ISVs) who\xe2\x80\x99ve developed a cloud-based platform to acquire, analyze, and act on IoT data. Examples include device management systems, visualization tools, predictive maintenance applications, data analytics, and machine learning software.\nBsquare Corporation\nC3 IoT\nSplunk\nPTC\nThinglogix\nConnectivity: Partners who provide systems to manage wide-area connectivity for edge and gateway devices.  Examples include device and subscription management platforms, billing and rating systems, device provisioning systems, and Mobile Network Operators (MNOs) and Mobile Virtual Network Operators (MVNOs)\nAmdocs, Inc.\nAsavie\nEseye\nSORACOM\nCongratulations to our launch IoT Consulting Competency Partners!\nAccenture\nAricent\nCloud Technology Partners\nMobiquity, Inc.\nLuxoft\nSolstice\nSturdy\nTrek10\nLearn More\nHear from two of our launch AWS IoT Competency Partners, MachineShop and C3 IoT, as they discuss why they work with AWS, and the value of the AWS IoT Competency for customers:\nC3 IoT:\nMachineShop:\nWant to learn more about the different IoT Partner Solutions? Click here.'"
256,Improved AWS IoT Management Console,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/improved-aws-iot-management-console/,"b'For many customers, the management console is the primary tool for interacting with and monitoring AWS IoT. This includes connecting a first device, diving into thing details, finding key resources, and testing with the MQTT client. Over the past year, we received feedback from customers that drove the redesign of a new AWS IoT console available today.\nIn the new console, you will see:\nNew visual design for improved usability and navigation\nImproved navigation to things, types, certificates, policies, and rules, making them easier to find\nA new dashboard with account-level metrics\nStreamlined MQTT web client to troubleshoot your IoT solutions\nA new wizard to connect devices in fewer steps\nA real-time feed of things\xe2\x80\x99 lifecycle events and shadow activity\nTo try the new console experience, sign in to the console.\nYour feedback is important to us as we continue to improve the AWS IoT console experience. To send feedback, please use the Feedback button in the footer of the console.\nFig 1 \xe2\x80\x93 New dashboard with account-level metrics.\nFig 2 \xe2\x80\x93 Things, types, certificates, policies, and rules all have their own areas.\nFig 3 \xe2\x80\x93 Drill in to resource details and take action.'"
257,Bites of IoT – Rules Engine and Amazon SNS,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/197-2/,"b'Welcome to another installment in the Bites of IoT blog series.\nIn this bite, we will use the AWS IoT rules engine to select and route a message to Amazon Simple Notification Service (Amazon SNS). Specifically, we\xe2\x80\x99ll send a text message to a phone number when someone rings a virtual doorbell.\nConcepts Covered in This Bite\nThe rules engine is often the first point at which your IoT solution can take actions on a device\xe2\x80\x99s messages (for example, message filtering, routing to other services, and even direct processing of messages in your solution).\nBy using  AWS IoT and Amazon SNS together, you can send near real-time notifications in response to changes in the physical world as reported by devices in your IoT solution. These notifications can be:\nsent to system operators or technicians for human intervention.\nadded to your existing ticketing system.\nused to kick off an automated workflow.\nConfigure the CLI\nAs with all Bites of IoT posts, we are using the AWS IoT ELF client available in AWS Labs on GitHub. If you aren\xe2\x80\x99t familiar with the ELF, check out the first post in this series.\nWe\xe2\x80\x99ll use the AWS CLI to create the Amazon SNS topic and AWS IoT rule. In addition to the permissions required by the AWS IoT ELF, you will need to configure the profile used by your CLI with, at minimum, the following permissions. Make sure to replace the value 012345678901 in the policy with your AWS account ID:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""sns:CreateTopic"",\n                ""sns:SetTopicAttributes"",\n                ""sns:Subscribe"",\n                ""sns:Publish"",\n                ""sns:DeleteTopic"",\n                ""iot:CreateTopicRule"",\n                ""iot:DeleteTopicRule"",\n                ""iam:AttachRolePolicy"",\n                ""iam:CreatePolicy"",\n                ""iam:CreateRole"",\n                ""iam:DetachRolePolicy"",\n                ""iam:DeletePolicy"",\n                ""iam:DeleteRole""\n            ],\n            ""Resource"": ""*""\n        },\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""iam:PassRole""\n            ],\n            ""Resource"": [\n                ""arn:aws:iam::012345678901:role/*""\n            ]\n        }\n    ]\n}\nCreate a Bites Directory\nIf you followed the steps in Getting Started, you should already have a local directory structure of ~/dev/aws-iot-elf (where \xe2\x80\x9c~\xe2\x80\x9d is shorthand for your computer user\xe2\x80\x99s home directory).\nEach Bite of IoT post will require the creation of local files. Start by creating your Bites directory. On Linux or Mac OS, execute the following commands:\ncd ~/dev\nmkdir bites\ncd ~/dev/bites\nNow, in your Bites directory, execute these commands to make a directory for the artifacts used in this post, and then change into that directory.\nmkdir sns\ncd ~/dev/bites/sns\nNow that the basic dev environment is set up, let\xe2\x80\x99s get into the details.\nCreate the SNS Topic\nCreate the Amazon SNS topic that the AWS IoT rules engine will be connecting with to send notifications. Use the following AWS CLI commands to create and name the topic. Remember to replace 012345678901 in the --topic-arn value with your AWS account ID.\naws sns create-topic --region us-west-2 --name door-alert\naws sns set-topic-attributes --region us-west-2 --topic-arn arn:aws:sns:us-west-2:012345678901:door-alert --attribute-name DisplayName --attribute-value DOORBELL\nNote: The DisplayName value DOORBELL will appear as the \xe2\x80\x9cfrom\xe2\x80\x9d address when you receive a notification on your mobile phone.\nNow subscribe your mobile phone to the topic using the following CLI command. Replace 1-012-345-6789 with your phone number. This command enables your mobile phone to receive the notification when the virtual doorbell rings.\naws sns subscribe --region us-west-2 --topic-arn arn:aws:sns:us-west-2:012345678901:door-alert --protocol sms --notification-endpoint 1-012-345-6789\nYou can use this command to validate the subscription:\naws sns publish --region us-west-2 --message ""A Bite of Hello"" --topic-arn arn:aws:sns:us-west-2:012345678901:door-alert\nCreate Permissions to Use Amazon SNS\nBefore we create the IoT rule, we need to create an IAM role that the AWS IoT rules engine will assume and use to securely publish a message to Amazon SNS.\nThe first step to creating the role is to make a trust policy that grants AWS IoT permission to assume the role. Copy and paste the following trust policy document into a temporary file named iot-role-trust.json:\n{\n    ""Version"":""2012-10-17"",\n    ""Statement"":[{\n        ""Effect"": ""Allow"",\n        ""Principal"": {\n            ""Service"": ""iot.amazonaws.com""\n        },\n        ""Action"": ""sts:AssumeRole""\n    }]\n}\nRun the following CLI command to create the role:\naws iam create-role --role-name iot_sns_role --assume-role-policy-document file://iot-role-trust.json\nAWS IoT now needs permission to publish to the Amazon SNS topic we created. Copy and paste the following IAM policy document to create a file named iot-policy.json:\n{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Action"": ""sns:Publish"",\n        ""Resource"": ""arn:aws:sns:us-west-2:012345678901:door-alert""\n    }\n}\nRun the following CLI command to create the policy:\naws iam create-policy --policy-name iot_sns_policy --policy-document file://iot-policy.json\nThen run this CLI command to attach the policy to the role:\naws iam attach-role-policy --role-name iot_sns_role --policy-arn arn:aws:iam::012345678901:policy/iot_sns_policy\nCreate the AWS IoT Rule\nNow we can set up the AWS IoT rule that will trigger a text alert when the bell rings. The rule will perform this task by sending every message that comes across the doorbell topic to Amazon SNS. Copy and paste the following rule definition into a file named sns-rule.json:\n{\n  ""sql"": ""SELECT * FROM \'doorbell/+\'"",\n  ""description"": ""Sends a message to SNS when a message comes across the \'doorbell\' topic"",\n  ""actions"": [\n    {\n      ""sns"": {\n        ""targetArn"":""arn:aws:sns:us-west-2:012345678901:door-alert"",\n        ""roleArn"":""arn:aws:iam::012345678901:role/iot_sns_role"",\n        ""messageFormat"": ""RAW""\n      }\n    }\n  ],\n  ""ruleDisabled"": false\n}\nRemember to replace 012345678901 in the rule with your AWS account ID.\nFinally, use this CLI command to create the rule:\naws iot create-topic-rule --region us-west-2 --rule-name sendToSNS --topic-rule-payload file://sns-rule.json\nSimulate the Doorbell\nEverything is now ready to ask the ELF to push the virtual doorbell button. Use the following commands to switch to the AWS IoT ELF directory and get the latest version:\ncd ~/dev/aws-iot-elf\n\ngit pull\nUse this command to activate the ELF\xe2\x80\x99s virtual environment:\nsource ~/dev/aws-iot-elf/venv/bin/activate\nOn Windows:\n.\\venv\\Scripts\\activate\nUse this command to create a thing in the AWS IoT service to serve as our doorbell:\npython elf.py --region us-west-2 create 1\nThe following command will now send a message on the topic as if the ELF pushed the virtual doorbell button.\npython elf.py --region us-west-2 send --duration 1 --topic \'doorbell\' \'Somebody is at the door!\'\nVery shortly, your mobile phone should receive a text message similar to this:\nDOORBELL> {""msg"": ""Somebody is at the door!"", ""ts"": ""1468958915.41""}\nClean Up\nYou can use the following commands to clean up your environment:\npython elf.py --region us-west-2 clean\n\naws iam detach-role-policy --role-name iot_sns_role --policy-arn arn:aws:iam::012345678901:policy/iot_sns_policy\n\naws iam delete-role --role-name iot_sns_role\n\naws iam delete-policy --policy-arn arn:aws:iam::012345678901:policy/iot_sns_policy\n\naws iot delete-topic-rule --region us-west-2 --rule-name sendToSNS\n\naws sns delete-topic --region us-west-2 --topic-arn arn:aws:sns:us-west-2:012345678901:door-alert\nIf you\xe2\x80\x99d like to clean up the files created in this post, you can remove them from the ~dev/bites/sns directory.\nDone!\nIn this bite, you\xe2\x80\x99ve learned how to use AWS IoT and Amazon SNS together to send near real-time notifications in response to messages that come from a thing.\nWe hope you found this walk-through useful. Feel free to leave your feedback in the comments.\nStay tuned for the next post in the Bite of IoT series. Until then, may your success be swift and your solution scalable.'"
258,Just-in-Time Registration of Device Certificates on AWS IoT,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/just-in-time-registration-of-device-certificates-on-aws-iot/,"b'In an earlier blog post about certificates, we discussed how use-your-own-certificate support in AWS IoT lets customers use device certificates signed and issued by their own certificate authority (CA) to connect and authenticate with AWS IoT. This is an alternative to using certificates generated by AWS IoT.\nUsing your own certificate with AWS IoT is a two-step process:\nThe first step is to register the CA certificate that signed and issued the device certificates.\nAfter registration, any device certificate that was signed by the CA can be registered with AWS IoT and used for authentication thereafter.\nNow, with support for just-in-time registration (JITR) of CA-signed certificates, AWS IoT eliminates the second step.\nIn this blog post, I will explain how JITR works and how it can be used to set up a workflow that activates device certificates and attaches policies to them automatically. I will also walk you through steps for deactivating a CA certificate and revoking device certificates.\nYou will do the following:\nCreate, register, and activate a CA certificate that will be used to sign your device certificate.\nEnable auto-registration of certificates.\nCreate device certificates signed by the CA and install them on your device.\nCreate and attach a rule with an AWS Lambda action that activates the certificate, and then creates and attaches policies to the certificate.\nConnect to AWS IoT using the device certificate.\nWhen you connect to AWS IoT with the device certificate for the first time, the service will detect an unknown certificate signed by a registered CA and will auto-register the device certificate. On successful registration, AWS IoT will publish a registration message on a reserved MQTT topic and disconnect the client. This MQTT registration event will trigger the attached AWS Lambda rules engine action, which will complete the provisioning of the certificate. After these steps, your device certificate will be ready to connect and authenticate with AWS IoT.\nIn this blog post, I assume you are familiar with AWS IoT and the process of creating an AWS IoT certificate. You will use the AWS CLI and OpenSSL to perform the procedures. If you don\xe2\x80\x99t have the AWS CLI installed, follow these steps. If you already have the AWS CLI, make sure you are using the most recent version.\nFor information about authentication in AWS IoT or how to use AWS IoT-generated certificates, see the AWS IoT Developer Guide.\nRegistering Your CA Certificate\nIf you are a manufacturer, you have purchased CA certificates from vendors like Symantec or Verisign or you have your own CA. To use your own X.509 certificates that have been signed by your CA certificate, AWS IoT must first verify that you not only own the CA certificate, but that you also have access to its private key. The process for validating ownership of a CA certificate is done through a challenge and response workflow.\nLet\xe2\x80\x99s start by using openssl in a terminal to create your sample CA certificate. In the real world, the signing or intermediate certificates would be issued by your CA vendor. This sample CA certificate is used later in the walkthrough to sign a device certificate that you register with AWS IoT:\n$ openssl genrsa -out sampleCACertificate.key 2048\n$ openssl req -x509 -new -nodes -key sampleCACertificate.key -sha256 -days 365 -out sampleCACertificate.pem\nFor simplicity, we are creating and registering the root CA certificate. In reality, the intermediate CA certificate would be signed by the root CA that signs the device certificates. In that case, you register the intermediate CA certificate with AWS IoT.\nNow that you\xe2\x80\x99ve created a sample CA certificate, you will register it with AWS IoT. When you register a CA certificate with AWS IoT, you follow a workflow to verify that you have access to both the CA certificate and the private key associated with the CA certificate. To verify ownership of the private key, you generate a verification certificate using the CA certificate, the private key, and a registration code that you generate from AWS IoT.\nThe registration workflow first requires retrieving the registration code. You can use the AWS CLI or the Register Certificate section in the AWS IoT console to get the registration code.\nTo use the AWS CLI, run the following command:\n$ aws iot get-registration-code\nThis command will return a randomly generated, unique registration code that is bound to your AWS account. This registration code is long-lived. It does not expire until you delete it.\nNext, you will use the registration code to create a CSR:\n$ openssl genrsa -out privateKeyVerification.key 2048\n$ openssl req -new -key privateKeyVerification.key -out privateKeyVerification.csr\nDuring the CSR creation process, you will be prompted for information. Enter the registration code into the Common Name field of the verification certificate:\n...\nOrganization Name (eg, company) []:\nOrganizational Unit Name (eg, section)\nCommon Name (e.g. server FQDN or YOUR name) []: XXXXXSAMPLEREGISTRATIONCODEXXXXX\nEMAIL ADDRESS []:\nThe registration code establishes that the generated verification certificate was created specifically for registering the CA certificate with AWS IoT, and that the verification certificate is not a previously issued certificate.\nNow that you have a CSR that includes the registration code, use your first sample CA certificate and the CSR to create a new certificate:\n$ openssl x509 -req -in privateKeyVerification.csr -CA sampleCACertificate.pem -CAkey sampleCACertificate.key -CAcreateserial -out privateKeyVerification.crt -days 365 -sha256\nWhen you register your CA certificate with AWS IoT, the combination of the registration code, verification certificate signed with the CA private key, and the CA certificate are used to verify ownership of the CA private key.\nNext, you will use the verification certificate to register your sample CA certificate:\n$ aws iot register-ca-certificate --ca-certificate file://sampleCACertificate.pem --verification-certificate file://privateKeyVerification.crt\nYou can make a describe-ca-certificate call to get the information on the registered CA certificate. You will use the certificate ID of the registered CA returned in the response of the previous CLI command.\n$ aws iot describe-ca-certificate --certificate-id <certificateId>\nNext, you will activate the CA certificate. By default, the CA certificate will be registered in an INACTIVE state. At the time of the registration of the device certificate, AWS IoT will consult the status of its registered CA certificate and will allow the registration of the device certificate only if the CA certificate is in an ACTIVE state. Use the update-ca-certificate CLI command to change the status of the CA certificate. Alternatively, you can register the CA certificate in the ACTIVE state by passing the set-as-active flag at the time of registration:\n$ aws iot update-ca-certificate --certificate-id <certificateId> --new-status ACTIVE\nBy default, the auto-registration-status of the registered CA certificate is disabled. That means any device certificate issued by the registered CA will not be auto-registered by default when it first connects to the AWS IoT service. However, you can use the register-certificate CLI command to explicitly register the device certificate. If the auto-registration-status is enabled for a CA certificate, the device certificate issued by that CA will be auto-registered, if not already registered, when it connects to AWS IoT for the first time. To opt in for the auto-registration of the device certificates issued by a registered CA, set the auto-registration-status for the CA certificate to ENABLE.\nYou can enable the auto-registration-status through the update-ca-certificate CLI command. Alternatively, you can register the CA certificate with the auto-registration-status enabled by passing the --allow-auto-registration flag to the register-ca-certificate CLI command.\n$ aws iot update-ca-certificate --certificate-id <caCertificateId> --new-auto-registration-status ENABLE\nDevice Certificate Registration Event and Action\nWhen a device attempts to connect with an X.509 certificate that is not known to AWS IoT but was signed by a CA that was registered with AWS IoT, the device certificate will be auto-registered by AWS IoT in a new PENDING_ACTIVATION state. PENDING_ACTIVATION means that the device certificate was auto-registered and is awaiting activation. Only AWS IoT can mark the status of a certificate as PENDING_ACTIVATION. If you connect with a certificate in PENDING_ACTIVATION state, a TLS handshake failure will occur because only ACTIVE certificates are authenticated with AWS IoT. For this reason, you need to change the status of the registered certificate from PENDING_ACTIVATION to ACTIVE so that it can be successfully authenticated.\nWhen AWS IoT auto-registers a certificate or when a certificate in PENDING_ACTIVATION status connects, it publishes a message to the following MQTT topic:\n$aws/events/certificates/registered/<caCertificateID>\nwhere the caCertificateId is the ID of the CA certificate that issued the device certificate.\nThe message published to this topic has the following structure:\n{\n  ""certificateId"": ""<certificateID>"",\n  ""caCertificateId"": ""<caCertificateId>"",\n  ""timestamp"": ""<timestamp>"",\n  ""certificateStatus"": ""PENDING_ACTIVATION"",\n  ""awsAccountId"": ""<awsAccountId>"",\n  ""certificateRegistrationTimestamp"": ""<certificateRegistrationTimestamp>""\n}\nYou can subscribe or attach any AWS IoT rule to the registration topic. The attached AWS IoT rules can then take some action based on the messages received. For example, an AWS IoT rule in your account can listen on the $aws/events/certificates/registered/+ topic to build an Amazon DynamoDB table of all the registered certificates. The general recommendation is to attach an AWS IoT rules engine action to the registration topic that will perform the bootstrapping or provisioning steps (like consulting your CRLs) and then activate/deactivate/revoke the certificate, create and attach the policies to the certificate, and so on.\nIn the following example, we will create a topic rule with an AWS Lambda action on the registration topic that will activate the certificate and create and attach a policy.\nUse the AWS Lambda console to create the AWS Lambda function:\nSign in to the AWS Management Console and open the AWS Lambda console at https://console.aws.amazon.com/lambda/home?region=us-east-1.\nChoose Create an AWS Lambda function.\nOn the Configure function page, type a name and description for the AWS Lambda function. In Runtime, choose Node.js 4.3.\nScroll down to the AWS Lambda function code section of the page. Replace the existing code with this sample code.\nScroll down to the AWS Lambda function handler and role section of the page. For Role, choose Create a custom role. When the IAM console opens, you can create an IAM role that AWS Lambda can assume when executing the AWS Lambda function.\nIn the navigation pane, choose Create New Role.\nFor Role name, type a role name.To edit the role\xe2\x80\x99s policy to give it permission to update the certificate and create and attach the policy:\nChoose View Policy Document.\nReplace the policy document with the following:\n{  \n   ""Version"":""2012-10-17"",\n   ""Statement"":[  \n      {  \n         ""Effect"":""Allow"",\n         ""Action"":[  \n            ""logs:CreateLogGroup"",\n            ""logs:CreateLogStream"",\n            ""logs:PutLogEvents""\n         ],\n         ""Resource"":""arn:aws:logs:*:*:*""\n      },\n      {  \n         ""Effect"":""Allow"",\n         ""Action"":[  \n            ""iot:UpdateCertificate"",\n            ""iot:CreatePolicy"",\n            ""iot:AttachPrincipalPolicy""\n         ],\n         ""Resource"":""*""\n      }\n   ]\n}\nChoose Allow.\nLeave the settings on the Advanced settings page at their defaults, and choose Next.\nOn the Review page, choose Create function.\nCreating an AWS Lambda Rule\nNow that you have created an AWS Lambda function, you can create a rule that invokes the function.\nIn the AWS IoT console, choose Create a resource.\nChoose Create a rule.\nType a name and description for the rule.\nEnter the following settings for the rule:\nSQL version: 2016-03-23-beta\nAttribute: *\nTopic filter: $aws/events/certificates/registered/<caCertificateID> Note: Replace <caCertificateId> with the ID of the registered CA certificate.\nFor Choose an action, choose Insert this message into a code function and execute it (AWS Lambda).\nFrom Function name, choose your AWS Lambda function name, and then choose Add action.\nChoose Create to create your AWS Lambda function.\nYou also need to grant permissions to the AWS IoT service principal to invoke the AWS Lambda function on your behalf when the MQTT message is published on the registration topic.\nNote: If you created the rule through the AWS IoT console, you can skip this step. The console does this for you when you create the AWS Lambda rule.\nYou will use the AWS Lambda AddPermission API to grant permissions:\naws lambda add-permission --function-name <lambda-function-name> --region us-east-1 --principal iot.amazonaws.com --source-arn <rule-arn> --source-account <your-aws-account> --statement-id Id-123 --action ""lambda:InvokeFunction""\nAuto-registration of a Device Certificate Signed by Your CA Certificate\nNow that you\xe2\x80\x99ve created, registered, and activated a sample CA certificate with auto-registration-status enabled and configured a rule with an AWS Lambda action to activate the certificate and attach policies, use the CA certificate to create a new device certificate and auto-register it when it first connects to AWS IoT.\nEnter the following commands in your terminal to create a device certificate:\n$ openssl genrsa -out deviceCert.key 2048\n$ openssl req -new -key deviceCert.key -out deviceCert.csr\n$ openssl x509 -req -in deviceCert.csr -CA sampleCACertificate.pem -CAkey sampleCACertificate.key -CAcreateserial -out deviceCert.crt -days 365 -sha256\nNext, try to connect to AWS IoT using the device certificate. Because you\xe2\x80\x99ve completed the preceding steps, your device certificates will be auto-registered during the TLS handshake when it connects to AWS IoT for the first time. At the time of connection, you need to send both the device certificate and its registered CA certificate.\nCreate a certificate file that contains the device certificate and its registered CA certificate. Here is the Linux command:\n$ cat deviceCert.crt sampleCACertificate.pem > deviceCertAndCACert.crt\nIn the following example, you will use the MQTT Mosquitto client to connect and publish to AWS IoT using the device certificate:\n$ mosquitto_pub --cafile root.cert --cert deviceCertAndCACert.crt --key deviceCert.key -h <prefix>-ats.iot.us-east-1.amazonaws.com -p 8883 -q 1 -t  foo/bar -i  anyclientID --tls-version tlsv1.2 -m ""Hello"" -d\nNote: The root.cert is the AWS IoT root certificate. The AWS IoT root CA certificate is used by a device to verify the identity of the AWS IoT servers. Click here to download the root certificate. Save this file to your desktop and name it \xe2\x80\x9croot.cert\xe2\x80\x9d.\nYou will see a TLS failure when you run the command because AWS IoT disconnects the connection after the registration of the device certificate. AWS IoT has registered the certificate in the PENDING_ACTIVATION state and won\xe2\x80\x99t let it connect and authenticate unless the certificate is marked ACTIVE. The client or device should implement an automatic reconnect strategy when it is disconnected due to the TLS error. The device should also implement a back-off strategy (that is, increase the time between retries) to avoid unnecessary network traffic and allow your own activation logic to complete before devices attempt to reconnect.\nThe commands to connect to AWS IoT with the device certificate whose CA has been registered will lead to the auto-registration of the device certificate during the TLS handshake. An MQTT registration event will be published on the registration topic and trigger the attached Lambda rule action to activate the certificate and attach the policy to it. This will complete the registration and provisioning of the device certificate. It can now be used for authentication and authorization with AWS IoT. After a device certificate is registered with AWS IoT, you can interact with it in a way that\xe2\x80\x99s similar to a device certificate generated by AWS IoT. You can activate/deactivate /revoke certificates, attach policies, and associate things to your device certificates. In addition, you can manage the lifecycle of that device certificate in AWS IoT by deactivating, revoking, or activating the certificate in your AWS account.\nDeactivate the CA Certificate\nDuring device certificate registration, AWS IoT will check if the associated CA certificate is active. If the CA certificate is inactive, AWS IoT will not allow the device certificate to be registered. This feature provides you with the flexibility to manage the lifecycle of device certificates signed by the registered CA that are yet to be registered with AWS IoT. By marking the status INACTIVE, you prevent any new device certificates issued by the compromised CA to be registered in your account. You can run the following command to deactivate the CA certificate:\n$ aws iot update-ca-certificate --certificate-id <certificateId> --new-status INACTIVE\nNote: Running this command will not deactivate all of your registered device certificates. It will prevent new device certificates from being registered.\nRevoke the Device Certificate\nIf you wish to revoke a registered device certificate, use the following command to revoke it:\n$ aws iot update-certificate --certificate-id <certificateId> --new-status REVOKED\nUse the list-certificates-by-ca CLI command to get a list of registered device certificates, sorted by the date of registration, that are issued by the CA certificate:\n$ aws iot list-certificates-by-ca --ca-certificate-id <caCertificateId>\nIf an error or exception occurs during the auto-registration of the device certificates, AWS IoT will send the events or message to CloudWatch Logs. To set up CloudWatch Logs for your account, see the AWS IoT Developer Guide.\n'"
259,Bites of IoT – Introduction,b'Nick Corbett',2017-05-11T21:57:31+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/bites-of-iot-introduction/,"b'Welcome to Bites of IoT, the first post in a series designed to introduce developers to AWS IoT.\nIn this first bite, we\xe2\x80\x99ll set up a very simple client that can create things in AWS IoT, send messages to those things, subscribe to topics to receive messages from things, and then clean up. The client is available through AWS Labs on GitHub. It\xe2\x80\x99s used in this post to illustrate some IoT concepts, but will be used in later posts in this series, too.\nBefore we get into the details, let\xe2\x80\x99s cover a few concepts:\nAWS IoT is a managed service in the AWS Cloud that enables your devices to easily and securely connect to a rich ecosystem of cloud-based services or your own homegrown systems. The service enables this connectivity while reliably scaling to billions of devices sending trillions of messages. The service includes these building blocks:\nMessage Broker \xe2\x80\x93 Acts as a front door for your device to the AWS Cloud. The message broker exposes publish-and-subscribe messaging capabilities available for use by devices through transport protocols like MQTT, HTTP, and WebSocket.\nRules Engine \xe2\x80\x93 This is the point closest to the front door where your solution can make decisions about a device\xe2\x80\x99s messages (for example, message filtering, routing messages to other services, and even a direct processing of messages in your solution). We will explore the facets of the rules engine in later posts.\nDevice Shadow \xe2\x80\x93 Sometimes referred to as a thing shadow, this is a logical representation of a physical device\xe2\x80\x99s reported state or desired future state. Although the concept is a bit abstract, this building block provides a huge benefit for customers who build web- or mobile-based applications that need to interact with real devices at any scale. In later posts, we will explore the ways in which the device shadow is used in these interactions.\nAWS APIs and the AWS Management Console \xe2\x80\x93 These are the mechanisms used to provision every AWS service. This post and all others in this series will include interaction with AWS through the APIs and AWS Management Console. In all Bites of IoT posts we assume you have an IAM user with developer-level permissions in an AWS account.\nThe relationships between these building blocks is:\nAWS IoT has a message broker, rules engine, and device shadows.\nAWS IoT is a part of the AWS Cloud.\nInstalling ELF\nThe AWS IoT ELF Python example client demonstrates how you can create things, send messages to things, subscribe to topics to receive messages from things, and clean up things in AWS IoT by using the AWS SDK for Python and the standard AWS IoT device client.\nTo ensure you have a simple working IoT client for this and subsequent blog posts, follow the Getting Started instructions for your computing environment. Make sure your AWS user can access the AWS IoT console.\nUnderstanding the ELF Client and AWS IoT\nWe\xe2\x80\x99ll go through the AWS IoT ELF commands to show how a device interacts with the building blocks of AWS IoT.\nWhen you execute the create command, AWS IoT ELF will create a certificate, then a thing, and then attach the thing to the certificate. At this point, the device that possesses the certificate (in this case, IoT ELF) can use the AWS IoT service as if it actually is the logical thing.\nLike a driver\xe2\x80\x99s license that identifies a person and conveys the privilege to drive, a certificate identifies the thing and conveys the privilege to use the thing\xe2\x80\x99s AWS IoT building blocks; specifically, the device can interact with the device shadow and message broker.\nWhen you execute the send command, AWS IoT ELF will first create a policy that allows interaction with thing-specific topics for general messaging and device shadow messages. Then AWS IoT ELF will attach the policy to the certificate. The device can now publish and subscribe to messages on topics in the message broker and interact with the device shadow associated with the previously attached thing.\nTo continue the driver\xe2\x80\x99s license analogy, even after drivers obtain a license, they can only use their car on roads in the country for which they have the privilege to drive. Similarly, when a device has a certificate, it can interact with the AWS IoT service, but the IoT policy dictates which topics or \xe2\x80\x9clanes\xe2\x80\x9d the device can use to send and receive messages.\nAfter a policy is configured for a device (or, in this case, AWS IoT ELF) the topics through which messages are sent convey the purpose of each message to a customer\xe2\x80\x99s solution.\nFor example, messages sent or received on a topic elf/thing_0 are considered general purpose messages for the ELF in the solution. These messages might have a customer-defined format and convey telemetry or commands for use by the customer\xe2\x80\x99s solution. But there are topics in AWS IoT that are reserved for interaction with building blocks of the AWS IoT service itself.\nFor example, a device named thing_0 can report its current state and subscribe to requests to change state through messages flowing through the thing\xe2\x80\x99s device shadow topic $aws/things/thing_0/shadow/update. Messages sent and received on this topic must follow the format expected by the device shadow and are tracked as state transitions of the thing.\nThis topic-based interaction keeps messages flowing in the correct lanes of the solution. It is controlled by using AWS IoT to attach policies to the certificate possessed by the device.\nFinally, when you execute the clean command, AWS IoT ELF detaches the IoT policy and thing from the certificate, deactivates the certificate, and then deletes the policy, thing, and certificate.\nSubscribing to Topics in the AWS Console\nInstead of using the subscribe command in AWS IoT ELF, we will now use the ELF to send messages to AWS IoT and then use the AWS IoT console to subscribe to those messages:\nSign in to the AWS Management Console, and then choose the AWS IoT icon.\nIn the AWS IoT console, choose MQTT Client.\nIn the Client ID field, type web-elf, and then choose Connect.\nChoose Subscribe to topic and in the Subscription topic field, type elf/#. This will subscribe the console\xe2\x80\x99s built-in MQTT client to the default AWS IoT ELF topic.\nNote: These steps are similar to those described in View Device MQTT Messages in the AWS IoT Developer Guide.\nExecute these commands from the directory in which you installed AWS IoT ELF:\npython elf.py create\npython elf.py send --duration 30\nGo back the AWS IoT console, and for about 30 seconds, you will see messages being sent by AWS IoT ELF.\nSpecifically, what you\xe2\x80\x99re seeing in the console is a result of:\nThe ELF creating messages to send.\nThe ELF sharing the certificate with AWS IoT to identify itself as a device mapped to a thing.\nThe ELF using the MQTT protocol to send a message to the elf/thing_0 topic.\nThe policy previously attached to the certificate being checked and, if the policy allows it, the message being sent on the elf/thing_0 topic.\nThe AWS IoT console\xe2\x80\x99s built-in MQTT client indirectly subscribing to the elf/thing_0 topic. (The # in elf/# is a wildcard that means \xe2\x80\x9ceverything from this point in the topic hierarchy and below.\xe2\x80\x9d)\nNext Topics in the Series\nUpcoming Bites of IoT posts will show simple routing examples using AWS IoT ELF and the rules engine. These examples will cover sending notifications, streaming and saving messages, republishing messages, computing on messages, and finally, searching messages.\nAfter that, we\xe2\x80\x99ll explore the not-so-shadowy world of device shadows to show how truly powerful this building block can be when added to an IoT solution designer\xe2\x80\x99s toolbox.\nI hope you\xe2\x80\x99ve enjoyed taking your first small bite out of IoT. I look forward to offering up other tasty morsels in the near future.\nMay your success be swift and your solution scalable. Feel free to leave your feedback in the comments.'"
260,Anomaly Detection Using AWS IoT and AWS Lambda,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/anomaly-detection-using-aws-iot-and-aws-lambda/,"b'September 8, 2021: Amazon Elasticsearch Service has been renamed to Amazon OpenSearch Service. See details.\nOne of the biggest benefits of the Internet of Things (IoT) is the ability to get contextual insight from sensor data. Before you analyze sensor data, you may want to remove anomalies. Sometimes, though, you may want to analyze the anomalies or at least be notified of their presence.\nIn this blog post, we will focus on detecting contextual anomalies. An example of a contextual anomaly is a temperature measurement that suddenly jumps from 50 to 70 degrees. The 70-degree measurement may not be unusual, but it is unusual in a context in which previous measurements were much lower. For more information about anomaly detection, see the survey by Varun Chandola, et al. [1]\nPrerequisites\nYou should be familiar with the AWS CLI and should have set up an Amazon Cognito identity pool. For information, see Authenticate Users with Amazon Cognito Identity.\nAlthough mathematical knowledge is not required, we encourage you to check out the references.\nContextual Anomaly Detection\nThe demo in this post uses wind velocity measurements from the San Francisco Wind Monitoring Data as the data set. You can download the formatted data set here. The algorithm we\xe2\x80\x99ll use is called the probabilistic exponentially weighted moving average (PEWMA), which was proposed by Carter and Streilein [2]. The details of the algorithm are not covered in this post, but at a high level, the algorithm is calculating an average and standard deviation of the time-series data and evaluating the probability of observing the current point. If the probability is below a set threshold, then it is marked as an anomaly. A plot of the raw data and an example of the upper and lower bounds of what is considered to be normal behavior is shown here:\nThe data flow for this anomaly detection process is shown in the following figure:\nData is sent from our sensor to AWS IoT, where it is routed to AWS Lambda through the AWS IoT Rules Engine. Lambda executes the logic for anomaly detection and because the algorithm requires knowledge of previous measurements, uses Amazon DynamoDB as a key-value store. The Lambda function republishes the message along with parameters extracted from the PEWMA algorithm. The results can be viewed in your browser through a WebSocket connection to AWS IoT on your local machine. A variation of this flow is to route observations marked as anomalous to Amazon OpenSearch Service (successor to Amazon Elasticsearch Service) or Amazon S3.\nFor the anomaly detection method, we are using AWS Lambda with Python 2.7. Use the following AWS CLI command to set up your DynamoDB table:\naws dynamodb create-table --table-name windDemo --attribute-definitions AttributeName=Station_Name,AttributeType=S  --key-schema AttributeName=Station_Name,KeyType=HASH --provisioned-throughput ReadCapacityUnits=50,WriteCapacityUnits=50\nNow we need to create a role that will give trust permissions to Lambda and AWS IoT to execute actions on our behalf. To do this, save the following text as iot_lambda_role.json.\n{\n""Version"": ""2012-10-17"",\n""Statement"": [{\n   ""Sid"": """",\n   ""Effect"": ""Allow"",\n   ""Principal"": {\n      ""Service"": [""lambda.amazonaws.com"", ""iot.amazonaws.com""]\n   },\n   ""Action"": ""sts:AssumeRole""\n }]\n}\nThe actions Lambda will execute on our behalf (access DynamoDB, AWS IoT, and logging) are defined in a policy document like the following. Save the following text as anom_det_policy.json.\n{\n ""Version"": ""2012-10-17"",\n ""Statement"": [\n  {\n   ""Sid"": ""Stmt1463425014235"",\n   ""Action"": [\n    ""dynamodb:GetItem"",\n    ""dynamodb:PutItem""\n   ],\n   ""Effect"": ""Allow"",\n   ""Resource"": ""*""\n  },\n  {\n   ""Sid"": ""Stmt1463425053236"",\n   ""Action"": [\n   ""iot:Connect"",\n   ""iot:Publish""\n  ],\n  ""Effect"": ""Allow"",\n  ""Resource"": ""*""\n },\n {\n  ""Effect"": ""Allow"",\n  ""Action"": [\n   ""logs:CreateLogGroup"",\n   ""logs:CreateLogStream"",\n   ""logs:PutLogEvents""\n  ],\n  ""Resource"": ""arn:aws:logs:*:*:*""\n  }\n ]\n}\nThe following commands will create the role, create the policy, and attach the policy to the role.\naws iam create-role --role-name iot_lambda_role --assume-role-policy-document file://iot_lambda_role.json\naws iam create-policy --policy-name anom_det_policy --policy-document file://anom_det_policy.json\naws iam attach-role-policy --role-name iot_lambda_role --policy-arn arn:aws:iam::<your-aws-account-id-here>:policy/anom_det_policy\nThe next step is to create the Lambda function. Download the code for the Lambda function. The Lambda function will be executed every time a message is sent to the anom/detect topic. It will perform the PEWMA algorithm and republish the results to the anom/pred topic. Use the following command to create the Lambda function from the AWS CLI.\naws lambda create-function \\\n --function-name anom_detector \\\n --runtime python2.7 \\\n --region us-east-1 \\\n --role arn:aws:iam::<your-aws-account-id-here>:role/iot_lambda_role  \\\n --handler lambda_function.lambda_handler \\\n --memory-size 512 \\\n --timeout 15 \\\n --description ""lambda function which implements probabilistic exponentially weighted moving average"" \\\n --zip-file fileb://lambda_function.zip\nNow we need to create a rule that will send messages on a topic in AWS IoT to the Lambda function and give our rule permission to invoke Lambda. Copy and paste the following code into a JSON file and save it as anomaly_rule.json.\n{\n        ""sql"": ""SELECT * FROM \'anom/detect\'"",\n        ""ruleDisabled"": false,\n        ""actions"": [{\n          ""lambda"": {\n            ""functionArn"": ""arn:aws:lambda:us-east-1:<your-aws-account-id-here>:function:anom_detector""\n           }\n         }]\n}\nWe will use this JSON message to create the rule and give it permission to call Lambda using the following AWS CLI commands.\naws iot create-topic-rule --rule-name anomaly_detection_lambda --topic-rule-payload file://anomaly_rule.json\naws lambda add-permission --function-name ""anom_detector"" --region ""us-east-1"" --principal iot.amazonaws.com --source-arn arn:aws:iot:us-east-1:<your-aws-account-id-here>:rule/anomaly_detection_lambda --source-account ""<your-aws-account-id-here>"" --statement-id ""123123123"" --action ""lambda:InvokeFunction""\nAll of the resources required to run the demo are now created. To run the demo, download this script, and then use the following AWS CLI command to start sending data to AWS IoT.\npython emit_json_data.py anom/detect SF36.json\nViewing Your Data Stream and Anomaly Boundaries\nTo connect to AWS IoT and view the output of the anomaly detection algorithm, download this WebSocket example. To use the websocket demo on your local machine, modify the config.js file to include your access key, secret key, Amazon Cognito pool ID, region, and AWS IoT endpoint. This websocket demo is only meant to be run on your local machine to be able to visualize the data stream and anomaly boundaries. Do not publish the html page in the demo to the public or in general any code that contains your API or secret key. If you don\xe2\x80\x99t know your IoT endpoint, use the following AWS CLI command.\naws iot describe-endpoint\nNow you can open the index.html file, connect to AWS IoT, and subscribe to the topic the anomaly detection algorithm is publishing to. You should start to see the plot of the raw data and the calculation of the anomaly boundaries. The anomaly boundaries set for the plot are 3.3 standard deviations away from the moving average, which corresponds to a threshold of 0.002. After the streaming plot is working, you can modify the alpha_0 and beta parameters in the Lambda function to see how those changes affect the anomaly boundary in real time.\nThe following figures shows what the streaming anomaly plot should look like in your browser:\n'"
261,Introducing AWS IoT Device SDKs for Java and Python,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/introducing-aws-iot-device-sdks-for-java-and-python/,"b'We are proud to announce two new device SDKs for AWS IoT \xe2\x80\x93 the AWS IoT SDK for Java and the AWS IoT SDK for Python. These SDKs add to those already available for AWS IoT:\nEmbedded C\nJavaScript/Node.js\nArduino Y\xc3\xban\niOS (part of AWS Mobile SDK and samples for iOS)\nAndroid (part of AWS Mobile SDK and samples for Android)\nThe Java and Python SDKs help you easily and quickly connect your device or application to AWS IoT, send and receive messages using either MQTT or MQTT over the WebSocket protocol, and exchange state information with device shadows (sometimes referred to as thing shadows). All of the SDKs are open-sourced on GitHub, so you can use them as is or tweak them for your device or application.\nUsing the AWS IoT SDK for Java\nYou can get started with the SDK for Java by integrating it into an existing application or by trying the included sample applications. The SDK and samples are available both as source code in GitHub and binaries in Maven. For information about using the SDK, see the readme. In this post, we will show you how to load and run the samples from source code so you can step through and see the SDK in action.\nAcquire and build the samples from source code\nClone the aws-iot-device-sdk-java repository to your development machine.\n$ git clone https://github.com/aws/aws-iot-device-sdk-java.git\n$ cd aws-iot-device-sdk-java\nTo build from the command line:\na. Make sure you have Maven installed.\nb. Navigate to the aws-iot-device-sdk-java-samples folder.\nc. Run mvn clean install to build the project.\nTo build from an IDE like Eclipse:\na. Make sure you have installed Maven support for your IDE.\nb. Navigate to the aws-iot-device-sdk-java-samples folder and load the pom.xml file in your IDE. (In Eclipse, from the File menu, choose Import, choose Maven, and then choose Existing Maven Projects.\nc. Build the project. Eclipse is configured by default to build automatically.\nRun the samples\nThere are three samples applications included with the SDK.\nPublish/Subscribe sample: This sample consists of two publishers publishing one message per second to a test topic, sdkTest/sub. One subscriber subscribing to the same topic receives and prints the messages.\nDevice Shadow sample: This example demonstrates how to keep the device connected with its shadow in the cloud. This is the recommended way of accessing a shadow and keeping it synchronized with the device. To see this in action, you can use the AWS IoT console to update the shadow and observe the corresponding state change in this sample application.\nDevice Shadow Echo sample: This sample consists of a simple demo that uses shadow methods to send a shadow update and then retrieve it every second.\nFrom the command line, use the following commands and parameters to execute the sample applications (assuming TLS mutual authentication is used) from the aws-iot-device-sdk-java-samples folder. If you are using Eclipse, specify the parameters in the Run/Debug Configurations of your project and then press F11 to launch it in debug mode. You can find the parameter values in the AWS IoT console by navigating to the thing and choosing Connect Device.\nTo run the Publish/Subscribe sample, use the following command:\n$ mvn exec:java -Dexec.mainClass=""com.amazonaws.services.iot.client.sample.pubSub.PublishSubscribeSample"" -Dexec.args=""-clientEndpoint .iot..amazonaws.com -clientId  -certificateFile  -privateKeyFile ""\nTo run the Device Shadow sample, use the following command:\n$ mvn exec:java -Dexec.mainClass=""com.amazonaws.services.iot.client.sample.shadow.ShadowSample"" -Dexec.args=""-clientEndpoint .iot..amazonaws.com -clientId -thingName -certificateFile -privateKeyFile ""\nTo run the Device Shadow Echo sample, use the following command:\n$ mvn exec:java -Dexec.mainClass=""com.amazonaws.services.iot.client.sample.shadowEcho.ShadowEchoSample"" -Dexec.args=""-clientEndpoint .iot..amazonaws.com -clientId -thingName -certificateFile -privateKeyFile ""\nUsing the AWS IoT SDK for Python\nYou can get started with the SDK for Python by integrating it into an existing application or by trying the included sample applications. The SDK is available both as a package in PyPi and as source with samples on GitHub. For information about using the SDK, see the readme. In this post, we will show you how to load and run the samples.\nAcquire the samples\nClone the aws-iot-device-sdk-python repository to your development machine.\n$ git clone https://github.com/aws/aws-iot-device-sdk-python.git\n$ cd aws-iot-device-sdk-python\n$ python setup.py install\nRun the samples\nThere are four samples applications included with the SDK:\nBasicPubSub sample: This example demonstrates a simple MQTT publish/subscribe operation using AWS IoT. It first subscribes to a topic and registers a callback to print new messages. It then publishes to the same topic in a loop.\nBasicPubSub with Amazon Cognito Session Token sample: This example builds on the first sample by using an Amazon Cognito Identity session token. Using the AWS SDK for Python (boto3), it first makes a request to Amazon Cognito to retrieve the access ID, the access key, and the session token for temporary authentication. Using the AWS IoT SDK for Python, it then uses these credentials to connect to AWS IoT and communicate data/messages using MQTT over the WebSocket protocol.\nThingShadowEcho sample: This example demonstrates how a device communicates with AWS IoT, syncing data into the device shadow in the cloud and receiving commands from another app. When there is a new command from the app to change the desired state of the device, the device receives this request on a delta callback function and applies the change by publishing it as the reported state. To see this in action, you can use the AWS IoT console to update the shadow and observe the corresponding state change in this sample application.\nBasicShadow sample: This example demonstrates the use of basic shadow operations (update/delta). It has two scripts that perform shadow update operations and listen on delta topics, respectively. The example shows how a shadow update request triggers delta events.\nFrom the command line, use the following commands and parameters to execute the sample applications. You can find the parameter values for the commands in the AWS IoT console by navigating to the thing and choosing Connect Device.\nTo run the BasicPubSub sample, use the command below that corresponds to your connection type:\n$ # Certificate based mutual authentication\n$ python basicPubSub.py -e -r -c -k\n$ # MQTT over WebSocket\n$ python basicPubSub.py -e -r -w\nFor the BasicPubSub with Amazon Cognito Session Token sample, you will need:\nYour Amazon Cognito identity pool ID.\nA role that allows unauthenticated identities to connect. Make sure that the policy attached to the unauthenticated role has permissions to access the required AWS IoT APIs. For more information about Amazon Cognito, see here.\nTo run the sample, use the following command:\n$ python basicPubSub_CognitoSTS.py -e -r -C\nTo run the ThingShadowEcho sample, use the command below that corresponds to your connection type:\n$ # Certificate based mutual authentication\n$ python ThingShadowEcho.py -e -r -c -k\n$ # MQTT over WebSocket\n$ python ThingShadowEcho.py -e -r -w\nTo run the BasicShadow sample, first start the basicShadowDeltaListener. Use the command below that corresponds to your connection type:\n$ # Certificate-based mutual authentication\n$ python basicShadowDeltaListener.py -e -r -c -k\n$ # MQTT over WebSocket\n$ python basicShadowDeltaListener.py -e -r -w\nThen, start the basicShadowUpdater. Use the command below that corresponds to your connection type:\n$ # Certificate-based mutual authentication\n$ python basicShadowUpdater.py -e -r -c -k\n$ # MQTT over WebSockets\n$ python basicShadowUpdater.py -e -r -w\nSummary\nWe hope you found this blog post useful. We regularly update all of the SDKs as new features are added to AWS IoT. We will also be adding more SDKs in the coming months. Stay tuned to this blog and GitHub for updates. Feel free to leave your feedback in the comments.'"
262,Device Simulation with AWS IoT and AWS Lambda,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/device-simulation-with-aws-iot-and-aws-lambda/,"b'September 8, 2021: Amazon Elasticsearch Service has been renamed to Amazon OpenSearch Service. See details.\nThe AWS IoT platform enables you to connect your devices and build scalable Internet of Things solutions with the breadth of Amazon Web Services.\nWhen shopping for a new tool, many developers want to be able to test-drive options before making a choice. When evaluating an IoT solution, it\xe2\x80\x99s not practical to do so at scale with physical devices. Building a sensor simulator is the next best choice. With a sensor simulator built on top of AWS Lambda, you can elastically generate device sensors that report their state to the cloud.\nIn this blog post, you will learn how to implement a simulator that feeds data sets into AWS IoT. You\xe2\x80\x99ll see how to monitor the simulators in real time, visualize data, configure your own sensor, and add hooks to start simulators from your projects.\nWhy Simulate? Why Lambda?\nOne device is cheap, but you\xe2\x80\x99re building at a bigger scale than that. What will data for all of your devices look like in AWS? Simulation is an inexpensive means to test a cloud platform at scale, without first making changes to your real devices.\nAWS Lambda is a perfect partner for simulation. On-demand, serverless compute time lets you try out a fleet of devices on AWS IoT with ease. In the Lambda function provided in this post, you\xe2\x80\x99ll be able to specify the following each time you run the function:\nnumber of devices to simulate\nsimulation duration\npublish frequency\nmessage topic\ndata set\nAmazon OpenSearch Service (successor to Amazon Elasticsearch Service) domain\nThe simulator connects to AWS IoT and publishes data as messages over MQTT. You can simulate many devices with the same configuration, or invoke multiple Lambda functions with unique configurations. You can test the functioning of AWS IoT policies by making changes to your Lambda execution role.\nRunning the AWS CloudFormation Template\nAs part of this blog post, we are providing an AWS CloudFormation template to get you up and running with Lambda simulators quickly. This template creates a stack of AWS resources that do the following:\na Lambda function that simulates devices publishing to AWS IoT.\nan Amazon ES domain for visualizing published data.\nan AWS IoT rule that forwards simulator messages to Amazon ES.\nan Amazon S3 bucket to store your simulator data sets.\nall required AWS Identity and Access Management (IAM) roles.\nNote: This CloudFormation template is written to be executed in the US West (Oregon) Region. When creating Lambda functions through CloudFormation, the Lambda simulator source must be hosted in the same region as the S3 bucket. To use this template in another AWS region, download the Lambda simulator source, and you can update the CloudFormation template to point to a bucket you own with the source there.\nTo run the CloudFormation template and create these resources:\nSign in to the AWS Management Console and open the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation/home?region=us-west-2.\nChoose Create Stack.\nIn the Template section, select Specify an Amazon S3 template URL to type ot paste the following URL, and then choose Next.\nhttps://s3-us-west-2.amazonaws.com/iot-us-west-2-simulator-publicbucket/createSimulator.json\n In the Specify Details section, type a name for your stack (for example, my-iot-simulator-stack).\nIn the Parameters section, type a name for your S3 bucket (for example, YOURNAME-iot-simulator-data-sets), and then choose Next.\nOn the Options page, choose Next.\nOn the Review page, under Capabilities, select the I acknowledge that this template might cause AWS CloudFormation to create IAM resources check box, and choose Create.\nCloudFormation will now create your AWS resources. It can take up to ten minutes to create an Amazon Elasticsearch Service domain.\nStarting the Simulator\nUntil you\xe2\x80\x99re familiar with the configuration parameters, you should start the simulator manually. To do so, navigate to the AWS Lambda console. The simulator will have the prefix of your CloudFormation stack (for example, my-iot-simulator-stack-AWSLambda-ABC123). In your function\xe2\x80\x99s view, from the Actions drop-down menu, choose Configure test event.\nThis is where you will set the runtime configuration of your simulator. The following sample JSON configuration is followed by an explanation of options.\n {\n  ""esEndpoint"": ""search-my-iot-elastic-1ubx76h2qqoan-3dijocbhik332asd4sryz4au5q.us-west-2.es.amazonaws.com"",\n  ""esDomainArn"": ""arn:aws:es:us-west-2:111122223333:domain/my-iot-elastic-1ubxg6r2qwean"",\n  ""topic"": ""test/topic"",\n  ""simTime"": 10000,\n  ""interval"": 500,\n  ""numDevice"": 3\n }\nesEndpoint: your Amazon ES domain endpoint.\nesDomainArn: your Amazon ES domain.\ntopic: the AWS IoT topic this simulator will publish to.\nsimTime: the duration of this simulator, in milliseconds (max 240000).\ninterval: the interval between publishes, in milliseconds.\nnumDevice: the number of devices of this configuration to run.\nbucketName: (OPTIONAL) the S3 bucket with your simulator data set to publish. Defaults to iot-us-west-2-simulator-publicbucket.\nkey: (OPTIONAL) the S3 key of your simulator data file to read for published messages. Defaults to physiological-data.csv.\nReplace the values shown for esEndpoint and esDomainArn with those for your domain. You can find these values in the Amazon OpenSearch Service console after you click on your domain.\nNote: If you omit the optional bucketName and key parameters, a data set file provided with the simulator will be used. It contains records of a sleep healthcare monitoring device. You can review this data set here.\nIn the AWS Lambda console, when you choose Save and test, your configuration JSON will be saved and the Lambda function will start with this configuration. If you scroll down, you\xe2\x80\x99ll see Execution result: succeeded. Congratulations, you\xe2\x80\x99ve run your first device simulator!\nVisualize the Data\nThere are two ways to see the simulator data in AWS:\nIn real time, in the AWS IoT console.\nIn a data visualization dashboard called Kibana, which is included with the Amazon ES domain.\nIn the AWS IoT console, navigate to the MQTT Client. Enter or generate a client ID, and then choose Connect. Choose Subscribe to topic, enter the topic you specified in your Lambda configuration, and then choose Subscribe. If your Lambda simulator is running, you should now see these messages arriving at the interval you specified, times the number of devices specified. If your simulator has already run, in the AWS Lambda console, choose Test again to restart it.\nTo visualize the published data from the simulator in Kibana, open the Amazon OpenSearch Service console. Find your Amazon ES domain in the list and choose it. Open the Kibana link in a new tab.\nOn your first visit to Kibana, you\xe2\x80\x99ll see a settings page where you can choose an index pattern. This tells Kibana which indices to surface in your queries. Clear the Index contains time-based events box (you may want this in the future for your own data sets), and in Index name or pattern, type \xe2\x80\x9cindex_*\xe2\x80\x9d. Choose Create.\nChoose the Discover tab to see your simulated data and start using Kibana. For more information about configuring visualizations of AWS IoT data in Kibana, see another of our blog posts.\nExtending the Simulator\nNow that you have a working device simulator, let\xe2\x80\x99s break down the important bits of code in the simulator Lambda function in case you want to extend it. This simulator will read through the input sample data and publish one message per line, per device, until the end of file, duration, or maximum Lambda runtime is reached.\nFor example, if the input sample data is 10 lines long, the number of devices to simulate is 30, and the interval is 1000 ms, then over 10 seconds of runtime, this simulator will make 30 connections to AWS IoT and publish a total of 300 messages.\nIn index.js, the event handler calls createResources(Object, Function). This exists to ensure that your Amazon ES domain is ready and your AWS IoT rule is set up to feed it incoming published messages. It also fetches a CSV file from S3, which will be parsed as messages for your simulated devices to publish.\n createResources(event, (err, data) => {\n   if (err) {\n     console.log(err);\n     return;\n   }\n   const s3 = new AWS.S3({\n     region: \'us-west-2\'\n   });\n   var bucket = event.bucketName;\n   var key = decodeURIComponent(event.key).replace(/\\+/g, "" "");\n \n   s3.getObject({\n     Bucket: bucket,\n     Key: key\n   }, (err, data) => {\n     if (err) {\n       context.fail(""Failed to read config file"");\n       return;\n     }\n     event.data = data.Body.toString(); // attach file content to event\n     const iot = new AWS.Iot();\n     iot.describeEndpoint({}, (err, data) => {\n       if (err) {\n         console.log(err);\n         return;\n       }\n       event.endpoint = data.endpointAddress;\n       processText(event, context);\n     });\n   });\n });\nAfter this is complete, the processText(Object, Object) function will be called. It will ingest your device sample data with parseData(Object, Integer) and then set up one MQTT client per device to be simulated. This is where you can adjust the way in which the MQTT clients are created.\n function processText(params, context) {\n   const mqttController = new mqtt.ClientControllerCache();\n   const jsonData = parseData(params, params.numDevice);\n   for (var i = 0; i < params.numDevice; i++) {\n     var connectOpts = {\n       accessKey: params.accessKey,\n       clientId: `${Math.random().toString(36).substring(2,12)}`, // 10-bit random string\n       endpoint: params.endpoint,\n       secretKey: params.secretKey,\n       sessionToken: params.sessionToken,\n       regionName: params.region,\n       topic: params.topic\n     };\n     var simOpts = {\n       simTime: params.simTime,\n       interval: params.interval,\n       index: i\n     };\n     createMqttClient(connectOpts, simOpts, mqttController, jsonData, context);\n   }\n }\nThe data parsing function, parseData(Object, Integer), reads in your sample data file and splits by new lines and then by comma characters. (This is the standard way of reading in a CSV file.) If you have a different file format to parse, you can edit the way this function works. To read in JSON, you\xe2\x80\x99ll want to iterate over keys or a JSON array value.\n function parseData(params, numDevice) {\n   var dataJSON = [];\n   const lines = params.data.split(\'\\n\');\n   var lineNumber = lines.length;\n   for (var i = 0; i < lineNumber; i++) {\n     var columns = lines[i].trim().split(\',\');\n     var dev = [];\n     for (var j = 0; j < numDevice; j++) { \n       var clientId = \'client_\' + j + \'@\' + params.endpoint;\n       dev.push({\n         clientId: clientId,\n         field: columns[j]\n       });\n     }\n     dataJSON.push(dev);\n   }\n   return dataJSON;\n }\nAfter parsing your data, the next step is to create one MQTT client per device to be simulated. This Lambda function uses MQTT over the WebSocket protocol to connect and publish messages to AWS IoT. The createMqttClient(Object, Object, Object, Array, Object) function sets up event handlers for the MQTT protocol events.\n function createMqttClient(connectOpts, simOpts, mqttController, jsonData, context) {\n   var cbs = {\n     onConnect: onConnect,\n     onSubSuccess: onSubSuccess,\n     onMessageArrived: onMessageArrived,\n     onConnectionLost: onConnectionLost\n   };\n   var clientController = mqttController.getClient(connectOpts, cbs);\n   /* ... define callback functions ... */\n }\nThe onConnect() function defines what happens when each device simulator completes the connection to AWS IoT. In this case, it then subscribes to topic, as defined in the Lambda event input (for example, test/topic). The onSubSuccess() function defines what happens when the subscription to a topic is successful. In this case, it starts the JavaScript interval, which will start publishing messages from your sample data.\n function onConnect() {\n   clientController.subscribe();\n }\n function onMessageArrived(data) {\n   // do nothing\n }\n function onSubSuccess() {\n   var index = 0;\n   var interval = setInterval(() => {\n     var line = jsonData[index++][simOpts.index];\n     clientController.publish(line);\n   }, simOpts.interval);\n   setTimeout(() => {\n     clearInterval(interval);\n     clientController.disconnect();\n     setTimeout(() => { // set drain time to disconnect all connections\n       context.succeed();\n     }, 1000);\n   }, simOpts.simTime);\n }\n function onConnectionLost() {\n   console.log(\'Connection is lost\');\n }\nThe simulator Lambda function is designed to simulate sensing devices; it does not define behavior for responding to incoming messages. If you\xe2\x80\x99d like to define an actuator device or a bi-directional sensing/actuating device, we recommend that you add simulation logic to the onMessageArrived() function. By expanding the scope of topics subscribed and behaviors to take when new messages arrive, you can quickly define a device simulator that sends and receives messages.\nAdding Hooks\nThe simplest way to start the device simulator is to send test events from the AWS Lambda console. If you\xe2\x80\x99re wondering how to spin up a fleet of different devices or dynamically start simulators, we\xe2\x80\x99ll describe ways to invoke Lambda functions.\nOne great way to define interfaces to Lambda is with Amazon API Gateway. With API Gateway, you can write an HTTP or HTTPS interface to invoke your Lambda functions. By wrapping your device simulator, you can write a web service to spin up device simulators either with a preconfigured simulator template or by passing HTTP parameters to dynamically define devices. This method makes it possible for web application and service developers to build on top of your simulator pattern. Now you can have a web hook, IFTTT, or Zapier plugin to start simulators!\nAnother pattern to start simulators is on a schedule with Amazon CloudWatch Events. You can specify a Cron expression that will set up a device fleet at certain times and days. Although you can add a CloudWatch event source in the AWS Lambda console, for this task the best practice is to add it from the CloudWatch console. It\xe2\x80\x99s easier to configure the Lambda event input required to start your simulator. Alternatively, you can create additional defaults in your Lambda function to avoid passing in any parameters.\nA third way to invoke your device simulators is in response to a message published to AWS IoT. You can set up a rule in AWS IoT that invokes your Lambda function to start up a simulated device fleet. Alternatively, you can model a fleet of devices based on a single prototype. Store all of a real device\xe2\x80\x99s messages in an Amazon DynamoDB table with one rule, and then use any Lambda invocation method to replay your real device as a simulated fleet.\nFinally, what better way to test your solution architecture than by running a fleet of simulated devices against it to see where it can be improved? Build a step into your workflow with Amazon Simple Workflow Service that starts up a simulation fleet as part of your flow. Or, as part of a code deployment in AWS CodeDeploy, you can send a deployment notification to an Amazon Simple Notification Service topic, which then invokes your Lambda simulator fleet to kick off a job that tests your new version of software.\nSummary\nThis blog post provides you with a CloudFormation template for getting started with device simulation in AWS IoT and AWS Lambda. It steps you through running the template and starting the simulator. It also gives you ideas for editing, extending, and invoking the simulator. Feel free to leave comments here or share your stories about device simulation and let us know what you build in the AWS IoT forums!'"
263,Archive AWS IoT Device Shadows in Amazon OpenSearch Service,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/archive-aws-iot-device-shadows-in-amazon-elasticsearch-service/,"b'September 8, 2021: Amazon Elasticsearch Service has been renamed to Amazon OpenSearch Service. See details.\nIn AWS IoT, you can create a device shadow (sometimes referred to as a thing shadow) that will be used as a communication layer between your mobile/cloud application and your devices connected to AWS IoT. The shadow is a persistent, virtual representation of your devices. Because it always has a point-in-time view of the state of your device, it\xe2\x80\x99s easy to write applications that interact with your devices through device shadows.\nWhen you update the shadow of your device, the Thing Shadows service will typically publish two messages:\n/update/accepted or /update/rejected\nThis message shows whether the update you sent was accepted by the service. It will show which fields were updated and include metadata containing the last updated timestamps of those fields.\n/update/delta\nThis message is published whenever the Thing Shadows service detects a difference between the desired and reported sections of the thing shadow.\nWe\xe2\x80\x99ve now introduced a new message for shadow updates that will be published for every update:\n/update/documents\nThis message will contain the entire shadow document before the service processes the request and the entire shadow document after the request is processed.\nThe new documents messages, coupled with AWS IoT integration in Amazon OpenSearch Service (successor to Amazon Elasticsearch Service), make it easy to forward your shadows to an Amazon OpenSearch Service cluster and then use Kibana to visualize the historical shadow data.\nIn this post, I\xe2\x80\x99ll walk you through sending data to your shadow, indexing the shadow in Amazon OpenSearch Service, and visualizing it in Kibana.\nCreate an Amazon OpenSearch Service Domain\nLet\xe2\x80\x99s start with creating an Amazon OpenSearch Service domain to store the historical shadow state.\nIn the Amazon OpenSearch Service console, create a domain with name delivery-fleet.\nIn the domain creation wizard, you will be asked to set the domain access policy. You need to specify an access policy that:\nAllows AWS IoT to put data into the Amazon OpenSearch Service domain.\nAllows intended clients (such as your desktop) to query data from the Amazon OpenSearch Service domain.\nThe access policy you choose should look similar to the following example:\n{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""AWS"": ""arn:aws:iam::xxxxxxxxxxxx:role/iot-es-action-role""\n      },\n      ""Action"": ""es:ESHttpPut"",\n      ""Resource"": ""arn:aws:es:us-east-1:xxxxxxxxxxxx:domain/delivery-fleet/*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""AWS"": ""*""\n      },\n      ""Action"": ""es:*"",\n      ""Resource"": ""arn:aws:es:us-east-1:xxxxxxxxxxxx:domain/delivery-fleet/*"",\n      ""Condition"": {\n        ""IpAddress"": {\n          ""aws:SourceIp"": [\n            ""xxx.xxx.xxx.xxx"",\n            ""xxx.xxx.xxx.xxx""\n          ]\n        }\n      }\n    }\n  ]\n}\nSpecify the public IP addresses or address ranges of your intended clients (such as your desktop) in the aws:SourceIp list. To find the public IP address of a client, on the client machine, go to https://www.google.com/#q=what+is+my+public+ip+address.\nCreate the Amazon OpenSearch Service domain. It will take a few minutes. When Active is displayed for  Domain status, make a note of the domain endpoint. The endpoint will look similar to search-delivery-fleet-xxxxxxxxxxxxxxxxxxxxxxxxxx.us-east-1.es.amazonaws.com.\nNext, create an index in the Amazon OpenSearch Service domain through an HTTP request. You can use an HTTP client such as curl or DHC. In Amazon OpenSearch Service, an index is the top-level logical structure where you store and index your data. For this example, create an index with the name trucks to store the delivery truck data. As you create the index, specify a mapping in the HTTP request body to help Amazon OpenSearch Service correctly interpret geo-location and time from the sample data.\nYour HTTP POST request should look similar to the following example. You should get an HTTP 200 in response.\ncurl -XPOST https://search-delivery-fleet-xxxxxxxxxxxxxxxxxxxxxxxxxx.us-east-1.es.amazonaws.com/trucks -d \'{\n ""mappings"": {\n    ""truck"": {\n      ""properties"": {\n         ""timestampMillis"": {\n          ""type"": ""long"",\n          ""copy_to"": ""datetime""\n        },\n        ""datetime"": {\n          ""type"": ""date"",\n          ""store"": true\n        },\n        ""state"": {\n          ""properties"": {\n            ""reported"": {\n              ""properties"": {\n                ""location"": {\n                  ""type"": ""geo_point""\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\'\nConfigure an AWS IoT Rule to Route Data to Amazon OpenSearch Service\nNow that your Elasticsearch index is ready to receive data, configure an AWS IoT rule that can route the inbound data from connected trucks to the Elasticsearch index. You can use the AWS IoT console or the AWS CLI to create a rule. Your AWS IoT rule should look like the following example:\n{\n""sql"": ""SELECT current.state AS state, cast(timestamp as number) * 1000 AS timestampMillis FROM \'$aws/things/truck42/shadow/update/documents\'"",\n\n""actions"": [\n\n{\n\n""elasticsearch"": {\n\n""roleArn"": ""arn:aws:iam::xxxxxxxxxxxx:role/iot-es-action-role"",\n\n""endpoint"": ""https://search-delivery-fleet- xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.us-east-1.es.amazonaws.com"",\n\n""index"": ""trucks"",\n\n""type"": ""truck"",\n\n""id"": ""${newuuid()}""\n\n}\n\n}\n\n],\n\n""ruleDisabled"": false,\n\n""awsIotSqlVersion"": ""2016-03-23-beta""\n\n}\nThe example rule forwards the entire state document under the current subtree from the documents topic for the device shadow named truck42 to the Elasticsearch index trucks.\nThe AWS IoT service must assume an AWS IAM role in your AWS account to obtain the permissions required to insert data into your Amazon OpenSearch Service domain. In particular, the IAM role must be allowed to call the es:ESHttpPut action.\nSimulate an Internet-Connected Truck Sending Data to Your AWS IoT Device Shadow\nYou are now ready to send data to the AWS IoT device shadow where it will be indexed into Amazon OpenSearch Service.\nCreate an AWS Lambda function using this sample code to simulate an Internet-connected truck sending location and performance metrics to AWS IoT. The code is designed to update your device shadow in AWS IoT at periodic intervals with the following state:\n{\n  ""state"": {\n    ""reported"": {\n      ""nms"": 1412638168724,\n      ""location"": ""39.09972,-94.57853"",\n      ""geoJSON"": {\n        ""type"": ""Point"",\n        ""coordinates"": [\n          -94.57853,\n          39.09972\n        ]\n      },\n      ""pressure"": 111,\n      ""engine_temperature"": 213,\n      ""cargo_temperature"": 41,\n      ""rpm"": 2216,\n      ""speed"": 18,\n      ""battery"": 12.3\n    }\n  }\n}\nAWS IoT generates an account-specific endpoint for your devices to send and receive data to and from your AWS account. When you create the Lambda function, you will need to update the code with your account-specific AWS IoT endpoint. To find this endpoint, use the aws iot describe-endpoint AWS CLI command.\nMake sure that the Lambda execution role has permission to invoke the iot:UpdateThingShadow action. You can use the AWS IAM console to edit the role\xe2\x80\x99s policy and grant this permission.\nLastly, increase the execution timeout for the Lambda function from the default of 3 seconds to 5 minutes. This allows the function to add a delay between sending several consecutive messages. You can configure the timeout under Advanced Settings. (Later, when you trigger the function through the console, you will get a warning, which you can safely ignore: \xe2\x80\x9cWe are unable to display results and logs for invocations that take longer than 60 seconds. You can view the results and logs for the function in Amazon CloudWatch once the function completes executing.\xe2\x80\x9d)\nYou are now just one click away from running the simulation. Before you trigger the simulation, optionally configure one or both of the following data flow debugging tools:\nFirst, use an MQTT client to confirm delivery of truck data as acknowledged by the Thing Shadows service. There is a browser-based MQTT client available on the upper-right corner of the AWS IoT console. Connect and subscribe to topic $aws/things/truck42/shadow/update/#. This will allow you to view the messages published by the device shadow as it sees the updates come into the shadow. For more information, see Using the MQTT Client in the AWS IoT Developer Guide.\nSecond, configure AWS IoT to send logs to Amazon CloudWatch Logs. Viewing the logs there is useful, in case you need to debug issues like authentication or rule execution failures. For more information, see Setting up Cloudwatch Logs in the AWS IoT Developer Guide.\nIn the AWS Lambda console, choose the Test button to run the truck simulator Lambda function. You should see messages coming from all destinations, including the browser-based MQTT client and the Amazon OpenSearch Service domain.\nExplore and Visualize the Shadow Data in Kibana\nYou are now ready to explore the connected truck shadow data. First, confirm that your Amazon OpenSearch Service domain has received and indexed the truck data by querying Amazon OpenSearch Service through an HTTP GET request. Use an HTTP client such as curl or DHC. Your HTTP GET request should look like the following example and you should get an HTTP 200 with a non-zero number of hits in the response body:\ncurl -i -X GET \'https://search-delivery-fleet-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.us-east-1.es.amazonaws.com/trucks/_search\'\nThe next step is to start using Kibana. In the Amazon OpenSearch Service console, look up and choose the Kibana endpoint for your Amazon OpenSearch Service domain. It will look like: search-delivery-fleet-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.us-east-1.es.amazonaws.com/_plugin/kibana/.\nOn the Configure an index pattern page, for Index name or pattern, type trucks and under Time-field name,choose datetime. Kibana will then list the fields found under the trucks index:\nGo to the Discover tab to start exploring the data. By default, Kibana sets the timeframe to Last 15 minutes. You may need to increase it to Last 1 hour or some other appropriate timeframe to include the time when the truck shadow simulator Lambda function published the data. Kibana will load the data as shown in the following example:\n\nNext, use the Visualize tab for more interesting visualizations. The following example is a map that shows the maximum speed of the truck against a geohash of the location data in the AWS IoT device shadow for the truck:\n\nThis walkthrough showed you how to archive an AWS IoT device shadow in an Amazon OpenSearch Service domain. We hope you found it useful. Try it out, and feel free to leave your feedback in the comments.'"
264,Elliptic Curve Cryptography and Forward Secrecy Support in AWS IoT,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/elliptic-curve-cryptography-and-forward-secrecy-support-in-aws-iot-3/,"b'Introduction\nAWS IoT now supports Elliptic Curve Cryptography (ECC) for devices connecting to AWS IoT using TLS. You can now request an EC-based certificate for your device from AWS IoT or register your device using an existing EC-based certificate in order to establish a TLS connection. You can also connect your devices to AWS IoT using EC-based cipher suites for enhanced security on your TLS communications.\nThis blog will discuss the use of EC-based certificates to establish TLS connections. First, it will describe how to request an EC-based certificate from AWS IoT. Next, it will show you how to connect to AWS IoT using Elliptic Curve Diffie-Hellman Ephemeral(ECDHE) TLS cipher suites that provides forward secrecy.\nIn this blog post, we assume you are familiar with AWS IoT and the process of creating an AWS IoT certificate or registering your own certificate. We are going to use the AWS CLI to perform the procedures. If you don\xe2\x80\x99t have the AWS CLI installed, follow these steps. If you have the AWS CLI installed, make sure you are using the most recent version.\nFor information about authentication in AWS IoT or how to use AWS IoT-generated certificates, see the AWS IoT Developer Guide.\nElliptic Curve Cryptography\nECC is an approach to public key cryptography based on elliptic curves over finite fields. The security of ECC systems rests on the elliptic curve discrete logarithm problem, rather than the RSA\xe2\x80\x99s integer factorization problem. ECC allows devices to maintain a high security bar. ECC uses smaller keys than RSA for the same cryptographic strength.\nSymmetric Key Size (bits) RSA Key Size (bits) Elliptic Curve Key size (bits)\n80 1024 160\n112 2048 224\n128 3072 256\n192 7680 384\n256 15360 512\nNational Institute of Standards and Technology (NIST)-recommended key sizes\n  As you can see from the NIST recommended key sizes table, to achieve 128-bit of security level, a 256-bit ECC key is equivalent in strength to a 3072-bit RSA key. Due to advances in cryptanalysis, recommended key lengths increase based on the period of time for which the information needs to be protected and the increased computational power that becomes available for a malicious user to attack the system. To achieve the next 256-bit level of security, a 512-bit elliptic curve key would be required. For an equivalent level of security, 15,360-bit RSA encryption keys are required.\nEC Diffie-Hellman Ephemeral(ECDHE) cipher suites and Forward Secrecy(FS)\nTo provide forward secrecy for the traffic on <custom-endpoint>.iot.<region>.amazonaws.com, AWS IoT supports the EC Digital Signature Algorithm (ECDSA) and EC Diffie-Hellman Ephemeral (ECDHE) cipher suites for TLS. Forward secrecy is a property of secure communication protocols in which compromise of long-term keys does not compromise past session keys. That means a malicious user who learns the private key of your device should not be able to decrypt any previous communication protected under that key. Under EC Diffie-Hellman Ephemeral cipher suites, the client and server establish a shared session secret that is independent of the long-term certified private keys used to authenticate the key exchange. In RSA key exchange cipher suites, the client-selected random session secret is encrypted using the server\xe2\x80\x99s public key and sent over the wire. That means if the server\xe2\x80\x99s private key gets compromised or cracked in the future, it can be used to decrypt all previous session secrets and used to decrypt any past recorded session traffic. The server itself can be authenticated and identified using RSA or EC-based certificates.\nCreating an EC-based certificate using AWS IoT\nIn this section, you will use the AWS IoT API to create an EC-based certificate.\nFirst, using Openssl in a terminal, you will create an ECC key pair. AWS IoT allows you to request an EC-based certificate with keys on the NIST P-256 or NIST P-384 curves. The following command creates an ECC key pair using NIST P-256 ECC curve:\n$ openssl ecparam -out ecckey.key -name prime256v1 -genkey\nNext, using the generated ECC key, you will create a certificate signing request (CSR):\n$ openssl req -new -sha256 -key ecckey.key -nodes -out eccCsr.csr\nDuring the CSR process, you will be prompted for information about your device. Enter the information that is appropriate for your device.\nUsing this CSR, you can now use the CreateCertificateFromCsr API to request an EC-based certificate from AWS IoT:\n$ aws iot create-certificate-from-csr --certificate-signing-request file://eccCsr.csr --certificate-pem-outfile eccCert.crt --set-as-active\nRegistering your own EC-based certificate with AWS IoT\nIf you have your own EC-based certificate, use the following CLI command to register it with AWS IoT. This assumes you have already registered the CA certificate with AWS IoT that has signed and issued the device certificate. For more information, see the \xe2\x80\x9cUse Your Own Certificates\xe2\x80\x9d section of Authentication in AWS IoT .\n$ aws iot register-certificate --certificate-pem file://myEccCertificate.crt --set-as-active\nPerforming MQTT operations using EC-based certificate and ECDHE cipher suites\nUsing the EC-based certificate you created/registered, you can now establish a TLS session and connect to AWS IoT using any mutually supported cipher suite. In the following example, you will use the MQTT mosquitto client to connect and publish to AWS IoT using the ECDHE-ECDSA-AES128-GCM-SHA256 cipher suite. This assumes you have the permissions required to connect and publish attached to the certificate. For more information, see Authorization in the AWS IoT Developer Guide.\n$ mosquitto_pub --cafile AWSIoTCACert.crt --cert eccCert.crt --key ecckey.key -h XXXXXXXXXXXXXX.iot.us-east-1.amazonaws.com -d -p 8883 -q 1 -t foo/bar -i test --tls-version tlsv1.2 -m \xe2\x80\x9cHelloWorld\xe2\x80\x9d --ciphers ECDHE-ECDSA-AES128-GCM-SHA256\n'"
265,Embracing the Cloud for the Internet of Things,b'John Renshaw',2016-07-18T21:59:53+00:00,https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png,https://aws.amazon.com/blogs/iot/embracing-the-cloud-for-the-internet-of-things/,"b'The pace at which the world is changing has never been faster than it is today. In the last decade, we have witnessed how mobile and big data are contributing to the next technology revolution: the Internet of Things (IoT). There is a lot of hype around IoT. Is it just that, hype? We want to welcome you to the Internet of Things on AWS Official Blog where we will answer questions about IoT, its thought leaders, and how you can deploy IoT solutions in the cloud.\nTelecom operators are deploying vast data networks, which enable ubiquitous connectivity, while the cost of sensors that can sense the world around us (GPS, gyro, temperature, and so on) is declining to affordable levels. Cloud providers have made storage and compute virtually limitless with on-demand, scalable infrastructure that meets the demands of big data manipulation. With more data, machine learning algorithms and models now predict outcomes or identify patterns more precisely, driving autonomous decisions in the real world. Combined, these ingredients enable IoT.\nIoT is a term coined by Kevin Ashton, a British technology pioneer working on radio-frequency identification (RFID) who conceived a system of ubiquitous sensors connecting the physical world to the Internet. Although things, Internet, and connectivity are the three core components of IoT, the value is in closing the gap between the physical and digital world in self-reinforcing and self-improving systems.\nPlacing sensors in remote locations and analyzing enormous data sets give us context and insight into IoT use cases: Measuring vibrations from wind turbine blades and performing real-time analysis to determine maintenance needs before the blades fail. Reducing energy consumption in buildings by controlling lighting on floors where no one is present. Adjusting window shades automatically to regulate temperature and reduce load on HVAC systems. Creating self-driving vehicles that process environmental information to make split-second decisions to stop and avoid accidents. The collective knowledge about the physical world, gained through IoT, becomes the input for more efficiency, new business models, lower pollution, and better health.\nMany customers have architected their solutions on AWS. Sonos analyzes audio data and optimizes the output of speakers based on your room acoustics. BMW streams video data from cars to better inform drivers of road conditions. Shokbox monitors impacts on an ice hockey player\xe2\x80\x99s helmet to predict concussion. These incredible applications are possible because of the security and scale provided by the cloud. Until now, though, those customers have had to build each component of their IoT solutions themselves. With AWS IoT, a purpose-built service for connected devices (constrained devices, in particular) customers can focus on what makes their products and solutions better, rather than the plumbing underneath them.\nEvery IoT project requires secure transport of data to and from devices over the Internet to a cloud endpoint. The endpoint must be highly scalable, capable of filtering out noise, enriching, transforming, and transferring data to storage or back-end systems for consumption by applications. AWS IoT is a managed cloud platform that lets connected devices easily and securely interact with cloud applications and other devices. AWS IoT can support billions of devices and trillions of messages. It can process and route those messages to AWS endpoints and other devices reliably and securely. With AWS IoT, your applications can keep track of and communicate with all your devices, all the time, even when they aren\xe2\x80\x99t connected.\nWhen AWS IoT was released in December 2015, it included:\nC and Node.js SDKs.\nA message broker that supports MQTT and HTTP.\nA security layer using X.509 certificates for mutual authentication of cloud and devices and TLS 1.2 for end-to-end encryption.\nA rules engine to filter, enrich, and route data to back-end services like Amazon S3, Amazon DynamoDB, Amazon Kinesis, AWS Lambda, and more.\nA device registry service to store device metadata.\nA Device Shadows service, which allows interaction between applications and devices even when the devices are not connected.\nSince the launch, AWS IoT has listened to customer feedback and released these new features:\nSDKs for iOS and Android.\nSupport for MQTT over the WebSocket protocol to stream data to a browser.\nThe ability to use your own certificates, rather than those generated by AWS, to enable authentication of your devices.\nIntegration with Amazon Machine Learning (Amazon ML) to apply smart models to the data flowing through AWS IoT.\nAWS IoT is available in these regions: US East (Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Tokyo), EU (Dublin), EU (Frankfurt).\nTo learn more about strategies for developing IoT solutions for the cloud, download our whitepaper Core Tenets of IoT.\nThese are exciting times. It is still Day 1, we hope this blog will help you discover more about the Internet of Things and AWS IoT. We look forward to your feedback!'"
